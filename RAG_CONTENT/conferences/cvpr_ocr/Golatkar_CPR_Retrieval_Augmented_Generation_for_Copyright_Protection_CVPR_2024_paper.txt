CPR: Retrieval Augmented Generation for Copyright Protection
Aditya Golatkar Alessandro Achille Luca Zancato
Yu-Xiang Wang Ashwin Swaminathan Stefano Soatto
AWS AI Labs
{agolatka,aachille,zancato,yuxiangw, swashwin,soattos }@amazon.com
Abstract
Retrieval Augmented Generation (RAG) is emerging as
a ﬂexible and robust technique to adapt models to private
users data without training, to handle credit attribution, and
to allow efﬁcient machine unlearning at scale. However,
RAG techniques for image generation may lead to parts of
the retrieved samples being copied in the model’s output. To
reduce risks of leaking private information contained in the
retrieved set, we introduce Copy-Protected generation with
Retrieval (CPR), a new method for RAG with strong copy-
right protection guarantees in a mixed-private setting for
diffusion models. CPR allows to condition the output of dif-
fusion models on a set of retrieved images, while also guar-
anteeing that unique identiﬁable information about those
example is not exposed in the generated outputs. In partic-
ular, it does so by sampling from a mixture of public (safe)
distribution and private (user) distribution by merging their
diffusion scores at inference. We prove that CPR satisﬁes
Near Access Freeness (NAF) which bounds the amount of
information an attacker may be able to extract from the
generated images. We provide two algorithms for copy-
right protection, CPR-KL and CPR-Choose. Unlike pre-
viously proposed rejection-sampling-based NAF methods,
our methods enable efﬁcient copyright-protected sampling
with a single run of backward diffusion. We show that our
method can be applied to any pre-trained conditional diffu-
sion model, such as Stable Diffusion or unCLIP . In partic-
ular, we empirically show that applying CPR on top of un-
CLIP improves quality and text-to-image alignment of the
generated results (81.4 to 83.17 on TIFA benchmark), while
enabling credit attribution, copy-right protection, and de-
terministic, constant time, unlearning.
1. Introduction
Foundation model users may need to adapt large-scale Dif-
fusion Models to their use cases, like personalization, edit-
ing, content creation etc. However, ﬁne-tuning the model
on the user data is often not an option. This is in part due to
the steep cost of ﬁne-tuning models, but also because userdata is a mutable entity: new data is constantly added, and
low-quality data may often be ﬁltered out. Moreover, data
owners may, at any point, change their mind and demand
that their data be removed.
Retrieval Augmented Generation (RAG) has emerged as
a promising method to handle these situations. Rather than
using the user data to ﬁne-tune the model, supporting sam-
ples are retrieved from it at inference time to guide the gen-
eration of new samples. Data may be easily added or re-
moved from the retrieval data store without changes to the
model, and users may access different subsets of the data
based on their access-right. However, RAG methods are
double edged, direct access to retrieved reference images
often signiﬁcantly improves the quality of generated sam-
ples but as we depict in Fig. 1, RAG models are prone
to copy information from the retrieved examples into the
model output, potentially resulting in signiﬁcant leak of pri-
vate information. We formalize this observation in Sec. 5
and we show that applying RAG on top of a public model,
while retrieving private user data at inference time, cannot
satisfy even the weaker notion of privacy.
To remedy this, we introduce Copy-Protected Genera-
tion with Retrieval (CPR). CPR retrieves multiple private
examples from the private user data pool. Information from
all these samples is combined to generate a “private” diffu-
sion ﬂow which uses common information of those samples
while discarding any unique and identiﬁable information.
The resulting private ﬂow is then optimally combined with
the “public” ﬂow generated by the base model to generate
new outputs which still beneﬁt from the retrieved samples,
but minimize the risk of information leak.
In particular, we show that our method satisﬁes the re-
cently proposed notion of copyright protection using Near
Access Freeness (NAF) [ 62], a relaxation of differential pri-
vacy aimed at protecting speciﬁc attribute of the training
data. Differently from previously proposed methods like
[62] that realize NAF with a computationally expensive re-
jection sampling method, CPR does so by construction dur-
ing the generation. Hence making our method signiﬁcantly
faster than the previous baselines and while also keeping
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
12374
(Safe)(NAF-Protected Images)(Private)Safe ModelRetrieved ImageRetrieval ScoreRetrieval-Mix-ScoreCPR-KLCPR-MinCPR-Alt
Figure 1. RAG vs CPR image generation. Images generated using the given prompt for a ﬁxed random seed using different methods.
Safe Model : Pre-trained model with no access to the retrievable data store, Retrieval-Score : Image generated using Eq. ( 7),Retrieval-Mix-
Score : Image generated using Eq. ( 8),CPR-KL, CPR-Min, CPR-Alt : Images generated using our algorithms in Algorithm 1Sec. 5.2.1 and
Algorithm 2Sec. 5.2.1 . Images generated without CPR bear more resemblance to the retrieved image, compared to the CPR generated
images, which are different from the retrieved image, while preserving the underlying concept in the prompt (for example the astronaut
seems to be on Moon, Big Ben is more textured with different design).
inference cost deterministic.
Theoretically, we formally prove in Lemmas 1and2that
CPR offers strong protection guarantees by ensuring that
the generated samples contain at most k-bits of unique in-
formation about retrieved samples, where kcan be tuned
by the user as required by the application. Empirically, we
show that CPR can use private data to improve quality of the
generated images ( 81.4→83.17TIFA score) while main-
taining privacy guarantees on the retrievable data.
The rest of the paper is organized as follows. In Sec. 2
we provide a study of the relevant related works in RAG and
privacy. In Sec. 3we deﬁne the necessary notations, and in
Sec. 4show how to perform RAG with pre-trained text-to-
image diffusion models by formulating inference over mix-
ture of public-private distribution. In Sec. 5we provide our
CPR algorithm, along with its theoretical guarantees, pro-
vide empirical evaluation of our method in Sec. 6, followed
by some discussion in Sec. 7.
2. Related Works
Retrieval Augmented Generation Retrival Augmented
Generation (RAG) methods have been successfully applied
to large language models (LLMs) [ 24,31,42,45,54]. RAG
has been shown to outperform even LLMs trained jointly on
the training set and the retrievable data pool. RAG have alsobeen explored for image synthesis [ 2,7,9,50,53,67,69].
However, rather than reusing existing models, current meth-
ods require training of retrieval-speciﬁc architectures which
— unlike the standard text-to-image diffusion models [ 46,
47,49,68] — can be prompted with several retrieved im-
ages along with conditional information, such as text, as
inputs. Instead, we explore RAG using more generic pre-
trained text-to-image diffusion models. [ 2,50,69] train a
diffusion-based image retrieval model that can be prompted
with latent image embeddings, while [ 9,67] use autoregres-
sive generative models inspired from LLMs.
Image Manipulation Several recent works [ 4,18,25,35,
40,41,51,63] have provided methods for image manipu-
lation, editing by either ﬁne-tuning or changing the cross-
attention values at inference. With an appropriate retrieval
function, and database such methods can be used to per-
form retrieval augmented generation by merging diffusion
scores [ 12,23,38]. However, the manipulation methods
signiﬁcantly lower inference speed. Instead, we opt to use
the unCLIP model [ 47] to generate a backward ﬂow us-
ing the retrieved images, and merge it with the ﬂow gen-
erated by a base text-to-image diffusion model at inference
[12,23,38,49].
Privacy Recent works [ 5,6,56,57] have shown that such
12375
models are able to memorize their training data. This raises
several privacy challenges, including:
Unlearning: Machine unlearning [ 3,20] enables users
to delete their data from the weights of trained models
[17,43]. [3,14,19,23,34,39] provide training methods
which makes unlearning efﬁcient, for example by break-
ing the dataset into multiple shards and training separate
models on each, followed by ensembling at inference. De-
spite their improved privacy utility trade-offs compared to
a single model, such approaches still require frequent re-
training/ﬁne-tuning. On the other hand, we propose split-
ting the training dataset into a core safe dataset [ 21] used to
train a core model, and a user owned private data store used
to retrieve samples. This allow instantaneous forgetting of
any private sample without having to retrain the model. This
strategy also improve performance (alignment), and enables
easy continual learning by simply adding new data to the
data store. Moreover, privacy of data which are never re-
trieved is completely preserved, unlike unlearning or dif-
ferential privacy [ 15,22] methods which mix information
about the entire dataset in the weights.
Copyright Protection: Memorization in foundation mod-
els also increases the risk of copying, style mimicry and
copyright [ 5,6,52] at inference. [ 62] proposed a deﬁnition
for copying in generative models using near access free-
ness (NAF), and provided the CP- ∆algorithm for copy-
protected generation. CP- ∆uses two generative models,
trained on two disjoint splits of the data, and then at in-
ference samples from the product and the minimum of the
two distributions. However, using it directly out-of-the-box
for diffusion models is challenging. Instead, they propose
another algorithm, CP- k, based on rejection sampling. Dif-
fusion models however tend to have slow inference speed,
and adding rejection sampling further aggravates the speed
problem. To address this, we introduce CPR, which pro-
vides a method to sample using CP- ∆(satisﬁes NAF) in a
single run, without the need for rejection sampling.
3. Preliminaries
Letp0(x0)be a data distribution over images, which we
seek to model using a diffusion model [ 27,58,60]. Score
based diffusion models models [ 60] deﬁne a (variance pre-
serving) forward ﬂow through a SDE, which transforms the
distribution p0(x0)at time t=0 in a reference distribution
p1(x1)=N(0,I)at time t=1:
dxt=−1
2βtxtdt+/radicalbig
βtdωt (1)
where xtis the diffused input at time t,dωtis a standard
Wiener process, and βtare time varying coefﬁcients (in
practice implemented through linear or cosine scheduling),
which determine the transition kernel and amount of noiseadded over time. The intermediate result pt(xt)of the diffu-
sion process at time tequivalently expressed as the result of
applying a Gaussian kernel pt(xt|x0)= N(xt;γtxo,σ2
tI)
top0(x0), resulting in pt(xt)=/integraltext
x0pt(xt|x0)p0(x0)dx0,
where γt=e x p ( −1
2·/integraltextt
0βtdt)andσ2
t=1−γ2
t.
The forward process in Eq. ( 1) can be inverted through a
corresponding backward process [ 37,60]. In particular, this
process can be used to generate samples of p0(x0)starting
from a sample of p1(x1)=N(0,I):
dxt=/parenleftbig
−1
2βtxt−∇xtlogpt(xt)/parenrightbig
dt+/radicalbig
βtdωt(2)
where ∇xtlogpt(xt)is the score function of data distribu-
tion at t. Efﬁciently computing the score function is dif-
ﬁcult. Instead, it can be approximated ∇xtlogpt(xt)≈
sθ(xt,t)using a deep network sθ(xt,t),i.e., a diffusion
model. In practice, diffusion models are often trained to
take additional inputs sθ(xt,t ,c)in order to model a condi-
tional distribution p0(x0|c), where the conditioning cpro-
vides additional information about the sample to generate,
such as textual prompts [ 11,26]. Given samples of the joint
distribution p0(x0,c), a diffusion model sθ(xt,t ,c)can be
trained by minimizing the score-matching objective:
E(x0,c)∼p0(x0,c)Et/bracketleftbig
∥sθ(xt,t ,c)−∇xtlogpt(xt|x0)∥/bracketrightbig
(3)
Directly generating samples using the backward ﬂow mod-
eled by sθ(xt,t ,c)can result into poor alignment [ 12,27,
58]. This can be improved through classiﬁer-free guidance
[26], which uses the modiﬁed score:
sθ(xt,t ,φ)+λ(sθ(xt,t ,c)−sθ(xt,t ,∅)),
where the hyper-parameter λcontrols the guidance scale ,
and∅denotes that no conditioning is fed to the model.
4. Mixed-Privacy RAG
In this section, we introduce a method for privacy-enabled
RAG that is based on the notion of mixed-privacy [ 21,22].
LetD={xi,ci}N
i=1∼p(x, c)be a safe training
dataset — meaning that samples are considered public
in the differential-privacy sense (see [ 21,22]). We as-
sume Dis used to train a core public diffusion model
sθ(xt,t ,c), that accepts cas conditioning information. We
shall also assume that cis the output of a CLIP encoder
c= CLIP( <prompt> )fed with either a text prompt or
an image prompt. Furthermore, let Dprivate ={xi,ci}M
i=1
be a private dataset which may require frequent unlearning,
or may require privacy or copyright protection. We shall
consider Dprivate as our data store for retrieval.
Retrieval At inference time, given a user prompt ctest
we retrieve a set of mrelevant examples Dretr =
12376
Number of Retrievals135ModelSafe ModelRetrieval-ScoreRetrieval-Mix-ScoreCPR-KLCPR-MinCPR-AltRetrieval-ScoreRetrieval-Mix-ScoreCPR-KLCPR-MinCPR-AltRetrieval-ScoreRetrieval-Mix-ScoreCPR-KLCPR-MinCPR-AltTIFA (COCO)85.574.4684.4786.6885.8986.7380.0786.0184.4685.9186.4480.9386.186.7686.5786.58TIFA (Non-COCO)77.4358.8176.6679.5778.179.7267.7778.2579.0278.2778.8069.2178.4678.9478.6678.81TIFA (Avg)81.466.4580.4983.1681.9283.1773.8182.0682.6782.0282.5774.9682.2182.7882.2582.63Table 1. Improved text-to-tmage alignment with retrieval : We compute the TIFA score [ 29] which measures the text-to-image alignment
on a set of prompts (Higher is better). We use a subset of MSCOCO [ 36] (2k images with high aesthetic score) as the private data store.
We show that simply using the retrieval-score (in Eq. ( 7)) is not enough to improve alignment, instead using the retrieval-mixture-score
(in Eq. ( 8)) is important to generate aligned and well composed images. CPR-KL, CPR-Min, CPR-Alt, meaningfully improve the text-to-
image alignment across different retrieval settings compared to the base model while protecting the private data store.
{(xi,φ(ci,ctest)}m
i=1⊂Dprivate to aid the generation pro-
cess. For simplicity, we simply retrieve the closest msam-
ples based on L2-CLIP similarity score:
score =∥ctest−ci∥+∥ctest−CLIP( xi)∥.
Note however that in Dretrwe are modifying the prompt
of the retrieved samples through a function φ(ci,ctest)=
ci+ctestin order to align them better with the user prompt.
Mixture-of-Distribution Retrieved samples are used to im-
prove the generation of new samples. Formally, the goal of
CPR is to modify the sampling backward process in order
to generate samples from a weighted mixture of the distri-
bution of DandDretr[12,23,38]:
p(x|c)=w0pD(x|c)+w1pDretr(x|c) (4)
where the weights w0=λandw1=1−λallow the user to
control the contribution of the retrieved samples at inference
time through an hyperparameter 0<λ< 1.
Mixture-of-Score To sample from this mixture distribution,
we need to compute its score function ∇logpt(xt)at time
t(see eq. 2). From Sec. 3we have:
pt(xt|c)=/integraldisplay
pt(xt|x0)/bracketleftbig
w0pD(x0|c)+w1pDretr(x0|c)/bracketrightbig
dx0
(5)
where pt(xt|x0)= N(xt;γtx0,σ2
tI)is a Gaussian kernel.
The following proposition expresses the score of the mix-
ture as a function of the score of the individual components:
Proposition 1. Let pt(xt|c)be as in Eq. (5), then
∇xtlogpt(xt|c)is given by:
∇xtlogpt=ˆwt
0∇xtlogpt
D(xt|c)+ ˆwt
1∇xtlogpt
Dretr(xt|c)
where we have deﬁned:
ˆwt
0=w0pt
D(xt|c)
pt(xt|c),ˆwt
1=w1pt
Dretr(xt|c)
pt(xt|c).and pt
D(xt|c)denotes the forward ﬂow of the distribu-
tion pD(xt|c)at time t(and similarly for pt
Dretr(xt|c)) and
pt(xt|c)=pt
D(xt|c)+pt
Dretr(xt|c).
While ˆwt
0and ˆwt
1could be computed exactly, we
ﬁnd that treating them as ﬁxed hyper-parameters simpli-
ﬁes the implementation and performs well. The scores
∇xtlogpD(xt|c)can be approximated empirically by a dif-
fusion model sθ0(x, t, c )trained on D. However, we do not
have a model trained on the retrieved data Dretrto estimate
∇xtlogpDretr(xt|c). To solve the issue, recall that such a
diffusion model sθ1that minimizes the loss:
sθ1= arg min
sθE(x0,c)∼pDretrExt/bracketleftbig
∥sθ(xt,t ,c)
−∇xtlog/parenleftbig/integraldisplay
pt(xt|x0)pDretr(x0,c)/parenrightbig/vextenddouble/vextenddouble/bracketrightbig
(6)
Since |Dretr|≪| D|, we expect the minimizer θ1to be a
small small perturbation θ1=θ0+∆θ1. However, ﬁne-
tuning sθ0(x, t, c )to ﬁnd such ∆θ1for every inference re-
quest is computationally prohibitive.
Instead of ﬁne-tuning, we approximate the expected be-
havior of sθ1through prompting. Textual inversion and
prompt tuning have been shown to perform comparably to
ﬁne-tuning on small datasets while using orders of magni-
tute less parameters [ 18,35,55,65]. However, despite the
reduction, it is still cumbersome to ﬁne-tune at inference.
Instead we propose manually modifying the user prompt
ctestusing the CLIP embeddings of the retrieved samples,
and deﬁne the retrieval-score function :
ˆsθ0(xt,t ,c test)/definessθ0/parenleftBig
xt,t ,1
m/summationdisplay
xi∈DretrCLIP (xi)/parenrightBig
(7)
We visualize in Fig. 1the results of sampling with Eq. ( 7).
This deﬁnition is motivated by the following proposition,
which bounds the distance of Eq. ( 7) from the optimal.
12377
Algorithm 1: CPR-KL
Input: ∇xtlog/integraltext
qt(xt|x0)q(1)(x|c)dx0,
∇xtlog/integraltext
qt(xt|x0)q(2)(x|c)dx0, T, N, ctest
Output: x0
1xT∼N(0,I)
2fort=T···0do
3 fori=1···Ndo
4 xt=xt+ϵt
2·
1
2/parenleftBig
∇xtlog/integraltext
qt(xt|x0)q(1)(x|ctest)dx0+
∇xtlog/integraltext
qt(xt|x0)q(2)(x|ctestdx0)/parenrightBig
+
√ϵtzwhere z∼N(0,I)
5 xt−1=xt
Proposition 2. Assume that sθis Lipschitz in θandc. Let
sθ0+∆θ1(xt,t ,c)be the optimal solution to Eq. (6)and let
Dretrthe private samples retrieved using ctest. Then
∥sθ1(xt,t ,c)−ˆsθ0(xt,t ,c test)∥≤
lθ∥∆θ1∥+lc/vextenddouble/vextenddouble/vextenddoublectest−1
m/summationdisplay
xi∈DretrCLIP( xi)/vextenddouble/vextenddouble/vextenddouble
Above result shows that we can approximate the op-
timal diffusion model trained on retrieved data using the
engineered prompt1
m/summationtext
xi∈DretrCLIP( xi), which only re-
quires computing the CLIP embeddings of the retrieved im-
ages. Combining Proposition 1and Proposition 2, we ﬁ-
nally obtain an expression for the score function of retrieval-
augmented mixture of distributions, which we call retrieval-
mixture-score :
sRAG(xt,t ,c test;Dprivate )/definesˆw0sθ0(xt,t ,c test)
+ˆw1sθ0/parenleftBig
xt,t ,(1/m)/summationdisplay
xi∈DretrCLIP (xi)/parenrightBig
(8)
Eq. ( 8) allows us any pre-trained CLIP-based diffusion
model to generate retrieval augmented samples without any
further changes (see Fig. 1). In Tab. 1we show that Eq. ( 8)
improves text-to-image alignment (TIFA goes from 81.4 to
82.21). Parallelly, the retrieval-mixture score function al-
ready has immediate application to privacy, since it makes it
trivial to unlearn examples contained in Dprivate in constant
time: these samples are not used to train any parameter, and
hence can be forgotten by simply removing them from disk.
However, samples retrieved at inference time can still leak
private information, which tackle this next.
5. Copy-Protected Generation
In this section, we will provide algorithms for copyright
protected generation — in the Near-Access Freeness sense
of [62] — using our mixed-privacy RAG method.Algorithm 2: CPR-Choose
Input: ctest,/tildewides(xt,t ,c;q(1)),/tildewides(xt,t ,c;q(2)),J,
reverse-update (xt,st)
Output: x0
1xT∼N(0,I)
2fort=T···,0do
3 ift∈Jthen
4 s(xt,t ,c test)=/tildewides(xt,t ,c test;q(2))
5 else if t̸∈Jthen
6 s(xt,t ,c test)=/tildewides(xt,t ,c test;q(1))
7 xt−1=reverse-update (xt,s(xt,t ,c test))
Near-Access Freeness LetDprivate be a set of private sam-
ples, whose information we want to protect, and let ∆
be a divergence measure between probability distributions,
such as the KL-divergence ∆KLor thr max-divergence
∆max(that is, the Renyi Divergence as α→∞). Let
safe : Dprivate →M be a function which maps a sample
xi∈Dprivate to a generative model trained without using
thatxi. The Near Access-Free (NAF) criteria is deﬁned as:
Deﬁnition 1 (NAF Deﬁnition 2.1 in [ 62]).We say that a
generative model p(x|c)iskc-near access-free (or kc-NAF)
on a prompt cwith respect to Dprivate , and ∆,safe, if for all
xi∈Dprivate we have ∆/parenleftBig
p(x|c)||safe xi(x|c)/parenrightBig
≤kc.
In practice, safe xican be a model trained with
leave-one-out , or be sharded-safe [62], or sim-
ply be the safe core diffusion model sθ0(xt,t ,c). The above
deﬁnition says that to perform safe generation the output
sample must be close in distribution to a model which did
not have access to the private samples in Dprivate .
5.1. CPR-KL
We ﬁrst report here Theorem 3.1 from [ 62] which provides
a simple procedure to generate NAF-protected samples with
respect to KL-divergence.
Theorem 1. (Theorem 3.1 [ 62]) Given a dataset /tildewideD, and
copyrighted samples C∈/tildewideD, split /tildewideDinto two disjoint shards
D1,D2, and train two generative models q(1),q(2)on each
respectively. Given the two models return a new model
which satisﬁes kc-NAF wrt ∆KL
p(x|c)=/radicalbig
q(1)(x|c)q(2)(x|c)
Z(c)(9)
where kc=−2 log (1 −H2(q(1)(x|c),q(2)(x|c))), H is the
Hellinger distance.
However, for diffusion models we do not
have access to q(1)and q(2), but only to
12378
Figure 2. (A)We plot the histogram of ∆max=l o gp(x|c)
safe( x|c)as we vary the contribution of the retrieval-score ( ˆw1in Eq. ( 8)). We use ˆw1
as a user tunable parameter which controls the amount of bits the generated images are different from safe. We show that as we reduce ˆw1,
empirical kc(max value on the x-axis with non-zero probability) decreases. (B)Comparison to baseline, [ 62], with k=1500 using rejection
sampling. Smaller k leads to slow generation which is evident from the distribution.
the scores ∇xtlog/integraltext
qt(xt|x0)q(1)(x|c)dx0and
∇xtlog/integraltext
qt(xt|x0)q(2)(x|c)dx0respectively, where
qt(xt|x0)is a variance preserving Gaussian distribution.
We therefore extend Theorem 1to generative models by
extending it to models’ scores.
Given score functions, we deﬁne the CPR-KL algorithm
in Algorithm 1where we average the two scores at every
step during backward diffusion using Langevin Dynamics
[8,12,44,59,64]. In the following result we prove that
sampling using Algorithm 1indeed ensures kc−NAF.
Lemma 1. Letx0be the output of Algorithm 1. Under
certain regularity conditions (see Supplementary Material),
x0iskc−NAF w.r.t. safe,C,∆KL.
By the previous result, Algorithm 1enables us to gen-
erate samples from Eq. ( 9), as T,N increases and ϵtde-
creases. However, in practice we do not have access to
the optimal scores, but instead approximations which use
DNNs. In our setting we shall consider having the safe
model sθ0(xt,t ,c), and the RAG score on the private data-
store sRAG(xt,t ,c test;Dprivate ). In practice, although com-
bining the two scores as in Algorithm 1can produce bet-
ter results, it also doubles the computation cost at inference
time. To circumvent this we now describe CPR-Choose
(Algorithm 2) which approximates Algorithm 1without in-
creasing computational complexity.
5.2. CPR-Choose
We now propose another CPR algorithm which does not in-
cur in higher computational cost of CPR-KL. First we recall
a result on the likelihood estimation of samples with MMSE
denoisers, then we show how to use it to deﬁne an efﬁcient
NAF algorithm w.r.t. ∆max.
Estimating sample likelihood with MMSE denoiser
Recently, [ 32,33] provided a simple method for estimat-ing the probability of individual samples by computing the
Minimum mean square error (MMSE) using pre-trained
text-to-image diffusion models. Let xt=γtx0+σtϵ,
x0∼p(x0|c)where ϵ∼N(0,I), and α(t) = logγ2
t
σ2
tbe
the log SNR. Then the MMSE denoiser for a distribution p
can deﬁned as:
/tildewides(xt,t ,c;p)/definesargmins(·)Ep(x0|c),ϵ∥ϵ−s(xt,t ,c)∥2
=Ep(x0|xt,c)/bracketleftBigxt−γtx0
σt/bracketrightBig
(10)
Using the MMSE denoiser, [ 32,33] provide a simple ex-
pression for estimating the log probability of x0.
logp(x0|c)=−/integraldisplay
Eϵ∥ϵ−/tildewides(xt,t ,c;p)∥2α′(t)dt+const
(11)
where α′(t)is the time-derivative of α(t). Note that
/tildewides(xt,t ,c;p)is also equivalent to the diffusion score we ob-
tained in the previous sections.
This result shows that to obtain NAF w.r.t. ∆max =
logp(x|c)/safe( x|c), all we need to do is bound the dif-
ference in MMSE at each time step t. We can bound this by
choosing p(x|c) = safe( x|c)for majority of t, while using
Dprivate intermittently for remaining t.
Using these results we will provide another algorithm
for copy-protected generation. Let q(1),q(2)be the mod-
els obtained using D1,D2respectively. And assume that
we shard the total data in such a way that D1contains the
safe data, while D2contains the copy-protected data. We let
q(1)be our safe-model . In practice, we will have access to
the score function or the MMSE denoiser, /tildewides(xt,t ,c;q(1)),
/tildewides(xt,t ,c;q(2)).
NAF ∆maxalgorithm LetJ={[ti,ti+1]|ti+1≤
ti+2,i∈{0,2,4,···,N},t0≥0,tN+1<∞,N < ∞}
12379
Figure 3. Concept similarity with CPR: In this ﬁgure we show the CLIP similarity between CPR generated images and the textual prompt
(Syn-Cap) and the retrieved images (Syn-Ret) respectively. We show that while the CPR generated image preserves the concept presented
in the textual prompt (their similarity with the caption is high), they do not copy the private retrieved images (their similarity with the
retrieved samples is low).
be a subset of disjoint time-intervals on the real line. Using
the set J, let us deﬁne a new distribution,
/tildewideq(x0|c, t)=q(1)(x0|c)
t̸∈J+q(2)(x0|c)
t∈J(12)
This new distribution is a time-dependent, which essentially
selects a distribution at time tto sample xt. The beneﬁt of
such an approach is that it enables the user to select one
of the two model during backward diffusion at each time-
step, which is similar to [ 1] which has shown to empirically
improve generation quality. Towards this end we have the
following result,
Proposition 3. Let/tildewides(xt,t ,c;/tildewideq)be the MMSE denoiser for
Eq.(12), then we can show that
/tildewides(xt,t ,c;/tildewideq)=/tildewides(xt,t ,c;q(1))
t̸∈J+/tildewides(xt,t ,c;q(2))
t∈J
This result states the fact that optimal MMSE denoiser
for Eq. ( 12) will choose one of the two denoisers depending
on the time-step, where the choice of Jcan be completely
user dependent. Using these observations we propose inter-
val based CPR algorithm (CPR-Choose), Algorithm 2
Lemma 2. Letx0be the output of Algorithm 2. Under
certain regularity conditions (see Supplementary Material),
x0iskc−NAF w.r.t. safe,C,∆max.
5.2.1 Time-Discretization
Often in practice we model the diffusion process using a
discrete markov chain [ 27,58] whose continuous limit is
SDE[ 60]. For discrete markov chains discrete in twe can
denote the output of models q(1)(safe-model), q(2)using
the entire trajectory, {x0,···,xT})[62]. The set of inter-
valsJbecomes a set of discrete time-steps. During back-
ward diffusion, at each tthe user can use one of the twomodels to generate the score for updating xt. Depending
on the choice of J, we can generate completely safe images
(Jto be empty) or no protection ( Jis the entire domain of
t).This leads to two CPR-Choose algorithms, depending on
the choice of J.
CPR-Min In this setting, we choose Jsuch that at each t,
we choose the model with the larger MSE, which can be
considered as choosing the worst model at each t. This will
generate samples from a distribution which approximates
theminimum of the two distributions. Under certain condi-
tions we can show that this algorithm is NAF protected (In
the appendix). This in intuitive because, for time-stamps
when we choose q(1)(which is the safe model), we incur no
loss for ∆max, and it is only for the remaining terms that we
need to bound ∆max.
CPR-Alt Similarly, we can choose Jtoalternate between
the two models by choosing q(2)(private model) at regular
intervals, like e.g. every /tildewidetsteps, or in the most simplest case,
in an alternating fashion. Using this approach, we will only
need to compute the ∆maxat every /tildewidetsteps to bound kc.
In our experiments, we will let q(1)be the sθ0(xt,t ,c)
which is trained on the safe-core data, while q(2)be the
sRAG(xt,t ,c;Dprivate )which uses the private data at infer-
ence using retrieval.
6. Experiments
We use the Stable-Diffusion 2.1 model [ 49] as our safe base
model, and use the Stable-Diffusion unCLIP model [ 47,49]
(without the prior model) as our retrieval-score model. Us-
ing the unCLIP model enables better control of the genera-
tion with the retrieved images Dretr⊂Dprivate . We use top
2k samples (based on the aesthetic score) from MSCOCO
12380
Figure 4. (a) Plot of the utility (generation quality) for increasing values of copyright protection, on samples from the MS-COCO dataset.
(b) The TIFA score of CPR increases as the size of the retrieval dataset grows. (c) Computational costs of CPR (ours) and CP-K[ 62]
compared to the base model.
[36] as our private data store and use the TIFA score [ 29] to
measure the text-image alignment and quality.
Improved text-to-image alignment Retrieval is often used
to improve the text-to-image alignment of the diffusion
model. In Tab. 1, we use TIFA benchmark to evaluate the
alignment of different methods. We observe that retrieving
images from the data store indeed improves the alignment
from 81.4 to 83.17. Interestingly, CPR regularizes the in-
ference, resulting in even better TIFA (with protection).
Comparing privacy leakage In Fig. 2, we plot the ∆max
(whose upper bound is kc) for various methods against safe
(on images generated with TIFA prompts). We use the con-
trol parameter ˆw1(Eq. ( 8) to vary the retrieval contribu-
tion. We show that increasing ˆw1, makes the model generate
more similar images to Dprivate , resulting in larger ∆max(log
prob. ratio w.r.t. safe). This is unlike the CP- ∆[62] which
does not allow the user to tune the NAF constant kc.W e
also compare with CP-K [ 62], which uses rejection sam-
pling on the outputs generated by a Stable Diffusion model
ﬁne-tuned on the private database Dprivate . We set k=1500,
and observe that logp(x|c)/safe( x|c)is almost uniformly
distributed, which results in much slower (5-10x) rejection
sampling for the same privacy level as our CPR algorithms.
Concept similarity with CPR In Fig. 3, we plot the CLIP-
score between the image generated using TIFA prompts
(Syn in Fig. 3) and the input captions (Cap in Fig. 3), re-
trieved images from Dprivate (Ret in Fig. 3) respectively. We
show that CPR reduces the similarity between the synthe-
sized images and the retrieved images, while improving the
similarity to the textual prompts. This implies that CPR
generates images corresponding to the concept present in
the prompt (with the help of the retrieved image), but en-
sures that the synthesized image is different from the re-
trieved image (prevents copying/memorization).
Ablations In Fig. 4we provide additional experiments
where we ablate the size of the retrieval store, show the pri-
vacy utility trade-off, and compare the computations cost of
various methods.7. Discussion and Limitations
Relation between kcand retrieval function The NAF
bound kcrelates to the private data store through the re-
trieval function, which in our case is the L2distance be-
tween the CLIP embeddings. Functions that retrieve images
which explain the concept underlying the ctestinstead of its
exact expression, can further help in improving privacy.
Classiﬁer-free guidance for privacy protected genera-
tion We can redeﬁne the expression in Eq. ( 9), to repre-
sent a more general form like p(x|c)∝qα
1(x|c)q1−α
2(x|c),
which when substituted with appropriate αprovides the ex-
pression for the classic classiﬁer free guidance (CFG) [ 26],
which implies that replacing the marginal in CFG with a
safe model, and using the RAG model in place of the condi-
tional results in private generation with appropriate scaling
ofkc. Thus CFG with appropriate model selection can be
considered a good candidate for NAF generation.
Unlearning, adapters, and RAG A direct consequence of
copied generation is the request to remove the appropri-
ate training samples from the dataset (in our case Dstore).
Such unlearning requests can be efﬁciently handled by our
CPR framework as it allows for cost free removal of private
samples. However, in certain settings, if the private data
store contains out-of-distribution (OOD) examples, simply
using Eq.(8) may not be enough to obtain high ﬁdelity
images. In such situations we may train separate adapters
[13,14,28,30,55] corresponding to the OOD samples (a
subset of Dstore. Hence at inference, we would ﬁrst retrieve
a private adapter, and then a set of samples from Dstore.
Upon a forgetting request, we discard both the adapter, and
the samples in Dstore.
Limitations One of the major limitation of diffusion model
based methods is the inability to compute the exact proba-
bility values (this is not the case for auto-regressive or ﬂow
based models). For instance, in Proposition 1,ˆw0, or even
the computation of the true NAF parameter depends on the
actual probability values.
12381
References
[1]Yogesh Balaji, Seungjun Nah, Xun Huang, Arash Vahdat,
Jiaming Song, Karsten Kreis, Miika Aittala, Timo Aila,
Samuli Laine, Bryan Catanzaro, et al. edifﬁ: Text-to-image
diffusion models with an ensemble of expert denoisers. arXiv
preprint arXiv:2211.01324 , 2022. 7
[2]Andreas Blattmann, Robin Rombach, Kaan Oktay, Jonas
M¨uller, and Bj ¨orn Ommer. Retrieval-augmented diffusion
models. Advances in Neural Information Processing Sys-
tems, 35:15309–15324, 2022. 2
[3]Lucas Bourtoule, Varun Chandrasekaran, Christopher A
Choquette-Choo, Hengrui Jia, Adelin Travers, Baiwu Zhang,
David Lie, and Nicolas Papernot. Machine unlearning. In
2021 IEEE Symposium on Security and Privacy (SP) , pages
141–159. IEEE, 2021. 3
[4]Tim Brooks, Aleksander Holynski, and Alexei A Efros. In-
structpix2pix: Learning to follow image editing instructions.
InProceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 18392–18402, 2023.
2
[5]Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew
Jagielski, Ariel Herbert-V oss, Katherine Lee, Adam Roberts,
Tom Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting
training data from large language models. In 30th USENIX
Security Symposium (USENIX Security 21) , pages 2633–
2650, 2021. 2,3
[6]Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagiel-
ski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ip-
polito, and Eric Wallace. Extracting training data from diffu-
sion models. In 32nd USENIX Security Symposium (USENIX
Security 23) , pages 5253–5270, 2023. 2,3
[7]Jian Chen, Ruiyi Zhang, Tong Yu, Rohan Sharma, Zhiqiang
Xu, Tong Sun, and Changyou Chen. Label-retrieval-
augmented diffusion models for learning from noisy labels.
arXiv preprint arXiv:2305.19518 , 2023. 2
[8]Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic
gradient hamiltonian monte carlo. In International confer-
ence on machine learning , pages 1683–1691. PMLR, 2014.
6
[9]Wenhu Chen, Hexiang Hu, Chitwan Saharia, and William W
Cohen. Re-imagen: Retrieval-augmented text-to-image gen-
erator. arXiv preprint arXiv:2209.14491 , 2022. 2
[10] Xiang Cheng and Peter Bartlett. Convergence of langevin
mcmc in kl-divergence. In Algorithmic Learning Theory ,
pages 186–211. PMLR, 2018. 13
[11] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. Advances in neural informa-
tion processing systems , 34:8780–8794, 2021. 3
[12] Yilun Du, Conor Durkan, Robin Strudel, Joshua B Tenen-
baum, Sander Dieleman, Rob Fergus, Jascha Sohl-Dickstein,
Arnaud Doucet, and Will Sussman Grathwohl. Reduce,
reuse, recycle: Compositional generation with energy-based
diffusion models and mcmc. In International Conference on
Machine Learning , pages 8489–8510. PMLR, 2023. 2,3,4,
6,14
[13] Yonatan Dukler, Alessandro Achille, Hao Yang, Varsha
Vivek, Luca Zancato, Ben Bowman, Avinash Ravichan-dran, Charless Fowlkes, Ashwin Swaminathan, and Ste-
fano Soatto. Introspective cross-attention probing for
lightweight transfer of pre-trained models. arXiv preprint
arXiv:2303.04105 , 2023. 8
[14] Yonatan Dukler, Benjamin Bowman, Alessandro Achille,
Aditya Golatkar, Ashwin Swaminathan, and Stefano Soatto.
Safe: Machine unlearning with shard graphs. arXiv preprint
arXiv:2304.13169 , 2023. 3,8
[15] Cynthia Dwork. Differential privacy. In International col-
loquium on automata, languages, and programming , pages
1–12. Springer, 2006. 3
[16] Murat A Erdogdu and Rasa Hosseinzadeh. On the conver-
gence of langevin monte carlo: The interplay between tail
growth and smoothness. In Conference on Learning Theory ,
pages 1776–1822. PMLR, 2021. 13
[17] Federico Fabbrini and Edoardo Celeste. The right to be for-
gotten in the digital age: The challenges of data protection
beyond borders. German law journal , 21(S1):55–65, 2020.
3
[18] Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patash-
nik, Amit H Bermano, Gal Chechik, and Daniel Cohen-
Or. An image is worth one word: Personalizing text-to-
image generation using textual inversion. arXiv preprint
arXiv:2208.01618 , 2022. 2,4
[19] Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-
Kaufman, and David Bau. Erasing concepts from diffusion
models. arXiv preprint arXiv:2303.07345 , 2023. 3
[20] Aditya Golatkar, Alessandro Achille, and Stefano Soatto.
Eternal sunshine of the spotless net: Selective forgetting in
deep networks. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 9304–
9312, 2020. 3
[21] Aditya Golatkar, Alessandro Achille, Avinash Ravichan-
dran, Marzia Polito, and Stefano Soatto. Mixed-privacy for-
getting in deep networks. In Proceedings of the IEEE/CVF
conference on computer vision and pattern recognition ,
pages 792–801, 2021. 3
[22] Aditya Golatkar, Alessandro Achille, Yu-Xiang Wang,
Aaron Roth, Michael Kearns, and Stefano Soatto. Mixed
differential privacy in computer vision. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 8376–8386, 2022. 3
[23] Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan,
and Stefano Soatto. Training data protection with composi-
tional diffusion models. arXiv preprint arXiv:2308.01937 ,
2023. 2,3,4
[24] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and
Mingwei Chang. Retrieval augmented language model pre-
training. In International conference on machine learning ,
pages 3929–3938. PMLR, 2020. 2
[25] Amir Hertz, Ron Mokady, Jay Tenenbaum, Kﬁr Aberman,
Yael Pritch, and Daniel Cohen-Or. Prompt-to-prompt im-
age editing with cross attention control. arXiv preprint
arXiv:2208.01626 , 2022. 2
[26] Jonathan Ho and Tim Salimans. Classiﬁer-free diffusion
guidance. arXiv preprint arXiv:2207.12598 , 2022. 3,8
12382
[27] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-
fusion probabilistic models. Advances in neural information
processing systems , 33:6840–6851, 2020. 3,7,14
[28] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-
Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.
Lora: Low-rank adaptation of large language models. arXiv
preprint arXiv:2106.09685 , 2021. 8
[29] Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Os-
tendorf, Ranjay Krishna, and Noah A Smith. Tifa: Accurate
and interpretable text-to-image faithfulness evaluation with
question answering. arXiv preprint arXiv:2303.11897 , 2023.
4,8
[30] Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie,
Serge Belongie, Bharath Hariharan, and Ser-Nam Lim. Vi-
sual prompt tuning. In European Conference on Computer
Vision , pages 709–727. Springer, 2022. 8
[31] Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettle-
moyer, and Mike Lewis. Generalization through memoriza-
tion: Nearest neighbor language models. arXiv preprint
arXiv:1911.00172 , 2019. 2
[32] Xianghao Kong, Rob Brekelmans, and Greg Ver
Steeg. Information-theoretic diffusion. arXiv preprint
arXiv:2302.03792 , 2023. 6
[33] Xianghao Kong, Ollie Liu, Han Li, Dani Yogatama, and
Greg Ver Steeg. Interpretable diffusion via information de-
composition. arXiv preprint arXiv:2310.07972 , 2023. 6
[34] Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli
Shechtman, Richard Zhang, and Jun-Yan Zhu. Ablating con-
cepts in text-to-image diffusion models. In Proceedings of
the IEEE/CVF International Conference on Computer Vi-
sion, pages 22691–22702, 2023. 3
[35] Nupur Kumari, Bingliang Zhang, Richard Zhang, Eli
Shechtman, and Jun-Yan Zhu. Multi-concept customization
of text-to-image diffusion. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 1931–1941, 2023. 2,4
[36] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll ´ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. In
Computer Vision–ECCV 2014: 13th European Conference,
Zurich, Switzerland, September 6-12, 2014, Proceedings,
Part V 13 , pages 740–755. Springer, 2014. 4,8,15
[37] Anders Lindquist and Giorgio Picci. On the stochastic real-
ization problem. SIAM Journal on Control and Optimization ,
17(3):365–389, 1979. 3
[38] Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and
Joshua B Tenenbaum. Compositional visual generation with
composable diffusion models. In European Conference on
Computer Vision , pages 423–439. Springer, 2022. 2,4
[39] Tian Yu Liu, Aditya Golatkar, and Stefano Soatto. Tangent
transformers for composition, privacy and removal. arXiv
preprint arXiv:2307.08122 , 2023. 3
[40] Shilin Lu, Yanzhu Liu, and Adams Wai-Kin Kong. Tf-icon:
Diffusion-based training-free cross-domain image composi-
tion. In Proceedings of the IEEE/CVF International Confer-
ence on Computer Vision , pages 2294–2305, 2023. 2
[41] Jian Ma, Junhao Liang, Chen Chen, and Haonan Lu.
Subject-diffusion: Open domain personalized text-to-imagegeneration without test-time ﬁne-tuning. arXiv preprint
arXiv:2307.11410 , 2023. 2
[42] Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh
Hajishirzi, Noah A Smith, and Luke Zettlemoyer. Silo lan-
guage models: Isolating legal risk in a nonparametric datas-
tore. arXiv preprint arXiv:2308.04430 , 2023. 2
[43] Mika Nakashima. The legal frameworks of the right to re-
quest the deletion of personal data in the eu, the us and japan
and the right to be forgotten: A study focusing on search
businesses. In Human-Centric Computing in a Data-Driven
Society: 14th IFIP TC 9 International Conference on Human
Choice and Computers, HCC14 2020, Tokyo, Japan, Septem-
ber 9–11, 2020, Proceedings 14 , pages 29–40. Springer,
2020. 3
[44] Radford M Neal. Annealed importance sampling. Statistics
and computing , 11:125–139, 2001. 6,13
[45] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,
Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham.
In-context retrieval-augmented language models. arXiv
preprint arXiv:2302.00083 , 2023. 2
[46] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,
Chelsea V oss, Alec Radford, Mark Chen, and Ilya Sutskever.
Zero-shot text-to-image generation. In International Confer-
ence on Machine Learning , pages 8821–8831. PMLR, 2021.
2
[47] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,
and Mark Chen. Hierarchical text-conditional image gen-
eration with clip latents. arXiv preprint arXiv:2204.06125 ,
2022. 2,7,15
[48] Gareth O Roberts and Richard L Tweedie. Exponential con-
vergence of langevin distributions and their discrete approx-
imations. Bernoulli , pages 341–363, 1996. 13
[49] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj ¨orn Ommer. High-resolution image
synthesis with latent diffusion models. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition , pages 10684–10695, 2022. 2,7,15
[50] Robin Rombach, Andreas Blattmann, and Bj ¨orn Om-
mer. Text-guided synthesis of artistic images with
retrieval-augmented diffusion models. arXiv preprint
arXiv:2207.13038 , 2022. 2
[51] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch,
Michael Rubinstein, and Kﬁr Aberman. Dreambooth: Fine
tuning text-to-image diffusion models for subject-driven
generation. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 22500–
22510, 2023. 2
[52] Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng,
Rana Hanocka, and Ben Y Zhao. Glaze: Protecting artists
from style mimicry by text-to-image models. arXiv preprint
arXiv:2302.04222 , 2023. 3
[53] Shelly Sheynin, Oron Ashual, Adam Polyak, Uriel Singer,
Oran Gafni, Eliya Nachmani, and Yaniv Taigman. Knn-
diffusion: Image generation via large-scale retrieval. arXiv
preprint arXiv:2204.02849 , 2022. 2
[54] Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo,
Rich James, Mike Lewis, Luke Zettlemoyer, and Wen-tau
12383
Yih. Replug: Retrieval-augmented black-box language mod-
els.arXiv preprint arXiv:2301.12652 , 2023. 2
[55] Kihyuk Sohn, Huiwen Chang, Jos ´e Lezama, Luisa Polania,
Han Zhang, Yuan Hao, Irfan Essa, and Lu Jiang. Visual
prompt tuning for generative transfer learning. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 19840–19851, 2023. 4,8
[56] Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas
Geiping, and Tom Goldstein. Diffusion art or digital forgery?
investigating data replication in diffusion models. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 6048–6058, 2023. 2
[57] Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas
Geiping, and Tom Goldstein. Understanding and mit-
igating copying in diffusion models. arXiv preprint
arXiv:2305.20086 , 2023. 2
[58] Jiaming Song, Chenlin Meng, and Stefano Ermon.
Denoising diffusion implicit models. arXiv preprint
arXiv:2010.02502 , 2020. 3,7,14
[59] Yang Song and Stefano Ermon. Generative modeling by esti-
mating gradients of the data distribution. Advances in neural
information processing systems , 32, 2019. 6
[60] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-based
generative modeling through stochastic differential equa-
tions. arXiv preprint arXiv:2011.13456 , 2020. 3,7
[61] Santosh Vempala and Andre Wibisono. Rapid convergence
of the unadjusted langevin algorithm: Isoperimetry suf-
ﬁces. Advances in neural information processing systems ,
32, 2019. 13
[62] Nikhil Vyas, Sham Kakade, and Boaz Barak. Provable
copyright protection for generative models. arXiv preprint
arXiv:2302.10870 , 2023. 1,3,5,6,7,8,12
[63] Ruichen Wang, Zekang Chen, Chen Chen, Jian Ma, Haonan
Lu, and Xiaodong Lin. Compositional text-to-image synthe-
sis with attention map control of diffusion models. arXiv
preprint arXiv:2305.13921 , 2023. 2
[64] Max Welling and Yee W Teh. Bayesian learning via stochas-
tic gradient langevin dynamics. In Proceedings of the 28th
international conference on machine learning (ICML-11) ,
pages 681–688, 2011. 6
[65] Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Goldblum,
Jonas Geiping, and Tom Goldstein. Hard prompts made
easy: Gradient-based discrete optimization for prompt tun-
ing and discovery. arXiv preprint arXiv:2302.03668 , 2023.
4
[66] Kaylee Yingxi Yang and Andre Wibisono. Convergence in
kl and r ´enyi divergence of the unadjusted langevin algorithm
using estimated score. In NeurIPS 2022 Workshop on Score-
Based Methods , 2022. 13
[67] Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi,
Richard James, Jure Leskovec, Percy Liang, Mike Lewis,
Luke Zettlemoyer, and Wen-tau Yih. Retrieval-augmented
multimodal language modeling. 2023. 2
[68] Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gun-
jan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yin-
fei Yang, Burcu Karagol Ayan, et al. Scaling autoregres-sive models for content-rich text-to-image generation. arXiv
preprint arXiv:2206.10789 , 2022. 2
[69] Mingyuan Zhang, Xinying Guo, Liang Pan, Zhongang Cai,
Fangzhou Hong, Huirong Li, Lei Yang, and Ziwei Liu.
Remodiffuse: Retrieval-augmented motion diffusion model.
arXiv preprint arXiv:2304.01116 , 2023. 2
12384
