A Dynamic Kernel Prior Model for Unsupervised Blind Image Super-Resolution
Zhixiong Yang1Jingyuan Xia1,∗Shengxi Li2Xinghua Huang1
Shuanghui Zhang1Zhen Liu1Yaowen Fu1Yongxiang Liu1
1College of Electronic Engineering, National University of Defense Technology, Changsha, China
2College of Electronic Engineering, Beihang University, Beijing, China
yzx21@nudt.edu.cn, j.xia10@nudt.edu.cn
Abstract
Deep learning-based methods have achieved signifi-
cant successes on solving the blind super-resolution (BSR)
problem. However, most of them request supervised pre-
training on labelled datasets. This paper proposes an un-
supervised kernel estimation model, named dynamic kernel
prior (DKP), to realize an unsupervised and pre-training-
free learning-based algorithm for solving the BSR problem.
DKP can adaptively learn dynamic kernel priors to realize
real-time kernel estimation, and thereby enables superior
HR image restoration performances. This is achieved by
a Markov chain Monte Carlo sampling process on random
kernel distributions. The learned kernel prior is then as-
signed to optimize a blur kernel estimation network, which
entails a network-based Langevin dynamic optimization
strategy. These two techniques ensure the accuracy of the
kernel estimation. DKP can be easily used to replace the
kernel estimation models in the existing methods, such as
Double-DIP and FKP-DIP , or be added to the off-the-shelf
image restoration model, such as diffusion model. In this
paper, we incorporate our DKP model with DIP and diffu-
sion model, referring to DIP-DKP and Diff-DKP , for val-
idations. Extensive simulations on Gaussian and motion
kernel scenarios demonstrate that the proposed DKP model
can significantly improve the kernel estimation with com-
parable runtime and memory usage, leading to state-of-
the-art BSR results. The code is available at https:
//github.com/XYLGroup/DKP .
1. Introduction
Deep learning provides a new avenue for solving the blind
super-resolution (BSR) problem, which aims to reconstruct
Zhixiong Yang and Jingyuan Xia contributed equally to this work
(*Corresponding author: Jingyuan Xia). This work is supported by Na-
tional Natural Science Foundation of China, projects 61921001, 62131020,
62322121 and 62171448, and the NSFDYS of Hunan 2022J110067.high-resolution (HR) images from the low-resolution (LR)
observations with unknown blur kernels, and is known to
be highly non-convex and ill-posed. To alleviate the non-
convexity and ill-posedness, most of learning-based BSR
methods incorporate image priors via supervised learning
based on paired LR-HR samples. However, pre-defined la-
beled training datasets are expensive, time-consuming, and
even not feasible in specific scenarios, such as for high
speed targets (e.g., satellites, aircraft) and medical images
(e.g., beating heart). Thus, unsupervised learning-based so-
lutions are highly demanded for BSR problem.
The existing BSR methods can be roughly divided into
model-based and learning-based strategies in terms of the
priors adopted to provide performance guarantee. Model-
based approaches [19, 21, 33, 51] typically adopt hand-
designed and explicit constraints as regularizations on im-
age properties, or expert knowledge of the blur kernel.
Meanwhile, learning-based BSR methods [12, 16, 20, 27–
29, 49, 53, 54, 56] aim to train an end-to-end network with
paired LR-HR image samples to leverage data priors for
boosting performances. However, these methods highly de-
mand the data and need to undergo throughing pre-training
before applications, leading to limited generalization abil-
ity towards varying blur kernels. To alleviate this issue,
quite a few methods [5, 13, 40, 50, 57, 59] substitute the
cumbersome training in advance by a well-trained diffu-
sion model with significantly less fine-tuning samples in an
off-the-shelf fashion. On the other side, a slice of works
[3, 17, 25, 34, 39, 51] propose to replace the HR image data
priors by kernel priors, which are more substantial, econom-
ical and efficient to be trained. However, both of these ad-
vances are underlying the supervised learning scheme with
necessity of training on labeled datasets, still hindering the
flexibility and generalization ability towards the BSR tasks
with different kernels and unknown HR ground truths.
In this paper, we propose a dynamic kernel prior (DKP)
generation model that can be plug-in with the majority of
image restoration (IR) models, to solve BSR problem in an
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
26046
unsupervised way. The proposed DKP model consists of
two modules: random kernel sampling (RKS) module and
prior kernel estimation (PKE) module. In the RKS module,
a Markov Chain Monte Carlo (MCMC) sampling strategy
on kernel distributions iteratively generates random kernels
as kernel priors, which are then assigned to the PKE mod-
ule. The PKE module is employed to estimate the blur ker-
nel with respect to the kernel prior generated from the RKS
module, the observed LR input and estimated HR image
from the IR model. The estimated blur kernel is then as-
signed to an adopted IR model for the HR image restoration.
Along with the alternative solving processes, the MCMC
process in RKS module converges to a desired kernel distri-
bution with respect to the LR observation and the estimated
HR image to guarantee a rational kernel prior. Meanwhile, a
network-based Langevin dynamics (NLD) paradigm is pro-
posed to optimize the kernel estimator in our PKE mod-
ule with respect to the RKS output kernel prior and the
data consistency based on the LR image reconstruction er-
ror. The RKS module realizes an unsupervised kernel prior
learning. The PKE module achieves promising kernel esti-
mation via the NLD update scheme, which further alleviates
the non-convexity and ill-posedness in the view of optimiza-
tion strategy. In this way, the DKP model is capable of pro-
viding the plug-and-play kernel estimation without training
in advance on paired LR-HR samples, and is flexible to be
applied to the existing IR models for solving the BSR prob-
lem.
Two applications are proposed to validate the feasibil-
ity and performance of our DKP model: deep image prior
(DIP) [44] and diffusion model [14] adopted as the IR
model, referring to DIP-DKP and Diff-DKP, respectively.
For the DIP-DKP, we simultaneously optimize the param-
eters of DIP and DKP models from scratch during the al-
ternative solution process. For the Diff-DKP, the adopted
diffusion model is off-the-shelf from [14] and is applied
as the fixed HR image restorer. The DKP model is opti-
mized from scratch as well. Extensive simulation results
show that the DIP-DKP achieves comparable performance
than the existing methods, while the Diff-DKP achieves the
state-of-the-art performance in both of Gaussian and motion
kernel scenarios. The main contributions are summarized as
follows:
• The RKS module is proposed to generate a rational kernel
prior from the MCMC sampling on random kernel distri-
butions. This way, an unsupervised kernel prior learning
is achieved to substitute the pre-training phase.
• In PKE module, the NLD is proposed to optimize the ker-
nel estimator, ensuring good convergence and concise es-
timation of the blur kernel from the perspective of opti-
mization strategy.
• The proposed DKP model enjoys the ease use on the pop-
ular IR models without the necessity of pre-training/re-training towards different scenarios. The two applica-
tions, i.e., DIP-DKP and Diff-DKP, validate the state-of-
the-art performance and excellent flexibility of our DKP
model.
2. Related Work
To alleviate the non-convexity and ill-posedness, early
model-based approaches [11, 31, 33, 37] typically con-
struct image priors in explicit formulations, such as the total
variation (TV) [36], gradient profile [42], hyper-Laplacian
[21] and sparsity [19]. In contrast, learning-based meth-
ods [7, 12, 16–18, 20, 28, 29, 45, 49, 53, 56] typically
train an end-to-end network on labelled image samples to
incorporate data priors. Wang et al. [45] proposed a CNN-
based deep network with degradation feature representation
module to learn image degradation feature from supervised
training on paired LR-HR images. Li et al. [24] proposed a
transformer network to learn multi-scale image feature via
self-attention mechanisms. To reduce the high training costs
of time and data, recent advances [5, 38, 40, 46, 50, 57, 59]
are proposed to solve BSR problem by an off-the-shelf dif-
fusion model [14]. Lin et al . [26] proposed to partially
fine-tune the parameters of diffusion model with signifi-
cantly less labeled images. Wang et al. [46] further for-
mulated a diffusion-based BSR algorithm that iteratively
solves super-resolution tasks with the given kernel without
re-training. Different from the end-to-end models that are
trained on paired image samples, recent methods tend to re-
solve BSR problem via pre-training on kernel datasets [25]
or pre-defined kernel priors [51]. An alternative framework
between the kernel estimation and image restoration is typ-
ically adopted in these methods [3, 10, 12, 39, 44, 58], such
as double-deep image prior (Double-DIP) [34]. On the basis
of this framework, Liang et al. [25] established a flow-based
kernel prior (FKP) network that is pre-trained on labeled
kernels to enroll kernel priors while the HR image is esti-
mated by DIP network in an online fashion. Yue et al. [51]
proposed a hand-crafted kernel prior model to improve the
robustness towards the Gaussian kernel scenario. Despite
the fact that these methods approximately bring down the
data requirements and training costs, the necessity of train-
ing in advances or hand-crafted design still limits the flexi-
bility and generalization ability towards the varying kernel
scenarios (Gaussian and motion) without ground truths.
3. Dynamic Kernel Prior (DKP)
Problem Formulation. The degradation model of BSR
problem is commonly expressed as follows,
y= (x⊗k)↓s+n, (1)
where ydenotes the LR image, xdenotes the HR image, ⊗
indicates the convolution operation, ↓sdenotes the down-
26047
Figure 1. The overview of the RKS module. The MCMC sim-
ulation can generate the random kernel kt
pfrom random kernel
distributions {kl
r}L
l=1as the kernel prior with respect to the cur-
rent model parameters xt−1,y.
sampling operation with scale factor s, andkdenotes the
blur kernel. The BSR problem (1) can be formulated as a
maximum a posteriori (MAP) problem:
max
x,kp(y|x,k)p(x)p(k), (2)
where p(y|x,k)denotes the likelihood of the observed LR
image y,p(x)andp(k)are the HR image and kernel pri-
ors, respectively. Image priors [8, 14, 41, 44, 55] have been
well-designed and fully-studied in the past decade. In con-
trast, researches on kernel priors p(k)are in the ascendant,
as kernel samples are less expensive to obtain and the train-
ing phase is more efficient [9, 12, 25, 51, 53].
In this paper, we propose the DKP model, which com-
prises two modules: RKS and PKE. The RKS module is
employed to generate rational kernel priors, which are as-
signed to the PKE module to support the estimation of blur
kernel. Let t= 1,2,···, Tdenote the alternative iterations
among these two modules and the adopted IR model, ktand
xtdenote the estimated blur kernel and HR image at the tth
iteration, respectively. The details of DKP model is given
below.
RKS module. At the tthiteration, the RKS module plays
the key role of generating a rational kernel prior kt
pfrom
the MCMC simulation. The overview diagram is shown in
Fig. 1. Let p(kr|Σr)denotes that the random kernel kr
is conditioned by the latent variable Σr, in which p(Σr)
determines the category of blur kernel. Then the distribution
of the kernel prior kt
pcan be formulated as
p(kt
p) =Z
Σrp(kr|Σr)p(Σr)dΣr. (3)
Here, Σris the parameter of kernel (e.g., the variance of
Gaussian kernel or the length of motion kernel). It is not
easy to sample all the possible Σr, and therefore, we con-
vert (3) into the Monte Carlo simulation in the following
form:
p(kt
p)≈LX
l=1p(kl
r|Σl
r)Σl
r, (4)where ldenotes the index of the Monte Carlo sampling, Σl
r
denotes the lthsampled latent variable, kl
ris the lthsam-
pled kernel, conditioned on the Σl
r.
To ensure the rationality of randomly generated kernels
towards the BSR problem, as well as the optimization dur-
ing the iterations, the MCMC simulation is proposed as fol-
lows,
p(kt
p|xt−1,y)≈LX
l=1p(kl
r|xt−1,y)p(kl
r|Σl
r)Σl
r,(5)
where p(kl
r|xt−1,y)denotes the kernel weight ωl, that is
conditioned on the observed LR image yand the estimated
HR image xt−1with respect to the MCMC loss LMCMC in
the following form
ωl=p(kl
r|xt−1,y)∝1
Ll
MCMC, (6)
where
Ll
MCMC =∥y−(xt−1⊗kl
r)↓s∥2
F+δ, (7)
δis the noise to prevent Ll
MCMC = 0. In this way, kt
pcan be
formulated as
kt
p=1
LLX
l=1ωlkl
r. (8)
The obtained kt
pis then assigned to the PKE module as a
rational kernel prior, which will be introduced next.
We note that the obtained kernel prior kt
pis an expecta-
tion of Ltimes sampling according to (4). The number of
the sampling times Lplays the role of annealing/tempering
in MCMC simulations as a hyper-parameter. Details of the
tuning on Lwill be given in Section 5.1.
PKE module. In our DKP model, the PKE module is em-
ployed to estimate the blur kernel by a lightweight network
Gkwith parameters ϕkas follows
kt=Gk(ϕt
k). (9)
The network G ktakes a fixed noise that is randomly initial-
ized as input, and we neglect it for demonstration conve-
nience as ϕt
kare the main variables.
This kernel estimator G kis optimized in the NLD
paradigm with respect to the data-consistency term and ker-
nel prior term, as shown in Fig. 2. The data-consistency
term is computed by the LR image reconstruction error,
which is given by
logp(ϕt−1
k|xt−1,y) =−∥y−(xt−1⊗Gk(ϕt−1
k))↓s∥2
F.
(10)
The kernel prior term is computed based on the difference
between the network-estimated kernel G k(ϕt−1
k)and the
26048
Figure 2. The overview of the PKE module. The blur kernel ktis
estimated by the network Gk, whose parameters ϕkare updated
by the kernel prior term from RKS module and data-consistency
term, based on the LR image reconstruction error.
random-sampled kernel kt
pfrom the RKS module as fol-
lows,
logp(ϕt−1
k|kt
p) =−∥Gk(ϕt−1
k)−kt
p∥2
F. (11)
By combining (10) and (11), the network parameters ϕt−1
k
can be updated as follows,
ϕt
k=ϕt−1
k+δ2
2∂logp(ϕt−1
k|xt−1,y)
∂ϕt−1
k
+δ∂logp(ϕt−1
k|kt
p)
∂ϕt−1
k, (12)
where the second term is the data-consistency update, the
third term is the additional update based on the random ker-
nelkt
p.
It has been proved to be effective that the random noise-
based disturbation can prevent being trapped into bad lo-
cal modes for the variable update in Langevin dynamics
[2, 32, 48, 51]. More details of Langevin dynamics refer
to the supplementary material. At this stage, the random
kernel sample from the RKS module can be regarded as the
random “noise” for the ϕt−1
kupdate. Eq. (12) can be refor-
mulated as follows,
ϕt
k=ϕt−1
k+δ2
2∂logp(ϕt−1
k|xt−1,y)
∂ϕt−1
k+ζt−1
ϕk,(13)
where ζt−1
ϕk=∂logp(ϕt−1
k|kt
p)
∂ϕt−1
kdenotes the parameters cor-
related Langevin dynamics disturbation.
The pipeline of our DKP at the tthiteration is given
in Algorithm 1. The whole DKP model is implemented in
a plug-and-play style, in which training in advance is not
required. Besides, the random kernels from the RKS mod-
ule are self-adaptively sampled through the MCMC simula-
tion, without the need of labeled training data. We should
also note that the DKP model only brings neglectable run-
time and memory cost in applications, as the adopted net-
work G kis typically lightweight. This leads to high flexi-
bility and low computational complexity. These three mer-
its promise our DKP the convenience of being applied toAlgorithm 1: The proposed DKP model.
1Given: xt−1,yandϕt−1
k.
2% Random Kernel Sampling (RKS) Module
3Sample random kernels {kl
r}L
l=1via MC.
4forl←0, 1,. . ., Ldo
5 ωl=1
Ll
MCMC,Ll
MCMC=∥y−(xt−1⊗kl
r)↓s∥2
F+δ
6end
7kt
p=1
LPL
l=1ωlkl
r
8% Prior Kernel Estimation (PKE) Module
9ϕt
k=ϕt−1
k+δ2
2∂logp(ϕt−1
k|xt−1,y)
∂ϕt−1
k+δ∂logp(ϕt−1
k|kt
p)
∂ϕt−1
k
10Output: kt=Gk(ϕt
k).
Figure 3. The overview of our DKP-based BSR method.
the existing image restoration approaches, including the un-
trained DIP model and off-the-shelf pre-trained diffusion
model, which will be detailed in the next section.
4. DKP-based BSR Methods
4.1. Pipeline
The overview of the proposed DKP-based BSR method is
illustrated in Fig. 3. The DKP model (gray box), including
RKS module (blue box), PKE module (lilac box), and IR
model (red box) alternatively optimize the blur kernel and
refine the HR image, respectively. For each iteration, the
estimated HR image xt−1and LR image yare first fed to
RKS module fRKSto generate kernel prior
kt
p=fRKS 
xt−1,y
, (14)
where xt−1denotes the estimated HR image from the last
IR model output. Then, the kernel prior kt
pwill be assigned
to the PKE module fPKE, which estimates kernel as follows,
kt=fPKE 
xt−1,y,kt
p
, (15)
where ktis the estimated kernel at the tthkernel estimation
iteration, which will be assigned to the IR model. The tth
HR image xtcan be estimated by the IR model as follows
xt=fIR 
xt−1,y,kt
, (16)
where fIRdenotes the adopted IR model. In this paper, two
representative IR models, DIP [44] and diffusion model [14]
, are applied to evaluate the DKP-based BSR solutions, re-
ferring to DIP-DKP and Diff-DKP, which are introduced in
the sequel.
26049
Algorithm 2: The proposed DIP-DKP.
1Given: y,ϕ0
x,ϕ0
DKP,x0=Gx(ϕ0
x).
2fort←0, 1,. . ., T-1 do
3 % DKP-based kernel estimation stage
4 ϕt+1
DKP=ϕt
DKP+δ2
2∂logp(ϕt
DKP|xt,y)
∂ϕt
DKP+δ∂logp(ϕt
DKP|kt
p)
∂ϕt
DKP
5 kt+1=GDKP(ϕt+1
DKP)
6 % DIP-based image restoration stage
7 ϕt+1
x=ϕt
x+γt
x∂logp(ϕt
x|y,kt)
∂ϕtx
8 xt+1=Gx(ϕt+1
x)
9end
10Output: xT,kT.
4.2. The proposed DIP-DKP
DIP-based Image Restoration. DIP [44] is designed for
capturing low-level image statistics, and estimates HR im-
agex=Gx(zx,ϕx)from a fixed random noise input zx
(we omit zxin the rest of this paper for demonstration con-
venience). A typical formulation of DIP-based BSR meth-
ods [25, 34] is given as follows


ϕ∗
x,ϕ∗
k= arg min
ϕx,ϕk∥y−
(Gx(ϕx)⊗Gk(ϕk))↓s∥2
F,(17)
x∗=Gx(ϕ∗
x),k∗=Gk(ϕ∗
k). (18)
Double-DIP [34] and FKP-DIP [25] have exploited the
effectiveness towards the BSR problem. However, the ker-
nel prior of G k(ϕ∗
k)either adopts the untrained network
with limited performances on the kernel estimation [34], or
pre-trained kernel network, referring to FKP [25], that re-
quests supervised training in advance. As shall be shown
in experiments, pre-trained networks do not perform well
to generate reasonable kernel estimations when the kernel
categories vary.
Proposed DIP-DKP. We replace the untrained or pre-
trained networks for kernel priors in the existing DIP-based
alternative framework by the proposed DKP model, which
we refer to as DIP-DKP. The objective of our proposed DIP-
DKP can be formulated as follows,


ϕ∗
x,ϕ∗
DKP= arg min
ϕx,ϕDKP∥y−(GDKP(ϕDKP)⊗
Gx(ϕx))↓s∥2
F+∥GDKP(ϕDKP)−kp)∥2
F,(19)
x∗=Gx(ϕ∗
x),k∗=GDKP(ϕ∗
DKP), (20)
where G DKP(ϕDKP)is the kernel network of the proposed
DKP model.
The overall solution procedure of the proposed DIP-
DKP is given in Algorithm 2. At each tthiteration, the
kernel ktis estimated in the DKP-based kernel estimation
stage and then is assigned to the DIP model for HR imageAlgorithm 3: The proposed Diff-DKP.
1Given: y,ϕT
DKP,SθandxT∼ N(0,I).
2fort←T, T-1, . . ., 1do
3 % Diffusion-based image restoration process
4 x0|t=1√
αt(xt− Sθ(xt, t)p
1−αt)
5 % DKP incorporated data consistency refinement
6 ϕt−1
DKP=ϕt
DKP+δ2
2∂logp(ϕt
DKP|x0|t,y)
∂ϕt
DKP+δ∂logp(ϕt
DKP|kt
p)
∂ϕt
DKP
7 kt−1=GDKP(ϕt−1
DKP)
8 ˆx0|t=x0|t+γt
x∂logp(x0|t|y,kt−1)
∂x0|t
9 xt−1∼p(xt−1|xt,ˆx0|t)
10end
11Output: x0,k0.
restoration in the forward propagation. In the back propa-
gation, the parameters of DIP and DKP, i.e., ϕxandϕDKP,
are updated while solving the BSR problem via an unsuper-
vised inference. With DKP, DIP-DKP realizes an adaptive
kernel learning along the convergence trajectory of the BSR
objective function, enabling accurate and dynamic kernel
estimation. Therefore, without expensive labeled data and
long training time in advance, DIP-DKP can estimate HR
image and blur kernel simultaneously in a plug-and-play
style.
4.3. Diff-DKP
Original DDPM Inference Process. Denoising diffusion
probabilistic models (DDPM) [14] defines a T-step forward
process to add noise to data and a T-step reverse process to
restore desired data from the noise. When an off-the-shelf
DDPM Sθis applied to solve image restoration problem,
the reverse process is implemented as inference process to
estimate the high quality image as follows,


x0|t=1√
αt(xt−Sθ(xt, t)p
1−αt), (21)
xt−1∼p(xt−1|xt,x0|t), (22)
where x0|tdenotes the estimated HR image x0at the tth
step, and αtis the hyper-parameter. To ensure that HR im-
agesx0∼q(x)can be reconstructed from random noise
xT∼ N(0,I), the existing methods typically re-train [38]
or fine-tune [50] the DDPM model via supervised learning
on LR-HR datasets, or provide ground truth kernel [46] to
enroll task-specific knowledge for convergence guarantee.
However, the performance of DDPM is unstable, even when
trained by a large number of labeled dataset.
Proposed Diff-DKP. The instability of DDPM mainly
comes from the training process that involves multiple im-
age processing tasks. In this case, the off-the-shelf diffusion
model cannot concentrate on BSR objective, thus leading to
26050
image distortion and content mismatch. To alleviate this is-
sue, the proposed Diff-DKP incorporates the DKP model
to provide task-specific data-consistency knowledge on the
basis of the vanilla DDPM reverse iterations. Specifically,
an external DKP incorporated data consistency refinement
ofx0|tis inserted between (21) and (22), given by
ˆx0|t=x0|t+γt
x∂logp(x0|t|y,kt)
∂x0|t, (23)
where γt
xis the update step, and
logp(x0|t|y,kt) =−∥y−(x0|t⊗kt)↓s∥2
F,(24)
which enables the inference process to converge to the right
direction along with the data-consistent solution.
The overview of the Diff-DKP algorithm is presented in
Algorithm 3. Let t=T, T−1, . . . , 1denote the index of
the diffusion reverse step. At each step, the diffusion model
first estimates the x0|t. Then, the DKP model adaptively
generates kernel prior with respect to the latest x0|t, while
x0|tis further updated with respect to the data consistency
Eq. (24), thus, ensuring the inference process is underly-
ing the BSR objective. It is noteworthy to point out that
the parameters of the diffusion model are fixed and only the
parameters of lightweight kernel estimator network are op-
timized in the inference process.
In this way, the off-the-shelf diffusion model plays the
role of HR image estimator, while the estimated HR image
is further refined by the BSR task specific prior knowledge,
referring to Eq. (23). Different from those methods that
incorporate prior knowledge of BSR task via supervised
re-training/fine-tuning, Diff-DKP behaves a plug-and-play
scheme, thus without data demands and training cost before
implementation.
5. Experiments
5.1. Experimental Setup
Data Preparation. Following the widely adopted ker-
nel assumption [25, 35, 45, 51], we conduct the experi-
ments on anisotropic Gaussian kernels and motion kernels,
which are shown in Fig. 4. The kernel sizes are set to
(4s+ 3)×(4s+ 3) . For the Gaussian kernel, the width
ranges are set to [0.175s,2.5s], and the rotation angle range
is set to [0, π], with a scale factor s= 4, respectively. For
the motion kernel, we adopt random motion kernel genera-
tion method proposed by [22], which simulates realistic and
complex blur kernels from random trajectories. Detailed
formulations of Gaussian and motion kernels are given in
the supplementary material. We synthesize LR images with
random kernels with respect to Eq. (1) for testing data based
on five popular public benchmark datasets, including Set5
[4], Set14 [52], BSD100 [30], Urban100 [15] and Real-
SRSet [23]. We compare these kernels in terms of the peaksignal to noise ratio (PSNR), and compare HR images in
terms of PSNR and structural similarity (SSIM) [47].
Comparison Methods. The proposed DIP-DKP and
Diff-DKP are compared with existing baselines including:
Double-DIP [34], DIP-FKP [25], DASR [45], BSRDM
[51], DCLS [29], DARM [58] and DiffBSR [26]. Specifi-
cally, Double-DIP tends to provide kernel priors by training
a FCN network only with respect to the LR image restora-
tion error. DIP-FKP incorporates the FKP model as ker-
nel prior which is pre-trained on kernel datasets. Kernel-
GAN+ZSSR and DARM are self-supervised and train an in-
teral generative adversarial network (GAN) to estimate the
blur kernel. BSRDM formulates an elaborate degradation
modelling on noise and kernel as handcrafted priors. DASR
is a representative end-to-end method that is pre-trained on
DIV2K [1] and Flickr2K [43] HR image datasets. DiffBSR
is fine-tuned on BSR labeled datasets before applied to es-
timate HR images.
Implementation and Hyper-parameters. The adopted
kernel estimation network G kof PKE module in this pa-
per is a three-layer fully-connected network (FCN). The
adopted DIP model follows the original settings in [44],
and the diffusion model is the vanilla version [14] that is
trained on ImageNet [6]. The number of sampling times
in the MCMC simulation Lis the only hyper-parameter in
the proposed DKP model. The hyper-parameter tuning re-
sults are given in Table 1.It is explicit that the performance
reaches equilibrium around L∈[4,8]. To balance the effi-
ciency and effectiveness, we set L= 5in this paper.
5.2. Comparison with State-of-the-Arts
Evaluation on Gaussian Kernel Scenario. Quantitative
evaluation results on four datasets with scale factors s= 4
are presented in the upper half part of Table 2. We can
see that the proposed DIP-DKP and Diff-DKP achieve the
second and the best results on all datasets. We note that
DIP-DKP only realizes slightly higher performance than the
existing state-of-the-art (SotA) methods, while Diff-DKP
achieves significantly better performances. This recalls our
demonstrations in Section 4: DIP-DKP is totally trained
while solving from scratch, and the DKP model plays the
role of providing better convergence guarantee. Diff-DKP
utilizes the DKP model to guide the well-trained diffusion
model with fruitful data priors to converge to BSR task for
better HR image restoration performances. In Table 3, we
further show that our DKP model achieves the accurate ker-
Figure 4. The visualization of the adopted blur kernels.
26051
Table 1. Average image PSNR performance of the proposed DIP-DKP and Diff-DKP on Set5 [4] on the Gaussian kernel scenario.
Methods L= 0 L= 2 L= 4 L= 6 L= 8 L= 10 L= 15
DIP-DKP (Ours) 20.99 27.12 28.44 28.57 28.52 28.29 28.03
Diff-DKP (Ours) 21.97 28.95 29.40 29.47 29.76 29.67 29.26
Table 2. Average PSNR/SSIM of different methods on public datasets that are synthesized by the random Gaussian/Motion kernels with
s= 4. The best and second best results are highlighted in red and blue colors, respectively.
Method Kernel Set5 [4] Set14 [52] BSD100 [30] Urban100 [15]
Double-DIP [34] 20.99/0.5578 18.31/0.4426 18.57/0.3815 18.15/0.4491
DASR [45] 27.37/0.7859 25.43/0.6591 25.11/0.6129 22.88/0.6448
DIP-FKP [25] 27.77/0.7914 25.65/0.6764 25.15/0.6354 22.89/0.6327
BSRDM [51] Gaussian 27.81/0.8029 25.35/0.6859 25.61/0.6526 22.36/0.6601
DCLS [29] kernel 27.50/0.7948 25.68/0.6639 25.34/0.6169 22.92/0.6475
DiffBIR [26] scenario 25.15/0.6468 23.01/0.5935 23.88/0.5586 21.94/0.5657
DARM [58] 26.25/0.6818 24.19/0.6187 24.29/0.5898 22.14/0.5967
DIP-DKP (Ours) 28.03/0.8039 25.98/0.6878 25.66/0.6531 23.24/0.6644
Diff-DKP (Ours) 29.44/0.8592 26.76/0.7400 26.63/0.7057 23.92/0.6875
Double-DIP [34] 18.92/0.4510 20.41/0.4847 19.00/0.3757 15.42/0.2932
DASR [45] 24.21/0.7252 24.16/0.6145 22.47/0.5836 20.24/0.5478
DIP-FKP [25] 24.61/0.7371 24.21/0.6227 22.80/0.5880 20.33/0.5572
BSRDM [51] Motion 24.01/0.7098 23.56/0.6009 22.62/0.5791 20.40/0.5494
DCLS [29] kernel 24.78/0.7323 24.38/0.6211 22.74/0.5922 20.49/0.5534
DiffBIR [26] scenario 23.63/0.6367 23.59/0.6043 22.35/0.5784 20.14/0.5347
DARM [58] 24.23/0.7269 23.95/0.6294 22.48/0.5830 20.58/0.5595
DIP-DKP (Ours) 25.30/0.7417 24.52/0.6434 23.02/0.6136 21.24/0.5667
Diff-DKP (Ours) 28.74/0.8313 26.03/0.6719 24.10/0.6287 22.26/0.5862
nel estimation with higher kernel PSNR.
Evaluation on Motion Kernel Scenario. The lower half
part of Table 2 shows the simulation results on the mo-
tion kernel scenario. The supervised learning methods,
i.e., DASR and DiffBIR, are re-trained/fine-tuned on mo-
tion kernel degraded HR image datasets. DIP-FKP is re-
trained on the motion kernel dataset. The proposed DIP-
DKP and Diff-DKP show significantly better performance
on the motion kernel scenario, which validates that the
proposed DKP model has good generalization ability to-
wards different kernel categories. Specifically, Diff-DKP
presents stable PSNR/SSIM scores when being applied to
estimate motion kernels, while the rest suffer significant
performance drop. This indicates that the proposed DKP
is expected to handle kernel varying tasks.
Visual Results. The visual results of different methods on
synthetic and real-world images are shown in Fig. 5. We
can see that 1) In the case of Gaussian kernel, all meth-
ods are capable of producing satisfactory deblurring results,
while our DIP-DKP and Diff-DKP yield better results with
more accurate kernel estimation. 2) In the case of mo-
tion kernel, certain distortion on the estimated kernel can
be seen in FKP-DKP and BSRDM fail to estimate motion
kernel. Meanwhile, our DIP-DKP and Diff-DKP achieve
approximately accurate motion kernel estimation. 3) In the
case of real image, both DIP-FKP and BSRDM estimate
the Gaussian-like kernels, whereas our DIP-DKP and Diff-
DKP tend to estimate the non-Gaussian kernels. This veri-
fies that an adaptive and flexible kernel estimation discipline
is learned by our DKP model, which may fit the real-world
applications better.Table 3. Average PSNR/SSIM of images and PSNR of kernels
on Set14 [52] with s= 4. The best and second best results are
highlighted in red and blue colors, respectively.
Method KernelKernel
PSNRImage
PSNR/SSIM
DIP-DKP without RKS 37.92 18.77/0.4227
Diff-DKP without RKS 40.93 17.33/0.3408
Double-DIP [34] Gaussian 50.62 18.31/0.4426
DIP-FKP [25] kernel 54.46 25.65/0.6764
BSRDM [51] scenario 55.38 25.35/0.6859
DIP-DKP (Ours) 56.20 25.98/0.6878
Diff-DKP (Ours) 56.76 26.76/0.7400
DIP-DKP without RKS 34.92 18.19/0.4223
Diff-DKP without RKS 34.78 17.65/0.3513
Double-DIP [34] Motion 35.52 20.41/0.4847
DIP-FKP [25] kernel 37.52 24.21/0.6227
BSRDM [51] scenario 37.88 23.56/0.6009
DIP-DKP (Ours) 39.33 24.52/0.6434
Diff-DKP (Ours) 40.37 26.03/0.6719
5.3. Ablation Studies
Ablation study of RKS module . The ablation studies are
carried on the MCMC sampling of kernel priors. “Without
RKS” denotes that the adopted DKP updates the kernel net-
work only by the data-consistency term without the learned
kernel prior. In Fig. 6 (left), it can be seen that the estimated
kernels without RKS have significant distortion, leading to
remarkable PSNR drop of the estimated HR image, while
DIP-DKP can estimate Gaussian kernels precisely with re-
spect to the ground truth (with red frame). Fig. 6 (right)
shows that the accurate motion kernel estimation no longer
exists when the RKS module is absent. It is thus obvious
that without the kernel prior learned from the MCMC pro-
cess, the Diff-DKP fails to converge to a rational motion
kernel estimation. The average kernel and image results are
shown in Table 3. Without kernel prior learned from the
RKS module, the kernel estimation performances of DKP-
26052
Figure 5. Visual results of different methods on public datasets for scale factor 4. Estimated/ground-truth kernels are shown on the top left.
Figure 6. The intermediate results of DIP-DKP, Diff-DKP and
their no RKS module versions over iterations on two test images.
Table 4. The ablation of PKE module. (Set5, x4, image PSNR)
Layers\Units 10 100 1000 10000
1 13.75 23.57 28.93 28.24
3 13.61 28.97 28.48 28.35
5 13.30 28.81 28.52 26.65
7 13.86 28.30 28.54 27.93
based BSR methods have a significant performance drop,
leading to poor image restoration performance as well.
Ablation study of PKE module . Since PKE essentially
estimates blur kernels on the basis of the random kernel pri-
ors and LR observations, thus it is indispensable and we
conduct ablation study on the different structures of kernel
network in PKE module in Table 4. We find that the kernel
network performs well when it has 3-7 layers with 100-1000
units in each layer. This indicates that the kernel network
has good generalization-ability for the structure without the
necessity of elaborately designing the network.
5.4. Model Size, Runtime and Memory Usage
The kernel network of our DKP model has a total of 562K
parameters (FLOPs: 536K) while Double-DIP and DIP-
FKP have 641Kparameters (FLOPs: 600K) and 143Kpa-
rameters (FLOPs: 178K), respectively. The runtime and
memory usage of our DIP-DKP on a GeForce RTX 3090GPU for generating a HR image of size 512×512are about
92seconds and 11GB memory, which is comparable with
the Double-DIP ( 91seconds and 11.2GB) and DIP-FKP ( 90
seconds and 10.6GB). As for Diff-DKP, the 512×512image
needs to be divided into four 256×256images for restora-
tion, which costs a total of 60seconds and 4GB memory.
Considering that our DIP-DKP and Diff-DKP are unsuper-
vised and plug-and-play, it is reasonable to say that our
methods have moderate computational costs.
Due to the page limitations, more experimental results
are given in the supplementary material.
6. Conclusion
In this paper, we propose a dynamic kernel prior (DKP)
model to solve the BSR problem in an unsupervised and
pre-training-free paradigm. DKP realizes the rational
kernel prior learning from MCMC sampling on random
kernel distributions, providing accurate kernel estimation
and thus leading to better HR image restoration. DKP
can be easily incorporated with existing image restoration
model, such as DIP and diffusion model, by replacing their
kernel modeling modules or adding as an external kernel
prior generator. When applied to solve the BSR problem,
DKP is trained while solving the task with respect to the LR
image restoration error, enabling no training necessity and
labeled data demands. Extensive experiments on Gaussian
and motion kernel scenarios with synthetic LR images and
real-world images validate that DKP-based methods im-
prove the kernel estimation accuracy significantly and thus
lead to superior BSR results. We believe that the concept
of using a trainable sampling process to provide adaptive
priors will lead to a new direction in solving low-level
tasks, aiming to achieve superior performance with modest
computational costs in the way of unsupervised inference.
26053
References
[1] Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge
on single image super-resolution: Dataset and study. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition workshops , pages 126–135, 2017. 6
[2] Dominique Bakry and Michel ´Emery. Diffusions hypercon-
tractives. In S´eminaire de Probabilit ´es XIX 1983/84: Pro-
ceedings , pages 177–206. Springer, 2006. 4
[3] Sefi Bell-Kligler, Assaf Shocher, and Michal Irani. Blind
super-resolution kernel estimation using an internal-gan. Ad-
vances in Neural Information Processing Systems , 32, 2019.
1, 2
[4] Marco Bevilacqua, Aline Roumy, Christine Guillemot, and
Marie Line Alberi-Morel. Low-complexity single-image
super-resolution based on nonnegative neighbor embedding.
InBritish Machine Vision Conference , pages 135–1, 2012.
6, 7
[5] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L
Klasky, and Jong Chul Ye. Diffusion posterior sam-
pling for general noisy inverse problems. arXiv preprint
arXiv:2209.14687 , 2022. 1, 2
[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and
pattern recognition , pages 248–255. Ieee, 2009. 6
[7] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou
Tang. Learning a deep convolutional network for image
super-resolution. In European conference on computer vi-
sion, pages 184–199. Springer, 2014. 2
[8] Yangyi Dong, Xiaoyun Zhang, Zhixin Wang, Ya Zhang,
Siheng Chen, and Yanfeng Wang. Unpaired face restora-
tion via learnable cross-quality shift. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 667–675, 2022. 3
[9] Netalee Efrat, Daniel Glasner, Alexander Apartsin, Boaz
Nadler, and Anat Levin. Accurate blur models vs. image pri-
ors in single image super-resolution. In Proceedings of the
IEEE International Conference on Computer Vision , pages
2832–2839, 2013. 3
[10] Yosef Gandelsman, Assaf Shocher, and Michal Irani. ”
double-dip”: Unsupervised image decomposition via cou-
pled deep-image-priors. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 11026–11035, 2019. 2
[11] Daniel Glasner, Shai Bagon, and Michal Irani. Super-
resolution from a single image. In 2009 IEEE 12th interna-
tional conference on computer vision , pages 349–356. IEEE,
2009. 2
[12] Jinjin Gu, Hannan Lu, Wangmeng Zuo, and Chao Dong.
Blind super-resolution with iterative kernel correction. In
Proceedings of the IEEE/CVF Conference on Computer Vi-
sion and Pattern Recognition , pages 1604–1613, 2019. 1, 2,
3
[13] Lanqing Guo, Chong Wang, Wenhan Yang, Siyu Huang,
Yufei Wang, Hanspeter Pfister, and Bihan Wen. Shadowd-
iffusion: When degradation prior meets diffusion model forshadow removal. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
14049–14058, 2023. 1
[14] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-
fusion probabilistic models. Advances in neural information
processing systems , 33:6840–6851, 2020. 2, 3, 4, 5, 6
[15] Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja. Single
image super-resolution from transformed self-exemplars. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 5197–5206, 2015. 6, 7
[16] Yan Huang, Shang Li, Liang Wang, Tieniu Tan, et al. Un-
folding the alternating optimization for blind super resolu-
tion. Advances in Neural Information Processing Systems ,
33:5632–5643, 2020. 1, 2
[17] Meiguang Jin, Stefan Roth, and Paolo Favaro. Normalized
blind deconvolution. In Proceedings of the European Con-
ference on Computer Vision (ECCV) , pages 668–684, 2018.
1
[18] Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Accurate
image super-resolution using very deep convolutional net-
works. In Proceedings of the IEEE conference on computer
vision and pattern recognition , pages 1646–1654, 2016. 2
[19] Kwang In Kim and Younghee Kwon. Single-image super-
resolution using sparse regression and natural image prior.
IEEE transactions on pattern analysis and machine intelli-
gence , 32(6):1127–1133, 2010. 1, 2
[20] Soo Ye Kim, Hyeonjun Sim, and Munchurl Kim. Koalanet:
Blind super-resolution using kernel-oriented adaptive local
adjustment. In Proceedings of the IEEE/CVF conference
on computer vision and pattern recognition , pages 10611–
10620, 2021. 1, 2
[21] Dilip Krishnan and Rob Fergus. Fast image deconvolution
using hyper-laplacian priors. Advances in neural information
processing systems , 22, 2009. 1, 2
[22] Orest Kupyn, V olodymyr Budzan, Mykola Mykhailych,
Dmytro Mishkin, and Ji ˇr´ı Matas. Deblurgan: Blind mo-
tion deblurring using conditional adversarial networks. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 8183–8192, 2018. 6
[23] Yuelong Li, Mohammad Tofighi, Junyi Geng, Vishal Monga,
and Yonina C Eldar. Efficient and interpretable deep blind
image deblurring via algorithm unrolling. IEEE Transac-
tions on Computational Imaging , 6:666–681, 2020. 6
[24] Yawei Li, Yuchen Fan, Xiaoyu Xiang, Denis Demandolx,
Rakesh Ranjan, Radu Timofte, and Luc Van Gool. Effi-
cient and explicit modelling of image hierarchies for image
restoration. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 18278–
18289, 2023. 2
[25] Jingyun Liang, Kai Zhang, Shuhang Gu, Luc Van Gool, and
Radu Timofte. Flow-based kernel prior with application to
blind super-resolution. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 10601–10610, 2021. 1, 2, 3, 5, 6, 7
[26] Xinqi Lin, Jingwen He, Ziyan Chen, Zhaoyang Lyu, Ben Fei,
Bo Dai, Wanli Ouyang, Yu Qiao, and Chao Dong. Diffbir:
Towards blind image restoration with generative diffusion
prior. arXiv preprint arXiv:2308.15070 , 2023. 2, 6, 7
26054
[27] Jie Liu, Wenjie Zhang, Yuting Tang, Jie Tang, and Gangshan
Wu. Residual feature aggregation network for image super-
resolution. In Proceedings of the IEEE/CVF conference on
computer vision and pattern recognition , pages 2359–2368,
2020. 1
[28] Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, and
Tieniu Tan. End-to-end alternating optimization for blind
super resolution. arXiv preprint arXiv:2105.06878 , 2021. 2
[29] Ziwei Luo, Haibin Huang, Lei Yu, Youwei Li, Haoqiang Fan,
and Shuaicheng Liu. Deep constrained least squares for blind
image super-resolution. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 17642–17652, 2022. 1, 2, 6, 7
[30] David Martin, Charless Fowlkes, Doron Tal, and Jitendra
Malik. A database of human segmented natural images
and its application to evaluating segmentation algorithms and
measuring ecological statistics. In Proceedings Eighth IEEE
International Conference on Computer Vision. ICCV 2001 ,
pages 416–423. IEEE, 2001. 6, 7
[31] Tomer Michaeli and Michal Irani. Nonparametric blind
super-resolution. In Proceedings of the IEEE International
Conference on Computer Vision , pages 945–952, 2013. 2
[32] Radford M Neal et al. Mcmc using hamiltonian dynamics.
Handbook of markov chain monte carlo , 2(11):2, 2011. 4
[33] Daniele Perrone and Paolo Favaro. A clearer picture of total
variation blind deconvolution. IEEE transactions on pattern
analysis and machine intelligence , 38(6):1041–1055, 2015.
1, 2
[34] Dongwei Ren, Kai Zhang, Qilong Wang, Qinghua Hu, and
Wangmeng Zuo. Neural blind deconvolution using deep pri-
ors. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition , pages 3341–3350,
2020. 1, 2, 5, 6, 7
[35] Gernot Riegler, Samuel Schulter, Matthias Ruther, and Horst
Bischof. Conditioned regression models for non-blind sin-
gle image super-resolution. In Proceedings of the IEEE In-
ternational Conference on Computer Vision , pages 522–530,
2015. 6
[36] Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear
total variation based noise removal algorithms. Physica D:
nonlinear phenomena , 60(1-4):259–268, 1992. 2
[37] Marshall F Tappen Bryan C Russell and William T Freeman.
Exploiting the sparse derivative prior for super-resolution
and image demosaicing. In Proceedings of the Third Inter-
national Workshop Statistical and Computational Theories
of Vision , pages 1–28, 2003. 2
[38] Chitwan Saharia, Jonathan Ho, William Chan, Tim Sal-
imans, David J Fleet, and Mohammad Norouzi. Image
super-resolution via iterative refinement. IEEE Transactions
on Pattern Analysis and Machine Intelligence , 45(4):4713–
4726, 2022. 2, 5
[39] Assaf Shocher, Nadav Cohen, and Michal Irani. “zero-shot”
super-resolution using deep internal learning. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition , pages 3118–3126, 2018. 1, 2
[40] Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan
Kautz. Pseudoinverse-guided diffusion models for inverseproblems. In International Conference on Learning Repre-
sentations , 2022. 1, 2
[41] Yang Song and Stefano Ermon. Generative modeling by esti-
mating gradients of the data distribution. Advances in neural
information processing systems , 32, 2019. 3
[42] Jian Sun, Zongben Xu, and Heung-Yeung Shum. Image
super-resolution using gradient profile prior. In 2008 IEEE
Conference on Computer Vision and Pattern Recognition ,
pages 1–8. IEEE, 2008. 2
[43] Radu Timofte, Eirikur Agustsson, Luc Van Gool, Ming-
Hsuan Yang, and Lei Zhang. Ntire 2017 challenge on single
image super-resolution: Methods and results. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition workshops , pages 114–125, 2017. 6
[44] Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky.
Deep image prior. In Proceedings of the IEEE conference on
computer vision and pattern recognition , pages 9446–9454,
2018. 2, 3, 4, 5, 6
[45] Longguang Wang, Yingqian Wang, Xiaoyu Dong, Qingyu
Xu, Jungang Yang, Wei An, and Yulan Guo. Unsuper-
vised degradation representation learning for blind super-
resolution. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 10581–
10590, 2021. 2, 6, 7
[46] Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-shot im-
age restoration using denoising diffusion null-space model.
arXiv preprint arXiv:2212.00490 , 2022. 2, 5
[47] Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Si-
moncelli. Image quality assessment: from error visibility to
structural similarity. IEEE transactions on image processing ,
13(4):600–612, 2004. 6
[48] Max Welling and Yee W Teh. Bayesian learning via stochas-
tic gradient langevin dynamics. In Proceedings of the 28th
international conference on machine learning (ICML-11) ,
pages 681–688, 2011. 4
[49] Yu-Syuan Xu, Shou-Yao Roy Tseng, Yu Tseng, Hsien-Kai
Kuo, and Yi-Min Tsai. Unified dynamic convolutional net-
work for super-resolution with variational degradations. In
Proceedings of the IEEE/CVF Conference on Computer Vi-
sion and Pattern Recognition , pages 12496–12505, 2020. 1,
2
[50] Xunpeng Yi, Han Xu, Hao Zhang, Linfeng Tang, and Jiayi
Ma. Diff-retinex: Rethinking low-light image enhancement
with a generative diffusion model. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 12302–12311, 2023. 1, 2, 5
[51] Zongsheng Yue, Qian Zhao, Jianwen Xie, Lei Zhang, Deyu
Meng, and Kwan-Yee K. Wong. Blind image super-
resolution with elaborate degradation modeling on noise
and kernel. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 2128–
2138, 2022. 1, 2, 3, 4, 6, 7
[52] Roman Zeyde, Michael Elad, and Matan Protter. On sin-
gle image scale-up using sparse-representations. In Interna-
tional conference on curves and surfaces , pages 711–730.
Springer, 2010. 6, 7
26055
[53] Kai Zhang, Wangmeng Zuo, and Lei Zhang. Learning
a single convolutional super-resolution network for multi-
ple degradations. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition , pages 3262–
3271, 2018. 1, 2, 3
[54] Kai Zhang, Luc Van Gool, and Radu Timofte. Deep unfold-
ing network for image super-resolution. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition , pages 3217–3226, 2020. 1
[55] Kai Zhang, Yawei Li, Wangmeng Zuo, Lei Zhang, Luc
Van Gool, and Radu Timofte. Plug-and-play image restora-
tion with deep denoiser prior. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence , 44(10):6360–6376,
2021. 3
[56] Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng
Zhong, and Yun Fu. Image super-resolution using very
deep residual channel attention networks. In Proceedings of
the European conference on computer vision (ECCV) , pages
286–301, 2018. 1, 2
[57] Zixiang Zhao, Haowen Bai, Yuanzhi Zhu, Jiangshe Zhang,
Shuang Xu, Yulun Zhang, Kai Zhang, Deyu Meng, Radu
Timofte, and Luc Van Gool. Ddfm: denoising diffusion
model for multi-modality image fusion. arXiv preprint
arXiv:2303.06840 , 2023. 1, 2
[58] Hongyang Zhou, Xiaobin Zhu, Jianqing Zhu, Zheng Han,
Shi-Xue Zhang, Jingyan Qin, and Xu-Cheng Yin. Learn-
ing correction filter via degradation-adaptive regression for
blind single image super-resolution. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 12365–12375, 2023. 2, 6, 7
[59] Yuanzhi Zhu, Kai Zhang, Jingyun Liang, Jiezhang Cao, Bi-
han Wen, Radu Timofte, and Luc Van Gool. Denoising dif-
fusion models for plug-and-play image restoration. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 1219–1229, 2023. 1, 2
26056
