PIE-NeRF /pizza-slice: Physics-based Interactive Elastodynamics with NeRF
Yutao Feng1,2*Yintong Shang2*Xuan Li3Tianjia Shao1†Chenfanfu Jiang3Yin Yang2
1State Key Laboratory of CAD&CG, Zhejiang University
2University of Utah
3University of California, Los Angeles
fytal0n@gmail.com yintong.shang@utah.edu xuanli1@math.ucla.edu
tjshao@zju.edu.cn chenfanfu.jiang@gmail.com yangzzzy@gmail.com
Rest poseFrame 100Frame 200Frame 300Frame 400
Figure 1. Swaying plant. PIE-NeRF /pizza-sliceis an efﬁcient and versatile pipeline that synthesizes physics-based novel motions of complex
NeRF models interactively. In this example, the user interactively manipulates the plant by applying external forces with the mouse. The
geometry of the plant is sampled in a meshless way, and a spatial model reduction is followed. We use 78 Q-GMLS kernels to capture the
nonlinear dynamics of the plant in real-time. PIE-NeRF generates novel poses of the model from novel views in a physics-grounded way.
Abstract
We show that physics-based simulations can be seamlessly
integrated with NeRF to generate high-quality elastody-
namics of real-world objects. Unlike existing methods, we
discretize nonlinear hyperelasticity in a meshless way, obvi-
ating the necessity for intermediate auxiliary shape proxies
like a tetrahedral mesh or voxel grid. A quadratic gener-
alized moving least square is employed to capture nonlin-
ear dynamics and large deformation on the implicit model.
Such meshless integration enables versatile simulations of
complex and codimensional shapes. We adaptively place
the least-square kernels according to the NeRF density ﬁeld
to signiﬁcantly reduce the complexity of the nonlinear sim-
ulation. As a result, physically realistic animations can be
conveniently synthesized using our method for a wide range
of hyperelastic materials at an interactive rate. For more
information, please visit our project page .
*Both authors contributed equally to this work
†Corresponding author1. Introduction
Neural radiance ﬁeld or NeRF [ 46] offers a new perspec-
tive to 3D reconstruction and representation. NeRF en-
codes the color, texture, and geometry information of a 3D
scene with an MLP net implicitly from multi-view input
photos. Its superior convenience and efﬁcacy inspired nu-
merous follow-up research for improved visual quality [ 41],
faster performance [ 19,85], and sparser inputs [ 29,86].
The target application has also been generalized from novel
view synthesis to moving scene reconstruction or shape
editing [ 22,59,81,87]. Nevertheless, complex, nonlinear,
and time-coherent elastodynamic motion synthesis that is
grounded on real-world physics remains less explored with
the current NeRF ecosystem.
This is probably because a physical procedure is innately
incompatible with implicit representations. For dynamic
models (i.e., with accelerated trajectories), spatial partial
differential equations (PDEs) of stress equilibriums are cou-
pled with an ordinary differential equation (ODE) to enforce
Newtonian laws of motion. One needs a good discretiza-
tion for existing simulation methods e.g., the ﬁnite element
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
4450
method (FEM) [ 92], and polygonal meshes remain the most
popular choice in this regard. As a result, a dedicated mesh-
ing step is often needed [ 42,87]. The computation cost
is another concern. Dynamic simulation normally leads to
a large sparse nonlinear system at each time step, and the
simulation becomes expensive and has to be ofﬂine [ 42].
We propose PIE-NeRF /pizza-slice, a NeRF-based framework that
allows users to interact with the scene in a physically mean-
ingful way, and thus generate novel deformed poses dynam-
ically. PIE-NeRF uses a meshless discretization scheme by
adaptively sampling the density ﬁeld encoded with NeRF
based on the magnitude of the density gradient. The efﬁ-
ciency of our computation comes from the meshless spa-
tial reduction that makes the simulation independent of the
sampling resolution. Speciﬁcally, PIE-NeRF employs a
generalized quadratic moving least square (Q-GMLS) [ 44]
to drive dynamics robustly even for codimensional shapes.
The prior of the quadratic displacement also allows us to de-
sign a better ray-warping algorithm so that the color/texture
information of the deformed model can be accurately re-
trieved. PIE-NeRF uses instant neural graphics primitives
(NGP) [ 52] for faster rendering. Some noteworthy features
of PIE-NeRF include:
Meshless Lagrangian dynamics in NeRF. We show the
feasibility of integrating classic Lagrangian dynamics with
NeRF in a meshless way. Honestly, we do not completely
avoid the conversion from the implicit deep representation
to an explicit form but a meshless shape proxy enhances the
ﬂexibility and simpliﬁes the pipeline of simulation in NeRF.
Robust Q-GMLS for meshless model reduction. We care-
fully design PIE-NeRF by accommodating the robustness,
expressivity and computation cost simultaneously. With
spatial reduction based on the V oronoi partition, we en-
hance the expressivity of our reduced model using quadratic
displacement interpolation, which captures the nonlinear
deformation of the model without locking artifacts. The
quadratic ﬁeld also contributes an improved ray-warping al-
gorithm during the view synthesis.
Versatile simulation at an interactive rate. Being a full
physics-based pipeline, PIE-NeRF can faithfully designate
material parameters such as Young’s modulus and Poisson’s
ratio to NeRF models. It is also efﬁcient, allowing an in-
teractive interaction between the virtual NeRF scene and
end users. Thanks to our high-order interpolation, codimen-
sional models can also be well handled with PIE-NeRF.
2. Related work
NeRF editing. Since the advent of NeRF, many tech-
niques tailored for implicit representation have emerged i.e.,
discretely estimating the deformation/displacement ﬁeld
for each frame [ 55,56,72,77] or estimating the time-
continuous 3D motion ﬁeld [ 15,17,23,38,40,61,79].Recently, Cao and colleagues have matched space-time fea-
tures to hexplanes for improved NeRF training [ 11].
There also exists a wide range of NeRF editing methods
for various purposes. These include semantic-driven edit-
ing [3,13,24,45,66,73], shading-driven adjustments (like
relighting and texturing) [ 21,43,64,68,78,84], scene mod-
iﬁcations (such as object addition or removal) [ 35,36,76,
83,90], face editing [ 27,31,70,89], physics based editing
from video[ 25,62], and multi-purpose editing [ 30,75,82].
Geometry editing with NeRF has also been widely in-
vestigated [ 32,86,88,91]. They normally concern static
shapes only, where the as-rigid-as-possible (ARAP) energy
sufﬁces [ 67] in most situations. The ARAP energy is of-
ten computed by converting neural implicit representation
to some explicit forms like grid or mesh [ 18]. To reduce
the computational overhead, some opt for coarser meshes,
utilizing cage-based deformation techniques [ 30,59,81].
Point-based shape editing is a viable alternative. Chen
and colleagues [ 12] proposed a more general editing frame-
work with the optimized points inherent in a point-based
variant of NeRF [ 80]. More recently, Prokudin and col-
leagues exploited a point-based surface derived from an im-
plicit volumetric representation [ 60].
Physics-based deformable model. The concept of de-
formable model dates back to 1980s [ 71], primarily as-
sociated with physics-based models [ 54]. Typically, an
explicit discretization is needed such as mass-spring sys-
tems [ 4] that were widely used in early graphics applica-
tions. FEM has become the standard for physics-based sim-
ulation [ 10,34,48,65], wherein the deformation is usually
measured by integrating over each tetrahedral or hexahedral
unit, that is, the element [ 92]. Physics-based modeling is
known to be expensive, which inspires a series of research
for accelerated simulation such as model reduction [ 5] or
GPU parallelization [ 74].
Meshless simulation. Meshless methods use unstructured
vertices in lieu of a predeﬁned mesh [ 7,16,39]. This
modality is quite effective when the simulation domain has
varying topology, such as ﬂuids, gases, fracturing or melt-
ing. Meshless deformation has evolved to handle contin-
uum mechanics [ 51]. A notable example is the shape match-
ing [ 50]. With the core idea of constraining vertices’ posi-
tions, shape matching paves the way to the position-based
methods [ 47,49,69]. Similar to shape functions in FEM,
meshless methods also need well-designed interpolation
schemes [ 16], such as moving least squares (MLS) [ 51,58]
or smoothed-particle hydrodynamics SPH [ 1].
Due to the large volume of relevant work, we can only
discuss a small fraction of excellent prior arts in this sec-
tion. Nevertheless, we note that synthesizing novel dynamic
motions of a NeRF scene in a physically grounded way re-
mains less explored. This gap inspires us to develop PIE-
NeRF/pizza-slice. PIE-NeRF is a physics-based, meshless, and efﬁ-
4451
cient framework allowing users to interactively manipulate
the NeRF scene.
3. Preliminary
To make the paper self-contained, we start with a brief re-
view of some core techniques on which our pipeline is built.
More details of our system are elaborated in § 4.
3.1. Neural radiance ﬁeld
NeRF implicitly represents the geometry and appearance
information of a 3D scene via a multi-layer perceptron
(MLP) net. Given the camera parameters, a pixel’s color
on the image plane is obtained via integrating the density
and color along the ray. A spatial coordinate pand a ray
direction dare often encoded as a feature vector ψp,ψd
before being fed to the MLP for the prediction of density
(σ) and color ( c). For instance, the vanilla NeRF [ 46] uses
positional encoding to better tackle high-frequency infor-
mation with MLPs. Our pipeline uses the instant neural
graphics primitives (NGP) [ 52]. NGP adopts a multi-level
hash-based encoding scheme and has demonstrated a strong
performance in terms of both efﬁciency and quality.
3.2. Nonlinear elastodynamic
Following the classic Lagrangian mechanics [ 53], the dy-
namic equilibrium of a 3D model is characterized as:
d
dt/parenleftbigg∂L
∂˙q/parenrightbigg
−∂L
∂q=fq, (1)
whereL=T−UisLagrangian i.e., the difference between
the kinematic energy ( T) and the potential energy ( U) of the
system.qand˙qare generalized coordinate and velocity.
fqis the generalized external force. Given a time integra-
tion scheme such as implicit Euler: qn+1=qn+h˙qn+1,
˙qn+1=˙qn+h¨qn+1, Eq. ( 1) can be reformulated a set of
nonlinear equations to be solved at each time step:
M(qn+1−qn−h˙q) =h2/parenleftbigg
−∂U
∂q+fq/parenrightbigg
. (2)
Here, the subscript indicates the time step index, and his the
time step size. qn+1is the unknown system coordinate to
be solved, while all the kinematic variables of the previous
time step such as qnor˙qnare considered known. −∂U/∂q
is the negative gradient of the potential, which embodies the
internal force.
4. Our method
As shown in Fig. 2, the input of our system is a collection
of images of a given 3D scene. We use NGP to encode
positional and texture information and train the correspond-
ing NeRF. Afterwards, we disperse particles into the scene.Those particles form an unstructured point-cloud-like proxy
of the 3D model of interest. They are then grouped under a
V oronoi partition, and the centers of V oronoi cells house
the generalized coordinate of the system ( qin Eq. ( 2)).
We further assign multiple integrator points (IPs) to facil-
itate energy integration. A quadratic generalized moving
least square (Q-GMLS) strategy is used to discretize the La-
grangian equation of Eq. ( 1). With the help of GPU, the
simulation can be done at an interactive rate or even in real-
time. We leverage the deformation information at IPs to
infer the rest-pose position during NGP-based NeRF ren-
dering. Thanks to NGP, this procedure is also in real-time.
Our pipeline allows users to interact with a NeRF scene by
applying external forces, position constraints etc., leading
to novel and physics-grounded dynamic effects. Next, we
give detailed expositions of each major step of the pipeline.
4.1. Augmented Poisson disk sampling
After the NGP-NeRF is trained, we choose a meshless way
to model the geometry of the 3D shape. While the underly-
ing goal of this step is similar to other static NeRF editing
systems [ 59,81,88], being mesh-free makes our pipeline
more ﬂexible and versatile. In theory, any sampling method
should work as long as the sampling particles sufﬁciently
capture the boundary of the model. For instance, one can
distribute particles by simply following the evenly-spaced
grid (Fig. 3, right). Doing so is similar to using a grid-based
cage to approximate the shape of the model [ 22].
Alternatively, we design an augmented Poisson disk
sampling (PDS) strategy. The original PDS requires that the
distance between any two particles be larger than a thresh-
old¯r. Starting from an initial point, PDS then tries to ﬁll
a banded ring between ¯rand2¯rwith new samples i.e.,
see [ 9]. Our observation is that more particles are needed
at the boundary of the shape, which coincides with a sharp
density variation. To this end, we adaptively adjust the sam-
ple radiusrbased on the norm of the density gradient of
NGP-NeRF ∥∇σ∥such that:
r= min/braceleftBigg
¯r,κ¯r/radicalbig
∥∇σ∥+α/bracerightBigg
, (3)
whereα= 10−3is a small number avoiding the division-
by-zero error. Eq. ( 3) suggests that the actual sample radius
rdecreases when ∥∇σ∥is a large quantity. The density
gradient∥∇σ∥can be conveniently computed by differen-
tiating the NPG-NeRF using AutoDiff [57]. We discard
PDS particles whose density values are less than ϵ= 10−2,
which are visualized as pink dots in Fig. 3.
Our sampling ensures that the distance between a PDS
particle at xand its nearest neighbor is at least r(x), and we
assign a volume of the PDS particle as:
V(x) =4
3πr3(x). (4)
4452
Poisson disc sampling ( Sec. 4.1 )
Input  Q-GMLS kernels & IPs ( Sec. 4.2 )
Quadratic warping ( Sec. 4.4 )Physics-based motion synthesis ( Sec. 5 )
Time
integration
Figure 2. Pipeline overview. The input of PIE-NeRF is the same as other NeRF-based frameworks, which consists of a collection of
images of a static scene. An adaptive Poisson disk sampling is followed to query the 3D geometry of the model, which are sparsiﬁed into
nQ-GMLS kernels. Integrator points are placed over the model, including centers of Q-GMLS kernels (i.e., kernel IPs). Discretization
at kernels and numerical integration at IPs enable efﬁcient synthesis of novel and physics-based elastodynamic motions. The quadratic
warping scheme helps to better retrieve the color/texture of a deformed spatial position to render the ﬁnal result.
Figure 3. Particle sampling. Our method is compatible with most
sampling algorithms – as long as particles cover the shape of the
3D model sufﬁciently well. In our implementation, we design a
novel augmented Poisson disk sampling scheme that is fast and
well captures the boundary of the model by default.
4.2. Q­GMLS kernels and integrator points
PDS particle
Q-GMLS kernel
& kernel IP
Integrator point
We perform a V oronoi par-
tition [ 2] over PDS particles
(see the inset) and use each
V oronoi cell as a GMLS ker-
nel for the body-wise dis-
placement interpolation to re-
duce the computation overhead. Let Ωbe the body of a 3D
model in NeRF sampled by PDS particles with nGMLS
kernels. The classic MLS assumes a kernel possesses an
afﬁne displacement ﬁled: Aip(xi), wherexiis the center
of thei-th kernel at the rest pose (green dots in the inset);
p(x) = [1,x⊤]⊤. By minimizing a displacement-based tar-get of:/summationtextn
i=1w(x−xi)∥Ap(xi)−ui∥2one can obtain:
u(x) =n/summationdisplay
i=1uiNi(x). (5)
Hereui=u(xi)is the displacement of i-the kernel cen-
ter;Ni(x) =p(x)⊤G−1(x)p(xi)w(x−xi), forG(x) =/summationtextn
i=1w(x−xi)p(xi)p(xi)⊤, is a shape-function-like trial
function; and w(d) = (1− ∥d∥2)3is a MLS weighting
function based on the distance between xandxi.
As the complexity of the simulation is up to n, we are in
favor of using fewer kernels for faster computation. Doing
so is likely to have xibe colinear/coplanar, and Gbecomes
singular. To improve the robustness of the kinematic in-
terpolation of Eq. ( 5), GMLS takes the local deformation
gradient information into account, which seeks the opti-
malAito minimize/summationtextn
i=1w(x−xi)∥Aip(xi)−ui∥2+/summationtextn
i=1/summationtext3
j=1w(x0−xi)∥Aip,j(xi)−ui,j∥2. The comma
here denotes the partial differentiation such that ui,1=
∂ui/∂x,ui,2=∂ui/∂y, andui,3=∂ui/∂z.
For thin and codimensional shapes, afﬁne GMLS suffers
from locking issues, wherein linearized shearing energy be-
comes orders stronger than nonlinear bending/twisting due
to the interpolation error. This problem gets more serious
with fewer kernels. To this end, we elevate the interpola-
tion order, leading to quadratic GMLS or Q-GMLS, which
assumes the per-kernel displacement ﬁeld is quadratic.
Namely, each x,y, orzcomponent of the displacement
(i.e., forj= 1,2,3respectively) is ﬁt by: uij=x⊤
iQj
ixi+
aj⊤
ip(xi). HereQj
iis a symmetric tensor, and aj
i∈R4is
4453
j-th row of Ai. The Q-GMLS displacement interpolation
can then be derived as:
u(x) =n/summationdisplay
i=1/bracketleftbig
uiNi+/summationdisplay
jui,jNj
i+/summationdisplay
j,kui,jkNjk
i/bracketrightbig
,(6)
forj,k= 1,2,3. Here
Ni(x) =p⊤(x)G−1(x)p(xi)w(x−xi),
Nj
i(x) =p⊤(x)G−1(x)p,j(xi)w(x−xi),
Njk
i(x) =p⊤(x)G−1(x)p,jk(xi)w(x−xi)(7)
only depend on the rest-shape position x, and
G(x) =n/summationdisplay
i=1w(x−xi)/bracketleftbig
p(xi)p⊤(xi)
+/summationdisplay
jp,j(xi)p⊤
,j(xi)+/summationdisplay
j,kp,jk(xi)p⊤
,jk(xi)/bracketrightbig
.(8)
It is convenient to re-organize Eq. ( 6) as:
u(x) =J(x)q, (9)
such that J= [N1I,N1
1I,N2
1I,...,N11
1I,...]∈R3×30nand
q= [u⊤
1,u⊤
1,1,u⊤
1,2,...,u⊤
1,11,...]⊤∈R30nare the Jacobi
matrix and generalized coordinate (i.e., in Eq. ( 1)). Thus the
generalized external force is computed via: fq=J⊤fext.
4.3. Energy integration
The total kinematic and potential energies of the model are:
T=1
2/integraldisplay
Ωρ(x)˙x⊤˙xdΩ,andU=/integraldisplay
ΩΨ(x)dΩ.(10)
We want to avoid integrating over all the PDS particles.
Therefore, our system includes another set of integrator
points or IPs. Conceptually, IPs are similar to the quadra-
ture points used in numerical integration [ 20], which allows
us to substantially reduce the computational cost of full in-
tegrals in Eq. ( 10). In addition to the centers of Q-GMLS
kernels i.e., kernel IPs, we add more IPs aiming to approxi-
mate Eq. ( 10) with high accuracy. Speciﬁcally, we initialize
new IPs at the PDS particle which is the most distant from
existing IPs to sample remote TandVvalues. This strategy
however tends to favor PDS particles at the model’s bound-
ary. As a result, we apply a few Lloyd relaxations [ 14] to
new IPs while keeping kernel IPs ﬁxed. The total number of
IPs is bigger than the number of Q-GMLS kernels but they
are of the same order, and we use Ito denote the set of all
the IPs.
4.4. Per­IP integration
Integrator pointIP cuboidWe envision each IP as a small elastic
cuboidΩk(see the inset) with three
edges being c1,c2,c3whose lengths
areh1,h2,h3respectively. Its co-
variance matrix can be computed as:
C=/summationtext
jV(xj)xjx⊤
j, where the summation carries over
K-nearest PDS particles whose rest positions are xj. Being
a symmetric matrix, Calways has three real non-negative
eigen values namely, λ1,λ2, andλ3. Note that coplanar
geometry around an IP can make Csingular. It is ﬁne for
numerical integration, suggesting the strains along certain
directions are zero. We then set the ratio among hito be the
same as√λi(i.e.,h1:h2:h3equals√λ1:√λ2:√λ3)
while requiring Πihi=/summationtext
jV(xj). Those two constraints
allow us to compute h1,h2, andh3whileciare the corre-
sponding eigen vectors.
The total kinematic energy can now be approximated as:
T=1
2/integraldisplay
Ωρ(x)˙x⊤˙xdΩ =1
2˙q⊤/parenleftbigg/integraldisplay
ΩρJ⊤JdΩ/parenrightbigg
˙q
≈1
2˙q⊤/bracketleftBigg/summationdisplay
xk∈IρVkJ⊤(xk)J(xk)/bracketrightBigg
˙q,(11)
andM=/summationtext
xk∈IρVkJ⊤(xk)J(xk)is the mass matrix.
Note thatVk=h1h2h3is the estimated volume of the IP
cuboid, not the volume of the PDS particle. ρis the density
of the 3D model, which should not be confused with σ.
Integrating the potential energy Uis handled in a sim-
ilar way. Under the assumption of hyperelasticity, the en-
ergy density Ψ(x)depends on the deformation gradient at
x:F=∇u(x)+I∈R3×3. According to Eq. ( 9), the
deformation gradient at the k-th IP is:
F(xk) =Fk=q·∇J⊤(xk)+I=q·∇J⊤
k+I.(12)
Jk∈R3×30nis the Jacobi corresponding to the IP, and
∇J⊤
k∈R30n×3×3is a third tensor. The potential accumu-
lated at the IP is estimated by integrating over its cuboid
(Ωk) assuming the IP lies at the center:
Uk=/integraldisplay
ΩkΨ(F(h)) =/integraldisplayh1
2
−h1
2/integraldisplayh2
2
−h2
2/integraldisplayh3
2
−h3
2Ψ(F(h)).(13)
Here,his the local coordinate spanning Ωk, andxkaligns
withh= 0. Whenh̸= 0, we ﬁrst-order approximate Fas:
F(h)≈F(0)+∇F(0)·h=F(xk)+∇F(xk)·h.(14)
This makes sense because Q-GMLS assumes uis quadratic,
which has a linearly-vary deformation gradient. Therefore,
the approximate in Eq. ( 14) should be exact. ∇Fcan be
computed by differentiating Eq. ( 12):
∇F(xk) =q·∇2J⊤
k=Hk·q. (15)
4454
Figure 4. Elastically deforming excavator. The excavator is a standard benchmark for NeRF-based frameworks. We use this classic model
to showcase the capability of PIE-NeRF, which generates interesting and novel dynamic effects in real time.
HereH=∂∇J⊤/∂xis a fourth tensor. This computation
boils down to evaluating ﬁrst- and second-derivatives of Ni,
Nj
i, andNjk
i, and can be pre-computed per Eq. ( 7).
Given an elastic material model Ψ(F), the total potential
can then be computed via:
U≈/summationdisplay
xk∈I/integraldisplay
ΩkΨ/parenleftbig
F(0)+Hk: (qh⊤)/parenrightbig
dΩk. (16)
The actual integration computation relies on the speciﬁc for-
mulation of Ψ(F). Please refer to the supplementary docu-
ment for detailed derivations of some commonly-used ma-
terial models such as ARAP and Neo-Hookean.
4.5. System assembly and solve
With energy integrals, we can assemble Eq. ( 2). The gen-
eralized internal force is fint=−∂U/∂q, and it can be
conveniently computed by the chain rule:
fint=−∂Ψ
∂F:∂F
∂q=−P:∇J, (17)
wherePis the ﬁrst Piola-Kirchhoff stress. This is a 30n-
dimension dense system as all Q-GMLS kernels have global
inﬂuences. We use Newton’s method to solve this system
iteratively. Each Newton iteration solves a linearized prob-
lem for an incremental improvement ∆q:
/parenleftbigg
M+h2∂fint
∂q/parenrightbigg
∆q=M(qn+h˙qn)+h2J⊤fext,(18)
where∂fint/∂qis the second differentiation of the total po-
tentialUknown as the tangent stiffness matrix. fextis the
external forces applied to the model. It is projected to the
Q-GMLS kinematic space by left multiplying J⊤.
4.6. NeRF rendering using quadratic warping
After the deformed model geometry is computed, we lever-
age the NGP-NeRF that is built for its rest shape to synthe-
size both novel views and novel deformations . Whenever
we query the NGP-NeRF for a deformed location ˜xalong
a ray, we warp this position to its rest conﬁguration x, ide-
ally through x=˜x−u(x). Unfortunately as xis unknownhere, we cannot obtain u(x)directly with Eq. ( 9). Instead,
we approximate u(x)based on the displacements at nearby
(deformed) IPs. The general rationale is that if ˜xis sufﬁ-
ciently close to an IP, we can Taylor expand the IP’s dis-
placement to estimate u(x). As IPs are sparse, it is possible
that˜xis not particularly close to one IP. In this case, we ﬁnd
three nearest IPs and average Taylor expansions at those IPs
based on the inverse distance weight.
For the IP at xk, we have:
˜x−˜xk=u(x)−u(xk)≈ ∇u(xk)(x−xk)
+1
2(∇F(xk)·(x−xk))·(x−xk).(19)
We can then compute xvia solving a nonlinear system of:
A(x)(x−xk) =b, (20)
where
A(x) =∇u(xk)+1
2∇F(xk)·(x−xk),
b=˜x−˜xk.(21)
While the analytic solution of Eq. ( 20) can be derived, we
ﬁnd Newton’s method starting from the guess of x=xk
is effective. The system converges within tens of iterations,
and each iteration only solves a 3 by 3 linear system.
This strategy of quadratic warping fully exploits the prior
ofubeing the quadratic displacement ﬁeld. If we only use
the ﬁrst-order Taylor expansion to estimate the undeformed
position of ˜x, as chosen in most existing NeRF editing sys-
tems [ 59,81], visual artifacts can be observed under large
deformations. Examples of such failure cases are provided
in the supplementary materials.
5. Experiments
We implemented PIE-NeRF pipeline using Python and
C++. The simulation module was based on CUDA . In ad-
dition, we used PyTorch [28] andTaichi [26] to imple-
ment a modiﬁed instant-NGP [ 52] for ray warping (§ 4.6).
Our hardware platform is a desktop computer equipped with
anInteli7-12700F CPU and an NVIDIA3090 GPU.
4455
Figure 5. Interactive NeRF deformation. We developed an intu-
itive UI for users to interact with NeRF scenes like applying exter-
nal forces and position constraints. Q-GMLS kernels can also be
set adaptively to capture local dynamics as highlighted.
Datasets We evaluate PIE-NeRF with several NeRF scenes.
In addition to original NeRF datasets, we utilize BlenderN-
eRF [ 63] to synthesize additional scenes including codi-
mensional objects. We used 100 multi-view images for each
scene as inputs for our NGP-NeRF training.
5.1. Interactive and dynamic NeRF simulation
PIE-NeRF formulates nonlinear dynamics of NeRF mod-
els with the generalized coordinate and Lagrangian equa-
tions (i.e., Eq. ( 1)), which makes the computation inde-
pendent of the PDS sampling resolution. We ﬁnd that a
few dozen Q-GMLS kernels are often sufﬁcient to model
complex models. The corresponding computation is light-
weight and can be processed in real-time on the GPU (see
Fig. 4). Therefore, interactive physics-based manipulation
of the NeRF scene becomes possible. To this end, we also
implemented a user-friendly interface as shown in Fig. 5,
left. With the interface, users can intuitively apply external
forces to the model, and observe the resulting novel motions
interactively. The users have full control over the trade-off
between visual richness and the efﬁciency of the simulation.
For instance, one can create a dedicated kernel to capture lo-
cal dynamics at speciﬁc foliage of the plant (Fig. 5, right).
5.2. Physics­grounded pose synthesis
Being a physics-based framework, PIE-NeRF is able to
model any nonlinear hyperelastic materials to match real-
world observations. This enhances existing NeRF editing
systems, which are mostly based on geometry-based heuris-
tic energy models like ARAP. Fig. 6reports a comparison
using the Neo-Hookean material [ 8] and ARAP to com-
press chocolate jelly with NeRF. The energy density of Neo-
Hookean material is:
Ψ =µ
2(IC−3)−µlogJ+λ
2log2J, (22)
whereµ,λare material parameters (a.k.a Lam ´e coefﬁ-
cients);IC=tr(F⊤F); andJ=det(F). The log barrier
ARAP
Neo-Hookean
Material
V olume percentageARAP
Neo-HookeanFigure 6. Volume preservation test. PIE-NeRF is capable of in-
corporating any real-world material models. In this example, we
apply a position constraint to compress a chocolate jelly. ARAP
energy, widely used in exiting NeRF editing systems [ 87], col-
lapses unnaturally. With Neo-Hookean energy, PIE-NeRF can bet-
ter synthesize this procedure.
Cut here
Figure 7. Topology change and shadows. We edit kernel weights
to cut the sculpture, which then falls on the ﬂoor. We then compute
the depth map from NGP-NeRF and generate the moving shadow
using shadow maps.
logJin Neo-Hookean energy strongly preserves the vol-
ume of the object. This feature is clearly demonstrated in
Fig. 6. As the compression rate increases, ARAP jelly (on
the top) loses nearly 40% of the original volume (visualized
as bar graphs at the bottom in Fig. 6).
Handle topology change. Being meshless makes PIE-
NeRF less sensitive to topology changes. As shown in
Fig. 7, we cut the NeRF sculpture by modifying Q-GMLS
weight functions. Besides that, there is no need for extra
safeguards for dealing with the change of the mesh connec-
tivity and resolution at the cutting area. In this example,
we extract the depth image with NGP-NeRF, from which a
shadow map can be generated for shadow synthesis.
Comparison with ground truth. We employ FEM as the
ground truth for comparison with our method. We gener-
ate multi-view images from the mesh rendered with same
rendering settings to ground truth as the dataset for PIE-
NeRF. Subsequently, dynamic results are produced using
the same boundary conditions, physical parameters, and ex-
ternal forces. Our implementation of FEM involves tetrahe-
dralizing the mesh and applying Newton’s method to solve
the dynamic system on tetrahedral mesh. The comparison
results, as illustrated in Fig. 8, demonstrate that our method
is nearly same to the ground truth. Thanks to the Q-GMLS,
the number of kernels in our approach is signiﬁcantly lower
than the number of vertices in FEM, and the number of IPs
4456
Ground truth OursFigure 8. Comparison with ground truth. We generate ground-
truth results by simulating the tetrahedral mesh with FEM. We can
see that our results are quite similar to the ground truth, despite
minor differences highlighted.
0 15 30 45 60
   NGP+
Quadratic 
 warping  Matrix 
assembly
Nonlinear 
   solveMatrix assembly
Nonlinear solvePure NGP
NGP+Linear warping
NGP+Quadratic warping
Time cost (ms)Major computation task
Figure 9. Time breakdown. There are three major steps for PIE-
NeRF, namely matrix assembly, solve, and warping. Thanks to Q-
GMLS-based reduction, they are all manageable making the sim-
ulation interactive. The percentage of each step is visualized as a
pie diagram on the right.
is also less than the number of tetrahedra in FEM.
Comparison with PAC-NeRF. PAC-NeRF [ 37] is a re-
cent contribution also aiming to combine physical models
with NeRF-based representations. The underlying numeri-
cal solver, on the other hand, is based on the material point
method (MPM) [ 6], a hybrid method that uses both par-
ticles and grids. While MPM excels in handling compli-
cated, multi-phase physics, it does not synergize well with
NeRF-based rendering. Speciﬁcally, under large deforma-
tion, PAC-NeRF fails to map material points back to their
rest-pose positions accurately due to excessive interpolation
smoothing between particles and grid cells, which leads to
over-blurred results at local ﬁne shapes. We show a side-
by-side comparison in Fig. 10.
5.3. Time performance
Fig. 9reports a breakdown of the run time performance of
our PIE-NeRF pipeline for Fig. 5. Three major tasks for
the simulation at the runtime are matrix assembly, nonlin-
ear solve, and quadratic warping. The matrix assembly re-
PIE-NeRF PAC-NeRF
Figure 10. PIE-NeRF vs PAC-NeRF. PAC-NeRF [ 37] is a closely
relevant competitor. A major limitation of PAC-NeRF is the ren-
dering. It is less intuitive to infer the right color/texture informa-
tion under large deformation using MPM. PIE-NeRF overcomes
this limitation with ease. Using implicit time integration, PIE-
NeRF runs much faster than PAC-NeRF (two orders in these ex-
amples).
quires an integral over all the IPs, leading to a dense 30n
by30nsystem. We use Cholesky factorization to solve the
resulting Newton system (Eq. ( 18)). In general, a couple
of iterations will converge the system so that we forward to
the next time step. As shown in the ﬁgure, quadratic warp-
ing used in PIE-NeRF is slightly more expensive than linear
warping. However, these additional expenses yield signiﬁ-
cantly improved visual results in general, as detailed in the
supplementary material.
6. Conclusion
PIE-NeRF /pizza-sliceis a physics-NeRF simulation pipeline. It is
directly based on PDS particles sampled over the NeRF
scene and applies a Q-GMLS model reduction to lower the
computational overhead of the simulation. As a result, PIE-
NeRF faithfully characterizes various real-world material
models. Its meshless representation makes the simulation
ﬂexible, and topology changes can be well accommodated.
The quadratic interpolation scheme is not only helpful in
tackling thin-geometry models but also leads to better im-
age synthesis with NGP-NeRF. We hope PIE-NeRF could
contribute new ingredients to the existing NeRF ecosystem.
Based on PIE-NerF, it is possible to integrate more (bet-
ter and faster) simulation and graphics techniques to deep
3D vision applications to imbue vivid, realistic, real-time
physics into static or dynamic environments. Along this ex-
citing endeavor, we will also explore other opportunities,
such as Gaussian splatting-based techniques [ 33], and ulti-
mately reach what you see is what you simulate, WS2.
Acknowledgement
We thank anonymous reviewers for their insightful com-
ments. We acknowledge support from NSF (2301040,
2008915, 2244651, 2008564, 2153851, 2023780), NSF-
China (62322209), UC-MRPI, Sony, Amazon, and TRI.
4457
References
[1] Carla Antoci, Mario Gallati, and Stefano Sibilla. Numerical
simulation of ﬂuid–structure interaction by sph. Computers
& structures , 85(11-14):879–890, 2007. 2
[2] Franz Aurenhammer. V oronoi diagrams—a survey of a fun-
damental geometric data structure. ACM Computing Surveys
(CSUR) , 23(3):345–405, 1991. 4
[3] Chong Bao, Yinda Zhang, Bangbang Yang, Tianxing Fan,
Zesong Yang, Hujun Bao, Guofeng Zhang, and Zhaopeng
Cui. Sine: Semantic-driven image-based nerf editing with
prior-guided editing ﬁeld. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 20919–20929, 2023. 2
[4] D BARAFF. Large steps in cloth simulation. In SIG-
GRAPH’98 Proceedings , pages 43–54, 1998. 2
[5] Jernej Barbi ˇc and Doug L James. Real-time subspace in-
tegration for st. venant-kirchhoff deformable models. ACM
transactions on graphics (TOG) , 24(3):982–990, 2005. 2
[6] S. Bardenhagen and Edward Kober. The generalized interpo-
lation material point method. CMES - Computer Modeling
in Engineering and Sciences , 5, 06 2004. 8
[7] Ted Belytschko, Yury Krongauz, Daniel Organ, Mark Flem-
ing, and Petr Krysl. Meshless methods: an overview and re-
cent developments. Computer methods in applied mechanics
and engineering , 139(1-4):3–47, 1996. 2
[8] Javier Bonet and Richard D Wood. Nonlinear continuum
mechanics for ﬁnite element analysis . Cambridge university
press, 1997. 7
[9] Robert Bridson. Fast poisson disk sampling in arbitrary di-
mensions. In ACM SIGGRAPH 2007 Sketches , SIGGRAPH
’07, page 22–es, New York, NY , USA, 2007. Association for
Computing Machinery. 3
[10] Morten Bro-Nielsen and Stephane Cotin. Real-time volu-
metric deformable models for surgery simulation using ﬁnite
elements and condensation. In Computer graphics forum ,
volume 15, pages 57–66. Wiley Online Library, 1996. 2
[11] Ang Cao and Justin Johnson. Hexplane: A fast representa-
tion for dynamic scenes. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 130–141, 2023. 2
[12] Jun-Kun Chen, Jipeng Lyu, and Yu-Xiong Wang. Neuraled-
itor: Editing neural radiance ﬁelds via manipulating point
clouds. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pages 12439–
12448, 2023. 2
[13] Jiahua Dong and Yu-Xiong Wang. Vica-nerf: View-
consistency-aware 3d editing of neural radiance ﬁelds. In
Thirty-seventh Conference on Neural Information Process-
ing Systems , 2023. 2
[14] Qiang Du, Maria Emelianenko, and Lili Ju. Convergence of
the lloyd algorithm for computing centroidal voronoi tessel-
lations. SIAM journal on numerical analysis , 44(1):102–119,
2006. 5
[15] Yilun Du, Yinan Zhang, Hong-Xing Yu, Joshua B Tenen-
baum, and Jiajun Wu. Neural radiance ﬂow for 4d view
synthesis and video processing. In 2021 IEEE/CVF In-
ternational Conference on Computer Vision (ICCV) , pages
14304–14314. IEEE Computer Society, 2021. 2
[16] Thomas-Peter Fries, Hermann G Matthies, et al. Classiﬁ-cation and overview of meshfree methods. Department of
Mathematics and Computer Science, Technical University of
Braunschweig , 2003. 2
[17] Chen Gao, Ayush Saraf, Johannes Kopf, and Jia-Bin Huang.
Dynamic view synthesis from dynamic monocular video. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 5712–5721, 2021. 2
[18] Stephan J Garbin, Marek Kowalski, Virginia Estellers,
Stanislaw Szymanowicz, Shideh Rezaeifar, Jingjing Shen,
Matthew Johnson, and Julien Valentin. V oltemorph: Real-
time, controllable and generalisable animation of volumetric
representations. arXiv preprint arXiv:2208.00949 , 2022. 2
[19] Stephan J Garbin, Marek Kowalski, Matthew Johnson, Jamie
Shotton, and Julien Valentin. Fastnerf: High-ﬁdelity neural
rendering at 200fps. In Proceedings of the IEEE/CVF In-
ternational Conference on Computer Vision , pages 14346–
14355, 2021. 1
[20] Thomas Gerstner and Michael Griebel. Numerical integra-
tion using sparse grids. Numerical algorithms , 18(3-4):209–
232, 1998. 5
[21] Bingchen Gong, Yuehao Wang, Xiaoguang Han, and Qi
Dou. Recolornerf: Layer decomposed radiance ﬁeld
for efﬁcient color editing of 3d scenes. arXiv preprint
arXiv:2301.07958 , 2023. 2
[22] Xiang Guo, Guanying Chen, Yuchao Dai, Xiaoqing Ye, Ji-
adai Sun, Xiao Tan, and Errui Ding. Neural deformable voxel
grid for fast optimization of dynamic view synthesis. In Pro-
ceedings of the Asian Conference on Computer Vision , pages
3757–3775, 2022. 1,3
[23] Xiang Guo, Jiadai Sun, Yuchao Dai, Guanying Chen, Xiao-
qing Ye, Xiao Tan, Errui Ding, Yumeng Zhang, and Jingdong
Wang. Forward ﬂow for novel view synthesis of dynamic
scenes. In Proceedings of the IEEE/CVF International Con-
ference on Computer Vision , pages 16022–16033, 2023. 2
[24] Ayaan Haque, Matthew Tancik, Alexei A Efros, Alek-
sander Holynski, and Angjoo Kanazawa. Instruct-nerf2nerf:
Editing 3d scenes with instructions. arXiv preprint
arXiv:2303.12789 , 2023. 2
[25] Florian Hofherr, Lukas Koestler, Florian Bernard, and Daniel
Cremers. Neural implicit representations for physical param-
eter inference from a single video. In Proceedings of the
IEEE/CVF Winter Conference on Applications of Computer
Vision , pages 2093–2103, 2023. 2
[26] Yuanming Hu, Tzu-Mao Li, Luke Anderson, Jonathan
Ragan-Kelley, and Fr ´edo Durand. Taichi: a language
for high-performance computation on spatially sparse data
structures. ACM Transactions on Graphics (TOG) , 38(6):1–
16, 2019. 6
[27] Sungwon Hwang, Junha Hyung, Daejin Kim, Min-Jung
Kim, and Jaegul Choo. Faceclipnerf: Text-driven 3d face
manipulation using deformable neural radiance ﬁelds. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 3469–3479, 2023. 2
[28] Sagar Imambi, Kolla Bhanu Prakash, and GR Kanagachi-
dambaresan. Pytorch. Programming with TensorFlow: Solu-
tion for Edge Computing Applications , pages 87–104, 2021.
6
[29] Ajay Jain, Matthew Tancik, and Pieter Abbeel. Putting nerf
on a diet: Semantically consistent few-shot view synthesis.
4458
InProceedings of the IEEE/CVF International Conference
on Computer Vision , pages 5885–5894, 2021. 1
[30] Cl ´ement Jambon, Bernhard Kerbl, Georgios Kopanas,
Stavros Diolatzis, George Drettakis, and Thomas
Leimk ¨uhler. Nerfshop: Interactive editing of neural
radiance ﬁelds. Proceedings of the ACM on Computer
Graphics and Interactive Techniques , 6(1), 2023. 2
[31] Kaiwen Jiang, Shu-Yu Chen, Feng-Lin Liu, Hongbo Fu, and
Lin Gao. Nerffaceediting: Disentangled face editing in neu-
ral radiance ﬁelds. In SIGGRAPH Asia 2022 Conference Pa-
pers, pages 1–9, 2022. 2
[32] Kacper Kania, Kwang Moo Yi, Marek Kowalski, Tomasz
Trzci ´nski, and Andrea Tagliasacchi. Conerf: Controllable
neural radiance ﬁelds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
18623–18632, 2022. 2
[33] Bernhard Kerbl, Georgios Kopanas, Thomas Leimk ¨uhler,
and George Drettakis. 3d gaussian splatting for real-time
radiance ﬁeld rendering. ACM Transactions on Graphics
(ToG) , 42(4):1–14, 2023. 8
[34] Theodore Kim and David Eberle. Dynamic deformables: im-
plementation and production practicalities (now with code!).
InACM SIGGRAPH 2022 Courses , pages 1–259. 2022. 2
[35] Sosuke Kobayashi, Eiichi Matsumoto, and Vincent Sitz-
mann. Decomposing nerf for editing via feature ﬁeld distil-
lation. Advances in Neural Information Processing Systems ,
35:23311–23330, 2022. 2
[36] Verica Lazova, Vladimir Guzov, Kyle Olszewski, Sergey
Tulyakov, and Gerard Pons-Moll. Control-nerf: Editable
feature volumes for scene rendering and manipulation. In
Proceedings of the IEEE/CVF Winter Conference on Appli-
cations of Computer Vision , pages 4340–4350, 2023. 2
[37] Xuan Li, Yi-Ling Qiao, Peter Yichen Chen, Krishna Murthy
Jatavallabhula, Ming Lin, Chenfanfu Jiang, and Chuang
Gan. Pac-nerf: Physics augmented continuum neural ra-
diance ﬁelds for geometry-agnostic system identiﬁcation.
arXiv preprint arXiv:2303.05512 , 2023. 8
[38] Zhengqi Li, Simon Niklaus, Noah Snavely, and Oliver Wang.
Neural scene ﬂow ﬁelds for space-time view synthesis of dy-
namic scenes. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 6498–
6508, 2021. 2
[39] Gui-Rong Liu and D Karamanlidis. Mesh free methods:
moving beyond the ﬁnite element method. Appl. Mech. Rev. ,
56(2):B17–B18, 2003. 2
[40] Jia-Wei Liu, Yan-Pei Cao, Weijia Mao, Wenqiao Zhang,
David Junhao Zhang, Jussi Keppo, Ying Shan, Xiaohu Qie,
and Mike Zheng Shou. Devrf: Fast deformable voxel radi-
ance ﬁelds for dynamic scenes. Advances in Neural Infor-
mation Processing Systems , 35:36762–36775, 2022. 2
[41] Lingjie Liu, Jiatao Gu, Kyaw Zaw Lin, Tat-Seng Chua, and
Christian Theobalt. Neural sparse voxel ﬁelds. Advances
in Neural Information Processing Systems , 33:15651–15663,
2020. 1
[42] Ruiyang Liu, Jinxu Xiang, Bowen Zhao, Ran Zhang, Jingyi
Yu, and Changxi Zheng. Neural impostor: Editing neu-
ral radiance ﬁelds with explicit shape manipulation. arXiv
preprint arXiv:2310.05391 , 2023. 2
[43] Steven Liu, Xiuming Zhang, Zhoutong Zhang, RichardZhang, Jun-Yan Zhu, and Bryan Russell. Editing condi-
tional radiance ﬁelds. In Proceedings of the IEEE/CVF inter-
national conference on computer vision , pages 5773–5783,
2021. 2
[44] Sebastian Martin, Peter Kaufmann, Mario Botsch, Eitan
Grinspun, and Markus Gross. Uniﬁed simulation of elas-
tic rods, shells, and solids. ACM Transactions on Graphics
(TOG) , 29(4):1–10, 2010. 2
[45] Aryan Mikaeili, Or Perel, Mehdi Safaee, Daniel Cohen-Or,
and Ali Mahdavi-Amiri. Sked: Sketch-guided text-based 3d
editing. In Proceedings of the IEEE/CVF International Con-
ference on Computer Vision , pages 14607–14619, 2023. 2
[46] Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,
Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. NeRF:
Representing scenes as neural radiance ﬁelds for view syn-
thesis. In The European Conference on Computer Vision
(ECCV) , 2020. 1,3
[47] Matthias M ¨uller and Nuttapong Chentanez. Solid simulation
with oriented particles. In ACM SIGGRAPH 2011 papers ,
pages 1–10. 2011. 2
[48] Matthias M ¨uller and Markus H Gross. Interactive virtual ma-
terials. In Graphics interface , volume 2004, pages 239–246,
2004. 2
[49] Matthias M ¨uller, Bruno Heidelberger, Marcus Hennix, and
John Ratcliff. Position based dynamics. Journal of Visual
Communication and Image Representation , 18(2):109–118,
2007. 2
[50] Matthias M ¨uller, Bruno Heidelberger, Matthias Teschner,
and Markus Gross. Meshless deformations based on shape
matching. ACM transactions on graphics (TOG) , 24(3):471–
478, 2005. 2
[51] Matthias M ¨uller, Richard Keiser, Andrew Nealen, Mark
Pauly, Markus Gross, and Marc Alexa. Point based anima-
tion of elastic, plastic and melting objects. In Proceedings
of the 2004 ACM SIGGRAPH/Eurographics symposium on
Computer animation , pages 141–151, 2004. 2
[52] Thomas M ¨uller, Alex Evans, Christoph Schied, and Alexan-
der Keller. Instant neural graphics primitives with a multires-
olution hash encoding. ACM Trans. Graph. , 41(4), jul 2022.
2,3,6
[53] Richard M Murray. Nonlinear control of mechanical sys-
tems: A lagrangian perspective. Annual Reviews in Control ,
21:31–42, 1997. 3
[54] Andrew Nealen, Matthias M ¨uller, Richard Keiser, Eddy
Boxerman, and Mark Carlson. Physically based deformable
models in computer graphics. In Computer graphics forum ,
volume 25, pages 809–836. Wiley Online Library, 2006. 2
[55] Keunhong Park, Utkarsh Sinha, Jonathan T Barron, Soﬁen
Bouaziz, Dan B Goldman, Steven M Seitz, and Ricardo
Martin-Brualla. Nerﬁes: Deformable neural radiance ﬁelds.
InProceedings of the IEEE/CVF International Conference
on Computer Vision , pages 5865–5874, 2021. 2
[56] Keunhong Park, Utkarsh Sinha, Peter Hedman, Jonathan T
Barron, Soﬁen Bouaziz, Dan B Goldman, Ricardo Martin-
Brualla, and Steven M Seitz. Hypernerf: A higher-
dimensional representation for topologically varying neural
radiance ﬁelds. arXiv preprint arXiv:2106.13228 , 2021. 2
[57] Adam Paszke, Sam Gross, Soumith Chintala, Gregory
Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Al-
4459
ban Desmaison, Luca Antiga, and Adam Lerer. Automatic
differentiation in pytorch. 2017. 3
[58] Mark Pauly, Richard Keiser, Leif P Kobbelt, and Markus
Gross. Shape modeling with point-sampled geometry. ACM
Transactions on Graphics (TOG) , 22(3):641–650, 2003. 2
[59] Yicong Peng, Yichao Yan, Shengqi Liu, Yuhao Cheng,
Shanyan Guan, Bowen Pan, Guangtao Zhai, and Xiaokang
Yang. Cagenerf: Cage-based neural radiance ﬁeld for gen-
eralized 3d deformation and animation. Advances in Neural
Information Processing Systems , 35:31402–31415, 2022. 1,
2,3,6
[60] Sergey Prokudin, Qianli Ma, Maxime Raafat, Julien
Valentin, and Siyu Tang. Dynamic point ﬁelds. arXiv
preprint arXiv:2304.02626 , 2023. 2
[61] Albert Pumarola, Enric Corona, Gerard Pons-Moll, and
Francesc Moreno-Noguer. D-nerf: Neural radiance ﬁelds
for dynamic scenes. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
10318–10327, 2021. 2
[62] Yi-Ling Qiao, Alexander Gao, and Ming C. Lin. Neu-
physics: Editable neural geometry and physics from monoc-
ular videos. In Conference on Neural Information Process-
ing Systems (NeurIPS) , 2022. 2
[63] Maxime Raafat. BlenderNeRF, May 2023. 7
[64] Viktor Rudnev, Mohamed Elgharib, William Smith, Lingjie
Liu, Vladislav Golyanik, and Christian Theobalt. Nerf for
outdoor scene relighting. In European Conference on Com-
puter Vision , pages 615–631. Springer, 2022. 2
[65] Eftychios Sifakis and Jernej Barbic. Fem simulation of
3d deformable solids: a practitioner’s guide to theory, dis-
cretization and model reduction. In Acm siggraph 2012
courses , pages 1–50. 2012. 2
[66] Hyeonseop Song, Seokhun Choi, Hoseok Do, Chul Lee,
and Taehyeong Kim. Blending-nerf: Text-driven localized
editing in neural radiance ﬁelds. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 14383–14393, 2023. 2
[67] Olga Sorkine and Marc Alexa. As-rigid-as-possible surface
modeling. In Symposium on Geometry processing , volume 4,
pages 109–116. Citeseer, 2007. 2
[68] Pratul P Srinivasan, Boyang Deng, Xiuming Zhang,
Matthew Tancik, Ben Mildenhall, and Jonathan T Barron.
Nerv: Neural reﬂectance and visibility ﬁelds for relighting
and view synthesis. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
7495–7504, 2021. 2
[69] Denis Steinemann, Miguel A Otaduy, and Markus Gross.
Fast adaptive shape matching deformations. In Proceedings
of the 2008 ACM SIGGRAPH/eurographics symposium on
computer animation , pages 87–94, 2008. 2
[70] Jingxiang Sun, Xuan Wang, Yong Zhang, Xiaoyu Li, Qi
Zhang, Yebin Liu, and Jue Wang. Fenerf: Face editing in
neural radiance ﬁelds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
7672–7682, 2022. 2
[71] Demetri Terzopoulos, John Platt, Alan Barr, and Kurt Fleis-
cher. Elastically deformable models. In Proceedings of the
14th annual conference on Computer graphics and interac-
tive techniques , pages 205–214, 1987. 2[72] Edgar Tretschk, Ayush Tewari, Vladislav Golyanik, Michael
Zollh ¨ofer, Christoph Lassner, and Christian Theobalt. Non-
rigid neural radiance ﬁelds: Reconstruction and novel view
synthesis of a dynamic scene from monocular video. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 12959–12970, 2021. 2
[73] Can Wang, Menglei Chai, Mingming He, Dongdong Chen,
and Jing Liao. Clip-nerf: Text-and-image driven manip-
ulation of neural radiance ﬁelds. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 3835–3844, 2022. 2
[74] Huamin Wang and Yin Yang. Descent methods for elastic
body simulation on the gpu. ACM Transactions on Graphics
(TOG) , 35(6):1–10, 2016. 2
[75] Xiangyu Wang, Jingsen Zhu, Qi Ye, Yuchi Huo, Yunlong
Ran, Zhihua Zhong, and Jiming Chen. Seal-3d: Interactive
pixel-level editing for neural radiance ﬁelds. In Proceedings
of the IEEE/CVF International Conference on Computer Vi-
sion, pages 17683–17693, 2023. 2
[76] Silvan Weder, Guillermo Garcia-Hernando, Aron Monsz-
part, Marc Pollefeys, Gabriel J Brostow, Michael Firman,
and Sara Vicente. Removing objects from neural radiance
ﬁelds. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition , pages 16528–16538,
2023. 2
[77] Chung-Yi Weng, Brian Curless, Pratul P Srinivasan,
Jonathan T Barron, and Ira Kemelmacher-Shlizerman. Hu-
mannerf: Free-viewpoint rendering of moving people from
monocular video. In Proceedings of the IEEE/CVF con-
ference on computer vision and pattern Recognition , pages
16210–16220, 2022. 2
[78] Qiling Wu, Jianchao Tan, and Kun Xu. Palettenerf:
Palette-based color editing for nerfs. arXiv preprint
arXiv:2212.12871 , 2022. 2
[79] Wenqi Xian, Jia-Bin Huang, Johannes Kopf, and Changil
Kim. Space-time neural irradiance ﬁelds for free-viewpoint
video. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition , pages 9421–9431,
2021. 2
[80] Qiangeng Xu, Zexiang Xu, Julien Philip, Sai Bi, Zhixin
Shu, Kalyan Sunkavalli, and Ulrich Neumann. Point-nerf:
Point-based neural radiance ﬁelds. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 5438–5448, 2022. 2
[81] Tianhan Xu and Tatsuya Harada. Deforming radiance ﬁelds
with cages. In European Conference on Computer Vision ,
pages 159–175. Springer, 2022. 1,2,3,6
[82] Bangbang Yang, Chong Bao, Junyi Zeng, Hujun Bao, Yinda
Zhang, Zhaopeng Cui, and Guofeng Zhang. Neumesh:
Learning disentangled neural mesh-based implicit ﬁeld for
geometry and texture editing. In European Conference on
Computer Vision , pages 597–614. Springer, 2022. 2
[83] Bangbang Yang, Yinda Zhang, Yinghao Xu, Yijin Li, Han
Zhou, Hujun Bao, Guofeng Zhang, and Zhaopeng Cui.
Learning object-compositional neural radiance ﬁeld for ed-
itable scene rendering. In Proceedings of the IEEE/CVF In-
ternational Conference on Computer Vision , pages 13779–
13788, 2021. 2
[84] Weicai Ye, Shuo Chen, Chong Bao, Hujun Bao, Marc Polle-
4460
feys, Zhaopeng Cui, and Guofeng Zhang. Intrinsicnerf:
Learning intrinsic neural radiance ﬁelds for editable novel
view synthesis. In Proceedings of the IEEE/CVF Inter-
national Conference on Computer Vision , pages 339–351,
2023. 2
[85] Alex Yu, Ruilong Li, Matthew Tancik, Hao Li, Ren Ng,
and Angjoo Kanazawa. Plenoctrees for real-time rendering
of neural radiance ﬁelds. In Proceedings of the IEEE/CVF
International Conference on Computer Vision , pages 5752–
5761, 2021. 1
[86] Yu-Jie Yuan, Yu-Kun Lai, Yi-Hua Huang, Leif Kobbelt, and
Lin Gao. Neural radiance ﬁelds from sparse rgb-d images for
high-quality view synthesis. IEEE Transactions on Pattern
Analysis and Machine Intelligence , 2022. 1,2
[87] Yu-Jie Yuan, Yang-Tian Sun, Yu-Kun Lai, Yuewen Ma,
Rongfei Jia, and Lin Gao. Nerf-editing: geometry editing of
neural radiance ﬁelds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
18353–18364, 2022. 1,2,7
[88] Yu-Jie Yuan, Yang-Tian Sun, Yu-Kun Lai, Yuewen Ma,
Rongfei Jia, Leif Kobbelt, and Lin Gao. Interactive nerf
geometry editing with shape priors. IEEE Transactions on
Pattern Analysis and Machine Intelligence , 2023. 2,3
[89] Jingbo Zhang, Xiaoyu Li, Ziyu Wan, Can Wang, and Jing
Liao. Fdnerf: Few-shot dynamic neural radiance ﬁelds for
face reconstruction and expression editing. In SIGGRAPH
Asia 2022 Conference Papers , pages 1–9, 2022. 2
[90] Jiakai Zhang, Xinhang Liu, Xinyi Ye, Fuqiang Zhao, Yan-
shun Zhang, Minye Wu, Yingliang Zhang, Lan Xu, and
Jingyi Yu. Editable free-viewpoint video using a layered neu-
ral representation. ACM Transactions on Graphics (TOG) ,
40(4):1–18, 2021. 2
[91] Chengwei Zheng, Wenbin Lin, and Feng Xu. Editablenerf:
Editing topologically varying neural radiance ﬁelds by key
points. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pages 8317–
8327, 2023. 2
[92] Olek C Zienkiewicz, Robert L Taylor, and Jian Z Zhu. The
ﬁnite element method: its basis and fundamentals . Elsevier,
2005. 2
4461
