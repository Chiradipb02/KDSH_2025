Finsler-Laplace-Beltrami Operators with Application to Shape Analysis
Simon Weber1,2*
sim.weber@tum.deThomas Dag `es3*
thomas.dages@cs.technion.ac.ilMaolin Gao1,2
maolin.gao@tum.deDaniel Cremers1,2
cremers@tum.de
Heuristic ALBOΔαθf
Finsler-based LBO (Ours)ΔFLBOfω=0ΔDf=−divX(D∇Xf)Heat equationvℛx(v)=v⊤M(x)vxRiemann metric
ℱx(v)=v⊤M(x)v+ω⊤(x)vvxω(x)Finsler metric
Dαθ(optional: further skew  )Heat equationDℱ*x=M*−ω*ω*⊤SkewΔXf=−divX(∇Xf)Laplace-Beltrami operator
Simpliﬁed special caseLaplace-Finsler operatorΔFf=−divX(ℱ*x(∇Xf)∇ℱ*x(∇Xf))DαθAnisotropic diﬀusivity (heuristic)
Anisotropic diﬀusivity (Finsler-based)if
Figure 1. Simplified overview of the derivation of the Finsler-Laplace-Beltrami operator (FLBO), built from a Finsler metric. It generalizes
the traditional heuristic anisotropic Laplace-Beltrami operators (ALBO) [6, 29] (top). The FLBO can directly replace the ALBOs in surface
processing tasks like shape correspondence, notably by constructing shape-dependent anisotropic convolutions in their spectral domain.
Abstract
The Laplace-Beltrami operator (LBO) emerges from
studying manifolds equipped with a Riemannian metric. It
is often called the swiss army knife of geometry process-
ingas it allows to capture intrinsic shape information and
gives rise to heat diffusion, geodesic distances, and a mul-
titude of shape descriptors. It also plays a central role in
geometric deep learning. In this work, we explore Finsler
manifolds as a generalization of Riemannian manifolds. We
revisit the Finsler heat equation and derive a Finsler heat
kernel and a Finsler-Laplace-Beltrami Operator (FLBO):
a novel theoretically justified anisotropic Laplace-Beltrami
operator (ALBO). In experimental evaluations we demon-
strate that the proposed FLBO is a valuable alternative to
the traditional Riemannian-based LBO and ALBOs for spa-
tial filtering and shape correspondence estimation. We hope
that the proposed Finsler heat kernel and the FLBO will
* equal contribution.
1Technical University of Munich
2Munich Center for Machine Learning
3Technion - Israel Institute of Technologyinspire further exploration of Finsler geometry in the com-
puter vision community.
1. Introduction
1.1. Finsler versus Riemann
In his PhD thesis of 1918, Paul Finsler introduced
the notion of a differentiable manifold equipped with a
Minkowski norm on each tangent space [22]. It constitutes
a generalization of Riemannian manifolds [39] that Elie
Cartan later referred to as Finsler manifolds [12]. While
Riemannian manifolds are omni-present in computer vision
and machine learning, Finsler manifolds have remained
largely unexplored.
Essentially, a Finsler metric is the same as a Riemannian
one without the quadratic assumption. The consequence is
that the metric not only depends on the location, but also
on the tangential direction of motion. This implies that the
length of a curve between two points AandBmay change
whether we are traversing it from AtoBor the other way
round, thus geodesic curves from AtoBmay differ from
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
3131
those from BtoA. This means that on a Finsler manifold,
AB
Figure 2. Due to non-uniform wind currents, the geodesic curve
fromAtoBdiffers from the one from BtoA. While not possible
in Riemannian geometry, such asymmetries are characteristic of
Finsler manifolds.
there is a built-in asymmetric anisotropy, which contrasts
with the symmetric Riemannian case. In the Riemannian
world, moving from an isotropic to a non isotropic metric
allows more flexibility to capture interesting features on the
manifolds. For instance, on a human hand shape, we may
want a point on a finger to be close in some sense to all the
points along the ring of the finger more than those along the
length of the finger. Shifting from a Riemannian world to a
Finsler world allows to increase the flexibility of anisotropy
by also allowing non-symmetric distances. For many phys-
ical systems the Finsler metric is actually the natural choice
of distance. For instance, a boat on a river or a plane in
the wind might find that a path along the maximum current
provides the shortest travel time whereas the return voyage
might require moving away from the maximum current –
see Fig. 2.
1.2. Contribution
The aim of this paper is to explore Finsler mani-
folds, study the Finsler heat diffusion, introduce a Finsler-
Laplace-Beltrami Operator (FLBO), and demonstrate its
applicability to shape analysis and geometric deep learning
via the shape matching problem. In particular:
• We present a theoretical exploration of Finsler manifolds
in a concise and self-contained form that is accessible to
the computer vision and machine learning community.
• We revisit the heat diffusion on Finsler manifolds and de-
rive a tractable equation.
• We generalize the traditional (anisotropic) Laplace-
Beltrami operator to a Finsler-Laplace-Beltrami operator
(FLBO).
• By leveraging the relationship between the diffusivity co-
efficient and the Riemannian metric, we propose an easy-
to-implement discretization of the FLBO.
• We perform extensive evaluation of the proposed ap-
proach for shape correspondence based on the FLBO. Wehighlight the benefits of this new operator in terms of ac-
curacy on both full and partial shape datasets.
• We release our code as open source to facilitate further
research: https://github.com/tum-vision/
flbo .
2. Related work
The research domains most relevant to our work are ge-
ometric deep learning for shape correspondence and the use
of the Finsler metric in computer vision.
Geometric deep learning for shape correspondence
Finding correspondences between shapes is a funda-
mental task in computer vision and a key component of
many geometry processing applications, such as object
recognition, shape reconstruction, texture transfer, or shape
morphing. Initially solved with handcrafted approaches
[16, 38, 44], the shape correspondence problem has recently
benefited from the success of neural networks [23, 25, 27,
28, 42, 43] to learn features achieving tremendous results.
Initially seen in the Euclidean space, shapes are nowa-
days mostly considered as embedded manifolds. Intrinsic
information, such as geodesic distances, are products of
the heat diffusion paradigm, which has mostly been stud-
ied on manifolds equipped with a Riemannian metric. For
such manifolds, heat diffusion is governed by the Poisson
equation, and thus naturally the Laplace-Beltrami opera-
tor (LBO) plays a central role [10]. The LBO is tradi-
tionally isotropic on the manifold, but recent approaches
have heuristically injected anisotropy into it, producing
anisotropic LBOs (ALBO) [1]. Coupled with spatial filter-
ing [29] ALBOs have shown impressive accuracy in shape
correspondence.
We here focus on methods centred around anisotropic
ALBOs. Nevertheless, many other types of approaches ex-
ist for full and partial shape correspondence. In particular,
we point out the vast literature based on the functional map
framework [3, 8, 9, 11, 20, 24, 30, 35, 36, 41].
In [31], the well-known heat kernel signature and wave
kernel signature are generalized by leveraging the spectral
properties of deformable shapes and learning task-specific
spectral filters. This work is extended in [7] to direction-
sensitive feature descriptors by using the eigendecompo-
sition of anisotropic Laplace-Beltrami Operators (ALBO)
[1]. Complementary to such spectral approaches, a line of
works builds on spatial filtering methods. The idea is to
construct patch operators directly on manifolds or graphs
in the spatial domain. In [33], a convolution operator acting
on vector fields without constraints on the filters themselves
is defined. In [6], a local intrinsic representation of a func-
tion defined on a manifold is extracted with anisotropic heat
kernels as spatial weighting functions. This idea is extended
3132
in [29] by introducing an anisotropic convolution operator
in the spectral domain. In this work, the eigendecompo-
sition of multiple ALBOs proposed in [1] is filtered via
Chebychev polynomials with learnable coefficients. This
method achieves impressive results for shape correspon-
dence in terms of accuracy.
Finsler computer vision
Computer vision on Finsler manifolds, a natural gener-
alization of Riemannian manifolds, is a largely uncharted
research area. In [37], robotics applications are pushed be-
yond Riemannian geometry and the Euler-Lagrange equa-
tion is reviewed from a Finsler point of view. A few works
in image segmentation use a Finsler metric, either to add the
orientation of an image as an extra spatial dimension [14],
or to reformulate geodesic evolutions for region-based ac-
tive contours [13, 15]. The heat equation on Finsler man-
ifolds has been defined in mathematics [34]. In [46], a
geodesic distance based on Finsler metrics is applied to
contour detection. Nevertheless the chosen heat equation
is theoretically unmotivated and is solely addressed from a
heuristic point of view.
3. Background
We traditionally model a 3D shape as a two-dimensional
compact Riemannian manifold (X, M ), with Xa smooth
manifold equipped with an inner product ⟨u, v⟩M=
u⊤M(x)vfor vectors u, v on the tangent space TxXat
each point x∈X. We alternatively model the shape as
a Finsler manifold (X,Fx)equipped with a Randers metric
Fx:TxX→Rat point x. This manifold can be viewed
as a generalization of the Riemannian model, as the metric
does not necessarily induce an inner product. We point out
that we recover a Riemannian manifold if Fxis symmetric.
In this section we briefly introduce the Riemannian heat dif-
fusion, the Randers metric and the Finsler heat diffusion.
3.1. Riemannian heat diffusion
Laplace-Beltrami operator. The Laplace-Beltrami Op-
erator (LBO) on the Riemannian shape Xis defined as:
∆Xf(x) =−divX(∇Xf(x)), (1)
with∇XfanddivXfbeing the intrinsic gradient and di-
vergence of f(x)∈L2(X). The LBO is a positive semi-
definite operator with a real eigen-decomposition (λk, ϕk):
∆Xϕk(x) =λkϕk(x), (2)
with countable eigenvalues 0 =λ0≤λ1≤. . .growing
to infinity. The corresponding eigenfunctions ϕ0, ϕ1. . .are
orthonormal for the standard inner product on L2(X):
⟨ϕi, ϕj⟩=δij, (3)and form an orthonormal basis for L2(X). It follows that
any function f∈L2(x)can be expressed as:
f(x) =X
k≥0⟨ϕk, f⟩ϕk(x) =X
k≥0ˆf(λk)ϕk(x),(4)
andˆf(λk) =⟨ϕk, f⟩are the coefficients of the manifold
Fourier transform of f. The Convolution Theorem on man-
ifolds is given by:
(f∗g)(x) =X
k≥0ˆf(λk)ˆg(λk)ϕk(x), (5)
where f∗gis the convolution of signal fwith filter kernel
gandˆf(λk)ˆg(λk)is the spectral filtering of fbyg.
Heat diffusion. The LBO governs the diffusion equation:
∂f(x, t)
∂t=−∆Xf(x, t), (6)
where f(x, t)is the temperature at point xat time t. Given
some initial heat distribution f0(x) =f(x,0)the solution
of Eq. (6) at time tis given by the convolution:
f(x, t) =Z
Xf0(ξ)ht(x, ξ)dξ, (7)
with the heat kernel ht(x, ξ). In the spectral domain it is
expressed as:
ht(x, ξ) =X
k≥0e−tλkϕk(x)ϕk(ξ). (8)
Anistropic LBO. Extending the traditional LBO pre-
sented above, an anistropic LBO (ALBO) is created by
changing the diffusion speed along chosen directions on the
surface, typically the principal directions of curvature [1]:
∆αf(x) =−divX(Dα(x)∇Xf(x)), (9)
where Dα(x)is a thermal conductivity tensor acting on the
intrinsic gradient direction in the tangent plane and αis a
scalar expressing the level of anisotropy. The ALBO can be
extended to multiple anisotropic angles θ[6]:
∆αθf(x) =−divX(Dαθ(x)∇Xf(x)), (10)
by defining the thermal conductivity tensor:
Dαθ(x) =RθDα(x)R⊤
θ, (11)
where Rθis a rotation in the tangent plane (around surface
normals) with angle θ.
3133
Anistropic convolution operator Similarly, Eq. (5) is ex-
tended by introducing the anisotropic convolution operator
[29]:
(f∗g)αθ(x) =Z
y∈Xf(y)gαθ,x(y)dy, (12)
where gαθ,x(y)is an oriented kernel function centered at
point xfrom the spectral domain
gαθ,x(y) =X
k≥0ˆg(λαθ,k)ϕαθ,k(x)ϕαθ,k(y). (13)
A straightforward derivation shows that:
(f∗g)αθ(x) =X
k≥0ˆg(λαθ,k)ˆf(λαθ,k)ϕαθ,k(x),(14)
where ˆf(λαθ,k) =⟨ϕαθ,k, f⟩are the coefficients of the
anisotropic Fourier transform of f. To extract features
along all directions, the anisotropic convolution operators
are summed and then:
(f∗g)α(x) =Z2π
0(f∗g)αθ(x)dθ. (15)
The design of ˆg(λ)is crucial when defining the anisotropic
convolution operators. Following [18], Chebychev polyno-
mials are adopted to define polynomial filters ˆg(λ)in [29].
3.2. Randers metric
Riemannian manifolds are equipped with a quadratic
metric Rx(v) =∥v∥M(x)that naturally induces a positive-
definite inner product on the tangent space TxMat each
point x. Finsler geometry is often said to be the same as
Riemannian geometry without the quadratic constraint. A
Finsler metric thus no longer induces an inner-product and
is not required to be symmetric. Formally, a Finsler metric
is given by the following properties.
Definition 1 (Finsler metric) .A Finsler metric Fx:
TxX→R+at point xis a smooth metric satisfying the
triangle inequality, positive homogeneity, and positive defi-
niteness axioms:

Fx(v+v′)≤ F x(v) +Fx(v′),∀v, v′∈TxX (16)
Fx(γv) =γFx(v), ∀(γ, v)∈R+×TxX(17)
Fx(v) = 0 ⇐⇒ v= 0. (18)
We consider Randers metrics, one of the simplest type of
Finsler metrics generalizing the Riemannian one.
Definition 2 (Randers metric) .LetM:X→S++
dbe a
tensor field of symmetric positive definite matrices and a
vector field ω:X→Rdsuch that ∥ω(x)∥M(x)−1<1
for all x∈X. The Randers metric associated to (M, ω)is
given by
Fx(v) =∥v∥M(x)+⟨ω(x), v⟩,∀x∈X, v∈TxX.(19)The Randers metric Fis the sum of the Riemannian met-
ric associated to Mand an asymmetric linear part governed
byω. Notably when ω≡0,Fis a traditional Rieman-
nian metric. The condition ∥ω(x)∥M(x)−1<1ensures the
positivity of the metric (see supplementary material).
From any metric we can construct a new metric associ-
ated to it, its dual, which plays a central role in differential
geometry.
Definition 3 (Dual Finsler metric) .The dual metric of a
Finsler metric Fxis the metric F∗
x:TxX→R+defined
by
F∗
x(v) = max {⟨v, b⟩;b∈Rd,Fx(b)≤1}. (20)
When considering only Randers metrics, a subtype of
Finsler metrics, the dual metric becomes explicit.
Lemma 1 (Dual Randers metric) .LetFxbe a Randers met-
ric given by (M, ω). The dual metric of Fxis also a Ran-
ders metric F∗
xassociated to (M∗, ω∗)that satisfies
αM∗ω∗
ω∗⊤ 1
α
=M ω
ω⊤1−1
, (21)
where α= 1− ⟨ω, M−1ω⟩>0.
A proof is provided in the supplementary material.
From Eq. (21) we can derive:
M∗=1
α2
αM−1+ (M−1ω)(M−1ω)⊤
, (22)
and
ω∗=−1
αM−1ω, . (23)
It is simple to show that ∥ω∗∥M∗(x)−1<1(see sup-
plementary material). The dual Randers metric F∗
xis the
Randers metric on the manifold Xassociated to the new
Riemannian and linear components (M∗, ω∗):
F∗
x(v) =∥v∥M∗(x)+⟨w∗(x), v⟩. (24)
3.3. Finsler heat equation
The classical heat equation in the Riemannian case is the
gradient flow of the Dirichlet energy, and by analogy we can
derive a Finsler heat equation as the gradient descent of the
dual energy1
2F∗
x(v)2, in the following way [5, 34].
Definition 4 (Finsler heat equation) .Given a manifold X
equipped with a Finsler metric Fx, the heat equation on
this Finsler manifold for smooth vector fields u(x, t)with
(x, t)∈X×R+is given by the gradient descent of the
dual energy
∂tu= div( F∗
x(∇u)∇F∗
x(∇u)). (25)
3134
4. Finsler heat kernel
We now analyse the Finsler heat equation to derive a
novel Laplacian operator for shape matching. Our plan is
the following:
• Analyse the heat equation on a Finsler manifold equipped
with a Randers metric,
• From a specific case where the solution is explicit, we
exhibit a simplified equation behaving like a regular heat
equation with an external heat source,
• The solution to this new problem is explicit and governed
by the homogeneous term, which is an anisotropic heat
diffusion with diffusivity involving the Randers metric,
• The homogeneous solution is given by a convolution with
an anisotropic kernel depending on the Randers metric,
• This heat kernel allows the construction of a new Finsler-
Laplace-Beltrami operator (FLBO) that benefits from all
the properties of ALBOs.
4.1. Finsler heat diffusion
The heat equation is well-known to be related to dis-
tances and geodesics in short time, and thus it is often ana-
lyzed when t→0. We look at the following specific case
in short time. To provide a tractable solution, we also here
assume that we slightly depart from Riemannian geometry
by taking small ∥ω∥.
Proposition 1 (Simplified Randers heat equation - distance
trick) .If the initial solution u0=u(x,0)of the heat equa-
tion satisfies F∗
x(∇u0) = 1 , then in short time the Finsler
heat equation on a Randers metric associated to (M, ω)
with small ∥ω∥simplifies to
∂tu= div
(M∗−ω∗ω∗⊤)∇u
+ div( ω∗). (26)
Proof. We provide the proof in the supplementary material.
The initial condition F∗
x(∇u0) = 1 holds when −u0is
a distance function, as the Finsler Eikonal equation is given
byF∗
x(−∇u) = 1 [32]. In practice, the solution to Eq. (26)
is not our primary concern. We only use this particular ini-
tialisation to exhibit a tractable solution that allows us to
define a family of Finsler-based LBOs. We name the coef-
ficient DF∗x=M∗−ω∗ω∗⊤as the Finlser diffusivity. We
can interpret Eq. (26) as a homogeneous heat equation:
∂tu(x, t) = div( DF∗x∇u(x, t)), (27)
to which we add an external heat source div(ω∗(x)). Given
some initial heat condition u0(x) =u(x,0), the solution of
Eq. (26) is the sum of the solution of Eq. (27),
u(x, t) =Z
Xu0(ξ)ht(x, ξ)dξ, (28)where htis the heat kernel for Eq. (27), and of any particular
solution, such as
ud(x, t) =Z
Xdiv(ω∗(ξ))ˆht(x, ξ)dξ , (29)
where ˆhis the average over time of the heat kernel ht:
ˆht(x, ξ) =Zt
s=0h(t−s)(x, ξ)ds . (30)
4.2. Finsler-Laplace-Beltrami operator
In Riemannian geometry, the heat kernel is by definition
given by the convolution kernel of the solution of the ho-
mogeneous equation. An external source introduces a con-
volution with the time average of the heat kernel. By anal-
ogy, from the homogeneous Eq. (27) we define the Finsler-
Laplace-Beltrami operator (FLBO) as:
∆FLBO u(x) =−divX(DF∗x∇Xu(x)). (31)
The FLBO is a special case of an ALBO on a Rieman-
nian manifold, that was derived after analyzing the heat
equation when the manifold is equipped with a Finsler met-
ric instead. Unlike previous ALBOs, it is theoretically justi-
fied rather than empirically designed based solely on heuris-
tics. Since the FLBO in an ALBO, it inherits all of its prop-
erties, such as the spectral decomposition of a compact pos-
itive semi-definite operator
∆FLBO ϕFLBO
k (x) =λFLBO
k ϕFLBO
k (x). (32)
The FLBO also differs from the Laplace-Finsler operator
(LF) deriving from Eq. (25):
∆Fu(x) =−div(F∗
x(∇u)∇F∗
x(∇u)), (33)
In particular, the LF operator acts on a Finsler manifold and
not a Riemannian one like the FLBO. Thus, it cannot be
used as a direct replacement of LBOs in most applications.
In the previous section we have shown that the solution
of the simplified Randers heat diffusion equation exhibits
the Finsler heat kernel ht(x, ξ)associated with the homo-
geneous Finsler heat diffusion equation.
Proposition 2. In the spectral domain, the Finsler heat ker-
nel can be expressed as
hFLBO
t (x, ξ) =X
k≥0e−tλFLBO
kϕFLBO
k (x)ϕFLBO
k (ξ).
(34)
We have unified the Finsler heat diffusion equation and
the anisotropic Laplace-Beltrami operator formulation. The
link comes from the Finsler heat kernel that was exhibited
in the explicit solution of the simplified equation Eq. (26) in
a special case. We point out that the asymmetric component
ωof the Randers metric influences the diffusivity coefficient
and then the eigendecomposition of the Finsler heat kernel.
3135
5. Experiments
5.1. Discretization
We present a possible discretization of our FLBO given a
manifold discretized by sampling nvertices. As the FLBO
is a positive semi-definite operator, and by analogy with the
LBO it can be approximated by an n×nsparse matrix
LFLBO =−S−1
FLBO WFLBO with the mass matrix SFLBO
and the stiffness matrix WFLBO . Our FLBO is not re-
stricted to a particular discrete surface representation. Fol-
lowing [6, 29], we focus on triangular meshes to discretize
the Finsler metrics, but representations for other discretiza-
tions can be easily deduced. As in [6, 29], we introduce
various angles θ, each giving a Finsler metric (Mθ, ωθ), to
produce convolution operators from FLBOs sensitive to θ,
and then sum them up to get a final Finsler-based convolu-
tion operator incorporating features from all directions. We
use the same notations as in [6, 29].
Our manifold is discretized as a triangular mesh with ver-
ticesV, edges E, and faces F. For each triangle ijk∈F,
we define Uijk= (ˆuM,ˆum,ˆn)as an orthonormal reference
frame associated to the face unit normal ˆnand the directions
of principal curvature ˆuM,ˆum∈R3. We denote ˆeij∈R3
the unit vector along the embedding of the edge (i, j)∈E
pointing from itoj, and αijandβijthe angles at kandh
of the adjacent triangles ijk∈Fandijh∈Frespectively.
We write Rθ∈R3the rotation matrix of angle θaround
the third basis vector (to be identified as ˆn). The notations
match those of Fig. 3.
ijkĥehîehĵekĵekîn̂um̂uMRθ̂umRθ̂uMβijαijθ
Figure 3. Notations for unit vectors and angles on the triangular
mesh. The figure mimics the illustration in [6].
In all our experiments, the mass matrix SFLBO is com-
puted as a diagonal matrix with diagonal element iequal to
one third of the areas of faces having ias a vertex [19].
Our chosen Riemannian metric is also anisotropic using
ideas from the ALBO community. When ω≡0we ob-
tain the traditional ALBO [29]. The diffusivity Dα(x)of
ALBOs is usually created by introducing a scaling factor
α > 0into one of its eigenvalues by various heuristic for-
mulae to break the isotropy along eigendirections [6, 29].
We firstly build on the strategy of [29] to create the uniform
anisotropic Riemannian diffusivity
Dα=1
1+α
1
, (35)withα= 10 in our experiments as in [29]. For each angle
θ, we rotate this diffusivity to create the oriented diffusivity
matrix Hαθ, also called shear matrix,
Hαθ=RθUijkDαU⊤
ijkR⊤
θ. (36)
We can now define our anisotropic Riemannian metric at
angle θ. As we want our construction to generalise the Rie-
mannian case ω≡0, and since DF∗xequals M−1(x)when
ω≡0, we choose
Mαθ=H−1
αθ. (37)
Note that our scheme recovers the isotropic Riemannian
metric when α= 0 as the shear matrix is then the iden-
tity. For each angle θ, we introduce the Randers anisotropic
component rotated by θfrom the direction of maximal cur-
vature
ωθ=τRθˆuM, (38)
where τis a hyperparameter to ensure ∥ω∥M−1
αθ<1. We
have thus constructed the Randers metric (Mαθ, ωθ), from
which we can easily compute its dual (M∗
αθ, ω∗
θ)and its
Finsler diffusivity Dαθ
F∗x. We then use the generalisation of
the classical cotangent weight scheme for anisotropic diffu-
sivities [6] to compute the weights of Wαθ
FLBO :
wij=

1
2 
⟨ˆekj,ˆeki⟩Dαθ
F∗x
sinαij+⟨ˆehj,ˆehi⟩Dαθ
F∗x
sinβij!
(i, j)∈E,
−P
k̸=iwik i=j,
0 else.
(39)
The FLBO at angle θis finally given by ∆αθ
FLBO =
−S−1
FLBO Wαθ
FLBO . Note that if we had taken ωθ≡0, then
we would have recovered the ALBO from [29]. See Fig. 1
for a illustrative summary of how we derive the FLBO.
Finsler-based anisotropic convolution operator Since
our FLBOs are ALBOs, we can use the method of [29]
to create θ-oriented convolution kernels gαθ,x according to
Eq. (13) by working in the spectral domain of ∆αθ
FLBO and
taking ϕαθ,0, ϕαθ,1. . .to be the eigenvectors of ∆αθ
FLBO .
Convolution (f∗g)αθof any function fwith this kernel
is then computed in the spectral domain (Eq. (14)) and then
oriented convolutions are summed to get the final convolu-
tion operator (f∗g)α(Eq. (15)). In our experiments, we use
eight uniformly spaced samples of θ∈[0, π)as in [29]. Fol-
lowing [29], we encode the spectral coefficients ˆg(λαθ,k)of
gαθ,x using Chebychev polynomials
ˆg(λαθ,k) =S−1X
s=0cαθ,sTs(λαθ,k), (40)
where S= 16 in our tests as in [29], Tsis the Chebychev
polynomial of the first kind of order s, i.e. Ts(cosγ) =
3136
cos(sγ)for any γ, and cαθ,s∈Rare coefficients to be
learned.
For visualisation purposes, we provide in the supplemen-
tary a plot of convolution filters gαθ,x for various θwhen
choosing the spectral coefficients of the kernel to be equal
to one of the Chebychev polynomials, similarly to [29].
5.2. An Application: Shape matching
As a concrete example, we use our FLBO for shape
matching, which is a common shape analysis application
where LBOs play a central role. We compare the re-
sults to those based on traditional Riemannian (anisotropic)
LBOs, namely FieldConv [33] and ACSCNN [29]. Note
that ACSCNN coincides with our method when τ= 0.
Datasets and evaluataion. We work on four publicly
available datasets: FAUST Remeshed [4, 38], SCAPE
Remeshed [2, 38], and SHREC’16 Partial Cuts [17] and
Holes [17]. We follow the Princeton benchmark protocol
[26]. We provide the percentage of matches that are at most
r-geodesically distant from the groundtruth correspondence
on the reference shape, with r∈[0,1].
Setting. Following [29], our chosen architecture is
SplineCNN [21]. We train each dataset for 100 epochs
with Adam optimizer and and we set the learning rate to
0.001. We take as input SHOT descriptors [40]. In particu-
lar, we use the open-source implementation of ACSCNN1.
The preprocessing step to get the Finsler-based filters is
done with our custom implementation.
5.3. Full mesh correspondence.
FAUST (Remeshed) dataset contains 100 human shapes
corresponding to 10 different human beings remeshed with
the LRVD [45] to generate more challenging shapes with
different mesh connectivity [4, 38]. It does not have one-to-
one correspondence between shapes and they do not share
the same number of vertices. As suggested in [20], we use
the first 80 shapes as the training set and we test on the
remaining 20 ones.
SCAPE (Remeshed) dataset contains 71 human shapes
corresponding to the same human being in different po-
sitions. Each shape is remeshed as in FAUST Remeshed
[2, 38]. The first 51 shapes form the training set and we test
on the other 20 shapes.
5.4. Partial correspondence.
SHREC’16 Partial Cuts andSHREC’16 Partial Holes
datasets contain respectively 135 and 90 shapes of human
1https://github.com/GCVGroup/ACSCNNMethod Accuracy (r = 0) Accuracy (r = 0.01)
FieldConv [33] 53.39 75.01
ACSCNN [29] 61.95 82.46
oursτ= 0.162.61 82.90
τ= 0.262.58 82.90
τ= 0.362.67 82.94
τ= 0.462.27 82.66
τ= 0.562.38 82.68
Table 1. Accuracy on FAUST Remeshed.
Method Accuracy (r = 0) Accuracy (r = 0.01)
FieldConv [33] 37.41 61.37
ACSCNN [29] 46.13 71.70
oursτ= 0.146.94 72.44
τ= 0.246.27 71.91
τ= 0.345.91 71.92
τ= 0.445.82 71.44
τ= 0.545.26 71.27
Table 2. Accuracy on SCAPE Remeshed.
and animals divided in 8 categories. The shapes are de-
formed following two kinds of partiality, respectively cuts
and holes. For each category in Cuts, we use the first 10
shapes as a training dataset and we test on the last 5 shapes.
For each category in Holes, we use the first 6 shapes as a
training dataset and we test on the last 4 shapes.
5.5. Results
We present quantitative results in Tabs. 1 to 4 for FAUST
Remeshed, SCAPE Remeshed, SHREC’16 Partial Cuts,
and SHREC’16 Partial Holes respectively. For the first
two datasets we provide the accuracy within r∈ {0,0.01}
geodesic radius of the groundtruth, whereas we only display
the performance for r= 0 in the last two datasets due to
space constraints as each of these datasets are decomposed
into 8 subdatasets. Clearly, FieldConv struggles compared
to the more advanced ACSCNN. Our method systemati-
cally outperforms, or is on par with, ACSCNN for a default
choice of τ= 0.1. This demonstrates that the FLBO can be
used in complement to advanced approaches to boost per-
formance, requiring only a small additional preprocessing
overhead for computing the metric and the FLBO, which is
negligible compared to neural network training times. We
test our method with other values of τand find that the
results remain consistent, proving that our approach is not
highly sensitive to finely tuning this hyperparameter. In the
literature, providing the results as a plot with respect to all
r∈[0,1]is sometimes performed. However, since our re-
sults are close to those of ACSCNN, the curves tend to su-
perimpose and do not provide any additional insight, so we
do not provide them here.
3137
Method Cat Centaur David Dog Horse Michael Victoria Wolf
FieldConv [33] 0.054 1.18 0 0.094 1.93 0.33 0.010 45.81
ACSCNN [29] 38.10 74.99 23.78 59.87 44.37 12.82 31.23 93.75
oursτ= 0.140.13 75.41 22.34 59.31 42.72 16.04 27.95 94.02
τ= 0.237.72 72.83 22.48 60.02 43.17 14.30 29.72 94.14
τ= 0.340.26 73.40 21.59 57.61 43.49 13.15 31.10 94.17
τ= 0.439.63 72.29 21.51 57.12 44.83 13.55 29.35 93.33
τ= 0.540.94 73.16 20.49 60.17 43.85 15.04 28.46 94.06
Table 3. Accuracy on SHREC’16 Partial Cuts.
Method Cat Centaur David Dog Horse Michael Victoria Wolf
FieldConv [33] N.A. 0.038 N.A. 0.11 N.A. 0.11 0.049 0.39
ACSCNN [29] 19.98 32.80 16.09 41.70 46.85 12.29 11.32 84.53
oursτ= 0.119.95 35.85 17.96 42.68 47.87 12.00 11.70 84.64
τ= 0.217.99 33.10 16.40 42.84 49.77 13.90 10.02 85.23
τ= 0.321.27 35.48 18.43 43.29 45.07 11.31 11.52 85.74
τ= 0.420.08 32.54 16.41 42.98 45.71 13.16 11.41 85.72
τ= 0.518.62 35.04 16.28 42.68 45.38 11.89 10.19 84.23
Table 4. Accuracy on SHREC16’ Partial Holes. N.A. indicates a
failure to process the dataset.
We plot some qualitative correspondence results in
Fig. 4. We find that our method is able to provide a con-
vincing mapping between shapes undergoing various highly
non-rigid deformations. It is also able to handle missing
parts such as cuts and holes, although performance natu-
rally deteriorates as the challenge is significantly harder.
6. Conclusion
We revisited Finsler manifolds, a generalization of Rie-
mannian manifolds that naturally allow for anisotropies. By
exploring their heat diffusion equation we derived a novel
Finsler heat kernel and a Finsler-Laplace-Beltrami oper-
ator (FLBO). This FLBO generalizes traditional heuristic
anisotropic LBOs while being theoretically motivated. It
can be used in place of LBOs or ALBOs and is compatible
with various advanced techniques such as spatial filtering
or geometric deep learning. We tested the pertinence of the
FLBO in shape correspondence experiments and found that
our approach can easily complement state-of-the-art geo-
metric deep learning methods using ALBOs. We hope that
the concise and self-contained review of Finsler geometry
and the derivation of a tractable Finsler heat equation and
FLBO will encourage further exploration of the Finsler ge-
ometry in the field of computer vision.
Limitations and future works. We have used some
strong assumptions to derive the Finsler heat equation.
While we acknowledge this limitation, it is necessary, in our
work, to exhibit some tractable operators. However, we be-
lieve that a further theoretical focus on this stage is an excit-
ing and promising research direction. Our experiments are
also built on a straightforward discretization. Although it is
not a major drawback, as our goal is to show that traditional
LBOs can be generalized to Finsler-based LBOs, an exten-
sion of our example to other choices of (M, ω)would also
be crucial. Finally, beyond our simple application to shape
Figure 4. Visual shape correspondence results on the FAUST
Remeshed (row 1), SCAPE remeshed (row 2), and SHREC’16
Partial Cuts (columns 1 and 2 in rows 3 to 5), and SHREC’16 Par-
tial Holes (columns 1 and 3 in rows 3 to 5) datasets. The source
shape is on the left, on which we perform dense correspondence
estimation on the shapes to the right. See the supplementary ma-
terial for more visual results on other shapes.
matching, we do believe that the importance of Finsler man-
ifolds in computer vision is largely uncharted and requires
further stimulating works.
Acknowledgement. This work was supported by the
ERC Advanced Grant SIMULACRON.
3138
References
[1] Mathieu Andreux, Emanuele Rodola, Mathieu Aubry, and
Daniel Cremers. Anisotropic Laplace-Beltrami operators for
shape analysis. In Sixth Workshop on Non-Rigid Shape Anal-
ysis and Deformable Image Alignment (NORDIA) , 2014. 2,
3
[2] Dragomir Anguelov, Praveen Srinivasan, Daphne Koller, Se-
bastian Thrun, Jim Rodgers, and James Davis. Scape: shape
completion and animation of people. In ACM Transactions
on Graphics (TOG) , pages 408–416. ACM, 2005. 7
[3] Souhaib Attaiki, Gautam Pai, and Maks Ovsjanikov. Dpfm:
Deep partial functional maps. In 2021 International Confer-
ence on 3D Vision (3DV) , pages 175–185. IEEE, 2021. 2
[4] Federica Bogo, Javier Romero, Matthew Loper, and
Michael J Black. Faust: Dataset and evaluation for 3d mesh
registration. In CVPR , pages 3794–3801, 2014. 7
[5] J Frederic Bonnans, Guillaume Bonnet, and Jean-Marie
Mirebeau. A linear finite-difference scheme for approximat-
ing Randers distances on cartesian grids. ESAIM: Control,
Optimisation and Calculus of Variations , 28:45, 2022. 4
[6] David Boscaini, Jonathan Masci, Emanuele Rodola, and
Michael Bronstein. Learning shape correspondence with
anisotropic convolutional neural networks. In Advances in
Neural Information Processing Systems , pages 3189–3197,
2016. 1, 2, 3, 6
[7] David Boscaini, Jonathan Masci, Emanuele Rodola, Michael
Bronstein, and Daniel Cremers. Anisotropic diffusion de-
scriptors. In Computer Graphics Forum , pages 431–441,
2016. 2
[8] Amit Bracha, Oshri Halim, and Ron Kimmel. Shape Corre-
spondence by Aligning Scale-invariant LBO Eigenfunctions.
InEurographics Workshop on 3D Object Retrieval . The Eu-
rographics Association, 2020. 2
[9] Amit Bracha, Thomas Dag `es, and Ron Kimmel. On partial
shape correspondence and functional maps. arXiv preprint
arXiv:2310.14692 , 2023. 2
[10] Alexander M Bronstein, Michael M Bronstein, and Ron
Kimmel. Numerical geometry of non-rigid shapes . Springer
Science & Business Media, 2008. 2
[11] Dongliang Cao, Paul Roetzer, and Florian Bernard. Unsu-
pervised learning of robust spectral shape matching. arXiv
preprint arXiv:2304.14419 , 2023. 2
[12] ´Elie Cartan. Les espaces m ´etriques fond ´es sur la notion
d’aire . Hermann, 1933. 1
[13] Da Chen, Jean-Marie Mirebeau, and Laurent D. Cohen.
Finsler geodesics evolution model for region based active
contours. In Proc. of the British Machine Vision Conference
(BMVC) , 2016. 3
[14] Da Chen, Jean-Marie Mirebeau, and Laurent D. Cohen. A
new Finsler minimal path model with curvature penalization
for image segmentation and closed contour detection. In
IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR) , pages 355–363, 2016. 3
[15] Da Chen, Jean-Marie Mirebeau, and Laurent D. Cohen.
Global minimum for a Finsler elastica minimal path ap-
proach. pages 458–483, 2017. 3[16] Qifeng Chen and Vladlen Koltun. Robust nonrigid registra-
tion by convex optimization. In Proceedings of the IEEE
International Conference on Computer Vision , pages 2039–
2047, 2015. 2
[17] Luca Cosmo, Emanuele Rodola, Michael M. Bronstein, An-
drea Torsello, Daniel Cremers, Y Sahillioglu, et al. Shrec’16:
Partial matching of deformable shapes. Proc. 3DOR , 2(9):
12, 2016. 7
[18] Micha ¨el Defferrard, Xavier Bresson, and Pierre Van-
dergheynst. Convolutional neural networks on graphs with
fast localized spectral filtering. In Advances in Neural In-
formation Processing Systems (NeurIPS) , pages 3844–3852,
2016. 4
[19] Mathieu Desbrun, Mark Meyer, Peter Schr ¨oder, and Alan H.
Barr. Implicit fairing of irregular meshes using diffusion and
curvature flow. In Proceedings of the ACM Siggraph’99 ,
pages 317–24, 1999. 6
[20] Nicolas Donati, Abhishek Sharma, and Maks Ovsjanikov.
Deep geometric functional maps: Robust feature learning
for shape correspondence. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 8592–8601, 2020. 2, 7
[21] Matthias Fey, Jan Eric Lenssen, Frank Weichert, and Hein-
rich M ¨uller. Splinecnn: Fast geometric deep learning with
continuous B-spline kernels. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition ,
pages 869–877, 2018. 7
[22] Paul Finsler. ¨Uber Kurven und Fl ¨achen in allgemeinen
R¨aumen . Philosophische Fakult ¨at, Georg-August-Univ.,
1918. 1
[23] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep
learning . MIT press, 2016. 2
[24] Oshri Halimi, Or Litany, Emanuele Rodola, Alex M. Bron-
stein, and Ron Kimmel. Unsupervised learning of dense
shape correspondence. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 4370–4379, 2019. 2
[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition , pages 770–778, 2016. 2
[26] Vladimir G Kim, Yaron Lipman, and Thomas Funkhouser.
Blended intrinsic maps. ACM transactions on graphics
(TOG) , 30(4):1–12, 2011. 7
[27] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
Imagenet classification with deep convolutional neural net-
works. Advances in neural information processing systems ,
25, 2012. 2
[28] Yann LeCun, L ´eon Bottou, Yoshua Bengio, and Patrick
Haffner. Gradient-based learning applied to document recog-
nition. Proceedings of the IEEE , 86(11):2278–2324, 1998.
2
[29] Qinsong Li, Shengjun Liu, Ling Hu, and Xinru Liu. Shape
correspondence using anisotropic Chebyshev spectral cnns.
InCVPR , pages 14658–14667, 2020. 1, 2, 3, 4, 6, 7, 8
[30] Or Litany, Tal Remez, Emanuele Rodola, Alex M. Bronstein,
and Michael M. Bronstein. Deep functional maps: Struc-
3139
tured prediction for dense shape correspondence. In Pro-
ceedings of the IEEE international conference on computer
vision , pages 5659–5667, 2017. 2
[31] Roee Litman and Alexander M Bronstein. Learning spec-
tral descriptors for deformable shape correspondence. IEEE
transactions on pattern analysis and machine intelligence ,
36(1):171–180, 2013. 2
[32] Jean-Marie Mirebeau. Efficient fast marching with Finsler
metric. pages 515–557, 2014. 5
[33] Thomas W. Mitchel, Vladimir G. Kim, and Michael Kazh-
dan. Field convolutions for surface cnns. In Proceedings of
the IEEE/CVF International Conference on Computer Vision
(ICCV) , pages 10001–10011, 2021. 2, 7, 8
[34] Shin-ishi Otha and Karl-Theodor Sturm. Heat flow on
Finsler manifolds. Commun. Pure Appl. Math. , 62(10):
1386–1433, 2009. 3, 4
[35] Maks Ovsjanikov, Mirela Ben-Chen, Justin Solomon, Adrian
Butscher, and Leonidas Guibas. Functional maps: a flexible
representation of maps between shapes. ACM Transactions
on Graphics (ToG) , 31(4):1–11, 2012. 2
[36] Maks Ovsjanikov, Etienne Corman, Michael Bronstein,
Emanuele Rodol `a, Mirela Ben-Chen, Leonidas Guibas,
Frederic Chazal, and Alex Bronstein. Computing and pro-
cessing correspondences with functional maps. In SIG-
GRAPH ASIA 2016 Courses , pages 1–60. 2016. 2
[37] Nathan D. Ratliff, Karl Van Wyk, Mandy Xie, Anqi Li, and
Muhammad Asif Rana. Generalized nonlinear and Finsler
geometry for robotics. In IEEE International Conference
on Robotics and Automation (ICRA) , pages 10206–10212,
2021. 3
[38] Jing Ren, Adrien Poulenard, Peter Wonka, and Maks Ovs-
janikov. Continuous and orientation-preserving correspon-
dences via functional maps. ACM Transactions on Graphics
(ToG) , 37(6):1–16, 2018. 2, 7
[39] Bernhard Riemann. ¨Uber die Hypothesen, welche der Ge-
ometrie zu Grunde liegen. Abhandlungen der k ¨oniglichen
Gesellschaft der Wissenschaften zu G ¨ottingen , 13:304–319,
1854. 1
[40] Samuele Salti, Federico Tombari, and Luigi Di Stefano.
Shot: Unique signatures of histograms for surface and tex-
ture description. Computer Vision and Image Understand-
ing, 125:251–264, 2014. 7
[41] Abhishek Sharma and Maks Ovsjanikov. Weakly supervised
deep functional maps for shape matching. Advances in Neu-
ral Information Processing Systems , 33:19264–19275, 2020.
2
[42] Karen Simonyan and Andrew Zisserman. Very deep convo-
lutional networks for large-scale image recognition. arXiv
preprint arXiv:1409.1556 , 2014. 2
[43] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
Shlens, and Zbigniew Wojna. Rethinking the inception archi-
tecture for computer vision. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition , pages
2818–2826, 2016. 2
[44] Matthias Vestner, Zorah L ¨ahner, Amit Boyarski, Or Litany,
Ron Slossberg, Tal Remez, Emanuele Rodola, Alex Bron-
stein, Michael Bronstein, Ron Kimmel, and Daniel Cre-
mers. Efficient deformable shape correspondence via kernelmatching. In 2017 International Conference on 3D vision
(3DV) , pages 517–526. IEEE, 2017. 2
[45] Dong-Ming Yan, Guanbo Bao, Xiaopeng Zhang, and Peter
Wonka. Low-resolution remeshing using the localized re-
stricted voronoi diagram. IEEE Transactions on Visualiza-
tion and Computer Graphics (TVCG) , 2014. 7
[46] Fang Yang, Li Chai, Da Chen, and Laurent D. Cohen.
Geodesic via asymmetric heat diffusion based on Finsler
metric. In Asian Conference on Computer Vision (ACCV),
Springer , pages 371–386, 2018. 3
3140
