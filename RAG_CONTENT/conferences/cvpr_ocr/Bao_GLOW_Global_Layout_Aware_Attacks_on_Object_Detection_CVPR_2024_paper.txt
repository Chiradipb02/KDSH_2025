GLOW: Global Layout Aware Attacks on Object Detection
Jun Bao*1, Buyu Liu∗2, Kui Ren2, and Jun Yu†3,4
1The State Key Laboratory of Blockchain and Data Security2Zhejiang University
3Hangzhou Dianzi University4Harbin Institute of Technology (Shenzhen)
{baojun, buyu.liu, kuiren }@zju.edu.cn, yujun@hdu.edu.cn
Abstract
Adversarial attacks aim to perturb images such that a pre-
dictor outputs incorrect results. Due to the limited research
in structured attacks, imposing consistency checks on natural
multi-object scenes is a practical defense against conven-
tional adversarial attacks. More desired attacks should be
able to fool defenses with such consistency checks. Therefore,
we present the first approach GLOW that copes with various
attack requests by generating global layout-aware adversar-
ial attacks, in which both categorical and geometric layout
constraints are explicitly established. Specifically, we focus
on object detection tasks and given a victim image, GLOW
first localizes victim objects according to target labels. And
then it generates multiple attack plans, together with their
context-consistency scores. GLOW, on the one hand, is ca-
pable of handling various types of requests, including single
or multiple victim objects, with or without specified victim
objects. On the other hand, it produces a consistency score
for each attack plan, reflecting the overall contextual consis-
tency that both semantic category and global scene layout
are considered. We conduct our experiments on MS COCO
and Pascal. Extensive experimental results demonstrate that
we can achieve about 30 %average relative improvement
compared to state-of-the-art methods in conventional single
object attack request; Moreover, such superiority is also
valid across more generic attack requests, under both white-
box and zero-query black-box settings. Finally, we conduct
comprehensive human analysis, which not only validates
our claim further but also provides strong evidence that our
evaluation metrics reflect human reviews well.
1. Introduction
Object detection aims to localize and recognise multiple
objects in given images with their 2D bounding boxes and
corresponding semantic categories [ 14,19]. Due to the phys-
ical commonsense and viewpoint preferences [ 16], detected
*Equal contribution.
†Corresponding author.
Figure 1. We propose a novel attack generation algorithm GLOW
that manages both conventional single targeted object (R1) and our
generic attack requests (R2,R3). Specifically, GLOW consists of
two steps. The first step localizes victim objects, if not provided.
The second step generates various attack plans with their consis-
tency scores. Then the one with the highest score is our final attack
plan and parsed to attackers. Best viewed in color.
bounding boxes in natural images are not only semantically
labeled but also placed relative to each other within a co-
herent scene geometry, reflecting the underlying 3D scene
structure. Such bounding box representation allows us to
derive a notion of both semantic and geometric constraints.
For example, co-occurrence matrix is a commonly exploited
semantic constraint where certain object categories are more
likely to co-occur, e.g., bed and pillow [ 20]. Geometric
constraints, on the other hand, leverage the inductive bias
of scene layout [ 11], such as when oc-occurring in a scene,
traffic light is more likely to be appeared on the upper region
with a smaller bounding box compared to car.
Adversarial attacks on object detectors mainly focus on
targeted victim setting [ 7,45] where the goal is to perturb a
specific victim object to target class. In this case, the location,
ground truth and target class of the victim object are assumed
to be known to attackers. Naturally, contextual cues are lever-
aged in attack and defense mechanisms [ 6,7,48] on detec-
tors to enhance or detect holistic context (in)consistency [ 6].
Though being well-motivated and demonstrating good per-
formances in conventional setting, the state-of-the-art meth-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
12057
ods [ 6,7] suffer the following problems in practice. Firstly,
the assumption of known location and ground truth label of
victim object might be too strong due to annotation cost [ 2].
Therefore, more vague attack requests where victim objects
are not specified, e.g. show me an apple and a chair, should
be considered in practice, which are beyond those existing
methods. Secondly, global geometric layout is commonly
neglected as existing methods either model semantic co-
occurrence [ 6] or consider relative sizes and distance w.r.t.
given victim object [7].
In this work, we introduce a novel yet generic attack
plan generation algorithm GLOW on both conventional and
generic attack requests to effectively leverage both categor-
ical and global layout cues, leading to superior white-box
attack performance and better transferability in black-box
setting. As for generic requests, we firstly loose the assump-
tion of known specific victim object by requesting only the
existence of certain target label, e.g. show me category X
in image. Compared to conventional setting, our request
demands the modelling of the locations and sizes of target
label X. Our second request further constrains label amount,
e.g. give me N objects of category X and M objects of
category Y , which necessitates the global layout of victim
image. To fulfill these requests, we propose a novel attack
plan generation method GLOW that accounts for both cate-
gorical and geometrical relations. Specifically, GLOW aims
to figure out the most context-consistent attack plan for each
victim image according to its underlying layout while con-
sidering the hard constraints, e.g. existence or amount of
some target labels under generic requests or a specific victim
object under conventional request. The first step in GLOW
localizes victim objects with given target label or amount on
victim image by modeling the joint distribution of bound-
ing box sizes and centers. And it enables generic attack
requests. Given these victim objects, the second step further
leverages the layouts of victim image to generate globally
context-consistent attack plans with consistency scores. This
is achieved by reformulating the plan generation task as a
layout similarity measurement problem. Therefore, those
consistency scores are similarity scores. Finally, the plan
with the highest score would be our selected attack plan.
We then implement the selected plan with existing attack
generation methods, or attackers. Details of our proposed
requests and GLOW can be found in Fig. 1.
We validate our ideas on coco2017val [ 32] as well as
Pascal [ 18] with both white-box and zero-query black-box
settings. And we design new evaluation metrics as well as
introduce human analysis to measure layout consistency thus
mimicking consistency defenses. We demonstrate that in
white-box setting, our proposed method achieves superior
performance with both conventional and proposed generic at-
tack setting compared to SOTAs. More importantly, GLOW
provides significantly better transfer success rates on zero-query black-box setting compared to existing methods.
Our contributions can be summarized as follows:
•A novel method GLOW that is capable of generating con-
text consistent attack plans while accounts for both seman-
tic and geometric coherency.
•Two generic attack requests and consistency evaluation
metrics to mimic realistic scenarios and delicate defenses.
• State-of-the-art performances on coco2017val and Pascal
images under both white-box and zero-query black-box
settings. Code, model and requests will be available.
2. Related Work
Object detection The goal of object detection is to predict
a set of bounding boxes and category labels for each object
of interest. Starting from [ 14,19], object detection explored
extensive cues, including semantic [ 27], geometric [ 46] and
other contextual cues [ 47], to improve its performance as
well as interpretability. Recently, deep neural networks
(DNNs) [ 26] have significantly improved many computer vi-
sion [ 21,26] and natural language processing tasks [ 15,23].
Modern detectors follow the neural networks design, such as
two-stage models where proposals are firstly generated and
then regression and classification are performed [ 5,21] and
one-stage models [ 33,43,52] that simultaneously predict
multiple bounding boxes and class probabilities with the
help of pre-defined anchors or object centers. More recently,
transformer-based models [ 8,53] are proposed to further
simplify the detection process by formulating the object de-
tection as a set prediction problem where unique predictions
can be achieved by bi-partite matching, rather than non-
maximum suppression [ 4,24]. Similarly, contextual cues
are also explored in modern detectors [ 1,3,12,35,51] with
various forms. In this paper, we focus on adversarial attacks
on DNNs-based detectors. And our GLOW generates con-
textually coherent attack plans with various requests, which
are also transferable to detectors of different architectures.
Adversarial attacks and defenses in object detection De-
spite impressive performance boosts, DNNs are vulnerable
to adversarial attacks, e.g. adding visually imperceptible
perturbations to images leads to significant performance
drop [ 9,22,42]. Adversarial attacks can be categorized
into white-box [ 22,36] and black-box [ 17,31], depending
on whether parameters of victim models are accessible or
not. Attacks such as DAG [ 45], RAP [ 30] and CAP [ 50] are
architecture-specific white-box attacks on detectors where
two-stage architecture is required since they work on pro-
posals generated by the first stage. More generic attacks,
such as UAE [ 44] and TOG [ 13], are capable of attacking
all different kinds of models regardless of their architectures.
Compared to the aforementioned methods that perturb the
image globally [ 45], patch-based attacks [ 34] also show-
case their ability in terms of fooling the detectors without
touching the victim objects [ 25]. In contrast, black-box at-
12058
tacks [ 10,28,29] are more practical yet challenging where
either a few queries or known surrogate models are exploited
to fool an unknown victim model. Observing the impacts of
adversarial attacks on detectors, various defense methods are
proposed to detect such attacks, wherein contextual cues are
explored [ 48]. However, contextual cues are almost always
represented in the form of semantic co-occurrence matrix
where global layouts are largely neglected [ 6,7]. In con-
trast, we propose a generic attack plan generation algorithm
that leverages both semantic and geometric coherency, e.g.
scene layout. Consequently, it manages both conventional
single targeted victim setting and generic attack requests
where locations are unknown or object amount is further
restricted, translating to SOTA performance under white-box
and black-box settings.
3. Method
We introduce the attack requests, our proposed GLOW and
attackers in Sec. 3.1, Sec. 3.2 and Sec. 3.3 respectively.
3.1. Attack requests
To attack a victim image, user may or may not specify
victim objects, e.g. providing their locations or labels. There-
fore, besides considering conventional attack request where a
specific object and its targeted label are given, more generic
requests should also be addressed, such as give me 2 cats
or mis-classify the rightmost boat to car. Let’s denote Das
the set of victim images. C={cp}C
p=1is the label space
withCsemantic categories. Given a known object detector
f, which can be the victim model in white-box attack or
the surrogate model under black-box setting, we can obtain
a set of predicted objects Oon victim image I∈ D , or
O=f(I) ={ln, sn}N
n=1, consisting the locations and se-
mantic categories of Nobjects. lndefines the location of the
n-th object, including its bounding box center coordinates,
height and width. And sn∈ Cis its semantic label.
R1: mis-classify the object sntocp.This is the conven-
tional attack request where the n-th object is our specific
victim object and cpis the targeted label.
Though one can always choose random object as victim
and random category as cp, we observe that the choices of
victim object and target label play an important role in attack
performances (see Sec. 4). To this end, we set different selec-
tion criteria for victim object and targeted label to evaluate
attack methods in various aspects. As for victim object, it
is unpractical to assume that ground-truth locations can be
provided by the users, e.g. bounding box annotations can be
time-consuming [ 2]. Therefore, we turn to the predictions
as reliable sources to help us to determine where the attack
should take place. In practice, choosing the one that has the
largest bounding box among all predictions with confidence
score above 0.85 provides good estimation for GT.
Figure 2. Examples of R1. Victim objects snare highlighted with
yellow bounding boxes and target labels cpgenerated with R1-5,
R1-50 and R1-95 are on the right side of each victim image.
As for target label cp, we mainly follow [ 6,7] where the
out-of-context attack is considered. Specifically, to eliminate
the chance of miscounting the existing objects as success, cp
is selected if and only if cpis not present in the I. Rather than
randomly selecting cpamong all unpresented categories [ 6,
7], our decision is made according to distance in word vector
space [ 49] as it captures the semantic and syntactic qualities
of words. Mathematically, for each unpresented cp, we
define its average distance as:
vd(cp) =1
NX
nv(cp, sn);∀cp/∈ Sn (1)
where Sn={sn}N
n=1andv(cp, sn)denotes the cosine
distance between category cpandsnin word vector space.
To evaluate the impact of target label cp, we collect three
cps according to vd(cp)and visualize them in Fig. 2. Specif-
ically, we firstly rank all cp/∈ Snbased on vd(cp). Then we
choose the top 5%,50% and95% ones as our target class
cps, referring as R1-95, R1-50 and R1-5, respectively.
Our ultimate goal of R1 is not only to mis-classify the
victim object, but also to fail the potential defenses w.r.t. con-
sistency checks. Therefore, the challenge of R1 mainly lies
in figuring out the attack plan that is contextually consistent
and beneficial for the mis-classification in practice.
R2: show me the category cp.Rather than assuming that
a specific victim object is known to attackers as in R1, R2
takes one step further in terms of relaxing the attack request.
Specifically, R2 comes in a much vague manner where user
only specifies the target label cp.
Though it seems that asking for the existence of cpis
an easier task compared to R1 as one can always flip a ran-
dom object to cp, we argue that this conclusion is valid if
only coarse semantic consistency check/defense, e.g. co-
occurrence matrix [ 6], is available, which unfortunately ne-
glects geometric context. A more desired consistency check
should be capable of capturing both geometric and semantic
context. For example, traffic light is less likely to appear on
the image bottom while poles usually have slim bounding
boxes. And our goal is to fool the victim model and these
delicate defenses simultaneously.
Therefore, we claim that R2 is more challenging than R1
as it requests additional understanding of the location-wise
distribution of target label cp. We kindly note our readers
that such challenge is beyond [ 6,7] (see Fig. 3). We omit the
details of cpin R2-5, R2-50 and R2-95 as they are selected
based on the same criteria as that of R1 (see supplementary).
12059
Figure 3. We visualize one victim image with their R2-5, R2-50
and R2-90 labels. And we highlight the victim object sn, which is
localized by GLOW, with yellow bounding box.
Figure 4. Challenge of R3. We have victim image on the left and
four example proposals based on request R3-5 on the right. Among
these four proposals, the left most one is more plausible than one
in middle considering the layout relations. And the right two are
totally wrong as they violate the amount restriction.
R3: give me multiple cps.R3 reflects another realistic attack
scenario, e.g. have a monitor and a mouse in victim image I.
Besides not specifying the victim object by providing only
target label information, R3 enforces additional constraint
on object amount, making it more challenging. Specifically,
multi-object relationship should be considered together with
hard restrictions on the amount of objects (see Fig. 4). For
example, besides modelling locations of mouse and monitor
individually, estimating their layout, e.g. monitor is more
likely to be above the mouse, is also essential to achieve
context consistent yet fooled predictions.
Theoretically, R3 can be multiple victim objects of the
same or different categories, which do not affect our follow-
ing GLOW method. In practice, when it comes to objects
with various categories, additional heuristics are needed to
avoid semantic inconsistency as vddoes not guarantee con-
textual consistent combinations. Moreover, such problem
becomes more severe with increasing number of objects,
together with the emerge of new challenge of underlying
constraints on object amount in natural image. For instance,
tenapples inIcan be natural but not for ten stop signs .
Therefore, we leave objects of different categories as our
future work and focus on two objects of the same cp. Details
of R3-5, R3-50 and R3-95 can be found in supplementary.
3.2. GLOW: Global LayOut aWare attacks
Contextually consistent attack has been discussed in many
previous work [ 6,7]. The main motivation is that perturbing
only the victim object may lead to inconsistency in context
thus global attack plan should be considered. Specifically,
an attack plan assigns target labels to all objects in victim
image, including ones that are not victims originally, to both
avoid inconsistency and benefit the attack request. Though
well-motivated, existing methods largely rely on semantic
context [ 6], neglecting geometric context such as scene lay-out. In addition, the ability of modelling prior knowledge,
such as having more than ten beds in an image is unlikely to
happen while obtaining ten books can be feasible, is lacking.
To this end, we propose a novel attack plan generation
method GLOW that accounts for both semantic and geo-
metric context, such as object locations and overall scene
layout. GLOW consists of two steps. The first localization
step aims to locate victim objects based on target labels
and their amounts under generic attack requests R2 and R3.
Then the second generation step further produces multiple
context-consistent attack plans as well as their scores with
given victim objects. Afterwards, the plan with the highest
score is selected as our final attack plan and then parsed to
existing attackers. See Fig. 5 for more details.
Victim object localization We aim to localize victim objects
under R2 and R3, where constraints on target labels and/or
their amount are available.
Let’s first assume there exist some images from annotated
detection dataset, which, in the simplest case, can be the set
that our victim/surrogate model is trained on. We denote
this dataset as T, including Timages and their bounding
box annotations A={At}T
t=1, where At={lt
m, st
m}M
m=1
is the set of bounding box annotations on the t-th image It.
As denoted in At,Itconsists of Mannotated objects. The
m-th object instance is further represented by its location lt
m
and corresponding semantic category st
m∈ C.
Determining the location of victim object under R2 and
R3 is equivalent to estimating the center, height and width
of bounding boxes of target label cp. And we formulate the
localization as a probability maximization problem. This
is achieved by modelling the joint probability of bounding
box center, height and width per category. Specifically, for
eachcp∈ C, we have Lcp={lt
m|st
m=cp}t,m, where lt
m
is normalized by image height and width. Then we apply
GMM [ 37] to fit q={1, . . . , Q }Gaussians Np
q(µp
q, δp
q)on
Lcp, where µp
qandδp
qare mean and co-variance of q-th
Gaussian at class cp.pd fp
qandπp
qare the probability density
function and the weight of Np
qrespectively. Q is set to 5
based on experiment on T. Given any x∈R4, our GMM is
able to provide a weighted probability density w(x)by:
wp(x) =1
QX
qπp
q×pd fp
q(x) (2)
Simply going through all xand choosing ones with high-
estwp(x)ignore overall scene layout, which might result
in significant layout changes, e.g. large bounding box on
objectless area or heavy occlusions, leading to less plausible
overall layouts. Alternatively, we narrow down our search
space to existing bounding boxes and find the optimal lo-
cation among all ln. As for R2, the victim object can be
found by n∗= arg max nwp(ln). As for R3, we rank and
select top ones depending on detailed request, e.g. choose
the top 2 if R3 is to have two objects of same target label cp.
12060
Figure 5. Overview of GLOW. The first step of GLOW aims to locate the victim object O∗under generic attack requests according to dataset
distribution. Afterwards, the GLOW produces various context-consistent attack plans, together with their consistency scores. The plan with
highest score is selected as our final attack plan ˆO∗.
We then denote the victim objects in IasO∗={l∗
p, c∗
p}∗,
where c∗
pequals to cpin R1 and R2. And {c∗
p}∗is the set of
requested target labels in R3. Similarly, l∗
pislnin R1 and
are from estimation in R2 ( ln∗) and R3. We further denote
the number of target objects as XandX= 1under R1 and
R2. Example victim objects O∗can be found in Fig. 6.
Global attack plan generation Given victim object O∗, our
next step is to generate target labels on objects that are not
victim. Specifically, it aims to find an mapping function
g(sn)∈ Cthat perturbs the label of these objects, resulting
inˆO={ln, g(sn)}n. The overall generated attack plan on
Iwould be ˆO∗={O∗,ˆO}.
Theoretically, there exist (N−X)Cpossible configu-
rations in ˆO. Instead of permuting all possible solutions,
we restrict ourselves with only feasible ones that occur in
existing dataset Tas scene layouts are naturally context-
consistent therein. To this end, we formulate our global
attack plan generation as a layout similarity measurement
problem, with hard constraint on victim objects O∗. Our
goal is therefore to map the bounding box labels according
to the best match based on layout similarity in T. Intuitively,
the more similar these layouts are, the more confident we
are in terms of performing mapping. Therefore the layout
similarity score reflects context consistency to some extent.
Our insights lie in the following design choices of obtaining
mapping function gand score s:
•Generate T∗={Tc∗p}c∗pwhere Tc∗pconsists of images
fromTwhere target label c∗
pis present.
•Compute the Intersection over Union (IoU) score between
victim objects O∗and objects that share the same target
labels in It∈ Tc∗
p, Mathematically,:
s1(It) =1
XX
l∗p∈O∗s(l∗
p) (3)
where s(l∗
p) = max m 1{c∗p=stm}IoU(l∗
p, lt
m). The IoU
score between victim object location l∗
pandm-th bounding
box in Itis obtained by IoU(l∗
p, lt
m).•Perform Hungarian matching [ 8,41] between objects in
Itand those in victim image I. Specifically, we find a
bipartite matching between these two sets by searching for
a permutation of Melements SMwith the lowest cost:
δ∗
t= arg max
δ∈SMX
ln/∈O∗Lm(ln, lt
δ(n))
= arg max
δ∈SMX
ln/∈O∗L1(ln, lt
δ(n)) +GIoU (ln, lt
δ(n))
(4)
where L1()andGIoU ()denote the L1 and GIoU [ 40]
scores between bounding boxes. δ∗
t(n)is the index of the
best match of n-th object which is not victim originally in
victim image I. And the match loss of δ∗
t(n)can be ob-
tained with s2(It) =1
N−XP
ln/∈O∗Lm(ln, lt
δ∗
t(n)). The
temporary mapping function based on the t-th image Itis
then defined as gt(sn) =st
δ∗
t(n).
The overall similarity score between It∈ T∗andIis ob-
tained by s(It) =s1(It)−λs2(It), where λis a hyper-
parameter chosen by experiment. We would like to note that
score saccounts for not only the victim objects reflecting by
s1, but also the overall layout similarity incorporated in s2.
Afterwards, we define the It∗as it 1) gives the highest
similarity score and 2) matches more than 95 %of objects
inI. Consequently, the mapping function g(sn)then equals
to the temporary mapping function of the t∗-th image, or
gt∗(sn). We refer the readers to Fig. 6 for more details.
3.3. Implementation of attack plan
To generate ˆO∗, evasion attacks can be implemented using
our victim model itself under white-box setting or a single
or multiple surrogate model(s) under zero-query black-box
setting. In white-box scenario, our implementation of attack
plan is based on TOG [ 13] so that we can perform fair com-
parisons with existing methods [ 7](see Sec. 4). Specifically,
we fix the weight of victim model fand learns a perturbation
12061
Figure 6. Step-wise illustration of GLOW. From left to right, we have victim image Iwith their initial prediction results O, target label cp
and the localized victim object O∗, best matching image It∗, the plan for other objects ˆOand our final attack plan ˆO∗.
Victim set D coco17val (3792/80) Pascal (500/20)
Victim fWhi. F F+Y
Blk. F→D F+Y→T
Victim model fis trained on and T coco17train
Table 1. Experimental setup. Our victim model is trained on
coco17train only and the victim images are from coco17val and
Pascal. The former consists of 3792 images with 80 categories
while the latter has 500 random images of 20 categories.
image δforIby minimizing L(clip(I+δ);ˆO∗)at every
iteration [ 22].clip()is enforced to ensure bounded perturba-
tion. Thereafter, the perturbed image clip(I+δ)is parsed to
another unknown victim model, mimicking the zero-query
black-box setting.
4. Experiment
To evaluate GLOW under various requests, we perform
extensive experiments on coco2017val [ 32] and Pascal [ 18],
with both white-box and black-box settings. As can be found
in Tab. 1, our victim model fcan be Faster-RCNN-R50-FPN-
1X-COCO( F) [39] and F-RCNN+YOLO( F+Y) [38] under
white-box setting. These aforementioned victim models are
later utilized as the surrogate model in our black-box attacks
where DETR( D) [8] and RetinaNet( T) [33] are our victim
models f. Our black-box attack is zero-query based, mean-
ing no feedback from victim model is available. Our GLOW
is generally applicable to different victim detectors and we
choose the aforementioned models mainly for efficiency and
re-productivity purpose [ 7]. We report our performance un-
der both perturbation budget 10 and 30. Due to the space
limitation, we refer the readers to supplementary materials
for results with the former and visualized examples. And
our claims are valid with different perturbation budgets.
Baselines We compare GLOW with four baselines. To per-
form fair comparison, attack plan implementations are all
obtained with TOG [ 13] thus we describe only the attack
plan generation process in the following:
•TOG [ 13] The attack plan generated by the TOG is context-
agnostic, or g(sn) =sn. Victim object is given in R1 andwill be randomly selected under R2 and R3.
•TOG+RAND. TOG+RAND. focuses on both victim ob-
jects and other objects. Victim object is provided in R1 and
randomly selected under R2 and R3. Mapping function
g(sn)is a random permutation function.
•TOG+SAME. Attack plan generated by TOG+SAME. in-
cludes all objects. And we enforce g(sn) =cp, meaning
all objects share the same target label cp.
•Cai [ 7] can be directly apply to R1. As for R2 and R3,
Cai [ 7] firstly selects random objects as victims and then
generates the attack plan.
Evaluation Metrics We follow the basic metric from [ 6] and
also introduce others for generic attack requests. Fooling
rate ( F) [6] is used to evaluate the attack performance on
victim objects. Specifically, one attack succeeds if (1) victim
object is perturbed as target label while IOU is score greater
than 0.3 compared to GT and (2) it pass the co-occurrence
check. And we define the fooling rate as the percentage of
the number of test cases for which the above two conditions
are satisfied. Besides, we further introduce Tto measure the
consistency on victim objects. Titself reveals the averaged
wp(l∗
p). When combined with other metrics, Tis satisfied as
long as the averaged wp(l∗
p)is above 0.02 (see Sec. 3.2). To
measure the overall layout consistency, we introduce Rthat
reflects the percentage of images whose maximum recall
rate compared to Ais above 0.5. We further design two
metrics, EandC, on R2 and R3 to report successful rate. E
checks whether target label cpexists in predictions. While
Cfurther verify the amount of cp. One attack is successful
if both target labels and their amount satisfy the request in
R3. We refer the readers to supplementary for more details
of all metrics and give some visual examples in Fig. 7.
4.1. Main results
Attack performance on R1 We report our main results
on conventional attack request R1 in Tab. 2 where perturba-
tion budgets is set to 30. In general, we observe that under
white-box setting, our Fis comparable to existing methods
on coco, which is reasonable as this metric accounts for only
oc-occurrence matrix and both TOG+SAME and Cai [ 7] con-
sider such semantic consistency. When considering global
12062
MethodsWhite-box (coco17val/Pascal) Zero query black-box (coco17val/Pascal)
R1-5 R1-50 R1-95 R1-5 R1-50 R1-95
F F+R F F+R F F+R F F+R F F+R F F+R
TOG [13] .64/.67 .11/.16 .75/.77 .15/.22 .87/.82 .20/.27 .08/.13 .01/.04 .16/.19 .02/.08 .23/.27 .03/.13
TOG+RAND .45/.48 .06/.08 .54/.61 .08/.14 .58/.66 .07/.14 .12/.10 .01/.02 .21/.17 .03/.04 .27/.26 .04/.06
TOG+SAME .89/.52 .18/.13 .90/.68 .18/.22 .91/.75 .18/.22 .21/.10 .01/.04 .34/.22 .03 /.11 .38/.31 .03/.11
Cai [7] .86/.46 .09/.08 .87/.63 .09/.09 .90/.74 .07/.11 .18/.08 .01/.03 .29/.19 .02/.08 .34/.30 .02/.11
GLOW .85/.61 .20/.20 .87/.76 .22/.28 .89/.79 .21/.29 .21/.11 .02/.05 .30/.22 .03 /.12 .35/.33 .04 /.18
Table 2. Overall performance of R1. As described in Sec. 3.1, we have three different target labels, R1-5, R1-50 and R1-95, for each victim
object and we report the results on all of them. We highlight the best scores in bold.
Figure 7. We visualize failure and successful cases of different
evaluation metrics and their key factors under R3, where our goal
is to have two elephants in given victim image.
layout R, we observe 30 %performance improvement over
existing methods under all scenarios (R1-5, R1-50, R1-95),
reflecting that GLOW is able to fool the victim object with
more contextually consistent layout. Noticeably, our ob-
servation of 30 %averaged improvement is also valid un-
der challenging zero-query black-box setting, which further
demonstrates the transferability of our proposed attack plan
generation. Please note that results on Pascal are obtained
with victim models that trained on coco17train, which further
showcase the generality and superiority of GLOW.
There are also other interesting observations in Tab. 2.
Firstly, there exists a trend of performance improvement
over all methods when comparing R1-5, R1-50 and R1-95,
indicating the choice of target label plays an important role
in terms of performance. This trend validates our hypothesis
that far-away labels, e.g. R1-5, are harder to attack com-
pared to close-by ones, which in return proves the necessity
of systematic design on target label rather than random gen-
eration. Secondly, though TOG+SAME simply assigns all
labels of existing objects to be target label cp, it gives good
performance under F. This observation further supports our
design of more delicate consistency check metrics, e.g. R,
as co-occurrence matrix is vulnerable to such simple hacks.
Attack performance on R2 The advantages of GLOW are
more noticeable in R2 where victim object is requested to
be localized by algorithm itself rather than being provided.
There are two main observations based on Tab. 3. Firstly,
GLOW almost always beats the SOTAs in terms of all eval-
uation metrics under R2-5, R2-50 and R2-95 in white-boxsetting, e.g. about 35 %relative improvement compared to
the second best in terms of F+T andE+R under R2-5. This
observation is also valid when victim models are trained on
coco17train and tested on Pascal. Interestingly, unlike R1
where victim object is fixed among all methods, results of T
in R2 showcase that the victim object selection matters under
generic request. Though neither TOG+SAME nor Cai [ 7]
considers the overall layout consistency, the former gives
better score than the latter as it naively enforces all objects
to share the same target label and EinE+R measures only
the existence of target label. Please note that EandFare dif-
ferent. For instance, assuming layout consistency is already
satisfied, if the attack on the victim object fails but turns an-
other object into target label, it will be regarded as a success
inEbut a failure in F. GLOW, again, produces superior re-
sults by leveraging layout explicitly. Our second observation
from Tab. 3 is that GLOW has better transfer rates, such as
24%improvement compared the context-aware baseline [ 7]
and various types of random assignment under black-box
setting, which further demonstrates the benefits of utilizing
global layout in attack plan generation and the potential lim-
itations of exploiting only semantic context. We observe
the same trend that the overall performance improves when
the target label is closer to presented labels in word space,
supporting our design of various target labels.
Attack performance on R3 Results of the most challenging
request R3 are provided in Tab. 4. We kindly remind our
readers that C+R andF+T+C reflect different aspects of an
algorithm as the former does not care about specific objects
but checks both target labels and their the amount. Assuming
R3 is to have two apples in victim image and our attacks are
contextually consistent, F+T+C will be successful if only
these two victim objects are perturbed to apple. In contrast,
C+R reflects the amount of apples in perturbed images and
mismatch in numbers would lead to failure. Again, our
GLOW is a much safer choice in terms of R3 as it almost
always, or about 13 out of all 18 entries, gives the best
performance with both white-box and black-box setting.
Human analysis We report the human analysis on Pascal in
Tab. 5 and kindly ask readers to check more details in sup-
plementary. In short, humans are asked to perform pairwise
comparisons on the attacked results of the same image from
12063
MethodsWhite-box (coco17val / Pascal)
R2-5 R2-50 R2-95
T F+T E+R T F+T E+R T F+T E+R
TOG [13] .18 / .18 .31 / .38 .17 / .14 .20 / .20 .41 / .44 .24 / .21 .22 / .20 .49 / .34 .25 / .15
TOG+RAND .19 / .22 .22 / .29 .04 / .09 .18 / .18 .27 / .35 .06 / .23 .22 / .20 .32 / .34 .06 / .15
TOG+SAME .18 / .23 .45 / .35 .21 / .22 .20 / .22 .51 / .43 .20 / .27 .23 / .19 .55 / .38 .20 / .26
Cai [7] .21 / .24 .44 / .30 .11 / .10 .20 / .22 .48 / .38 .11 / .15 .24 / .19 .53 / .37 .09 / .16
GLOW .38/.35 .64 /.50 .32 /.24 .40/.35 .67 /.55 .35 /.29 .44/.33 .69 /.48 .32 /.29
Zero query black-box (coco17val / Pascal)
TOG [13] .25 / .26 .04 / .08 .01 / .04 .24 / .25 .08 / .15 .02 / .12 .28 / .21 .12 / .12 .03 / .15
TOG+RAND .20 / .28 .05 / .08 .01 / .03 .20 / .20 .08 / .12 .01 / .05 .29 / .25 .14 / .15 .03 / .07
TOG+SAME .23 / .30 .12 / .10 .02 / .06 .22 / .25 .20 / .19 .03 /.18 .27 / .26 .25 / .17 .05/ .16
Cai [7] .26 / .37 .10 / .09 .02 / .07 .25 / .26 .15 / .12 .02 / .13 .30 / .21 .20 / .14 .02 / .18
GLOW .37/.38 .17 /.14 .03 /.10 .38/.35 .22 / .18 .04/ .15 .44/.38 .29 /.23 .05 /.19
Table 3. Overall performance of R2. Similar to R1, we have three different target labels for victim image. Since the victim object location is
not provided in R2, T,F+T andE+R reflects different aspects of layout consistency.
MethodsWhite-box (coco17val / Pascal)
R3-5 R3-50 R3-95
T F+T+C C+R T F+T+C C+R T F+T+C C+R
TOG [13] .18 / .21 .35 / .28 .10 / .05 .19 / .15 .43 / .37 .13 /.16 .22 / .19 .50 / .35 .14/.17
TOG+RAND .18 /.30 .27 / .24 .08 / .05 .19 / .20 .33 / .32 .11 / .16 .22 / .19 .38 / .31 .12 / .16
TOG+SAME .18 / .23 .14 / .16 .11 / .06 .20 / .21 .15 / .18 .12 / .14 .22 / .19 .17 / .16 .12 / .17
Cai [7] .20 / .25 .17 / .10 .02 / .02 .21 / .24 .22 / .16 .02 / .06 .23 / .22 .21 / .13 .02 / .04
GLOW .32/ .28 .48/ .27 .13/.07 .34/.28 .52 / .35 .15/ .12 .35/.27 .53 /.37 .14 / .11
Zero query black-box (coco17val / Pascal)
TOG [13] .21 / .32 .01 / .01 .00 / .01 .21 / .23 .03 / .03 .01 / .03 .28 / .26 .04/.04 .02 /.05
TOG+RAND .22 / .31 .01 / .01 .00 / .01 .21 / .21 .02 / .03 .01 / .03 .28 / .25 .04/.04 .01 / .04
TOG+SAME .21 / .32 .01 / .01 .00 / .01 .22 / .23 .02 / .01 .01 / .04 .27 / .25 .03 / .03 .02/.05
Cai [7] .25 / .35 .01 / .01 .00 / .01 .25 / .31 .01 / .00 .01 / .01 .30 / .27 .02 / .02 .00 / .03
GLOW .31/.38 .02 /.02 .01 /.02 .34/.38 .04 / .02 .01 / .02 .37/.36 .04 /.04 .01 / .03
Table 4. Overall performance of R3. Compared to R2, our C+R accounts for both layout consistency and amount restriction.
Methods TOG [13] [13]+RAND [13]+SAME Cai [7] GLOW
TOG [13] - .71 .59 .30 .24
[13]+RAND .43 - .25 .18 .14
[13]+SAME .52 .77 - .35 .18
Cai [7] .69 .79 .61 - .42
GLOW .78 .89 .80 .70 -
Table 5. Human analysis on Pascal under R2-5. We colored results
under white and black settings in red and blue respectively. For
instance, the bottom-left 0.78 means that 78% of GLOW results
are voted to be better than TOG [13] by humans.
two methods. We observe that our method outperforms all
methods significantly in Tab. 5, proving that it gives superior
layout-consistent attacks. Such observation is also consis-
tent with our evaluation metrics, indicating that these metrics
provide reasonable estimations of layout consistency.5. Conclusion
In this paper, we propose a novel attack generation algo-
rithm GLOW for adversarial attacks on detectors. Compared
to existing work, it explicitly takes both semantic context
and geometric layout into consideration. By validating on
two datasets, we demonstrate that GLOW produces supe-
rior performances under both conventional attack request
and more generic ones where victim objects are obtained
by estimation. In addition, we would like to highlight that
GLOW demonstrates better transfer rates under challenging
zero-query black-box setting.
6. Acknowledgement
This work was supported in part by the National Natural
Science Foundation of China (No. 62125201, 62020106007).
12064
References
[1]Ehud Barnea and Ohad Ben-Shahar. Exploring the bounds of
the utility of context for object detection. In Proceedings of
theIEEE/CVF Conference onComputer Vision andPattern
Recognition, pages 7412–7420, 2019. 2
[2]Amy Bearman, Olga Russakovsky, Vittorio Ferrari, and Li
Fei-Fei. What’s the point: Semantic segmentation with point
supervision. In European conference oncomputer vision ,
pages 549–565. Springer, 2016. 2, 3
[3]Sean Bell, C Lawrence Zitnick, Kavita Bala, and Ross
Girshick. Inside-outside net: Detecting objects in con-
text with skip pooling and recurrent neural networks. In
Proceedings oftheIEEE conference oncomputer vision and
pattern recognition, pages 2874–2883, 2016. 2
[4]Navaneeth Bodla, Bharat Singh, Rama Chellappa, and Larry S
Davis. Soft-nms–improving object detection with one line
of code. In Proceedings oftheIEEE international conference
oncomputer vision, pages 5561–5569, 2017. 2
[5]Zhaowei Cai and Nuno Vasconcelos. Cascade r-cnn: high
quality object detection and instance segmentation. IEEE
transactions onpattern analysis andmachine intelligence , 43
(5):1483–1498, 2019. 2
[6]Zikui Cai, Shantanu Rane, Alejandro E Brito, Chengyu Song,
Srikanth V Krishnamurthy, Amit K Roy-Chowdhury, and
M Salman Asif. Zero-query transfer attacks on context-
aware object detectors. In Proceedings oftheIEEE/CVF
Conference onComputer Vision and Pattern Recognition ,
pages 15024–15034, 2022. 1, 2, 3, 4, 6
[7]Zikui Cai, Xinxin Xie, Shasha Li, Mingjun Yin, Chengyu
Song, Srikanth V Krishnamurthy, Amit K Roy-Chowdhury,
and M Salman Asif. Context-aware transfer attacks for ob-
ject detection. In Proceedings oftheAAAI Conference on
Artificial Intelligence , pages 149–157, 2022. 1, 2, 3, 4, 5, 6,
7, 8
[8]Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas
Usunier, Alexander Kirillov, and Sergey Zagoruyko. End-
to-end object detection with transformers. In European
conference oncomputer vision , pages 213–229. Springer,
2020. 2, 5, 6
[9]Nicholas Carlini and David Wagner. Adversarial exam-
ples are not easily detected: Bypassing ten detection meth-
ods. In Proceedings ofthe10th ACM workshop onartificial
intelligence andsecurity, pages 3–14, 2017. 2
[10] Anirban Chakraborty, Manaar Alam, Vishal Dey, Anu-
pam Chattopadhyay, and Debdeep Mukhopadhyay. Ad-
versarial attacks and defences: A survey. arXiv preprint
arXiv:1810.00069, 2018. 3
[11] Xinlei Chen and Abhinav Gupta. Spatial memory for context
reasoning in object detection. In Proceedings oftheIEEE
international conference oncomputer vision , pages 4086–
4096, 2017. 1
[12] Zhe Chen, Shaoli Huang, and Dacheng Tao. Context refine-
ment for object detection. In Proceedings oftheEuropean
conference oncomputer vision (ECCV) , pages 71–86, 2018.
2[13] Ka-Ho Chow, Ling Liu, Margaret Loper, Juhyun Bae,
Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei, and
Yanzhao Wu. Adversarial objectness gradient attacks in
real-time object detection systems. In 2020 Second IEEE
International Conference onTrust, Privacy andSecurity in
Intelligent Systems andApplications (TPS-ISA) , pages 263–
272. IEEE, 2020. 2, 5, 6, 7, 8
[14] Navneet Dalal and Bill Triggs. Histograms of oriented gradi-
ents for human detection. In 2005 IEEE computer society
conference oncomputer vision and pattern recognition
(CVPR’05), pages 886–893. Ieee, 2005. 1, 2
[15] Jacob Devlin, Rabih Zbib, Zhongqiang Huang, Thomas
Lamar, Richard Schwartz, and John Makhoul. Fast and
robust neural network joint models for statistical machine
translation. In proceedings ofthe52nd annual meeting ofthe
Association forComputational Linguistics (V olume 1:Long
Papers), pages 1370–1380, 2014. 2
[16] Santosh K Divvala, Derek Hoiem, James H Hays, Alexei A
Efros, and Martial Hebert. An empirical study of context
in object detection. In 2009 IEEE Conference oncomputer
vision and Pattern Recognition , pages 1271–1278. IEEE,
2009. 1
[17] Yinpeng Dong, Fangzhou Liao, Tianyu Pang, Hang Su, Jun
Zhu, Xiaolin Hu, and Jianguo Li. Boosting adversarial attacks
with momentum. In Proceedings oftheIEEE conference on
computer vision andpattern recognition , pages 9185–9193,
2018. 2
[18] M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I.
Williams, J. Winn, and A. Zisserman. The pascal visual object
classes challenge: A retrospective. International Journal of
Computer Vision, 111(1):98–136, 2015. 2, 6
[19] Pedro Felzenszwalb, David McAllester, and Deva Ramanan.
A discriminatively trained, multiscale, deformable part model.
In2008 IEEE conference oncomputer vision andpattern
recognition, pages 1–8. Ieee, 2008. 1, 2
[20] Carolina Galleguillos, Andrew Rabinovich, and Serge Be-
longie. Object categorization using co-occurrence, location
and appearance. In 2008 IEEE Conference onComputer
Vision andPattern Recognition, pages 1–8. IEEE, 2008. 1
[21] Ross Girshick. Fast r-cnn. In Proceedings oftheIEEE
international conference oncomputer vision , pages 1440–
1448, 2015. 2
[22] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
Explaining and harnessing adversarial examples. arXiv
preprint arXiv:1412.6572, 2014. 2, 6
[23] Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-
rahman Mohamed, Navdeep Jaitly, Andrew Senior, Vincent
Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neu-
ral networks for acoustic modeling in speech recognition: The
shared views of four research groups. IEEE Signal processing
magazine, 29(6):82–97, 2012. 2
[24] Jan Hosang, Rodrigo Benenson, and Bernt Schiele. Learn-
ing non-maximum suppression. In Proceedings ofthe
IEEE conference oncomputer vision andpattern recognition ,
pages 4507–4515, 2017. 2
[25] Shengnan Hu, Yang Zhang, Sumit Laha, Ankit Sharma, and
Hassan Foroosh. Cca: Exploring the possibility of contex-
tual camouflage attack on object detection. In 2020 25th
12065
International Conference onPattern Recognition (ICPR) ,
pages 7647–7654. IEEE, 2021. 2
[26] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Im-
agenet classification with deep convolutional neural networks.
Communications oftheACM, 60(6):84–90, 2017. 2
[27] L’ubor Ladick `y, Paul Sturgess, Karteek Alahari, Chris Rus-
sell, and Philip HS Torr. What, where and how many? com-
bining object detectors and crfs. In European conference on
computer vision, pages 424–437. Springer, 2010. 2
[28] Maosen Li, Cheng Deng, Tengjiao Li, Junchi Yan, Xinbo
Gao, and Heng Huang. Towards transferable targeted attack.
InProceedings oftheIEEE/CVF conference oncomputer
vision andpattern recognition, pages 641–649, 2020. 3
[29] Qizhang Li, Yiwen Guo, and Hao Chen. Practical no-
box adversarial attacks against dnns. Advances inNeural
Information Processing Systems, 33:12849–12860, 2020. 3
[30] Yuezun Li, Daniel Tian, Ming-Ching Chang, Xiao Bian, and
Siwei Lyu. Robust adversarial perturbation on deep proposal-
based models. arXiv preprint arXiv:1809.05962, 2018. 2
[31] Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang,
and John E Hopcroft. Nesterov accelerated gradient and
scale invariance for adversarial attacks. arXiv preprint
arXiv:1908.06281, 2019. 2
[32] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll ´ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. In
European conference oncomputer vision , pages 740–755.
Springer, 2014. 2, 6
[33] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He,
and Piotr Doll ´ar. Focal loss for dense object detection.
InProceedings oftheIEEE international conference on
computer vision, pages 2980–2988, 2017. 2, 6
[34] Xin Liu, Huanrui Yang, Ziwei Liu, Linghao Song, Hai Li, and
Yiran Chen. Dpatch: An adversarial patch attack on object
detectors. arXiv preprint arXiv:1806.02299, 2018. 2
[35] Yong Liu, Ruiping Wang, Shiguang Shan, and Xilin Chen.
Structure inference net: Object detection using scene-level
context and instance-level relationships. In Proceedings ofthe
IEEE conference oncomputer vision andpattern recognition ,
pages 6985–6994, 2018. 2
[36] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,
Dimitris Tsipras, and Adrian Vladu. Towards deep learn-
ing models resistant to adversarial attacks. arXiv preprint
arXiv:1706.06083, 2017. 2
[37] Carl Rasmussen. The infinite gaussian mixture model.
Advances inneural information processing systems , 12,
1999. 4
[38] Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali
Farhadi. You only look once: Unified, real-time object de-
tection. In Proceedings oftheIEEE conference oncomputer
vision andpattern recognition, pages 779–788, 2016. 6
[39] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun.
Faster r-cnn: Towards real-time object detection with re-
gion proposal networks. Advances inneural information
processing systems, 28, 2015. 6
[40] Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir
Sadeghian, Ian Reid, and Silvio Savarese. Generalized in-
tersection over union: A metric and a loss for boundingbox regression. In Proceedings oftheIEEE/CVF conference
oncomputer vision andpattern recognition , pages 658–666,
2019. 5
[41] Russell Stewart, Mykhaylo Andriluka, and Andrew Y
Ng. End-to-end people detection in crowded scenes. In
Proceedings oftheIEEE conference oncomputer vision and
pattern recognition, pages 2325–2333, 2016. 5
[42] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus.
Intriguing properties of neural networks. arXiv preprint
arXiv:1312.6199, 2013. 2
[43] Zhi Tian, Chunhua Shen, Hao Chen, and Tong He. Fcos: Fully
convolutional one-stage object detection. In Proceedings of
theIEEE/CVF international conference oncomputer vision ,
pages 9627–9636, 2019. 2
[44] Xingxing Wei, Siyuan Liang, Ning Chen, and Xiaochun Cao.
Transferable adversarial attacks for image and video object
detection. arXiv preprint arXiv:1811.12641, 2018. 2
[45] Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou,
Lingxi Xie, and Alan Yuille. Adversarial examples for se-
mantic segmentation and object detection. In Proceedings of
theIEEE international conference oncomputer vision , pages
1369–1378, 2017. 1, 2
[46] Yi Yang, Sam Hallman, Deva Ramanan, and Charless
Fowlkes. Layered object detection for multi-class segmen-
tation. In 2010 IEEE Computer Society Conference on
Computer Vision andPattern Recognition , pages 3113–3120.
IEEE, 2010. 2
[47] Jian Yao, Sanja Fidler, and Raquel Urtasun. Describing the
scene as a whole: Joint object detection, scene classifica-
tion and semantic segmentation. In 2012 IEEE conference
oncomputer vision andpattern recognition , pages 702–709.
IEEE, 2012. 2
[48] Mingjun Yin, Shasha Li, Zikui Cai, Chengyu Song, M Salman
Asif, Amit K Roy-Chowdhury, and Srikanth V Krishnamurthy.
Exploiting multi-object relationships for detecting adversarial
attacks in complex scenes. In Proceedings oftheIEEE/CVF
International Conference onComputer Vision , pages 7858–
7867, 2021. 1, 3
[49] Zhou Yu, Jun Yu, Yuhao Cui, Dacheng Tao, and Qi Tian. Deep
modular co-attention networks for visual question answering.
InThe IEEE Conference onComputer Vision andPattern
Recognition (CVPR), pages 6281–6290, 2019. 3
[50] Hantao Zhang, Wengang Zhou, and Houqiang Li. Contex-
tual adversarial attacks for object detection. In 2020 IEEE
International Conference onMultimedia andExpo (ICME) ,
pages 1–6. IEEE, 2020. 2
[51] Ji Zhang, Mohamed Elhoseiny, Scott Cohen, Walter Chang,
and Ahmed Elgammal. Relationship proposal networks. In
Proceedings oftheIEEE conference oncomputer vision and
pattern recognition, pages 5678–5686, 2017. 2
[52] Xingyi Zhou, Dequan Wang, and Philipp Kr ¨ahenb ¨uhl. Objects
as points. arXiv preprint arXiv:1904.07850, 2019. 2
[53] Xizhou Zhu, Weijie Su, Lewei Lu, Bin Li, Xiaogang
Wang, and Jifeng Dai. Deformable detr: Deformable trans-
formers for end-to-end object detection. arXiv preprint
arXiv:2010.04159, 2020. 2
12066
