HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved
Diffusion Models
Li Pang1,3,*, Xiangyu Rui2,3,*, Long Cui1,Hongzhong Wang1, Deyu Meng2,3,4, Xiangyong Cao1,3,†
1School of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China
2School of Mathematics and Statistics, Xi’an Jiaotong University, Xi’an, China
3MOEKLINNS Laboratory, Xi’an Jiaotong University, Xi’an, China
4Macao Institute of Systems Engineering, Macau University of Science and Technology, Taipa, Macao
Abstract
Hyperspectral image (HSI) restoration aims at recov-
ering clean images from degraded observations and plays
a vital role in downstream tasks. Existing model-based
methods have limitations in accurately modeling the com-
plex image characteristics with handcraft priors, and deep
learning-based methods suffer from poor generalization
ability. To alleviate these issues, this paper proposes an
unsupervised HSI restoration framework with pre-trained
diffusion model (HIR-Diff), which restores the clean HSIs
from the product of two low-rank components, i.e., the re-
duced image and the coefficient matrix. Specifically, the re-
duced image, which has a low spectral dimension, lies in
the image field and can be inferred from our improved diffu-
sion model where a new guidance function with total varia-
tion (TV) prior is designed to ensure that the reduced image
can be well sampled. The coefficient matrix can be effec-
tively pre-estimated based on singular value decomposition
(SVD) and rank-revealing QR (RRQR) factorization. Fur-
thermore, a novel exponential noise schedule is proposed
to accelerate the restoration process (about 5 ×accelera-
tion for denoising) with little performance decrease. Ex-
tensive experimental results validate the superiority of our
method in both performance and speed on a variety of HSI
restoration tasks, including HSI denoising, noisy HSI super-
resolution, and noisy HSI inpainting. The code is available
at https://github.com/LiPang/HIRDiff.
1. Introduction
Hyperspectral imaging is an advanced imaging technique
that captures and processes a large number of narrow, con-
tiguous spectral bands across the electromagnetic spectrum.
Thus Hyperspectral images (HSIs) can provide more abun-
*Equal contribution
†Corresponding author (caoxiangyong@xjtu.edu.cn)dant spatial and spectral information than natural images
and have extensive applications in various fields, e.g., agri-
culture [7, 19], mineral exploration [26, 41] and environ-
mental monitoring [22]. However, due to sensor limitations
and atmospheric interference, HSIs suffer various degener-
ation during the acquisition process, significantly impair-
ing the performance of downstream tasks. Therefore, HSI
restoration is very important for HSI applications and nu-
merous methods have emerged in the past decades.
Existing HSI restoration methods can be mainly catego-
rized into two classes, i.e. model-based approaches [50, 52,
53] and deep learning (DL)-based approaches [2, 11, 34,
37]. Model-based methods reformulate the image inverse
problem as an optimization problem which contains data fi-
delity term and regularization term. The data fidelity term
ensures that the restored image is close to the observed im-
age and the regularization term constrains the solving space
by exploiting the prior knowledge of the clean images, e.g.
low-rank and total variation property. This type of method
obtains good generalization ability but the handcraft priors
are always subjective and thus cannot fully reveal image
characteristics, leaving a large room for improvement. Ad-
ditionally, the optimization problem could be very complex,
resulting in high time costs and suboptimal solutions.
In the past decade, extensive DL-based approaches have
been proposed for HSI restoration and these methods can
learn the image structure and details from a substantial
amount of clean and degraded image pairs. Despite the
promising performance, the DL-based methods suffer from
a poor generalization problem. Besides, training deep neu-
ral networks (DNNs) requires a lot of image pairs, but
HSIs are very precious and only limited data are available
in most cases. Recently, extensive diffusion-based mod-
els have emerged for image restoration tasks such as de-
noising [18], super-resolution [5, 18, 40, 49] and inpaint-
ing [18, 28, 39, 45, 49]. Among these methods, DDRM [18]
solves linear inverse problems by performing singular value
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
3005
decomposition (SVD) of the linear degradation matrix and
performing diffusion in the spectral space with a pre-trained
diffusion model. However, the method cannot be applied di-
rectly for HSI restoration since HSIs have more bands than
natural images, and the number of bands varies in different
datasets due to different sensors. After that, DDS2M [32]
presents a self-supervised diffusion model for HSI restora-
tion, which restores HSI only using the degraded HSI and
can be adaptive to different HSI datasets. Although demon-
strating desirable HSI restoration performance and superior
generalization ability, DDS2M fails to utilize prior knowl-
edge of available datasets and takes a lot of time to complete
the self-supervised training process for each dataset.
To alleviate these issues, inspired by [38] which em-
ploys pre-trained diffusion models for pansharpening, we
propose an unsupervised HSI restoration framework with
pre-trained diffusion model (HIR-Diff). We start from the
point that HSIs can be restored from the product of two
low-rank components, i.e. the reduced image and the co-
efficient matrix, which can be estimated separately. Con-
cretely, the reduced image which has a low spectral dimen-
sion is defined as several linearly independent bands from
the HSI and can be restored using our improved diffusion
model, where we propose a new guidance function and a
novel exponential noise schedule. The guidance function
consisting of a data fidelity term and a total variation (TV)
regularization ensures that the reduced image can be better
estimated during the diffusion sampling process. The expo-
nential noise schedule can accelerate the diffusion process,
that is, it can enable the reduced image to be restored within
20 sampling steps (5 ×acceleration for denoising) with lit-
tle performance decrease. The coefficient matrix, which is
needed for the restoration of the reduced image, can be pre-
estimated from the degraded image and a predefined band
index of the reduced image without any additional informa-
tion. In this work, we resort to singular value decompo-
sition (SVD) to estimate the coefficient matrix since SVD
is noise-robust. Besides, the predefined band index of the
reduced image needs to be carefully designed so that each
band in the reduced image contains different contents and
the estimated coefficient matrix is robust to perturbations.
To this end, the ranking-revealing QR (RRQR) factoriza-
tion [12] which can identify the numerical rank of a matrix,
is adopted to determine the band selection index.
In summary, our contributions are as follows.
• We propose an unsupervised HSI restoration frame-
work with an improved diffusion model (HIR-Diff),
which recovers the clean HSIs from the product of the
reduced image and the coefficient matrix. Additionally,
a new guidance function with TV prior is designed in
the reverse sampling process of the diffusion model to
ensure the reduced image can be well sampled.
• We propose an efficient and noise-robust method to es-timate the coefficient matrix utilizing SVD and RRQR
factorization. Specifically, the RRQR is adopted to pre-
define the band index of the reduced image so that the
estimated coefficient matrix is robust to perturbations.
• We propose a novel exponential noise schedule, which
can significantly accelerate the diffusion process com-
pared with existing noise schedules (e.g., 5 ×accelera-
tion for denoising) with little performance decrease.
2. Preliminaries
2.1. Diffusion Models
Diffusion models are probabilistic generative models that
capture the underlying dynamics of data evolution over
time [14, 44]. Owing to the powerful generation ability, dif-
fusion models have gained considerable attention in various
tasks, e.g., audio and text generation [16, 20]. A typical dif-
fusion process contains a T-step forward process and a T-
step reverse process. The forward process starts with a clean
image and progressively adds noise over Tsteps, while the
reverse process operates in the opposite direction. Given a
noise scheduler {¯αt}T
t=1and a clean data x0, adding Gaus-
sian noise to x0iteratively over titerations yields
xt=√¯αtx0+ (√
1−¯αt)ϵ, ϵ∼ N(0,I). (1)
A diffusion model ϵθis trained to predict the noise as
ϵθ(xt, t)≈ϵ=xt−√¯αtx0√1−¯αt. (2)
The reverse process starts with random noise and progres-
sively refines the sample over Tsteps. Recently numerous
approaches are proposed to accelerate the sampling process
of diffusion models. A typical method is the denoising dif-
fusion implicit model (DDIM) [43], where the forward pro-
cess is modeled as non-Markovian. The model predicts the
starting point as
ˆx0=xt−(√1−¯αt)ϵθ(xt, t)√¯αt, (3)
and then xt−1is sampled as
xt−1=√¯αt−1ˆx0+ (p
1−¯αt−1)ϵθ. (4)
We adopt DDIM as the sampling method in this work since
this model can accelerate sampling without significant per-
formance degradation.
2.2. Hyperspectral Image Restoration
HSI restoration task aims to recover clean images from de-
graded observations and its degradation process is
Y=H(X) +Z, (5)
3006
Figure 1. The overall framework of the proposed HIR-Diff. First, the coefficient matrix Eis estimated from the degraded image using
SVD and RRQR. Then, taking the degraded image and the estimated matrix Eas conditions, the reduced image Ais reconstructed with
an improved pre-trained diffusion model that contains a newly designed guidance function. Finally, the clean image is restored from the
product of the estimated EandA.
where Yis the degraded image, Xis the clean HSI, His
a known degradation operation, and Zdenotes an additive
Gaussian noise. For the denoising task, His an identity
operation. For the super-resolution task, Hcontains a blur
operation and a down-sampling operation. For the inpaint-
ing task, Hdenotes a random mask.
3. Proposed Model
3.1. Notations
The scalar, vector, matrix and tensor are defined as x,x,X
andX, respectively. Given a third-order tensor X ∈
RH×W×Kand a matrix E∈RB×K, mode-3 multiplica-
tion can be defined as Y=X × 3E, resulting in a new
tensor Y ∈RH×W×B.X(3)∈RB×HWdenotes the mode-
3 unfolding of Xand is obtained by flattening the first two
dimensions of X. And fold 3(X(3))means reshaping X(3)
back to X.
3.2. Overall Framework
Due to strong spectral correlation, HSIs thus exhibit low-
rank property, which has been widely used for HSI restora-
tion [3, 13, 21]. Following this research line, we assume
that the clean HSI X ∈RH×W×Bcan be recovered as
X=A × 3E, (6)
where A ∈RH×W×Kdenotes the reduced image, E∈
RB×Kdenotes the coefficient matrix and K≪B. There-
fore, to restore the clean HSI, we first need to estimate the
reduced image Aand the coefficient matrix E. In this work,
we propose a method to separately estimate AandE. The
overall framework is illustrated in Fig. 1.
Overall, given a degraded HSI Y, we first estimate the
coefficient matrix E, which is a necessary condition for the
restoration of the reduced image A. Then, we estimate thereduced image Ausing our improved diffusion model. Ais
supposed to be a sequence of bands selected from the HSI so
that the distribution is consistent with the diffusion priors.
In other words, defining (i1, i2, ..., i K)as the band index,
Asatisfies A(3)=
xT
i1,xT
i2,···,xT
iKT, where xinde-
notes the inth row of X(3). Given a predefined band index
(i1, i2, ..., i K)of the reduced image and a degraded image
Y, the coefficient matrix Ecan be estimated by singular
value decomposition (SVD) without any additional infor-
mation. Once Eis well estimated, Acould be inferred by
applying our improved diffusion model with our newly de-
signed guidance function. Moreover, an exponential noise
schedule is also proposed to accelerate the sampling.
Although a restored image can be obtained for each pos-
sible predefined band selection index, the band index needs
to be carefully designed to ensure that each band in Acan
encode different contents, which helps to generate a more
robust estimation of Eand thus obtain better restoration re-
sults. To this end, we resort to a classical rank revealing QR
(RRQR) decomposition [12] to determine the band index.
Next, we provide a more detailed description for estimating
the coefficient matrix Eand the reduced image A.
3.3. Coefficient Matrix Estimation
3.3.1 Coefficient Matrix Estimation Using SVD
As discussed before, the coefficient matrix Eneeds to be
pre-estimated from an observed degraded image Yand a
predefined band index (i1, i2, ..., i K)without any additional
information about the reduced image Aand the clean image
X. To this end, inspired by [13], we resort to SVD to esti-
mate the coefficient matrix E. First, the matrix version of
the HSI Yis decomposed using the rank- KSVD as
YT
(3)= (US)VT, (7)
3007
where U∈RHW×K,S∈RK×KandV∈RB×K. We
define Vs=
vT
i1,vT
i2,···,vT
iKT, where vindenotes the
inth row of V. Then we can obtain
AT
Y(3)= (US)VsT, (8)
Combining Eq. (7) and Eq. (8), we have
YT
(3)=AT
Y(3)(VsT)−1VT, (9)
which is equivalent to
Y=AY×3(VV−1
s). (10)
Then we have the following remark
Remark 3.1 LetYT
(3)= (US)VTbe the rank- KSVD of
the observed HSI Y, and define Vsas the (i1, i2, ..., i K)th
rows of V. Then VV−1
sis equivalent to the expected Ein
Eq. (6) when rank Kis small.
Here we provide a rough proof for this remark. Defining
¯Y=H(X), the degraded image Ycould be regarded as ¯Y
with i.i.d. Gaussian noise. ¯Ycan be decomposed similarly
to Eq. (10), namely
¯Y=¯AY×3(¯V¯V−1
s), (11)
where ¯AYis the (i1, i2, ..., i K)th bands of ¯Y,¯Vis the right
singular vectors obtained from the SVD of ¯Yand¯Vsis the
(i1, i2, ..., i K)th rows of ¯V. Due to the favourable mathe-
matical property of the SVD, Vis an orthonormal matrix,
i.e.VTV=I. The orthogonal property encourages the
representations of Vto be more distinguishable from each
other, helping to keep the noise of V[13]. Additionally,
when Kis small, there is no significant difference between
Vand¯Vas the columns of Vindicate the directions that
capture the most significant variations in the data. There-
fore, the decomposition of ¯Ycan be rewritten as
¯Y=¯AY×3(VV−1
s), (12)
As the degradation operation His linear and is performed
in the spatial dimension, then we have
¯Y=H(X) =H(A × 3E) =H(A)×3E=¯AY×3E.
(13)
By comparing Eq. (12) and Eq. (13), it can be easily seen
that the coefficient matrix can be defined as
E=VV−1
s. (14)3.3.2 Band Index Selection Using RRQR
While the coefficient matrix could be estimated from
Eq. (14), the predefined index (i1, i2, ..., i K)of the reduced
image needs to be carefully selected so that |det(Vs)|>0
andV−1
sexists. Actually, |det(Vs)|is expected to be large
owing to the following two reasons: A larger |det(Vs)|
indicates that each band in the reduced image Aencodes
different image information, improving the HSI restoration
performance. In addition, if |det(Vs)|is small, the value
in the coefficient matrix Ecould be very large, which could
lead to numerical instability during the estimation process
of the reduced image A. To this end, a rank-revealing QR
(RRQR) algorithm proposed in [12] is employed to deter-
mine the band selection index. Using the RRQR factoriza-
tion on the matrix VTcan be decomposed as
VTΠ=QR≡
QR 1QR 2
, (15)
where Π∈RB×Bis a permutation matrix, Q∈RK×K
is an orthogonal matrix and R∈RK×Bis an upper trian-
gular matrix. The RRQR factorization algorithm works by
interchanging any pair of columns that increases sufficiently
|det(R1)|. We define VT
sasQR 1and then we could ob-
tain|det(Vs)|=|det(R1)|. Therefore, when the algo-
rithm terminates, |det(Vs)|is maximized and the indices
corresponding to the first Kcolumns of the permuted ma-
trixVTΠcan be defined as the band selection index. The
choice of selection index could not cause |det(Vs)|to be
too large, which could also result in numerical instability.
Concretely, from Hadamard’s inequality [9], we have
|det(Vs)| ≤KY
i=1∥vsi∥2, (16)
where vsiis the ith column of Vs. Since each column vin
matrix Vsatisfies ∥v∥2= 1, we have ∥vsi∥2≤ ∥vi∥2= 1
and|det(Vs)| ≤1.
3.4. Conditional Denoising Diffusion Model
With the pre-estimated coefficient matrix Eand a prede-
fined band index, we employ a pre-trained diffusion model
to estimate the reduced image A. Recently, emerging ap-
proaches [1, 6, 8] are proposed for image generation with
various conditions utilizing a pre-trained diffusion model.
In general, given a condition or a guidance y, these ap-
proaches model pθ(xt−1|xt,y)during the reverse sampling
process by introducing gradient on ϵθas
ˆϵθ(xt, t) =ϵθ(xt, t) +s(t)· ∇xtL(ˆx0,y), (17)
where s(t)denotes the guidance strength in the tth step and
Ldenotes a loss function which measures the distance be-
tween the current predicted ˆx0and the expected image. In
our case, taking the degraded image Yand the pre-estimated
3008
Algorithm 1: HIR-Diff Method
Input: ATsampled from N(0, I), diffusion model
ϵθ, noise scales {¯αt}T
t=1, guidance strength
s(t), loss function L, degraded HSI Y,
estimated coefficient E
Output: Clean HSI X0
fort=T, T−1,···1do
step 1: estimate ˆA0by Eq. (19)
step 2: calculate L(ˆA0,E,Y)by Eq. (21)
step 3: estimate ˆϵθ(At, t)by Eq. (18)
step 4: sample At−1by Eq. (20)
end
X0=A0×3E
return X0
coefficient matrix Eas conditions, we employ diffusion
models to estimate the reduced image Aas shown in Fig. 1.
Specifically, Eq. (17) can be rewritten as
ˆϵθ(At, t) =ϵθ(At, t) +s(t)· ∇AtL(ˆA0,E,Y),(18)
where ˆA0is estimated by Eq.(3) as
ˆA0=At−(√1−¯αt)ϵθ(At, t)√¯αt. (19)
ThenAt−1is sampled from Eq. (1) as
At−1=√¯αt−1ˆA0+ (p
1−¯αt−1)ˆϵθ(At, t). (20)
The loss function L(ˆA0,E,Y)proposed in our work con-
tains a data fidelity term and a TV regularization. The
data fidelity term ensures that the predicted image closely
matches the observed data. The TV term that has been
widely adopted in HSI restoration [35, 36, 48] contributes to
denoising and edge preservation. Specifically, the guidance
function L(ˆA0,E,Y)is defined as
L(ˆA0,E,Y) =λ∥H(ˆA0×3E)− Y∥2
F+β∥ˆA0×3E∥TV,
(21)
where λandβare hyperparameters. The proposed method
is summarized in Algorithm 1. When diffusion sampling
finishes, the restored HSI X0is represented as A0×3E.
3.5. Exponential Noise Schedule
We found that when the widely used linear noise sched-
ule [14] and the cosine noise schedule [33] are used, the
Peak Signal-to-Noise Ratio (PSNR) value of the restored
image fluctuates drastically at the beginning and does not
converge at the end of the sampling process, as shown in
Fig. 2. Increasing the sampling steps or improving the
strength of the guide does not alleviate the problem. One
Figure 2. (a) The ¯αtin the linear schedule, cosine schedule and
our proposed exponential schedule. (b) The PSNR values through-
out the diffusion process with different noise schedules. Linear
schedule (*) and cosine schedule (*) denote the results when the
guidance strength is enhanced.
possible reason is that with the guidance information as il-
lustrated in Eq. (17), the noise rapidly decays at the be-
ginning of the sampling process since the diffusion pro-
cess starts with random noise while the conditional image
contains abundant image details. It can be observed from
Eq. (1) that the noise schedule ¯αtreflects how much infor-
mation is contained in the current sample. Therefore, the
¯αtis supposed to increase rapidly at the beginning, which
is inconsistent with the linear schedule and cosine schedule.
Besides, the PSNR value increases rapidly at the end of the
sampling process, indicating that a larger ¯αthelps to refine
the image details and achieve the local optimum at the end.
During this stage, the diffusion prior progressively works to
generate a desirable image. Therefore, we design a different
noise schedule in terms of ¯αtas
¯αt=e−kt/T, t= 1,2,···, T, (22)
¯αt=¯αt−min{¯αt}T
t=1
max{¯αt}T
t=1−min{¯αt}T
t=1×(1−ϵ) +ϵ,(23)
t= 1,2,···, T. (24)
where kis a hyperparamter and ϵis a small value to pre-
vent ˆα0from being zero. Our exponential noise schedule
increases rapidly at the beginning and changes slowly at the
end so that the random noise can converge to the observed
image rapidly and the image details can be well refined.
Remark: It should be noted that our improved diffusion
model modifies DDIM in two aspects, i.e. the proposed
exponential noise schedule and the designed guidance func-
tion introduced in Sec. 3.4, and thus providing better sample
quality and faster sampling speed. The effectiveness of the
two modifications will be discussed in Sec. 4.5.
4. Experiment
4.1. Datasets and Evaluation Metrics
We evaluate the HSI restoration performance on three pub-
licly available datasets, namely Washington DC (WDC)
3009
Mall1whose size is 1208×307×191, Houston2whose
size is 349×1905×144, and Salinas3whose size is
512×217×224. For each dataset, we crop the center area
and remove some noisy bands, deriving three HSIs with size
256×256×191,256×256×124and128×128×190,
respectively. Two commonly used evaluation metrics, i.e.
peak signal-to-noise ratio (PSNR) and structure similarity
(SSIM), are adopted to evaluate the performance.
4.2. Competing Methods
HSI Denoising: The HSI denoising aims at recovering
the clean HSI from its noisy observation. We mainly con-
sider Gaussian noise, and the standard deviation of Gaus-
sian noise σin the range of [0, 255] is set as 30, 50, and
70, respectively. Three model based methods including
BM4D [31], NGMeet [13], ETPTV [4], four deep learn-
ing based methods including T3SC [2], MACNet [51],
SST [23], SERT [24] and an unsupervised deep learning
based methods (i.e. DDS2M [32]) are adopted for compar-
ison. For the DL-based methods, we use available models4
trained on ICVL5with Gaussian noise for comparison.
Noisy HSI Super-Resolution: The noisy HSI super-
resolution aims at recovering the clean HSI from a noisy
low-resolution observation. Specifically, the low-resolution
image is obtained by first spatially blurring the clean im-
age using a Gaussian-shape filter, then downsampling the
blurred image and finally adding the image with Gaussian
noise with σ= 30 . Seven methods, including two un-
supervised deep learning based methods, i.e. DIP2d [42]
and DIP3d [42], and five supervised deep learning based
methods, i.e. SFCSR [46], SSPSR [17], MCNet [25],
RFSR [47], PDENet [15] are adopted for comparison. Since
the pre-trained model is not available, we train all the super-
vised models on CA VE6with the setting proposed in [46].
Noisy HSI Inpainting: The noisy HSI inpainting aims
at recovering the clean HSI from noisy and incomplete
data. Concretely, we randomly mask a portion of pix-
els and add the Gaussian noise ( σ= 30 ) to the observed
area. The mask rate is set as 0.7, 0.8 and 0.9, respec-
tively. Four model-based methods (i.e. TRPCA [27],
TRLRF [52], S2NTNN [30] and HLRTF [29]) and three un-
supervised DL-based methods (i.e. DIP2d [42], DIP3d [42]
and DDS2M [32]) are adopted for comparison.
1http://lesun.weebly.com/hyperspectral- data-
set.html
2https://hyperspectral.ee.uh.edu/?page_id=459
3https : / / www . ehu . eus / ccwintco / index . php /
Hyperspectral_Remote_Sensing_Scenes
4https://github.com/MyuLi/SERT
5https://icvl.cs.bgu.ac.il/hyperspectral/
6https://www.cs.columbia.edu/CAVE/databases/
multispectral/4.3. Implementation Details
A pre-trained diffusion model7trained on a large amount of
3-channel (i.e. RGB) remote sensing images [10] is used to
generate the reduced image A. The diffusion sampling step
Tis set as 20 for all the HSI restoration tasks. All DL-based
models are trained on an NVIDIA Geforce RTX 3090 GPU.
Table 1. The average quantitative results for HSI denoising. The
best and second-best values are highlighted.
standard deviation 30 50 70Time (s)Dataset Method PSNR SSIM PSNR SSIM PSNR SSIM
WDC mallBM4D 37.09 0.90 34.48 0.83 32.81 0.77 286
NGMeet 43.77 0.98 41.07 0.96 39.82 0.94 65
ETPTV 41.08 0.95 37.12 0.91 35.15 0.87 629
T3SC 38.70 0.92 37.04 0.88 35.94 0.86 3
SST 39.09 0.93 37.24 0.90 36.19 0.87 5
SERT 38.98 0.93 37.08 0.89 35.90 0.86 5
DDS2M 41.58 0.95 39.13 0.93 38.83 0.92 3132
Ours 42.85 0.97 40.77 0.94 39.33 0.92 17
HoustonBM4D 33.89 0.84 31.83 0.77 30.57 0.72 184
NGMeet 38.50 0.94 35.77 0.89 34.36 0.85 62
ETPTV 35.78 0.90 33.75 0.84 32.47 0.80 322
T3SC 35.74 0.90 33.91 0.85 32.75 0.81 3
SST 36.26 0.92 34.19 0.87 32.87 0.83 6
SERT 36.11 0.91 33.96 0.86 32.58 0.82 4
DDS2M 35.64 0.91 33.44 0.85 31.96 0.79 1813
Ours 38.13 0.94 36.01 0.90 34.56 0.86 25
SalinasBM4D 38.62 0.91 35.96 0.86 34.23 0.82 68
NGMeet 44.76 0.98 42.23 0.96 40.96 0.95 16
ETPTV 42.52 0.95 40.44 0.93 38.03 0.91 91
T3SC 41.06 0.95 39.47 0.94 38.36 0.92 3
SST 38.93 0.94 37.51 0.92 36.39 0.91 4
SERT 38.80 0.94 37.26 0.92 36.07 0.90 3
DDS2M 43.29 0.96 40.05 0.93 38.10 0.90 846
Ours 43.79 0.96 41.95 0.95 39.48 0.93 13
4.4. Results for HSI Restoration
The results of different methods on HSI denoising, noisy
HSI super-resolution and noisy HSI inpainting are demon-
strated in Table 1, Table 2 and Table 3, respectively. It
can be seen that our proposed method demonstrates supe-
rior HSI restoration performance compared to other com-
petitive models. Compared with model-based approaches
(e.g., BM4D and ETPTV) which highly rely on handcraft
priors, the pre-trained diffusion model employed in our
method is able to capture complex intrinsic characteris-
tics and image details from abundant data. The supervised
DL-based methods suffer limited generalization ability and
struggle with the restoration task of unseen data. In con-
trast, our model demonstrates desirable generalization abil-
ity as the employed diffusion model learns the image struc-
ture and details in a self-supervised manner, which enables
the model to be competitive for various tasks and datasets.
In addition, prior knowledge including low rank and total
variation is introduced in our model, which helps to regular-
ize the restoration process and thus obtain better restoration
7https://github.com/wgcban/ddpm-cd
3010
results. Moreover, other unsupervised DL-based methods,
e.g., DIP2d, DIP3d and DDS2M, take lots of time to ex-
ploit the image inherent structure with an untrained neural
network for each individual dataset, while our method ben-
efitting from self-supervised training is considerably more
efficient and fast. Some visual results for different tasks
are shown in Fig. 3, from which it can be observed that our
method can restore more accurate and reliable visual results.
Table 2. The average quantitative results for noisy HSI super-
resolution. The best and second-best values are highlighted.
Scale ×2 ×4 ×8Time (s)Dataset Method PSNR SSIM PSNR SSIM PSNR SSIM
WDC mallDIP2d 32.18 0.58 31.62 0.57 29.92 0.53 206
DIP3d 31.81 0.57 32.05 0.58 30.10 0.51 16644
SFCSR 33.74 0.71 32.92 0.66 31.85 0.58 6
SSPSR 33.32 0.71 32.38 0.66 30.63 0.55 6
MCNet 34.55 0.74 33.55 0.69 31.76 0.59 22
RFSR 33.70 0.72 32.73 0.66 31.06 0.56 15
PDENet 29.79 0.64 28.78 0.57 29.28 0.55 16
Ours 36.67 0.81 34.68 0.74 32.20 0.60 22
HoustonDIP2d 27.67 0.61 27.61 0.61 27.15 0.60 178
DIP3d 27.72 0.61 27.67 0.61 27.29 0.60 4841
SFCSR 29.90 0.69 29.00 0.65 27.35 0.60 5
SSPSR 29.99 0.72 29.12 0.67 27.49 0.61 5
MCNet 30.52 0.72 29.60 0.68 28.03 0.62 16
RFSR 30.27 0.71 29.22 0.66 27.64 0.62 10
PDENet 28.83 0.60 28.06 0.56 27.71 0.58 11
Ours 31.83 0.78 30.68 0.72 29.10 0.65 28
SalinasDIP2d 36.29 0.88 34.35 0.84 30.72 0.75 85
DIP3d 35.24 0.86 34.60 0.85 32.34 0.82 1866
SFCSR 35.63 0.87 34.42 0.86 32.15 0.82 4
SSPSR 33.71 0.86 32.40 0.84 30.08 0.79 5
MCNet 36.01 0.89 35.13 0.87 32.47 0.82 10
RFSR 35.26 0.87 34.02 0.85 31.59 0.81 12
PDENet 31.45 0.70 30.52 0.67 31.14 0.75 8
Ours 39.44 0.91 37.53 0.88 34.48 0.82 14
4.5. Ablation Study
Reduced Image Estimation In our work, an HSI is re-
stored from a reduced image Awhich is supposed to be
several bands, and a corresponding coefficient matrix E.
Nevertheless, there exists other alternative tensor decom-
position methods to restore an HSI. One of them is directly
defining the Vmatrix obtained from SVD as the coefficient
matrix E, and employing the diffusion model to restore the
”pseudo” image A=fold3(US). Another solution [38]
is that the coefficient matrix Eis estimated by solving a
least square problem with several observed noisy bands, and
thenAis estimated from the diffusion model. The defini-
tion of these decomposition strategies is inconsistent with
the diffusion prior or is susceptible to noise, leading to poor
restoration results. The HSI restoration results of different
decomposition strategies on WDC dataset are illustrated in
Table 4 and Fig. 4. Our method demonstrates superior HSI
restoration performance as the SVD operation effectively
suppresses noise and the definition of the tensor Alies in
the image field, which is consistent with the diffusion prior.Table 3. The average quantitative results for noisy HSI inpainting.
Thebest and second-best values are highlighted.
Masking Rate 0.7 0.8 0.9Time (s)Dataset Method PSNR SSIM PSNR SSIM PSNR SSIM
WDC mallTRPCA 22.29 0.23 22.72 0.22 23.30 0.22 346
TRLRF 22.03 0.27 20.61 0.19 11.79 0.03 1000
S2NTNN 35.64 0.80 33.70 0.73 31.03 0.62 32
HLRTF 37.03 0.85 36.07 0.82 34.08 0.72 160
DIP2d 31.55 0.57 31.54 0.57 30.71 0.56 50
DIP3d 31.47 0.57 31.90 0.57 31.69 0.57 12876
DDS2M 38.32 0.91 36.18 0.85 32.35 0.71 4920
Ours 37.90 0.87 36.82 0.83 35.08 0.76 17
HoustonTRPCA 22.13 0.21 22.46 0.21 22.84 0.22 175
TRLRF 21.16 0.20 19.11 0.13 13.32 0.04 768
S2NTNN 31.01 0.76 28.08 0.67 24.48 0.46 16
HLRTF 30.82 0.77 29.92 0.72 28.53 0.65 57
DIP2d 26.45 0.59 26.35 0.58 26.19 0.58 48
DIP3d 26.51 0.59 26.28 0.58 26.12 0.58 3037
DDS2M 31.91 0.81 30.05 0.73 29.13 0.67 2638
Ours 32.42 0.82 31.19 0.78 29.67 0.72 20
SalinasTRPCA 22.67 0.18 23.30 0.20 23.96 0.23 79
TRLRF 22.75 0.19 20.42 0.13 13.09 0.03 324
S2NTNN 37.74 0.88 34.14 0.75 26.79 0.61 11
HLRTF 33.97 0.79 33.40 0.78 32.56 0.77 31
DIP2d 34.71 0.86 33.65 0.84 32.15 0.82 41
DIP3d 33.76 0.85 33.04 0.83 31.77 0.81 1274
DDS2M 40.49 0.94 38.23 0.91 36.80 0.89 1354
Ours 40.70 0.94 39.40 0.92 37.61 0.90 16
Table 4. The HSI restoration results of different tensor decompo-
sition methods. ”SVD Only” denotes that the tensor Ais defined
as the pseudo image of SVD and ”Least Square” denotes that the
matrixEis estimated by solving the least square problem.
Task Denoising Super-Resolution Inpainting
Methods PSNR SSIM PSNR SSIM PSNR SSIM
SVD Only 28.88 0.55 27.86 0.43 28.16 0.44
Least Square 37.53 0.89 34.37 0.73 35.55 0.79
Ours 40.73 0.94 34.79 0.74 37.02 0.85
Table 5. The HSI restoration results of different band selection
indexes. (·,·,·)∗denotes the bands selected using our method.
Task Bands |det(Vs)|The Maximum
Value in EPSNR
Denoising(1, 48, 96) 0.000681 7.91 27.85
(37, 84, 132) 0.001427 5.86 28.00
(73, 120, 168) 0.000068 11.57 18.40
(21,31,60)∗0.011500 1.01 44.27
Super-Resolution(1, 48, 96) 0.000195 24.86 11.02
(37, 84, 132) 0.000566 10.28 20.41
(73, 120, 168) 0.000193 12.58 9.96
(22,33,58)∗0.012835 1.00 39.68
Inpainting(1, 48, 96) 0.001308 3.11 34.54
(37, 84, 132) 0.000617 16.07 9.93
(73, 120, 168) 0.000007 47.34 6.51
(21,34,58)∗0.014779 1.00 41.02
Coefficient Matrix Estimation As introduced in
Sec. 3.3, we employ RRQR to determine the band selection
index (i1, i2, ..., i K). The HSI restoration results on Salinas
dataset of several indexes selected at equal intervals are
3011
Figure 3. The visual result comparison of all the competing methods on the HSI restoration task.
Figure 4. The reduced image Aestimated by different methods.
Ground Truth denotes the bands selected from the clean HSI.
Table 6. Ablation study of the proposed guidance function.
Data Fidelity
TermTV Regularization
TermDenoising Super-Resolution Inpainting
PSNR SSIM PSNR SSIM PSNR SSIM
✗ ✗ 10.12 0.07 11.49 0.16 11.13 0.08
✓ ✗ 34.99 0.87 27.10 0.45 29.90 0.67
✓ ✓ 36.14 0.90 30.70 0.72 31.71 0.80
provided in Table 5 to prove the necessity of RRQR. As
can be observed, due to the low-rank property of HSIs, the
determinant of Vscould be extremely small, indicating
a high similarity between the selected bands and thus
resulting in large values in Eand numerical instability. In
contrast, the bands selected using our method encode more
abundant information and provide desirable results.
Guidance Function The results of different guidance
functions are provided in Table 6. As can be seen, the ab-
sence of any condition leads to the worst performance since
the model becomes a pure generative model. In addition,
the TV regularization adopted in our work contributes to
the improvement of restoration performance, verifying the
effectiveness of our proposed guidance function.Noise Schedule The results of different noise schedules
are shown in Table 7. The restoration performance is im-
proved with our exponential schedule and declines much
slower when the number of sampling step decreases since
there are more effective steps as introduced in Sec. 3.5.
Table 7. The HSI restoration results of different noise schedules.
TaskStep×T 20 50 100
Schedule PSNR SSIM PSNR SSIM PSNR SSIM
DenoisingLinear 34.34 0.86 35.18 0.88 35.70 0.89
Cosine 34.61 0.86 35.46 0.88 35.86 0.89
Exponential 36.01 0.90 36.10 0.90 36.14 0.90
Super-ResolutionLinear 29.47 0.66 30.01 0.68 30.39 0.70
Cosine 30.25 0.70 30.45 0.70 30.56 0.71
Exponential 30.68 0.72 30.69 0.72 30.70 0.72
InpaintingLinear 29.96 0.70 30.86 0.74 31.44 0.77
Cosine 30.17 0.71 31.07 0.76 31.46 0.77
Exponential 31.19 0.78 31.65 0.79 31.71 0.80
5. Conclusion
In this paper, we propose an unsupervised HSI restoration
approach. Using the low-rank property of HSIs, the clean
HSI can be restored by the product of a reduced image and
a coefficient matrix. Specifically, the coefficient matrix can
be pre-estimated from the observed image using SVD and
Rank-Revealing QR (RRQR), and the reduced image can be
estimated from the pre-trained diffusion model with a newly
designed guidance function. Additionally, the proposed ex-
ponential noise schedule has been proven to be more rea-
sonable for our conditional diffusion model and can sig-
nificantly accelerate the sampling process. Our proposed
method is a universal HSI restoration framework and can
perform better than other state-of-the-art methods on vari-
ous HSI restoration tasks.
Acknowledgement This research was supported by National
Key R&D Program of China (2021ZD0112902) and China NSFC
Projects (62272375, 12226004).
3012
References
[1] Arpit Bansal, Hong-Min Chu, Avi Schwarzschild,
Soumyadip Sengupta, Micah Goldblum, Jonas Geip-
ing, and Tom Goldstein. Universal guidance for diffusion
models. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition , pages 843–852,
2023. 4
[2] Th ´eo Bodrito, Alexandre Zouaoui, Jocelyn Chanussot, and
Julien Mairal. A trainable spectral-spatial sparse coding
model for hyperspectral image restoration. Advances in Neu-
ral Information Processing Systems , 34:5430–5442, 2021. 1,
6
[3] Xiangyong Cao, Qian Zhao, Deyu Meng, Yang Chen, and
Zongben Xu. Robust low-rank matrix factorization under
general mixture noise distributions. IEEE Transactions on
Image Processing , 25(10):4677–4690, 2016. 3
[4] Yang Chen, Wenfei Cao, Li Pang, Jiangjun Peng, and Xi-
angyong Cao. Hyperspectral image denoising via texture-
preserved total variation regularizer. IEEE Transactions on
Geoscience and Remote Sensing , 2023. 6
[5] Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune
Gwon, and Sungroh Yoon. Ilvr: Conditioning method for
denoising diffusion probabilistic models. arXiv preprint
arXiv:2108.02938 , 2021. 1
[6] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L
Klasky, and Jong Chul Ye. Diffusion posterior sam-
pling for general noisy inverse problems. arXiv preprint
arXiv:2209.14687 , 2022. 4
[7] Laura M Dale, Andr ´e Thewis, Christelle Boudry, Ioan Ro-
tar, Pierre Dardenne, Vincent Baeten, and Juan A Fern ´andez
Pierna. Hyperspectral imaging applications in agriculture
and agro-food product quality and safety control: A review.
Applied Spectroscopy Reviews , 48(2):142–159, 2013. 1
[8] Ben Fei, Zhaoyang Lyu, Liang Pan, Junzhe Zhang, Weidong
Yang, Tianyue Luo, Bo Zhang, and Bo Dai. Generative dif-
fusion prior for unified image restoration and enhancement.
InProceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 9935–9946, 2023. 4
[9] David JH Garling. Inequalities: a journey into linear analy-
sis. Cambridge University Press, 2007. 4
[10] Wele Gedara Chaminda Bandara, Nithin Gopalakrish-
nan Nair, and Vishal M Patel. Remote sensing change detec-
tion (segmentation) using denoising diffusion probabilistic
models. arXiv e-prints , pages arXiv–2206, 2022. 6
[11] Zhaori Gong, Nannan Wang, De Cheng, Xinrui Jiang, Jing-
wei Xin, Xi Yang, and Xinbo Gao. Learning deep resonant
prior for hyperspectral image super-resolution. IEEE Trans-
actions on Geoscience and Remote Sensing , 60:1–14, 2022.
1
[12] Ming Gu and Stanley C Eisenstat. Efficient algorithms for
computing a strong rank-revealing qr factorization. SIAM
Journal on Scientific Computing , 17(4):848–869, 1996. 2, 3,
4
[13] Wei He, Quanming Yao, Chao Li, Naoto Yokoya, and Qibin
Zhao. Non-local meets global: An integrated paradigm for
hyperspectral denoising. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition ,
pages 6868–6877, 2019. 3, 4, 6
[14] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu-
sion probabilistic models. Advances in Neural Information
Processing Systems , 33:6840–6851, 2020. 2, 5
[15] Jinhui Hou, Zhiyu Zhu, Junhui Hou, Huanqiang Zeng, Jin-
jian Wu, and Jiantao Zhou. Deep posterior distribution-based
embedding for hyperspectral image super-resolution. IEEE
Transactions on Image Processing , 31:5720–5732, 2022. 6
[16] Rongjie Huang, Max WY Lam, Jun Wang, Dan Su, Dong Yu,
Yi Ren, and Zhou Zhao. Fastdiff: A fast conditional diffu-
sion model for high-quality speech synthesis. arXiv preprint
arXiv:2204.09934 , 2022. 2
[17] Junjun Jiang, He Sun, Xianming Liu, and Jiayi Ma. Learn-
ing spatial-spectral prior for super-resolution of hyperspec-
tral imagery. IEEE Transactions on Computational Imaging ,
6:1082–1096, 2020. 6
[18] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming
Song. Denoising diffusion restoration models. Advances
in Neural Information Processing Systems , 35:23593–23606,
2022. 1
[19] Sami Khanal, Kushal Kc, John P Fulton, Scott
Shearer, and Erdal Ozkan. Remote sensing in agricul-
ture—accomplishments, limitations, and opportunities.
Remote Sensing , 12(22):3783, 2020. 1
[20] Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and
Bryan Catanzaro. Diffwave: A versatile diffusion model for
audio synthesis. arXiv preprint arXiv:2009.09761 , 2020. 2
[21] Damien Letexier and Salah Bourennane. Noise removal from
hyperspectral images by multidimensional filtering. IEEE
Transactions on Geoscience and Remote Sensing , 46(7):
2061–2069, 2008. 3
[22] Jun Li, Yanqiu Pei, Shaohua Zhao, Rulin Xiao, Xiao Sang,
and Chengye Zhang. A review of remote sensing for envi-
ronmental monitoring in china. Remote Sensing , 12(7):1130,
2020. 1
[23] Miaoyu Li, Ying Fu, and Yulun Zhang. Spatial-spectral
transformer for hyperspectral image denoising. In Proceed-
ings of the AAAI Conference on Artificial Intelligence , pages
1368–1376, 2023. 6
[24] Miaoyu Li, Ji Liu, Ying Fu, Yulun Zhang, and Dejing Dou.
Spectral enhanced rectangle transformer for hyperspectral
image denoising. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
5805–5814, 2023. 6
[25] Qiang Li, Qi Wang, and Xuelong Li. Mixed 2d/3d convolu-
tional network for hyperspectral image super-resolution. Re-
mote Sensing , 12(10):1660, 2020. 6
[26] Lei Liu, Jun Zhou, Dong Jiang, Dafang Zhuang, Lamin R
Mansaray, and Bing Zhang. Targeting mineral resources
with remote sensing and field data in the xiemisitai area, west
junggar, xinjiang, china. Remote Sensing , 5(7):3156–3171,
2013. 1
[27] Canyi Lu, Jiashi Feng, Yudong Chen, Wei Liu, Zhouchen
Lin, and Shuicheng Yan. Tensor robust principal component
analysis with a new tensor nuclear norm. IEEE Transactions
on Pattern Analysis and Machine Intelligence , 42(4):925–
938, 2019. 6
3013
[28] Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher
Yu, Radu Timofte, and Luc Van Gool. Repaint: Inpainting
using denoising diffusion probabilistic models. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 11461–11471, 2022. 1
[29] Yisi Luo, Xi-Le Zhao, Deyu Meng, and Tai-Xiang Jiang.
Hlrtf: Hierarchical low-rank tensor factorization for inverse
problems in multi-dimensional imaging. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 19303–19312, 2022. 6
[30] Yi-Si Luo, Xi-Le Zhao, Tai-Xiang Jiang, Yi Chang,
Michael K Ng, and Chao Li. Self-supervised nonlinear
transform-based tensor nuclear norm for multi-dimensional
image recovery. IEEE Transactions on Image Processing ,
31:3793–3808, 2022. 6
[31] Matteo Maggioni, Vladimir Katkovnik, Karen Egiazarian,
and Alessandro Foi. Nonlocal transform-domain filter for
volumetric data denoising and reconstruction. IEEE Trans-
actions on Image Processing , 22(1):119–133, 2012. 6
[32] Yuchun Miao, Lefei Zhang, Liangpei Zhang, and Dacheng
Tao. Dds2m: Self-supervised denoising diffusion spatio-
spectral model for hyperspectral image restoration. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 12086–12096, 2023. 2, 6
[33] Alexander Quinn Nichol and Prafulla Dhariwal. Improved
denoising diffusion probabilistic models. In International
Conference on Machine Learning , pages 8162–8171. PMLR,
2021. 5
[34] Li Pang, Weizhen Gu, and Xiangyong Cao. Trq3dnet: A
3d quasi-recurrent and transformer based network for hy-
perspectral image denoising. Remote Sensing , 14(18):4598,
2022. 1
[35] Jiangjun Peng, Qi Xie, Qian Zhao, Yao Wang, Leung Yee,
and Deyu Meng. Enhanced 3dtv regularization and its ap-
plications on hsi denoising and compressed sensing. IEEE
Transactions on Image Processing , 29:7889–7903, 2020. 5
[36] Jiangjun Peng, Hailin Wang, Xiangyong Cao, Xinling Liu,
Xiangyu Rui, and Deyu Meng. Fast noise removal in hyper-
spectral images via representative coefficient total variation.
IEEE Transactions on Geoscience and Remote Sensing , 60:
1–17, 2022. 5
[37] Xiangyu Rui, Xiangyong Cao, Qi Xie, Zongsheng Yue, Qian
Zhao, and Deyu Meng. Learning an explicit weighting
scheme for adapting complex hsi noise. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 6739–6748, 2021. 1
[38] Xiangyu Rui, Xiangyong Cao, Zeyu Zhu, Zongsheng Yue,
and Deyu Meng. Unsupervised pansharpening via low-rank
diffusion model. arXiv preprint arXiv:2305.10925 , 2023. 2,
7
[39] Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee,
Jonathan Ho, Tim Salimans, David Fleet, and Mohammad
Norouzi. Palette: Image-to-image diffusion models. In
ACM SIGGRAPH 2022 Conference Proceedings , pages 1–
10, 2022. 1
[40] Chitwan Saharia, Jonathan Ho, William Chan, Tim Sal-
imans, David J Fleet, and Mohammad Norouzi. Imagesuper-resolution via iterative refinement. IEEE Transactions
on Pattern Analysis and Machine Intelligence , 45(4):4713–
4726, 2022. 1
[41] Hojat Shirmard, Ehsan Farahbakhsh, R Dietmar M ¨uller, and
Rohitash Chandra. A review of machine learning in pro-
cessing remote sensing data for mineral exploration. Remote
Sensing of Environment , 268:112750, 2022. 1
[42] Oleksii Sidorov and Jon Yngve Hardeberg. Deep hyper-
spectral prior: Single-image denoising, inpainting, super-
resolution. In Proceedings of the IEEE/CVF International
Conference on Computer Vision Workshops , pages 0–0,
2019. 6
[43] Jiaming Song, Chenlin Meng, and Stefano Ermon.
Denoising diffusion implicit models. arXiv preprint
arXiv:2010.02502 , 2020. 2
[44] Yang Song and Stefano Ermon. Generative modeling by esti-
mating gradients of the data distribution. Advances in Neural
Information Processing Systems , 32, 2019. 2
[45] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-based
generative modeling through stochastic differential equa-
tions. arXiv preprint arXiv:2011.13456 , 2020. 1
[46] Qi Wang, Qiang Li, and Xuelong Li. Hyperspectral im-
age superresolution using spectrum and feature context.
IEEE Transactions on Industrial Electronics , 68(11):11276–
11285, 2020. 6
[47] Xinya Wang, Jiayi Ma, and Junjun Jiang. Hyperspectral im-
age super-resolution via recurrent feedback embedding and
spatial–spectral consistency regularization. IEEE Transac-
tions on Geoscience and Remote Sensing , 60:1–13, 2021. 6
[48] Yao Wang, Jiangjun Peng, Qian Zhao, Yee Leung, Xi-Le
Zhao, and Deyu Meng. Hyperspectral image restoration via
total variation regularized low-rank tensor decomposition.
IEEE Journal of Selected Topics in Applied Earth Observa-
tions and Remote Sensing , 11(4):1227–1243, 2017. 5
[49] Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-shot im-
age restoration using denoising diffusion null-space model.
arXiv preprint arXiv:2212.00490 , 2022. 1
[50] Fengchao Xiong, Jun Zhou, and Yuntao Qian. Hyperspec-
tral restoration via l0gradient regularized low-rank tensor
factorization. IEEE Transactions on Geoscience and Remote
Sensing , 57(12):10410–10425, 2019. 1
[51] Fengchao Xiong, Jun Zhou, Qinling Zhao, Jianfeng Lu, and
Yuntao Qian. Mac-net: Model-aided nonlocal neural net-
work for hyperspectral image denoising. IEEE Transactions
on Geoscience and Remote Sensing , 60:1–14, 2021. 6
[52] Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao, and
Qibin Zhao. Tensor ring decomposition with rank minimiza-
tion on latent space: An efficient approach for tensor com-
pletion. In Proceedings of the AAAI Conference on Artificial
Intelligence , pages 9151–9158, 2019. 1, 6
[53] Hongyan Zhang, Wei He, Liangpei Zhang, Huanfeng Shen,
and Qiangqiang Yuan. Hyperspectral image restoration using
low-rank matrix recovery. IEEE Transactions on Geoscience
and Remote Sensing , 52(8):4729–4743, 2013. 1
3014
