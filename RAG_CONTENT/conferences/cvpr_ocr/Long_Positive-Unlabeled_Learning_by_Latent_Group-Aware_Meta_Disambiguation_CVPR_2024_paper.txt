Positive-Unlabeled Learning by Latent Group-Aware Meta Disambiguation
Lin Long1*Haobo Wang1∗Zhijie Jiang1Lei Feng2Chang Yao1†Gang Chen1Junbo Zhao1
1Zhejiang University, China2Singapore University of Technology and Design, Singapore
{llong, wanghaobo, zjjjj882, changy, cg, j.zhao }@zju.edu.cn, lfengqaq@gmail.com
Abstract
Positive-Unlabeled (PU) learning aims to train a bi-
nary classifier using minimal positive data supplemented
by a substantially larger pool of unlabeled data, in the spe-
cific absence of explicitly annotated negatives. Despite its
straightforward nature as a binary classification task, the
currently best-performing PU algorithms still largely lag
behind the supervised counterpart. In this work, we iden-
tify that the primary bottleneck lies in the difficulty of de-
riving discriminative representations under unreliable bi-
nary supervision with poor semantics, which subsequently
hinders the common label disambiguation procedures. To
cope with this problem, we propose a novel PU learn-
ing framework, namely Latent Group- Aware Meta Dis-
ambiguation ( LaGAM ), which incorporates a hierarchi-
cal contrastive learning module to extract the underlying
grouping semantics within PU data and produce compact
representations. As a result, LaGAM enables a more ag-
gressive label disambiguation strategy, where we enhance
the robustness of training by iteratively distilling the true
labels of unlabeled data directly through meta-learning.
Extensive experiments show that LaGAM significantly out-
performs the current state-of-the-art methods by an aver-
age of 6.8% accuracy on common benchmarks, approach-
ing the supervised baseline. We also provide compre-
hensive ablations as well as visualized analysis to verify
the effectiveness of our LaGAM. The code is available at
https://github.com/llong-cs/LaGAM .
1. Introduction
The remarkable success of deep learning can be largely at-
tributed to the availability of comprehensively annotated
data which provides valid supervision. However, the ne-
cessity for high-quality labeled data is not always feasible
in many scenarios [21, 39, 50]. A real-world case lies in the
medical field [50], where the application of deep learning
for diagnosing certain chronic diseases can be challenging
*Joint first authors.
†Corresponding author.
Very-MildMildModerateNonMRI Image-LevelHippocampal AtrophyWhite Matter LesionsEntricularEnlargementPathogenesis-LevelDiagnosis-LevelPositiveNegativeClassification BoundaryFigure 1. Illustration for hierarchical Alzheimer’s Disease diag-
nosis with brain MRI. Given an MRI image ( 1stLevel), firstly we
need to identify any suspicious structural changes and match them
with typical lesion characteristics of AD. ( 2ndLevel). The final
diagnosis ( 4thLevel) will then be given based on a comprehensive
assessment of the number and severity of symptoms ( 3rdLevel).
due to the scarcity of diagnosed (positive) samples available
for training. While data from a larger population of undiag-
nosed individuals are more accessible, they are all “unla-
beled” for possibly being either diseased or healthy. Such
label ambiguity will hamper effective model training.
Addressing this issue, Positive- Unlabeled (PU) learn-
ing has been increasingly studied in recent years [2]. PU
learning refers to a specific binary classification task where
only a limited amount of positive samples are explicitly
labeled but all other instances are unlabeled[30, 32]. A
popular strategy for PU learning is to cast it as a cost-
sensitive classification task through importance reweight-
ing [12, 13, 26, 43]. For instance, Self-PU [10] pioneers
meta-learning to diminish the influence of false negatives.
Despite the promising results, samples being “filtered out”
are actually not being effectively utilized for model train-
ing. Another set of works tries to select reliable negative
(or positive) samples from the unlabeled set to construct a
pseudo-binary labeled set [10, 29, 32, 43]. However, the
selection results are not always precise, which may lead to
confirmation bias or accumulated error [18, 49, 51].
While most previous studies target at straight label dis-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
23138
ambiguation, there always seems to be a dilemma where
model generalizability and supervision intensity cannot be
simultaneously ensured, making PU learning still largely
lag behind the fully supervised counterpart nowadays.
Carefully looking into this trade-off, we spot that the pri-
mary bottleneck actually lies in the difficulty of develop-
ing discriminative representations under the constraints of
unreliable binary labels. In other words, insufficient super-
vision is provided by the ambiguous yet semantically poor
binary labels . Meanwhile, we observe that in real-world PU
scenarios, the binary classes generally originate from finer-
grained categories. For example, as Figure 1 shows, the di-
agnosis of Alzheimer’s Disease (AD) can be idealized as an
inductive process, where it is the underlying pathogenesis
that provides a more concrete representation of a patient.
Following this intuition, we propose a novel PU learn-
ing framework, namely LatentGroup- Aware Meta Dis-
ambiguation ( LaGAM ), to produce compact representa-
tions which encapsulate the intrinsic group semantics of
PU data. To achieve this goal, we introduce a hierarchi-
cal contrastive learning module based on three guidelines:
(i)-alignment with unsupervised prototypes to achieve latent
group awareness; (ii)-refinement with dichotomized cut-off
for enhanced binary prediction; (iii)-unification between lo-
cal neighbors for further smoothness. Visual representa-
tions in Figure 5 validate that LaGAM does evolve the abil-
ity to distinguish valid latent categories. Moreover, based
on the reliable representations, LaGAM integrates a meta-
disambiguation objective, with which we iteratively refine
the pseudo-labels of unlabeled samples, enabling the train-
ing of a robust binary classifier. Extensive experiments on
four benchmark datasets show that LaGAM surpasses the
current state-of-the-art by an average of 6.8%accuracy.
Particularly for AD recognition 2, LaGAM has a significant
advantage of 6.1%, indicating its practicability.
Our main contributions can be summarized as follows:
•(Insights) This study represents a pioneering effort in the
semantic analysis of PU data within real-world contexts,
addressing the bottleneck of representation learning using
unreliable binary labels with a lack of semantics.
•(Methodology) We propose LaGAM, leveraging a group-
aware contrastive learning objective to explore the latent
categories beyond binary labels and meta-learning to re-
fine the labels of unlabeled data for label disambiguation.
•(Experiments) We conduct extensive experiment to show
that our LaGAM outperforms the current state-of-the-art,
approaching the supervised learning counterpart.
2. Related Work
Positive-Unlabeled (PU) Learning. The existing PU
learning algorithms primarily fall into two categories. The
current mainstream adopts the framework of cost-sensitive
learning, the key of which is decomposing the naive binaryclassification risk into individual risks over positive and un-
labeled data respectively, to correct the bias derived from
negativity estimation. uPU [12, 13] first proposes the unbi-
ased risk estimator of PU learning, with follow-up works
like nnPU [26], ImbPU [42] and Self-PU [10] trying to
improve this technique from different aspects. Notably,
most of these methods are established on the Selected Com-
pletely at Random (SCAR) assumption [15] and greatly rely
on the knowledge of class prior, which rarely hold in prac-
tice. To mitigate such limitations, works like PUSB [24],
bPU [3, 24, 41] and aPU [17] manage to relax the prerequi-
sites to more general settings. Correspondingly, there also
emerges some class prior estimation algorithms, including
PE [14], Pen-L1 [14], KM1, KM2 [37] and TIcE [1].
The second type of PU learning algorithm is based on
sample selection[32, 52]. As the name suggests, the ba-
sic idea of this type of method is to select reliable in-
stances from the unlabeled set, followed by traditional
(semi-)supervised algorithms. The early studies mainly fo-
cus on exploiting various heuristic strategies for negative
sample selection, such as 1-DNF [35, 51, 52], Naive Bayes
[32], Rocchio extraction [29], kNN [53] and k-means [7].
Recent studies like PUbN [22], GenPU [20], PULNS [33]
and PAN [23] leverage auxiliary models for sample iden-
tification or generation. Meanwhile, VPU [23], MixPUL
[47] and P3MIX [28] adopt mixup technique to refine the
imprecise supervision.
Contrastive Learning. As a promising paradigm of self-
supervised learning, contrastive learning (CL) [19, 45] has
been frequently used for learning discriminative representa-
tion with the absence of manually annotated data [9, 19, 45].
The essence of contrastive learning is to find a feature space
wherein positive pairs are drawn closer together while nega-
tive pairs are pushed apart. To this end, most of the existing
algorithms differ in the specific ways to construct this sort
of data pairs. One commonly used pretext task treats each
instance as a class and constructs positive pairs through dif-
ferent data augmentations [9, 19, 48], which is also known
as Instance Discrimination (ID). There are also methods
using the clustering results to guide the pair construction
[5, 31], which proves to be especially effective for latent
group recognition.
Meta-Learning. Meta-learning [16, 34], i.e. learning to
learn better, has recently emerged as an effective framework
for weakly-supervised tasks including noisy label disam-
biguation [10, 38, 40] and semi-supervised learning [36].
The existing methods generally contain two loops of learn-
ing: an inner loop, where virtual training on meta-model
occurs, and an outer loop, which optimizes the evaluation
loss w.r.t. meta-parameters. Most of these methods rely on
a golden support set for evaluating the meta-model, and to
23139
correct the biased training labels by adjusting their impor-
tance weights [38, 40].
3. Notations and Preliminaries
Positive-Unlabeled Learing. Letx∈Rdandybe the in-
put feature and binary label, respectively. Following [28],
we specify the positive instances with y= 1and the nega-
tive ones with y= 0. Under PU setting, the training dataset
Dtrainis composed of a positive set P={(xi, yi= 1)}np
i=1,
and an unlabeled set U={(xi)}np+nu
i=np+1with pseudo-labels
˜y, where npandnurefer to the number of positive and un-
labeled samples, respectively. The target of PU learning is
to train a binary classifier f(x) :Rd7→[0,1]parameterized
byθ, with training set Dtrain=P ∪ U , where the loss can be
denoted as Lcls(D, θ) =1
|D|P
(xi,yi)∈Dℓ(fθ(xi), yi).ℓ(·)
can be arbitrary loss like Binary Cross-Entropy (BCE):
ℓ(fθ(xi), yi)=−[yilogfθ(xi)+(1−yi) log(1 −fθ(xi))].
(1)
Contrastive Learning. In this paper, we resemble [19,
25] to construct a basic framework of contrastive learning,
where the per-sample contrastive loss can be defined as:
ℓcont(x,P)=−1
|P(x)|X
k+∈P(x)logeq·k+/τ
P
ki∈A\{q}eq·ki/τ,(2)
where qis the embedding of xandτis the temperature.
Arefers to a set that contains all contrastive embeddings.
The essence of contrastive learning is to align the represen-
tations of similar samples as defined by positive set P(x),
and to separate the dissimilar ones. In addition to Instance
Discrimination (ID) [9, 19, 48], where we let P(x)consist
of the embeddings from different augmentations of x, there
are many other ways to construct the positive set. Each of
them offers a unique definition of similarity, allowing the
model to learn different semantics via contrastive learning.
4. Method
To tackle the PU problem, LaGAM encapsulates (i)-a hier-
archical contrastive learning module to improve the repre-
sentation quality, and (ii)-a meta-disambiguation objective
to refine the noisy labels. Next, we will describe these two
components in detail.
4.1. Latent Group-Aware Representation Learning
As mentioned earlier, data representation plays a critical
part in PU learning, the quality of which directly determines
the effect of upper-level label disambiguation. Based on
our observation, the binary class in PU learning generally
encompasses finer-grained sub-categories, where there ex-
ists some mappings between the underlying groups and the
(iii)-LocalNeighborSmoothing(i)-UnsupervisedClusteringLocal Neighbor RegionCluster Region
PositiveSampleNegativeSample
(ii)-DichotomizedCutoff
Cluster PrototypeFigure 2. Overview of the hierarchical contrastive learning frame-
work. The arrows indicate the samples’ moving direction in the
latent space guided by Lcont, where samples are: (i)-converged to-
wards the cluster centers; (ii)-separated from the binary boundary;
and (iii)-aggregated within the local neighbor regions.
highly abstracted binary labels. Motivated by this, we re-
sort to a hierarchical contrastive learning objective, which
actively explores the latent groups that reflect the essential
semantics of PU data. Though contrastive learning has been
extensively studied for representation learning in recent lit-
erature, the PU setting posits unique challenges for adapt-
ing this technique, which mainly lies in two aspects.
Challenge 1: How to find the latent groups? Without ex-
plicit labels, constructing a positive set that can guide the
model to distinguish samples from different latent groups is
not as straightforward. To this, we generate pseudo-positive
pairs based on unsupervised clustering. Specifically, we ap-
plyk-means [7] clustering in the embedding space on Dtrain
at the beginning of each epoch, yielding kcluster centers:
C(x) :Rd7→ {1,2, . . . , k }, (3)
where C(x)maps an input xto one of the kcluster centers.
We use Scluster(x)to represent a set that consists of the em-
beddings of all samples belonging to the same cluster center
asx. In this way, we artificially define a series of latent cat-
egories and thus can construct a positive set that encourages
closely aligned representations of samples from the same
latent group. In other words, we facilitate the spontaneous
organization of data according to latent groups by manip-
ulating features, which leads to better separability between
those (potentially) semantically distinct data in the embed-
ding space.
Challenge 2: How do the latent groups enhance the bi-
nary prediction? Considering that unsupervised cluster-
ing might yield some inaccurate results that will mislead
the model’s learning, regular alignment between the latent
categories and the given binary labels is necessary. There-
23140
y(t-1)∆y(t-1)y(t)
𝜃(t-1)Meta LossEval Lossℒclsℒcont𝜃′(t-1)𝜃(t-1)𝜃(t)TNFNFPTPVirtual TrainFigure 3. Illustration of the meta-disambiguation process.
fore, we cut off those mis-clustered pairs according to the
dichotomized outputs of the classifier, restricting the latent
categories to be semantically binarizable. Specifically, two
samples from the same cluster are considered as a positive
pair only if they carry the same predicted label. Similarly,
we use Sbinary(x)to represent a set that consists of the em-
beddings of all samples that have the same label as x. With
this extra constraint, we effectively mitigate the risk of con-
firmation bias caused by incorrect clustering.
Furthermore, we also adopt data-driven neighbor aug-
mentation based on kNN[53], which helps to distribute the
representations more smoothly within local neighborhoods.
The Latent Group-Aware (LGA) positive set can thus be:
PLGA(x)= (Scluster(x)∩ S binary(x))∪ S neighbor (x),(4)
where Sneighbor (x)refers to a set consists of the knearest
neighbors of x. The overall contrastive objective that com-
bines the losses of Instance Discrimination (ID) and Latent
Group-Awareness can thus be formulated as:
Lcont(D,θ)=1
|D|X
(xi,yi)∈D[ℓcont(xi,PID)+ℓcont(xi,PLGA)].
(5)
4.2. Meta Label Disambiguation
Recalling the trade-off arising between model generaliz-
ability and supervision intensity, though meta-learning has
already demonstrated powerful capabilities in sample-wise
tuning [10] (with the cost of only a small golden support set
consisting of a few labeled samples), it still relies on im-
portance reweighting to achie label disambiguation, where
the sample utilization rate is sacrificed. However, the en-
hanced representations attained through our proposed hi-
erarchical contrastive learning enable the model to better
comprehend the relationships between PU data and their bi-
nary labels, which may allow more aggressive label disam-
biguation with direct label refinement .
Meta Objective for Disambiguation. Before label dis-
ambiguation, we first set ˜yto0by default, i.e., assuming
all unlabeled data are negative. In contrast to Self-PU[10]
which employs meta-learning for sample reweighting, wewould like to directly distill the true labels of unlabeled data
through meta-learning. Formally, we define the following
objective function, using a bi-level optimization structure
of meta-learning:
˜y∗= arg min
˜yLcls(Dsup, θ(˜y)) (6)
s.t.θ(˜y) = arg min
θLcls(Dtrain, θ). (7)
That is, in the inner loop (7), we first acquire model pa-
rameters θ(˜y)that minimize the supervised loss over train-
ing data pseudo-labeled with ˜y, which will then be eval-
uated on the support set Dsup. To this, in the outer loop
(6) we minimize the evaluation loss w.r.t. the pseudo-labels
˜y. Intuitively, the closer ˜yaligns with the ground-truth,
the less label ambiguity there is, and thus the model trained
with it is supposed to exhibit better generalizability on the
golden support set. In this way, label disambiguation can
be transformed into an optimization problem of minimizing
the evaluation loss to obtain ˜y∗. The corresponding classi-
fier trained with ˜y∗will be our target model.
Online Disambiguation. However, from Eq. (6)(7) we
can observe that, the calculation of ˜y∗requires two nested
loops of optimization, each of which can be very expensive.
Therefore, inspired by [10, 38, 40], we iteratively adapt an
online ˜yand alternate minimization between the inner and
outer loop, gradually converging towards the ground-truth
labels. Specifically, the online optimization comprises two
main steps: Label-Update andActual-Training .
At the stage of Label-Update , we try to align ˜ywith the
label distribution of Dsup, which is considered to be clean
and unbiased. Specifically, consider the tthiteration, we
first perform a one-step “virtual” update on the model pa-
rameters with the given training mini-batch Btrain:
θ′(t)(˜y) =θ(t)−λ∇θLcls(Btrain, θ)|θ=θ(t), (8)
where λis the learning rate. θ′(t)(˜y)can be considered as
a reasonable approximation for the optimal model parame-
ter obtained with ˜y. Being “virtually” trained with ˜y, the
generalizability of the meta-model fθ′(t)can also reflect the
correctness of the current ˜yto some extent.
Therefore, we then calculate the gradients of the evalu-
ation loss of fθ′(t)on the support set Dsup, w.r.t. ˜y, which
indicates the direction of label update towards higher model
generalizability and thus better ˜y:
δ(t)=−∇ ˜yLcls(Dsup, θ′(t)(˜y))
˜y=˜y(t), (9)
where ˜y(t)refers to the values of pseudo-labels at time step
t. However, we empirically found that direct gradient de-
scent yields poor performance possibly due to the bias from
23141
negativity estimation [43]. To mitigate this issue, we instead
use the projected gradients together with the Exponential
Moving Average (EMA) for label updating:
s(t)
i=(
1, δ(t)
i≥0,
0, δ(t)
i<0,(10)
˜y(t+1)=ϵ˜y(t)+ (1−ϵ)s(t), (11)
where ϵ∈[0,1)is the EMA parameter for controlling the
evolving speed of pseudo-labels ˜y, to ensure label consis-
tency among different time steps. Simply speaking, we first
map each element in δ(t)to{0,1}, through which we drop
the magnitude information of the gradient, retaining only
the direction information. This together with the introduc-
tion of the EMA updating strategy significantly increases
the model’s tolerance for bias and thus enhances its robust-
ness. Particularly, when ϵis set to 0, a replacement strat-
egy is adopted rather than momentum stepping, which pro-
vides stronger yet less consistent supervision signals. We
further study the effect of different updating strategies in
Section 5.3. With each update, ˜yis getting more and more
accurately annotated, i.e., towards the direction that leads
to better generalizability, and thus can be better utilized for
subsequent training of a robust binary classifier. For bet-
ter understanding, we elaborate our theoretical insights of
this debiased learning procedure from an influence function
perspective in Appendix B.
Next, for the Actual-Training of the classifier, we opti-
mize θto fit the pseudo-labels ˜y(t+1)using a binary clas-
sification loss Lclscoupled with the contrastive loss Lcont:
θ(t+1)=θ(t)−λ∇θ[Lcls(Btrain, θ)+βLcont(Btrain, θ)]|θ=θ(t),
(12)
where βis a weighting parameter.
Alternatively updating ˜yandθ, we iteratively approach
the optimal solution together with the distillation of ˜y. The
detailed procedure can be referred to in the Appendix.
5. Experiment
5.1. Experimental Settings
Datasets. In the experiments, we employ two prevalent
benchmark datasets, CIFAR-10 [27] and STL-10 [11]. Ad-
ditionally, we extend the setup in [8, 26] to CIFAR-100
[27], which contains more sub-categories, for evaluating the
model’s performance on data with more complex distribu-
tions. For each dataset, we divide its category labels (which
range from 0to9for CIFAR-10 and STL-10, and 0to19for
the superclasses of CIFAR-100) into two disjoint subsets of
comparable sizes, and generate two synthetic PN datasets
by specifying one of them as positive set. Particularly for
CIFAR-100, we instead use two different partitions: oneis balanced and the other is imbalanced, to examine the
performance of LaGAM under different class distributions.
Following [28], for each dataset, we uniformly select 1000
positive instances from the training set to be labeled, and
split500instances from the validation set to form the sup-
port set. To show that LaGAM not only works on the con-
trived datasets, we also evaluate its performance with the
real-world Alzheimer dataset1for Alzheimer’s Disease di-
agnosis [56], which doesn’t contain explicitly given latent
categories. Detailed statistics are given in Appendix C.
Baselines. To verify the effectiveness of LaGAM, we uti-
lize 8 PU learning baselines, including uPU [12, 13], nnPU
[26], Self-PU [10], PAN [23], VPU [23], Dist-PU [56],
and two versions of P3MIX [28], together with the super-
vised counterpart for comparison. For all baselines, we
unify the backbone used for each dataset. Specifically, we
adopt 7-layer CNN for CIFAR-10 and STL-10, and 13-
layer CNN and ResNet-50 for more complex CIFAR-100
and Alzheimer, respectively [56]. Furthermore, to show the
superiority of LaGAM in terms of learning capacity brought
by the representation learning module, we also conduct ex-
periments replacing the backbone with deeper ResNet-18
and comparing our LaGAM with the current SOTA Dist-
PU and P3MIX-C under the same setup. Note that the cost-
sensitive based methods including uPU[13], nnPU[26] and
Self-PU[10], require prior knowledge of class proportion,
which is however unknown for STL-10 wherein many train-
ing samples are naturally unlabeled. Addressing this prob-
lem, following the work of P3MIX [28], we use the current
SOTA KM2 [37] to estimate the class proportion of STL-10.
Implementation Details. Considering that the effect of
meta-disambiguation largely relies on the quality of repre-
sentations, the early introduction of meta-learning when the
representation space is not yet in shape may lead to poor
performance. Therefore, we disable meta-disambiguation
and warm up the model with Eq. (12) for the first 20epochs.
Empirically, we find that warm-up significantly improves
the model’s performance and the convergence rate. More-
over, to accelerate the calculation of second-order gradients
involved in Eq. (6)(7), all layers of the classifier except for
the classification head are frozen during meta-learning. Sur-
prisingly, we found that not only does it make the training
process significantly faster, but it also leads to higher con-
verged accuracy, possibly due to the mitigation of the nega-
tive interference of meta-disambiguation on representation
learning. Besides, we linearly ramp down the EMA param-
eterϵfrom 0.95to0.8, to allow the label updating to be
more conservative at the beginning, and switch to a larger
step size as the training trajectory gradually stabilizes. We
1https://www.kaggle.com/datasets/tourist55/alzheimers-dataset-4-
class-of-images
23142
Backbone Method CIFAR-10-1 CIFAR-10-2 CIFAR-100-1 CIFAR-100-2 STL-10-1 STL-10-2
CNNuPU 76.5±2.5 71.6 ±1.4 90.2 ±0.2 64.2 ±1.7 76.7 ±3.8 78.2 ±4.1
nnPU 84.7±2.4 83.7 ±0.6 63.2 ±1.3 68.1 ±2.1 77.1 ±4.5 80.4 ±2.7
Self-PU 85.1±0.8 83.9 ±2.6 87.1 ±2.9 68.4 ±1.4 78.5 ±1.1 80.8 ±2.1
PAN 87.0±0.3 82.8 ±1.0 75.6 ±1.8 66.6 ±1.4 77.7 ±2.5 79.8 ±1.4
VPU 86.8±1.2 82.5 ±1.1 90.1 ±0.1 50.0 ±0.1 78.4 ±1.1 82.9 ±0.7
Dist-PU 86.8±0.7 87.2 ±0.9 69.2 ±2.4 72.9 ±0.6 79.8 ±0.6 82.9 ±0.4
P3MIX-E 88.2±0.4 84.7 ±0.5 87.3 ±1.3 54.9 ±1.6 80.2 ±0.9 83.7 ±0.7
P3MIX-C 88.7±0.4 87.9 ±0.5 88.1 ±0.9 52.9 ±1.2 80.7 ±0.7 84.1±0.3
LaGAM (ours) 89.6±0.4 90.6±0.8 92.6±0.7 85.9±0.1 87.5±0.3 81.9±1.5
Supervised 91.3±0.3 91.3 ±0.3 93.5 ±0.5 91.9 ±0.4 - -
ResNetDist-PU 88.8±0.8 88.9 ±0.7 65.8 ±2.3 69.1 ±0.7 81.7 ±1.6 83.4 ±1.5
P3MIX-C 76.1±0.6 74.9 ±0.6 88.5 ±1.3 51.4 ±1.1 71.1 ±0.9 72.3 ±1.1
LaGAM (ours) 96.2±0.5 96.1±0.3 92.1±0.4 86.6±0.3 88.5±0.5 88.1±0.7
Supervised 98.7±0.5 98.7 ±0.5 94.2 ±0.4 92.8 ±0.7 - -
Table 1. Results of classification accuracy (mean ±std). CIFAR-100-1 and CIFAR-100-2 refer to imbalanced and balanced partitions,
respectively. Best performance on each setup is highlighted. Supervised learning is unavailable for STL-10, the training data of which are
mostly unlabeled.
Method Accuracy F1 Score AUC
uPU 68.5±2.2 67.6 ±2.8 73.8 ±2.9
nnPU 68.3±2.1 68.6 ±3.2 72.9 ±2.8
Self-PU 70.9±0.7 72.1 ±1.1 75.9 ±1.8
VPU 67.4±0.7 70.2 ±1.1 73.1 ±0.9
Dist-PU 71.7±0.6 73.7 ±1.6 77.1 ±0.7
LaGAM (ours) 77.8±2.8 84.5±2.6 83.2±1.7
Table 2. Comparative results on Alzheimer (mean ±std).
also apply the mixup technique [4, 8, 47, 54] to improve
the robustness of the classification loss Lclsused for model
training (12) [6, 44, 55].
5.2. Main Results
For each dataset, we independently run each method 5 times
with random seeds and report the average classification ac-
curacy together with the standard deviation as shown in
Table 1, noting that part of the results are adopted from
[28, 46]. For the Alzheimer dataset, we additionally report
the metrics of F1 score and AUC as shown in Table 2, which
are more practically significant.
Overall Performance. With a shallow CNN backbone,
our proposed LaGAM outperforms most of the baselines
across 7setups, indicating its superiority. Compared with
cost-sensitive methods like uPU [13], nnPU [26], Self-PU
[10] and Dist-PU [56], LaGAM holds a significant advan-tage of average 9.5%accuracy without requiring class prior
nor SCAR assumption, demonstrating its universality in
real-world practice. Benefiting from effective representa-
tion learning, a dominant advantage of up to 13.0%can
be observed from LaGAM in more challenging tasks of
CIFAR-100, where the latent categories are more finely sub-
divided. For CIFAR-100-1, where the ratio between posi-
tive and negative categories is 2 : 18 , the classifier only
needs to recognize the features of those specific two cate-
gories or can even get a 90% accuracy with the trivial so-
lution of assigning all inputs to the same class. However,
in CIFAR-100-2, with the ratio being 10 : 10 , the classifier
needs to identify features of at least ten categories to achieve
good performance, where common methods are generally
challenged while LaGAM maintains stably outstanding per-
formance. On the Alzheimer dataset, LaGAM still holds an
absolute advantage over all three metrics, which confirms
its practicability.
Learning Capacity. Furthermore, to further investigate
the difference in learning capacity brought by the well-
designed representation learning framework, we replace the
backbone model with deeper ResNet-18 and compare the
performance of current SOTA Dist-PU [56] and P3MIX-
C [28] with LaGAM. The results show that the classifica-
tion accuracy of LaGAM gets significantly improved by
0.8%to6.2%after applying a deeper network. Dist-
PU also shows a slight improvement while severe model
degradation occurs in P3MIX-C probably due to the mis-
match between the learning capacity and model complex-
23143
Ablation Meta Lcont CIFAR-10 CIFAR-100
LaGAM ✓ ✓ 96.6 89.8
nnPU w/ Lcont ✗ ✓ 91.2 87.8
Only Meta ✓ ✗ 87.6 73.5
Naive BCE ✗ ✗ 60.0 50.0
Table 3. Ablation study on key components with ✓indicating the
enabling of meta-disambiguation or Lcont.
ity given rough data. It indicates that group-aware rep-
resentation learning together with stable supervision sig-
nals obtained from meta-disambiguation enables PU learn-
ing to better adapt to deeper network architectures in gen-
eral cases, thereby fully leveraging the learning capacity of
deep neural networks. Detailed investigation can be found
in Appendix C.
5.3. Ablation Studies
In this section, we present the ablation results to show the
effectiveness as well as reasonability of our LaGAM.
Effect of Lcontand Meta Disambiguation. We ablate
the contributions of the two key components of LaGAM:
group-aware contrastive learning and meta label disam-
biguation. In particular, we compare LaGAM with three
types of different variants: 1) nnPU w/ Lcont, where Lcont
is jointly used with the non-negative unbiased risk estima-
tor [26] but without meta disambiguation; 2) LaGAM w/o
Lcont, where the target classifier is completely trained on a
BCE loss with pseudo-labels obtained through meta disam-
biguation; and 3) Naive BCE , where the classifier is trained
on a BCE loss assuming that all the unlabeled data are neg-
ative. From Tabel 3, we can observe that Lcontsignificantly
boost the performance of nnPU compared with the results
in Table 1, indicating that group-aware contrastive learning
possesses a certain universality, being able to integrate well
with some other methods by enhancing their performance in
representation learning. On the other hand, the gap between
LaGAM and variant 1 also suggests that due to the involve-
ment of dichotomized cut-off, Lcontis able to achieve the
best results if the classifier provides valid guidance that can
effectively restrict its clustering direction. Besides, the sig-
nificant difference between the performance of variant 2 and
variant 3 demonstrates that meta-disambiguation can indeed
correct the misestimated labels.
Effect of Different Label Updating Strategies. Since
there are various ways to perform label updating in meta-
learning, we also conduct ablation experiments with two
variants of LaGAM on CIFAR-10, adopting different up-
dating strategies: 1) soft update using normalized gradientsAblation Gradient EMA w/o CL w/ CL
LaGAM Projected ✓ 87.6 96.6
Soft Update Normalized ✓ 88.4 96.1
w/o EMA Projected ✗ 91.2 95.3
Table 4. Ablation study on label updating strategies.
(a) w/o CL
 (b) w/ CL
Figure 4. The variation in mean square error (MSE) between
pseudo-labels and ground-truths.
and 2) pseudo-label update w/o EMA . Interestingly, from
Table 4 we can see that though EMA update with projected
gradients which is used in LaGAM has the worst perfor-
mance under the circumstance without Lcont, while the com-
parative results completely reverse once Lcontis involved.
We hypothesize that variant 2 provides the strongest binary
classification supervision signals which can mitigate over-
fitting on estimation bias without Lcont, as shown in Figure
4. However, when paired with Lcont, the intensity of the su-
pervision signal may not be the priority, instead, stability
and consistency take precedence, while variant 2 exhibits
significant oscillation during the label updating process.
Ablation ID UC DC NS Acc.
LaGAM ✓✓✓✓ 96.6
w/o Neighor Smoothing ✓ ✓ ✓ ✗ 96.3
w/o NS +Dichotomized Cutoff ✓ ✓ ✗ ✗ 96.1
Only Instance Discrimination ✓ ✗ ✗ ✗ 91.8
Table 5. Ablation study on positive set constructions in Lcont.
Effect of Different Constructions of Positive Set. To
better understand the impact of each criterion used for the
construction of positive set in the hierarchical contrastive
learning, we compare the model accuracy on CIFAR-10 af-
ter removing each criterion in Table 5 and visualize the cor-
responding representation distributions respectively. In ad-
dition to the increase in classification accuracy, we can also
observe from Figure 5 that with each added criterion, the
distinguishability of the sample representations distribution
23144
(a) Only Instance Discrimination
 (b) w/o NS +Dichotomized Cutoff
(c) w/o Neighor Smoothing
 (d) LaGAM
Figure 5. Representation layout obtained on CIFAR-10 using dif-
ferent contrastive learning frameworks. We use PCA since it pro-
duces a clearer decision boundary.
Cluster Number CIFAR-10 CIFAR-100
5 96.4 88.4
10 97.0 89.8
20 96.6 90.2
100 96.6 89.8
Table 6. Sensitivity analysis on cluster number (default 100).
is significantly enhanced. Specifically, with Unsupervised
Clustering ( UC), the samples begin to distribute in clus-
ters as the colors of different categories start to show up.
With Dichotomized Cutoff ( DC), we can clearly see that the
clusters begin to separate towards opposite sides with a gap
emerging between them. With local Neighbor Smoothing
(NS), the clusters are more distinctly separated as the col-
ors of different regions are more uniform.
5.4. Sensitivity Analysis
To verify the feasibility of LaGAM, we also conduct an ex-
periment on the effect of specifying different cluster num-
bers in the k-means algorithm (3), to show that LaGAM
is competitive without requiring any prior knowledge about
the number of latent categories. Intuitively, as shown in Ta-
ble 6, the classifier has the best performance when the num-
ber of true latent categories (which is 10and20for CIFAR-
10 and CIFAR-100, respectively) equals the one manually
set. But more importantly, as the cluster number continues
to increase, the decrease in classification accuracy is rela-
tively minor, which implies that we can choose a necessarily
large cluster number rather than the exact number of latent
(a) # Cluster=5
 (b) # Cluster=10
(c) # Cluster=20
 (d) # Cluster=100
Figure 6. Representation layout obtained on CIFAR-10 using dif-
ferent cluster numbers. We use t-SNE since it produces clearer
data clusters.
categories, without losing utility. To understand the under-
lying reasons, from Figure 6 we can observe that when the
cluster number has far exceeded the number of true latent
categories, different clusters belonging to the same latent
category still tend to cluster together, and thus will not in-
terfere with the model’s classification boundary.
6. Conclusion
In this paper, we study the challenge of representation learn-
ing caused by the lack of semantics under PU setting, and
manage to tackle it with a group-aware contrastive learn-
ing objective that extracts the underlying features consistent
with the natural distribution of PU data. Based on this key
idea, we propose a novel PU learning framework, namely
LaGAM, wherein we also make an aggressive attempt at
label disambiguation strategy, directly distilling the labels
of unlabeled data through meta-learning. Empirically, we
conduct extensive experiments and show that LaGAM es-
tablishes state-of-the-art performance and even approaches
the supervised counterpart. Visualized results also prove
that LaGAM can indeed learn effective representations that
are well aligned with the real semantics. We hope our work
will open new avenues for the community to explore PU
learning from the perspective of representation learning.
Acknowledgements
This work is supported by the Pioneer R&D Program of
Zhejiang (No. 2024C01035). Chang Yao is supported by
the Key Research and Development Program of Zhejiang
Province (No. 2023C03192).
23145
References
[1] Jessa Bekker and Jesse Davis. Estimating the class prior in
positive and unlabeled data through decision tree induction.
InAAAI , pages 2712–2719. AAAI Press, 2018. 2
[2] Jessa Bekker and Jesse Davis. Learning from positive and
unlabeled data: a survey. Mach. Learn. , 109(4):719–760,
2020. 1
[3] Jessa Bekker, Pieter Robberechts, and Jesse Davis. Beyond
the selected completely at random assumption for learning
from positive and unlabeled data. In ECML , pages 71–85.
Springer, 2019. 2
[4] David Berthelot, Nicholas Carlini, Ian J. Goodfellow, Nico-
las Papernot, Avital Oliver, and Colin Raffel. Mixmatch: A
holistic approach to semi-supervised learning. In NeurIPS ,
pages 5050–5060, 2019. 6
[5] Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Pi-
otr Bojanowski, and Armand Joulin. Unsupervised learn-
ing of visual features by contrasting cluster assignments. In
NeurIPS , 2020. 2
[6] Luigi Carratino, Moustapha Ciss ´e, Rodolphe Jenatton, and
Jean-Philippe Vert. On mixup regularization. J. Mach.
Learn. Res. , 23:325:1–325:31, 2022. 6
[7] Sneha Chaudhari and Shirish K. Shevade. Learning from
positive and unlabelled examples using maximum margin
clustering. In ICONIP , pages 465–473. Springer, 2012. 2, 3
[8] Hui Chen, Fangqing Liu, Yin Wang, Liyue Zhao, and Hao
Wu. A variational approach for learning from positive and
unlabeled data. In NeurIPS , 2020. 5, 6
[9] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-
offrey E. Hinton. A simple framework for contrastive learn-
ing of visual representations. In ICML , pages 1597–1607.
PMLR, 2020. 2, 3
[10] Xuxi Chen, Wuyang Chen, Tianlong Chen, Ye Yuan, Chen
Gong, Kewei Chen, and Zhangyang Wang. Self-pu: Self
boosted and calibrated positive-unlabeled training. In ICML ,
pages 1510–1519, 2020. 1, 2, 4, 5, 6
[11] Adam Coates, Andrew Y . Ng, and Honglak Lee. An analysis
of single-layer networks in unsupervised feature learning. In
AISTATS , pages 215–223. JMLR.org, 2011. 5
[12] Marthinus Du Plessis, Gang Niu, and Masashi Sugiyama.
Convex formulation for learning from positive and unlabeled
data. In ICML , pages 1386–1394, 2015. 1, 2, 5
[13] Marthinus Christoffel du Plessis, Gang Niu, and Masashi
Sugiyama. Analysis of learning from positive and unlabeled
data. In NeurIPS , pages 703–711, 2014. 1, 2, 5, 6
[14] Marthinus Christoffel du Plessis, Gang Niu, and Masashi
Sugiyama. Class-prior estimation for learning from positive
and unlabeled data. In ACML , pages 221–236. JMLR.org,
2015. 2
[15] Charles Elkan and Keith Noto. Learning classifiers from only
positive and unlabeled data. In SIGKDD , pages 213–220,
2008. 2
[16] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-
agnostic meta-learning for fast adaptation of deep networks.
InICML , pages 1126–1135. PMLR, 2017. 2[17] Zayd Hammoudeh and Daniel Lowd. Learning from positive
and unlabeled data with arbitrary positive shift. In NeurIPS ,
2020. 2
[18] Fengxiang He, Tongliang Liu, Geoffrey I Webb, and
Dacheng Tao. Instance-dependent pu learning by bayesian
optimal relabeling. arXiv preprint arXiv:1808.02180 , 2018.
1
[19] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and
Ross B. Girshick. Momentum contrast for unsupervised vi-
sual representation learning. In CVPR , pages 9726–9735.
Computer Vision Foundation / IEEE, 2020. 2, 3
[20] Ming Hou, Brahim Chaib-Draa, Chao Li, and Qibin Zhao.
Generative adversarial positive-unlabelled learning. arXiv
preprint arXiv:1711.08054 , 2017. 2
[21] Cho-Jui Hsieh, Nagarajan Natarajan, and Inderjit S. Dhillon.
PU learning for matrix completion. In ICML , pages 2445–
2453. JMLR.org, 2015. 1
[22] Yu-Guan Hsieh, Gang Niu, and Masashi Sugiyama. Classifi-
cation from positive, unlabeled and biased negative data. In
ICML , pages 2820–2829. PMLR, 2019. 2
[23] Wenpeng Hu, Ran Le, Bing Liu, Feng Ji, Jinwen Ma,
Dongyan Zhao, and Rui Yan. Predictive adversarial learn-
ing from positive and unlabeled data. In AAAI , pages 7806–
7814, 2021. 2, 5
[24] Masahiro Kato, Takeshi Teshima, and Junya Honda. Learn-
ing from positive and unlabeled data with a selection bias. In
ICLR , 2018. 2
[25] Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna,
Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, and
Dilip Krishnan. Supervised contrastive learning. Advances
in neural information processing systems , 33:18661–18673,
2020. 3
[26] Ryuichi Kiryo, Gang Niu, Marthinus Christoffel du Plessis,
and Masashi Sugiyama. Positive-unlabeled learning with
non-negative risk estimator. In NeurIPS , pages 1675–1685,
2017. 1, 2, 5, 6, 7
[27] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009. 5
[28] Changchun Li, Ximing Li, Lei Feng, and Jihong Ouyang.
Who is your right mixup partner in positive and unlabeled
learning. In ICLR . OpenReview.net, 2022. 2, 3, 5, 6
[29] Xiaoli Li and Bing Liu. Learning to classify texts using pos-
itive and unlabeled data. In IJCAI , pages 587–592, 2003. 1,
2
[30] Xiaoli Li and Bing Liu. Learning from positive and unla-
beled examples with different data distributions. In ECML ,
pages 218–229. Springer, 2005. 1
[31] Yunfan Li, Peng Hu, Zitao Liu, Dezhong Peng, Joey Tianyi
Zhou, and Xi Peng. Contrastive clustering. In AAAI , pages
8547–8555, 2021. 2
[32] Bing Liu, Wee Sun Lee, Philip S. Yu, and Xiaoli Li. Partially
supervised classification of text documents. In ICML , pages
387–394. Morgan Kaufmann, 2002. 1, 2
[33] Chuan Luo, Pu Zhao, Chen Chen, Bo Qiao, Chao Du,
Hongyu Zhang, Wei Wu, Shaowei Cai, Bing He, Sara-
vanakumar Rajmohan, and Qingwei Lin. PULNS: positive-
unlabeled learning with effective negative sample selector. In
AAAI , pages 8784–8792. AAAI Press, 2021. 2
23146
[34] Alex Nichol, Joshua Achiam, and John Schulman. On first-
order meta-learning algorithms. CoRR , abs/1803.02999,
2018. 2
[35] Tao Peng, Wanli Zuo, and Fengling He. SVM based adaptive
learning method for text classification from positive and un-
labeled documents. Knowl. Inf. Syst. , 16(3):281–301, 2008.
2
[36] Hieu Pham, Zihang Dai, Qizhe Xie, and Quoc V . Le. Meta
pseudo labels. In CVPR , pages 11557–11568. Computer Vi-
sion Foundation / IEEE, 2021. 2
[37] Harish G. Ramaswamy, Clayton Scott, and Ambuj Tewari.
Mixture proportion estimation via kernel embeddings of dis-
tributions. In ICML , pages 2052–2060. JMLR.org, 2016. 2,
5
[38] Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urta-
sun. Learning to reweight examples for robust deep learning.
InICML , pages 4331–4340. PMLR, 2018. 2, 3, 4
[39] Yafeng Ren, Donghong Ji, and Hongbin Zhang. Positive un-
labeled learning for deceptive reviews detection. In EMNLP ,
pages 488–498. ACL, 2014. 1
[40] Zhongzheng Ren, Raymond A. Yeh, and Alexander G.
Schwing. Not all unlabeled data are equal: Learning to
weight data in semi-supervised learning. In NeurIPS , 2020.
2, 3, 4
[41] Tomoya Sakai and Nobuyuki Shimizu. Covariate shift adap-
tation on learning from positive and unlabeled data. In AAAI ,
pages 4838–4845, 2019. 2
[42] Guangxin Su, Weitong Chen, and Miao Xu. Positive-
unlabeled learning from imbalanced data. In IJCAI , pages
2995–3001. ijcai.org, 2021. 2
[43] Daiki Tanaka, Daiki Ikami, and Kiyoharu Aizawa. A novel
perspective for positive-unlabeled learning via noisy labels.
CoRR , abs/2103.04685, 2021. 1, 5
[44] Sunil Thulasidasan, Gopinath Chennupati, Jeff A. Bilmes,
Tanmoy Bhattacharya, and Sarah Michalak. On mixup train-
ing: Improved calibration and predictive uncertainty for deep
neural networks. In NeurIPS , pages 13888–13899, 2019. 6
[45] A ¨aron van den Oord, Yazhe Li, and Oriol Vinyals. Repre-
sentation learning with contrastive predictive coding. CoRR ,
abs/1807.03748, 2018. 2
[46] Xinrui Wang, Wenhai Wan, Chuanxin Geng, Shaoyuan LI,
and Songcan Chen. Beyond myopia: Learning from positive
and unlabeled data through holistic predictive trends. arXiv
preprint arXiv:2310.04078 , 2023. 6
[47] Tong Wei, Feng Shi, Hai Wang, Wei-Wei Tu, and Yu-Feng
Li. Mixpul: Consistency-based augmentation for positive
and unlabeled learning. CoRR , abs/2004.09388, 2020. 2, 6
[48] Zhirong Wu, Yuanjun Xiong, Stella X. Yu, and Dahua Lin.
Unsupervised feature learning via non-parametric instance-
level discrimination. CoRR , abs/1805.01978, 2018. 2, 3
[49] Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun
Yu, Gang Niu, and Masashi Sugiyama. Sample selection
with uncertainty of losses for learning with noisy labels. In
ICLR . OpenReview.net, 2022. 1
[50] Peng Yang, Xiaoli Li, Jian-Ping Mei, Chee Keong Kwoh,
and See-Kiong Ng. Positive-unlabeled learning for disease
gene identification. Bioinform. , 28(20):2640–2647, 2012. 1[51] Hwanjo Yu, Jiawei Han, and Kevin Chen-Chuan Chang.
PEBL: positive example based learning for web page clas-
sification using SVM. In SIGKDD , pages 239–248. ACM,
2002. 1, 2
[52] Hwanjo Yu, Jiawei Han, and Kevin Chen-Chuan Chang.
PEBL: web page classification without negative examples.
IEEE Trans. Knowl. Data Eng. , 16(1):70–81, 2004. 2
[53] Bangzuo Zhang and Wanli Zuo. Reliable negative extract-
ing based on knn for learning from positive and unlabeled
examples. J. Comput. , 4(1):94–101, 2009. 2, 4
[54] Hongyi Zhang, Moustapha Ciss ´e, Yann N. Dauphin, and
David Lopez-Paz. mixup: Beyond empirical risk minimiza-
tion. In ICLR . OpenReview.net, 2018. 6
[55] Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghor-
bani, and James Zou. How does mixup help with robustness
and generalization? In ICLR . OpenReview.net, 2021. 6
[56] Yunrui Zhao, Qianqian Xu, Yangbangyan Jiang, Peisong
Wen, and Qingming Huang. Dist-pu: Positive-unlabeled
learning from a label distribution perspective. In CVPR ,
pages 14461–14470, 2022. 5, 6
23147
