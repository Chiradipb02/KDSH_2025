Score-Guided Diffusion for 3D Human Recovery
Anastasis Stathopoulos
Rutgers UniversityLigong Han
Rutgers UniversityDimitris Metaxas
Rutgers University
SOTA MethodSOTA Method +Our RefinementInput Image
Figure 1. Although achieving remarkable 3D human reconstructions, a recent state-of-the-art monocular regression approach [13] may
encounter challenges in aligning the human body model to the image (middle image). To address this, we propose an iterative refinement
approach that utilizes image observations ( e.g., 2D keypoint detections) and achieves better image-model alignment (right image).
Abstract
We present Score-Guided Human Mesh Recovery
(ScoreHMR), an approach for solving inverse problems for
3D human pose and shape reconstruction. These inverse
problems involve fitting a human body model to image ob-
servations, traditionally solved through optimization tech-
niques. ScoreHMR mimics model fitting approaches, but
alignment with the image observation is achieved through
score guidance in the latent space of a diffusion model.
The diffusion model is trained to capture the conditional
distribution of the human model parameters given an in-
put image. By guiding its denoising process with a task-
specific score, ScoreHMR effectively solves inverse prob-
lems for various applications without the need for retrain-
ing the task-agnostic diffusion model. We evaluate our ap-
proach on three settings/applications. These are: (i) single-
frame model fitting; (ii) reconstruction from multiple un-
calibrated views; (iii) reconstructing humans in video se-
quences. ScoreHMR consistently outperforms all optimiza-
tion baselines on popular benchmarks across all settings.
We make our code and models available on the project web-
site:https://statho.github.io/ScoreHMR .
1. Introduction
Approaches for recovering the 3D human pose and
shape from 2D evidence ( e.g., image, 2D keypoints) typ-ically predict the parameters of a human body model,
such as SMPL [38], and solve the problem with regres-
sion [12, 13, 20, 25, 62] or optimization [2, 29, 40, 60]. The
traditional approach estimates the model parameters by it-
eratively fitting the model to 2D measurements using hand-
crafted objectives and energy minimization techniques [2].
However, this optimization process contains multiple local
minima, is sensitive to the choice of initialization and typ-
ically slow. To avoid those drawbacks, regression methods
train a neural network to predict the human model parame-
ters directly from images. But no existing feed-forward sys-
tem achieves both accurate 3D reconstruction and image-
model alignment, especially in the monocular setting. A
synergy between the regression and optimization paradigms
has been established [19, 26, 28], where the regression es-
timate is further refined through optimization given addi-
tional observations ( e.g., 2D keypoint detections). How-
ever, even in that case the optimization remains challeng-
ing, riddled with multiple local minima, while several prior
terms are necessary to obtain a meaningful solution.
Diffusion models [17, 50] have recently gained a lot of
attention for their ability to capture complex data distribu-
tions [10, 43]. These models learn the implicit prior of the
underlying data distribution xby matching the gradient of
the log density ‚àáxlogp(x)[50], also known as the score
function. This learned prior can be utilized when solv-
ing inverse problems that aim to recover xfrom the ob-
servations yby incorporating the gradient of the log likeli-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
906
hood‚àáxlogp(y|x),a.k.a score guidance term, during sam-
pling/denoising. The denoising process in diffusion models,
characterized by its iterative nature, presents these models
as a data-driven substitute for the iterative minimization em-
ployed in optimization-based techniques. Thus far, diffu-
sion models have primarily been utilized in the generation
of human motions based on text descriptions [41, 52, 61],
rather than being harnessed as a tool for addressing inverse
problems in 3D human recovery applications.
In this paper, we address this gap by leveraging diffu-
sion models to solve inverse problems related to Human
Mesh Recovery (HMR). We introduce Score-Guided Hu-
man Mesh Recovery (ScoreHMR), an approach designed to
refine initial, per-frame 3D estimates obtained from off-the-
shelf-regression networks [13, 20, 25, 26] based on addi-
tional observations. Our approach uses a diffusion model as
a learned prior of a human body model ( e.g., SMPL) param-
eters and guides its denoising process with a guidance term
that aligns the human model with the available observation.
The diffusion model, task-agnostic in nature, is trained on
the generic task of capturing the distribution of plausible
SMPL parameters conditioned on an input image. Given an
initial regression estimate, we invert it to the correspond-
ing latent of the diffusion model through DDIM [48] inver-
sion. Then we perform deterministic DDIM sampling with
guidance, where this guidance term acts as the data term
in a standard optimization setting, and the diffusion model
serves as a learned parametric prior. The DDIM inversion ‚Äì
DDIM guided sampling loop iterates until the body model
aligns with the available observation. ScoreHMR can be
conceptualized as a data-driven iterative fitting approach,
achieving alignment with image observations through score
guidance in the latent space of the diffusion model.
The diffusion model can be used in many downstream
applications without any need for task-specific retraining.
For instance, by incorporating guidance with a keypoint re-
projection term, we align the human body model with 2D
keypoint detections. In scenarios with multiple uncalibrated
views of a person, we employ cross-view consistency guid-
ance to recover a 3D human mesh that maintains consis-
tency across all viewpoints. Furthermore, in the context of
inferring human motion from a video sequence, temporal
consistency guidance, and optionally keypoint reprojection
guidance, refines per-frame regression estimates, resulting
in temporally consistent human motions. A visual summary
of ScoreHMR and its applications is provided in Figure 2.
We contribute ScoreHMR, a novel approach addressing
inverse problems in 3D human recovery. We demonstrate
the effectiveness of ScoreHMR with extensive experiments
on the three inverse problems, refining an initial regression
estimate with monocular images, multi-view images and
video frames as input. Notably, our method surpasses ex-
isting optimization approaches across all datasets and eval-uation settings without relying on task-specific designs or
training. Beyond achieving superior results, ScoreHMR
stands out as the only approach enhancing the 3D pose
performance of the state-of-the-art monocular feed-forward
system [13] in the single-frame model fitting setting. We
make our code and models available to support future work.
We provide qualitative results on video sequences on the
project page.
2. Related Work
Regression for human mesh recovery. When learning to
recover the 3D shape of articulated objects [51, 56, 59],
most approaches have to simultaneously learn a represen-
tation for the shape. This is not the case for the human cat-
egory, since parametric models [38, 58] of the human body
exist, and most approaches in this paradigm learn to regress
their parameters. HMR [20] uses MLP layers on top of im-
age features from a CNN to regress the SMPL model [38]
parameters and is the canonical example in this category.
Subsequent research [11, 12, 14, 25, 31, 32, 34, 55, 62] has
led to many improvements in the original method. Notably,
PyMAF [62] proposes a more specialized design for the
CNN backbone and incorporates a mesh alignment module
for SMPL parameter regression. PARE [25] learns distinct
features for the pose and shape parameters of SMPL and
introduces a body-part-guided attention mechanism to han-
dle occlusions. Recently, HMR 2.0 [13] proposes a fully
‚Äútransformerized‚Äù version of HMR and can effectively re-
construct unusual poses that have been difficult for previous
methods. Another line of work [5, 27, 35, 36], makes non-
parametric predictions by directly regressing the vertices of
the SMPL model. The SMPL parameters can be regressed
from non-parametric predictions with an MLP without any
loss in reconstruction performance [27]. In this work, we
assume that an initial estimate in the form of SMPL param-
eters from a regression network is available and our goal is
to improve it with our proposed approach.
Optimization for human mesh recovery. Methods falling
under this category [2, 29, 40, 47, 57, 60] utilize itera-
tive optimization to estimate the parameters of a human
model [38, 40, 58]. The objective is often formulated as an
energy minimization problem by fitting a parametric model
to the available observations, and consists of data and prior
terms. The data terms measure the deviation between the
estimated and detected features, while the prior terms im-
pose constraints on the model parameters. Parametric pri-
ors are important during the optimization in order to obtain
a meaningful solution, and several works have proposed a
variety of them [2, 9, 28, 40, 42, 53].
Nonetheless, optimization suffers from many difficulties,
including sensitivity to parameter initialization, the exis-
tence of multiple local minima and the trade-off between
the data and prior terms. Regression methods often serve
907
Additional viewsConsolidated mesh
2D keypointsFitted mesh
Additional framesSmoothed mesh(a) KeypointFitting(b) Cross-view Consistency(c) Temporal Consistency
√óùúè/Œîùë°	ùë†ùë°ùëíùëùùë†
‚Ä¶Regressor
ObservationGuidanceùúñ!ùúñ!ùë¶DDIM InversionGuided SamplingInput ImageRepeat until aligned with observations
Iterative refinement√óùúè/Œîùë°	ùë†ùë°ùëíùëùùë†Figure 2. Score-Guided Human Mesh Recovery and its applications. Top row: Overview of ScoreHMR, which iteratively refines
an initial regression estimate in a DDIM inversion ‚Äì DDIM guided sampling loop until the human body model aligns with the available
observation. Bottom row: Applications. (a): Body model fitting to 2D keypoints. (b): Multi-view refinement of individual per-frame
predictions with cross-view consistency guidance. (c): Recovering temporally consistent and smooth 3D human motion from a video
sequence given initial per-frame estimates.
as an initial point for an optimization-based method, which
refines the estimated parameters until a convergence crite-
rion is met [19, 26, 28]. This practice not only makes the
optimization converge faster, but also typically results in a
better solution since a lot of local minima are avoided. The
need for multi-stage optimization procedures, as followed
by early systems ( e.g., SMPLify [2]), is also alleviated since
the regressed parameters are typically close to a good solu-
tion. We evaluate our proposed approach in this setting,
where our aim is to refine an initial regression estimate.
Solving inverse problems with diffusion models. Diffu-
sion models [17, 46, 50] are used to represent complex dis-
tributions, exhibiting remarkable success in various applica-
tions such as text-to-image generation [43, 45], personaliza-
tion [15, 44], image editing [16] and video inpainting [63].
Their state-of-the-art performance in image generation [10]
has led to their usage as structural priors when solving in-
verse problems in image processing applications, such as
image inpainting [7, 8, 49], super-resolution [49], deblur-
ring [8] and colorization [7] among others. Diffusion mod-
els have not been used to solve inverse problems in the con-
text of 3D human pose and shape estimation, and our work
aims to bridge this gap.
3. Background
Diffusion models. We first offer some background for dif-
fusion models, namely the denoising diffusion probabilis-
tic model (DDPM) [17] formulation. Let x0‚àºpdata(x)
denote samples from the data distribution. Diffusion mod-
els progressively perturb data to noise ‚Äì forward process‚Äì via Gaussian kernels for Ttimesteps, creating latents
{xt}T
t=1. The noise is added with a predefined variance
schedule {Œ∂t}T
t=1, such that we obtain a standard Gaussian
distribution when t=T,i.e.xT‚àº N (0,I). Latents xt
can be directly sampled from a data point x0asq(xt|x0) =
N(‚àöŒ±tx0,(1‚àíŒ±t)I), where Œ±t:=Qt
s=1(1‚àíŒ∂s). A de-
noising model œµœïis trained to predict the added noise to a
clean sample via minimization of the following re-weighted
evidence lower bound [17, 23]:
Lsimple (œï) =Ex0,t,œµ||œµœï(xt, t)‚àíœµ||2, (1)
where tis sampled uniformly from {1, .., T}, and noise œµis
added to a clean sample x0‚àºpdata to get a noisy sample
xt. Once the denoising model œµœïis learned, we can use it
to generate samples from the diffusion model by sampling
xT‚àº N(0,I)and iteratively refining it with œµœï. The pre-
dicted noise for a latent xtat timestep t(noise level) from
the denoising model œµœïis related to the score of the model
at that timestep [50]:
œµœï(xt, t) =‚àí‚àö
1‚àíŒ±t‚àáxtlogp(xt). (2)
Since the sampling process ‚Äì reverse process ‚Äì of the
DDPM formulation is known to be slow [17, 48], Song et
al. [48] proposed the denoising diffusion implicit model
(DDIM) formulation for diffusion models, which defines
the diffusion process as a non-Markovian process with the
same forward marginals as DDPM. This enables faster sam-
pling with the sampling steps given by:
xt‚àí1=‚àöŒ±t‚àí1ÀÜx0(xt) +q
1‚àíŒ±t‚àí1‚àíœÉ2
tœµœï(xt, t) +œÉtz,(3)
908
where z‚àº N (0,I),œÉtis the variance of the noise used
during sampling, and ÀÜx0(xt)denotes the predicted x0from
xtand is given by:
ÀÜx0(xt) =1‚àöŒ±t(xt‚àí‚àö
1‚àíŒ±tœµœï(xt, t)), (4)
‚âÉ1‚àöŒ±t(xt+ (1‚àíŒ±t)‚àáxtlogp(xt)).
By setting œÉtto 0, the sampling process becomes de-
terministic and enables inversion of samples from pdata to
their corresponding latents [48]. The same framework can
be used for modeling conditional distributions, by incorpo-
rating the conditional information in the forward and re-
verse processes [10].
4. Method
Body model. SMPL [38] is a parametric human body
model. It consists of pose Œ∏‚ààR24√ó3and shape Œ≤‚ààR10
parameters, and defines a mapping M(Œ∏, Œ≤)from the hu-
man body parameters to a body mesh M‚ààRN√ó3, where
N= 6980 is the number of mesh vertices. For a given out-
put mesh M, the 3D body joints Jcan be computed as a
linear combination of the mesh vertices J=WM , where
Wis a pre-trained linear regressor.
Problem statement. Suppose we have observations y‚àà
Rnthat relate to some unknown signal x0‚ààRmthrough:
y=A(x0) +Œ∑, (5)
where A(¬∑)is a forward operator and Œ∑is the observation
noise. Our goal is to recover x0fromy,i.e. solve the in-
verse problem. We are interested in recovering the SMPL
parameters x0={Œ∏0, Œ≤0}from observations y(e.g., 2D
keypoint detections), from which the closed-form map to
x0is intractable. Solutions to this family of problems are
given through iterative optimization by minimization:
arg min
x0=Ldata(x0) +Lprior(x0), (6)
where Ldata measures the deviation between the estimated
and detected features and Lconsists of several prior terms
necessary to obtain a plausible solution.
In our setting, we are given an input image Iof a person
and the corresponding SMPL estimate xreg={Œ∏reg, Œ≤reg}
from regression. Our goal is to improve xregin the pres-
ence of additional observations y. In order to achieve this
we propose an approach that injects suitable information in
the denoising process of a diffusion model through the log
likelihood score, as described next.
4.1. Score-Guided Human Mesh Recovery
Our main objective is to explore how we can leverage
diffusion models to solve inverse problems for human meshrecovery applications. Here, we assume that an initial es-
timate xregfor the SMPL parameters is acquired through
any off-the-shelf regression network such as [13, 20, 26],
while observations yare also automatically detected. Fur-
thermore, we assume that we have access to a trained dif-
fusion model œµœï(xt, t, I)that sufficiently captures the con-
ditional distribution of SMPL model parameters given an
input image I. Our goal is to improve xregwith the help of
the diffusion model and detected observations y.
To use the regression estimate xregas an initial point, we
invert it to the latent xœÑat noise level œÑwith the determin-
istic DDIM inversion process:
xt+1=‚àöŒ±t+1ÀÜx0(xt) +p
1‚àíŒ±t+1œµœï(xt, t, I).(7)
Running the deterministic DDIM sampling starting from
xœÑ, we would get back the initial estimate xreg. We found
that this reconstruction error is less than 10‚àí3per dimen-
sion, which suggests that the DDIM inversion ‚Äì DDIM sam-
pling loop works as intended. However, we are not inter-
ested in getting back the initial regression estimate, but we
wish to improve it based on the available observation y.
Ideally, we would like to use the conditional score
‚àáxtlogp(xt|I,y)during DDIM sampling instead of the
score ‚àáxtlogp(xt|I)of the data distribution. Using
Bayes rule we can write the score ‚àáxtlogp(xt|I,y) =
‚àáxtlogp(xt|I) +‚àáxtlogp(y|I,xt), where the first term
is the score of the diffusion model œµœï(xt, t, I). However,
the issue with this posterior sampling approach is that there
does not exist an analytical formulation for the likelihood
score‚àáxtlogp(y|I,xt). To resolve this, a recent line of
work estimates the likelihood under some mild assump-
tions [8, 49]. Inspired by [8], by assuming that the observa-
tion noise Œ∑in Eq. (5) is Gaussian, we get:
‚àáxtlogp(y|I,xt)‚âÉ ‚àá xtlogp(y|I,ÀÜx0(xt))
=‚àíœÅ‚àáxt||y‚àí A(ÀÜx0(xt))||2
2,(8)
where œÅcan be viewed as a tunable step size. Approximat-
ing the likelihood score with Eq. (8), we apply guidance
to the deterministic DDIM sampling process, with the sam-
pling equations seen below:
ÀÜx‚Ä≤
0(xt) =1‚àöŒ±t(xt‚àí‚àö
1‚àíŒ±tœµ‚Ä≤
œï(xt, t, I)), (9)
xt‚àí1=‚àöŒ±t‚àí1ÀÜx‚Ä≤
0(xt) +p
1‚àíŒ±t‚àí1œµ‚Ä≤
œï(xt, t, I).
where œµ‚Ä≤
œïis the modified noise prediction after guidance:
œµ‚Ä≤
œï=œµœï(xt, t, I)+œÅ‚àö
1‚àíŒ±t‚àáxt||y‚àíA(ÀÜx0(xt))||2
2.(10)
We use DDIM inversion (Eq. (7)) followed by guided
DDIM sampling (Eqs. (9) and (10)) in a loop, aligning the
human body model with the detected observations. The
909
loop stops when the relative change of the guidance loss
Lg=||y‚àí A(ÀÜx0(xt))||2
2is below a given threshold Œªthr.
We provide a pseudo-code implementation of ScoreHMR in
the supplemental.
4.2. Model Design and Training
Without loss of generality, we choose to model only
the pose SMPL parameters with our diffusion model, i.e.
x0=Œ∏, to maintain a fair comparison with optimization
methods utilizing a learned pose prior ( e.g., ProHMR [28]).
We emphasize that the shape parameters Œ≤of SMPL can
also be accommodated using the same approach and we
present results from such experiments in the supplemental.
However, we do not notice any performance improvement
by including the SMPL Œ≤in ScoreHMR. One plausible ex-
planation is that inferring Œ≤from a single image is relatively
more straightforward compared to inferring Œ∏for existing
methods [13, 20, 26].
In our setting, we are given an input image Iof a per-
son, which we encode with a CNN backbone gand obtain
a context feature c=g(I). We model the distribution
of plausible poses for that person conditioned on Iwith
a diffusion model œµœï(xt, t, c =g(I)). The backbone g
can be either trained end-to-end with œµœïor remain frozen
while training the diffusion model. In the latter case, we
can use the features from the backbone of a regression net-
work [20, 25, 26, 28]. We did not observe any performance
improvement from training gend-to-end with œµœï, and there-
fore, we acquire the context feature cfrom a pretrained re-
gression network in all of our experiments.
Architecture. We follow [64] and use the 6D represen-
tation for 3D rotations, thus x0is a 144-dimensional vec-
tor. The denoising model œµœïis comprised of 3 MLP blocks
that are conditioned on the timestep tand image features c.
The model is given a noisy sample xtfor the pose parame-
ters, the timestep tand image features cas input. First, we
use a linear layer to project xtto the features h(1)given as
input to the first MLP block. We condition the input fea-
turesh(i)‚ààR144of each MLP block on the timestep t,
by applying scaling and shifting to get the features h(i)
t=
tsh(i)+tb, where (ts,tb)‚ààR2√ó144=MLP (œà(t))is
the output of a MLP with a sinusoidal encoding function œà.
Then, we condition each MLP block on the image features
by concatenating h(i)
tandc. Additional details are provided
in the supplemental.
Training. Let us assume that we have a collection of images
paired with SMPL pose annotations. Then, we could train
the diffusion model with its standard training loss:
LDM(œï) =E(I,x0),t,œµ||œµœï(xt, t, I)‚àíœµ||2. (11)
Unfortunately, such paired annotations are not generally
available, so we use pseudo ground-truth SMPL pose an-
notations from various datasets (see Sec. 5).4.3. Applications of ScoreHMR
In this part we show how we can use our approach for
solving HMR-related inverse problems. We highlight that
for all these applications we use the same trained diffusion
model with no per-task training.
Body model fitting. In this setting the detected image ob-
servations are 2D keypoints detections ykpand their con-
fidences yconf. Optimization approaches fit the SMPL
body model to the 2D keypoints by minimizing ŒªJEJ+
ŒªpriorEprior , where EJpenalizes the deviations between
the projected model joints and the detected joints and Eprior
include prior energy terms for the pose and shape parame-
ters of SMPL.
Typically the predicted weak-perspective camera from
a regression network is converted to a perspective camera
œÄ= (R, Œ≥)based on the bounding box of a person and is
also included as a variable to be optimized. The camera œÄ
has fixed focal length and intrinsics K. Since the parame-
tersŒ∏already include a global orientation, R‚ààR3√ó3is as-
sumed to be identity and only the camera translation Œ≥‚ààR3
is optimized along with the human body model parameters.
In this setting, the forward operator that relates
the body model parameters with the detected joints is
Œ†K(WM(x0, Œ≤) +Œ≥), where Œ†Kis the projection matrix
with camera intrinsics KandWis a matrix that regresses
the 3D model joints from the mesh vertices of the model.
This means that the guidance loss in Eq. (10) becomes:
Lrepr=yconf||Œ†K(WM(ÀÜx0(xt), Œ≤)+Œ≥)‚àíykp||2
2.(12)
The camera translation Œ≥is also optimized with Lrepr as in
standard optimization procedures.
Multi-view refinement. In this setting we have a set
{I(n)}N
n=1of uncalibrated views of the same person, and
their monocular regression estimate that we want to im-
prove based on information from the other views. For each
frame, we decompose the pose parameters x0(n)to global
orientation x(n)
0,gland body pose parameters x(n)
0,b. We can
consolidate all single-frame predictions to improve x(n)
0,b
with a cross-view consistency guidance loss:
LMV=NX
n=1||ÀÜx(n)
0,b(x(n)
t)‚àí¬Øx0,b||2
2, (13)
where ¬Øx0,b=1
NPN
nx(n)
0,b(x(n)
t)and its minimization is
equivalent to minimizing the squared distance between all
pairs of body poses.
Human motion refinement. Although our model has been
trained in the monocular setting, we can use the learned
conditional distribution to obtain temporally consistent and
smooth predictions in a video sequence V={I(n)}N
n=1.
In this setting, the forward operator is the identity function
910
and the observations are the pose predictions of the previ-
ous frame in the sequence. We can enforce temporal con-
sistency with the following guidance loss:
Ltemp=NX
n=2||ÀÜx(n)
0(xt)‚àíÀÜx(n‚àí1)
0 (xt)||2
2. (14)
Guidance with the previous loss can be considered as
a learnable smoothing operation that makes sure that the
smoothed parameters remain consistent with the image evi-
dence under the image-conditional distribution captured by
the diffusion model. We can optionally use additional guid-
ance with the keypoint reprojection loss in Eq. (12) when
2D keypoint detections are available.
5. Experiments
Training. We use the typical datasets for training, i.e.,
Human3.6M [18], MPI-INF-3DHP [39], COCO [37] and
MPII [1]. The quality of the pseudo ground-truth pose
annotations plays an important role for training the diffu-
sion model. We compare two models trained with pseudo
ground-truth from SPIN [26] and EFT [19] respectively.
To showcase that ScoreHMR can work with image features
from various HMR models, we also train two different ver-
sions of œµœïwith image features from ProHMR [28] and
PARE [25] respectively. When training with PARE features,
we only use its pose features. Implementation details and
hyper-parameters are provided in the supplemental.
Evaluation datasets. For the body model fitting to 2D key-
points and human motion refinement settings, we conduct
evaluation on the test set of 3DPW [54] and on the split of
EMDB [22] that contains the most challenging sequences
(i.e., EMDB 1). For the multi-view refinement experiment,
we report results on Human3.6M [18] and Mannequin Chal-
lenge [33]. For Mannequin Challenge we use the annota-
tions produced by Leroy et al. [30] and employ the entire
dataset for evaluation.
Evaluation setup. In order to demonstrate the efficacy
of our approach in refining the regression estimates from
various networks and accuracy levels, we use the pre-
dictions from the less accurate ProHMR‚Äôs regression net-
work [28] and the highly accurate HMR 2.0 [13] as our
starting points. For experiments with HMR 2.0, we use the
HMR 2.0b model, which trains longer and on more data
than HMR 2.0a, and can reconstruct humans in challenging
and unusual poses.
5.1. Quantitative Evaluation
5.1.1 Body model fitting
We evaluate the accuracy of methods that fit the SMPL body
model to 2D keypoint detections. The keypoints are de-
tected with OpenPose [3].Features Fits 3DPW (14) EMDB 1 (24)
ProHMR [28] - - 59.8 86.1
+ ScoreHMR ProHMR SPIN 55.7 77.8
+ ScoreHMR ProHMR EFT 55.5 77.4
+ ScoreHMR PARE SPIN 55.6 77.4
+ ScoreHMR PARE EFT 54.7 77.1
HMR 2.0 [13] - - 54.3 78.7
+ ScoreHMR ProHMR SPIN 52.4 76.5
+ ScoreHMR ProHMR EFT 51.3 76.4
+ ScoreHMR PARE SPIN 52.4 76.6
+ ScoreHMR PARE EFT 51.1 76.6
Table 1. Ablation study. ScoreHMR is initialized by the corre-
sponding regression results. All numbers are PA-MPJPE in mm.
Parenthesis denotes the number of body joints used to compute
PA-MPJPE.
3DPW (14) EMDB 1 (24)
LGD [47] 55.9 81.1
LFMM [6] 52.2 -
ProHMR [28] 59.8 86.1
+ SMPLify [2] 60.9 84.6
+ fitting [28] 55.1 79.8
+ ScoreHMR-a 55.7 77.8
+ ScoreHMR-b 54.7 77.1
HMR 2.0 [13] 54.3 78.7
+ SMPLify [2] 60.1 83.5
+ fitting [28] 55.1 80.1
+ ScoreHMR-a 52.4 76.5
+ ScoreHMR-b 51.1 76.6
Table 2. Evaluation of different model fitting methods. The
fitting algorithms are initialized by the corresponding regression
results, except LGD [47] and LFMM [6]. All numbers are PA-
MPJPE in mm. Parenthesis denotes the number of body joints
used to compute PA-MPJPE.
Ablation study. First, we provide an ablation study of the
core components of ScoreHMR. We benchmark ScoreHMR
with diffusion models trained with frozen image features
from ProHMR [28] and PARE [25], and pseudo ground-
truth pose annotations from SPIN [26] and EFT [19]. We
report results of iterative refinement with ScoreHMR using
the keypoint reprojection loss Lrepr in Eq. (12). Follow-
ing the typical protocols of prior work [26, 28] we use the
PA-MPJPE metric for evaluation and present results in Ta-
ble 1. From Table 1 we observe that running ScoreHMR
on top of regression reduces the 3D pose errors in all cases.
We also observe that iterative refinement with ScoreHMR is
robust to the choice of image features and pseudo ground-
truth. The diffusion model, trained with PARE image fea-
tures and fits from EFT, attains the highest performance. We
use ScoreHMR with our worst (ProHMR features & SPIN
fits) and best (PARE features & EFT fits) models for evalu-
911
H36M (14) Mannequin (17)
MPJPE ‚Üì PA-MPJPE ‚Üì MPJPE ‚Üì PA-MPJPE ‚Üì
ProHMR [28] 65.1 43.7 165.3 86.8
+ fitting [28] 59.6 34.5 162.6 80.2
+ ScoreHMR-a 55.8 34.1 162.0 81.1
+ ScoreHMR-b 51.9 34.2 157.7 80.2
HMR 2.0 [13] 52.8 35.6 156.0 90.1
+ fitting [28] 52.6 32.9 155.5 79.4
+ ScoreHMR-a 47.9 28.4 151.0 79.3
+ ScoreHMR-b 44.7 29.0 148.3 79.1
Table 3. Evaluation of multi-view refinement. We compare our
proposed approach with the single-view 3D reconstruction and an
optimization-based method [28]. Parenthesis denotes the number
of body joints used to compute MPJPE and PA-MPJPE.
ation in the rest of the paper, denoting them as ScoreHMR-a
and ScoreHMR-b respectively.
Comparison with optimization methods. Next, we com-
pare with model fitting baselines that are trained to optimize
starting from the canonical pose and shape ( i.e., LGD [47],
LFMM [6]) as well as with baselines that can use the param-
eters from a regression network as a starting point ( i.e., SM-
PLify [2], ProHMR-fitting [28]). We benchmark SMPLify
(single-stage implementation from [26]) and ProHMR-
fitting starting from the predictions of the ProHMR‚Äôs regres-
sion network [28] and those of HMR 2.0 [13]. Results are
reported in Table 2. Performing SMPLify on top of regres-
sion increases the 3D pose errors, while ProHMR-fitting
fails to improve the performance of HMR 2.0. Iterative re-
finement with ScoreHMR reduces the 3D pose errors in all
cases, and ScoreHMR-b outperforms all baselines.
5.1.2 Multi-view refinement
Next, we evaluate the capability of ScoreHMR at refining
the per-view regression estimates when several uncalibrated
views of the same person are available. For this task, we
use guidance with the cross-view consistency loss LMVin
Eq. (13). We test our approach on the Human3.6M [18]
and the Mannequin Challenge [33] (some YouTube videos
were missing) datasets, reporting MPJPE and PA-MPJPE
following [28]. We compare with the individual per-view
regression predictions as well as with an optimization-based
method [28]. Results are shown in Table 3. Results from
Table 3 show that both ScoreHMR and ProHMR-fitting im-
prove the per-frame predictions, but our approach consis-
tently leads to lower MPJPE errors. This happens because
refining the body poses at a given noise level also influences
the global orientation in the next noise level of the diffusion
model, as the model captures the joint distribution of SMPL
poses Œ∏. This is not possible with ProHMR-fitting, since
only the body poses are updated during the optimization
process. Notably, the runtime of ScoreHMR is remarkably
swift, requiring only 1.5 minutes for the entire Mannequin
Challenge dataset, which contains 20K frames.3DPW (14) EMDB 1 (24)
PA-MPJPE ‚Üì Acc Err ‚Üì PA-MPJPE ‚Üì Acc Err ‚Üì
Vibe [24] 56.7 31.5 85.7 43.8
Vibe-opt [24] 63.9 42.1 83.6 41.4
ProHMR [28] 59.8 25.0 86.1 37.7
+ fitting [28] 54.5 14.0 77.9 18.4
+ ScoreHMR-a 54.9 11.4 76.5 12.8
+ ScoreHMR-b 53.9 11.2 75.7 12.1
HMR 2.0 [13] 54.3 17.3 78.7 23.7
+ fitting [28] 53.8 14.1 76.2 20.0
+ ScoreHMR-a 51.7 10.7 75.1 11.9
+ ScoreHMR-b 50.5 11.1 75.3 11.9
Table 4. Evaluation of human motion refinement. We compare
different model fitting algorithms and our proposed approach in a
temporal setting. Parenthesis denotes the number of body joints
used to compute PA-MPJPE and Acc Err.
Figure 3. Qualitative evaluation of ScoreHMR Pink: Regres-
sion with ProHMR [28]. White: Regression with HMR 2.0 [13].
Green: Regression + ScoreHMR (ours).
5.1.3 Human motion refinement
In this part, we evaluate ScoreHMR at refining the single-
frame regression estimates in a video sequence with 2D
keypoint detections. In this setting, we use guidance with
Lrepr andLtemp terms. Following prior work [21] we also
report the acceleration error ( mm/s2), computed as the dif-
ference in acceleration between the ground-truth and pre-
dicted 3D joints. We use all SMPL body joints for com-
puting this error in EMDB 1, in contrast to the evaluation
in [22] that uses specific joints for some temporal metrics
(e.g. Jitter).
We compare our approach with the temporal mesh opti-
mization baselines (VIBE-opt [24], ProHMR-fitting [28]).
VIBE-opt is initialized by the temporal mesh regression re-
sult of VIBE [24]. We run ProHMR-fitting [28] with the de-
fault hyperparameters adding a smoothness regularization
term. We report results in Table 4. Our approach consis-
tently outperforms all baselines across all datasets and met-
rics. Notably, ScoreHMR significantly enhances temporal
consistency compared to prior works, resulting in a relative
improvement of 21.3%(3DPW) and 40.5%(EMDB 1) in
acceleration error compared to ProHMR-fitting, when both
methods start from the monocular regression estimate of
HMR 2.0. Finally, ScoreHMR exhibits exceptional runtime
efficiency requiring only 14 minutes for the entire 3DPW
test set, which contains 35K frames.
912
Figure 4. Body model fitting results. Pink: Regression (ProHMR [28]). White: Regression (HMR 2.0 [13]). Green: Regression +
ScoreHMR (ours). Blue: Regression + ProHMR-fitting [28]. Grey: Regression + SMPLify [2].
5.2. Qualitative Results
We show qualitative results in body model fitting on
top of ProHMR and HMR 2.0 regression in Figure 3.
ScoreHMR effectively aligns the body model with the de-
tected keypoints even when the initial regression estimate is
inaccurate ( e.g., example of first row). Our reconstructions
are valid when seen from a novel view. In addition, we com-
pare our approach with SMPLify and ProHMR-fitting in
Figure 4. Our approach achieves more faithful reconstruc-
tions than the baselines. This is more evident in challeng-
ing poses ( e.g., example of last row). SMPLify encounters
challenges with inaccurate keypoint detections ( e.g., exam-
ple of second row). ProHMR-fitting faces difficulties when
there is ambiguity in the image evidence ( e.g., occlusion in
the example of third row). A potential cause for this issue
may be the mode supervision used during ProHMR training,
which leads to capturing a less diverse pose distribution as
shown in [4].6. Conclusion
We present ScoreHMR, an approach for solving inverse
problems for 3D human pose and shape reconstruction.
ScoreHMR mirrors model fitting approaches, but alignment
with the image observation is achieved through score guid-
ance in the latent space of a diffusion model. We demon-
strate the effectiveness of our method with empirical results
in several benchmarks and evaluation settings. ScoreHMR
achieves strong performance in challenging datasets and
outperforms optimization-based methods. Our work high-
lights the promising potential of score-guided diffusion pro-
cesses as a better alternative to conventional optimization-
based approaches in addressing 3D human recovery inverse
problems.
Acknowledgements: This research has been partially funded by
research grants to D. Metaxas through NSF: 2310966, 2235405,
2212301, 2003874, and AFOSR-835531
913
References
[1] Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and
Bernt Schiele. 2d human pose estimation: New benchmark
and state of the art analysis. In CVPR , 2014. 6
[2] Federica Bogo, Angjoo Kanazawa, Christoph Lassner, Peter
Gehler, Javier Romero, and Michael J Black. Keep it smpl:
Automatic estimation of 3d human pose and shape from a
single image. In ECCV , 2016. 1, 2, 3, 6, 7, 8
[3] Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and
Yaser Sheikh. Openpose: Realtime multi-person 2d pose
estimation using part affinity fields. IEEE TPAMI , 2019. 6
[4] Rongyu Chen, Linlin Yang, and Angela Yao. Mhentropy:
Entropy meets multiple hypotheses for pose and shape re-
covery. In ICCV , 2023. 8
[5] Junhyeong Cho, Kim Youwang, and Tae-Hyun Oh. Cross-
attention of disentangled modalities for 3d human mesh re-
covery with transformers. In ECCV , 2022. 2
[6] Vasileios Choutas, Federica Bogo, Jingjing Shen, and Julien
Valentin. Learning to fit morphable models. In ECCV , 2022.
6, 7
[7] Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and
Jong Chul Ye. Improving diffusion models for inverse prob-
lems using manifold constraints. In NeurIPS , 2022. 3
[8] Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L
Klasky, and Jong Chul Ye. Diffusion posterior sampling for
general noisy inverse problems. In ICLR , 2023. 3, 4
[9] Andrey Davydov, Anastasia Remizova, Victor Constantin,
Sina Honari, Mathieu Salzmann, and Pascal Fua. Adver-
sarial parametric pose prior. In CVPR , 2022. 2
[10] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. In NeurIPS , 2021. 1, 3, 4
[11] Qi Fang, Kang Chen, Yinghui Fan, Qing Shuai, Jiefeng Li,
and Weidong Zhang. Learning analytical posterior probabil-
ity for human mesh recovery. In CVPR , 2023. 2
[12] Georgios Georgakis, Ren Li, Srikrishna Karanam, Terrence
Chen, Jana Ko Àáseck¬¥a, and Ziyan Wu. Hierarchical kinematic
human mesh recovery. In ECCV , 2020. 1, 2
[13] Shubham Goel, Georgios Pavlakos, Jathushan Rajasegaran,
Angjoo Kanazawa, and Jitendra Malik. Humans in 4d: Re-
constructing and tracking humans with transformers. In
ICCV , 2023. 1, 2, 4, 5, 6, 7, 8
[14] Riza Alp Guler and Iasonas Kokkinos. Holopose: Holistic
3d human reconstruction in-the-wild. In CVPR , 2019. 2
[15] Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar,
Dimitris Metaxas, and Feng Yang. Svdiff: Compact param-
eter space for diffusion fine-tuning. In ICCV , 2023. 3
[16] Ligong Han, Song Wen, Qi Chen, Zhixing Zhang, Kunpeng
Song, Mengwei Ren, Ruijiang Gao, Anastasis Stathopoulos,
et al. Proxedit: Improving tuning-free real image editing
with proximal guidance. In WACV , 2024. 3
[17] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu-
sion probabilistic models. In NeurIPS , 2020. 1, 3
[18] Catalin Ionescu, Dragos Papava, Vlad Olaru, and Cristian
Sminchisescu. Human3. 6m: Large scale datasets and pre-
dictive methods for 3d human sensing in natural environ-
ments. IEEE TPAMI , 2014. 6, 7[19] Hanbyul Joo, Natalia Neverova, and Andrea Vedaldi. Exem-
plar fine-tuning for 3d human model fitting towards in-the-
wild 3d human pose estimation. In 3DV, 2021. 1, 3, 6
[20] Angjoo Kanazawa, Michael J Black, David W Jacobs, and
Jitendra Malik. End-to-end recovery of human shape and
pose. In CVPR , 2018. 1, 2, 4, 5
[21] Angjoo Kanazawa, Jason Y Zhang, Panna Felsen, and Jiten-
dra Malik. Learning 3d human dynamics from video. In
CVPR , 2019. 7
[22] Manuel Kaufmann, Jie Song, Chen Guo, Kaiyue Shen, Tian-
jian Jiang, Chengcheng Tang, Juan Jos ¬¥e Z¬¥arate, and Otmar
Hilliges. Emdb: The electromagnetic database of global 3d
human pose and shape in the wild. In ICCV , 2023. 6, 7
[23] Diederik P Kingma and Max Welling. Auto-encoding varia-
tional bayes. In ICLR , 2014. 3
[24] Muhammed Kocabas, Nikos Athanasiou, and Michael J
Black. Vibe: Video inference for human body pose and
shape estimation. In CVPR , 2020. 7
[25] Muhammed Kocabas, Chun-Hao P Huang, Otmar Hilliges,
and Michael J Black. Pare: Part attention regressor for 3d
human body estimation. In ICCV , 2021. 1, 2, 5, 6
[26] Nikos Kolotouros, Georgios Pavlakos, Michael J Black, and
Kostas Daniilidis. Learning to reconstruct 3d human pose
and shape via model-fitting in the loop. In ICCV , 2019. 1, 2,
3, 4, 5, 6, 7
[27] Nikos Kolotouros, Georgios Pavlakos, and Kostas Dani-
ilidis. Convolutional mesh regression for single-image hu-
man shape reconstruction. In CVPR , 2019. 2
[28] Nikos Kolotouros, Georgios Pavlakos, Dinesh Jayaraman,
and Kostas Daniilidis. Probabilistic modeling for human
mesh recovery. In ICCV , 2021. 1, 2, 3, 5, 6, 7, 8
[29] Christoph Lassner, Javier Romero, Martin Kiefel, Federica
Bogo, Michael J Black, and Peter V Gehler. Unite the peo-
ple: Closing the loop between 3d and 2d human representa-
tions. In CVPR , 2017. 1, 2
[30] Vincent Leroy, Philippe Weinzaepfel, Romain Br ¬¥egier,
Hadrien Combaluzier, and Gr ¬¥egory Rogez. Smply bench-
marking 3d human pose estimation in the wild. In 3DV,
2020. 6
[31] Jiefeng Li, Chao Xu, Zhicun Chen, Siyuan Bian, Lixin Yang,
and Cewu Lu. Hybrik: A hybrid analytical-neural inverse
kinematics solution for 3d human pose and shape estimation.
InCVPR , 2021. 2
[32] Jiefeng Li, Siyuan Bian, Qi Liu, Jiasheng Tang, Fan Wang,
and Cewu Lu. Niki: Neural inverse kinematics with invert-
ible neural networks for 3d human pose and shape estima-
tion. In CVPR , 2023. 2
[33] Zhengqi Li, Tali Dekel, Forrester Cole, Richard Tucker,
Noah Snavely, Ce Liu, and William T Freeman. Learning
the depths of moving people by watching frozen people. In
CVPR , 2019. 6, 7
[34] Zhihao Li, Jianzhuang Liu, Zhensong Zhang, Songcen Xu,
and Youliang Yan. Cliff: Carrying location information in
full frames into human pose and shape estimation. In ECCV ,
2022. 2
[35] Kevin Lin, Lijuan Wang, and Zicheng Liu. End-to-end hu-
man pose and mesh reconstruction with transformers. In
CVPR , 2021. 2
914
[36] Kevin Lin, Lijuan Wang, and Zicheng Liu. Mesh
graphormer. In CVPR , 2021. 2
[37] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll ¬¥ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. In
ECCV , 2014. 6
[38] Matthew Loper, Naureen Mahmood, Javier Romero, Gerard
Pons-Moll, and Michael J Black. Smpl: A skinned multi-
person linear model. ACM TOG , 2015. 1, 2, 4
[39] Dushyant Mehta, Helge Rhodin, Dan Casas, Pascal
Fua, Oleksandr Sotnychenko, Weipeng Xu, and Christian
Theobalt. Monocular 3d human pose estimation in the wild
using improved cnn supervision. In 3DV, 2017. 6
[40] Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani,
Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, and
Michael J Black. Expressive body capture: 3d hands, face,
and body from a single image. In CVPR , 2019. 1, 2
[41] Sigal Raab, Inbal Leibovitch, Guy Tevet, Moab Arar, Amit H
Bermano, and Daniel Cohen-Or. Single motion diffusion. In
ICLR , 2024. 2
[42] Davis Rempe, Tolga Birdal, Aaron Hertzmann, Jimei Yang,
Srinath Sridhar, and Leonidas J Guibas. Humor: 3d human
motion model for robust pose estimation. In ICCV , 2021. 2
[43] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj ¬®orn Ommer. High-resolution image syn-
thesis with latent diffusion models. In CVPR , 2022. 1, 3
[44] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch,
Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine
tuning text-to-image diffusion models for subject-driven
generation. In CVPR , 2023. 3
[45] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li,
Jay Whang, Emily Denton, et al. Photorealistic text-to-
image diffusion models with deep language understanding.
InNeurIPS , 2022. 3
[46] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,
and Surya Ganguli. Deep unsupervised learning using
nonequilibrium thermodynamics. In ICML , 2015. 3
[47] Jie Song, Xu Chen, and Otmar Hilliges. Human body model
fitting by learned gradient descent. In ECCV , 2020. 2, 6, 7
[48] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denois-
ing diffusion implicit models. In ICLR , 2021. 2, 3, 4
[49] Jiaming Song, Arash Vahdat, Morteza Mardani, and Jan
Kautz. Pseudoinverse-guided diffusion models for inverse
problems. In ICLR , 2023. 3, 4
[50] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-based
generative modeling through stochastic differential equa-
tions. In ICLR , 2021. 1, 3
[51] Anastasis Stathopoulos, Georgios Pavlakos, Ligong Han,
and Dimitris Metaxas. Learning articulated shape with key-
point pseudo-labels from web images. In CVPR , 2023. 2
[52] Guy Tevet, Sigal Raab, Brian Gordon, Yonatan Shafir,
Daniel Cohen-Or, and Amit H Bermano. Human motion dif-
fusion model. In ICLR , 2023. 2
[53] Garvita Tiwari, Dimitrije Anti ¬¥c, Jan Eric Lenssen, Nikolaos
Sarafianos, Tony Tung, and Gerard Pons-Moll. Pose-ndf:
Modeling human pose manifolds with neural distance fields.
InECCV , 2022. 2[54] Timo V on Marcard, Roberto Henschel, Michael J Black,
Bodo Rosenhahn, and Gerard Pons-Moll. Recovering ac-
curate 3d human pose in the wild using imus and a moving
camera. In ECCV , 2018. 6
[55] Yufu Wang and Kostas Daniilidis. Refit: Recurrent fitting
network for 3d human recovery. In ICCV , 2023. 2
[56] Shangzhe Wu, Ruining Li, Tomas Jakab, Christian Rup-
precht, and Andrea Vedaldi. Magicpony: Learning articu-
lated 3d animals in the wild. In CVPR , 2023. 2
[57] Donglai Xiang, Hanbyul Joo, and Yaser Sheikh. Monocular
total capture: Posing face, body, and hands in the wild. In
CVPR , 2019. 2
[58] Hongyi Xu, Eduard Gabriel Bazavan, Andrei Zanfir,
William T Freeman, Rahul Sukthankar, and Cristian Smin-
chisescu. Ghum & ghuml: Generative 3d human shape and
articulated pose models. In CVPR , 2020. 2
[59] Gengshan Yang, Minh V o, Natalia Neverova, Deva Ra-
manan, Andrea Vedaldi, and Hanbyul Joo. Banmo: Building
animatable 3d neural models from many casual videos. In
CVPR , 2022. 2
[60] Vickie Ye, Georgios Pavlakos, Jitendra Malik, and Angjoo
Kanazawa. Decoupling human and camera motion from
videos in the wild. In CVPR , 2023. 1, 2
[61] Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, and Jan
Kautz. Physdiff: Physics-guided human motion diffusion
model. In CVPR , 2023. 2
[62] Hongwen Zhang, Yating Tian, Xinchi Zhou, Wanli Ouyang,
Yebin Liu, Limin Wang, and Zhenan Sun. Pymaf: 3d human
pose and shape regression with pyramidal mesh alignment
feedback loop. In CVPR , 2021. 1, 2
[63] Zhixing Zhang, Bichen Wu, Xiaoyan Wang, Yaqiao Luo,
Luxin Zhang, Yinan Zhao, Peter Vajda, Dimitris Metaxas,
and Licheng Yu. Avid: Any-length video inpainting with
diffusion model. In CVPR , 2024. 3
[64] Yi Zhou, Connelly Barnes, Jingwan Lu, Jimei Yang, and Hao
Li. On the continuity of rotation representations in neural
networks. In CVPR , 2019. 5
915
