NC-TTT: A Noise Constrastive Approach for Test-Time Training
David Osowiechi* Gustavo A. Vargas Hakim∗
Mehrdad Noori Milad Cheraghalikhani Ali Bahri Moslem Yazdanpanah
Ismail Ben Ayed Christian Desrosiers
´ETS Montr ´eal, Canada
Abstract
Despite their exceptional performance in vision tasks,
deep learning models often struggle when faced with do-
main shifts during testing. Test-Time Training (TTT) meth-
ods have recently gained popularity by their ability to en-
hance the robustness of models through the addition of an
auxiliary objective that is jointly optimized with the main
task. Being strictly unsupervised, this auxiliary objective
is used at test time to adapt the model without any access
to labels. In this work, we propose Noise-Contrastive Test-
Time Training (NC-TTT), a novel unsupervised TTT tech-
nique based on the discrimination of noisy feature maps.
By learning to classify noisy views of projected feature
maps, and then adapting the model accordingly on new do-
mains, classiﬁcation performance can be recovered by an
important margin. Experiments on several popular test-
time adaptation baselines demonstrate the advantages of
our method compared to recent approaches for this task.
The code can be found at: https://github.com/
GustavoVargasHakim/NCTTT.git
1. Introduction
A crucial requirement for the success of traditional deep
learning methods is that training and testing data should be
sampled from the same distribution. As widely shown in
the literature [ 20,22], this assumption rarely holds in prac-
tice and a model’s performance can drop dramatically in the
presence of domain shifts. The ﬁeld of Domain Adaptation
(DA) has emerged to address this important issue, propos-
ing various mechanisms that adapt learning algorithms to
new domains.
In the realm of domain adaptation, two notable directions
of research have surfaced: Domain Generalization and Test-
Time Adaptation. Domain Generalization (DG) approaches
*Equal contribution. Correspondence to
david.osowiechi.1@ens.etsmtl.ca , gustavo-adolfo.vargas-
hakim.1@ens.etsmtl.ca[12,21,24,26,27] typically train a model with an ex-
tensive source dataset encompassing diverse domains and
augmentations, so that it can achieve a good performance
on test examples from unseen domains, without retraining.
Conversely, Test-Time Adaptation (TTA) [ 2,11,25] entails
the dynamic adjustment of the model to test data in real-
time, typically adapting to subsets of the new domain, such
as mini-batches. TTA presents a challenging, yet practical
problem as it functions without supervision for test sam-
ples or access to the source domain data. While they do
not require training data from diverse domains as DG ap-
proaches, TTA methods are often susceptible to the choice
of unsupervised loss used at test time, a factor that can sub-
stantially inﬂuence their overall performance. Test-Time
Training (TTT), as presented in [ 5,7,15,19,23], offers
a compelling alternative to TTA. In TTT, an auxiliary task
is learned from the training data (source domain) and subse-
quently applied during test-time to reﬁne the model. Gener-
ally, unsupervised and self-supervised tasks are selected for
their capacity to support an adaptable process, without rely-
ing on labeled data. Finally, employing a dual-task training
approach in the source domain allows the model to be more
conﬁdent at test time, as it is already familiar with the aux-
iliary loss.
Motivated by recent developments in machine learn-
ing using Noise-Contrastive Estimation (NCE) [ 1,16,18],
we introduce a Noise-Contrastive Test-Time-Training (NC-
TTT) method that efﬁciently learns the distribution of
sources samples by contrasting it with a noisy distribution.
This is achieved by training a discriminator that learns to
distinguish noisy out-of-distribution (OOD) features from
in-distribution ones. At test time, the output of the discrimi-
nator is used to guide the adaptation process, modifying the
parameters of the network encoder so that it produces fea-
tures that match in-distribution ones. Our contributions can
be summarized as follows:
• We present an innovative Test-Time Training approach in-
spired by the paradigm of Noise-Constrastive Estimation
(NCE). While NCE was initially proposed for generative
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
6078
models as a way to learn a data distribution without hav-
ing to explicitly compute the partition function [ 6,16],
and later employed for unsupervised representation learn-
ing [1,18], our work is the ﬁrst to show the usefulness of
this paradigm for test-time training.
• We motivate our method with a principled and efﬁcient
framework deriving from density estimation, and use this
framework to guide the selection of important hyperpa-
rameters.
• In a comprehensive set of experiments, we expose our
NC-TTT method to a variety of challenging TTA scenar-
ios, each featuring unique types of domain shifts. Re-
sults of these experiments demonstrate the superior per-
formance of our method compared to recent approaches
for this problem.
The subsequent sections of this paper are structured as fol-
lows. Section 2reviews prior research on TTA, TTT, and
NCE. Section 3presents our NC-TTT method along with
the experimental framework for its evaluation, detailed in
Section 4. Section 5offers experimental results and dis-
cussions, while Section 6concludes the paper with ﬁnal re-
marks.
2. Related work
Test-Time Adaptation. TTA is the challenging problem
of adapting a pre-trained model from a source domain to
an unlabeled target domain in an online manner (i.e., on a
batch-wise basis). In this problem, it is assumed that the
model no longer has access to source samples, making the
setting more realistic and applicable as an off-the-shelf tool.
Finally, the online nature of TTA also limits the possibil-
ity of computing accurate target data distributions, specially
when the number of samples is low.
Two classic TTA methods have prevailed in the lit-
erature, Prediction Time Batch Normalization (PTBN)
[17] and Test-Time Adaptation by Entropy Minimization
(TENT) [ 25]. The former consists in simply recomputing
the statistics from each batch of data inside the batch norm
layers, instead of using the frozen source statistics. The later
goes one step further by minimizing the entropy loss on the
model’s predictions and updating only the afﬁne parame-
ters of the batch norm layers. Recently, LAME [ 2] intro-
duced a closed-form optimization mechanism that acts on
the model’s predictions for target images. This method is
based on the Laplacian of the feature maps, which enforces
their clustering based on similarity. A more detailed pre-
sentation of TTA approaches can be found in [ 14].
Test-Time Training. TTA methods assume the existence
of an implicit property in the model that can be linked to ac-
curacy and can be used for adaptation at test time (e.g., en-
tropy [ 25]). In contrast, TTT techniques explicitly introduce
a given property by learning a secondary task alongside themain classiﬁcation task at training. As seminal work in the
ﬁeld, TTT [ 23] introduced a Y-shaped architecture allow-
ing for a self-supervised rotation prediction task. This sub-
network can be attached to any layer of a CNN. Formally,
the overall TTT objective is composed of a supervised loss
Lsup(e.g., cross-entropy) and an auxiliary, task-dependent
lossLaux, as follows:
LTTT=Lsup+λLaux (1)
The auxiliary loss is used at test time to update the model’s
encoder, reconditioning the features into being more simi-
lar to those from the source domain. TTT++ [ 15] proposed
using contrastive learning as the secondary task, while also
preserving statistical information from the source domain’s
feature maps to align the test-time features. Similarly, TTT-
MAE [ 9] used Masked Autoencoder (MAE) [ 5] image re-
construction as the auxiliary task. Normalizing Flows (NF)
[4,13] have also been employed in TTTFlow [ 19], adapt-
ing the feature encoder at test time by approximating a
likelihood-based domain shift detector. Unlike previous ap-
proaches, TTTFlow requires two separate training proce-
dures for the original model and the NF network, which
makes source training more complex. Recently, ClusT3 [ 7]
introduced an unsupervised secondary task where the pro-
jected features of a given layer are clustered using a mu-
tual information maximization objective. Although ClusT3
achieves competitive results, the hyperparameters of this
method (e.g., number clusters) are dataset dependent, which
limits its generalization capabilities.
Noise-contrastive estimation (NCE). Our work is also re-
lated to NCE, a useful tool to model unknown distibutions
bycomparison [6]. In NCE, a dataset is contrasted against a
set of noisy points drawn by an arbitrary distribution. A dis-
criminator is then trained to distinguish between both sets,
thereby learning the original dataset’s properties. This ap-
proach has been employed to learn word embeddings [ 16],
training Variational Autoencoders [ 1], and self-supervised
learning (InfoNCE) [ 18], among others. To our knowledge,
this work is the ﬁrst to investigate the potential of NCE for
test-time training. We hypothesize that NCE is well suited
to estimate the source domain distribution at training time,
and that this estimation can be used in an unsupervised man-
ner at test time to adapt a model to target domain samples.
3. Methodology
We begin by presenting an overview of our NC-TTT
method for Test-Time Training. We then proceed to detail
the Noise-Contrastive Estimation framework on which it is
grounded.
3.1. The proposed method
The problem of Test-Time Training can be formally de-
ﬁned as follows. Let the source domain be represented
6079
Figure 1. Overview of our Noise-Contrastive Test-Time-Training (NC-TTT) method. The auxiliary module comprises a linear projector
pϕthat reduces the scale of features, and a classiﬁer qϕto discriminate between two different noisy views of the reduced features.
by a joint distribution P(Xs,Ys), whereXsandYscor-
respond to the image and labels spaces, respectively. Like-
wise, denote as P(Xt,Yt)the target domain distribution,
withXtandYtas the respective target images and labels.
Following previous research, we consider the likelihood
shift [ 2] between source and target datasets, expressed as
P(Xs|Ys)̸=P(Xt|Yt), and assume the label space to be
the same between domains ( Ys=Yt). Given a model
F:X → Y trained on source data (x,y)∈ Xs× Ys,
the goal of TTT is to adapt this model to target domain ex-
amples from Xtat test time, without having access to source
samples or target labels.
As shown in Fig. 1, our NC-TTT model follows the same
Y-shaped architecture as in previous works, with the ﬁrst
branch corresponding to the main classiﬁcation task and
the second one to the auxiliary TTT task. The classiﬁ-
cation branch can be deﬁned as Fθ,ϕ= (hϕ◦fθ)where
fθ= (fL
θ◦...◦f1
θ)is an encoder that transforms images
into feature maps via Lconvolutional layers (blocks) and hϕ
is a classiﬁcation head that takes features from the last en-
coder layer and outputs the class probabilities. This branch
is trained with a standard cross-entropy loss LCE
Following recent TTT approaches [ 7,19], our auxiliary
task operates on the features of the encoder. Without loss of
generality, we suppose that the features come from layer ℓ
of the encoder and denote as fℓ
θ(x)∈RB×W×H×DtheD
feature maps of size W×Hfor a batch of Bimages. We ﬁrst
reshape these feature maps to a (BWH)×Dfeature matrix
and then use a linear projector to reduce its dimensional-
ity, giving projected features z=pφ(fℓ
θ(x))∈RBWH×d
withd≪D. Next, we generate two noisy versions of z,
an in-distribution version ˜zs=z+ϵs,ϵs∼ N(0,σ2
sI),
and an out-of-distribution (OOD) version ˜zo=z+ϵo,
ϵo∼ N(0,σ2
oI)whereσo> σs. These noisy features are
fed into a discriminator qφwhich predicts in-distribution
probabilities [0,1]BWH. This discriminator, which is builtusing two linear layers with ReLU in between, is trained by
minimizing loss Lauxcomputing the binary cross-entropy
between the predicted probabilities and soft-labels which
will be described in the next section. To update the encoder
parameters at test-time, as we do not have class labels, we
only compute gradients from Laux.
3.2. Noise­contrastive Test­time Training
We now present our noise-contrastive strategy for test-time
training. Let us denote as ps(z)the probability of features
from the source domain. Our method employs a density
estimation strategy to learn ps(z)from training source ex-
amplesDs={zi}Ns
i=1, whereNs=BWH . Afterwards, it
uses the estimated distribution ˆps(z)to adapt the model to
distribution shifts at test time.
Estimating the source distribution. We consider the well-
known kernel density estimation approach to model ps(z).
This approach puts a small probability mass around each
training example xi∈ Ds, in the shape of a D-dimensional
Gaussian with isotropic variance Σs=σ2
sI, and then esti-
mates the distribution as
ˆps(z) =1
Ns(2π/parenrightbigD/2σDsNs/summationdisplay
i=1exp/parenleftbigg
−1
2σ2s∥z−zi∥2/parenrightbigg
(2)
At test-time, one could use this probability estimation to de-
ﬁne an adaption objective Lauxthat minimizes the negative
log-likelihood of test examples Dt={zj}Nt
j=1:
Laux=−1
NtNt/summationdisplay
j=1logˆps(zj). (3)
However, this simple approach faces two important issues.
First, estimating the density in high-dimensional space is
problematic since moving away from a training example
6080
Figure 2. Posterior probability p(ys= 1|z)of 2D points with different pairs (σs,σo). The in-domain inﬂuence expands by increasing
σofor a ﬁxed σs(see difference row-wise). Furthermore, this region is more regular when σsincreases when σois ﬁxed (see difference
column-wise).
Figure 3. Noise 2D vectors sampled with σs= 0.05andσo=
1(left). The overlapping of both distributions can be overcome
by assigning a probability to each point based on our threshold
method.
quickly reduces the probability to zero. Second, the training
examples from the source domain are no longer available at
test time, hence the density of samples in Eq. ( 2) cannot be
evaluated.
To overcome these issues, we propose a noise contrastive
approach, which uses a discriminator to learn feature dis-
tribution ps(z). Toward this goal, we contrast ps(z)with
an out-of-domain distribution po(z)which is also estimated
using Eq. ( 2) but replacing the variance with σ2
o, where
σo> σs. Letysbe a domain indicator variable such that
ys= 1 if an example is from the source domain, else
ys= 0. Assuming equal priors p(ys= 1) =p(ys= 0) , we
can use Bayes’ theorem to get the posterior
p(ys= 1|z) =ˆps(z)
ˆps(z) +ˆpo(z). (4)
To illustrate this model, we show in Figure 2the prob-
abilityp(ys= 1|z)obtained for different values of σs
andσo, when training with randomly-sampled 2D points.
For a ﬁxed σs, increasing σoexpands the in-domain region
around the training samples. Likewise, for the same σo,using a greater σsgives a larger and more regular (less de-
termined by individual points) in-domain region.
Training the disciminator. To train the discriminator
qφ(·), for each training example zi∈ Ds, we generate
2Msamples˜zi,m=zi+ϵi,m, the ﬁrst Mfrom the in-
domain distribution, i.e. ϵi,m∼ N(0,σ2
sI), and the other
Mones from the noisier out-of-domain distribution, i.e.
ϵi,m∼ N(0,σ2
oI). For these samples, we assume that
exp(−∥˜zi,m−zj∥2
2/2σ2
s)≈0, forj̸=i, hence the poste-
rior simpliﬁes to
p(ys= 1|˜zi,m) =
σ−D
sexp/parenleftBig
−1
2σ2s∥ϵi,m∥2/parenrightBig
σ−Dsexp/parenleftBig
−1
2σ2s∥ϵi,m∥2/parenrightBig
+σ−Doexp/parenleftBig
−1
2σ2o∥ϵi,m∥2/parenrightBig
(5)
whereϵi,m=˜zi,m−zi. For large values of D, this for-
mulation is numerically unstable it leads to division by zero
errors. Instead, we use an equivalent formulation p(ys=
1|˜z) = sigmoid( u), where pre-activation “logit” uis given
by
u=1
2/parenleftbigg1
σ2o−1
σ2s/parenrightbigg
∥ϵi,m∥2+Dlog/parenleftbiggσo
σs/parenrightbigg
(6)
See Appendix A in the supplementary material for a proof.
The in-domain region, p(ys= 1|˜z)≥0.5, which corre-
sponds to the case where u≥0, is thus deﬁned by the fol-
lowing condition:
∥ϵi,m∥ ≤σsσo/radicalBigg
2D
(σ2s−σ2o)log/parenleftbiggσs
σo/parenrightbigg
(7)
Figure 3shows examples of noise vectors ϵsampled with
σs= 0.05andσo= 1 (left), and their corresponding pos-
terior probability ( right ). As can be seen, the posterior
6081
-2 -1 0 1 2-2-1012<s= 0 :05;<o= 5
0.20.40.60.8
Figure 4. Heatmap of in-distribution probabilities, i.e., p(ys=
1|z)approximated by qϕ(z)in our model, and spatial gradient
of log-likelihood function, i.e. ∇logqϕ(z), which is used as test-
time adaptation objective. The arrow shows how an OOD test sam-
ple (white point) is adapted toward the source distribution.
probability correctly separates in-distribution samples from
OOD ones. Doing so, it overcomes the problem of having
OOD samples that are similar to in-distribution ones (red
circles near the center), which would confuse the discrimi-
nator during training.
Using these samples ˜zi,m, we train the discriminator
qφ(·)by minimizing the cross-entropy between its predic-
tion and the soft-label ˜pi,m=p(ys= 1|˜zi,m):
Laux=−1
2MNsNs/summationdisplay
i=12M/summationdisplay
m=1˜pi,mlogqφ(˜zi,m)
+/parenleftbig
1−˜pi,m/parenrightbig
log/parenleftbig
1−qφ(˜zi,m)/parenrightbig(8)
Adapting the model at test time. During inference, we
adapt the parameters of the encoder in layers where the aux-
iliary loss is computed, as well as those of preceding layers.
The adaptation modiﬁes the encoder so that the trained dis-
criminator qφ(·)perceives the encoded features {zj}Nt
j=1of
test examples as being in-distribution. This is achieved by
minimizing the following test-time loss:
Ltest
aux=−1
NtNt/summationdisplay
j=1logqφ(zj) (9)
As illustrated in Fig. 4, our method models the in-
distribution probability p(ys= 1|z)using NCE and then
approximates this distribution with discriminator qφ(·). At
test time, the encoder is updated to move OOD features
(white point) toward the source distribution, making them
more suitable for the source-trained classiﬁer. Thanks to
the non-zero in-distribution noise ( σs>0), we avoid over-
adapting the encoder (the white point stops at the border of
the in-distribution region and not at a training sample), a
problem often found in other TTT approaches.
3.3. Selecting the distribution variances
Our model requires to specify the in-distribution variance
σ2
sand the OOD variance σ2
o. In this section, we presenthow these can be chosen. The OOD variance should be
greater than the in-distribution, hence we can write σo=
βσs, withβ=σo/σs>1. Hence,βis a measure of noise
ratio for the in-distribution and OOD samples. Using this
relationship, Eq. ( 6) simpliﬁes to
u=−1
2σ2s/parenleftbiggβ2−1
β2/parenrightbigg
∥ϵ∥2+Dlogβ (10)
For OOD samples, the expected value of “logit” uis then
given by
uβ=Eϵ∼N(0,σ2oI)/bracketleftbigg
−1
2σ2s/parenleftbiggβ2−1
β2/parenrightbigg
∥ϵ∥2+Dlogβ/bracketrightbigg
=−1
2σ2s/parenleftbiggβ2−1
β2/parenrightbigg
Eϵ∼N(0,σ2
oI)/bracketleftbig
∥ϵ∥2/bracketrightbig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
σ2
o=β2σ2
s+Dlogβ
=−1
2/parenleftbig
β2−1/parenrightbig
+Dlogβ
(11)
Figure 5show how the expected in-distribution predic-
tionE[ys|z] = sigmoid( uβ)varies as function of β, for
D= 16 (the dimension used in our experiments). In this
case, to have near-zero probability for OOD samples, one
can choose any β >1.5. In our experiments, we selected
β= 2.
Figure 5. Expected in-distribution label as a function of noise ratio
β=σo/σs.
4. Experimental Settings
We evaluate NC-TTT on several TTT datasets, following
the protocol of previous works. These benchmarks emulate
different challenging domain shift scenarios, which help
evaluating the effectiveness of our approach. As in [ 7,23],
these benchmarks are categorized as common corruptions ,
andsim-to-real domain shift.
Forcommon corruptions , we evaluate our method on
CIFAR-10-C and CIFAR-100-C [ 10]. This family of do-
main shifts include 15 different corruptions such as Gaus-
sian noise, JPEG compression, among others. Each corrup-
tion has 5 different levels of severity with 10,000 images,
which amounts to 75 different testing scenarios. For each
6082
IterationsAccuracy (%)
20406080100
10 20 30 40 50Gaussian Noise Shot Noise Impulse Noise Defocus Blur
Glass Blur Motion Blur Zoom Blur Snow Frost Fog
Brightness Contrast Elastic Transform Pixelate 1 autresFigure 6. Evolution of accuracy on all corruptions in CIFAR-10-
C.
of the aforementioned datasets, CIFAR-10 and CIFAR-100
are used as source domains, with 10 and 100 classes respec-
tively. Finally, the challenging large-scale VisDA-C [ 20]
dataset corresponds to the sim-to-real domain shift . The
source domain comprises a training set of 152,397 images
of 3D renderings from 12 different classes, while the test set
consists in 72,372 video frames of the same categories.
Source training. The cross-entropy and auxiliary losses
are jointly trained on the source dataset. We explored dif-
ferent architectural choices for each setting. For common
corruptions (i.e. CIFAR-10/100-C), we deﬁne the projector
as a1×1convolutional layer that reduces the number of
channels to D= 96 to later be ﬂattened for classiﬁcation.
We utilize a discriminator composed of two linear layers
with a Batch Norm layer and Leaky ReLU in between, and
a hidden dimension of 1024 in the intermediate layer. For
this particular case, we use the tuple (σs= 0,σo= 0.015) ,
which was experimentally determined as it produced the
best performance. The model is trained using 128 images
per batch for 350 epochs using SGD, an initial learning rate
of 0.1, and a multi-step scheduler with a decreasing factor
of 10 at epochs 150 and 250. Due to the challenging nature
of the sim-to-real domain shift from VisDA-C, we escalate
the architecture to make it able to learn more source do-
main information. We utilize a 1×1convolutional projector
with an output number of channels of D= 16 . As opposed
to ﬂattening the features, we also employ two 1×1convo-
lutional layers for the discriminator, with an intermediate
number of channels of 1024 . The noise values are sampled
with(σs= 0.025,σo= 0.05)and added pixel-wise to the
projected feature maps. Following related works’ protocol
for VisDA-C, we use an ImageNet-pre-trained model [ 3]
as a warm start, to then perform the source training with a
batch size of 50 for 100 epochs with SGD and a learning
rate of 0.01. ResNet50 [ 8] is the chosen architecture for all
datasets.Test-time adaptation. Adaptation is performed on the en-
coder’s blocks (including BatchNorm layers). If the auxil-
iary task is plugged to the third layer block, for instance, the
weights of all the previous blocks will be optimized. The
source training on CIFAR-10 is used to adapt for CIFAR-
10-C. In an analog way, CIFAR-100 is utilized to adapt for
CIFAR-100-C. For all this cases, the ADAM optimizer with
a learning rate of 10−5is used in batches of 128 images. As
for VisDA-C, a batch size of 50 is employed with a learning
rate of10−4. The weights of the source model are restored
after each batch.
Benchmarking. We compare the performance of NC-
TTT with previous works from the state-of-the-art in TTT
and TTA. Chosen works in TTA include PTBN [ 17],
TENT [ 25], and LAME [ 2], whereas for TTT we con-
sider TTT [ 23], TTT++ [ 15], and ClusT3 [ 7]. We utilize
the source model (named ResNet50 in our results) without
adaptation to measure accuracy gains.
5. Results
In this section, we present the experimental results obtained
from NC-TTT and compare them against the state-of-the-
art. In accordance with previous TTT research, we also
offer insights on the working mechanisms that take part in
the success of our technique.
5.1. Image classiﬁcation on common corruptions
We assess the performance of ClusT3 using the CIFAR-
10/100-C dataset, considering 15 distinct corruptions. Sub-
sequently, our experiments concentrate exclusively on
Level 5, recognized as the most demanding adaptation sce-
nario. Comprehensive results for all severity levels are pro-
vided in the Supplementary material.
The data presented in Fig 6reveals that peak accuracy
is typically reached around 20 iterations, depending on the
speciﬁc corruption type. Remarkably, accuracy remains sta-
ble even beyond the 20th iteration. In the case of certain
corruptions, speciﬁcally the ones with noise such as Im-
pulse Noise which signiﬁcantly degrade the image quality,
we observe a decline in performance with an increase in the
number of adaptation iterations.
As shown in Table 1, NC-TTT achieves an average
improvement of 30.61 %with respect to the baseline (i.e.
ResNet50), and obtains a considerable advantage in all the
different corruptions. Moreover, our method achieves to
outperform ClusT3 in most corruptions and in average for
the whole dataset. It is worth noticing that, besides the
strong relation of NC-TTT to Gaussian-like noise, the per-
formance on the Gaussian Noise corruption is not neces-
sarily the highest, which could be due to the fact that the
auxiliary task does not bias the model towards any type
of domain shift. Table 2shows a more surprising trend
6083
ResNet50 LAME [ 2] PTBN [ 17] TENT [ 25] TTT [ 23] TTT++ [ 15] ClusT3 [ 7] NC-TTT (ours)
Gaussian Noise 21.01 22.90±0.07 57.23±0.13 57.15±0.19 66.14±0.12 75.87±5.05 76.01±0.19 75.30±0.04
Shot noise 25.77 27.11±0.13 61.18±0.03 61.08±0.18 68.93±0.06 77.18±1.36 77.67±0.17 77.74±0.05
Impulse Noise 14.02 30.99±0.15 54.74±0.13 54.63±0.15 56.65±0.03 70.47±2.18 69.76±0.15 68.80±0.11
Defocus blur 51.59 45.16±0.13 81.61±0.07 81.39±0.22 88.11±0.08 86.02±1.35 87.85±0.11 88.77±0.09
Glass blur 47.96 36.58±0.06 53.43±0.11 53.36±0.14 60.67±0.06 69.98±1.62 71.34±0.15 70.15±0.16
Motion blur 62.30 55.41±0.15 78.20±0.28 78.04±0.17 83.52±0.03 85.93±0.24 86.10±0.11 86.93±0.05
Zoom blur 59.49 51.48±0.20 80.29±0.13 80.26±0.22 87.25±0.03 88.88±0.95 86.68±0.05 88.40±0.06
Snow 75.41 66.14±0.12 71.59±0.21 71.59±0.04 79.29±0.05 82.24±1.69 83.71±0.09 84.92±0.08
Frost 63.14 50.03±0.22 68.77±0.25 68.52±0.20 79.84±0.11 82.74±1.63 83.69±0.03 84.79±0.05
Fog 69.63 64.56±0.19 75.79±0.05 75.73±0.10 84.46±0.09 84.16±0.28 85.12±0.13 86.85±0.10
Brightness 90.53 84.27±0.10 84.97±0.05 84.77±0.13 91.23±0.08 89.07±1.20 91.52±0.02 93.05±0.03
Contrast 33.88 31.46±0.23 80.81±0.15 80.70±0.15 88.58±0.09 86.60±1.39 84.40±0.11 87.78±0.15
Elastic transform 74.51 64.23±0.10 67.14±0.17 67.13±0.10 75.69±0.10 78.46±1.83 82.04±0.17 80.99±0.11
Pixelate 44.43 39.32±0.08 69.17±0.31 68.70±0.29 76.35±0.19 82.53±2.01 82.03±0.09 82.26±0.11
JPEG compression 73.61 66.19±0.02 65.86±0.05 65.83±0.07 73.10±0.19 81.76±1.58 83.24±0.10 79.66±0.06
Average 53.82 49.06 70.05 69.93 77.32 81.46 82.08 82.43
Table 1. Accuracy (%) on CIFAR-10-C dataset with Level 5 corruption for NC-TTT compared to previous TTA and TTT methods.
ResNet50 LAME [ 2] PTBN [ 17] TENT [ 25] TTT [ 23] ClusT3 [ 7] NC-TTT (ours)
Gaussian Noise 12.67 10.55±0.08 43.00±0.16 43.17±0.24 33.99±0.11 49.77±0.18 46.03±0.12
Shot noise 14.79 12.58±0.04 44.57±0.16 44.47±0.23 36.55±0.08 50.54±0.16 47.04±0.14
Impulse Noise 6.47 5.83±0.07 36.76±0.11 36.64±0.28 26.87±0.08 44.35±0.31 41.53±0.11
Defocus blur 29.97 29.07±0.11 66.68±0.06 66.74±0.06 65.96±0.14 64.40±0.12 67.00±0.09
Glass blur 21.36 19.58±0.02 45.17±0.08 45.09±0.06 34.90±0.01 50.78±0.24 48.08±0.07
Motion blur 39.60 41.26±0.09 62.61±0.17 62.54±0.23 57.10±0.10 62.62±0.15 64.31±0.02
Zoom blur 35.75 34.93±0.02 65.36±0.03 65.29±0.05 62.90±0.07 63.81±0.08 66.24±0.25
Snow 42.05 43.58±0.20 52.82±0.27 52.31±0.16 54.97±0.03 55.84±0.12 58.70±0.10
Frost 31.44 32.67±0.12 51.92±0.09 51.79±0.23 54.60±0.16 55.46±0.06 58.55±0.11
Fog 30.96 35.95±0.12 55.78±0.05 55.91±0.28 55.80±0.09 51.39±0.07 57.73±0.17
Brightness 61.80 64.84±0.03 66.20±0.06 66.47±0.06 73.25±0.06 66.71±0.11 71.36±0.10
Contrast 12.31 15.50±0.04 60.84±0.15 60.91±0.19 60.97±0.09 54.67±0.05 61.53±0.20
Elastic transform 53.06 51.32±0.13 56.38±0.04 56.43±0.33 53.51±0.04 59.44±0.27 60.25±0.04
Pixelate 26.08 27.65±0.02 58.21±0.14 58.19±0.22 50.39±0.05 60.75±0.09 61.17±0.33
JPEG compression 52.19 49.95±0.07 51.65±0.16 51.30±0.16 49.62±0.09 59.94±0.12 55.69±0.09
Average 31.37 31.68 54.53 54.48 51.43 56.70 57.68
Table 2. Accuracy (%) on CIFAR-100-C dataset with Level 5 corruption for NC-TTT and the works from the state-of-the-art .
on CIFAR-100-C, as our technique outperforms the clos-
est competitor on the majority of the corruptions, and ob-
tains an average improvement of 26.31% with respect to
ResNet50. Based on the above, NC-TTT can approximate
the source information even when: a) the number of classes
increases, and b) the auxiliary task works at a smaller scale
as the main classiﬁcation task.
Figure 7demonstrates the impact of NC-TTT during
adaptation through t-SNE plots showcasing the target fea-
ture maps before and after adaptation, along with the as-
sociated model predictions. The challenging corruption of
shot noise becomes more manageable with the assistance of
NCE, contributing to improved predictions by reﬁning the
clustering of diverse class samples within the target dataset.5.2. Image classiﬁcation on sim­to­real domain shift
For adaptation on VisDA-C, the ﬁrst encoder’s layer block
is chosen for the auxiliary task. The obtained results concur
with previous works [ 7,23], in that the ﬁrst layers of the
network’s encoder are sufﬁcient for adaptation.
As shown in Table 3, NC-TTT obtains a competitive per-
formance with respect to previous works on VisDA-C. The
severe domain shift in this dataset makes it a very chal-
lenging scenario, as can be seen when testing the source
model. NC-TTT obtains a gain of 16.19% in accuracy, and
surpasses previous methods by an important margin.
6. Conclusions
We proposed NC-TTT, a Test-Time Training method based
on the popular theory of Noise-Contrastive Estimation. Our
6084
(a) Prediction (before adaptation) (b) Prediction (after adaptation)
(c) Ground truth (before adaptation) (d) Ground truth (after adaptation)
Figure 7. t-SNE visualizations depict shot noise characteristics in the features extracted from NC-TTT. Panels (a) and (b) illustrate the
model predictions without and with 20 iterations of adaptation, respectively. Panels (c) and (d) showcase the ground truth labels in the
absence of adaptation and for the adapted representations, respectively.
Method Acc. (%)
ResNet50 46.31
LAME-L [ 2] 22.02±0.23
LAME-K [ 2] 42.89±0.14
LAME-R [ 2] 19.33±0.11
PTBN [ 17] 60.33±0.04
TENT [ 25] 60.34±0.05
TTT [ 23] 40.57±0.02
ClusT3 [ 7] 61.91±0.02
NC-TTT (ours) 62.71±0.09
Table 3. Results on VisDA-C.
method learns a proximal representation of the source do-
main by discriminating between noisy views of feature
maps. The entire model can be added on top of any given
layer of a CNN’s encoder, and comprises only a linear pro-
jector and a classiﬁer.
The proposed experiments support already established
hypothesis of TTT, which states that adaptation in the ﬁrst
encoder’s layer blocks (e.g. ﬁrst or second) is often sufﬁ-
cient to recover the model’s performance on a new domain.NC-TTT is evaluated on different challenging benchmarks,
and its performance is compared against recent state-of-the-
artmethods in the ﬁeld.
This work leads to interesting questions that can be ad-
dressed as future work. First, different types of added noise
could be explored to analyze their impact in the learning of
the auxiliary task. A similar framework can eventually be
derived for different distributions. Moreover, and as an open
question partaking all the existent TTT methods, the ex-
act mechanisms that allow auxiliary tasks to learn domain-
related information are unclear. This is especially intriguing
considering that the scale of such tasks is small compared
to the classiﬁcation task. Their properties and their relation
with the models’ performance a suitable research direction.
References
[1] Jyoti Aneja, Alex Schwing, Jan Kautz, and Arash Vahdat.
A contrastive learning approach for training variational au-
toencoder priors. Advances in neural information processing
systems , 34:480–493, 2021. 1,2
[2] Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, and
6085
Luca Bertinetto. Parameter-free online test-time adaptation.
InIEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 8344–8353, 2022. 1,2,3,6,7,
8
[3] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and
pattern recognition , pages 248–255. Ieee, 2009. 6
[4] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Ben-
gio. Density estimation using real nvp. arXiv preprint
arXiv:1605.08803 , 2016. 2
[5] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei A
Efros. Test-time training with masked autoencoders. In Ad-
vances in Neural Information Processing Systems , 2022. 1,
2
[6] Michael Gutmann and Aapo Hyv ¨arinen. Noise-contrastive
estimation: A new estimation principle for unnormalized
statistical models. In Proceedings of the thirteenth inter-
national conference on artiﬁcial intelligence and statistics ,
pages 297–304. JMLR Workshop and Conference Proceed-
ings, 2010. 2
[7] Gustavo A. Vargas Hakim, David Osowiechi, Mehrdad
Noori, Milad Cheraghalikhani, Ali Bahri, Ismail Ben Ayed,
and Christian Desrosiers. ClusT3: Information Invariant
Test-Time Training. pages 6136–6145, 2023. 1,2,3,5,
6,7,8
[8] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) , 2016. 6
[9] Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr
Doll´ar, and Ross Girshick. Masked autoencoders are scalable
vision learners. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 16000–
16009, 2022. 2
[10] Dan Hendrycks and Thomas Dietterich. Benchmarking neu-
ral network robustness to common corruptions and perturba-
tions. 2019. 5
[11] Ansh Khurana, Sujoy Paul, Piyush Rai, Soma Biswas, and
Gaurav Aggarwal. Sita: single image test-time adaptation.
arXiv:2112.02355 [cs] , 2021. arXiv: 2112.02355. 1
[12] Donghyun Kim, Kaihong Wang, Stan Sclaroff, and Kate
Saenko. A broad study of pre-training for domain gener-
alization and adaptation. In Computer Vision – ECCV 2022 ,
pages 621–638, Cham, 2022. Springer Nature Switzerland.
1
[13] Durk P Kingma and Prafulla Dhariwal. Glow: Generative
ﬂow with invertible 1x1 convolutions. In Advances in Neu-
ral Information Processing Systems . Curran Associates, Inc.,
2018. 2
[14] Jian Liang, Ran He, and Tieniu Tan. A comprehensive sur-
vey on test-time adaptation under distribution shifts. arXiv
preprint arXiv:2303.15361 , 2023. 2
[15] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste
Bellot-Gurlet, Taylor Mordan, and Alexandre Alahi. Ttt++:
When does self-supervised test-time training fail or thrive?
Neural Information Processing Systems (NeurIPS) , 2021. 1,
2,6,7[16] Andriy Mnih and Koray Kavukcuoglu. Learning word em-
beddings efﬁciently with noise-contrastive estimation. Ad-
vances in neural information processing systems , 26, 2013.
1,2
[17] Zachary Nado, Shreyas Padhy, D. Sculley, Alexander
D’Amour, Balaji Lakshminarayanan, and Jasper Snoek.
Evaluating prediction-time batch normalization for robust-
ness under covariate shift. arXiv:2006.10963 [cs, stat] ,
2021. arXiv: 2006.10963. 2,6,7,8
[18] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Repre-
sentation learning with contrastive predictive coding. arXiv
preprint arXiv:1807.03748 , 2018. 1,2
[19] David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad
Noori, Milad Cheraghalikhani, Ismail Ayed, and Christian
Desrosiers. Tttﬂow: Unsupervised test-time training with
normalizing ﬂow. In 2023 IEEE/CVF Winter Conference on
Applications of Computer Vision (WACV) , pages 2125–2126,
Los Alamitos, CA, USA, 2023. IEEE Computer Society. 1,
2,3
[20] Xingchao Peng, Ben Usman, Neela Kaushik, Dequan Wang,
Judy Hoffman, and Kate Saenko. Visda: A synthetic-to-
real benchmark for visual domain adaptation. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) Workshops , 2018. 1,6
[21] Aayush Prakash, Shaad Boochoon, Mark Brophy, David
Acuna, Eric Cameracci, Gavriel State, Omer Shapira, and
Stan Birchﬁeld. Structured domain randomization: Bridging
the reality gap by context-aware synthetic data. In 2019 In-
ternational Conference on Robotics and Automation (ICRA) ,
pages 7249–7255. IEEE, 2019. 1
[22] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and
Vaishaal Shankar. Do CIFAR-10 classiﬁers generalize to
cifar-10? CoRR , abs/1806.00451, 2018. 1
[23] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A.
Efros, and Moritz Hardt. Test-time training with self-
supervision for generalization under distribution shifts. In In-
ternational Conference on Machine Learning (ICML) , 2020.
1,2,5,6,7,8
[24] Riccardo V olpi, Hongseok Namkoong, Ozan Sener, John C
Duchi, Vittorio Murino, and Silvio Savarese. Generalizing
to unseen domains via adversarial data augmentation. Ad-
vances in neural information processing systems , 31, 2018.
1
[25] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Ol-
shausen, and Trevor Darrell. Tent: Fully test-time adaptation
by entropy minimization. 2021. 1,2,6,7,8
[26] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang,
Tao Qin, Wang Lu, Yiqiang Chen, Wenjun Zeng, and Philip
Yu. Generalizing to unseen domains: A survey on domain
generalization. IEEE Transactions on Knowledge and Data
Engineering , 2022. 1
[27] Kaiyang Zhou, Yongxin Yang, Yu Qiao, and Tao Xiang. Do-
main generalization with mixstyle. In International Confer-
ence on Learning Representations , 2020. 1
6086
