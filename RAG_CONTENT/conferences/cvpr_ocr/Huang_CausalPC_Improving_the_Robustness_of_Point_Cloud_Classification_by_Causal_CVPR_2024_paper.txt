CausalPC : Improving the Robustness of Point Cloud Classification by
Causal Effect Identification
Yuanmin Huang, Mi Zhang*, Daizong Ding, Erling Jiang, Zhaoxiang Wang, Min Yang
School of Computer Science, Fudan University, China
{yuanminhuang23@m.,mi zhang@,17110240010@,eljiang21@m.,wangzx23@m.,m yang@ }fudan.edu.cn
Abstract
Deep neural networks have demonstrated remarkable
performance in point cloud classification. However, pre-
vious works show they are vulnerable to adversarial per-
turbations that can manipulate their predictions. Given the
distinctive modality of point clouds, various attack strate-
gies have emerged, posing challenges for existing defenses
to achieve effective generalization. In this study, we for the
first time introduce causal modeling to enhance the robust-
ness of point cloud classification models. Our insight is
from the observation that adversarial examples closely re-
semble benign point clouds from the human perspective. In
our causal modeling, we incorporate two critical variables,
the structural information, (standing for the key feature
leading to the classification) and the hidden confounders,
(standing for the noise interfering with the classification).
The resulting overall framework CausalPC consists of three
sub-modules to identify the causal effect for robust classi-
fication. The framework is model-agnostic and adaptable
for integration with various point cloud classifiers. Our ap-
proach significantly improves the adversarial robustness of
three mainstream point cloud classification models on two
benchmark datasets. For instance, the classification accu-
racy for DGCNN on ModelNet40 increases from 29.2%to
72.0%with CausalPC , whereas the best-performing base-
line achieves only 42.4%.
1. Introduction
Recent years have witnessed tremendous development in
autonomous driving, where understanding 3D point clouds
plays an indispensable role. Although deep neural networks
(DNN) have achieved extraordinary performance in point
cloud classification [32, 33, 45], the deep and non-linear
structure also raises the concern of adversarial attacks . For
instance, an attacker can slightly modify a point cloud by
human-unnoticeable perturbations to mislead the prediction
*Corresponding author: Mi Zhang
Delete
 Shape-invariant
Shift
 Add
OriginalFigure 1. The demonstration of adversarial point clouds generated
by various adversarial attacks.
of a DNN. Since such misprediction can lead to severe con-
sequences in real-world scenarios, the study of adversarial
examples in point cloud classification has become an in-
tense topic in 3D vision.
Existing adversarial attacks for point cloud data are sum-
marized in Fig.1. Each attack holds a distinct geometric pat-
tern. For instance, beyond the conventional shifting points
attacks [15, 51] (i.e., slight perturbation on the position of
existing points), previous works also propose adding [51] or
deleting [62] points as their attack strategies. Recent vari-
ants of shifting points attacks use generative models like
GANs and AutoEncoders to yield perturbed point clouds
[11, 64]. Following the definition of adversarial examples,
these attacks produce such slight perturbations to a point
cloud that are imperceptible to human eyes, which however
become the key for us to design an effective defense.
Existing defenses against adversarial examples in point
cloud data are roughly categorized into adversarial train-
ingandinput-oriented defense . The former incorporates the
generated adversarial examples into the training set, aiding
classifiers in correctly identifying perturbed point clouds
[20, 21]. In contrast, the latter explicitly recognize specific
patterns, such as outliers within adversarial point clouds,
and mitigate these identified patterns [7, 63]. However,
both the above approaches share the common limitation:
they fail to generalize in defending against more sophisti-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
19779
cated attacks. For instance, recent findings [12] reveal that
a model trained with PGD adversarial training can be suc-
cessfully attacked by GeoA3 [46], an intricately designed
attack. Moreover, newly proposed shape-invariant attacks
[12, 46] can evade input-oriented defenses as they introduce
significantly fewer outlier biases during the attack.
When faced with emerging attack strategies, develop-
ing a defense framework that can effectively mitigate di-
verse adversarial examples becomes a primary challenge.
To tackle this issue, we direct our attention to the following
observation: Regardless of the attack strategy to generate
perturbations, the resulting adversarial examples still bear
a strong resemblance to benign ones for human eyes. This
can be observed in Fig.1, where the perturbed point cloud
remains identifiable as a table. Motivated by this finding,
we propose to incorporate the causal language [8, 29] into
the formulation of point cloud classification. This helps in-
vestigate the causal relation between variables which aligns
with human reasoning about the natural world.
Technically, incorporating the causal language in point
cloud applications is challenging: the unique modality of
point cloud data makes it impractical to apply existing
causal modeling and effect identification techniques. In
Section 3, we first summarize two causal variables that in-
fluence point cloud classification, i.e., the structural infor-
mation that humans usually extract to recognize a point
cloud and the hidden confounders that may influence both
the point cloud and prediction, e.g., the potential adversar-
ial perturbations and the noises caused by LiDAR sensors.
Based on the above variables, we build a causal graph to
identify the causal effect from the point cloud data to the
label. We note that humans could correctly identify the
causal effect naturally, i.e., neglecting the influence of the
hidden confounders and paying attention to the structural
information given the point cloud data. Therefore, humans
are insensitive to noises or adversarial perturbations in most
cases. In contrast, existing classifiers are designed to char-
acterize the statistical correlations instead of the causal ef-
fect between the input and the label. As a result, exist-
ing classifiers are sensitive to noises and adversarial per-
turbations, though they seem to be effective in modeling the
structural information in some cases [22, 51].
Following the above analysis, our defense neglects the
influences caused by hidden confounders and identifies the
correct causal effect from the point cloud data to the la-
bel. In Section 4, we propose a novel defense framework
called CausalPC to achieve the goal. Faced with the chal-
lenge that the hidden confounders are difficult to measure
or even observe in this problem, we develop a causal in-
ference algorithm based on front-door adjustment , which
could effectively approximate the expectation of predictions
over all potential hidden confounders. Furthermore, we take
inspiration from the mesh representation of real-world ob-jects and propose an effective module to characterize the
structural information. Finally, we develop a novel atten-
tion module to incorporate the structural information into
the prediction.
In summary, we mainly make the following contributions:
• We propose CausalPC , the first solution to mitigate ad-
versarial examples in point cloud classification through
a causal lens. Instead of focusing on certain kinds of at-
tack techniques or input patterns, we take inspiration from
human recognition systems and propose to identify the
causal effect to make correct classification under various
kinds of adversarial perturbations.
•CausalPC is a model-agnostic defense framework, which
could be incorporated with different point cloud classi-
fiers. With the aid of the proposed causal inference algo-
rithm, we could correctly identify the causal effect with
only slight structure modifications and partial finetuning
on existing classification models.
•CausalPC substantially improves the adversarial robust-
ness of three mainstream PC classification models on two
benchmark datasets (Section 5). For example, the classi-
fication accuracy is increased from 29.2%to72.0%for
DGCNN on ModelNet40, while the best baseline only
achieves 42.4%.
2. Preliminary and Related Work
2.1. Point Cloud Classification
Point cloud classification aims to categorize objects con-
sisting of a set of points with 3D coordinates into differ-
ent classes. Formally, the task can be viewed as learning
a mapping function F:X7→y, where X∈RN×3de-
notes a point cloud with Npoints with 3D coordinates and
y∈ {1,2, . . . , C }denotes the ground truth label among C
categories that Xbelongs to. Recently, deep neural net-
works have achieved great success in point cloud classifica-
tion with their deep non-linear feature extraction capability
[24]. In this paper, we mainly consider point-based models
[32, 33] due to the superior effectiveness of characterizing
geometry patterns. These models directly take 3D coordi-
nates of point clouds as input without further pre-processing
procedures such as voxelization [52] or pillarization [17].
Generally, a point-based model first extracts latent features
for each of the Npoints in an input point cloud X∈RN×3
with its non-linear feature extractor f, e.g., MLP in Point-
Net/PointNet++ [32, 33], GNN in DGCNN [45], and CNN
in PointCNN [19]. Then, a fully-connected layer is used as
the classification head given the extracted global feature h
of the point cloud. For a more comprehensive study, please
refer to the work [24].
19780
2.2. Adversarial Examples
Adversarial attacks aim to mislead the output of DNN mod-
els by introducing minor perturbations to the input sam-
ples. Following attacks targeting image classification mod-
els [9, 39], adversarial attacks have begun to emerge in the
context of point cloud classification as well [46, 51]. The
objective of adversarial attacks can be formulated as,
min
ηL(F(˜X,˜y)),s.t.,||η||p≤δ, (1)
where FandLdenote the model and classification loss
function, η,˜X=X⊕ηand˜yare the perturbation, adver-
sarial example and target label, respectively. Adversarial at-
tacks for point clouds are diverse in methodology. In terms
of the form of perturbations, i.e., ⊕in Eq.1, shifting all the
points by a certain distance [51], adding [22, 51] or delet-
ing [47, 62] points or transforming the entire point cloud
[11, 64] are all alternatives. As for the perturbation budget
||η||p, multiple distance metrics including L0,L2,L∞have
been utilized, e.g., Chamfer Distance as a representative for
L2distance [51].
Adversarial defenses for point cloud classifiers develop
as well. Recent works can be roughly categorized into the
adversarial training (AT)-based ones [21, 59] and the input-
oriented-based ones [63]. The former line takes inspiration
from works in image classification [26], where the defender
augments the training data of a classifier with adversarial
examples. On the other hand, input-oriented-based defenses
pay attention to the particular characteristics introduced by
specific attack strategies. To name a few, SOR [63] fil-
ters out outlier points introduced by adversarial perturba-
tions, while DUP-Net [63] further copes with the inconsis-
tent point density within a point cloud caused by attacks.
GvG [7] tends to correct the relative position bias of local
parts of a perturbed point cloud.
Despite the effectiveness in defending against certain
kinds of attacks, both lines of defense share a similar draw-
back. They generalize poorly to unseen attacks with char-
acteristics other than attacks that have been considered. In
comparison, our work focuses on the inherent characteristic
of point cloud adversarial examples that they preserve the
similarity to normal samples from the perspective of human
perception. Subsequently, we propose a defense method
with the capability to counter various types of attacks.
2.3. Causal Inference
Causality refers to the modeling of relationships between
factors in a task from a human perspective [8, 29]. Al-
though deep neural networks (DNNs) have shown superior
performance over humans in certain tasks, recent studies
have revealed that they may rely on spurious correlations,
as their optimization objective is to learn statistical corre-
lations only [14]. Since DNNs lack the ability to performcausal reasoning, they are more susceptible to paying at-
tention to irrelevant features, such as a model relying on
the wrong parts of input to make classification decisions
[34, 44]. This vulnerability to external noise decreases
model performance, reinforcing the importance of incorpo-
rating causal reasoning into machine learning models.
As a result, several researches have been proposed to
study the causal effect between variables through causal in-
ference [1, 29, 31] to improve the performance of DNNs
from various aspects, such as fairness [10, 16], generaliza-
tion [57], and adversarial robustness [35, 61]. Causal infer-
ence helps models learn the correct causal relations between
variables and focus on those causal factors only.
Although several works have focused on enhancing the
robustness of image classification models against adversar-
ial [35, 61] or natural noises [42] with causal inference, it
is nontrivial to adapt these methods to point cloud classi-
fication due to the inherent differences in human modeling
between the two tasks, which leads to completely different
solutions. For instance, previous works characterize image
style information [61] and background patterns [35] to in-
vestigate the causal relations between images and classifi-
cation decisions, which are not applicable to point cloud
data. In this work, we propose a specific causal modeling
approach based on human observations for point cloud clas-
sification for the first time.
3. The Causal Modeling
3.1. Causal Modeling of Point Cloud Classification
To quantify the underlying logic behind human decision-
making, we introduce the use of causal graph [8, 29], which
employs structured paths (i.e., causal reasoning paths ) be-
tween nodes (i.e., causal variables ). Specifically, we con-
struct a causal graph to formalize the process of point cloud
classification, as illustrated in Fig.2 (a), consisting of three
causal variables during mapping point cloud data Xto clas-
sification results Y: the physical object Ocorresponding to
X, the structural information Zinvolved in X, and external
noises U.1We now show the four causal reasoning paths
regarding the decision process for this task:
•Point cloud generation : We first consider the genera-
tion process from a real-world object to point cloud data.
From the physical world perspective, given an object O,
we can obtain point cloud data Xthrough multiple Li-
DAR scans [48] or modeling mesh data and sampling
[49]. This process can be described as O→X, where
the arrow represents a causal reasoning path.
1Throughout the paper in the following sections, we use capital letters
likeXto denote random variables, while lowercase letters like xto denote
a specific value taken for the variable.
19781
Physical ObjectPoint CloudHidden Confounder
Structure
LiDAR
Scan
Label“airplane”(a) Causal Graph (b) CausalPC
 
  
  
 
 
FPS AlgorithmStructure Extraction Module
Point Cloud Reconstruction Module
Up-sampling Network Randomized Down-samplingCausal EffectClassifierJoint Attention 
Classification Module
Point Cloud
AttentionFigure 2. The proposed point cloud classification through a causal lens: (a) the causal graph; (b) the proposed framework.
•Structural information extraction : At first glance, humans
typically recognize the structural information of an ob-
ject, i.e., the framework [13]. This process involves iden-
tifying the main parts of the object and their relative po-
sitions, as well as the symmetry and other features that
determine the overall structure. We use Zto represent
such structural information and path X→Zto describe
such a process.
•Classification : With the accurate structural information
Z, the classification of a point cloud can be correctly per-
formed. Specifically, humans recall what kinds of objects
share a similar structure, i.e., the path Z→Y.
•Hidden confounders : Various hidden variables influ-
ence the generation of point cloud X, including sam-
pling noises from different LiDAR sensors and adversar-
ial noise from potential attackers with specific strategies.
We represent these potential noises collectively with vari-
ableUand refine the generation process as (O, U)→X
in the causal graph. In real-world scenarios, where Y
may itself be subject to spurious noises like dataset an-
notation errors [43] and recognition bias introduced by
humans [27], we also introduce the variable Uto denote
such noises for convenience, resulting in the causal path
(Z, U)→Y. In this context, variable Userves as hidden
confounders in causal modeling, influencing both the in-
putXand the output Ythrough the causal reasoning path
X←U→Y.
3.2. Flaws of Existing Models and Defenses
Based on the built causal graph, we now analyze why DNN-
based point classification models are vulnerable to adversar-
ial perturbations. In related literature, DNNs tend to model
the statistical correlations between point cloud Xand label
Y, given the optimization goal of maximizing the classifi-
cation accuracy [14]. With the absence of the modeling of
hidden confounders, such a naive optimization goal would
lead DNNs to overfit the potential spurious features, e.g.,
the local pattern of normal point clouds, instead of struc-
tural information [47, 50]. Therefore, DNNs may rely ona shortcut solution where the negative impact of Uspreads
to the classification through the indirect causal reasoning
pathX←U→Y. As a result, when facing adversar-
ial point clouds, DNNs would be confused by a previously
unseen statistical pattern, which leads to a wrong classifica-
tion. In comparison, recent research has also pointed out
that humans are able to model the causal effect between
data instead of statistical ones, which therefore helps avoid
the influence of the confounding variables within the data
[37, 58]. For instance, in point cloud classification, we can
notice abnormal points in Fig.1 and still recognize the struc-
ture of the table, which helps us make the correct classifica-
tion decision.
Through the lens of causal reasoning, existing defenses
[7, 21, 63] in point cloud classification attempt to optimize
the modeling process of the classification task with only
partial observation of U. Identifying the perturbation pat-
terns of points introduced by particular types of attacks,
these methods improve the modeling between XandYby
explicitly considering certain kinds of U, e.g., specific in-
put patterns or attack techniques. However, due to the in-
complete modeling of U, these defenses can not general-
ize well to new attacks with other patterns, leading to poor
robustness. For instance, our empirical results (in Section
5) show that the adversarial training baseline trained with
IFGM [21] adversarial examples still reaches an attack suc-
cess rate of 100% when attacked by GeoA3 [46], an attack
with distinct geometry patterns from IFGM, on PointNet
and DGCNN.
4. The Proposed CausalPC
4.1. Causal Effect Identification
To avoid making the classification process overfit to specific
hidden confounders, we propose to perform robust model-
ing according to the causal graph in Fig.2 (a). To this end,
we leverage the techniques of the graphical causal model
(GCM) framework [29] to formulate the causal graph and
identify the causal effect, where conditional probabilities
are used to represent the causal effects between variables.
19782
For instance, the distribution P(Z|X)stands for the causal
effect X→Zin the graph. Based on the definition, we
formulate the classification as follows,
P(Y|do(X=x)) =Z
P(Y|Z, U)P(Z|x)P(U)dUdZ.
(2)
where the operation do-calculus is the causal intervention
in related literature [8]. In our problem, the causal inter-
vention stands for performing classification given a certain
point cloud x. As such, OandU-related terms on xare
omitted because the observed xhas deterministic OandU.
Eq.2 stands with our motivation that the causal mod-
eling of point cloud classification should take all possi-
ble values of confounding noise Uinto account. In addi-
tion, the proper structural information Zshould also be ex-
tracted to perform the classification indicated by the term
P(Z|x), where xmay contain the information of hidden
confounders. However, an obvious challenge present is that
such a requirement for integration on Uis unrealistic during
the implementation due to the unobservable Uthat cannot
be exhaustively enumerated. To tackle this challenge, we
propose the following theorem based on the front-door ad-
justment [8].
Theorem 1. Under the causal graph in Fig.2 (a), suppose
the real-world object of a point cloud data xiso. The causal
effect is transformed into the following equation:
P(Y|do(X=x)) =P(Y|do(X=x, O =o))
=Z
P(Z|x)Z
P(Y|Z, X )P(X|o)dX
dZ.
(3)
Theorem 1 states that we derive Eq.3 from Eq.2, which
excludes the explicit modeling for the unobservable U. In-
tuitively, the conditional probability P(X|o)describes the
distribution of all sampled point cloud data Xgiven phys-
ical object o, which implicitly enumerates the hidden con-
founders U. The complete proof for the theorem can be
found in the supplementary material.
4.2. Causal Inference
Based on Eq.3, we now show how we build up a practi-
cal causal inference framework to identify the causal effect.
First of all, we propose to leverage the Monte Carlo sam-
pling to approximate the integral term,
P(Y|do(X=x, O =o)) =Ez∼P(Z|x),x′∼P(X|o)
P(Y|z, x′)
≈1
Mz·MxMzX
i=1MxX
j=1P(Y|zi, x′
j),
(4)
where x′
jandziare sampled from P(X|o)andP(Z|x),
MxandMzare the sampling size of the two variables,
Physical Object
 Mesh Representation Vertices
Structural 
Information
Vertices: red points
Facets: gray areas
Polygons3D 
ModelingExtractionFigure 3. The mesh representation of physical objects and the
demonstration of framework vertices.
respectively. To implement the sampling process and the
causal inference, the practical modeling of the three distri-
butions P(Z|x),P(X|o), and P(Y|Z, X)becomes a tech-
nical challenge. To fill the gap, we develop three sub-
modules, i.e., a structure extraction module, a point cloud
reconstruction module, and a joint attention classification
module. They work together as illustrated in Fig.2 (b). We
detail their design as follows.
Structure Extraction Module. Forz∼P(Z|x), i.e.,
extracting the structural information of an observed point
cloud x, we take inspiration from the mesh representation
of real-world 3D objects. Specifically, a mesh is a set of
small polygons as an approximation of 3D objects, where
each one of the polygons is typically built by several ver-
tices and a facet, as shown in Fig.3. In related literature, the
vertices and facets describe the structural and textural infor-
mation of a 3D object [49]. Motivated by this, we propose to
use the farthest point sampling (FPS) strategy [33] to sam-
ple a subset of points from the observed point cloud xas
an approximation of vertices in mesh representation. FPS
starts from a randomly selected point and iteratively sam-
ples new points far from the set of selected points, which
shares a similar idea to the mesh construction for an object
where the vertices are expected to be scattered along the
object surface [2].
Point Cloud Reconstruction Module. Forx∼P(X|o),
the observed point clouds given a physical object o, we need
to simulate the sampling process of modern point cloud
scanners like a LiDAR sensor ideally. However, such a sim-
ulation is impractical due to the unaccessible original object
o. Therefore, we first seek for a solution to recover ofrom
x. As our causal graph shows, the point cloud generation
process (O, U)→Xinevitably leaves out some of the de-
tailed features of the physical object to represent a surface
with limited points. This motivates us to develop an up-
sampling network to recover the lost details. To this end, we
train an up-sampling model based on PU-Net [56], which
effectively transforms a point cloud into a denser one. With
the reconstructed point cloud data, we utilize random sub-
sampling to approximate the point cloud sampling process,
19783
i.e.,x∼P(X|o). Moreover, to simulate the random noises
introduced during point cloud sampling, we add additional
noises of uniform distribution to the sampled point clouds.
Joint Attention Classification Module. The estimation
ofP(Y|Z, X)denotes the overall classification distribu-
tion given a resampled point cloud xand the structural
information z. Different from existing works that lever-
age a similar front-door adjustment technique in other tasks
[38, 54], where typically an extra network is dedicated for
modeling P(Y|Z, X), we propose to directly adopt existing
point cloud classifiers, e.g., PointNet [32], DGCNN [45]
and PointCNN [19]. We show that one advantage of the
mainstream models is that they can take an arbitrary num-
ber of points for a point cloud as input, making inference
valid with the union of xandz. Particularly, we leverage
the feature extractor fof existing models to extract feature
hzxfor the concatenated zandx. In addition to hzx, we
also introduce hz=f(z),hx=f(x)for joint classifi-
cation. Now that hzxencodes the global feature of both
structural and reconstructed object information, we design
extra cross-attentions to better extract the structural feature
inzand object feature in x, where hzxacts as the query for
point-wise features in hzandhx. The attention features hatt
z
andhatt
xare then fused with hzxas the overall point cloud
feature h, which is later classified by the classification heads
of existing models. In practice, we reuse pre-trained mod-
els and fine-tune the cross-attention and classification heads
for only a few epochs. The design of the joint module is
described in Fig.4. More design details can be found in the
supplementary material.
4.3. Summary
As a recap, to develop a defense framework for various ad-
versarial attacks, our work first models point cloud classifi-
cation from humans’ perspective and constructs the causal
graph accordingly. To estimate the unobservable confound-
ing variable Uduring causal effect identification, we pro-
pose Theorem 1 to find a solution. For the implementation
of Eq.4, we propose three sub-modules to realize the causal
inference with only slight modifications to existing point
cloud classifiers.
5. Experiments
5.1. Experimental Settings
Models and datasets. To validate the effectiveness of our
proposed method, we conduct experiments on three repre-
sentative point cloud classification models: PointNet [32],
DGCNN [45] and PointCNN [19] with two commonly used
benchmark datasets: ShapeNet [4] and ModelNet40 [49],
each consisting of CAD models belonging to 55and40
human-labeled object classes, respectively. The ShapeNet
...
Feature Extraction
max
pooling
Cross Attention Feature FusionPoint-wise Global
... ...
FC
Figure 4. The attention module for modeling P(Y|Z, X ).
dataset has 35,708training samples and 15,429test sam-
ples, while the ModelNet40 dataset official split has 9,843
training samples and 2,468test samples initially. For both
datasets, we uniformly sample 2,048points from each ob-
ject and normalize them into a unit sphere. All baselines
are evaluated on the test set of each dataset. To improve ef-
ficiency, we follow the approach of previous work [46] and
perform sub-sampling on the dataset. Specifically, we ran-
domly select a subset of 2,732samples from the test set of
ShapeNet, with at most 60 samples from each class.
Baseline attacks. We consider ten representative adver-
sarial attack methods in this paper, ranging from adding,
shifting, deleting, and shape-invariant attacks, including
Minimal [15], Smooth [25], IFGM [21], Gen3D-Add [51],
Gen3D-Pert [51], AdvPC [11], Drop [62], KNN [40],
GeoA3 [46], and ShapeInvariant [12]. Among these attacks,
Gen3D-Add adds additional adversarial points to perform
attacks, Drop removes existing points, AdvPC is based on
autoencoders, and the others shift existing points in a be-
nign point cloud. Various regulations are leveraged by these
methods to perform stealthy attacks, e.g., KNN and GeoA3
usek-NN distance loss and local curvature loss respectively
to perform shape-invariant attacks. Specifically, as GeoA3
requires normal vectors of a point cloud to perform, it is
only evaluated on the ModelNet40 dataset. For a complete
comparison, we consider both targeted and untargeted at-
tack settings, i.e., an attacker either promotes the prediction
of a specifically designated label or suppresses the predic-
tion of the ground truth label. Note that most of the existing
adversarial attacks are targeted ones. Therefore, we take
IFGM, Minimal, Gen3D-Pert, and Drop as the untargeted
attack baselines, where we modify the objective function
accordingly to perform the specific type of attack.
Baseline defenses. As for defense baselines, we choose
three effective input-oriented defenses: SOR [63], DUP-Net
[63] and GvG [7], and two adversarial training (AT)-based
defenses: AT [21] and PAGN [20]. SOR and DUP-Net pre-
process the adversarial point cloud by filtering outliers to
recover the benign one. GvG leverages the predicted gather
19784
Table 1. Classification accuracy ( %) of untargeted attack strategies against different defense methods on ModelNet40 dataset. The best
among all defenses is in bold.
PointNet DGCNN PointCNN
Vanilla SOR DUP-Net GvG AT PAGN Ours Vanilla SOR DUP-Net AT PAGN Ours Vanilla SOR DUP-Net AT PAGN Ours
IFGM 1.6 23.6 24.8 1.6 15.1 24.1 49.0 0.0 11.9 32.1 22.7 10.5 75.9 40.8 59.9 54.2 47.2 63.2 68.9
Minimal 32.5 63.0 61.4 32.1 59.6 61.8 77.5 12.6 37.9 35.9 59.0 41.0 80.7 66.6 67.8 40.3 57.7 68.8 70.0
Gen3D-Pert 64.4 63.4 63.0 64.4 48.1 63.5 64.4 34.6 35.2 37.1 28.6 34.9 48.4 48.9 51.2 37.1 42.3 45.4 56.0
Drop 65.0 69.0 67.8 60.5 36.3 69.5 78.6 69.6 71.6 49.2 59.1 71.2 83.1 82.1 77.6 42.7 72.2 73.7 71.7
Avg. 40.9 54.8 54.3 39.7 39.8 54.7 67.4 29.2 39.2 38.6 42.4 39.4 72.0 59.6 64.1 43.6 54.9 62.8 66.6
Table 2. Attack success rates ( %) of targeted attack strategies against different defense methods on ModelNet40 dataset. The best among
all defenses is in bold.
PointNet DGCNN PointCNN
Vanilla SOR DUP-Net GvG AT PAGN Ours Vanilla SOR DUP-Net AT PAGN Ours Vanilla SOR DUP-Net AT PAGN Ours
Minimal 26.2 7.4 6.8 12.8 7.6 5.7 1.5 7.5 2.7 1.9 3.3 4.6 0.6 1.3 1.2 1.5 1.3 1.2 0.8
Smooth 48.7 4.7 3.8 42.5 29.6 7.1 1.2 81.7 23.4 2.8 75.0 23.4 1.0 3.3 2.2 2.1 2.8 1.5 1.1
IFGM 67.3 3.8 2.8 61.1 61.1 5.3 0.8 97.7 1.4 1.1 85.2 1.3 0.5 6.3 2.5 1.5 6.4 1.5 1.1
Gen3D-Add 60.4 5.7 4.9 49.1 56.4 5.9 2.2 38.9 3.0 2.1 33.3 4.2 0.5 0.9 0.9 1.8 0.8 0.9 0.6
Gen3D-Pert 98.4 7.1 5.1 77.8 0.6 3.8 1.1 96.8 4.9 1.7 89.1 5.0 0.4 57.4 23.1 4.6 5.6 3.1 1.3
AdvPC 99.0 5.2 4.3 99.7 100.0 6.4 1.9 84.2 3.3 1.7 82.5 4.9 0.7 5.2 2.6 2.4 2.2 2.8 2.2
KNN 90.6 23.1 15.8 97.1 76.3 31.6 4.7 98.4 12.9 2.5 98.7 19.1 0.4 55.1 27.4 5.5 12.1 10.0 4.1
GeoA3 100.0 19.1 15.8 100.0 100.0 30.7 3.2 97.1 7.6 2.2 100.0 14.1 1.1 16.8 11.5 4.7 6.2 11.1 3.9
ShapeInvariant 67.2 7.3 6.8 60.0 64.0 7.6 3.6 8.2 2.4 2.3 9.4 2.2 1.5 4.1 3.7 2.2 3.0 3.5 2.7
Avg. 73.1 9.3 7.3 66.7 55.1 11.6 2.2 67.8 6.8 2.0 64.1 8.8 0.7 16.7 8.3 2.9 4.5 4.0 2.0
vector for each point to recover the perturbed prediction.
We apply GvG to PointNet only due to its model-specific
design. The AT-based methods generate adversarial point
clouds for model training. Specifically, we take IFGM ad-
versarial examples for AT, and PAGN generates perturba-
tions in the feature space.
Evaluation metrics. To evaluate the performance, we
take classification accuracy (ACC) and attack success rate
(ASR) as metrics for untargeted and targeted attacks. The
ACC is the rate of examples that remain correctly classified,
while the ASR stands for the rate of adversarial examples
that are classified as the designated target labels. Therefore,
a higher ACC or a lower ASR indicates a more robust clas-
sifier under specific attacks. For more details including the
model training settings, hyper-parameter settings of base-
line methods, the design of the attacks and more results,
please refer to the supplementary material.
5.2. The Robustness of the Proposed Framework
We first show the effectiveness of CausalPC under both un-
targeted and targeted attack settings. The performance of
our method and all baselines on ModelNet40 is shown in
Table 1 and 2. The results of ShapeNet are presented in
the supplementary material. We report the performance of
the classifiers with no defense as the Vanilla columns. Ours
columns stand for the classifiers with CausalPC. The Avg.
row describes the averaged results of each column.
From the results, we observe that our CausalPC can
substantially improve the adversarial robustness of current
point cloud classifiers against various attacks. For ex-
ample, we observe a remarkable increase in the average
ACC of DGCNN from 29.2%to72.0%for untargeted at-tacks, which greatly outperforms the current best baseline
of42.4%. Similarly, for targeted attacks, the average ASR
of PointNet reduces drastically from 73.1%to2.2%.
Current defense mechanisms often overfit to specific
types of attacks. In the case of AT-based defenses , as re-
ported in Table 2, it is observed that while AT achieves an
ASR of 3.3%against the Minimal attack for DGCNN, due
to the training regimen involving similar IFGM adversarial
examples, it proves ineffective against novel unseen attacks
such as KNN and GeoA3, exhibiting an ASR approach-
ing100% . Although PAGN demonstrates slightly improved
performance owing to its adversarial training in the fea-
ture space, its robustness against shape-invariant attacks is
still unsatisfying. Input-oriented defenses such as SOR and
DUP-Net exhibit comparatively superior performance com-
pared to AT-based ones. This is attributed to their consider-
ation of a broader range of attack patterns, typically involv-
ing the removal of outlier points and the restoration of ob-
jects. The average ASR of both methods can be reduced to
below 10%. However, DUP-Net performs poorly when fac-
ing the Drop attack which doesn’t produce outliers, where
the ACC is even lower than Vanilla for PointCNN against
untargeted attacks. For shape-invariant attacks, whose at-
tack goals are carefully designed to generate imperceptible
adversarial examples, all input-oriented defenses tend to be
breached. The ASR against GvG even reaches near 100%
for KNN and GeoA3 attacks.
CausalPC outperforms these baselines by employing
causal modeling in the context of point cloud classifica-
tion tasks. When utilized for inference, CausalPC enables
existing classifiers to accurately identify causal effects in
classification, leading to enhanced adversarial robustness.
19785
Table 3. Classification accuracy ( %) of untargeted attacks
against CausalPC with different modules on ModelNet40 dataset,
DGCNN. The best among all baselines is in bold.
Method P(Z|x)P(X|o)Attention IFGM Minimal Gen3D-Pert Drop Avg.
Vanilla 0.0 12.6 34.6 69.6 29.2
no Att, x✓ 30.9 33.1 27.8 33.8 31.4
no Att, z ✓ 37.9 45.8 38.1 51.1 43.2
no Att ✓ ✓ 72.9 78.6 43.0 85.7 70.1
Ours ✓ ✓ ✓ 75.9 80.7 48.4 83.1 72.0
For instance, for Drop attack, the ACC exceeds 70%, and
for shape-invariant attacks, the ASR consistently remains
below 5%. In terms of overall performance, the average
ASR for PointNet on targeted attacks is only 2.2%, com-
pared to 7.3%for the best-performing baseline, DUP-Net.
5.3. Ablation Study
Subsequently, we investigate the relative impacts of the
three modules within CausalPC. An ablation study is con-
ducted on ModelNet40 using DGCNN, as presented in Ta-
ble 3. This study assesses the robustness of CausalPC with
the sub-modules analyzed individually.
The results indicate that different modules contribute di-
versely to robustness. For instance, when utilizing only
structural information z(theno Att, xrow), CausalPC ex-
hibits only a marginal improvement over Vanilla. This is
because zalone lacks detailed information essential for ef-
fective classification, albeit reducing susceptibility to ad-
versarial perturbations. Similarly, employing only the re-
constructed point cloud x(the no Att, zrow) results in a
modest enhancement of robustness. In the no Att row, it
is demonstrated that through the causal modeling of both z
andx, CausalPC achieves exceptional robustness, reflected
in an ACC of 70.1%. Finally, the incorporation of the joint
attention module in modeling P(Y|Z, X)further elevates
the robustness of our framework to an ACC of 72.0%.
5.4. Visualization
To further illustrate the difference between the extracted
structure information zand the reconstructed point cloud
x, we randomly pick an adversarial example generated by
GeoA3 on PointNet in ModelNet40, whose ground truth la-
bel is airplane . We visualize an extracted zand a recon-
structed xfrom the sample in Fig.5.
As shown in the figure, the contour of an airplane can be
recognized from zat first glance, which demonstrates that
the FPS algorithm is effective in extracting the structural in-
formation of a point cloud. However, upon closer inspection
of details such as the zoomed-in wing part, we observe that
zpreserves only the framework of the original object and
has lost the details. In contrast, the reconstructed xprovides
a denser point cloud with recovered details. By combining
zandxas input, the joint classification module is able to
leverage both the structural information and surface details
Figure 5. Visualization of zandx.
to achieve a more robust classification. For a more intuitive
visualization of the adversarial robustness gained from joint
classification, please refer to the supplementary material.
6. Conclusion & Limitations
In this study, driven by the pivotal observation that adversar-
ial point clouds closely resemble benign ones to the human
eye, we introduce a causal framework to enhance the robust-
ness of point cloud classification. Specifically, we formulate
the modeling of two crucial causal variables, the structural
information Zand the hidden confounders U. This anal-
ysis reveals that the incompletely modeled Uconstitutes
a limitation in existing defense strategies. Guided by the
proposed causal modeling, we devise three effective sub-
modules to identify the causal effect for robust classifica-
tion, yielding significant performance improvements over
existing baselines.
However, despite the guidance of the causal analysis,
the sub-modules in actual implementation may induce in-
accuracy inevitably. Such a flaw introduces a gap between
the causal framework and the algorithm design. In our
work, we have tried our best to utilize suitable modules
for point cloud data and achieved a balance between effec-
tiveness and efficiency. Future works should consider more
advanced implementations and provide an analytical lower
bound for the robustness.
For other future investigations, we aim to: (1) deepen our
insights into causal relations by focusing on real-world ob-
jects; (2) extend the application of causal inference to other
point cloud-related tasks, such as 3D object detection.
Acknowledgements
We would like to thank the anonymous reviewers for their
insightful comments that helped improve the quality of the
paper. This work was supported in part by the National Key
Research and Development Program (2021YFB3101200),
National Natural Science Foundation of China (U1736208,
U1836210, U1836213, 62172104,62172105, 61902374,
62102093, 62102091). Min Yang is a faculty of Shanghai
Institute of Intelligent Electronics & Systems, Shanghai In-
situte for Advanced Communication and Data Science, and
Engineering Research Center of Cyber Security Auditing
and Monitoring, Ministry of Education, China. Mi Zhang is
the corresponding author.
19786
References
[1] Joshua D Angrist, Guido W Imbens, and Donald B Ru-
bin. Identification of causal effects using instrumental vari-
ables. Journal of the American statistical Association , 91
(434):444–455, 1996. 3
[2] Marshall W Bern and Paul E Plassmann. Mesh generation.
Handbook of computational geometry , 38, 2000. 5
[3] Nicholas Carlini and David Wagner. Towards evaluating the
robustness of neural networks. In 2017 ieee symposium on
security and privacy (sp) , pages 39–57. Ieee, 2017. 2, 3
[4] Angel X Chang, Thomas Funkhouser, Leonidas Guibas,
Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese,
Manolis Savva, Shuran Song, Hao Su, et al. Shapenet:
An information-rich 3d model repository. arXiv preprint
arXiv:1512.03012 , 2015. 6
[5] Wenda Chu, Linyi Li, and Bo Li. Tpc: Transformation-
specific smoothing for point cloud models. In International
Conference on Machine Learning , pages 4035–4056. PMLR,
2022. 4
[6] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified
adversarial robustness via randomized smoothing. In In-
ternational Conference on Machine Learning , pages 1310–
1320. PMLR, 2019. 4
[7] Xiaoyi Dong, Dongdong Chen, Hang Zhou, Gang Hua,
Weiming Zhang, and Nenghai Yu. Self-robust 3d point
recognition via gather-vector guidance. In 2020 IEEE/CVF
Conference on Computer Vision and Pattern Recognition
(CVPR) , pages 11513–11521. IEEE, 2020. 1, 3, 4, 6, 2
[8] Madelyn Glymour, Judea Pearl, and Nicholas P Jewell.
Causal inference in statistics: A primer . John Wiley & Sons,
2016. 2, 3, 5
[9] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy.
Explaining and harnessing adversarial examples. arXiv
preprint arXiv:1412.6572 , 2014. 3, 2
[10] Vincent Grari, Sylvain Lamprier, and Marcin Detyniecki.
Fairness without the sensitive attribute via causal variational
autoencoder. arXiv preprint arXiv:2109.04999 , 2021. 3
[11] Abdullah Hamdi, Sara Rojas, Ali Thabet, and Bernard
Ghanem. Advpc: Transferable adversarial perturbations on
3d point clouds. In European Conference on Computer Vi-
sion, pages 241–257. Springer, 2020. 1, 3, 6, 2
[12] Qidong Huang, Xiaoyi Dong, Dongdong Chen, Hang Zhou,
Weiming Zhang, and Nenghai Yu. Shape-invariant 3d adver-
sarial point clouds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
15335–15344, 2022. 2, 6
[13] John E Hummel. Object recognition. Oxford handbook of
cognitive psychology , 810:32–46, 2013. 4
[14] Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan
Engstrom, Brandon Tran, and Aleksander Madry. Adversar-
ial examples are not bugs, they are features. Advances in
neural information processing systems , 32, 2019. 3, 4
[15] Jaeyeon Kim, Binh-Son Hua, Thanh Nguyen, and Sai-Kit
Yeung. Minimal adversarial examples for deep learning on
3d point clouds. In Proceedings of the IEEE/CVF Interna-
tional Conference on Computer Vision , pages 7797–7806,
2021. 1, 6, 2[16] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo
Silva. Counterfactual fairness. Advances in neural informa-
tion processing systems , 30, 2017. 3
[17] Alex H Lang, Sourabh V ora, Holger Caesar, Lubing Zhou,
Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders
for object detection from point clouds. In Proceedings of
the IEEE/CVF conference on computer vision and pattern
recognition , pages 12697–12705, 2019. 2
[18] Linyi Li, Tao Xie, and Bo Li. Sok: Certified robustness
for deep neural networks. arXiv preprint arXiv:2009.04131 ,
2020. 4
[19] Yangyan Li, Rui Bu, Mingchao Sun, Wei Wu, Xinhan Di,
and Baoquan Chen. Pointcnn: Convolution on x-transformed
points. Advances in neural information processing systems ,
31, 2018. 2, 6
[20] Qi Liang, Qiang Li, Weizhi Nie, and An-An Liu. Pagn: per-
turbation adaption generation network for point cloud adver-
sarial defense. Multimedia Systems , pages 1–9, 2022. 1, 6,
2
[21] Daniel Liu, Ronald Yu, and Hao Su. Extending adversarial
attacks and defenses to deep 3d point cloud classifiers. In
2019 IEEE International Conference on Image Processing
(ICIP) , pages 2279–2283. IEEE, 2019. 1, 3, 4, 6, 2
[22] Daniel Liu, Ronald Yu, and Hao Su. Adversarial shape per-
turbations on 3d point clouds. In European Conference on
Computer Vision , pages 88–104. Springer, 2020. 2, 3
[23] Hongbin Liu, Jinyuan Jia, and Neil Zhenqiang Gong. Point-
guard: Provably robust 3d point cloud classification. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 6186–6195, 2021. 3, 4, 5
[24] Haoming Lu and Humphrey Shi. Deep learning for 3d
point cloud understanding: a survey. arXiv preprint
arXiv:2009.08920 , 2020. 2
[25] Chengcheng Ma, Weiliang Meng, Baoyuan Wu, Shibiao Xu,
and Xiaopeng Zhang. Towards effective adversarial attack
against 3d point cloud classification. In 2021 IEEE Interna-
tional Conference on Multimedia and Expo (ICME) , pages
1–6. IEEE, 2021. 6, 2
[26] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt,
Dimitris Tsipras, and Adrian Vladu. Towards deep learn-
ing models resistant to adversarial attacks. arXiv preprint
arXiv:1706.06083 , 2017. 3
[27] Slava Mikhaylov, Michael Laver, and Kenneth R Benoit.
Coder reliability and misclassification in the human coding
of party manifestos. Political Analysis , 20(1):78–91, 2012. 4
[28] Ronghui Mu, Wenjie Ruan, Leandro S. Marcolino, and
Qiang Ni. 3DVerifier: Efficient robustness verification for
3D point cloud models. Machine Learning , pages 1–28,
2022. 4
[29] Judea Pearl. Causality . Cambridge university press, 2009.
2, 3, 4, 1
[30] Juan C. P ´erez, Motasem Alfarra, Silvio Giancola, and
Bernard Ghanem. 3deformrs: Certifying spatial deforma-
tions on point clouds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
15169–15179, 2022. 4
19787
[31] Jonas Peters, Dominik Janzing, and Bernhard Sch ¨olkopf. El-
ements of causal inference: foundations and learning algo-
rithms . The MIT Press, 2017. 3
[32] Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas.
Pointnet: Deep learning on point sets for 3d classification
and segmentation. In Proceedings of the IEEE conference
on computer vision and pattern recognition , pages 652–660,
2017. 1, 2, 6
[33] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J
Guibas. Pointnet++: Deep hierarchical feature learning on
point sets in a metric space. Advances in neural information
processing systems , 30, 2017. 1, 2, 5
[34] Yongming Rao, Guangyi Chen, Jiwen Lu, and Jie Zhou.
Counterfactual attention learning for fine-grained visual cat-
egorization and re-identification. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 1025–1034, 2021. 3
[35] Qibing Ren, Yiting Chen, Yichuan Mo, Qitian Wu, and
Junchi Yan. DICE: Domain-attack Invariant Causal Learn-
ing for Improved Data Privacy Protection and Adversarial
Robustness. In Proceedings of the 28th ACM SIGKDD Con-
ference on Knowledge Discovery and Data Mining , pages
1483–1492, 2022. 3
[36] Radu Bogdan Rusu, Zoltan Csaba Marton, Nico Blodow, Mi-
hai Dolha, and Michael Beetz. Towards 3d point cloud based
object maps for household environments. Robotics and Au-
tonomous Systems , 56(11):927–941, 2008. 2
[37] Bernhard Sch ¨olkopf, Francesco Locatello, Stefan Bauer,
Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and
Yoshua Bengio. Toward causal representation learning. Pro-
ceedings of the IEEE , 109(5):612–634, 2021. 4
[38] Hongda Sun, Shufang Xie, Shuqi Li, Yuhan Chen, Ji-Rong
Wen, and Rui Yan. Debiased, Longitudinal and Coordinated
Drug Recommendation through Multi-Visit Clinic Records.
Advances in Neural Information Processing Systems , 35:
27837–27849, 2022. 6, 1
[39] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan
Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. In-
triguing properties of neural networks. In 2nd International
Conference on Learning Representations, ICLR 2014 , 2014.
3
[40] Tzungyu Tsai, Kaichen Yang, Tsung-Yi Ho, and Yier Jin.
Robust adversarial objects against deep learning models. In
Proceedings of the AAAI Conference on Artificial Intelli-
gence , pages 954–962, 2020. 6, 2
[41] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-
reit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia
Polosukhin. Attention is all you need. Advances in neural
information processing systems , 30, 2017. 1
[42] Julius V on K ¨ugelgen, Yash Sharma, Luigi Gresele, Wieland
Brendel, Bernhard Sch ¨olkopf, Michel Besserve, and
Francesco Locatello. Self-supervised learning with data aug-
mentations provably isolates content from style. Advances
in neural information processing systems , 34:16451–16467,
2021. 3
[43] Fei Wang, Liren Chen, Cheng Li, Shiyao Huang, Yanjie
Chen, Chen Qian, and Chen Change Loy. The devil of facerecognition is in the noise. In Proceedings of the European
Conference on Computer Vision (ECCV) , pages 765–780,
2018. 4
[44] Tan Wang, Chang Zhou, Qianru Sun, and Hanwang Zhang.
Causal attention for unbiased visual recognition. In Proceed-
ings of the IEEE/CVF International Conference on Com-
puter Vision , pages 3091–3100, 2021. 3
[45] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma,
Michael M Bronstein, and Justin M Solomon. Dynamic
graph cnn for learning on point clouds. Acm Transactions
On Graphics (tog) , 38(5):1–12, 2019. 1, 2, 6
[46] Yuxin Wen, Jiehong Lin, Ke Chen, CL Philip Chen, and Kui
Jia. Geometry-aware generation of adversarial point clouds.
IEEE Transactions on Pattern Analysis and Machine Intelli-
gence , 2020. 2, 3, 4, 6
[47] Matthew Wicker and Marta Kwiatkowska. Robustness of 3d
deep learning in an adversarial setting. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 11767–11775, 2019. 3, 4
[48] Yutian Wu, Yueyu Wang, Shuwei Zhang, and Harutoshi
Ogai. Deep 3d object detection networks using lidar data:
A review. IEEE Sensors Journal , 21(2):1152–1171, 2020. 3
[49] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Lin-
guang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3d
shapenets: A deep representation for volumetric shapes. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 1912–1920, 2015. 3, 5, 6
[50] Ziyi Wu, Yueqi Duan, He Wang, Qingnan Fan, and
Leonidas J. Guibas. If-defense: 3d adversarial point cloud
defense via implicit function based restoration. arXiv
preprint arXiv:2010.05272 , 2020. 4
[51] Chong Xiang, Charles R Qi, and Bo Li. Generating 3d ad-
versarial point clouds. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
9136–9144, 2019. 1, 2, 3, 6
[52] Jianwen Xie, Zilong Zheng, Ruiqi Gao, Wenguan Wang,
Song-Chun Zhu, and Ying Nian Wu. Generative voxelnet:
learning energy-based models for 3d shape synthesis and
analysis. IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence , 2020. 2
[53] Ziqi Xu, Debo Cheng, Jiuyong Li, Jixue Liu, Lin Liu, and
Kui Yu. Causal Effect Estimation with Variational Au-
toEncoder and the Front Door Criterion. arXiv preprint
arXiv:2304.11969 , 2023. 1
[54] Xu Yang, Hanwang Zhang, Guojun Qi, and Jianfei Cai.
Causal attention for vision-language tasks. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition , pages 9847–9857, 2021. 6, 1
[55] Lequan Yu, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and
Pheng-Ann Heng. Pu-net: Point cloud upsampling network.
InProceedings of the IEEE conference on computer vision
and pattern recognition , pages 2790–2799, 2018. 2
[56] Lequan Yu, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, and
Pheng-Ann Heng. Pu-net: Point cloud upsampling network.
InProceedings of the IEEE conference on computer vision
and pattern recognition , pages 2790–2799, 2018. 5, 1
[57] Zhongqi Yue, Qianru Sun, Xian-Sheng Hua, and Hanwang
Zhang. Transporting causal mechanisms for unsupervised
19788
domain adaptation. In Proceedings of the IEEE/CVF Inter-
national Conference on Computer Vision , pages 8599–8608,
2021. 3
[58] Cheng Zhang, Kun Zhang, and Yingzhen Li. A causal view
on robustness of neural networks. Advances in Neural Infor-
mation Processing Systems , 33:289–301, 2020. 4
[59] Haichao Zhang and Jianyu Wang. Defense against adversar-
ial attacks using feature scattering-based adversarial training.
InNeurIPS , 2019. 3
[60] Jinghuai Zhang, Jinyuan Jia, Hongbin Liu, and Neil Zhen-
qiang Gong. PointCert: Point Cloud Classification with De-
terministic Certified Robustness Guarantees. arXiv preprint
arXiv:2303.01959 , 2023. 4
[61] Yonggang Zhang, Mingming Gong, Tongliang Liu, Gang
Niu, Xinmei Tian, Bo Han, Bernhard Sch ¨olkopf, and Kun
Zhang. Adversarial robustness through the lens of causality.
arXiv preprint arXiv:2106.06196 , 2021. 3
[62] Tianhang Zheng, Changyou Chen, Junsong Yuan, Bo Li, and
Kui Ren. Pointcloud saliency maps. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 1598–1606, 2019. 1, 3, 6, 2
[63] Hang Zhou, Kejiang Chen, Weiming Zhang, Han Fang,
Wenbo Zhou, and Nenghai Yu. Dup-net: Denoiser and up-
sampler network for 3d adversarial point clouds defense. In
Proceedings of the IEEE/CVF International Conference on
Computer Vision , pages 1961–1970, 2019. 1, 3, 4, 6, 2
[64] Hang Zhou, Dongdong Chen, Jing Liao, Kejiang Chen, Xi-
aoyi Dong, Kunlin Liu, Weiming Zhang, Gang Hua, and
Nenghai Yu. Lg-gan: Label guided adversarial network for
flexible targeted attack of point cloud based deep networks.
InProceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 10356–10365, 2020.
1, 3
[65] Xinyuan Zhu, Yang Zhang, Fuli Feng, Xun Yang, Dingx-
ian Wang, and Xiangnan He. Mitigating hidden confound-
ing effects for causal recommendation. arXiv preprint
arXiv:2205.07499 , 2022. 1
19789
