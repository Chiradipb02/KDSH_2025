Unmixing Diffusion for Self-Supervised Hyperspectral Image Denoising
Haijin Zeng1Jiezhang Cao2*Kai Zhang3Yongyong Chen4Hiep Luong1Wilfried Philips1
1IMEC-UGent2ETH Zurich3Nanjing University4Harbin Institute of Technology, Shenzhen
{Haijin.Zeng, Hiep.Luong, Wilfried.Philips }@UGent.be, jiezhang.cao@vision.ee.ethz.ch
Abstract
Hyperspectral images (HSIs) have extensive applica-
tions in various fields such as medicine, agriculture, and
industry. Nevertheless, acquiring high signal-to-noise ra-
tio HSI poses a challenge due to narrow-band spectral fil-
tering. Consequently, the importance of HSI denoising is
substantial, especially for snapshot hyperspectral imaging
technology. While most previous HSI denoising methods
are supervised, creating supervised training datasets for
the diverse scenes, hyperspectral cameras, and scan pa-
rameters is impractical. In this work, we present Diff-
Unmix, a self-supervised denoising method for HSI us-
ing diffusion denoising generative models. Specifically,
Diff-Unmix addresses the challenge of recovering noise-
degraded HSI through a fusion of Spectral Unmixing and
conditional abundance generation. Firstly, it employs a
learnable block-based spectral unmixing strategy, comple-
mented by a pure transformer-based backbone. Then, we
introduce a self-supervised generative diffusion network to
enhance abundance maps from the spectral unmixing block.
This network reconstructs noise-free Unmixing probability
distributions, effectively mitigating noise-induced degrada-
tions within these components. Finally, the reconstructed
HSI is reconstructed through unmixing reconstruction by
blending the diffusion-adjusted abundance map with the
spectral endmembers. Experimental results on both simu-
lated and real-world noisy datasets show that Diff-Unmix
achieves state-of-the-art performance.
1. Introduction
Hyperspectral images (HSIs) offer richer spectral informa-
tion compared to RGB images, making them valuable for
various applications such as face recognition [48, 49], veg-
etation detection [6], and medical diagnosis [54]. However,
the substantial number of spectral bands in HSIs, combined
with scanning designs [3] and narrow band spectral filter-
ing, results in limited photon counts per band, making HSIs
susceptible to noise [62]. This noise not only degrades
*Corresponding Author
Hyperspectral Image Toy
GT Patch Noisy Patch
DDS2M Diff-Unmix
Figure 1. Comparison (wavelength 600nm) between diffusion
based DDS2M [36] and the proposed Diff-Unmix on a hyperspec-
tral image Toycorrupted with Gaussian noise N(0,0.3). Diff-
Unmix shows the ability to restore fine details by leveraging a pre-
trained diffusion model on RGB images.
visual quality but also hinders downstream tasks, which
makes denoising a crucial pre-processing step.
Similar to RGB images, HSIs exhibit spatial self-
similarity, implying that similar pixels can be jointly de-
noised. Furthermore, HSIs possess inherent spectral cor-
relations due to their nominal spectral resolution. Conse-
quently, effective denoising methods for HSIs must con-
sider the prior within both spatial and spectral domains.
Traditional model-based HSI denoising approaches [11, 17,
22] rely on handcrafted priors to capture spatial and spec-
tral correlations through iterative optimization. These meth-
ods often employ priors like total variation [20, 22, 68],
non-local similarity [18], low-rank [9, 10] properties, and
sparsity [53]. Nonetheless, the effectiveness of these meth-
ods relies heavily on the precision of manually crafted pri-
ors. Furthermore, model-based denoising entails significant
computational demands due to iterative processes and may
struggle to generalize across a wide range of scenarios.
To achieve robust noise removal, deep learning ap-
proaches [7, 44, 52, 60] have been applied to HSI denois-
ing, achieving impressive results. However, many of these
methods employ convolutional neural networks (CNNs) for
feature extraction, relying on local filter responses within
a limited receptive field to distinguish noise from signal.
Recently, vision Transformers have shown promise in var-
ious tasks, including both high-level [16, 50] and low-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
27820
level [2, 15, 61] tasks. They excel at modeling long-range
dependencies in image regions. However, efficiently bal-
ancing the strength of noise reduction and details keeping
remains a challenge for HSI denoising Transformers.
The spectral correlation also indicates that HSIs exhibit
spectral low-rank sub-spaces [8, 10, 19, 31, 72], enabling
them to retain valuable prior while suppressing noise. Thus,
exploiting low-rank spectral statistics is essential for HSI
denoising. However, existing methods [26, 57] mainly
leverage low-rank characteristics through matrix factoriza-
tion, relying on a single HSI and requiring substantial com-
putation. Moreover, these methods are sensitive to noise
reduction and high-frequency detail recovery due to hyper-
parameter tuning, e.g., rank and trade-off coefficients.
Based on the theory of spectral low-rank subspaces, it
is natural to represent HSIs by decomposing mixed pixel
spectra into their constituent endmembers and correspond-
ing abundances, resulting in the product of two tensors [42].
One of these tensors possesses the same spatial dimensions
as the HSI but significantly reduced spectral dimensions, re-
ferred to as abundance map. The other tensor represents the
spectral endmembers, describing how the HSI is spanned
by the abundance map. However, it is evident that this de-
composition factorization is not unique [42], and the fea-
tures of the base tensor generated by common decompo-
sition strategies like Principal Component Analysis (PCA)
and sparse representation do not resemble those of real im-
ages. Consequently, it becomes inconvenient to explicitly
leverage well-established knowledge of image distribution.
To reconstruct details with high-quality while reduce
noise effectively, we introduce a physically explainable dif-
fusion model for HSI restoration, known as Diff-Unmix .
Our approach aims to integrate the advantages of physical
spectral unmixing models and generative networks. Diff-
Unmix formulates HSI restoration as a spectral unmixing
problem and conditional image generation task. In the spec-
tral unmixing, we incorporate Transformer-based character-
istics [33, 61] and meticulously design a Spectral Unmixing
Transformer network (STU) to enhance the decomposition
applicability. STU decomposes the HSI into endmembers
and corresponding abundances. Subsequently, we employ a
self-supervised conditioning function guided generative dif-
fusion network to denoise the abundance while preserving
high-frequency details and achieving improved restoration
results. The main contributions are three folds:
- We rethink HSI restoration from the perspective of condi-
tional abundance generation. Rather than being limited
to enhancing the original low-quality HSI, we propose
a generative Unmixing framework to further compensate
for content loss and spectral deviation caused by noise.
- Considering the issues of decomposition in spectral un-
mixing models, we propose a novel Transformer decom-
position network. It can take full advantage of multi-scaleattention to efficiently unmix HSI.
- We proposed a state matching and conditioning strategy,
which enables the representation of noisy abundances
as samples from an intermediate state in the diffusion
Markov chain. This facilitates the generation of detailed,
clean abundance maps without the need for ground truth.
2. Related Work
HSI denoising is an essential pre-processing step with ap-
plications in computer vision [10, 18, 56] and remote sens-
ing [43, 60]. The field has seen the development of two
main categories of denoising methods: model-based and
deep learning-based approaches. Traditional model-based
methods [11, 34, 34, 59, 69] typically approach noise re-
moval through iterative optimization, guided by handcrafted
priors. These methods include adaptive spatial-spectral dic-
tionary methods [17] and the hyper-Laplacian regularized
unidirectional low-rank tensor recovery method introduced
by Chang et al. [10]. Additionally, some approaches in-
tegrate spatial non-local similarity and global spectral low-
rank properties [18] for denoising, while others use spatial
regularizers [34, 68] and low-rank regularization techniques
[9] to model the spatial and spectral prior.
Deep learning methods [7, 37, 52, 57] have demonstrated
great potential for automatically learning and representing
features for HSI denoising. These approaches have ex-
plored spectral-spatial features using residual convolutional
networks [60], spatial-spectral global reasoning networks
[7], and hybrid convolutional and recurrent neural networks
[37, 52]. Model-guided interpretable networks have also
been actively investigated [5, 56]. Our proposed method
stands out by exploring spectral unmixing transformer and
multi-path generative diffusion networks to effectively re-
cover high-quality spatial and spectral information.
Recently, there has been a growing trend in applying
Transformers to HSI restoration [2, 47, 67] and HSI classi-
fication [25, 32]. While these techniques exhibit robust fit-
ting capabilities for underlying data, the inherent variability
between test and training data poses a challenge in effec-
tively reducing noise while preserving fine-grained details.
In this context, we propose a transformer based diffusion
model with self-supervised conditioning function for HSI.
This model adeptly captures the spectral-spatial properties,
two pivotal characteristics of HSIs, and additionally gener-
ates high-quality textures through the diffusion process.
3. Methodology
Main Idea . Given a noisy HSI Y, the inverse problem for
HSI denoising is to separate the clean image X, Gaussian
noiseNdefined by:
Y=X+N. (1)
Given the inherently ill-posed nature of HSI reconstruction
as an inverse problem, extant methodologies continue to
27821
Upsample
Downsample
AT
At
A0 ... ...AT
At
A0 ... ...
Conditioning Function 
(CF)Self-
SupervisedFixed
Eq. 15
STU block
Abundance
Spectral EndmembersNoisy HSI  YAy
Ey
STU block
Abundance
Spectral EndmembersNoisy HSI  YAy
EyURUnmixing 
Reconstruction
UR
Reverse Diffusion
Eq. 15
XdiffAyAyCFCFP(A(t-1)|A(t), Ac, Ey)
AtAt-1 A0...AT...CF
EyAy, EyEq. 18Spectral Unmixing Markov Chain State Matching
Controlled Reverse Diffusion Conditional info
Matched start statefrom STU block
Reverse spectral 
unmixing Eq. 19Ay
Noise model
Noise model
Fit Gaussian
t
Start image
Figure 2. The overall framework of Diff-Unmix consists of three distinct yet interrelated modules. These modules include the spectral
unmixing based on Spectral Transformer Unmixing Network (STU, Fig. 3), serving as a latent space decomposition method with physical
significance in the context of Hyperspectral Imaging. Additionally, we have the Conditioning Function (CF) and Abundance Diffusion
Adjustment (ADA) modules, which play pivotal roles in refining the spectral unmixing process.
grapple with several notable challenges in the simultane-
ous achievement of accurate detail reconstruction and ef-
fective noise reduction. The denoising diffusion model, en-
dowed with its generative capability, stands out as a promis-
ing solution to this predicament. Nevertheless, (i)the dearth
of HSI datasets relative to RGB images, along with the
substantially higher dimensionality inherent in HSI data,
presents a formidable hurdle when endeavoring to retrain
a diffusion model tailored specifically for HSI applications.
(ii)Using pre-trained 2-D diffusion models for individual
HSI bands along the spectral axis is a potential strategy.
However, this approach may lead to incoherent reconstruc-
tions due to the lack of consideration for inter-band depen-
dencies and spectral correlations [21, 35, 51]. (iii)Further-
more, the iterative diffusion process for HSIs with tens or
hundreds of bands can be time-intensive.
To answer these questions, in this section, we demon-
strate that refined approximations of clean HSI ˆX, can be
produced through the integration of a spectral unmixing
model, where X=A × 3E, and a diffusion model op-
erating on the abundance map, A.×3is mode-3 tensor
matrix product [29]. To condition the diffusion sampling
process on the noisy input, denoted as Y, our approach in-
volves representing Ay(Y=Ay×3E)as a sample drawn
from a posterior distribution at an empirically derived in-
termediate state, denoted as At, within the Markov chain.
Subsequently, we initiate the sampling procedure directly
fromAyvia the conditional distribution p(AT|Ay).
3.1. Transformer Unmixing Network
The spectral unmixing theory assumes that an image can be
decomposed into abundance and spectral endmembers as:
X=A × 3E, (2)where Xis the input HSI. AandEdenote the abundance
maps and spectral endmembers, respectively. It is essen-
tially an ill-posed problem and many potential solutions ex-
ist. The abundance refers to the relative proportion of differ-
ent pure materials, known as endmembers, present within a
mixed pixel. These abundances signify the contribution of
each endmember to the overall spectral signature observed
in that pixel. For instance, in a landscape image, the abun-
dance values would represent the percentages of materials
like grass, soil, water, and rocks within a given pixel. On
the other hand, endmembers represent the pure spectral sig-
natures of individual materials in a scene, ideally devoid of
any mixture [28]. They serve as reference spectra for known
materials, so it tends to be constant in different noise degra-
dation conditions. Thus, the noise is decomposed into the
abundance map, and a visual illustration is shown in Fig. 3.
The optimization objective to realize spectral unmixing in
our method is generally represented via Eq. (3):
min
A,Eτ(A × 3E) +αϕ(A) +βψ(E), (3)
where τ(A × 3E)ensures that the image can be recon-
structed from the decomposed abundance and spectral end-
members. ϕ(A), ψ(E)constrain the consistency of abun-
dance map and spectral endmembers. α, β are the hyper-
parameters. Subsequently, a self-supervised loss function is
designed in next subsection.
3.1.1 Loss Functions
Utilizing the formulation presented in Equation (3), we
formulate distinct loss functions: the reconstruction loss,
abundance consistency loss, and spectral endmembers loss,
which are integral components in the optimization process
27822
CONV 2D
MaxPool 2D
CONV 2D
MaxPool 2D
CONV 2D
MaxPool 2D
CONV 2D  × 4
UpSample
Sigmoid
Abundance
Spectral Endmembers
Down -sample Up-sampleFigure 3. Detailed architecture of STU Unmixing network, which
consists of two parallel branches, and the details of Global Spectral
Attention (GSA) is shown in Fig. 4.
of the Transformer Unmixing Network. To address the need
for abundance consistency under varying noise conditions,
our training dataset comprises paired sets of noisy HSIs,
denoted as In, and their corresponding noise-variant coun-
terparts, denoted as Im. The abundance maps derived from
these datasets are denoted as AnandAmrespectively. Ad-
ditionally, the respective spectral endmembers are denoted
asEnandEm.
Reconstruction Loss τ(A × 3E): This loss term ensures
that the decomposed abundance maps Aand spectral end-
members Eaccurately reconstruct the original hyperspec-
tral image. It is defined by considering the fidelity of the
reconstructed images:
Lrec=∥In−An×3En∥1+αrec∥Im−Am×3Em∥1,(4)
where αrecserves as a hyper-parameter, allowing for the
adjustment of the contribution of different noise levels.
Abundance Fidelity Loss ϕ(A): The abundance loss term
is used to ensure abundance fidelity, which is defined as:
Laf=∥An− A m∥1. (5)
Spectral Endmembers Consistency Loss ψ(L): This loss
term enforces the consistency of spectral endmembers un-
der varying noise conditions, considering that the abun-
dance of objects remains invariant,
Lse=∥En−Em∥1. (6)
Finally, the comprehensive decomposition loss is given
by:
L=Lrec+γafLaf+γseLse, (7)
where γafandγserepresent hyper-parameters.
3.1.2 Network Architecture
As shown in Fig. 3, Spectral Transformer Unmixing net-
work (STU) consists of two branches, i.e., the Abundance
Decomposition (AD) branch and the Spectral Endmember
Decomposition (SED) branch.
...FC LayerRotate
RotateSoftmaxFigure 4. Detailed network architecture of GSA. The attention is
calculated in the direction of cross spectral mode to realize the
efficient unmixing of a hyperspectral image.
In the spectral endmember decomposition branch, mul-
tiple convolutional layers are employed to reduce compu-
tational complexity while ensuring effective decomposi-
tion, as discussed in [58]. In the abundance decomposi-
tion branch of the AD, a multi-stage spectral Transformer
encoder and decoder are utilized to preserve the intrinsic
characteristics of abundance and spectral endmember maps.
This approach enhances recovery performance and infor-
mation retention in the abundance map. Specifically, both
the Transformer encoder and decoder incorporate a Global
Spectral Attention module and a mapping layer. Given an
image Iof size H×W×Bto be decomposed, AD first
obtains its embedding features Finit∈RH×W×Cthrough a
convolutional projection, and the subsequent computations
in the AD block can be summarized as:
ˆFi= GSA( Norm (Fi−1)) +Fi−1, (8)
Fi= Mapping( ˆFi) +ˆFi, (9)
where Norm denotes normalization. Fi−1represents the
input feature map of the current AD block.
The time complexity of transformer scales quadratically
with the image size, posing computational challenges for
high-dimensional HSI data. Spectral unmixing primarily
relies on spectral correlations among spectral bands. Con-
sequently, allocating equal computational resources to both
spatial and spectral modes during spectral unmixing decom-
position may not be optimal. To solve this problem, inspired
by the spectral attention in [30], we utilize a novel global
spectral-wise attention (GSA) mechanism for computing at-
tention in AD, as shown in Fig. 4. On the premise of main-
taining the spectral unmixing performance, it reduces the
attention computation complexity to a great extent.
In the GSA module, a feature tensor X ∈RH×W×C,
obtained after applying Layer-Norm, is initially rotated as
X′for ease of correlating its spectral direction using a con-
volution operation. This leads to projections of the feature
intoQ,K, andV. Specifically, the projections result in
Q=WqX′,K=WkX′, andV=WvX′. This enables
the computation of attention in the spectral mode direction
27823
P(A(t-1)|A(t))
At A0...At A0...P(A(t-1)|A(t))
At A0...P(A(t-1)|A(t), A')
At A0...At A0...P(A(t-1)|A(t), A')
At A0...P(A(t-1)|A(t), ϕ(A'))
At A0...At A0...P(A(t-1)|A(t), ϕ(A'))
At A0...
a b cFigure 5. Comparison on reverse diffusion start from noisy A′, (a)
without condition, and conditioned on (b) A′, (c)Ac= Φ(A′).
via a transformer module. Mathematically, it can be ex-
pressed as shown in Equation (10):
ˆX=softmax (QK/d)· V+X, (10)
where drepresents a scale factor.
3.2. Diffusion Generation Adjustment
This section introduces a methodology for generating pre-
cise abundance approximations ( ˆA) using a pre-trained off-
the-shelf diffusion model enhanced with a trainable condi-
tioning function. To condition the diffusion sampling on
noisy input ( A′), we represent it as a sample from a data-
driven intermediate state ( At) in the Markov chain. We then
initiate the sampling process directly from A′through the
conditional probability p(At|A′), as shown in Fig. 2.
This formulation raises two key questions: (i) What
methodology maps A′to an intermediate state within the
Markov chain? and (ii) How to control the pre-trained diffu-
sion model to generate images with the intended semantics
when the best-matched states is available? To streamline pa-
rameter tuning, we devise Diff-Unmix in two stages, each
addressing these questions: (I) Markov chain state match-
ing; and (II) Diffusion model reverse conditioning.
Forward Diffusion Process . The forward diffusion pro-
cess can be viewed as a Markov chain progressively adding
Gaussian noise to the data. The data at step tis only depen-
dent on that at step t−1. Given t∈[0, T], the transition
probability is usually assumed to be a Gaussian distribution:
q(At|At−1) =N(At|√αtAt−1,(1−αt)I), (11)
and its parameter αtis preset as constant. By using repa-
rameterization, we can find the conditional distribution
aboutAtandS0as
q(At|A0) =N(At|√¯αtA0,(1−¯αt)I), (12)
where ¯αt=Qt
i=1αt. Then, in the forward process, the
distribution q(At|A0)approximates N(0,1)with gradually
adding noise to the previous state.
Conditioning Function Design . Denoising diffusion is
known as its generation capability. However, due to the in-
herent stochastic nature of the generative process in DDPM,generating images with the intended semantics remains
challenging even if we start with a state ATonA′.
Using the observed noisy image YorA′as direct con-
ditions is a natural approach. However, the noisy image
is of low quality and doesn’t offer effective guidance for
both low-frequency structure and high-frequency texture, as
demonstrated in Fig. 5. To exert more precise control over
unconditional DDPM using observed noisy measurements,
we employ Φas a conditioning function to derive a condi-
tional variable Ac= Φ( STU(Y))in a self-supervised man-
ner. Specifically, in signal processing, it is often assumed
that noisy signals arise from the introduction of noise, based
on a specified model, into clean signals [40, 55]. How-
ever, establishing an effective mapping between the input Y
and the output Xbecomes challenging when we lack prior
knowledge of this corruption process. Building upon the J-
Invariance theory [4], we propose training a denoising neu-
ral network directly on noisy images. Using the noisy signal
Yas input, the denoising function Φapproximates a refined
abundance matrix:
Ac≈ˆA= Φ(A′),A′= STU( Y). (13)
This method equips Φto perform regression on low-
dimensional abundances while incorporating spectral end-
members to form Y′=ˆA × 3E, which is important for un-
supervised learning. This approach makes that: (i) training
only weight-light ΦonAfor the entire spectral sequence
in a unsupervised manner, (ii) maintaining stable denoising
quality even with heavy noise, and (iii) achieving improved
spatial-spectral consistency in denoised bands. Here, we
learn Φvia an U-Net-like “hourglass” architecture, and its
detailed structure can be found in supplementary materials.
Here, we propose an unsupervised loss that ensures con-
sistency, that is
arg min
ΦEY
∥Y − Φ(A′)×3E− N∥2	
+Esn
∥ˆX −Φ(STU(ˆX), As)×3E∥2o
,(14)
where ˆX= Φ(A′)×3E,Asis a transform randomly se-
lected from a given set of transforms T,Nis Gaussian
noise with known deviation. The first term ensures mea-
surement consistency Y= Φ(A′)×3E+N, whereas the
second term enforces consistency across transforms, i.e.,
Φ(A′) = Φ( STU(AsΦ(A′)×3E), As)for all As∈T.
Markov Chain State Matching . Once an optimal mapping
function is learned by Φ, noise model can also be obtained
by fitting the approximated residual noise ˆNto a Gaussian
distribution N(σ2I)with zero mean and a variable standard
deviation σ(G-Fit ) [55]. Without any constraints, ˆNmay
not necessarily have a mean value of zero, and direct fitting
can lead to a shift in the distribution mean. To address this,
we propose to explicitly adjust the mean value of ˆN, de-
noted as µˆN=1
||ˆN||PˆN, to be zero: ˆN:=ˆN −µˆN,
27824
AT A0...AT A0...At A0...At A0...
Manual Steps:   T=500 Matched state:  t=61 Noisy InputMultispectral Data KAIST
PSNR:33.29dB   SSIM: 0.967Time: 41s
PSNR:34.36dB   SSIM: 0.975Time: 311s
Figure 6. Comparison on reverse diffusion conditioned on Φ(A′),
started from manual steps T= 500 and the matched state t= 61 .
The adjusted ˆNcan then be used to model the noise distri-
bution Gand estimate the parameter σ. Recall that in the
diffusion model, a noise schedule β1,···,Tis predefined to
represent the noise level at every state in the Markov chain.
We identify a matching state of A′by comparing the noise
model with all possible posteriors p(At)in terms of σand√βt. Specifically, a state is considered a match when a time
stamp tis found that minimizes the distance:
arg min
t||p
βt−σ||p, σ= G-Fit( ˆN,N(σ2I)),(15)
where || · ||pdenotes the p-norm distance. Since tis a dis-
crete integer within a finite interval: {1,···, T}, we refor-
mulate the optimization problem as a surrogate search [55].
Controlled Reverse Diffusion Process. A match at state
Atindicates that, given the specific noise schedule β, there
exists at least one potential sample from the posterior at
stateAtin the baseline unconditional generation process
that closely approximates the provided input A′. Conse-
quently, a more precise image can be sampled at state A0
through an iterative reverse process denoted as p(A0|At)
with condition Acfrom (13). With the matched state tand
trained ϵθ(·, t), reverse diffusion process [24] starting from
Atwith noisy abundance At=A′, and the reverse process
is updated as follows:
At−1=1√αt
At−1−αt√1−¯αtϵθ(At, t)
+√1−αtzt,(16)
where zt∼ N (0,1), t∈[T].As [42, 46], we formulate
the ancestral sampling process (16) as the discretization of
reverse SDE. Together with condition Acand the estimated
endmembers Eas conditioning variables, we can reformu-
late the reverse SDE concerning Aas
dA=
f(A, t)−g2(t)∇A(t)logpt(A(t)|Ac, E)
dt+g(t)d¯w,
(17)
where f(A, t) =−1
2(1−α(t))andg(t) =p
1−α(t),
¯wis the reverse of the standard Wiener process. The gradi-
ent∇A(t)logpt(A(t))is commonly referred to as the score
function of A(t). Then, we discretize the reverse SDE (17)using the form of ancestral sampling process (16):
At−1=1√αt 
At+ (1−αt)∇A(t)logpt(A(t)|Ac, E)
≈1√αt
At−1−αt√1−¯αtϵθ(At, t)
+√
1−αtzt
−η∇At∥Ac−ˆA0×3E∥F, (18)
where η=1−αt√αtγ. At time t, we can see that the sam-
pling consists of two parts. The first part is equal to sam-
pling from parameterized p(At−1|At)with fixed variance√1−αt. The second part pushes the sample towards the
consistent form with constraint on abundance. See sup-
plementary materials for the detailed inference of (17) and
(18). Finally, the HSI is reconstructed through unmixing
reconstruction, achieved by mixing the diffusion generative
adjusted abundance map with the spectral endmembers,
Xdiff=ˆA0×3Ey. (19)
4. Experiment
4.1. Implementation Details and Datasets
Implementation Details. The proposed Diff-Unmix model
undergoes two self-supervised training stages. Initially,
the STU is trained, then we fix the pre-trained diffusion
model [1] with unconditional mode and train the condition-
ing function associated with the diffusion generation adjust-
ment. The transform set Tincludes shift, flip, rotation . The
input image are cropped to patches of size 256×256. All
experiments are conducted using PyTorch on two NVIDIA
RTX 4060Ti GPUs running Ubuntu 22.04.2.
Datasets. To assess generalization capabilities, we train
the conditioning function and STU block on CAVE dataset
in a self-supervised manner, then test Diff-Unmix on
KAIST [14], CAVE ,CAVE-Toy [38] datasets with simu-
lated Gaussian noise: N(0,0.2), andN(0,0.3), and Ur-
ban1dataset with real-world noise including stripes, dead-
lines, atmospheric interference, water absorption, and other
unidentified sources.
4.2. Synthetic Noise
In simulated noise case, we compare the proposed
Diff-Unmix with 15 SOTA denoising methods within
five categories: (1) optimization based NonLRMA [12],
LRTDTV [63], LLRSSTV [21], TLRLSSTV [65],
LLxRGTV [64], 3DTNN [70], 3DTNN FW [71], LRTD-
CTV [63], E3DTV [39], FGSLR [13], (2) deep prior based
DIP [45], (3) plug and play framework based LLRPnP [66],
(4) self-supervised tensor network HLRTF [35], (5) diffu-
sion based DDRM [27] and DDS2M [36]. The STU unmix-
ing block and conditioning function are trained on CA VE
1http://www.tec.army.mil/ hypercube/
27825
Toy Dataset
GT Patch Noisy Patch 3DTNN [70] 3DTNN-FW [71] NonLRMA [12] FGSLR [13] LLRSSTV [21] LLxRGTV [64] TLRLSSTV [65]
LLRPnP [66] E3DTV [39] LRTDCTV [63] LRTDTV [51] DIP [45] DDRM [27] HLRTF [35] DDS2M [36] Diff-Unmix
Figure 7. Visual comparison of HSI denoising methods on Toydataset.
KAIST Dataset
GT Patch Noisy Patch 3DTNN [70] 3DTNN-FW [71] NonLRMA [12] FGSLR [13] LLRSSTV [21] LLxRGTV [64] TLRLSSTV [65]
LLRPnP [66] E3DTV [39] LRTDCTV [63] LRTDTV [51] DIP [45] DDRM [27] HLRTF [35] DDS2M [36] Diff-Unmix
Figure 8. Visual comparison of HSI denoising methods on KAIST dataset.
CA VE Dataset
GT Patch Noisy Patch 3DTNN [70] 3DTNN-FW [71] NonLRMA [12] FGSLR [13] LLRSSTV [21] LLxRGTV [64] TLRLSSTV [65]
LLRPnP [66] E3DTV [39] LRTDCTV [63] LRTDTV [51] DIP [45] DDRM [27] HLRTF [35] DDS2M [36] Diff-Unmix
Figure 9. Visual comparison of HSI denoising methods on CAVE dataset.
Table 1. Quantitative PSNR, SSIM, FSIM, SAM and Time on KAIST dataset, gray: deep prior, PnP and tensor network based models,
yellow: denoising diffusion based methods, the rest is model based algorithm. Left: Case :N(0,0.2), right: Case :N(0,0.3).
Method Reference PSNR ↑SSIM ↑FSIM ↑SAM↓Time (s)
Noisy None 16.175 0.115 0.401 0.801 None
NonLRMA [12] TGRS 2017 21.259 0.414 0.803 0.882 11
LRTDTV [51] JSTAR 2017 31.061 0.772 0.882 0.297 38
LLRSSTV [21] JSTAR 2018 28.145 0.682 0.814 0.432 36
TLR LSSTV [65] TGRS 2021 24.875 0.532 0.767 0.395 76
LLxRGTV [64] SP 2021 31.152 0.802 0.917 0.205 38
3DTNN [70] IS 2020 25.477 0.668 0.887 0.227 16
3DTNN FW [71] TGRS 2019 28.035 0.780 0.881 0.197 20
LRTDCTV [63] JSTAR 2023 25.952 0.658 0.816 0.406 43
E3DTV [39] TIP 2020 30.335 0.868 0.926 0.221 10
FGSLR [13] TGRS 2021 30.126 0.737 0.878 0.262 249
DIP [45] ICCVW 2019 24.181 0.608 0.825 0.475 72
LLRPnP [66] IA 2020 28.664 0.748 0.861 0.379 240
HLRTF [35] CVPR 2022 33.011 0.808 0.925 0.275 23
DDRM [27] NeurIPS 2022 29.412 0.865 0.922 0.293 20
DDS2M [36] ICCV 2023 32.804 0.786 0.895 0.334 354
Diff-Unmix Ours 33.059 0.964 0.940 0.116 37Method Reference PSNR ↑SSIM ↑FSIM ↑SAM↓Time (s)
Nosiy None 12.980 0.064 0.320 0.862 None
NonLRMA [12] TGRS 2017 20.300 0.355 0.772 0.918 11
LRTDTV [51] JSTAR 2017 28.606 0.670 0.829 0.331 38
LLRSSTV [21] JSTAR 2018 25.340 0.562 0.743 0.487 37
TLR LSSTV [65] TGRS 2021 22.824 0.407 0.689 0.459 76
LLxRGTV [64] SP 2021 27.640 0.679 0.868 0.218 38
3DTNN [70] IS 2020 22.278 0.558 0.853 0.271 16
3DTNN FW [71] TGRS 2019 26.035 0.724 0.848 0.212 20
LRTDCTV [63] JSTAR 2023 24.593 0.533 0.739 0.431 42
E3DTV [39] TIP 2020 28.358 0.819 0.900 0.248 9
FGSLR [13] TGRS 2021 25.561 0.480 0.718 0.470 499
DIP [45] ICCVW 2019 20.063 0.405 0.798 0.538 74
LLRPnP[66] IA 2020 25.102 0.592 0.768 0.425 289
HLRTF [35] CVPR 2022 30.340 0.689 0.874 0.329 25
DDRM [27] NeurIPS 2022 27.810 0.786 0.893 0.387 23
DDS2M [36] ICCV 2023 30.078 0.666 0.834 0.355 318
Diff-Unmix Ours 31.408 0.902 0.958 0.282 42
dataset in a self-supervised manner. For the optimization
based methods, the hyperparameters are set according to
the original papers, and we fine-tune the rank slightly to
get better PSNR. For DDRM, we adapt its denoising mod-
els with σ= 0.2,0.3. In Tab. 1 and Tab. 2, Fig. 8, 7, 9, we
present the denoising performance of the different methods.
One can see that Diff-Unmix achieves the best indexes and
visual effects in most cases.4.3. Real-World Noise
The urban HSI is affected by a range of noise sources in-
cluding stripes, deadlines, atmospheric interference, water
absorption, and other unidentified sources [23]. In Fig. 10, a
comparison on the real Urban dataset is shown. It is evident
that HLRTF and Diff-Unmix demonstrate superior denois-
ing capabilities when compared to DDRM and DDS2M.
Although DDRM and DDS2M perform well under simu-
27826
Table 2. Quantitative results on CAVE andCAVE-Toy dataset, gray: deep prior, PnP and tensor network based models, yellow: denoising
diffusion based methods, the rest is optimization based algorithm. PSNR, SSIM, FSIM, SAM and running time are reported.
(a)Comparisons on Toydataset.
Method Framework PSNR ↑SSIM ↑FSIM ↑SAM↓Time (s)
Noisy None None 12.334 0.122 0.374 0.605 None
NonLRMA [12] Model Self-Sup 21.600 0.566 0.766 0.268 12
LRTDTV [51] Model Self-Sup 26.578 0.729 0.836 0.181 39
TLR LSSTV [65] Model Self-Sup 21.681 0.556 0.736 0.199 80
LLxRGTV [64] Model Self-Sup 26.450 0.752 0.874 0.118 39
3DTNN [70] Model Self-Sup 23.397 0.712 0.857 0.124 19
3DTNN FW [71] Model Self-Sup 25.496 0.771 0.843 0.111 23
LRTDCTV [63] Model Self-Sup 25.214 0.665 0.783 0.228 45
E3DTV [39] Model Self-Sup 24.157 0.810 0.878 0.156 11
FGSLR [13] Model Self-Sup 21.525 0.573 0.798 0.241 1149
TwoStage [41] CNN Semi-Sup 29.032 0.869 0.911 0.181 2h+
DIP [45] CNN Self-Sup 22.092 0.594 0.895 0.191 67
LLRPnP [66] PnP Self-Sup 23.088 0.541 0.717 0.207 240
HLRTF [35] Tensor-CNN Self-Sup 27.308 0.730 0.941 0.161 41
DDRM [27] Diffusion Self-Sup 27.886 0.858 0.910 0.159 16
DDS2M [36] Diffusion Self-Sup 29.344 0.844 0.977 0.111 320
Diff-Unmix Diffusion Self-Sup 28.046 0.945 0.993 0.156 43(b)Comparisons on CAVE dataset.
Method Reference PSNR ↑SSIM ↑FSIM ↑SAM↓Time (s)
Nosiy None 12.980 0.064 0.320 0.862 None
NonLRMA [12] TGRS 2017 22.002 0.374 0.764 0.612 14
LRTDTV [51] JSTAR 2017 30.545 0.678 0.766 0.241 42
LLRSSTV [21] JSTAR 2018 25.319 0.435 0.641 0.299 39
TLR LSSTV [65] TGRS 2021 24.375 0.352 0.589 0.314 82
LLxRGTV [64] SP 2021 28.743 0.712 0.829 0.121 40
3DTNN [70] IS 2020 25.161 0.826 0.922 0.094 17
3DTNN FW [71] TGRS 2019 31.069 0.930 0.918 0.116 23
LRTDCTV [63] JSTAR 2023 24.394 0.444 0.631 0.315 47
E3DTV[39] TIP 2020 32.344 0.951 0.955 0.108 11
FGSLR [13] TGRS 2021 24.474 0.346 0.554 0.511 1758
DIP [45] ICCVW 2019 20.480 0.554 0.864 0.313 66
LLRPnP[66] IA 2020 24.809 0.445 0.668 0.284 246
HLRTF [35] CVPR 2022 30.308 0.770 0.861 0.185 133
DDRM [27] NeurIPS 2022 30.521 0.754 0.873 0.196 16
DDS2M [36] ICCV 2023 30.837 0.724 0.863 0.251 319
Diff-Unmix Ours 32.714 0.940 0.957 0.129 43
Real Urban
 Noisy Patch DDRM [27] SST [30] HLRTF [35] SERT [31] DDS2M [36] Diff-Unmix
Figure 10. Results on Urban with real-world noise including stripes, deadlines, atmospheric interference, water absorption, and other
unidentified sources. One can see that our Diff-Unmix adeptly mitigates mixed noise, ensuring the retention of fine-grained details.
KAIST
GT Patch GT with N(0,0.3)
DDS2M [36] Diff-Unmix
Figure 11. Visual comparison on over-enhanced case.
lated Gaussian noise, they tend to overly smooth out cru-
cial details when confronted with real mixed noise. On
the other hand, Diff-Unmix efficiently retains most of the
details while effectively removing mixed noise by utilizing
information from diverse spectral bands.
4.4. Ablation Study
Transformer Unmixing Network . To assess the efficacy
of the STU network, we conduct a visual analysis of the
decomposition process. It is crucial to note that spectral
unmixing poses an inherently ill-posed problem, lacking an
exact optimal solution. A pivotal consideration is the neces-
sity for consistent endmember information across varying
levels of noise. For comparative purposes, we also employ
Singular Value Decomposition technique for unmixing, the
results are shown in supplementary material.
Markov Chain State Matching . The impact of State
Matching is illustrated in Fig. 6, demonstrating that aligning
the noisy input with an intermediate state in the diffusionMarkov chain accelerates the inference process, leading to
a faster generation of the desired HSI (41s vs.311s).
Conditioning Function Φ. A visual comparison of Diff-
Unmix w/andw/oconditioning on Φis depicted in Fig. 5.
It is evident that the inclusion of Φeffectively guides the
Diff-Unmix process to generate high-quality details.
4.5. Limitations
Similar to many applications of DDPM, Diff-Unmix has the
potential to generate spurious details (over-enhancement)
due to its generative nature, as illustrated in Fig. 11. In
contrast, DDS2M yields a distorted result in this scenario.
5. Conclusion
In this paper, we rethink the HSI denoising task and propose
a generative Diff-Unmix denoising model. Diff-Unmix for-
mulates the HSI denoising task as a paradigm of spectral un-
mixing and image generation. It can adaptively decompose
images into abundance map and spectral endmembers and
solve degradation by generative denoising diffusion models.
The experimental results show that Diff-Unmix has excel-
lent performance and makes subtle-detail completion and
inference details restoration of noise reduction into reality.
Besides, the proposed method demonstrates superior gen-
eralization capacity for unseen real and mixed noise com-
pared to state-of-the-art methods.
6. Acknowledgments
This work was supported in part by the Flemish Gov-
ernment (AI Research Program), UGent-Special Research
Fund (BOF).
27827
References
[1] Wele Gedara Chaminda Bandara, Nithin Gopalakrishnan
Nair, and Vishal M Patel. Ddpm-cd: Remote sensing change
detection using denoising diffusion probabilistic models.
arXiv preprint arXiv:2206.11892 , 2022. 6
[2] Wele Gedara Chaminda Bandara and Vishal M Patel. Hy-
pertransformer: A textural and spectral feature fusion trans-
former for pansharpening. In CVPR , pages 1767–1777,
2022. 2
[3] Robert W Basedow, Dwayne C Carmer, and Mark E Ander-
son. Hydice system: Implementation and performance. In
Imaging Spectrometry , volume 2480, pages 258–267. SPIE,
1995. 1
[4] Joshua Batson and Loic Royer. Noise2self: Blind denoising
by self-supervision. In ICML , pages 524–533. PMLR, 2019.
5
[5] Th ´eo Bodrito, Alexandre Zouaoui, Jocelyn Chanussot, and
Julien Mairal. A trainable spectral-spatial sparse coding
model for hyperspectral image restoration. In NeurIPS , vol-
ume 34, pages 5430–5442, 2021. 2
[6] P ´eter Burai, Bal ´azs De ´ak, Orsolya Valk ´o, and Tam ´as To-
mor. Classification of herbaceous vegetation using airborne
hyperspectral imagery. Remote Sensing , 7(2):2046–2066,
2015. 1
[7] Xiangyong Cao, Xueyang Fu, Chen Xu, and Deyu Meng.
Deep spatial-spectral global reasoning network for hyper-
spectral image denoising. IEEE TGRS , 2021. 1, 2
[8] Xiangyong Cao, Qian Zhao, Deyu Meng, Yang Chen, and
Zongben Xu. Robust low-rank matrix factorization under
general mixture noise distributions. IEEE TIP , 25(10):4677–
4690, 2016. 2
[9] Yi Chang, Luxin Yan, Xi-Le Zhao, Houzhang Fang, Zhi-
jun Zhang, and Sheng Zhong. Weighted low-rank tensor
recovery for hyperspectral image restoration. IEEE TCYB ,
50(11):4558–4572, 2020. 1, 2
[10] Yi Chang, Luxin Yan, and Sheng Zhong. Hyper-laplacian
regularized unidirectional low-rank tensor recovery for mul-
tispectral image denoising. In CVPR , pages 4260–4268,
2017. 1, 2
[11] Guangyi Chen and Shen-En Qian. Denoising of hyperspec-
tral imagery using principal component analysis and wavelet
shrinkage. IEEE TGRS , 49(3):973–980, 2010. 1, 2
[12] Yongyong Chen, Yanwen Guo, Yongli Wang, Dong Wang,
Chong Peng, and Guoping He. Denoising of hyperspec-
tral images using nonconvex low rank matrix approximation.
IEEE TGRS , 55(9):5366–5380, 2017. 6, 7, 8
[13] Yong Chen, Ting-Zhu Huang, Wei He, Xi-Le Zhao, Hongyan
Zhang, and Jinshan Zeng. Hyperspectral image denoising
using factor group sparsity-regularized nonconvex low-rank
approximation. IEEE TGRS , 60:1–16, 2021. 6, 7, 8
[14] Inchang Choi, MH Kim, D Gutierrez, DS Jeon, and G Nam.
High-quality hyperspectral reconstruction using a spectral
prior. In Technical report , 2017. 6
[15] Xiangxiang Chu, Zhi Tian, Yuqing Wang, Bo Zhang, Haib-
ing Ren, Xiaolin Wei, Huaxia Xia, and Chunhua Shen.
Twins: Revisiting the design of spatial attention in vision
transformers. In NeurIPS , volume 34, pages 9355–9366,
2021. 2
[16] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. arXiv preprint
arXiv:2010.11929 , 2020. 1
[17] Ying Fu, Antony Lam, Imari Sato, and Yoichi Sato. Adaptive
spatial-spectral dictionary learning for hyperspectral image
denoising. In ICCV , pages 343–351, 2015. 1, 2
[18] Wei He, Quanming Yao, Chao Li, Naoto Yokoya, and Qibin
Zhao. Non-local meets global: An integrated paradigm for
hyperspectral denoising. In CVPR , pages 6868–6877, 2019.
1, 2
[19] Wei He, Quanming Yao, Chao Li, Naoto Yokoya, Qibin
Zhao, Hongyan Zhang, and Liangpei Zhang. Non-local
meets global: An iterative paradigm for hyperspectral image
restoration. IEEE TPAMI , 44(4):2089–2107, 2020. 2
[20] Wei He, Hongyan Zhang, Huanfeng Shen, and Liangpei
Zhang. Hyperspectral image denoising using local low-rank
matrix recovery and global spatial–spectral total variation.
IEEE J-STARS , 11(3):713–729, 2018. 1
[21] Wei He, Hongyan Zhang, Huanfeng Shen, and Liangpei
Zhang. Hyperspectral image denoising using local low-rank
matrix recovery and global spatial–spectral total variation.
IEEE J-STARS , 11(3):713–729, 2018. 3, 6, 7, 8
[22] Wei He, Hongyan Zhang, Liangpei Zhang, and Huanfeng
Shen. Total-variation-regularized low-rank matrix factor-
ization for hyperspectral image restoration. IEEE TGRS ,
54(1):178–188, 2015. 1
[23] Wei He, Hongyan Zhang, Liangpei Zhang, and Huanfeng
Shen. Total-variation-regularized low-rank matrix factor-
ization for hyperspectral image restoration. IEEE TGRS ,
54(1):178–188, 2015. 7
[24] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-
fusion probabilistic models. NeurIPS , 33:6840–6851, 2020.
6
[25] Danfeng Hong, Zhu Han, Jing Yao, Lianru Gao, Bing Zhang,
Antonio Plaza, and Jocelyn Chanussot. Spectralformer: Re-
thinking hyperspectral image classification with transform-
ers.IEEE TGRS , 60:1–15, 2021. 2
[26] Jie Huang, Ting-Zhu Huang, Liang-Jian Deng, and Xi-Le
Zhao. Joint-sparse-blocks and low-rank representation for
hyperspectral unmixing. IEEE TGRS , 57(4):2419–2438,
2018. 2
[27] Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming
Song. Denoising diffusion restoration models. NeurIPS ,
35:23593–23606, 2022. 6, 7, 8
[28] Nirmal Keshava and John F Mustard. Spectral unmixing.
IEEE signal processing magazine , 19(1):44–57, 2002. 3
[29] Tamara G Kolda and Brett W Bader. Tensor decompositions
and applications. SIAM review , 51(3):455–500, 2009. 3
[30] Miaoyu Li, Ying Fu, and Yulun Zhang. Spatial-spectral
transformer for hyperspectral image denoising. In Proceed-
ings of the AAAI Conference on Artificial Intelligence , vol-
ume 37, pages 1368–1376, 2023. 4, 8
[31] Miaoyu Li, Ji Liu, Ying Fu, Yulun Zhang, and Dejing Dou.
Spectral enhanced rectangle transformer for hyperspectral
image denoising. In CVPR , pages 5805–5814, 2023. 2, 8
[32] Bing Liu, Anzhu Yu, Kuiliang Gao, Xiong Tan, Yifan Sun,
and Xuchu Yu. Dss-trm: Deep spatial–spectral transformer
27828
for hyperspectral image classification. European Journal of
Remote Sensing , 55(1):103–114, 2022. 2
[33] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng
Zhang, Stephen Lin, and Baining Guo. Swin transformer:
Hierarchical vision transformer using shifted windows. In
ICCV , pages 10012–10022, 2021. 2
[34] Ting Lu, Shutao Li, Leyuan Fang, Yi Ma, and J ´on Atli
Benediktsson. Spectral–spatial adaptive sparse represen-
tation for hyperspectral image denoising. IEEE TGRS ,
54(1):373–385, 2015. 2
[35] Yisi Luo, Xi-Le Zhao, Deyu Meng, and Tai-Xiang Jiang.
Hlrtf: Hierarchical low-rank tensor factorization for inverse
problems in multi-dimensional imaging. In CVPR , pages
19303–19312, 2022. 3, 6, 7, 8
[36] Yuchun Miao, Lefei Zhang, Liangpei Zhang, and Dacheng
Tao. Dds2m: Self-supervised denoising diffusion spatio-
spectral model for hyperspectral image restoration. In ICCV ,
pages 12086–12096, 2023. 1, 6, 7, 8
[37] Erting Pan, Yong Ma, Xiaoguang Mei, Fan Fan, Jun Huang,
and Jiayi Ma. Sqad: Spatial-spectral quasi-attention re-
current network for hyperspectral image denoising. IEEE
TGRS . 2
[38] Jong-Il Park, Moon-Hyun Lee, Michael D Grossberg, and
Shree K Nayar. Multispectral imaging using multiplexed il-
lumination. In ICCV , pages 1–8. IEEE, 2007. 6
[39] Jiangjun Peng, Qi Xie, Qian Zhao, Yao Wang, Leung Yee,
and Deyu Meng. Enhanced 3dtv regularization and its appli-
cations on hsi denoising and compressed sensing. IEEE TIP ,
29:7889–7903, 2020. 6, 7, 8
[40] Mangal Prakash, Alexander Krull, and Florian Jug. Fully un-
supervised diversity denoising with convolutional variational
autoencoders. arXiv preprint arXiv:2006.06072 , 2020. 5
[41] Yuntao Qian, Honglin Zhu, Ling Chen, and Jun Zhou. Hy-
perspectral image restoration with self-supervised learning:
A two-stage training approach. IEEE TGRS , 60:1–17, 2021.
8
[42] Xiangyu Rui, Xiangyong Cao, Zeyu Zhu, Zongsheng Yue,
and Deyu Meng. Unsupervised pansharpening via low-rank
diffusion model. arXiv preprint arXiv:2305.10925 , 2023. 2,
6
[43] Qian Shi, Xiaopei Tang, Taoru Yang, Rong Liu, and Liangpei
Zhang. Hyperspectral image denoising using a 3-d attention
denoising network. IEEE TGRS , 2021. 2
[44] Oleksii Sidorov and Jon Yngve Hardeberg. Deep hyper-
spectral prior: Single-image denoising, inpainting, super-
resolution. In CVPR , pages 0–0, 2019. 1
[45] Oleksii Sidorov and Jon Yngve Hardeberg. Deep hyper-
spectral prior: Single-image denoising, inpainting, super-
resolution. In ICCV , pages 0–0, 2019. 6, 7, 8
[46] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-based
generative modeling through stochastic differential equa-
tions. In ICLR , 2021. 6
[47] Xunyang Su, Jinjiang Li, and Zhen Hua. Transformer-based
regression network for pansharpening remote sensing im-
ages. IEEE TGRS , 60:1–23, 2022. 2
[48] Muhammad Uzair, Arif Mahmood, and Ajmal Mian. Hyper-
spectral face recognition with spatiospectral information fu-
sion and pls regression. IEEE TIP , 24(3):1127–1137, 2015.1
[49] Muhammad Uzair, Arif Mahmood, and Ajmal S Mian. Hy-
perspectral face recognition using 3d-dct and partial least
squares. In BMVC , volume 1, page 10, 2013. 1
[50] Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao
Song, Ding Liang, Tong Lu, Ping Luo, and Ling Shao.
Pyramid vision transformer: A versatile backbone for dense
prediction without convolutions. In ICCV , pages 568–578,
2021. 1
[51] Yao Wang, Jiangjun Peng, Qian Zhao, Yee Leung, Xi-Le
Zhao, and Deyu Meng. Hyperspectral image restoration via
total variation regularized low-rank tensor decomposition.
IEEE J-STARS , 11(4):1227–1243, 2017. 3, 7, 8
[52] Kaixuan Wei, Ying Fu, and Hua Huang. 3-d quasi-recurrent
neural network for hyperspectral image denoising. TNNLS ,
32(1):363–375, 2020. 1, 2
[53] Wei Wei, Lei Zhang, Chunna Tian, Antonio Plaza, and Yan-
ning Zhang. Structured sparse coding-based hyperspectral
imagery denoising with intracluster filtering. IEEE TGRS ,
55(12):6860–6876, 2017. 1
[54] Xueling Wei, Wei Li, Mengmeng Zhang, and Qingli Li.
Medical hyperspectral image classification based on end-to-
end fusion deep neural network. IEEE TIM , 68(11):4481–
4492, 2019. 1
[55] Tiange Xiang, Mahmut Yurt, Ali B Syed, Kawin Setsom-
pop, and Akshay Chaudhari. Ddm ˆ2: Self-supervised diffu-
sion mri denoising with generative diffusion models. arXiv
preprint arXiv:2302.03018 , 2023. 5, 6
[56] Fengchao Xiong, Jun Zhou, Shuyin Tao, Jianfeng Lu, Jiantao
Zhou, and Yuntao Qian. Smds-net: Model guided spectral-
spatial network for hyperspectral image denoising. IEEE
TIP, 31:5469–5483, 2022. 2
[57] Fengchao Xiong, Jun Zhou, Qinling Zhao, Jianfeng Lu, and
Yuntao Qian. Mac-net: Model-aided nonlocal neural net-
work for hyperspectral image denoising. IEEE TGRS , 60:1–
14, 2021. 2
[58] Xunpeng Yi, Han Xu, Hao Zhang, Linfeng Tang, and Jiayi
Ma. Diff-retinex: Rethinking low-light image enhancement
with a generative diffusion model. In Proceedings of the
IEEE/CVF International Conference on Computer Vision ,
pages 12302–12311, 2023. 4
[59] Qiangqiang Yuan, Liangpei Zhang, and Huanfeng Shen. Hy-
perspectral image denoising employing a spectral–spatial
adaptive total variation model. IEEE TGRS , 50(10):3660–
3677, 2012. 2
[60] Qiangqiang Yuan, Qiang Zhang, Jie Li, Huanfeng Shen, and
Liangpei Zhang. Hyperspectral image denoising employ-
ing a spatial–spectral deep residual convolutional neural net-
work. IEEE TGRS , 57(2):1205–1218, 2018. 1, 2
[61] Syed Waqas Zamir, Aditya Arora, Salman Khan, Mu-
nawar Hayat, Fahad Shahbaz Khan, and Ming-Hsuan Yang.
Restormer: Efficient transformer for high-resolution image
restoration. In CVPR , pages 5728–5739, 2022. 2
[62] Haijin Zeng, Jiezhang Cao, Kai Feng, Shaoguang
Huang, Hongyan Zhang, Hiep Luong, and Wilfried
Philips. Degradation-noise-aware deep unfolding trans-
former for hyperspectral image denoising. arXiv preprint
arXiv:2305.04047 , 2023. 1
[63] Haijin Zeng, Shaoguang Huang, Yongyong Chen, Hiep Lu-
27829
ong, and Wilfried Philips. All of low-rank and sparse: A
recast total variation approach to hyperspectral denoising.
IEEE J-STARS , 2023. 6, 7, 8
[64] Haijin Zeng and Xiaozhen Xie. Hyperspectral image denois-
ing via global spatial-spectral total variation regularized non-
convex local low-rank tensor approximation. Signal Process-
ing, 178:107805, 2021. 6, 7, 8
[65] Haijin Zeng, Xiaozhen Xie, Haojie Cui, Hanping Yin, and
Jifeng Ning. Hyperspectral image restoration via global l 1-
2 spatial–spectral total variation regularized local low-rank
tensor recovery. IEEE TGRS , 59(4):3309–3325, 2020. 6, 7,
8
[66] Haijin Zeng, Xiaozhen Xie, Wenfeng Kong, Shuang Cui, and
Jifeng Ning. Hyperspectral image denoising via combined
non-local self-similarity and local low-rank regularization.
IEEE Access , 8:50190–50208, 2020. 6, 7, 8
[67] Feng Zhang, Kai Zhang, and Jiande Sun. Multiscale spatial–
spectral interaction transformer for pan-sharpening. Remote
Sensing , 14(7):1736, 2022. 2
[68] Hongyan Zhang, Lu Liu, Wei He, and Liangpei Zhang. Hy-
perspectral image denoising with total variation regulariza-
tion and nonlocal low-rank tensor decomposition. IEEE
TGRS , 58(5):3071–3084, 2019. 1, 2
[69] Xiangtao Zheng, Yuan Yuan, and Xiaoqiang Lu. Hyperspec-
tral image denoising by fusing the selected related bands.
IEEE TGRS , 57(5):2596–2609, 2018. 2
[70] Yu-Bang Zheng, Ting-Zhu Huang, Xi-Le Zhao, Tai-Xiang
Jiang, Teng-Yu Ji, and Tian-Hui Ma. Tensor n-tubal rank
and its convex relaxation for low-rank tensor recovery. In-
formation Sciences , 532:170–189, 2020. 6, 7, 8
[71] Yu-Bang Zheng, Ting-Zhu Huang, Xi-Le Zhao, Tai-Xiang
Jiang, Tian-Hui Ma, and Teng-Yu Ji. Mixed noise removal
in hyperspectral image via low-fibered-rank regularization.
IEEE TGRS , 58(1):734–749, 2019. 6, 7, 8
[72] Lina Zhuang and Jos ´e M Bioucas-Dias. Fast hyperspec-
tral image denoising and inpainting based on low-rank
and sparse representations. IEEE J-STARS , 11(3):730–742,
2018. 2
27830
