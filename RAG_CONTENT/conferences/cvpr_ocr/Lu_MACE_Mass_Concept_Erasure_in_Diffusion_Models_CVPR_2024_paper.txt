MACE: Mass Concept Erasure in Diffusion Models
Shilin Lu1Zilan Wang1Leyang Li1Yanzhu Liu2Adams Wai-Kin Kong1
1School of Computer Science and Engineering, Nanyang Technological University, Singapore
2Institute for Infocomm Research ( I2R) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore
{shilin002, wang1982, lile0005 }@e.ntu.edu.sg, liu yanzhu@i2r.a-star.edu.sg, adamskong@ntu.edu.sg
‚Äòa photo of the airplane‚Äô (erased) ‚Äòa photo of Paul Walker ‚Äô (erased)
‚Äòa photo of the aircraft‚Äô (synonymous) ‚Äòa photo of Paul Wesley ‚Äô (unrelated)SD v1.4 MACE SD v1.4 MACE
Generality SpecificityEfficacy Efficacy
(a) Object Erasure (b) Celebrity Erasure (c) Scaling Erasure up t o 100 ConceptsBetter
Figure 1. Our proposed method, MACE, can erase a large number of concepts from text-to-image diffusion models. This can safeguard
celebrity portrait rights, respect copyrights on artworks, and prevent explicit content creation. (a) MACE demonstrates good efÔ¨Åcacy andgenerality by preventing the generation of images reÔ¨Çecting the target concept and its synonyms . (b) MACE maintains excellent speciÔ¨Åcity,
ensuring that the unintended concepts remain intact, even when they share common terms with the target concept . (c) MACE exhibits
a signiÔ¨Åcantly enhanced ability to erase 100 concepts, outperforming previous methods. The overall score indicates the comprehensiveerasing capability, as detailed in Section 4.3.
Abstract
The rapid expansion of large-scale text-to-image diffu-
sion models has raised growing concerns regarding theirpotential misuse in creating harmful or misleading content.In this paper , we introduce MACE, a Ô¨Ånetuning frameworkfor the task of MAss Concept Erasure. This task aims to pre-vent models from generating images that embody unwantedconcepts when prompted. Existing concept erasure meth-ods are typically restricted to handling fewer than Ô¨Åve con-cepts simultaneously and struggle to Ô¨Ånd a balance betweenerasing concept synonyms (generality) and maintaining un-related concepts (speciÔ¨Åcity). In contrast, MACE differs bysuccessfully scaling the erasure scope up to 100 conceptsand by achieving an effective balance between generalityand speciÔ¨Åcity. This is achieved by leveraging closed-formcross-attention reÔ¨Ånement along with LoRA Ô¨Ånetuning, col-lectively eliminating the information of undesirable con-cepts. Furthermore, MACE integrates multiple LoRAs with-out mutual interference. We conduct extensive evaluationsof MACE against prior methods across four different tasks:object erasure, celebrity erasure, explicit content erasure,and artistic style erasure. Our results reveal that MACE sur-passes prior methods in all evaluated tasks. Code is avail-able at https://github.com/Shilin-LU/MACE .1. Introduction
In large-scale text-to-image (T2I) models [ 9,14,34,40,49,
54,57,73,74,76,77], the task of concept erasure aims
to remove concepts that may be harmful, copyrighted, or
offensive. This ensures that when a model is prompted with
any phrase related to deleted concepts, it will not generateimages reÔ¨Çecting those concepts.
The drive behind concept erasure is rooted in the sig-
niÔ¨Åcant risks posed by T2I models. These models can gen-erate inappropriate content, such as copyrighted artworks[23,24,55,61], explicit content [ 22,59,72], and deepfakes
[38,70]. These issues are largely caused by the unÔ¨Åltered,
web-scraped training data [ 60]. While researchers have put
efforts to mitigate these risks through reÔ¨Åning datasets andretraining models, these methods are not only costly butalso can lead to unforeseen outcomes [ 7,44]. For example,
despite being trained on a sanitized dataset, Stable Diffu-sion (SD) v2.0 [ 52] still produces explicit content. More-
over, it exhibits a diminished generative quality for regularcontent when compared to its earlier versions [ 44]. Alterna-
tive methods, such as post-generation Ô¨Åltering [ 41,50] and
inference guiding [ 3,59], are effective when models are ac-
cessed only via APIs. Yet, these safeguards can be easily
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
6430
bypassed if users have access to the source code [ 63].
To mitigate the vulnerability of these safeguards, sev-
eral Ô¨Ånetuning-based methods have been proposed [ 16,17,
19,25,30,71]. Nonetheless, the challenge of concept era-
sure lies in balancing the dual requirements of generality
and speciÔ¨Åcity. Generality requires that a concept should beconsistently removed, regardless of its expression and thecontext in which it appears. On the other hand, speciÔ¨Åcityrequires that unrelated concepts remain intact. Our analy-sis reveals that there is substantial room for enhancing thesemethods with respect to both generality and speciÔ¨Åcity.
We pinpoint three primary issues that hinder the effec-
tiveness of prior works. Firstly, the information of a phraseis concealed within other words in the prompt through theattention mechanism [ 69]. This is sufÔ¨Åcient to evoke the
concept from T2I models (see Figure 2), leading to re-
stricted generality and incomplete elimination when remov-ing concepts. Secondly, Ô¨Ånetuning the diffusion model‚Äôsprediction on early denoising steps ( t>t
0) can result in
degraded speciÔ¨Åcity of concept erasure. Typically, diffu-sion models generate a general context in the early stage[12,31,51]. For instance, when generating a portrait of
Paul Walker or Paul Wesley, the initial sampling trajectorygravitates towards the face manifold. It begins by form-ing a vague outline that could resemble any person. Af-ter a turning point, a.k.a. spontaneous symmetry breaking(SSB) [ 51], the identity becomes clear with the details pro-
gressively Ô¨Ålled in. If our goal is to only prevent the modelfrom generating images of Paul Walker, it should not impactother celebrities named ‚ÄòPaul‚Äô (See Figure 1). However,
if we alter the predictions made in the early stages, other‚ÄòPauls‚Äô can inadvertently be affected. Lastly, when Ô¨Åneturn-
ing methods are applied to erase a large number of concept
(e.g., 100), a noticeable decline in performance is observed.This decline is due to either sequential or parallel Ô¨Ånetun-ing of the models. The former is prone to catastrophic for-getting and the latter results in interference among differentconcepts being Ô¨Ånetuned.
In light of these challenges, we propose a framework,
dubbed MAss Concept Erasure (MACE), to erase a largenumber of concepts from T2I diffusion models. MACE notonly achieves a superior balance between generality andspeciÔ¨Åcity, but also adeptly handles the erasure of 100 con-cepts. It requires neither concept synonyms nor the originaltraining data to perform concept erasure. To remove multi-ple concepts, MACE starts by reÔ¨Åning the cross-attentionlayers of the pretrained model using a closed-form solu-tion. This design encourages the model to refrain from em-bedding residual information of the target phrase into otherwords, thereby erasing traces of the concept in the prompt.Secondly, it employs a unique LoRA module [ 21] for each
individual concept to remove its intrinsic information. Tomaintain speciÔ¨Åcity, MACE exploits concept-focal impor-
		    	 
			

	
!"	 	[EOS]
Figure 2. A concept can be generated solely via residual infor-
mation: (a) Average cross-attention map for each word presents
that a concept‚Äôs information is embedded within other words. (b)A puppy can be generated solely using residual information by re-placing the text embedding of ‚Äòpuppy‚Äô with that of the Ô¨Ånal [EOS]
token. Additional examples are available in Appendix G.
tance sampling during LoRA training, mitigating the impact
on unintended concepts. Finally, we develop a loss functionfor MACE to harmoniously integrate multiple LoRA mod-ules without interfering with one another, while prevent-ing catastrophic forgetting. This integration loss can alsobe swiftly solved using a closed-form solution. We conductextensive evaluations on four distinct tasks, including objecterasure, celebrity erasure, explicit content erasure, and artis-tic style erasure. MACE demonstrates superior performanceon mass concept erasure and strikes an effective balancebetween speciÔ¨Åcity and generality, compared with state-of-the-art (SOTA) methods. This achievement paves the wayfor safer and more regulated T2I applications.
2. Related Work
Concept erasure. Existing research on preventing un-
wanted outputs from T2I models can be broadly groupedinto four categories: post-image Ô¨Åltering [ 41,50], infer-
ence guidance [ 3,59], retraining with the curated dataset
[40,52], and model Ô¨Ånetuning [ 16,17,19,25,30,39,71].
The Ô¨Årst two methods are post-hoc solutions and do not ad-dress the inherent propensity of the models to generate in-appropriate content [ 63]. Although retraining with curated
datasets may offer a solution, it demands signiÔ¨Åcant compu-tational effort and time (e.g., over 150,000 A100 GPU hoursfor retraining Stable Diffusion) [ 53]. Finetuning pretrained
T2I models is a more viable approach. However, most meth-ods either overlook the residual information of the targetphrase embedded within co-existing words, focusing solelyon the target phrase [ 16,17,71], or they Ô¨Ånetune uniformly
across timesteps [ 16,25,30,71]. ModiÔ¨Åcations to diffusion
models conditioned on timesteps before SSB [ 51] can nega-
tively affect the generation of retained concepts. In contrast,the proposed MACE addresses these challenges effectively.
Image cloaking. An alternative method for safeguarding
images against imitation or memorization [ 8,65] by T2I
6431
models involves an additional step of applying adversar-
ial perturbations to photographs or artworks before they areposted online. This technique, often referred to as cloaking,enables individuals to effectively conceal their images frommodels during the training phase but remain accessible anddiscernible to human viewers [ 58,62,75]. Nevertheless, it
is crucial to note that this strategy is applicable only to con-tent not yet posted online. To safeguard the vast amount ofcontent already on the web, concept erasure can serve as aviable strategy for large model providers as they prepare torelease more advanced models in subsequent evolutions.
3. Method
We aim to develop a framework to erase a large number of
concepts from pretrained T2I diffusion models. This frame-work takes two inputs: a pretrained model and a set of targetphrases that expresses the concepts to be removed. It returnsa Ô¨Ånetuned model that is incapable of generating images de-
picting the concepts targeted for erasing. An effective era-sure framework should fulÔ¨Åll the following criteria:
‚Ä¢EfÔ¨Åcacy (block target phrases): If the Ô¨Ånetuned model
is conditioned on prompts with those target phrases, itsoutputs should have limited semantic alignment with theprompts. Yet, the outputs should still appear natural, ei-ther aligning with a generic category (e.g., sky), or de-faulting to the super-category of the concept, if one exists.
‚Ä¢Generality (block synonyms): The model should also
prevent the generation of images semantically related toany synonyms of the targeted phrases, ensuring that theerasure is not limited to the exact wording of the prompts.
‚Ä¢SpeciÔ¨Åcity (preserve unrelated concepts): If the Ô¨Åne-
tuned model is conditioned on prompts that are semanti-cally unrelated to the erased concepts, its output distribu-tion should closely align with that of the original model.
To this end, we introduce MACE, a MAss Concept Era-
sure framework. The information of a phrase is embeddednot only within the phrase itself but also within the words
it co-exists with. To effectively erase the targeted concepts,
our framework Ô¨Årst removes the residual information fromthe co-existing words (Section 3.1). Subsequently, distinct
LoRA modules are trained to eliminate the intrinsic infor-mation speciÔ¨Åc to each target concept (Section 3.2). Lastly,
our framework integrates multiple LoRA modules without
mutual interference, leading to a Ô¨Ånal model that effectively
forgets a wide array of concepts (Section 3.3). Figure 3
presents an overview of our framework.
3.1. Closed-Form Cross-Attention ReÔ¨Ånement
In this section, we suggest a closed-form cross-attention re-Ô¨Ånement to encourage the model to refrain from embed-ding residual information of the target phrase into otherwords. Such residual information is adequate to evoke the


	

	
	

	
	

	


		  ! !    

 !
   
! 
!	






























































	
	
	
	
	
	
	
	
	
	
	
	


 
 	
Figure 3. Overview of MACE: (a) Our framework focuses on tun-
ing the prompts-related projection matrices, WkandWv, within
cross-attention (CA) blocks. (b) (Section 3.1& Figure 4) The pre-
trained U-Net‚Äôs CA blocks are reÔ¨Åned using a closed-form so-lution, discouraging the model from embedding the residual in-formation of the target phrase into surrounding words. (c) (Sec-tion 3.2 & Figure 5) For each concept targeted for removal, a
distinct LoRA module is learned to eliminate its intrinsic infor-mation. (d) (Section 3.3) A closed-form solution is introduced to
integrate multiple LoRA modules without interfering with one an-
other while averting catastrophic forgetting.
unwanted concept from T2I models. The root of this issue
lies in the attention mechanism [ 69], where the text embed-
ding of a token encapsulates information from other tokens.This results in its ‚ÄòKey‚Äô and ‚ÄòV alue‚Äô vectors absorbing andreÔ¨Çecting information from other tokens.
To tackle this, we focus on reÔ¨Åning the cross-attention
modules, which play a pivotal role in processing textprompts. For example, when altering the projection matrixW
k, we modify it such that the ‚ÄòKeys‚Äô of the words that co-
exist with the target phrase in the prompt are mapped to the‚ÄòKeys‚Äô of those same words in another prompt, where thetarget phrase is replaced with either its super-category ora generic concept. Notably, the ‚ÄòKeys‚Äô of the target phraseitself remain unchanged to avoid impacting on other unin-tended concepts associated with that phrase. Figure 4illus-
trates this process using the projection matrix W
k, and the
same principle is applicable to Wv.
Drawing upon methods that view matrices as linear as-
sociative memories [ 1,28], often used to edit knowledge
embedded within neural networks [ 2,4,5,17,36,37,43],
we formulate our objective function as follows:
min
W/prime
kn/summationdisplay
i=1/vextenddouble/vextenddouble/vextenddoubleW/prime
k¬∑ef
i‚àíWk¬∑eg
i/vextenddouble/vextenddouble/vextenddouble2
2
+Œª1n+m/summationdisplay
i=n+1/bardblW/prime
k¬∑ep
i‚àíWk¬∑ep
i/bardbl2
2,(1)
whereŒª1‚ààR+is a hyperparameter, ef
iis the embedding
of a word co-existing with the target phrase, eg
iis the em-
6432

	




	
	
		

 
	
		

	
		
	
		
		

	
	




Figure 4. Closed-Form Cross-Attention ReÔ¨Ånement: TheW/prime
k
is tuned such that the ‚ÄòKeys‚Äô of words co-existing with the target
phrase ‚Äòairplane‚Äô are mapped to the ‚ÄòKeys‚Äô of those same wordswhen the target phrase is replaced with a generic concept ‚Äòsky‚Äô.
bedding of that word when the target phrase is replaced with
its super-category or a generic one, ep
iis the embedding for
preserving the prior, Wkis the pretrained weights, and n,m
are the number of embeddings for mapping and preserving,respectively. As derived in Appendix B, this optimization
problem has a closed-form solution:
W
/prime
k=/parenleftBiggn/summationdisplay
i=1Wk¬∑eg
i¬∑(ef
i)T+Œª1n+m/summationdisplay
i=n+1Wk¬∑ep
i¬∑(ep
i)T/parenrightBigg
¬∑/parenleftBiggn/summationdisplay
i=1ef
i¬∑(ef
i)T+Œª1n+m/summationdisplay
i=n+1ep
i¬∑(ep
i)T/parenrightBigg‚àí1
, (2)
where/summationtextn+m
i=n+1Wkep
i(ep
i)Tand/summationtextn+m
i=n+1ep
i(ep
i)Tare pre-
cached constants for preserving prior. These constants are
capable of encapsulating both general and domain-speciÔ¨Åcknowledge, as detailed in Appendix B. The general knowl-
edge is estimated on the MS-COCO dataset [ 32] by default.
3.2. Target Concept Erasure with LoRA
After applying the closed-form reÔ¨Ånement to eliminate the
traces of the target concepts from co-existing words (Sec-tion 3.1), our focus shifts to erasing the intrinsic information
within the target phrase itself.
Loss function. Intuitively, if a concept is to appear in gener-
ated images, it should exert signiÔ¨Åcant inÔ¨Çuence on severalpatches of those images [ 10,46]. This implies that the atten-
tion maps corresponding to the tokens of the concept shoulddisplay high activation values in certain regions. We adaptthis principle in an inverse manner to eliminate the infor-mation within the target phrase itself. The loss function isdesigned to suppress the activation in certain regions of theattention maps that correspond to the target phrase tokens.These speciÔ¨Åc regions are identiÔ¨Åed by segmenting the in-put image with Grounded-SAM [ 27,33]. Figure 5depicts
the training process. The loss function is deÔ¨Åned as:
min/summationdisplay
i‚ààS/summationdisplay
l/vextenddouble/vextenddoubleAi
t,l‚äôM/vextenddouble/vextenddouble2
F, (3)
whereSis the set of indices corresponding to the tokens of
the target phrase, Ai
t,lis the attention map of token iat layerClosed-Form 
Refined U-Net
‚Äòphoto of airplane‚ÄôLoRA
Gradient
Grounded-SAM
:
Figure 5. Training with LoRA to Erase Intrinsic Information:
Eight images are generated for each target concept as a trainingset via SD v1.4. To obtain the attention maps, the images undergoforward diffusion to timestep tand then are fed into the closed-
form reÔ¨Åned model for predicting noise at timestep t. The LoRA
modules are trained to reduce the activation in the masked atten-
tion maps that correspond to the target phrase.
land timestep t,Mis the segmentation mask, and /bardbl¬∑/bardblFis
the Frobenius norm.
Parameter subset to Ô¨Ånetune. To minimize the loss func-
tion (Eq. ( 3)), we tune the closed-form reÔ¨Åned projection
matrices, W/prime
kandW/prime
v, by identifying a set of weight mod-
ulations,ŒîWkandŒîWv. Determining high-dimensional
modulation matrices in large-scale models is non-trivial.However, weight modulations usually have a low intrinsic
rank when they are adapted for speciÔ¨Åc downstream tasks[21]. Hence, we decompose the modulation matrices us-
ing LoRA [ 21]. SpeciÔ¨Åcally, for each target concept and
each projection matrix (e.g., W
/prime
k‚ààRdin√ódout), we learn
two matrices, B‚ààRdin√órandD‚ààRr√ódout, wherer/lessmuch
min(din,dout)is the decomposition rank. The new modu-
lated matrices are:
ÀÜWk=W/prime
k+ŒîWk=W/prime
k+B√óD. (4)
Concept-focal importance sampling (CFIS). If the atten-
tion loss (Eq. ( 3)) is computed based on attention maps that
are obtained at uniformly sampled timesteps, the predictedscore function at various noise levels will be affected. Con-sequently, it will inÔ¨Çuence the entire sampling trajectory,undermining the speciÔ¨Åcity of concept erasure. This issueis especially problematic when erasing phrases that containpolysemous words or common surnames and given names.The reason lies in the nature of the diffusion trajectory.The sample initially gravitates towards the data manifoldand possesses the potential to converge to various conceptmodes associated with the conditional phrase [ 11,51]. Af-
ter the turning point (a.k.a., SSB [ 51]), the speciÔ¨Åc mode
to be fully denoised is determined [ 51]. Our goal is to in-
Ô¨Çuence only the path leading to a particular mode, such as‚ÄòBill Clinton‚Äô, rather than affecting paths leading to every
celebrity named ‚ÄòClinton‚Äô or ‚ÄòBill‚Äô. Thus, it is crucial thatthe early sampling trajectory remains largely unaffected.
6433
To this end, we opt not to sample the timestep tfrom a
uniform distribution when training LoRA. Instead, we intro-duce a sampling distribution that assigns greater probabilityto smaller values of t. The probability density function for
sampling tis deÔ¨Åned as (A graph of this function is pro-
vided in Appendix E):
Œæ(t)=1
Z(œÉ(Œ≥(t‚àít1))‚àíœÉ(Œ≥(t‚àít2))), (5)
whereZis a normalizer, œÉ(x)is the sigmoid function
1/(1 +e‚àíx), witht1andt2as the bounds of a high prob-
ability sampling interval (t1<t 2), andŒ≥as a temperature
hyperparameter. We empirically set t1= 200,t2= 400 ,
andŒ≥=0.05throughout our experiments. In addition to
increasing the speciÔ¨Åcity, this design enhances the trainingby making it more focused and efÔ¨Åcient.
3.3. Fusion of Multi-LoRA Modules
In this section, we present a scheme to fuse multiple LoRA
modules. Each LoRA module acts as a conceptual suppres-
sor for the pretrained model, inducing a state of amnesiawherein the model loses their grasp on a speciÔ¨Åc concept.When working collaboratively, these modules should col-lectively enable the model to forget all the concepts targetedfor erasure. A na ¬®ƒ±ve solution for integrating LoRA modules
is to utilize a weighted sum [ 56]:
ÀÜW
k=W/prime
k+q/summationdisplay
i=1œâiŒîWk,i,s.t.q/summationdisplay
i=1œâi=1,(6)
where W/prime
kis the closed-form reÔ¨Åned weight, ŒîWk,iis the
LoRA module associated with the ith concept, œâiis the nor-
malized weighting factor, and qis the number of the target
concepts. This na ¬®ƒ±ve fusion method leads to interference
among the modules, thereby diminishing the erasure per-formance, as evidenced in the ablation study (Section 4.6).
To preserve the capability of LoRA modules, we intro-
duce a novel fusion technique illustrated in Figure 3(d). We
input the text embeddings of the target phrases into the re-
spective LoRA module. The resulting outputs serve as theground truth for optimizing the projection matrices. The ob-jective function is deÔ¨Åned by:
min
W‚àó
kq/summationdisplay
i=1p/summationdisplay
j=1/vextenddouble/vextenddouble/vextenddoubleW‚àó
k¬∑ef
j‚àí(W/prime
k+ŒîWk,i)¬∑ef
j/vextenddouble/vextenddouble/vextenddouble2
2
+Œª2p+m/summationdisplay
j=p+1/vextenddouble/vextenddoubleW‚àó
k¬∑ep
j‚àíWk¬∑ep
j/vextenddouble/vextenddouble2
2,(7)
where Wkis the original weight, W/prime
kis the closed-form
reÔ¨Åned weight, ef
iis the embedding of a word co-existing
with the target phrase, ep
jis the embedding for prior pre-
serving,Œª2‚ààR+is a hyperparameter, qis the number oferased concepts, and p,m are the number of embeddings for
mapping and preserving. Similar to Eq. ( 2), this optimiza-
tion problem has a closed-form solution as well.
Compared with sequential or parallel Ô¨Ånetuning of a pre-
trained model for erasing multiple concepts, employing sep-arate LoRA modules for each concept and then integratingthem offers better prevention against catastrophic forgettingand provides more Ô¨Çexibility.
4. Experiments
In this section, we conduct a comprehensive evaluation
of our proposed method, benchmarking it against SOTAbaselines across four tasks. The baselines comprise ESD-
u[16], ESD-x [ 16], FMN [ 71], SLD-M [ 59], UCE [ 17],
and AC [ 30]. The four tasks are: object erasure (Sec-
tion 4.2), celebrity erasure (Section 4.3), explicit content
erasure (Section 4.4), and artistic style erasure (Section 4.5).
Our evaluation not only measures efÔ¨Åcacy but also ex-
plores the generality and speciÔ¨Åcity of the erasure methods.The generality assessment is primarily conducted in the ob-ject erasure, since synonyms for a particular object tend tobe precise and universally acknowledged compared to thosefor celebrities and artists. Evaluating speciÔ¨Åcity is morestraightforward and is therefore applied across all tasks. Wealso focus on the effectiveness of these methods in handlingmulti-concept erasure, using the celebrity erasure as a keybenchmark. We then highlight the superior performance ofour proposed method in erasing explicit content and artisticstyles. Lastly, we conduct ablation studies (Section 4.6)t o
understand the impact of the key components.
4.1. Implementation Details
We Ô¨Ånetune all models on SD v1.4 and generate imageswith DDIM sampler [ 66] over 50 steps. We follow [ 30]t o
augment the input target concept using prompts generatedby the GPT-4 [ 42]. The prompt augmentation varies de-
pending on the target concept type (e.g., objects or styles).Each LoRA module is trained for 50 gradient update steps.We implement baselines as per the conÔ¨Ågurations recom-mended in their original settings. Further details are pro-vided in Appendix C.
4.2. Object Erasure
Evaluation setup. For each erasure method, we Ô¨Ånetune
ten models, with each model designed to erase one objectclass of the CIFAR-10 dataset [ 29]. To assess erasure efÔ¨Å-
cacy, we use each Ô¨Ånetuned model to generate 200 imagesof the intended erased object class, prompted by ‚Äòa photo of
the{erased class name }‚Äô. These images are classiÔ¨Åed us-
ing CLIP [ 47], and the criterion for successful erasure is
a low classiÔ¨Åcation accuracy. To assess speciÔ¨Åcity, we useeach Ô¨Ånetuned model to generate 200 images for each of thenine remaining, unmodiÔ¨Åed object classes with prompts ‚Äòa
6434
Table 1. Evaluation of Erasing the CIFAR-10 Classes: Results for the Ô¨Årst four individual classes, along with the average results across 10
classes, are presented. CLIP classiÔ¨Åcation accuracies are reported for each erased class in three sets: the erased class itself (Acc e, efÔ¨Åcacy),
the nine remaining unaffected classes (Acc s, speciÔ¨Åcity), and three synonyms of the erased class (Acc g, generality). The harmonic means
HoreÔ¨Çect the comprehensive erasure capability. All presented values are denoted in percentage (%). Results pertaining to the latter six
classes are available in Appendix D. The classiÔ¨Åcation accuracies of images generated by the original SD v1.4 are presented for reference.
MethodAirplane Erased Automobile Erased Bird Erased Cat Erased Average across 10 Classes
Acc e‚Üì Acc s‚Üë Acc g‚ÜìHo‚Üë Acc e‚Üì Acc s‚Üë Acc g‚ÜìHo‚Üë Acc e‚Üì Acc s‚Üë Acc g‚ÜìHo‚Üë Acc e‚Üì Acc s‚Üë Acc g‚ÜìHo‚Üë Acc e‚Üì Acc s‚Üë Acc g‚ÜìHo‚Üë
FMN [ 71] 96.76 98.32 94.15 6.13 95.08 96.86 79.45 11.44 99.46 98.13 96.75 1.38 94.89 97.97 95.71 6.83 96.96 96.73 82.56 6.13
AC [ 30] 96.24 98.55 93.35 6.11 94.41 98.47 73.92 13.19 99.55 98.53 94.57 1.24 98.94 98.63 99.10 1.45 98.34 98.56 83.38 3.63
UCE [ 17] 40.32 98.79 49.83 64.09 4.73 99.02 37.25 82.12 10.71 98.35 15.97 90.18 2.35 98.02 2.58 97.70 13.54 98.45 23.18 85.48
SLD-M [ 59] 91.37 98.86 89.26 13.69 84.89 98.86 66.15 28.34 80.72 98.39 85.00 23.31 88.56 98.43 92.17 13.31 84.14 98.54 67.35 26.32
ESD-x [ 16] 33.11 97.15 32.28 74.98 59.68 98.39 58.83 50.62 18.57 97.24 40.55 76.17 12.51 97.52 21.91 86.98 26.93 97.32 31.61 76.91
ESD-u [ 16] 7.38 85.48 5.92 90.57 30.29 91.02 32.12 74.88 13.17 86.17 20.65 83.98 11.77 91.45 13.50 88.68 18.27 86.76 16.26 83.69
Ours 9.06 95.39 10.03 92.03 6.97 95.18 14.22 91.15 9.88 97.45 15.48 90.39 2.22 98.85 3.91 97.56 8.49 97.35 10.53 92.61
SD v1.4 [ 54] 96.06 98.92 95.08 - 95.75 98.95 75.91 - 99.72 98.51 95.45 - 98.93 98.60 99.05 - 98.63 98.63 83.64 -
photo of the {unaltered class name }‚Äô. A high classiÔ¨Åcation
accuracy indicates excellent erasure speciÔ¨Åcity. For assess-ing generality, we prepare three synonyms for each object
class, listed in Table ??. Each Ô¨Ånetuned model is used to
generate 200 images for each synonym associated with theerased class, using the prompt ‚Äòa photo of the {synonym
of erased class name }‚Äô. In this case, good generality is re-
Ô¨Çected by lower classiÔ¨Åcation accuracies.
Importantly, to evaluate the overall erasure capability of
methods, we use the harmonic mean of efÔ¨Åcacy, speciÔ¨Åcity,and generality. It is calculated as follows:
H
o=3
(1‚àíAcc e)‚àí1+(Acc s)‚àí1+(1‚àíAcc g)‚àí1,(8)
whereHois the harmonic mean for object erasure, Acc eis
the accuracy for the erased object (efÔ¨Åcacy), Acc sfor the
remaining objects (speciÔ¨Åcity), and Acc gfor the synonyms
of the erased object (generality). A lower value of Acc eand
Acc g, and a higher Acc scontribute to a higher harmonic
mean, indicating a superior comprehensive erasure ability.
Discussions and analysis. Table 1presents the results of
erasing the Ô¨Årst four object classes of the CIFAR-10 dataset,as well as the average results across all 10 classes. The re-sults of the latter six classes can be found in Appendix D.
Our approach attains the highest harmonic mean acrossthe erasure of nine object classes, with the exception of
‚Äòcat‚Äô, where our performance nearly matches the top result.
This underscores the superior erasure capabilities of our ap-proach, striking an effective balance between speciÔ¨Åcity andgenerality. Additionally, it is noteworthy that while meth-ods like FMN [ 71] and AC [ 30] are proÔ¨Åcient in removing
speciÔ¨Åc features of a subject, they fall short in completely
eradicating the subject‚Äôs generation.
4.3. Celebrity Erasure
Evaluation setup. In this section, we evaluate the erasure
methods with respect to their ability to erase multiple con-cepts. We establish a dataset consisting of 200 celebri-ties whose portraits, generated by SD v1.4, are recogniz-able with remarkable accuracy (>99%) by the GIPHY
Celebrity Detector (GCD) [ 18]. The dataset is divided into
two groups: an erasure group with 100 celebrities whomusers aim to erase, and a retention group with 100 other
celebrities whom users intend to preserve. The complete listof these celebrities is provided in Appendix C.
We perform a series of four experiments where SD v1.4
is Ô¨Ånetuned to erase 1, 5, 10, and all 100 celebrities in theerasure group. The efÔ¨Åcacy of each erasure method is testedby generating images of the celebrities intended for erasure.Successful erasure is measured by a low top-1 GCD accu-racy in correctly identifying the erased celebrities. To test
the speciÔ¨Åcity of methods on the retained celebrities, we
generate and evaluate images of the celebrities in the reten-tion group in the same way. A high speciÔ¨Åcity is indicatedby a high top-1 GCD accuracy.
Similar to Eq. ( 8), we underscore the comprehensive
ability of the multi-concept erasure method by computingthe harmonic mean of efÔ¨Åcacy and speciÔ¨Åcity:
H
c=2
(1‚àíAcc e)‚àí1+(Acc s)‚àí1, (9)
whereHcis the harmonic mean for celebrity erasure, Acc e
is the accuracy for the erased celebrities (efÔ¨Åcacy), and Acc s
for the retained celebrities (speciÔ¨Åcity). Furthermore, we as-
sess the speciÔ¨Åcity of methods on regular content utiliz-ing the MS-COCO dataset [ 32]. We sample 30,000 cap-
tions from the validation set to generate images and evaluateFID [ 45] and CLIP score [ 47].
Discussions and analysis. Figure 7(c) illustrates a notable
enhancement in overall erasure performance achieved byour method, particularly when 100 concepts are erased. Thisimprovement indicates a more effective balance between ef-Ô¨Åcacy and speciÔ¨Åcity. FMN [ 71], AC [ 30], and SLD-M [ 59]
demonstrate limited effectiveness in erasing multiple con-cepts, which inadvertently results in their high speciÔ¨Åcity.UCE [ 17] proves more effective, but its speciÔ¨Åcity decreases
rapidly when more than 10 concepts are erased. Further-more, it fails to maintain FID and CLIP score within a rea-sonable range when erasing more than 10 celebrities whilepreserving only 100. As to ESD-u [ 16] and ESD-x [ 16],
while effective, result in a lower proportion of facial imagesin their outputs (i.e., limited conceptual integrity), as shown
in Figure 7(f). This suggests that when their reÔ¨Åned mod-
els are conditioned on erased celebrities, their outputs de-
6435
SD v1.4 UCE SLD-M ESD-x ESD-u Ours
Specificity: ‚ÄòA sketch of Bill Murray‚ÄôEfficacy: ‚ÄòBill Clinton in an official photo‚Äô
Specificity: ‚ÄòA portrait of Amanda Seyfried ‚Äô
Figure 6. Qualitative Comparison of Erasing 100 Celebrities from SD v1.4: Bill Clinton belongs to the erasure group for assessing
efÔ¨Åcacy, while Bill Murray and Amanda Seyfried are in the retention group to evaluate speciÔ¨Åcity. Preserving Bill Murray‚Äôs images ischallenging, as his Ô¨Årst name is the same as Bill Clinton‚Äôs, who is in the erasure group. Additional examples are in Appendix G.
(a) Efficacy (b) Specificity (c) Overall
(d) Image Quality (e) Semantic Alignment (f) Conceptual Integrity
Figure 7. Evaluation of Erasing Multiple Celebrity: The evalu-
ation metrics include the detection accuracy on images of erasedcelebrities (Acc
e‚Üì) and those of retained celebrities (Acc s‚Üë),
the harmonic mean ( Hc‚Üë) which indicates overall erasure per-
formance, FID, CLIP score, and the ratio of facial images.
viate from human likenesses, often leading to unpredictable
and uncontrollable outcomes. This phenomenon is shown inFigure 6, which presents a qualitative comparison of eras-
ing 100 celebrities. In this comparison, Bill Clinton is in theerasure group, whereas Bill Murray and Amanda Seyfriedare in the retention group. Notably, the preservation of BillMurray‚Äôs image poses a challenge due to his shared Ô¨Årstname, ‚ÄòBill,‚Äô with Bill Clinton in the erasure group. Ourmethod effectively overcomes this issue.4.4. Explicit Content Erasure
Evaluation setup. In this section, we attempt to mitigate the
generation of explicit content in T2I models. We adopt thesame setting used in SA [ 19], Ô¨Ånetuning SD v1.4 to erase
four target phrases: ‚Äònudity‚Äô, ‚Äònaked‚Äô, ‚Äòerotic‚Äô, and ‚Äòsexual‚Äô.To evaluate efÔ¨Åcacy and generality, we use each Ô¨Ånetunedmodel to generate images using all 4,703 prompts sourcedfrom the Inappropriate Image Prompt (I2P) dataset [ 59].
The NudeNet [ 6] is employed to identify explicit content
in these images, using a detection threshold of 0.6. Addi-tionally, to assess speciÔ¨Åcity on regular content, we evalu-ate FID and CLIP score on the MS-COCO validation set,similar to the process described in Section 4.3.
Discussions and analysis. Table 2presents our Ô¨Åndings.
Our reÔ¨Åned model successfully generates the least amountof explicit content when conditioned on 4,703 prompts.Moreover, it showcases an impressive performance in FID,even surpassing the original SD v1.4. We note that suchÔ¨Ånetuning often does not have a consistent trend in improv-ing or worsening FID and CLIP score on regular contentgeneration. This pattern is also observed in the celebrityerasure, as shown in Figure 7(d) and (e). Therefore, we
consider the performance acceptable as long as FID andCLIP score remain within a reasonable range. It is also note-worthy that retraining SD v2.1 from scratch using a dataset
curated to exclude explicit content yields only a minor im-
provement, compared with the original SD v1.4. Qualitativecomparisons are provided in Appendix Gfor reference.
4.5. Artistic Style Erasure
In this section, we evaluate our method and the baselines on
erasing multiple artistic styles from SD v1.4. We utilize the
6436
Table 2. Assessment of Explicit Content Removal: (Left) Quantity of explicit content detected using the NudeNet detector on the I2P
benchmark. (Right) Comparison of FID and CLIP on MS-COCO. The performance of the original SD v1.4 is presented for reference.SD v2.1 serves as a baseline that retrains the model from scratch on the curated dataset.
‚Ä†: Results sourced from [ 19]. F: Female. M: Male.
MethodResults of NudeNet Detection on I2P (Detected Quantity) MS-COCO 30K
Armpits Belly Buttocks Feet Breasts (F) Genitalia (F) Breasts (M) Genitalia (M) Total ‚Üì FID‚Üì CLIP‚Üë
FMN [ 71] 43 117 12 59 155 17 19 2 424 13.52 30.39
AC [ 30] 153 180 45 66 298 22 67 7 838 14.13 31.37
UCE [ 17] 29 62 7 29 35 5 11 4 182 14.07 30.85
SLD-M [ 59]4 7 7 2 3 21 39 1 26 3 212 16.34 30.90
ESD-x [ 16] 59 73 12 39 100 6 18 8 315 14.41 30.69
ESD-u [ 16] 32 30 2 19 27 3 8 2 123 15.10 30.21
SA‚Ä†[19]7 2 7 7 1 9 2 5 8 3 1 6 00 292 - -
Ours 17 19 2 39 16 29 7 111 13.42 29.41
SD v1.4 [ 54] 148 170 29 63 266 18 42 7 743 14.04 31.34
SD v2.1 [ 52] 105 159 17 60 177 9 57 2 586 14.87 31.53
Table 3. Assessment of Erasing 100 Artistic Styles: Haindicates
overall erasure performance.
Method CLIP e‚Üì CLIP s‚ÜëHa‚Üë FID-30K ‚Üì CLIP-30K ‚Üë
FMN [ 71] 29.63 28.90 -0.73 13.99 31.31
AC [ 30] 29.26 28.54 -0.72 14.08 31.29
UCE [ 17] 21.31 25.70 4.39 77.72 19.17
SLD-M [ 59] 28.49 27.89 -0.6 17.95 30.87
ESD-x [ 16] 20.89 21.21 0.32 15.19 29.52
ESD-u [ 16] 19.66 19.55 -0.11 17.07 27.76
Ours 22.59 28.58 5.99 12.71 29.51
SD v1.4 29.63 28.90 - 14.04 31.34
Image Synthesis Style Studies Database [ 23], which com-
piles a list of artists whose styles can be replicated by SDv1.4. From this database, we sample 200 artists and split
them into two groups: an erasure group of 100 artists anda retention group with 100 other artists. To assess efÔ¨Åcacyand speciÔ¨Åcity, we apply prompts like ‚ÄòImage in the style of
{artist name }‚Äôto both the erased and retained artists. We
evaluate the erasure methods using two metrics: CLIP
eand
CLIP s. The CLIP e, which tests efÔ¨Åcacy, is calculated be-
tween the prompts of the erased artists and the generatedimages. A lower CLIP
eindicates better efÔ¨Åcacy. Similarly,
the CLIP s, which assesses speciÔ¨Åcity, is calculated between
the prompts of the retained artists and the generated images.
A higher CLIP ssigniÔ¨Åes better speciÔ¨Åcity. We calculate the
overall erasing capability by Ha=CLIP s‚àíCLIP e. As re-
ported in Table 3, our method also shows the superior ability
to erase artistic styles on a large scale.
4.6. Ablation Study
To study the impact of our key components, we conduct ab-lation studies on the challenging task of erasing 100 celebri-ties from SD v1.4. Different variations and their results arepresented in Table 4. V ariation 1 struggles to balance ef-
Ô¨Åcacy and speciÔ¨Åcity. When prioritizing prior preservation,its ability to erase is compromised. V ariation 2, which trainsLoRA without CFIS, restricts its speciÔ¨Åcity. Moreover, thena¬®ƒ±ve integration of LoRA exacerbates this issue, leading to
poor speciÔ¨Åcity despite the successful erasure of the targetconcepts. V ariation 3 fuses LoRA with closed-form fusion,Table 4. Ablation Study on Erasing 100 Celebrities. CFR:
closed-form reÔ¨Ånement. NLF: na ¬®ƒ±ve LoRA fusion. CFLF: closed-
form LoRA fusion. CFIS: concept-focal importance sampling. Allpresented values are denoted in percentage (%).
ConÔ¨ÅgComponents Metrics
CFR LoRA NLF CFLF CFIS Acc e‚Üì Acc s‚ÜëHc‚Üë
1 /check√ó√ó√ó√ó 67.79 85.05 46.72
2 /check/check/check √ó√ó 0.08 32.16 48.66
3 /check/check √ó /check√ó 18.70 61.78 70.21
Ours /check/check √ó /check/check 4.31 84.56 89.78
which prevents interference from different LoRA modules,
thereby improving speciÔ¨Åcity. However, without the CFIS,this conÔ¨Åguration shows reduced training efÔ¨Åciency in era-
sure and decreased speciÔ¨Åcity. Additional ablation studiesand applications are provided in Appendix F.
5. Limitations and Conclusion
Our proposed method, MACE, offers an effective solution
for erasing mass concepts from T2I diffusion models. Ourextensive experiments reveal that MACE achieves a remark-able balance between speciÔ¨Åcity and generality, particularlyin erasing numerous concepts, surpassing the performanceof prior methods. However, a discernible decline in the har-monic mean is observed as the number of erased conceptsincreases from 10 to 100. This trend could pose a limita-tion in erasing thousands of concepts from more advancedmodels in the future. Exploring ways to further scale upthe erasure scope presents a crucial direction for future re-search. We believe MACE can be a pivotal tool for gen-erative model service providers, empowering them to efÔ¨Å-ciently eliminate a variety of unwanted concepts. This is avital step in releasing the next wave of advanced models,contributing to the creation of a safer AI community.
Acknowledgement. This research is supported by National
Research Foundation, Singapore under its Strategic Capa-bility Research Centres Funding Initiative. Any opinions,Ô¨Åndings and conclusions or recommendations expressed inthis material are those of the author(s) and do not reÔ¨Çect theviews of National Research Foundation, Singapore.
6437
References
[1] James A Anderson. A simple neural network generating
an interactive memory. Mathematical biosciences , 14(3-4):
197‚Äì220, 1972. 3
[2] Dana Arad, Hadas Orgad, and Y onatan Belinkov. Refact:
Updating text-to-image models by editing the text encoder.
arXiv preprint arXiv:2306.00738 , 2023. 3
[3] AUTOMA TIC1111. Negative prompt. https :
/ / github . com / AUTOMATIC1111 / stable -diffusion - webui / wiki / Negative - prompt .
1,2
[4] Samyadeep Basu, Nanxuan Zhao, Vlad Morariu, Soheil
Feizi, and V arun Manjunatha. Localizing and editing knowl-edge in text-to-image generative models. arXiv preprint
arXiv:2310.13730 , 2023. 3
[5] David Bau, Steven Liu, Tongzhou Wang, Jun-Yan Zhu, and
Antonio Torralba. Rewriting a deep generative model. InComputer Vision‚ÄìECCV 2020: 16th European Conference,Glasgow, UK, August 23‚Äì28, 2020, Proceedings, Part I 16 ,
pages 351‚Äì369. Springer, 2020. 3
[6] P Bedapudi. Nudenet: Neural nets for nudity classiÔ¨Åcation,
detection and selective censoring, 2019. 7
[7] Nicholas Carlini, Matthew Jagielski, Chiyuan Zhang, Nico-
las Papernot, Andreas Terzis, and Florian Tramer. The pri-vacy onion effect: Memorization is relative. Advances in
Neural Information Processing Systems , 35:13263‚Äì13276,
2022. 1
[8] Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagiel-
ski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ip-polito, and Eric Wallace. Extracting training data from diffu-sion models. In 32nd USENIX Security Symposium (USENIX
Security 23) , pages 5253‚Äì5270, 2023. 2
[9] Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot,
Jose Lezama, Lu Jiang, Ming-Hsuan Yang, Kevin Mur-phy, William T Freeman, Michael Rubinstein, et al. Muse:Text-to-image generation via masked generative transform-ers. arXiv preprint arXiv:2301.00704 , 2023. 1
[10] Hila Chefer, Y uval Alaluf, Yael Vinker, Lior Wolf, and
Daniel Cohen-Or. Attend-and-excite: Attention-based se-mantic guidance for text-to-image diffusion models. ACM
Transactions on Graphics (TOG) , 42(4):1‚Äì10, 2023. 4
[11] Defang Chen, Zhenyu Zhou, Jian-Ping Mei, Chunhua Shen,
Chun Chen, and Can Wang. A geometric perspective on dif-fusion models. arXiv preprint arXiv:2305.19947 , 2023. 4
[12] Jooyoung Choi, Jungbeom Lee, Chaehun Shin, Sungwon
Kim, Hyunwoo Kim, and Sungroh Y oon. Perception pri-oritized training of diffusion models. In Proceedings of
the IEEE/CVF Conference on Computer Vision and PatternRecognition , pages 11472‚Äì11481, 2022. 2
[13] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. Advances in Neural Informa-
tion Processing Systems , 34:8780‚Äì8794, 2021.
[14] Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang.
Cogview2: Faster and better text-to-image generation via hi-erarchical transformers. Advances in Neural Information
Processing Systems , 35:16890‚Äì16902, 2022. 1[15] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming
transformers for high-resolution image synthesis. In Pro-
ceedings of the IEEE/CVF conference on computer visionand pattern recognition , pages 12873‚Äì12883, 2021.
[16] Rohit Gandikota, Joanna Materzynska, Jaden Fiotto-
Kaufman, and David Bau. Erasing concepts from diffusionmodels. arXiv preprint arXiv:2303.07345 , 2023. 2,5,6,8
[17] Rohit Gandikota, Hadas Orgad, Y onatan Belinkov, Joanna
Materzy ¬¥nska, and David Bau. UniÔ¨Åed concept editing in dif-
fusion models. arXiv preprint arXiv:2308.14761 , 2023.
2,3,
5,6,8
[18] Nick Hasty, Ihor Kroosh, Dmitry V oitekh, and Dmytro Ko-
rduban. Giphy celebrity detector. https://github.
com/Giphy/celeb-detection-oss .6
[19] Alvin Heng and Harold Soh. Selective amnesia: A continual
learning approach to forgetting in deep generative models.arXiv preprint arXiv:2305.10120 , 2023. 2,7,8
[20] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffu-
sion probabilistic models. Advances in Neural Information
Processing Systems , 33:6840‚Äì6851, 2020.
[21] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-
Zhu, Y uanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.Lora: Low-rank adaptation of large language models. arXiv
preprint arXiv:2106.09685 , 2021. 2,4
[22] Tatum Hunter. Ai porn is easy to make now. for women,
that‚Äôs a nightmare. 2023. 1
[23] Surea I, Proxima Centauri B, Erratica, and Stephen
Y oung. Image synthesis style studies. https://
www . aiartapps . com / ai - art - apps / image -synthesis-style-studies .1,8
[24] Harry H Jiang, Lauren Brown, Jessica Cheng, Mehtab Khan,
Abhishek Gupta, Deja Workman, Alex Hanna, JohnathanFlowers, and Timnit Gebru. Ai art and its impact on artists.InProceedings of the 2023 AAAI/ACM Conference on AI,
Ethics, and Society , pages 363‚Äì374, 2023. 1
[25] Sanghyun Kim, Seohyeon Jung, Balhae Kim, Moonseok
Choi, Jinwoo Shin, and Juho Lee. Towards safe self-distillation of internet-scale text-to-image diffusion models.arXiv preprint arXiv:2307.05977 , 2023. 2
[26] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan
Ho. V ariational diffusion models. Advances in neural infor-
mation processing systems , 34:21696‚Äì21707, 2021.
[27] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,
Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-head, Alexander C. Berg, Wan-Yen Lo, Piotr Doll ¬¥ar, and
Ross Girshick. Segment anything. arXiv:2304.02643 , 2023.
4
[28] Teuvo Kohonen. Associative memory: A system-theoretical
approach . Springer Science & Business Media, 2012. 3
[29] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple
layers of features from tiny images. 2009. 5
[30] Nupur Kumari, Bingliang Zhang, Sheng-Y u Wang, Eli
Shechtman, Richard Zhang, and Jun-Yan Zhu. Ablating con-cepts in text-to-image diffusion models. In Proceedings of
the IEEE/CVF International Conference on Computer Vi-sion , pages 22691‚Äì22702, 2023. 2,5,6,8
6438
[31] Mingi Kwon, Jaeseok Jeong, and Y oungjung Uh. Diffusion
models already have a semantic latent space. arXiv preprint
arXiv:2210.10960 , 2022. 2
[32] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
Pietro Perona, Deva Ramanan, Piotr Doll ¬¥ar, and C Lawrence
Zitnick. Microsoft coco: Common objects in context. InComputer Vision‚ÄìECCV 2014: 13th European Conference,Zurich, Switzerland, September 6-12, 2014, Proceedings,
P a r tV1 3 , pages 740‚Äì755. Springer, 2014. 4,6
[33] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao
Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, JunZhu, et al. Grounding dino: Marrying dino with groundedpre-training for open-set object detection. arXiv preprint
arXiv:2303.05499 , 2023. 4
[34] Shilin Lu, Yanzhu Liu, and Adams Wai-Kin Kong. Tf-icon:
Diffusion-based training-free cross-domain image composi-tion. In Proceedings of the IEEE/CVF International Confer-
ence on Computer Vision , pages 2294‚Äì2305, 2023. 1
[35] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang
Zhao. Latent consistency models: Synthesizing high-resolution images with few-step inference. arXiv preprint
arXiv:2310.04378 , 2023.
[36] Kevin Meng, David Bau, Alex Andonian, and Y onatan Be-
linkov. Locating and editing factual associations in gpt.Advances in Neural Information Processing Systems , 35:
17359‚Äì17372, 2022. 3
[37] Kevin Meng, Arnab Sen Sharma, Alex Andonian, Y onatan
Belinkov, and David Bau. Mass-editing memory in a trans-
former. arXiv preprint arXiv:2210.07229 , 2022. 3
[38] Yisroel Mirsky and Wenke Lee. The creation and detection
of deepfakes: A survey. ACM Computing Surveys (CSUR) ,
54(1):1‚Äì41, 2021. 1
[39] Zixuan Ni, Longhui Wei, Jiacheng Li, Siliang Tang, Y ueting
Zhuang, and Qi Tian. Degeneration-tuning: Using scram-bled grid shield unwanted concepts from stable diffusion. InProceedings of the 31st ACM International Conference onMultimedia , pages 8900‚Äì8909, 2023. 2
[40] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav
Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, andMark Chen. Glide: Towards photorealistic image generationand editing with text-guided diffusion models. arXiv preprint
arXiv:2112.10741 , 2021. 1,2
[41] OpenAI. Dall¬∑e 3 system card. 2023. 1,2
[42] OpenAI. Gpt-4 technical report. 2023. 5
[43] Hadas Orgad, Bahjat Kawar, and Y onatan Belinkov. Edit-
ing implicit assumptions in text-to-image diffusion models.arXiv preprint arXiv:2303.08084 , 2023. 3
[44] Ryan O‚ÄôConnor. Stable diffusion 1 v s 2 - what you need to
know. 2022. 1
[45] Gaurav Parmar, Richard Zhang, and Jun-Yan Zhu. On
aliased resizing and surprising subtleties in gan evaluation.InProceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , pages 11410‚Äì11420, 2022.
6
[46] Quynh Phung, Songwei Ge, and Jia-Bin Huang. Grounded
text-to-image synthesis with attention refocusing. arXiv
preprint arXiv:2306.05427 , 2023. 4[47] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learningtransferable visual models from natural language supervi-sion. In International conference on machine learning , pages
8748‚Äì8763. PMLR, 2021. 5,6
[48] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee,
Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, andPeter J Liu. Exploring the limits of transfer learning witha uniÔ¨Åed text-to-text transformer. The Journal of Machine
Learning Research
, 21(1):5485‚Äì5551, 2020.
[49] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,
and Mark Chen. Hierarchical text-conditional image gener-ation with clip latents. arXiv preprint arXiv:2204.06125 ,1
(2):3, 2022. 1
[50] Javier Rando, Daniel Paleka, David Lindner, Lennart Heim,
and Florian Tram `er. Red-teaming the stable diffusion safety
Ô¨Ålter. arXiv preprint arXiv:2210.04610 , 2022. 1,2
[51] Gabriel Raya and Luca Ambrogioni. Spontaneous symme-
try breaking in generative diffusion models. arXiv preprint
arXiv:2305.19693 , 2023. 2,4
[52] Robin Rombach. Stable diffusion 2.0 release. 2022. 1,2,8
[53] Robin Rombach. Stable diffusion v1-4 model card. 2022. 2
[54] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj ¬®orn Ommer. High-resolution image
synthesis with latent diffusion models. In Proceedings of
the IEEE/CVF conference on computer vision and patternrecognition , pages 10684‚Äì10695, 2022. 1,6,8
[55] Kevin Roose. An ai-generated picture won an art prize.
artists aren‚Äôt happy. 2022. 1
[56] Simo Ryu. Low-rank adaptation for fast text-to-image
715 diffusion Ô¨Åne-tuning. https://github.com/
cloneofsimo/lora .5
[57] Chitwan Saharia, William Chan, Saurabh Saxena, Lala
Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour,Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans,et al. Photorealistic text-to-image diffusion models with deeplanguage understanding. Advances in Neural Information
Processing Systems , 35:36479‚Äì36494, 2022. 1
[58] Hadi Salman, Alaa Khaddaj, Guillaume Leclerc, Andrew
Ilyas, and Aleksander Madry. Raising the cost of maliciousai-powered image editing. arXiv preprint arXiv:2302.06588 ,
2023. 3
[59] Patrick Schramowski, Manuel Brack, Bj ¬®orn Deiseroth, and
Kristian Kersting. Safe latent diffusion: Mitigating inappro-priate degeneration in diffusion models. In Proceedings of
the IEEE/CVF Conference on Computer Vision and PatternRecognition , pages 22522‚Äì22531, 2023. 1,2,5,6,7,8
[60] Christoph Schuhmann, Romain Beaumont, Richard V encu,
Cade Gordon, Ross Wightman, Mehdi Cherti, TheoCoombes, Aarush Katta, Clayton Mullis, Mitchell Worts-man, et al. Laion-5b: An open large-scale dataset for trainingnext generation image-text models. Advances in Neural In-
formation Processing Systems , 35:25278‚Äì25294, 2022. 1
[61] Riddhi Setty. Ai art generators hit with copyright suit over
artists‚Äô images, 2023. 1
6439
[62] Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng,
Rana Hanocka, and Ben Y Zhao. Glaze: Protecting artists
from style mimicry by text-to-image models. arXiv preprint
arXiv:2302.04222 , 2023. 3
[63] SmithMano. Tutorial: How to remove the safety Ô¨Ålter in 5
seconds, 2022. 2
[64] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,
and Surya Ganguli. Deep unsupervised learning usingnonequilibrium thermodynamics. In International Confer-
ence on Machine Learning , pages 2256‚Äì2265. PMLR, 2015.
[65] Gowthami Somepalli, V asu Singla, Micah Goldblum, Jonas
Geiping, and Tom Goldstein. Diffusion art or digital forgery?
investigating data replication in diffusion models. In Pro-
ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition , pages 6048‚Äì6058, 2023. 2
[66] Jiaming Song, Chenlin Meng, and Stefano Ermon. De-
noising diffusion implicit models. arXiv preprint
arXiv:2010.02502 , 2020. 5
[67] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-basedgenerative modeling through stochastic differential equa-tions. arXiv preprint arXiv:2011.13456 , 2020.
[68] Aaron V an Den Oord, Oriol Vinyals, et al. Neural discrete
representation learning. Advances in neural information pro-
cessing systems , 30, 2017.
[69] Ashish V aswani, Noam Shazeer, Niki Parmar, Jakob Uszko-
reit, Llion Jones, Aidan N Gomez, ≈Åukasz Kaiser, and Illia
Polosukhin. Attention is all you need. Advances in neural
information processing systems , 30, 2017. 2,3
[70] Luisa V erdoliva. Media forensics and deepfakes: an
overview. IEEE Journal of Selected Topics in Signal Pro-
cessing , 14(5):910‚Äì932, 2020. 1
[71] Eric Zhang, Kai Wang, Xingqian Xu, Zhangyang Wang, and
Humphrey Shi. Forget-me-not: Learning to forget in text-to-image diffusion models. arXiv preprint arXiv:2303.17591 ,
2023. 2,5,6,8
[72] Yimeng Zhang, Jinghan Jia, Xin Chen, Aochuan Chen, Yi-
hua Zhang, Jiancheng Liu, Ke Ding, and Sijia Liu. To gener-ate or not? safety-driven unlearned diffusion models are stilleasy to generate unsafe images... for now. arXiv preprint
arXiv:2310.11868 , 2023. 1
[73] Chen Zhao, Weiling Cai, Chenyu Dong, and Chengwei
Hu. Wavelet-based fourier information interaction with fre-quency diffusion adjustment for underwater image restora-tion. arXiv preprint arXiv:2311.16845 , 2023. 1
[74] Chen Zhao, Chenyu Dong, and Weiling Cai. Learn-
ing a physical-aware diffusion model based on trans-
former for underwater image enhancement. arXiv preprint
arXiv:2403.01497 , 2024. 1
[75] Zhengyue Zhao, Jinhao Duan, Xing Hu, Kaidi Xu, Chenan
Wang, Rui Zhang, Zidong Du, Qi Guo, and Y unji Chen. Un-learnable examples for diffusion models: Protect data fromunauthorized exploitation. arXiv preprint arXiv:2306.01902 ,
2023. 3
[76] Dewei Zhou, Zongxin Yang, and Yi Yang. Pyramid diffusion
models for low-light image enhancement. arXiv preprint
arXiv:2305.10028 , 2023. 1[77] Dewei Zhou, Y ou Li, Fan Ma, Zongxin Yang, and Yi Yang.
Migc: Multi-instance generation controller for text-to-imagesynthesis. arXiv preprint arXiv:2402.05408 , 2024. 1
6440
