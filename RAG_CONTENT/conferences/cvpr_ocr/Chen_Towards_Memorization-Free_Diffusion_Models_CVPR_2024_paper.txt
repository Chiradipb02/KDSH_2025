Towards Memorization-Free Diffusion Models
Chen Chen Daochang Liu Chang Xu
School of Computer Science, Faculty of Engineering, The University of Sydney
{cche0711@uni., daochang.liu@, c.xu@ }sydney.edu.au
Abstract
Pretrained diffusion models and their outputs are widely
accessible due to their exceptional capacity for synthe-
sizing high-quality images and their open-source nature.
The users, however, may face litigation risks owing to
the models’ tendency to memorize and regurgitate train-
ing data during inference. To address this, we introduce
Anti-Memorization Guidance (AMG), a novel framework
employing three targeted guidance strategies for the main
causes of memorization: image and caption duplication,
and highly specific user prompts. Consequently, AMG en-
sures memorization-free outputs while maintaining high im-
age quality and text alignment, leveraging the synergy of
its guidance methods, each indispensable in its own right.
AMG also features an innovative automatic detection sys-
tem for potential memorization during each step of in-
ference process, allows selective application of guidance
strategies, minimally interfering with the original sampling
process to preserve output utility. We applied AMG to pre-
trained Denoising Diffusion Probabilistic Models (DDPM)
and Stable Diffusion across various generation tasks. The
results demonstrate that AMG is the first approach to suc-
cessfully eradicates all instances of memorization with no
or marginal impacts on image quality and text-alignment,
as evidenced by FID and CLIP scores.
1. Introduction
Diffusion models [12, 23, 34] have attracted substantial in-
terest, given their superiority in terms of diversity, fidelity,
scalability [28] and controllability [24] over previous gener-
ative models including V AEs [17], normalizing flows [29],
and GANs [10, 14–16]. With guidance techniques [7, 11],
diffusion models can be further improved by the strategical
diversity-fidelity trade-off. State-of-the-art diffusion mod-
els trained on vast web-scale datasets are widespreadly used
and have seen deployment at a commercial scale [1, 30, 31].
Such widespread adoption, however, has significantly
heightened the litigation risks for companies using these
models, particularly due to allegations that the models
memorize and reproduce training data during inference
without informing the data owners and the users of diffusion
Figure 1. Stable Diffusion’s capacity to memorize training data,
manifested as pixel-level memorization (left) and object-level
memorization (right). Our approach successfully guides pre-
trained diffusion models to produce memorization-free outputs.
models. This potentially violates copyright laws and intro-
duces ethical dilemmas, further complicated by the fact that
the extensive size of training sets impedes detailed human
review, leaving the intellectual property rights of the data
sources largely undetermined. An ongoing example is that a
legal action contends that Stable Diffusion is a 21st-century
collage tool that remixes the copyrighted works of millions
of artists whose work was used as training data [32].
Prior studies [4, 35, 36] have observed memorization in
pretrained diffusion models, particularly during uncondi-
tional CIFAR-10 [18] and text-conditional LAION dataset
[33] generations. While previous research proposed strate-
gies to reduce memorization, these often lead to only mod-
est improvements and fail to fully eliminate the issue. The
effectiveness often come with reduced output quality and
text-alignment [36], the need for retraining models [4], and
extensive manual intervention [19]. Moreover, these strate-
gies lack an automated way to differentiate potential mem-
orization cases for targeted mitigation. For example, [19]
relies on a predefined list of text prompts prone to causing
memorization, and [36] applies randomization mechanisms
uniformly without distinguishing between scenarios.
In this paper, we undertake the following systematic ef-
forts to address the issue of memorization. Firstly , we have
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
8425
identified and detailed the primary causes of memorization,
pinpointing image and text duplication in training datasets,
along with the high specificity of user prompts for text
conditioning, as key contributors. Secondly , we propose
a novel unified framework, Anti-Memorization Guidance
(AMG), which comprises three distinct guidance strategies,
namely, desspecification guidance (Gspe),caption dedupli-
cation guidance (Gdup), and dissimilarity guidance (Gsim),
with each meticulously crafted to address one of these iden-
tified causes. Each strategy within AMG effectively guides
generations away from memorized training images, offer-
ing unique benefits. GspeandGdupexcel in maximally
preserving the quality of generated images, while Gsim
provides a definitive assurance against memorization. The
absence of any one of these strategies would compromise
the delicate balance between privacy and utility, underscor-
ing the indispensability of each of the three methods in the
framework. To further enhance the privacy-utility trade-off,
AMG features an automatic detection mechanism that con-
tinuously assesses the similarity between the current predic-
tion and its nearest training data during the inference pro-
cess to identify potential instances of memorization. This
allows AMG to apply guidance selectively rather than uni-
formly, ensuring that the original sampling process of the
pretrained diffusion model is maximally preserved.
We conducted experiments with AMG on pretrained De-
noising Diffusion Probabilistic Models (DDPM) and Sta-
ble Diffusion, spanning various generation tasks such as
unconditional, class-conditional, and text-conditional gen-
erations. The outcomes, both qualitative and quantitative,
demonstrate that AMG is the first method that effectively
eradicates all memorization instances with minimal impact
on image quality and text-alignment. In summary, our con-
tributions through AMG are multifaceted and significant:
1) AMG introduces three guidance strategies, each metic-
ulously designed to address one of the primary causes of
memorization, providing a comprehensive solution that ef-
fectively balances privacy and utility. 2) AMG is equipped
with an automatic detection system for potential memoriza-
tion during each step of the inference process. This allows
for the selective application of guidance strategies, maxi-
mizing the preservation of output utility. 3) Expanding upon
previous research that focused only on unconditional and
text-conditional generations, our study is the first to iden-
tify and address memorization in class-conditional diffusion
model generations, and is the first that successfully achieves
memorization-free generations with minimal compromise
on image quality and text-alignment.
2. Related Work
Memorization in Diffusion Models has received increased
scrutiny over the past year. [35] found that pretrained Sta-
ble Diffusions and unconditional DDPMs trained on small
datasets like CelebA [22] and Oxford Flowers [25] oftenreplicate training data. [4] reported memorization in pre-
trained DDPMs on CIFAR-10.Our work focus on pretrained
diffusion models, which are extensively used and directly
expose their users to litigation risks. We also pioneer in
studying class-conditional model memorization, proposing
a unified framework that successfully eradicates memoriza-
tion in various generation tasks including unconditional,
class-conditional, and text-conditional generations.
Mitigation Strategies .Training data deduplication , ini-
tially effective in language models [13, 20], was adapted
for diffusion models [4], who removed 5,275 similar images
from CIFAR-10 and retrained the model, achieving a reduc-
tion in memorization. Yet, it offers limited improvement
and requires retraining the entire model, which is computa-
tionally intensive, especially for advanced diffusion models
with large datasets. Concept ablation [19], implemented for
Stable Diffusion, involved fine-tuning the pre-trained model
on two sets of text-image pairs (one prone to memorization
and the other not), curated using ChatGPT-generated para-
phrases, to minimize their output disparity. While effective,
this method demands extensive manual effort and relies
heavily on the crafted prompts’ quality. Also, it assumes
the availability of a predefined list of memorization-prone
prompts, which is unrealistic in many cases. Randomizing
text conditioning [36] during training or inference can also
reduce memorization but has limitations. It mitigates, rather
than fully prevents, memorization and lacks guaranteed ef-
fectiveness in untested scenarios. It results in significant
declines in CLIP [27] score, indicating a poorly balanced
trade-off between reducing memorization and maintaining
text-alignment of generated images. Furthermore, its uni-
form application across all text conditions, without consid-
ering their potential for causing memorization, further di-
minishes the images’ practical value. Our approach, AMG,
adopts a distinct strategy. Instead of altering text conditions
to indirectly affect image generation, we aim to directly
modify the generated image, thereby providing a guaran-
tee of reduced similarity and addressing the issue of mem-
orization more effectively. Moreover, AMG uses real-time
similarity metrics to selectively apply guidance to likely du-
plicates during inference, ensuring a targeted approach that
leaves unaffected cases unaltered, in contrast to the indis-
criminate application of randomization techniques , also by-
passing the need for manual crafting of concept ablation .
Other Privacy-Preservation Strategies encompass the
adoption of Differential Privacy (DP) [9] in training gen-
erative models [5, 8, 40], primarily through the use of the
differentially-private stochastic gradient descent (DP-SGD)
algorithm [2]. Although effective on smaller datasets like
MNIST and CelebA, [4] noted that implementing DP-SGD
in diffusion models tends to result in divergence during
training on datasets of CIFAR-10 scale. The feasibility of
applying DP-SGD to even larger datasets, such as LAION,
8426
remain unexplored. In addition, methods such as dataset
distillation [21, 39] offer a means to prevent raw data being
directly used in the training of generative models, thereby
aiding in privacy preservation. Yet, there has been no ex-
ploration of these methods on the LAION dataset to date.
3. Preliminaries
3.1. Diffusion Models
Denoising Diffusion Probabilistic Models (DDPMs) [12,
23] consist of two processes, firstly, a forward process is re-
quired to gradually add Gaussian noise to an image sampled
from a real-data distribution x0„qpxqoverTtimesteps
such that xT„Np0,Iq. The Diffusion Kernel then enables
sampling xtat arbitrary timestep tin a closed form:
qpxt|x0q“Npxt;?¯αtx0,p1´¯αtqIq (1)
where xtis the noised version of x0at timestep t, αt“
1´βtis the noise schedule controls the amount of noise in-
jected into the data at each step, and ¯αt“śt
s“1αs. Then,
in the backward process, generative modelling can be real-
ized by learning a denoiser network ϵθto predict the noise
ϵtinstead of the image xt´1at any arbitrary step t:
L“EtPr1,Ts,ϵ„Np0,Iqr}ϵt´ϵθpxt, tq}2
2s (2)
where the denoiser network can be easily reformulated as
a conditional generative model ϵθpxt, y, tqby incorporating
additional class or text conditioning y.
Score-based formulation [38] aims to construct a con-
tinuous time diffusion process, where tPr0, Tsis continu-
ous. The reverse processes can be formulated as:
dxt“„
´1
2βptqxt´βptq∇xtlogqtpxtqȷ
dt`a
βptqd¯wt
(3)
where βptqis a time-dependent function that allows differ-
ent step sizes βt“βptq∆talong the process t. A denoiser
network ∇xtlogpθpxtqis then learned to approximate the
score function ∇xtlogqtpxtqin the reverse process using a
denoising score matching objective, which can be derived
to be the same objective as in Eq. (2), leveraging the con-
nection between diffusion models and score matching:
∇xtlogpθpxtq“´1?1´αtϵθpxtq (4)
3.2. Guidance in Diffusion Models
Classifier guidance (CG) and classifier-free guidance (CFG)
are methods used in diffusion models to steer image gen-
eration towards higher likelihood outcomes as determined
by an explicit or implicit classifier pϕpy|xtq. In the score-
based framework [38], CG and CFG involve learning the
gradient of the log probability for the conditional model,
∇xtlogpθpxt|yq, rather than the score of unconditionalmodel, ∇xtlogpθpxtq. The conditional score can be easily
derived using Bayes’ rule as the sum of the unconditional
score and the gradient of the log classifier probability:
∇xtlogpθpxt|yq“∇xtlogpθpxtq`∇xtlogpϕpy|xtq
(5)
Classifier Guidance (CG) [7] involves training an explicit
classifier pϕpy|xtqon perturbed images xtand then em-
ploying its gradients ∇xtlogpϕpy|xtqto direct the diffusion
sampling process towards a class label y. Inserting Eq. (4)
into Eq. (5), [7] shows a new epsilon prediction ˆϵcorre-
sponds to the score presented in Eq. (5):
ˆϵ:“ϵθpxtq´?
1´¯αt∇xtlogpϕpy|xtq (6)
Classifier-Free Guidance (CFG) [11] eliminates the need
of an explicit classifier for computing Eq. (5). It requires
concurrent training on conditional and unconditional objec-
tives. At inference, the epsilon prediction is linearly di-
rected towards the conditional prediction and away from
the unconditional, and s0ą1controls the degree of ad-
justment:
ˆϵÐϵθpxtq`s0¨pϵθpxt, yq´ϵθpxtqq. (7)
4. Memorization in Diffusion Models
Memorization in generative models is identified when gen-
erated images exhibit extreme similarity to certain training
samples. The strictest definition of memorization relates to
high pixel-level similarity, often qualitatively represented as
the generated image being near-copies of training samples
as in Fig. 4 and left of Fig. 1. To quantify this similarity,
the negative normalized Euclidean L2-norm distance (nL2)
is employed as a pixel-level metric [4]. For a generated
representation ˆx0, this involves first identifying its nearest
neighbor n0using the ℓ2norm, and then normalizing the
norm as follows:
σt“´ℓ2pˆx0, n0q
α¨1
kř
z0PSˆx0ℓ2pˆx0, z0q(8)
where Sˆx0is a set of k“50nearest neighbors of ˆx0, andα
is a scaling constant with a default value of 0.5.
A broader definition of memorization encompasses re-
constructive memory in diffusion models, where the mod-
els reassemble various elements from memorized training
images, such as foreground and background objects. These
reconstructions might include transformations like shifting,
scaling, or cropping. Consequently, the reconstructed out-
puts do not necessarily match any training image on a pixel-
by-pixel basis, yet they exhibit a high degree of similarity to
certain training images at the object level. In right section of
Fig. 1, we observe that the outputs generated by Stable Dif-
fusion are not pixel-level identical to the training images.
However, they demonstrate significant object-level similar-
ity. To quantify such object-level similarity, a commonly
8427
Figure 2. Geometric interpretation of different guidance methods
and generations. The center Orepresents a scenario where the
generated image is identical to the memorized training image. The
distance of any point from Oreflects its degree of dissimilarity
to the memorized image. The surface of the sphere signifies the
threshold that defines the presence of a memorization issue. The
arrows represent different types of guidance strategies.
used metric is the dot product of embeddings of ˆx0andn0:
σt“Epˆx0qT¨Epn0q (9)
where Ep¨qrepresents the embedding obtained via a fea-
ture extractor, with Self-supervised Copy Detection (SSCD)
[26] being the preferred method for identifying object-level
memorization [35], n0represents the nearest neighbor of
x0, identified using this metric.
In later studies [19, 36] that examine memorization is-
sues within the diverse LAION dataset, where numerous
object-level memorization instances are identified, SSCD
has been established as the standard metric. On the other
hand, for the CIFAR-10 dataset, the negative nL2 is found
to be an efficient measure [4], attributable to the dataset’s
smaller size and consistency in image presentation.
4.1. Causes of Memorization
The main causes of memorization in diffusion models are
identified as follows: 1) Overly specific user prompts act
as a “key” to the pretrained model’s memory, potentially
retrieving a specific training image corresponding to this
“key”, as observed by [36]. 2) Duplicated training im-
ages are more inclined to be memorized by diffusion mod-
els as noted by [4, 35], likely due to overfitting. 3) Du-
plicated captions across those duplicated images can ex-
acerbate the memorization issue [36] by overfitting the text-
image pairs to text-conditional diffusion models, turning the
caption into a “key” that consistently retrieves the “value”
of the associated image. Therefore, when a user employs
such repetitive captions or closely related text prompts as
the conditioning, the model is prone to generate the corre-
sponding duplicated training image.
5. Anti-Memorization Guidance
Leveraging insights into the primary causes of memoriza-
tion, for diffusion models, we present Anti-Memorization
Guidance (AMG) , a unified framework integrating a com-
prehensive suite of three distinct guidance strategies,namely, dissimilarity guidance ,desspecification guidance ,
andcaption deduplication guidance . Each strategy within
AMG is meticulously crafted to address and effectively
eliminate specific causes of memorization in these mod-
els. As illustrated in Fig. 2, in the original diffusion mod-
els employing classifier-free guidance (CFG), the uncondi-
tional generation (point A) is linearly guided towards its
text-conditional generation (point B), which may falls in-
side the sphere, indicating that it has become a memorized
case. In the AMG framework, all three guidance methods
are capable of steering the generation process away from
memorization, represented by moving the generation out-
side the sphere in the geometric representation. From an
implementation standpoint, each guidance strategy is read-
ily integrable with different types of pretrained diffusion
models, such as conditional and unconditional Denoising
Diffusion Probabilistic Models (DDPMs) and Latent Diffu-
sion Models (LDMs), without the necessity for additional
re-training or fine-tuning. This compatibility extends to dif-
ferent sampling methods, including DDPM sampler and ac-
celerated sampling method such as DDIM [37]. The frame-
work solely requires updating the epsilon prediction ˆϵin ac-
cordance with each specific guidance strategy, which is then
combined with xtto estimate the previous step representa-
tionxt´1in the reverse process of diffusion models:
ˆϵÐˆϵ`1tσtąλtu¨pGspe`Gdup`Gsimq (10)
xt´1Ð?¯αt´1ˆxt´?1´¯αtˆϵ?¯αt˙
`a
1´¯αt´1ˆϵ(11)
To minimize alterations to the original sampling process
and thus preserve output utility to the greatest extent, we
introduce an indicator function 1tσtąλtuthat activates guid-
ance only when the current similarity σtexceeds a pre-set
threshold λt. Importantly, we have designed λtas a dy-
namic, rather than static, threshold. This dynamic nature ac-
counts for the observed fluctuations of σtthroughout the in-
ference process. For instance, in the early denoising stages,
when tis large, the prediction ˆx0is generally less precise
than at later stages when tapproaches 0. Consequently, σt
tends to be lower at higher tvalues and increases as tde-
creases. To effectively manage this variation, we adopt a
parabolic scheduling for λtin alignment with the charac-
teristics of the denoising stages. As a result, this design of
conditional guidance with parabolic scheduling operates as
an automatic mechanism to selectively activates guidance
only when necessary. Such a configuration enables AMG to
optimize the balance between reducing memorization and
maintaining high-quality outputs.
Moreover, AMG ensures that the generated images, dur-
ing inference time, diverge from the memorized training im-
age at either pixel or object level. The type and strength of
this divergence can be flexibly tailored based on the user’s
specific application and objectives.
8428
5.1. Despecification Guidance
As previously discussed, a primary cause of memorization
in text-conditional diffusion models is the overly specific
nature of user prompts, acting as a “key” to the pretrained
model’s memory [36]. To reduce caption specificity by in-
structing the inference process, we firstly employ a desspec-
ification guidance . Given an noised image or latent-space
representation xtand predicted noise ˆϵat time t, we can ob-
tain its prediction of ˆx0using the Diffusion Kernel (Eq. (1)):
ˆx0“xt´?1´¯αt¨ˆϵ?¯αt(12)
Then, we search its nearest neighbor n0in the training set
and compute the similarity σtbetween ˆx0andn0. Depend-
ing on the user’s goal to prevent pixel-level or object-level
memorization, the similarity measure σtcan be computed
accordingly using nL2 (Eq. (8)) or SSCD (Eq. (9)).
This method aligns with the principles of CFG but pur-
sues the inverse goal: to attenuate the original CFG scale to
linearly adjust the epsilon prediction to be less aligned with
the prompt-conditional prediction:
s1“maxpminpc1σt, s0´1q,0q (13)
Gspe“´s1pϵθpxt, yq´ϵθpxtqq (14)
where ϵθpxt, yqrepresents the pretrained diffusion model’s
prediction conditioned on user’s text prompt, while ϵθpxtq
denotes the unconditional prediction. s0is the original scale
of CFG, c1is a constant and c1σtdefines the guidance scale
at step t, which is directly proportional to the similarity σt
at step t. This enables the algorithm to adaptively adjust the
scale of desspecification guidance throughout the sampling
process, corresponding to the current level of the memoriza-
tion, as indicated by the value of σtat any step t. The func-
tionmaxp¨,0qguarantees the guidance scale ´s1to be non-
positive, thus diminishing caption specificity, while minp¨q
function bounds c1σtto not exceed s0´1, safeguarding
against excessive low text-image alignment.
From a geometric perspective as in Fig. 2, Despecifica-
tion guidance ( Gspe) is capable of steering the generation
process away from memorization, start from point B,Gspe
directs the prediction in the exact opposite direction of the
CFG, exiting the sphere at point Xon the surface.
5.2. Caption Deduplication Guidance
As outlined in Sec. 4, duplicated captions can act as precise
“keys” to retrieve memorized data from the training set, so
why not turn this to our advantage? By intentionally using
them as prompts for pretrained diffusion models to generate
predictions that replicates these memorized images, we can
then apply classifier-free guidance techniques to steer the
generation away from these images:
s2“maxpminpc2σt, s0´s1´1q,0q (15)
Figure 3. Comparison of similarity scores throughout the infer-
ence process, with and without the application of Gdup.
Gdup“´s2pϵθpxt, yNq´ϵθpxtqq (16)
where yNdenotes the caption of n0, which is the nearest
neighbor of current prediction ˆx0as defined in Eq. (12). In
case where n0is a duplicated image prone to memorization
and accompanied by a duplicated caption, yNwould corre-
spond to this replicated caption. Consequently, ϵθpxt, yNq
reflects the conditional prediction based on the duplicated
caption, serving as an ideal antithesis to the prediction we
aim to achieve. The function maxp¨,0qagain guarantees
non-positive guidance scale ´s2, directs ˆϵaway from condi-
tional prediction compared to the unconditional prediction
ϵθpxtq, while minp¨qbounds the total scale of s1`c2σtto
not exceed s0´1for preserving text-image alignment.
From a geometric standpoint as in Fig. 2, caption dedu-
plication guidance ( Gdup) runs parallel to line OA, rep-
resenting the guidance direction when using perfect text-
conditioning that leads to memorization as a negative
prompt. This method exits the sphere at point Yon the sur-
face, thereby moving the generation out of the memoriza-
tion zone. Fig. 3 further illustrates the efficiency of Gdup.
It demonstrates that when the similarity score exceeds the
dashed parabolic threshold line λt, as defined in Eq. (10),
Gdupis activated. This activation prompts Gdupto guide
the generations in a direction opposite to that of the training
image, effectively preventing memorization.
5.3. Dissimilarity Guidance
Distinct from the first two strategies, which linearly ad-
just the epsilon prediction ˆϵalong the vector direction be-
tween conditional and unconditional predictions, dissimi-
larity guidance identifies another dimension that offer ef-
fective guidance to reduce, or even eliminate, memorization
8429
in diffusion models. It extends the discrete class label yin
classifier guidance Eq. (6) to a continuous embedding rep-
resented by the similarity score. This approach assures that
our generated images are actively directed towards reducing
their similarity score, thereby ensuring persistent dissimi-
larity from their closest counterparts in the training set, as
measured by metrics such as nL2 and SSCD.
Gsim“c3?
1´¯αt¨∇xtσt (17)
where we use the similarity metric σtinstead of log classi-
fier probability logpϕpy|xtqto compute gradient and guide
the inference process. We also invert the sign preceding the
guidance term from Eq. (6) to indicate our new objective:
to minimize similarity as opposed to maximizing it. An ad-
ditional scaling factor c3is also employed, which functions
as a hyperparameter to control the intensity of the guidance,
thereby managing the privacy-utility trade-off and tailoring
user’s specific goals. A larger c3permits greater deviation
of the generated data from the nearest training image, but at
the expense of reduced quality and text alignment.
Geometrically as in Fig. 2, dissimilarity guidance ( Gsim)
steers the generation direction directly away from point O,
which represents the perfectly memorized case ( i.e., the
training data), eventually exit at point Zon the sphere.
5.4. Unpacking AMG’s Threefold Guidance
We present a detailed analysis of the indispensable role and
synergies of each of the three guidance methods in AMG for
achieving the optimal balance between privacy and utility.
Impact on quality and text-alignment. Similar to
CFG, our Gspemethod linearly combines the unconditional
prediction ϵθpxtqand user-prompt based conditional predic-
tions ϵθpxt, yq. Altering the guidance scale modifies the
weights of these components, but as both are derived from
pretrained diffusion model’s high-quality outputs, overall
output quality remains largely consistent. However, text
alignment decreases with lower weights on ϵθpxtq, neces-
sitating a minimum weight of one to preserve text align-
ment. Similarly, for Gdup, assuming using a neighbor’s cap-
tionyNleads to an exact replication of training image, the
output maintains high quality, thus its linear combination
withϵθpxtqalso yields quality on par with the pretrained
model. Geometrically, results within the ABY plane, formed
by lines ABandBY, maintain quality, but those closer to A
(along line AB) show reduced text alignment. Gsim, how-
ever, does not align with the ABY plane, so its scale affects
the quality and must be minimally set to preserve quality.
Importance of dissimilarity guidance ( Gsim).Gsim,
as shown in Fig. 2, is vital despite its possible quality im-
pact. The necessity stems from the fact that Gspeand
Gdup’s combined scale, capped at s0´1, cannot assure
moving the generation outside the sphere, potentially leav-
ing it within the BXY sector. Gsim, on the other hand, re-liably ensures the generation is guided out of the sphere,
effectively addressing memorization.
Importance of caption deduplication guidance
(Gdup). Text-conditioning heightens specificity, thus
reducing diversity in generations. In severe cases, such
as when point Bnear center O,Gsimwould need a high
scale to prevent memorization without GspeandGdup,
risking artifacts. GspeandGdupmitigate this by lowering
the needed scale for Gsim, thus preserving output quality.
Comparing GspeandGdup, both maintain quality within
theABY plane, but Gdup involves less text alignment
sacrifice due to the shorter linear projection of BYon the
ABline ( i.e.,BY’ăBX), thus more beneficial than Gspe.
Importance of despecification guidance ( Gspe).The
inclusion of Gspe, despite Gdup’s apparent advantages, is
justified by Gdup’s practical limitations as it idealizes dedu-
plication guidance, requiring access to perfect “keys” for
pretrained model memories, approximated here by captions
of memorized training images. Such ideal “keys” are un-
common, and caption-based approximations may not al-
ways be as precise as prompt-based methods in Gspe, par-
ticularly when memorized images’ captions are not dupli-
cated in the dataset. Consequently, our approach in AMG
integrates both GspeandGdupto emulate these ideal “keys”
for effective negative guidance.
Unconditional and class-conditional generations. Our
research reveals that in the absence of text-conditioning,
memorization in diffusion models is reduced but not elim-
inated, aligning with our prior findings. This significantly
lessens memorization, leaving image duplication as the only
remaining issue. In such cases, Gspeis highly effective in
eliminating memorization due to two factors: 1) Early De-
tection : During initial stages of reverse diffusion, our con-
ditional guidance with a parabolic schedule efficiently iden-
tifies potential replication. 2) Increased Diversity : With-
out specific text-conditioning, the generation process yields
greater diversity. This enables Gdisto effectively steer
generations away from memorized modes to un-memorized
ones in the initial stages, ensuring they don’t revert. Once
memorization ceases to be detected, further guidance appli-
cation is discontinued. As a result, this method predomi-
nantly impacts the coarse structure, with guidance typically
applied only during the early stages of the denoising pro-
cess. The finer details in later stages remain intact, thus
ensuring the overall quality of the output is preserved.
6. Experiments
6.1. Experimental Setup
Scope . In the realm of pretrained diffusion models, studies
[4, 35, 36] have identified memorization in unconditional
DDPMs on CIFAR-10 and text-conditional Stable Diffu-
sion on LAION datasets. While [35] found no memoriza-
8430
Figure 4. Applying AMG to iDDPM on CIFAR-10. Left: Class-
conditional generation. Right: Unconditional generation.
tion in latent diffusion models using ImageNet, our analysis
of DDPMs on ImageNet [6] and LSUN Bedroom [41] also
showed no memorization cases. Beyond these scenarios, we
explored class-conditional generation and identified memo-
rization cases on CIFAR-10. Our findings confirm the suc-
cessful elimination of memorization in all tested scenarios,
highlighting the wide applicability of our approach.
Evaluation metrics. To assess text-conditional genera-
tions (Tab. 1), we employ three metric types: memorization,
quality, and text-alignment. Memorization metrics include
the 95th percentile [36] of similarity scores of all generated
images, determined using pixel-level nL2 norm (Eq. (8)) or
object-level SSCD embedding similarity (Eq. (9)). We con-
tend that relying solely on this metric might be misleading,
especially if the distribution of the generated data exhibits a
heavy upper tail beyond the 95th percentile. In such scenar-
ios, the similarity score could be significantly understated.
We propose to additionally examine the maximum similar-
ity score within the distribution, to gauge the worst-case
scenario regarding memorization. Additionally, the propor-
tion of images exceeding certain similarity thresholds, thus
flagged as memorized, is a key metric [4]. Notably, thresh-
olds vary; for CIFAR-10, an nL2 below 1.4normally indi-
cates pixel-level memorization, while for LAION, an SSCD
above 0.5suggests object-level memorization following the
convention of previous work [19, 35, 36]. We use FID to
measure the fidelity and diversity of generated images, and
CLIP score to measure the generated images’ alignment
with the input text prompts.
Implementational details. Experimental results depend
on variables such as text prompts, number of generated im-
ages, training image scope (e.g., LAION-10k to LAION-
5B), choice of diffusion model, and sampling steps. Since
baseline methods often employ different settings, we have
reimplemented these baselines to ensure a fair and compa-
rable evaluation. In our text-conditional generation exper-
iments on the LAION5B dataset, we utilized [3]’s system
for replicates identification. They used a CLIP embedding-
based index for LAION5B, with an efficient retrieval sys-
tem for identifying k-nearest neighbors. Our approach dif-
fered in seeking the singular nearest neighbor based onMemorization Metrics by SSCD Ó
Top5% Top1 % ą0.5 %ą0.4 FIDÓ CLIPÒ
SD [30] 0.91 0.93 44.85 59.23 106.41 28.04
Ablation [19] - - 0.30* - - -
GNI [36] 0.91 0.94 42.75 58.18 97.81 27.79
RT [36] 0.61 0.84 15.07 26.75 101.69 22.63
CWR [36] 0.79 0.85 26.45 40.93 96.25 25.96
RNA [36] 0.75 0.82 17.78 29.05 99.68 23.37
Ours(Main) 0.41 0.47 0.00 7.07 99.12 26.98
Ours(Strong) 0.34 0.39 0.00 0.00 100.45 26.72
Table 1. Comparisons on text-conditional generation of LAION5B
based on SSCD similarity. AMG successfully eliminates memo-
rization with minimal impact on quality and text-alignment.
Memorization Metrics by nL2
Top5%ÒTop1Ò %ă1.4Ó%ă1.6ÓFIDÓ
iDDPM [23] 1.58 0.51 0.93 5.78 7.44
Ours(Main) 1.61 1.47 0.00 4.34 7.25
Ours(Strong) 1.71 1.68 0.00 0.00 6.98
Table 2. Comparisons on unconditional generation of CIFAR-10
based on nL2 similarity. AMG effectively eliminates memoriza-
tion without affecting image quality.
Memorization Metrics by nL2
Top5%ÒTop1Ò %ă1.4Ó%ă1.6ÓFIDÓ
iDDPM [23] 1.53 0.51 1.53 9.77 11.81
Ours(Main) 1.56 1.46 0.00 8.70 11.54
Ours(Strong) 1.71 1.68 0.00 0.00 11.44
Table 3. Comparisons on class-conditional generation of CIFAR-
10 based on nL2 similarity. AMG effectively eliminates memo-
rization without affecting image quality.
SSCD embedding similarity. To approximate this, we first
identified 1,000 images with the lowest CLIP embedding
similarities, then computed SSCD similarities to find the
highest match, using it for memorization metrics. Sta-
ble Diffusion v1.4 with a DDIM sampler and 50 sampling
steps was our model of choice. For unconditional and
class-conditional generations on CIFAR-10, which com-
prises 50,000 images, we calculated SSCD similarities for
each generated image with the entire training set. OpenAI’s
iDDPM [23] with a DDPM sampler and 250 sampling steps
was used. Further details are in the supplementary material.
6.2. Comparison with Baselines
Text-conditional generations on LAION. Table 1 shows
that AMG outperforms all baselines in memorization met-
rics by a huge margin, eliminating all memorization cases
defined by a similarity score over 0.5. It also shows a mini-
mal loss in text-alignment, evidenced by having the second-
highest CLIP score among mitigation strategies, thus main-
taining strong alignment with user intentions. Notably, the
strategy with the highest CLIP score, GNI, performs poorly
in memorization metrics, closely resembling the original
Stable Diffusion without mitigation. AMG matches base-
lines in FID, indicating comparable quality. Overall, AMG
leads to memorization-free generations and stands out in
balancing quality and utility. AMG’s flexibility allows users
8431
Mem. by SSCD Ó
Top5% %ą0.5 FIDÓ CLIPÒ
Baseline [30] 0.9133 44.85 106.41 28.04
Gsim`Gspe 0.4072 0.00 119.13 26.67
Gsim`Gdup 0.4073 0.00 120.48 26.17
Gspe`Gdup 0.7396 31.62 87.10 27.18
Full 0.4066 0.00 99.12 26.98
Table 4. Ablation studies on text-conditional generation based on
SSCD. Grey-colored font denotes areas of sacrifice.
Mem. by nL2
Top5%Ò %ă1.4Ó FIDÓ
Baseline [23] 1.58 0.93 7.44
w/o conditional guidance 1.49 0.00 257.27
w constant schedule 1.59 0.04 7.44
Full 1.61 0.00 7.25
Table 5. Ablation studies on unconditional generation based on
nL2. Grey-colored font denotes areas of sacrifice.
to adjust guidance strength based on their definition of
memorization. While the standard threshold is 0.5, increas-
ing AMG’s guidance scale ( i.e., the strong version of AMG)
effectively prevents memorization even at a 0.4threshold, at
a minimal extra cost of quality and text-alignment.
Unconditional and class-conditional generations on
CIFAR-10. Tab. 2 and Tab. 3 illustrate AMG’s effec-
tiveness in transitioning from text-conditional to class-
conditional or unconditional generation tasks, and from pre-
venting object-level to pixel-level memorization. AMG
consistently outperforms, even when compared to [4], who
reported a 23% reduction in memorization by retraining dif-
fusion models on a deduplicated CIFAR-10 dataset. AMG
ensures memorization-free outputs and even slightly ex-
ceeds the original diffusion model’s quality, as reflected
in FID scores, likely due to the increased diversity of its
generated images compared to the original model’s repli-
cated outputs. This success is attributed to two main fac-
tors: 1) AMG’s early memorization detection during reverse
sampling, utilizing a conditional guidance with a parabolic
schedule; 2) The absence of text-conditioning eliminates
key memorization causes, like specific user prompts and
caption duplication, enhancing output diversity. Solely us-
ingdissimilarity guidance in AMG can be very effective in
preventing memorization whilst preserving output quality,
since it only alters the coarse structure of images in early
stages of reverse sampling when potential memorization is
detected. Guidance ceases once memorization is no longer
detected, thus preserving sample quality.
6.3. Ablation Studies
Table 4 underlines the crucial role of AMG’s tripartite
guidance in optimizing the privacy-utility trade-off. Key
observations include: 1) All AMG versions notably en-
hance memorization metrics, particularly those incorpo-
rating Gsim, which eradicate memorization entirely with
proper guidance scale tuning. This underscores Gsim’s the-oretical guarantee against memorization, albeit with slight
impacts on quality and text-alignment. Ablation of Gsim
improves FID and CLIP scores but results in 31.62% of
generated images being marked as memorized. Thus, Gsim
inclusion significantly boosts privacy with minimal utility
loss. 2) Comparisons between the full AMG version and
variants lacking either GduporGspedemonstrate that while
achieving similar privacy levels, the ablated versions yield
inferior FID and CLIP scores. This confirms the importance
of both GdupandGspein the guidance ensemble.
Table 5 highlights the efficacy of our conditional guid-
ance with parabolic scheduling. Applying guidance indis-
criminately during sampling, rather than selectively based
on potential memorization, guarantees elimination of mem-
orization but degrades output quality, evidenced by signifi-
cantly higher FID scores. This is due to excessive alteration
of both coarse structures (early sampling stages) and finer
details (later stages). The parabolic schedule aligns with
denoising stages: initially, predictions are highly noised and
dissimilar to training images, becoming more accurate and
revealing potential memorization cases with higher similar-
ity as denoising progresses. This schedule enables early de-
tection and effective resolution of memorization issues. A
constant schedule would fail to provide this early detection,
leading to 0.04% of generations being memorized, which
could be eliminated by increasing the guidance scale but
at the cost of quality. Therefore, our conditional guidance
strategy enhances the privacy-utility trade-off by negating
the need for this additional quality compromise.
7. Conclusion
We introduce AMG , a unified framework featuring three
specialized guidance strategies, each addressing a specific
cause of memorization in diffusion models. Theoretical
analysis and empirical ablation studies confirm the essential
role of each strategy in achieving an optimal privacy-utility
trade-off. AMG’s strategic guidance scheduling and inno-
vative automatic detection enable conditional application,
further refining this balance. Our experiments demonstrate
that AMG reliably generates images during inference that
are distinct from memorized training images, maintaining
high quality and text-alignment. Furthermore, AMG offers
the flexibility to adapt to various user requirements by al-
lowing customization in the type of memorization prevented
(pixel-level or object-level) through adjustments in the sim-
ilarity metrics employed in its guidance. Additionally, it
provides options for guidance intensity (main or strong ver-
sion) by adjusting the guidance scale, catering to a wide
range of applications and user preferences.
8. Acknowledgement
This work was supported in part by the Australian Research
Council under Projects DP210101859 and FT230100549.
8432
References
[1] Midjourney. https://www.midjourney.com/ . 1
[2] Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan
McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep
learning with differential privacy. In Proceedings of the 2016
ACM SIGSAC conference on computer and communications
security , pages 308–318, 2016. 2
[3] Romain Beaumont. Clip retrieval: Easily compute
clip embeddings and build a clip retrieval system with
them. https://github.com/rom1504/clip-
retrieval , 2022. 7
[4] Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagiel-
ski, Vikash Sehwag, Florian Tram `er, Borja Balle, Daphne
Ippolito, and Eric Wallace. Extracting training data from
diffusion models. In USENIX Security Symposium , pages
5253–5270, 2023. 1, 2, 3, 4, 6, 7, 8
[5] Chen Chen, Daochang Liu, Siqi Ma, Surya Nepal, and
Chang Xu. Private image generation with dual-purpose aux-
iliary classifier. In CVPR , 2023. 2
[6] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE Conference on Computer Vision and
Pattern Recognition , pages 248–255. IEEE, 2009. 7
[7] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. In NeurIPS , pages 8780–8794,
2021. 1, 3
[8] Tim Dockhorn, Tianshi Cao, Arash Vahdat, and Karsten
Kreis. Differentially Private Diffusion Models. Transactions
on Machine Learning Research , 2023. 2
[9] Cynthia Dwork, Aaron Roth, et al. The algorithmic foun-
dations of differential privacy. Foundations and Trends® in
Theoretical Computer Science , 9(3–4):211–407, 2014. 2
[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and
Yoshua Bengio. Generative adversarial nets. In NeurIPS ,
2014. 1
[11] Jonathan Ho and Tim Salimans. Classifier-free diffusion
guidance. arXiv:2207.12598 , 2022. 1, 3
[12] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif-
fusion probabilistic models. In NeurIPS , pages 6840–6851,
2020. 1, 3
[13] Nikhil Kandpal, Eric Wallace, and Colin Raffel. Deduplicat-
ing training data mitigates privacy risks in language models.
InICML , 2022. 2
[14] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
Progressive growing of GANs for improved quality, stability,
and variation. arXiv preprint arXiv:1710.10196 , 2017. 1
[15] Tero Karras, Samuli Laine, and Timo Aila. A style-based
generator architecture for generative adversarial networks. In
CVPR , pages 4401–4410, 2019.
[16] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,
Jaakko Lehtinen, and Timo Aila. Analyzing and improving
the image quality of StyleGAN. In CVPR , pages 8110–8119,
2020. 1
[17] Diederik P. Kingma and Max Welling. Auto-encoding vari-
ational bayes. In ICLR , 2014. 1[18] Alex Krizhevsky. Learning multiple layers of features from
tiny images. Technical report, University of Toronto, 2009.
1
[19] Nupur Kumari, Bingliang Zhang, Sheng-Yu Wang, Eli
Shechtman, Richard Zhang, and Jun-Yan Zhu. Ablating con-
cepts in text-to-image diffusion models. In ICCV , 2023. 1,
2, 4, 7
[20] Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan
Zhang, Douglas Eck, Chris Callison-Burch, and Nicholas
Carlini. Deduplicating training data makes language mod-
els better. In ACL, pages 8424–8445, 2022. 2
[21] Songhua Liu, Kai Wang, Xingyi Yang, Jingwen Ye, and
Xinchao Wang. Dataset distillation via factorization. Ad-
vances in neural information processing systems , 35:1100–
1113, 2022. 3
[22] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang.
Deep learning face attributes in the wild. In Proceedings of
International Conference on Computer Vision (ICCV) , 2015.
2
[23] Alex Nichol and Prafulla Dhariwal. Improved denoising dif-
fusion probabilistic models. In ICML , 2021. 1, 3, 7, 8
[24] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav
Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and
Mark Chen. Glide: Towards photorealistic image generation
and editing with text-guided diffusion models. 2021. 1
[25] Maria-Elena Nilsback and Andrew Zisserman. Automated
flower classification over a large number of classes. In
Proceedings of the Indian Conference on Computer Vision,
Graphics and Image Processing , pages 722–729, 2008. 2
[26] Ed Pizzi, Sreya Dutta Roy, Sugosh Nagavara Ravindra, Priya
Goyal, and Matthijs Douze. A self-supervised descriptor for
image copy detection. In CVPR , pages 14532–14542, 2022.
4
[27] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya
Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,
Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen
Krueger, and Ilya Sutskever. Learning transferable visual
models from natural language supervision. arXiv preprint
arXiv:2103.00020 , 2021. 2
[28] Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,
and Mark Chen. Hierarchical text-conditional image gener-
ation with clip latents. 2022. 1
[29] Danilo Rezende and Shakir Mohamed. Variational inference
with normalizing flows. In ICML , pages 1530–1538, 2015.
1
[30] Robin Rombach, Andreas Blattmann, Dominik Lorenz,
Patrick Esser, and Bj ¨orn Ommer. High-resolution image syn-
thesis with latent diffusion models. In CVPR , pages 10684–
10695, 2022. 1, 7, 8
[31] Chitwan Saharia, William Chan, Saurabh Saxena,
Lala Li, Jay Whang, Emily Denton, Seyed Kamyar
Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi,
Rapha Gontijo Lopes, et al. Photorealistic text-to-image
diffusion models with deep language understanding. arXiv
preprint arXiv:2205.11487 , 2022. 1
[32] Joseph Saveri and Butterick Matthew. Stable diffusion liti-
gation, 2023. 2023. 1
8433
[33] Christoph Schuhmann, Romain Beaumont, Richard Vencu,
Cade Gordon, Ross Wightman, Mehdi Cherti, Theo
Coombes, Aarush Katta, Clayton Mullis, Mitchell Worts-
man, Patrick Schramowski, Srivatsa Kundurthy, Katherine
Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and Jenia
Jitsev. Laion-5b: An open large-scale dataset for training
next generation image-text models. 2022. 1
[34] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,
and Surya Ganguli. Deep unsupervised learning using
nonequilibrium thermodynamics. In ICML , pages 2256–
2265, 2015. 1
[35] Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas
Geiping, and Tom Goldstein. Diffusion art or digital forgery?
investigating data replication in diffusion models. In CVPR ,
pages 6048–6058, 2023. 1, 2, 4, 6, 7
[36] Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas
Geiping, and Tom Goldstein. Understanding and mitigating
copying in diffusion models. In NeurIPS , 2023. 1, 2, 4, 5, 6,
7
[37] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denois-
ing diffusion implicit models. In ICLR , 2021. 4
[38] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-
hishek Kumar, Stefano Ermon, and Ben Poole. Score-based
generative modeling through stochastic differential equa-
tions. In ICLR , 2021. 3
[39] Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and
Alexei A Efros. Dataset distillation. arXiv preprint
arXiv:1811.10959 , 2018. 3
[40] Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu
Zhou. Differentially private generative adversarial network.
arXiv preprint arXiv:1802.06739 , 2018. 2
[41] Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas
Funkhouser, and Jianxiong Xiao. Lsun: Construction of a
large-scale image dataset using deep learning with humans
in the loop. In arXiv preprint arXiv:1506.03365 , 2015. 7
8434
