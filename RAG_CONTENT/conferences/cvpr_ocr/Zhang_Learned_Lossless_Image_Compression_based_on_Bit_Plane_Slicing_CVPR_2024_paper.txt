Learned Lossless Image Compression based on Bit Plane Slicing
Zhe Zhang1Huairui Wang1Zhenzhong Chen1∗Shan Liu2
1Wuhan University2Tencent Media Lab
{zhe zhang, zzchen }@whu.edu.cn
Abstract
Autoregressive Initial Bits (ArIB), a framework that com-
bines subimage autoregression and latent variable models,
has shown its advantages in lossless image compression.
However, in current methods, the image splitting makes the
information of latent variables being uniformly distributed
in each subimage, and causes inadequate use of latent vari-
ables in addition to posterior collapse. To tackle these is-
sues, we introduce Bit Plane Slicing (BPS), splitting images
in the bit plane dimension with the considerations on differ-
ent importance for latent variables. Thus, BPS provides a
more effective representation by arranging subimages with
decreasing importance for latent variables. To solve the
problem of the increased number of dimensions caused by
BPS, we further propose a dimension-tailored autoregres-
sive model that tailors autoregression methods for each di-
mension based on their characteristics, efficiently captur-
ing the dependencies in plane, space, and color dimensions.
As shown in the extensive experimental results, our method
demonstrates the superior compression performance with
comparable inference speed, when compared to the state-
of-the-art normalizing-flow-based methods. The code is at
https://github.com/ZZ022/ArIB-BPS .
1. Introduction
Lossless image compression is widely applied in many do-
mains where the preservation of high-quality images is de-
manded such as photography, scientific exploration, and re-
mote sensing. The significance of these compression tech-
niques lies in their ability to reduce image file sizes while
preserving the original content, accomplished through the
exploitation of inherent image correlations.
Fundamentally, Shannon’s source coding theorem [30]
sets a lower bound for coding length based on the im-
age’s entropy, which is determined by its inherent dis-
tribution. Consequently, many deep generative models
∗Corresponding author. This work was supported by the National Nat-
ural Science Foundation of China (Grant No. 62036005) and Tencent.[4], which have exhibited remarkable efficacy in distribu-
tion modeling, have found widespread application within
the realm of lossless image compression. These encom-
pass a variety of methodologies, including autoregressive
methods (ARMs) [29, 37], variational autoencoders (V AEs)
[19, 22, 34, 35], normalizing flows (NFs) [12, 13, 41, 42],
and diffusion models [14, 17]. These diverse approaches
involve trade-offs between compression performance and
inference speed. Furthermore, compression performance
encompasses dataset compression, which often approaches
the theoretical limits optimized by neural networks, and
single-image compression, which is affected by the initial
bits required for bits back coding [34]. Bits back coding
is utilized in V AEs, continuous NFs, and variational dif-
fusion models. In summary, per pixel ARMs and diffu-
sion models demonstrate impressive compression perfor-
mance but necessitate impractical inference time [22, 28].
Among the remaining methods, continuous NFs offer the
best dataset compression but exhibit weaker performance in
single-image compression.
A potential option for achieving a better trade-off is the
combined use of subimage autoregression and V AEs, a kind
of latent variable model. This approach has shown compet-
itive performance in the field of lossless image compres-
sion, particularly in its single-image compression perfor-
mance when using the Autoregressive Initial Bits (ArIB)
framework [28]. ArIB excludes latent variables for some
subimages and uses their bits as initial bits, significantly re-
ducing the overhead associated with initial bits for single-
image compression.
Current methods [28] split the image in the space dimen-
sion. Pixels with the same coordinate in different subim-
ages are adjacent in the original image. This splitting uni-
formly distributes the information of latent variables in each
subimage. Thus, each subimage carries similar importance
for latent variables. However, latent variables are inade-
quately used due to their exclusion for some subimages. In
addition, there’s a growing risk of posterior collapse [21]
along the subimage sequence due to the growing volume of
the autoregressive prior. Posterior collapse, a phenomenon
where non-useful latent variables are learned, adversely im-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
27579
pacts compression performance. Given the importance of
all subimages for latent variables, current methods suffer
from posterior collapse [28].
To address these issues, we propose the utilization of
bit plane slicing (BPS). BPS splits images along the bit
plane dimension, with a reduction in the volume of global
data modality from the most significant plane (MSP) to the
least significant plane (LSP) (see Figure 2). Given that la-
tent variables are utilized for learning global data modalities
[22, 28], the importance for latent variables decreases from
MSP to LSP (see Figure 3). We arrange subimages with
decreasing importance for latent variables. Hence, a more
adequate utilization of latent variables is achieved by ex-
cluding subimages with minor importance. Moreover, we
enhance autoregression by introducing the autoregression
from MSP to LSP. This autoregression has a mitigated risk
of posterior collapse since subimages important for latent
variables are subject to a low risk of posterior collapse.
The introduction of BPS increases the number of dimen-
sions of subimages. When combining autoregression in the
plane dimension with that in the existing space and color
dimensions, an efficient method is required. To solve the
problem, we propose a dimension-tailored autoregressive
model. Autoregressive methods are tailored based on the
unique characteristics of each dimension: a non-neural dis-
tribution model for the simplest color space, a simple neural
network for the space dimension, and a much more com-
plex network for the challenging plane dimension. This
model demonstrates a substantial improvement in perfor-
mance, balanced with a suitable increase in complexity, as
evidenced by our experimental results.
Consequently, our method outperforms the current ArIB
methods in compression performance. Moreover, compared
to the state-of-the-art NF-based methods, our approach
demonstrates superior compression performance with com-
parable inference time.
Our contributions could be summarized as follows:
• We introduce bit plane slicing (BPS) for ArIB, since it
splits the subimages with different importance for latent
variables. By arranging subimages with decreasing im-
portance for latent variables, BPS enables adequate use
of latent variables as well as enhanced autoregression in
a mitigated risk of posterior collapse.
• We propose a dimension-tailored autoregressive model.
This model tailors autoregression methods for each di-
mension based on their different characteristics, effi-
ciently modeling dependencies in an increased number of
dimensions caused by BPS.
• With the merit of the BPS and dimension-tailored autore-
gressive model, our method surpasses the state-of-the-art
normalizing-flow-based methods in compression perfor-
mance with comparable inference time.2. Related Work
Autoregressive Models compress images by predicting the
probability of the current component based on previously
decoded ones. Per-pixel ARMs [29, 37] decode images
pixel by pixel, yielding impressive compression perfor-
mance. However, as image resolution increases, the number
of required network evaluations grows linearly, leading to
impractically long decoding times. To mitigate this issue,
subimage ARMs divide an image into a fixed number of
subimages, significantly reducing inference time in compar-
ison to per-pixel ARMs. Various image-splitting methods
have been proposed, including spatial splitting [9], channel-
wise splitting [24], unevenly channel-wise splitting [10],
lossy and residual decomposition [23], autoregressive sub-
pixel convolution [28], and low-high frequency decompo-
sition [26]. In the neural compression community, autore-
gression in the bit plane dimension has been adopted for
order-agnostic autoregressive diffusion models [14], pro-
gressive compression [15], and high bit-depth medical im-
age compression [38]. These methods employ BPS for dif-
ferent goals. Our method leverages autoregression in the
bit plane dimension for ArIB to enhance autoregression in
a mitigated risk of posterior collapse.
Latent variable models utilize extracted latent variables
from input images to aid in compression. L3C [22] employs
a neural network to extract latent variables as auxiliary in-
formation. V AE-based methods [19, 34, 35] use posterior
sampling for obtaining latent variables to improve perfor-
mance. LBB [12] defines a posterior distribution for la-
tent variables, enabling discretization for continuous NFs,
which is also applied in iFlow [41]. However, posterior
sampling requires bits back coding [34], which introduces
significant overhead for single-image compression.
Combined methods integrate latent variable models and
ARMs. They have witnessed great success in the neural
lossy compression community [25] and have been explored
in lossless compression recently [16, 28]. This combination
enables the efficient capture of both local and global data
modalities. SHVC [28] further introduces ArIB based on
the combination to reduce the overhead by initial bits.
3. Method
In this section, we introduce our Autoregressive Initial Bits
with Bit Plane Slicing (ArIB-BPS) method. To provide a
clear overview of our method, Figure 1 illustrates the key
components and workflow of ArIB-BPS.
3.1. Background
Subimage Autoregressive Models split the image xinto a
fixed number of subimages {x1, x2, . . . , x n}. The proba-
bility of xis factorized into the product of conditional dis-
tributions as follows
27580
𝒙𝒙
𝒙𝒙𝟏𝟏:𝒔𝒔𝒙𝒙𝒔𝒔+𝟏𝟏:𝟖𝟖
Latent 
Encoder
Entropy 
Decoder
Latent 
DecoderEntropy 
Encoder �𝒛𝒛Dimension -
Tailored
AutoregressionDimension -
Tailored
AutoregressionBit Plane Slicing
Initial 
Bits𝒒𝒒(𝒛𝒛|𝒙𝒙𝟏𝟏:𝒔𝒔)
𝒑𝒑(𝒛𝒛)𝑭𝑭𝒛𝒛Space Slicing
Dimension -Tailored Autoregression For 𝒙𝒙𝒋𝒋𝒊𝒊Plane
Autoregression 𝒙𝒙<𝒊𝒊
𝒙𝒙<𝒋𝒋𝒊𝒊 Space
Autoregression𝑭𝑭𝒛𝒛Parameters
NetFor  𝒊𝒊≤𝒔𝒔𝑭𝑭𝒑𝒑
𝑭𝑭𝒔𝒔Color
Autoregression𝒙𝒙𝒋𝒋𝒊𝒊
𝒇𝒇𝒓𝒓,𝒇𝒇𝒈𝒈,𝒇𝒇𝒃𝒃
𝜶𝜶,𝜷𝜷,𝜸𝜸𝒑𝒑𝒓𝒓=𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬 𝒇𝒇𝒓𝒓
𝒑𝒑𝒈𝒈=𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬 𝒇𝒇𝒈𝒈+𝜶𝜶⋅𝒙𝒙𝒓𝒓
𝒑𝒑𝒃𝒃=𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬𝐬 𝒇𝒇𝒃𝒃+𝜷𝜷⋅𝒙𝒙𝒓𝒓+𝜸𝜸⋅𝒙𝒙𝒈𝒈Color Autoregression
𝑭𝑭𝒑𝒑1313
4242
1313
4242
𝒙𝒙𝒊𝒊11
1133
33
𝒙𝒙𝟏𝟏𝒊𝒊𝒙𝒙𝟑𝟑𝒊𝒊
44
4422
22
𝒙𝒙𝟒𝟒𝒊𝒊 𝒙𝒙𝟐𝟐𝒊𝒊
Entropy 
EncoderEntropy 
Encoder𝒑𝒑𝒓𝒓,𝒑𝒑𝒈𝒈,𝒑𝒑𝒃𝒃𝒑𝒑𝒓𝒓,𝒑𝒑𝒈𝒈,𝒑𝒑𝒃𝒃
𝒑𝒑𝒓𝒓
𝒑𝒑𝒈𝒈
𝒑𝒑𝒃𝒃Plane Prior Figure 1. Overview of our method: the left subfigure illustrates the encoding process. Here, sdenotes the split index. The depth of the
orange indicates the complexity of the networks in the dimension-tailored autoregression. In the encoding process, the insignificant planes
xs+1:8 are first encoded conditioned on the significant planes x1:s. Then, the posterior distribution q(z|x1:s)is obtained from x1:s. The
latent variables ˆzare obtained by decoding from the previously encoded bitstream using q(z|x1:s). Next, x1:sis encoded, conditioned on
ˆz. Finally, ˆzis encoded with prior distribution p(z). The decoding order is the reverse of the encoding process.
p(x) =p(x1)nY
i=2p(xi|x1:i−1) (1)
Latent variable models extract latent variables zfrom the
input image xto assist compression. For V AEs and contin-
uous NFs, the approach to obtain zis sampling for a poste-
rior distribution q(z|x). In this case, bits back coding [34]
is required. It encodes the image via the following steps:
Step 1: Decode zwithq(z|x)from initial bits.
Step 2: Encode xwithp(x|z).
Step 3: Encode zwithp(z).
Here, p(·)represents the prior distribution. The asymmetric
numeral system (ANS) [8], an entropy coder with a reversed
order between encoding and decoding, is required.
LBB [12] introduces local bits back, using q(z|x)to dis-
cretize continuous NFs for lossless compression. Moreover,
V AEs use neural networks to obtain q(z|x). When sequen-
tially encoding a set of images {x(1), x(2), . . . , x(N)}, bits
from previously encoded images could be used as initial bits
for the current image. For V AEs, the average code length
for encoding the image set is
¯C=1
NNX
i=1
−logp(x(i)|z(i))−logp(z(i))
+ log q(z(i)|x(i))
−1
Nlogq(z(1)|x(1))(2)
The first term, which is the Evidence Lower Bound
(ELBO), can be optimized by neural networks. The sec-
ond term can be amortized when compressing a dataset.However, when compressing a single image, the overhead
−logq(z|x)is not negligible, which limits the usage of
these methods for single-image compression. Nonetheless,
single-image compression is required for image compres-
sion applications, and it enables parallel compression when
compressing a dataset.
When combined with subimage autoregression, this
overhead could be reduced via autoregressive initial bits
(ArIB) [28]. ArIB partitions the subimage sequence into
two subsets: x1:sandxs+1:n. Latent variables are employed
exclusively for x1:s, while the bits used to compress xs+1:n
serve as initial bits. If the number of bits provided is larger
than the number of bits required, the overhead for bits back
coding is eliminated.
3.2. Bit Plane Slicing for Autoregressive Initial Bits
The current method, SHVC-ArIB [28], splits the image in
the space dimension. Its splitting ensures pixels with the
same coordinates are adjacent in the original image. Thus,
each subimage is equally important for latent variables.
This splitting causes inadequate use of latent variables, as
latent variables are excluded for some subimages that are
important for latent variables. For SHVC-ArIB, this incurs
a performance cost compared to utilizing latent variables for
all subimages. Moreover, the performance of SHVC-ArIB
is constrained by posterior collapse [21]. Posterior collapse
refers to the collapse of the posterior to the prior, indicating
that non-useful information is extracted by latent variables.
A common cause of posterior collapse is highly capable de-
coders [21]. Specifically, a strong autoregressive prior en-
hances the decoder’s capability, increasing the likelihood of
posterior collapse. Consequently, subimages positioned at
27581
Figure 2. Visualization for each bit plane. The planes are arranged
from MSP to LSP, from left-top to right-bottom. The volume of
global data modality decreases from MSP to LSP.
the end of the autoregressive sequence are in a high risk of
posterior collapse due to their strong autoregressive priors.
In SHVC-ArIB, enhancing spatial autoregression leads to
slight improvements or even a decline in performance be-
cause of posterior collapse. In this paper, we introduce bit
plane slicing (BPS) to address these issues.
Bit Plane Slicing is a well-established technique in digital
image processing. For a d-bit image, it partitions the entire
image into dbit planes. Here, each pixel intensity is repre-
sented as x, and the lthbit is represented as xl. The value
ofxlcan be determined using the following equation:
xl=⌊x/2d−l⌋mod 2 (3)
In this equation, ⌊x⌋denotes the largest integer less than
or equal to x. The original pixel value xcan be recon-
structed using the equation:
x=dX
l=12d−l×xl(4)
In this paper, we focus specifically on 8-bit images. We
define the significant planes as those with smaller lvalues,
and the insignificant planes as those with larger lvalues.
The volume of global data modality decreases from the
most significant plane (MSP) to the least significant plane
(LSP), as illustrated in Figure 2. Considering latent vari-
ables are employed to learn global data modalities [22, 28],
we hypothesize that the importance for latent variables sim-
ilarly decreases from MSP to LSP. To test this hypothesis,
we employ the latent variable model from [34] for each
bit plane. Subsequently, we evaluate the Bit Per Dimen-
sion (BPD) savings and calculate the bit rate percentage at-
tributed to latent variables within the entire subimage. The
results, illustrated in Figure 3, display a consistent descend-
ing trend from MSP to LSP, with values becoming negligi-
ble in the final few insignificant planes. This observation
corroborates our initial hypothesis.
Based on this finding, we employ BPS for ArIB. We par-
tition the image into two segments using a slice index rang-ing in {1, . . . , 8}, denoted as s. The first segment com-
prises the significant planes, represented as x1:s, while the
second segment includes the insignificant planes, denoted
asxs+1:8. Latent variables zare exclusively used for the
significant planes, while ARMs are employed for both seg-
ments. This approach enables a more adequate use of latent
variables since x1:sis more important for them. Moreover,
we introduce plane-by-plane autoregression from MSP to
LSP to enhance autoregression. As the volume of autore-
gressive prior increases along the subimage sequence, the
risk of posterior collapse intensifies sequentially. In this au-
toregression, subimages that are more important for latent
variables are placed in positions where they are less likely
to encounter posterior collapse. In comparison, SHVC-
ArIB split the image into subimages with similar impor-
tance, meaning that subimages in positions where there’s
a high risk of posterior collapse are also important for la-
tent variables. Thus, the overall risk of posterior collapse is
mitigated by our method.
The overall bit rate of the image xcan be expressed as
follows, where RsigandRinsdenote the bit rates associated
with significant and insignificant planes, respectively:
Rx=Rsig+Rins
=−logp(x1:s|z)−logp(xs+1:8|x1:s)(5)
We further propose some modifications to suit our ArIB
with BPS method.
Hierarchical Latent Variables are commonly utilized in
V AEs to improve performance. These variables are struc-
tured in a hierarchy comprising Llayers, denoted as z=
{z1, . . . , z L}. The prior probability distribution of zis fac-
torized as follows:
p(z1:L) =p(zL)L−1Y
i=1p(zi|zi+1:L) (6)
There are two methods for obtaining the posterior
q(z|x1:s): top-down, which proceeds from layer Lto layer
1, and bottom-up, which goes from layer 1to layer L. The
former has been shown to exhibit superior compression per-
formance [32, 35], while the latter can leverage the bit-swap
technique [19] to reduce the number of initial bits required.
Given that the bit rate increases from MSP to LSP [43], in-
significant planes can contribute a larger number of initial
bits. Consequently, we opt for the top-down inference mod-
els, a choice that differentiates our approach from SHVC-
ArIB. In this context, the posterior distribution can be ex-
pressed as follows:
q(z1:L|x1:s) =q(zL|x1:s)L−1Y
i=1q(zi|zi+1:L, x1:s) (7)
27582
0102030405060Percentage of Z
1 2 3 4 5 6 7 80102030405060BPD Savings(%)
Plane IndexFigure 3. BPD savings achieved using latent variables and the
bit rate percentage attributed to latent variables for each bit plane.
The results are averaged over the CIFAR10, ImageNet32, and Im-
ageNet64 [6] datasets. The importance for latent variables de-
creases from MSP to LSP.
Discretization also plays a pivotal role: a higher precision
tends to enhance compression performance but also requires
more initial bits. Given the variation in available initial bits
across different images, we propose an image-adaptive dis-
cretization strategy.
In our method, we utilize equal mass discretization [35]
for the top-down model. This ensures that all latent vari-
ables maintain equal probability mass for p(z). We define
the discretization precision k, which discretizes zwithin 2k
possible values. It is important to note that q(z|x)closely
approximates p(z), as the Kullback-Leibler divergence be-
tween them is minimized during optimization. As a result,
each element of znecessitates roughly −log(1/(2k)) = k
initial bits. Furthermore, the size of the latent variables, de-
noted as |z|, can be quantified. The bit rate Rinscan be de-
termined by measuring the length of the encoded bitstream.
Following these calculations, the precision kis derived us-
ing the equation:
k=⌊Rins
|z|⌋ (8)
For training V AEs, the bit rate of latent variables is
calculated with the condition that they are discretized to
high precision. In practical scenarios, most images ex-
hibit a sufficiently large precision value k, ensuring neg-
ligible impact on compression performance when employ-
ing discretization. Nevertheless, low precision is required
in minor cases, where the discretization hurts the compres-
sion performance. To tackle this, we propose a discretizedsampling technique for sampling latent variables for fine-
tuning. More specifically, both the prior and posterior distri-
butions are modeled using a univariate logistic distribution,
characterized by mean parameters µpandµq, respectively.
We sample ϵfrom a standard logistic distribution. The cal-
culation of a sampled latent variable ˆzand its corresponding
bit rate can be represented as follows:
tl=⌈2k·sigmoid( ϵ+µq−µp)⌉ −1,
ˆz= logittl+ 0.5
2k
+µp,
Rˆz= log(sigmoid(logittl+ 1
2k
+µp−µq)
−sigmoid(logittl
2k
+µp−µq)) +k,(9)
where ⌈x⌉signifies the smallest integer greater than or
equal to x. During back-propagation, the Straight Through
Estimator [3] is utilized to manage this operation.
3.3. Dimension-Tailored Autoregressive Model
BPS results in an increased number of dimensions for au-
toregression, specifically, the bit plane dimension. In ad-
dition to the plane dimension, we consider autoregression
in space and color dimensions, which have demonstrated
their efficacy in previous studies [26, 40]. Using a uni-
form approach to model all dimensions is employed in pre-
vious works [14]. However, this method has certain lim-
itations. First, these dimensions present uneven modeling
challenges. Employing a one-size-fits-all network to ad-
dress all dimensions directly may either compromise mod-
eling accuracy in the more complex dimensions or lead to
inefficient use of computational resources in simpler dimen-
sions. Second, strong autoregression in the space and color
dimensions can potentially lead to posterior collapse. To ad-
dress these issues, we propose a dimension-tailored autore-
gressive model that tailors the approach for each dimension
based on its specific characteristics. An overview is shown
in the right subfigures of Figure 1.
Our autoregressive model operates in three stages. In
the first stage, we focus on the plane dimension, which
presents a significant challenge due to the extensive range
of possible values that the pixels in its preceding planes,
denoted as x1:i−1, can take on, amounting to 2i−1possibil-
ities. To effectively leverage the autoregressive prior from
x1:i−1and apply it to xi, we employ a sophisticated plane
context model, Φp. To capture the global data modality em-
bedded in the preceding planes, we adopt a U-Net archi-
tecture [27]. Specifically, we use two models that employ
the architecture of diffusion models [7]: one for the signifi-
cant planes and the other for the insignificant planes. Time
embedding is used to differentiate planes.
27583
In the second stage, we address the space dimension.
Compared to the plane dimension, this dimension is less
complex, as each bit in the current bit plane can only take
one of two possible values. We adopt a 4-stage checker-
board model [9, 26], which involves dividing the bit plane
xiinto four sub-planes, denoted as xi
1, xi
2, xi
3, xi
4, as illus-
trated in Figure 1. For each sub-plane xi
j, we utilize a sim-
ple network, Φs, to extract the spatial autoregressive prior
Fsfrom xi
1:j−1. Then, a parameter network Θis used to
fuse information from both the plane and space dimensions.
To effectively integrate information, we employ a relatively
complex network for Θ. Although the complexity of Θ
does contribute to the overall computational demand of our
model, the complexity remains significantly lower than that
of employing the architecture of Φpfor both dimensions, re-
sulting in a more efficient modeling process. More specif-
ically, Φsis a single ResBlock [11], and Θcombines an
ECANet [39] with several wider ResBlocks.
The third stage is for the color dimension. As identified
in PixelCNN++ [29], the correlations among the color chan-
nels of a pixel are typically straightforward, and deep net-
works are often unnecessary for their modeling. Therefore,
we adopt a non-network approach for the color dimension.
Specifically, we model the distribution of bits in each color
channel using a Bernoulli distribution, where the probabil-
ity parameter p=P(x= 1) is determined autoregressively
based on the bits with the same spatial position in previously
decoded channels. In our method, Θpredict six parameters
θ={fr, fg, fb, α, β, γ }, and model the probability for each
channel as follows:
pr= sigmoid( fr)
pg= sigmoid( fg+α·xr)
pb= sigmoid( fb+β·xr+γ·xg)(10)
The 1st and 2nd stages of our dimension-tailored autore-
gressive model can be expressed as follows:
Fpi= Φ p(x1:i−1)
Fsi
j= Φ s(xi
1:j−1)
θi
j=(Θ(Fpi, Fsi
j, Fz), i≤s
Θ(Fpi, Fsi
j), i > s(11)
In summary, we initially derive Fpfor the entire bit
plane. Subsequently, for each of the four subimages in the
bit plane, we compute Fs. These are then concatenated with
FpandFz(only for significant planes) and fed into Θto de-
termine the six parameters θ. Finally, we calculate the prob-
ability using non-network color autoregression as outlined
in Equation 10.
Loss function of our method is expressed as:
l=Rz+Rx
=−logp(z) + log q(z|x1:s) +Rx(12)4. Experiments
4.1. Architecture and Training Details
In accordance with prior research, our experimental
setup entails training three models using three benchmark
datasets: CIFAR10, ImageNet32, and ImageNet64 [6]. For
all models, we set the split index, s, to4, based on Figure
3, and utilize 3 layers of hierarchical latent variables. For
latent variables, we apply a factor 2 downsampling for each
hierarchy of latent variables in latent encoders. The channel
number for latent variables is set to 3 across all models. For
Φp, the number of hierarchical levels in the U-Net is set to
4 across all models.
We utilize the Adam optimizer [18] with an initial learn-
ing rate of 0.0001, and we apply step decay as the learning
rate schedule. For fine-tuning with discretized sampling, we
employ Equation 8 with the previously trained model to ob-
tain the precision kfor each image in the training set. All
experiments are conducted on a GeForce GTX 1080 Ti.
4.2. Compression Performance
We evaluate the performance of our method across four dis-
tinct datasets: CIFAR10, ImageNet32, ImageNet64, and
DIV2K [1], using bits per dimension (BPD) as our primary
metric. The first three datasets are of low resolution, while
the last one, DIV2K, is a high-resolution dataset. Following
most previous works, we exclude per-pixel autoregressive
methods [29, 37] and diffusion models [14, 17] from our
evaluation due to their impractical time complexity.
Our method evaluates performance in two distinct com-
pression settings: dataset compression and single-image
compression. In dataset compression, we sequentially com-
press 5,000 images with a fixed discretization precision of
10. For single-image compression, each image’s kvalue is
calculated using Equation 8 and clipped between 3 and 10.
If the calculated kis less than 3, additional (3−k)×|z|(|z|
represents the size of z) bits are added to ensure success-
ful encoding. These possible bits, along with the kvalue
and image bits, are written to a bitstream. The single im-
age compression performance is determined by measuring
the bitstream size. Following [28, 41, 42], we evaluate the
performance on the DIV2K dataset using the model trained
on ImageNet64 by cropping images into 64 × 64 patches.
We compare our method against advanced approaches
from traditional methods, learned methods without bits
back coding, and learned methods with bits back coding.
We present the detailed results of our experiments in Ta-
ble 1. Our method demonstrates superior compression per-
formance, particularly in single-image compression. In
dataset compression, our method excels in three out of
four datasets, achieving the second-best performance on
the remaining dataset. In single-image compression, our
method outperforms other methods in all datasets. We note
27584
Table 1. Compression performance in BPD for four datasets, where lower values indicate better performance. The best performance is
highlighted in bold.∗: ImageNet32 ,∗∗: ImageNet64,+: Flickr2k [33],−: OpenImage [20]. 1st Group: traditional methods, 2nd Group:
learned methods without bits back coding, 3rd Group: learned methods with bits back coding. Some values of SHVC and SHVC-ArIB are
not available, and we list their available lower bound here.∆: These values are obtained by adding dataset performance and initial bits.
Dataset Compression Single-Image Compression
Method CIFAR10 ImageNet32 ImageNet64 DIV2K CIFAR10 ImageNet32 ImageNet64 DIV2K
PNG [5] 5.89 6.39 5.74 4.23 5.89 6.39 5.74 4.23
FLIF [31] 4.19 4.52 4.54 2.91 4.19 4.52 4.54 2.91
JPEG-XL [2] 5.74 6.39 5.89 2.79 5.74 6.39 5.89 2.79
L3C [22] - 4.76 4.42 3.09−- 4.76 4.42 3.09−
IDF [13] 3.34 4.18 3.90 - 3.34 4.18 3.90 -
IDF++ [36] 3.26 4.12 3.81 - 3.26 4.12 3.81 -
LC-FDNet [26] 3.77+4.40+4.28+2.71+3.77+4.40+4.28+2.71+
Bit-Swap [19] 3.82 4.50 - - 6.53 6.97 - -
Hilloc [35] 3.56∗4.20 3.90∗- - - - -
SHVC [28] 3.16 3.98 3.68 2.57∗∗>3.96 >4.78 >4.48 -
SHVC-ArIB [28] >3.16 >3.98 >3.68 - >3.16 >3.98 >3.68 -
iVPF [42] 3.20 4.03 3.75 2.68∗∗9.20∆- - -
LBB [12] 3.12 3.88 3.70 - 42.98∆49.84∆41.70∆-
iFlow [41] 3.12 3.88 3.70 2.57∗∗37.40∆38.27∆38.12∆-
ArIB-BPS (ours) 3.06 3.91 3.63 2.55∗∗3.07 3.92 3.64 2.59∗∗
Table 2. Comparison with advanced and available flow-based methods. The batchsize is 64 following LBB and iFlow. We train the small
model to align with the inference speed of iFlow on ImageNet64.
Compression Performance (BPD) ↓Inference Time (ms/sample) ↓
dataset Method theoretical dataset single encode decode
CIFAR10LBB [12] 3.116 3.118 42.978 64.94 64.94
iFlow [41] 3.116 3.118 37.398 17.38 47.56
ArIB-BPS 3.048 3.057 3.070 14.93 14.93
ImageNet32LBB [12] 3.871 3.875 49.835 194.14 194.14
iFlow [41] 3.871 3.873 38.273 74.84 119.30
ArIB-BPS 3.904 3.911 3.918 52.96 52.96
ImageNet64LBB [12] 3.701 3.703 41.703 95.57 95.57
iFlow [41] 3.701 3.703 38.123 37.49 58.08
ArIB-BPS (Small) 3.677 3.685 3.693 43.65 43.65
ArIB-BPS 3.624 3.633 3.641 107.80 107.80
that precise values for the single-image compression perfor-
mance of SHVC, as well as the compression performance of
SHVC-ArIB, are not available. However, the lower bound
could be obtained. Moreover, it could be inferred that our
method surpasses SHVC-ArIB by an average of more than
0.10 BPD on low-resolution datasets in both compression
settings. Additional details are provided in the Appendix.
To further demonstrate the effectiveness of our approach,
we conducted a detailed comparison between our method
and continuous normalizing-flow-based methods, which ex-
hibit state-of-the-art performance in dataset compression.
As Table 2 illustrates, ArIB-BPS outperforms iFlow in both
single-image and dataset compression performance for CI-
FAR10 and ImageNet64, with comparable inference time.For ImageNet32, although ArIB-BPS lags slightly behind
in dataset compression performance, it excels in other met-
rics, particularly in single-image compression. These re-
sults imply that our method achieves a better trade-off be-
tween compression performance and inference speed.
4.3. Ablation Studies
We conduct three ablation studies on the CIFAR10 dataset
to show the efficiency of our dimension-tailored autoregres-
sive model and the effectiveness of discretized sampling.
We note that results in Table 3 and 4 are evaluated using
models without using discretized sampling for fine-tuning.
Therefore, the results of ArIB-BPS are slightly different
from those in Table 2.
27585
Table 3. Ablation for the effectiveness of autoregression on plane,
space, and color dimensions. Inference time is identical for encod-
ing and decoding. The batchsize is 64.
plane space colorTheoretical
BPD↓Inference Time
(ms/sample) ↓
✓ ✓ ✓ 3.052 14.93
✓ ✓ 3.458 14.92
✓ ✓ 3.470 10.36
✓ ✓ 3.522 5.83
Table 4. Compression performance and inference time of various
usages of the architecture of Φp. The batch size is 64. P: plane. S:
space. C: color. Sig: significant planes. Ins: insignificant planes.
We also train two small models to further validate our design.
Theoretical
BPD↓Inference Time
(ms/sample) ↓
Sig Ins Total Sig Ins Total
P (Ours) 1.041 2.011 3.052 6.30 8.64 14.93
PS 1.052 1.993 3.045 14.46 24.97 39.42
PSC 1.043 1.971 3.015 43.83 74.97 118.80
PS (Small) 1.055 2.070 3.125 9.08 11.44 20.51
PSC (Small) 1.096 2.218 3.314 9.64 13.96 23.59
4.3.1 Dimension-Tailored Autoregressive Model
Firstly, we conduct experiments to assess the impact of au-
toregression in each dimension. To do this, we train and
evaluate three additional models, each with autoregression
removed in either the color, space, or plane dimension.
In the model that does not incorporate plane autoregres-
sion, we employ the color autoregressive model from Pix-
elCNN++ [29] to ensure compatibility. Additionally, we
enhance Φsby employing the architecture of Φp, accom-
modating the increased complexity in the spatial dimension,
which now has 256 possible values per pixel instead of just
2. In our experiments, this configuration results in improved
performance. Table 3 clearly demonstrates that incorporat-
ing autoregression in each dimension consistently leads to
significant improvements in compression performance. We
note that our autoregression for the color dimension incurs
only a negligible overhead in inference time.
Furthermore, we conduct an evaluation to assess the ef-
ficiency of our dimension-tailored design. Specifically, we
train two additional models: one using the architecture of
Φpfor both the plane and space dimensions and the other
using the architecture of Φpfor all three dimensions. Sub-
sequently, we evaluate the impact of these modifications
on significant and insignificant planes separately. As de-
picted in Table 4, the dimension-tailored autoregressive
model achieves superior performance in significant planes
with lower complexity. This superiority is attributed to re-
duced hindrance to the latent variables, facilitated by sim-
3 4 5 6 7 8 9 100.000.020.040.060.080.10bpd saving
precisionFigure 4. Average BPD savings through fine-tuning using dis-
cretized sampling across various discretization precisions.
pler spatial autoregression and color-wise autoregression, as
reflected in higher bit rates for latent variables. In the case
of insignificant planes, although strengthened autoregres-
sion can lead to performance gains, it results in significantly
longer inference time. To further validate our method’s ef-
ficiency, we train two small models with reduced inference
time. Our method demonstrates better compression perfor-
mance. Considering the trade-off between inference time
and compression performance, our design is more efficient.
4.3.2 Discretized Sampling
We assess the performance improvement after fine-tuning
across various kvalues, as illustrated in Figure 4. The
method improves performance across all precision values,
particularly at lower precision levels. While low-precision
cases form a minor segment, their optimization boosts per-
formance in edge cases.
5. Conclusion
We have proposed ArIB-BPS, a new approach for loss-
less image compression. BPS enables us to achieve ade-
quate use of latent variables as well as enhanced autoregres-
sion in a mitigated risk of posterior collapse by arranging
subimages with decreasing importance for latent variables.
In addition, we present a dimension-tailored autoregressive
model that takes into account the different characteristics
of each dimension. It efficiently captures dependencies in
space, color, and plane dimensions. Experimental results
demonstrate that our method achieves superior compression
performance compared to the state-of-the-art normalizing-
flow-based methods with comparable inference time.
The limitation of our work lies in the complexity of
higher bit-depth. The complexity of our method would in-
crease as the bit-depth increases due to the interdependency
among bit planes. To extend our method for high-bit-depth
images, efficient strategies such as handling multiple planes
in one step should be explored in our future work.
27586
References
[1] Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge
on single image super-resolution: Dataset and study. In The
IEEE Conference on Computer Vision and Pattern Recogni-
tion Workshops , 2017. 6
[2] Jyrki Alakuijala, Ruud Van Asseldonk, Sami Boukortt, Mar-
tin Bruse, Iulia-Maria Coms ,a, Moritz Firsching, Thomas Fis-
chbacher, Evgenii Kliuchnikov, Sebastian Gomez, Robert
Obryk, et al. Jpeg xl next-generation image compression ar-
chitecture and coding tools. In Applications of Digital Image
Processing XLII , pages 112–124. SPIE, 2019. 7
[3] Yoshua Bengio, Nicholas L ´eonard, and Aaron Courville.
Estimating or propagating gradients through stochastic
neurons for conditional computation. arXiv preprint
arXiv:1308.3432 , 2013. 5
[4] Sam Bond-Taylor, Adam Leach, Yang Long, and
Chris George Willcocks. Deep generative modelling:
A comparative review of vaes, gans, normalizing flows,
energy-based and autoregressive models. IEEE Transactions
on Pattern Analysis and Machine Intelligence , 2021. 1
[5] Thomas Boutell. Png (portable network graphics) specifica-
tion version 1.0. Technical report, 1997. 7
[6] Patryk Chrabaszcz, Ilya Loshchilov, and Frank Hutter. A
downsampled variant of imagenet as an alternative to the ci-
far datasets. arXiv preprint arXiv:1707.08819 , 2017. 5, 6
[7] Prafulla Dhariwal and Alexander Nichol. Diffusion models
beat gans on image synthesis. Advances in Neural Informa-
tion Processing Systems , 34:8780–8794, 2021. 5
[8] Jarek Duda. Asymmetric numeral systems. arXiv preprint
arXiv:0902.0271 , 2009. 3
[9] Dailan He, Yaoyan Zheng, Baocheng Sun, Yan Wang,
and Hongwei Qin. Checkerboard context model for effi-
cient learned image compression. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 14771–14780, 2021. 2, 6
[10] Dailan He, Ziming Yang, Weikun Peng, Rui Ma, Hongwei
Qin, and Yan Wang. Elic: Efficient learned image compres-
sion with unevenly grouped space-channel contextual adap-
tive coding. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 5718–
5727, 2022. 2
[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition , pages 770–778, 2016. 6
[12] Jonathan Ho, Evan Lohn, and Pieter Abbeel. Compression
with flows via local bits-back coding. Advances in Neural
Information Processing Systems , 32, 2019. 1, 2, 3, 7
[13] Emiel Hoogeboom, Jorn Peters, Rianne Van Den Berg, and
Max Welling. Integer discrete flows and lossless compres-
sion. Advances in Neural Information Processing Systems ,
32, 2019. 1, 7
[14] Emiel Hoogeboom, Alexey A Gritsenko, Jasmijn Bastings,
Ben Poole, Rianne van den Berg, and Tim Salimans. Au-
toregressive diffusion models. In International Conference
on Learning Representations , 2022. 1, 2, 5, 6[15] Seungmin Jeon, Kwang Pyo Choi, Youngo Park, and Chang-
Su Kim. Context-based trit-plane coding for progressive im-
age compression. In Proceedings of the IEEE/CVF Con-
ference on Computer Vision and Pattern Recognition , pages
14348–14357, 2023. 2
[16] Ning Kang, Shanzhao Qiu, Shifeng Zhang, Zhenguo Li, and
Shu-Tao Xia. Pilc: Practical image lossless compression
with an end-to-end gpu oriented neural framework. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition , pages 3739–3748, 2022. 2
[17] Diederik Kingma, Tim Salimans, Ben Poole, and Jonathan
Ho. Variational diffusion models. Advances in Neural Infor-
mation Processing Systems , 34:21696–21707, 2021. 1, 6
[18] Diederik P Kingma and Jimmy Ba. Adam: A method for
stochastic optimization. arXiv preprint arXiv:1412.6980 ,
2014. 6
[19] Friso Kingma, Pieter Abbeel, and Jonathan Ho. Bit-swap:
Recursive bits-back coding for lossless compression with hi-
erarchical latent variables. In International Conference on
Machine Learning , pages 3408–3417, 2019. 1, 2, 4, 7
[20] Ivan Krasin, Tom Duerig, Neil Alldrin, Vittorio Ferrari, Sami
Abu-El-Haija, Alina Kuznetsova, Hassan Rom, Jasper Ui-
jlings, Stefan Popov, Andreas Veit, Serge Belongie, Vic-
tor Gomes, Abhinav Gupta, Chen Sun, Gal Chechik, David
Cai, Zheyun Feng, Dhyanesh Narayanan, and Kevin Mur-
phy. Openimages: A public dataset for large-scale multi-
label and multi-class image classification. Dataset available
from https://github.com/openimages , 2017. 7
[21] James Lucas, George Tucker, Roger B Grosse, and Moham-
mad Norouzi. Don’t blame the elbo! a linear vae perspective
on posterior collapse. Advances in Neural Information Pro-
cessing Systems , 32, 2019. 1, 3
[22] Fabian Mentzer, Eirikur Agustsson, Michael Tschannen,
Radu Timofte, and Luc Van Gool. Practical full resolu-
tion learned lossless image compression. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 10629–10638, 2019. 1, 2, 4, 7
[23] Fabian Mentzer, Luc Van Gool, and Michael Tschannen.
Learning better lossless compression using lossy compres-
sion. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition , pages 6638–6647,
2020. 2
[24] David Minnen and Saurabh Singh. Channel-wise autoregres-
sive entropy models for learned image compression. In 2020
IEEE International Conference on Image Processing , pages
3339–3343. IEEE, 2020. 2
[25] David Minnen, Johannes Ball ´e, and George D Toderici.
Joint autoregressive and hierarchical priors for learned im-
age compression. Advances in Neural Information Process-
ing Systems , 31, 2018. 2
[26] Hochang Rhee, Yeong Il Jang, Seyun Kim, and Nam Ik
Cho. Lc-fdnet: Learned lossless image compression with
frequency decomposition network. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 6033–6042, 2022. 2, 5, 6, 7
[27] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-
net: Convolutional networks for biomedical image segmen-
27587
tation. In International Conference on Medical Image Com-
puting and Computer-assisted Intervention , pages 234–241.
Springer, 2015. 5
[28] Tom Ryder, Chen Zhang, Ning Kang, and Shifeng Zhang.
Split hierarchical variational compression. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 386–395, 2022. 1, 2, 3, 4, 6, 7
[29] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P.
Kingma. PixelCNN++: Improving the pixelCNN with dis-
cretized logistic mixture likelihood and other modifications.
InInternational Conference on Learning Representations ,
2017. 1, 2, 6, 8
[30] Claude Elwood Shannon. A mathematical theory of commu-
nication. The Bell System Technical Journal , 27(3):379–423,
1948. 1
[31] Jon Sneyers and Pieter Wuille. Flif: Free lossless image for-
mat based on maniac compression. In IEEE International
Conference on Image Processing , pages 66–70. IEEE, 2016.
7
[32] Casper Kaae Sønderby, Tapani Raiko, Lars Maaløe,
Søren Kaae Sønderby, and Ole Winther. Ladder variational
autoencoders. Advances in Neural Information Processing
Systems , 29, 2016. 4
[33] Radu Timofte, Eirikur Agustsson, Luc Van Gool, Ming-
Hsuan Yang, and Lei Zhang. Ntire 2017 challenge on single
image super-resolution: Methods and results. In Proceed-
ings of the IEEE Conference on Computer Vision and Pattern
Recognition Workshops , pages 114–125, 2017. 7
[34] James Townsend, Thomas Bird, and David Barber. Practi-
cal lossless compression with latent variables using bits back
coding. In International Conference on Learning Represen-
tations , 2018. 1, 2, 3, 4
[35] James Townsend, Thomas Bird, Julius Kunze, and David
Barber. Hilloc: lossless image compression with hierarchi-
cal latent variable models. In International Conference on
Learning Representations , 2019. 1, 2, 4, 5, 7
[36] Rianne van den Berg, Alexey A Gritsenko, Mostafa De-
hghani, Casper Kaae Sønderby, and Tim Salimans. Idf++:
Analyzing and improving integer discrete flows for lossless
compression. In International Conference on Learning Rep-
resentations , 2020. 7
[37] A ¨aron van den Oord, Nal Kalchbrenner, and Koray
Kavukcuoglu. Pixel recurrent neural networks. In Pro-
ceedings of The 33rd International Conference on Machine
Learning , pages 1747–1756, 2016. 1, 2, 6
[38] Kai Wang, Yuanchao Bai, Deming Zhai, Daxin Li, Junjun
Jiang, and Xianming Liu. Learning lossless compression
for high bit-depth medical imaging. In 2023 IEEE Inter-
national Conference on Multimedia and Expo , pages 2549–
2554. IEEE, 2023. 2
[39] Qilong Wang, Banggu Wu, Pengfei Zhu, Peihua Li, Wang-
meng Zuo, and Qinghua Hu. Eca-net: Efficient channel at-
tention for deep convolutional neural networks. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , pages 11534–11542, 2020. 6
[40] Honglei Zhang, Francesco Cricri, Hamed R Tavakoli, Nan-
nan Zou, Emre Aksu, and Miska M Hannuksela. Losslessimage compression using a multi-scale progressive statistical
model. In Proceedings of the Asian Conference on Computer
Vision , 2020. 5
[41] Shifeng Zhang, Ning Kang, Tom Ryder, and Zhenguo Li.
iflow: Numerically invertible flows for efficient lossless
compression via a uniform coder. Advances in Neural In-
formation Processing Systems , 34:5822–5833, 2021. 1, 2, 6,
7
[42] Shifeng Zhang, Chen Zhang, Ning Kang, and Zhenguo Li.
ivpf: Numerical invertible volume preserving flow for effi-
cient lossless compression. In Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition ,
pages 620–629, 2021. 1, 6, 7
[43] Zhizheng Zhang, Zhibo Chen, Jianxin Lin, and Weiping Li.
Learned scalable image compression with bidirectional con-
text disentanglement network. In IEEE International Con-
ference on Multimedia and Expo , pages 1438–1443. IEEE,
2019. 4
27588
