Distilled Datamodel with Reverse Gradient Matching
Jingwen Ye Ruonan Yu Songhua Liu Xinchao Wang†
National University of Singapore
jingweny@nus.edu.sg, {ruonan,songhua.liu }@u.nus.edu, xinchao@nus.edu.sg
Abstract
The proliferation of large-scale AI models trained on ex-
tensive datasets has revolutionized machine learning. With
these models taking on increasingly central roles in var-
ious applications, the need to understand their behavior
and enhance interpretability has become paramount. To in-
vestigate the impact of changes in training data on a pre-
trained model, a common approach is leave-one-out re-
training. This entails systematically altering the training
dataset by removing specific samples to observe resulting
changes within the model. However, retraining the model
for each altered dataset presents a significant computa-
tional challenge, given the need to perform this operation
for every dataset variation. In this paper, we introduce
an efficient framework for assessing data impact, compris-
ing offline training and online evaluation stages. During
the offline training phase, we approximate the influence of
training data on the target model through a distilled synset,
formulated as a reversed gradient matching problem. For
online evaluation, we expedite the leave-one-out process
using the synset, which is then utilized to compute the at-
tribution matrix based on the evaluation objective. Ex-
perimental evaluations, including training data attribution
and assessments of data quality, demonstrate that our pro-
posed method achieves comparable model behavior evalu-
ation while significantly speeding up the process compared
to the direct retraining method.
1. Introduction
In the contemporary landscape of machine learning and
artificial intelligence, our substantial reliance on large-
scale training data has become increasingly pronounced.
The notable successes of large AI models like GPT-3 [7],
BERT [10], and DALL-E [33] can predominantly be at-
tributed to the availability of extensive datasets, enabling
them to discern complex patterns and relationships. As
AI models progressively embrace a data-driven paradigm,
†Corresponding author.comprehending the notion of “training data attribution”
within a machine learning framework emerges as pivotal. It
is imperative to acknowledge that model errors, biases, and
the overall capabilities of these systems are frequently inter-
twined with the characteristics of the training data, making
the enhancement of training data quality a reliable avenue
for bolstering model performance.
Despite the various techniques available for interpret-
ing models’ decision-making processes, the very most of
them concentrate on assessing the significance of fea-
tures [29, 35, 40] and explaining the internal representations
of models [3, 14, 20, 48]. When examining the attribution
of training data, a persistent dilemma surfaces, one that re-
volves around the delicate balance between computational
demands and effectiveness. On one hand, techniques like
influence approximation [16, 21] prioritize computational
efficiency, but they may exhibit unreliability, especially in
non-convex environments. Concurrently, another line of re-
search has achieved remarkable progress in approximating
the impact of even minor alterations, such as the removal of
a single data point or a small subset from the complete train-
ing set, on the trained model [32, 47]. These methods, how-
ever, are tailored specifically for scenarios involving minor
changes in the training data, lacking the necessary flexibil-
ity for broader applications.
In this study, we prioritize flexibility and robustness by
opting to retrain the model using a dataset that excludes
specific data points. Subsequently, we compare the newly
trained models with the original model. The attribution ma-
trix is then computed based on the specific objectives of
model evaluation. Specifically, to effectively and explic-
itly study the newly trained models, we introduce in this
paper a novel Distilled Datamodel framework (DDM). The
DDM framework is centered around the estimation of pa-
rameters for the newly trained models, rather than solely
focusing on the evaluation of prediction performance at a
specific test point. This approach grants the flexibility to an-
alyze various aspects of model behavior and performance.
As is shown in Fig. 1, DDM encompasses two distinct pro-
cesses: offline training and online evaluation. During of-
fline training, we distilled the influence of the training data
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
11954
back to the input space to get a rather small synset, a process
achieved through reversed gradient matching. We contend
that this novel reversed gradient matching approach, when
compared to the standard gradient matching [55], is more
effective in afterward mitigating the influence of specific
training data on the target network. During online evalu-
ation, we perturbed the synset by deleting, which, along
with the target network, is leveraged to quickly train the
new model. With all the newly trained networks, the attri-
bution matrix can be easily obtained for different evaluation
objectives. In a word, our contributions are:
• We explore a training data attribution framework that ex-
plicitly identifies a training sample’s responsible for var-
ious behaviors exhibited by the target model. By quanti-
fying the impact and contribution of individual samples,
our framework provides insights into the relationship be-
tween the training data and the model.
• We introduce a novel influence-based dataset distillation
scheme that matches the reversed gradient update, which
results in a highly efficient unlearning of certain data
points from the target network.
• Experimental results demonstrate that the proposed anal-
ysis method provides an accurate interpretation and
achieves a significant speedup compared to its unlearning
counterpart.
2. Related Work
2.1. Data-based Model Analysis
Model behavior analysis has emerged as a foundational as-
pect of machine learning and artificial intelligence research
and development, often categorized into training data based
and testing data based methods
Testing data based methods focus on elucidating the
model’s inference capabilities for for a certain input. Plenty
researches [1, 2, 9, 13, 34, 41, 42, 44–46, 52, 56] contribute
to this field of research.
In this study, our primary focus is on analyzing the
model’s behavior based on its training data, with one key
approach being the utilization of influence approximation
techniques as demonstrated by prior research [4, 16, 21, 37].
As pointed out by the authors, these approaches primarily
focus on local changes that are infinitesimally-small , which
are also extremely time consuming. Datamodels [19] is pro-
posed for analyzing the behavior of a model class in terms
of the training data, which measures the correlation between
true model outputs and attribution-derived predictions for
those outputs. Following this work, ModelPred [53] is pro-
posed for predicting the trained model parameters directly
instead of the trained model behaviors. Nevertheless, both
these methods still entail the training of a considerable num-
ber of models, often in the thousands or tens of thousands,
for effectiveness. In this work, we investigate a more effi-cient framework to facilitate this process.
2.2. Machine Unlearning
The concept of unlearning is firstly introduced by Bourtoule
et al. [5], which aims to eliminate the effect of data point(s)
on the already trained model. Along this line, machine un-
learning has attracted more attentions, of which the existing
approaches can be roughly divided into exact [5, 6, 8, 15]
methods and approximate methods [6, 18, 30, 39, 49, 50].
Exact methods decrease the time it takes to ex-
actly/directly retrain the models. Bourtoule et al. [5] pro-
pose an unlearning framework that when data needs to be
unlearned, only one of the constituent models whose shards
contains the point to be unlearned needs to be retrained.
Cao et al. [8] transform learning algorithms used by a sys-
tem into a summation form and to forget a training data
sample, they simply update a small number of summations.
DaRE trees [6] are proposed to enable the removal of train-
ing data with minimal retraining, which cache statistics at
each node and training data at each leaf to update only the
necessary subtrees as data is removed. Unlike the exact
methods, the approximate ones try to find a way to approx-
imate the retraining procedure. To minimize the retrain-
ing time, data removal-enabled forests [6] are introduced
as a variant of random forests, which delete data orders of
magnitude faster than retraining from scratch while sacri-
ficing little to no predictive power. Nguyen et al. [30] study
the problem of approximately unlearning a Bayesian model
from a small subset of the training data to be erased.
The above unlearning methods focus more on balancing
the accuracies and the efficiency. Here we focus more on the
efficiency, which model the network behavior for analyzing
the attributions of a target model.
2.3. Dataset Distillation
Dataset condensation/distillation [25–28, 51, 54] aims to
condense a large training set into a small synthetic set to
obtain the highest generalization performance with a model
trained on such small set of synthetic images. Zhao et al.
[54] formulate the goal as a gradient matching problem be-
tween the gradients of deep neural network weights that
are trained on the original and the synthetic data. Zhou et
al. [57] address these challenges of significant computation
and memory costs by neural feature regression with pool-
ing. Nguyen et al. [31] apply a distributed kernel-based
meta-learning framework to achieve state-of-the-art results
for dataset distillation using infinitely wide convolutional
neural networks. Sucholutsky et al. [43] propose to simul-
taneously distill both images and their labels, thus assigning
each synthetic sample a ‘soft’ label.
Different from the previous data condensation methods,
we tend to use the fast convergence and the gradient match-
ing properties for the analysis of the target network. Thus,
11955
TargetNetTrain
OfflineTrainingOnlineEvaluationNormalTraining
…TrainsetDistillSynset…
…𝑘Clusters𝒟𝒟!𝒟"𝒟#𝒮!𝒮"𝒮#Reverse Gradientmatching
…Synset𝒮!𝒮"𝒮#
Perturb
/
/……Attribution Matrix{𝑊!,𝑊",…,𝑊#}Compute
𝒮$
/Leave-one-outRetraining
StoreEvaluationObjectiveFigure 1. The framework of the proposed distilled datamodel. During the offline training, the synset is distilled during the normal training
of target network. As for online evaluation we perturb the learned synset and fast learn the perturbed model set, which is computed to form
the final attribution matrix.
we focus on how to model the data’s impact on the network
not just for improving the accuracies.
3. Proposed Method
In this paper, we propose the distilled datamodel frame-
work to build the training data attribution to evaluate var-
ious model behaviors.
3.1. Problem Statement
Given a target model Mtrained on dataset D, we tend to
construct direct relationship between them, which is de-
noted as the attribution matrix W. Each weight in Wmea-
sures the responsible of the corresponding training points
on certain behaviors of M.
The attribution matrix Wlearned by the proposed DDM
framework works on various behaviors, which include but
not limited to:
•Model functionality analysis. This involves evaluating
the performance of the target network using the training
data. This could include measuring key metrics such as
accuracy, precision, recall, and F1 score, and comparing
the results to established benchmarks or industry stan-
dards.
•Model diagnose. This involves examining the errors
made by the target network when processing the train-
ing data. This could include identifying the types of er-
rors made, such as misclassifications or false positives,
and determining the root cause of the errors, such as data
quality issues or model limitations.
•Influence function of certain test samples. This traces
a model’s prediction through the learning algorithm and
back to its training data, thereby identifying training
points most responsible for a given prediction.In what follows, we take studying the model behavior on
the influence of certain test samples as an example, show-
ing how to learn the corresponding training data attribution
with the proposed DDM framework. We would also include
more details on studying other kinds of model behaviors in
the supplementary.
Note that in Fig. 1, the proposed DDM framework intro-
duces a two-step process:
•Offline Training (Sec. 3.2): This step is learned only
once and can be integrated into network training. Its ob-
jective is to distill and store data influence with improved
approximation and reduced storage requirements.
•Online Evaluation (Sec. 3.3): This phase involves eval-
uation to meet specific requirements for model behavior
analysis, which is realized by perturbing the dataset. The
primary goal is to compute the training data attribution
matrix while minimizing time and computational costs.
3.2. Offline Training
During the offline training, we tend to obtain the synset
S(|S| ≪ |D| ) to distill the training data influence from
the target network M, so as to produce the parameters
of the network with perturbed dataset. To begin with,
we cluster the original training data DintoKgroups as
{D1,D2, ...,DK}, with the consideration that the existing
of single data point won’t be able to make much difference
on the behaviors of the target network M. So it’s more
meaningful to build the cluster-level training data attribu-
tion under this circumstance.
Here the target network is initialized with parameters θ0
and subsequently trained on the dataset Dforτepochs, and
the synset is for finetuning the trained target network for
Tepochs, resulting in updated parameters θτand˜θT. The
11956
objective is formulated as:
A(D):θτ=arg min
θL(θ,D)=arg min
θX
kL(θ,Dk),
U(Dκ)=A([
k̸=κDk) :θκ
τ= arg min
θX
k̸=κL(θ,Dk),
F(Sκ) :˜θκ
T= arg min
θL(θ,Sκ),
s.t.Sκ= arg min
Sκ,|Sκ|≪|D κ|
Dist(θκ
τ,˜θκ
τ)
,(1)
where κ={1,2, ..., K}andL(·,·)is the loss for training
the target network M.Astands for the learning process
withτepochs, Ustands for the unlearning process (equiv-
alent to training without the unlearn set with τepochs), F
stands for the fine-tuning process starting with ˜θ0←θτ
withTepochs. The synset S={S1,S2, ...,SK}is ex-
tremely small in scale comparing with the original dataset
D. To achieve this goal, our approach involves the mini-
mization of the distribution distance, denoted as Dist(,),
between the parameters of the synset fine-tuned model ˜θκ
τ,
and the directly unlearned parameters θκ
τ.
Assuming that the target network parameters are up-
dated through stochastic gradient descent for t= 1,2, ..., τ
epochs with a learning rate ηa, and the finetuning process
of the target network spans t= 1,2, ..., T epochs with a
learning rate ηf, we can reformulate the problem based on
Eq. 1 as follows:
θt+1←θt−ηa∇L(θt,D),
θκ
t+1←θκ
t−ηaX
k̸=κ∇L(θκ
t,Dk)w.r.t. θκ
0=θ0,
˜θκ
t+1←˜θκ
t−ηf∇L(˜θκ
t,Sk)w.r.t. ˜θκ
0=θτ,(2)
where ∇Lis the gradient computed on θ. Based on it, we
simplify the problem by setting η=ηa=ηfandτ=T.
In this way, we accumulate the gradients in the learning and
finetuning process as:
θτ=θ0−ηX
t∇L(θt,D),
θκ
τ=θ0−ηX
tX
k̸=κ∇L(θκ
t,Dk),
=θ0−ηX
t
∇L(θt,D)− ∇L (θκ
t,Dκ)
,
˜θκ
τ=θτ−ηX
t∇L(˜θκ
t,Sκ).(3)
Note that our goal is to make ˜θκ
τ≈θκ
τ, then Eq. 3 can be
further simplified as:
−X
t∇L(˜θκ
t,Sκ) =X
t∇L(θκ
t,Dκ),(4)
𝜃"𝜃#𝜃-𝜃$%&#𝜃$%&MinimizeLearnFinetuneFigure 2. The proposed reverse gradient matching process. The
synset is optimized by the reverse gradients.
given that ˜θκ
0=θτandθκ
0=θ0, the sufficient solution to
Eq. 4 is:
∇L(˜θκ
τ−t,Sκ) =−∇L (θκ
t,Dκ),
⇒X
κ∇L(˜θκ
τ−t,Sκ) =−X
κ∇L(θκ
t,Dκ),
⇒X
κ∇L(θτ−t,Sκ) =−X
κ∇L(θt,Dκ),(5)
where the synset in our proposed DDM is learnt for match-
ing the reverse training trajectory while training the target
network initialized from θ0toθτ. This reverse gradient
matching process is depicted in Fig. 2. Thus, synset Shere
is for predicting the parameters of the target network M
that unlearns the κ-th data cluster Dκ, which is achieved by
directly finetuning the target network with the synset S.
We constrain the scale of the synset to ensure efficient
storage and fine-tuning process. Motivated by the idea
of dataset condensation [55] with gradient matching, we
propose the reverse gradient matching to distill and store
the gradient information to a couple of synthetic images S
(|S| ≪ |D| ). The synset Sis optimized by:
arg min
|S|=K×ipcX
tX
κDist 
∇L(θτ−t,Sκ),−∇L (θt,Dκ)
,(6)
where for each data cluster Dκ, we learn a corresponding Sκ
which contains ipcimages. In experiments, we set ipc= 1
and using the cosine distance for Dist(·).
Why do we choose reverse gradient matching over
gradient matching ? There are two main reasons:
•Enhanced matching performance. Since the number
of unlearn set is smaller than the whole set and the op-
timization of data matches the initial stage of the learn-
ing trajectory, making the accumulated trajectory error
much smaller using our proposed reverse gradient match-
ing. Detailed evidence supporting this claim is provided
in the supplementary materials.
•Improved Privacy Protection: While traditional data
distillation using gradient matching offers a degree of
privacy protection for the dataset [11], the distilled im-
ages still retain distinguishable patterns of the main ob-
ject, posing privacy risks. In contrast, images synthesized
11957
using reverse gradient matching exhibit no explicit pat-
terns, thus ensuring a higher level of privacy protection.
Detailed comparisons in this regard are presented in the
experimental results.
3.3. Online Evaluation
During the online evaluation stage, both the synset Sand
the target network Mare available, allowing for the evalu-
ation of specific model behaviors.
The primary concept behind online evaluation is to em-
ploy leave-one-out cross-validation, which entails systemat-
ically perturbing the training dataset Dby removing specific
training samples. This process helps analyze the resulting
impact on the model’s performance. Here we take studying
the influence function for example, which is a typical task
for analyzing the model’s data sensitivity, offering insights
into its robustness and decision boundaries. To be concrete,
given a test sample {xt, yt}, The corresponding prediction
result as ˜yt, where the target model is trained on the original
whole dataset D. The objective here is to directly build the
relationship with the network prediction ˜ytand the training
dataD(dataset →target network →prediction) by the attri-
bution matrix W:
˜yt(pt◦D)=W·pt+b, p t⊆ {0,1}K, (7)
where ptstands for the perturbation operation over the
dataset, and pt(κ) = 0 denotes the deletion of that data clus-
terDκfrom the training set. And ˜yt(Pt◦D)denotes the pre-
diction by the target network, which is trained from scratch
using the dataset pt◦ D.
Then, the attribution matrix Wcalculated from perturb-
ing the training data can be calculated as:
arg min
WX
pt⊆Ptβpt· Dist 
˜yt(pt◦D), W·pt
,(8)
where ptis randomly sampled from the {0,1}K,βptrep-
resents the weights corresponding to the number of 0s in
pt. The distance function Dist(·)is set as the L2 norm dis-
tance for measuring influence function of the model. And
the attribution matrix W⊆RK×|yt|, signifies the contri-
bution of each training data cluster to the confidence scores
of each label in the target network’s prediction for the test
sample xt. Let Ptdenote the perturbation set. To calculate
the attribution matrix W, a minimum of Kperturbations is
required, such that |Pt| ≥K, applied to the training data.
The main difficulty in Eq. 8 lies in obtaining |Pt|new
trained models training with the perturbed dataset pt◦ D,
so as to get the corresponding inference ˜yt(pt◦D). Recall
that during the offline training process, we already got the
distilled synthetic data Sκfor each data cluster Dκ, which
could fast unlearn Dκfrom the target network. And themodel parameters with the perturbed dataset could be fine-
tuned with the synset as:
θpt← F
κ∈{1,2,...,K},pt(κ)=0(Sκ). (9)
As a result, in the offline evaluation stage, we solve this dif-
ficulty by eliminating each cluster of training data from the
target network, which is further accelerated by our proposed
reverse gradient matching.
Accelerate with hierarchical distilled datamodel. To
expedite the online evaluation process, we implement a
hierarchical data distillation approach. This strategy en-
compasses the distillation of both the class-wise datamodel
(with K=|y|) and the cluster-wise datamodel (with K=
|y|×c, where each label’s data is partitioned into cclusters).
By following this approach, we can construct both the
class-wise and the cluster-wise attribution matrices. This
approach accelerates the analysis of model behavior, includ-
ing tasks such as identifying the most influential training
data. This is achieved by initially pinpointing the class-wise
data points and subsequently calculating the training matrix
within each class.
Algorithm 1 The Proposed DDM Framework
—————————- Offline Training —————————-
Input: D: training set; M: target model; {θ0, θ1, ..., θ τ}:
training trajectory of the target network ; s: trajectory step.
1:Divide the training data DintoKclusters;
2:Randomly initialize Ksynthetic samples, formed as S;
3:foreach distillation step do
4: Choose random start from target trajectory: θt(0≤t<τ);
5: Choose the end from target trajectory: θt+s(t+s < τ );
6: forκ= 1,2, ..., K do
7: Calculate the gradients on real data: ∇L(θt;Dκ);
8: Calculate the gradients of the synset ∇L(θt+s,Sκ);
9: minDist(∇L 
θt;Dκ),−∇L (θt+s,Sκ)
to update
Sκ;
10: end for
11:end for
Output: Cluster-wise synthetic data {S1,S2, ...,SK}.
————————– Online Evaluation ————————–
Input: M: target model; S: synset; xt: test sample.
1:Randomly sample perturbations ptto form Pt;
2:foreachptinPtdo
3: Perform perturbation pton the synset Saspt◦ S;
4: Fine-tune Mwithpt◦ S;
5: Input xtto the fine-tuned network and get ˜yt;
6:end for
7:Calculate the attribution matrix Wwith Eq. 8.
Output: Attribution matrix W.
11958
Table 1. Ablation study on the influence analysis of certain test samples on MNIST, CIFAR10 and CIFAR100 datasets. We locate to the
source data considering three distance functions. We report the value ×100forDist1in the table, larger is better and tiny number in red
donates the improvement or drop compared with ‘Random Select’.
MethodMNIST CIFAR10 CIFAR100
Dist1 Dist2 Dist3 Dist1 Dist2 Dist3 Dist1 Dist2 Dist3
Random Select 3.3 0.43 0.07 2.7 0.34 0.54 2.3 0.54 0.8
Predict-based 5.5 +2.2 - - 3.1 +0.4 - - 3.9 +1.6 - -
Clustering-based 6.2 +2.9 - - 2.5 -0.2 - - 3.6 +1.3 - -
DDM w/o cluster 9.1 +5.8 0.55 +0.12 0.11 +0.04 5.9 +3.2 0.57 +0.23 0.78 +0.24 3.5 +1.2 0.77 +0.23 1.2 +0.4
DDM-match 10.8 +7.5 0.73 +0.30 0.13 +0.06 5.8 +3.1 0.76 +0.42 0.81 +0.27 4.8 +2.5 0.71 +0.17 1.6 +0.8
DDM-full (ours) 10.8 +7.5 0.73 +0.30 0.13 +0.06 6.8 +4.1 0.81 +0.41 0.92 +0.38 5.3 +3.0 0.88 +0.34 1.6 +0.8
3.4. Algorithm and Discussions.
We depict the proposed algorithm including offline training
and online evaluation in Alg. 1. During the offline training
stage, we follow and modify the basic optimization frame-
work of dataset distillation. And we give the algorithm for
evaluating the influence function with xtas input. In the
online evaluation phase, adjustments are made to accom-
modate different evaluation objectives. Importantly, the of-
fline training process occurs only once and remains fixed
for subsequent evaluations.
4. Experiments
4.1. Experimental Settings
Datasets and networks. We conduct our experiments on
several standard image classification datasets: digit recog-
nition on MNIST dataset [24], CIFAR-10 dataset, CIFAR-
100 dataset [22] and TinyImageNet [36]. Regarding the ar-
chitectures of the target network, we evaluated various ar-
chitectures, including AlexNetIN [23], ResNet18, ViT, and
ConvNet.
Training details and parameter settings. We imple-
mented our experiments using the PyTorch framework. In
the default setting, unless otherwise specified, we set the
number of clusters per class to num cluster = 10 . This
implies that there are a total of K= 100 clusters for the
MNIST and CIFAR-10 datasets, and K= 1000 clusters
for the CIFAR-100 dataset. For both class-wise and cluster-
wise condensation, we used a single synthetic image per
cluster. These synthetic images were initialized by ran-
domly sampling real images, and standard data augmenta-
tion techniques were applied during training. The learning
rate for updating synthetic images was set to 10, while the
learning rate for updating network parameters was set to
0.01. To perturb the training set D, we set |Pt|=K.
Evaluation metrics. To assess the attribution of training
data to the behavior of the target network when influencing
specific test samples, we investigate three influence objec-tives, each defined by a distinct distance metric. We ran-
domly select 20 test samples ( |Xt|= 20 ) from the valida-
tion set of the training data and report the average distance
metrics. And in order to compare the accuracy of such built
relationship, we use the exact-unlearn network for evalu-
ation. That is, after locating the data cluster Diwith the
target influence objective, we scratch train the unlearn net-
workMuonD/Di, and get predictions as yu
t. We compute
distance function Avgdist regarding different types of in-
fluence analysis:
Avgdist=Ext∼XtDisti
where Dist1=∥yu
t−˜yt∥2,Dist2=ℓce(yu
t, yt),
Dist3= 1/(1 +∥yu
t−˜yt∥2),(10)
where ytis the groundtruth label for xtand˜ytis the output
from the target network M. For all three distance metrics,
namely Dist1,Dist2, andDist3, larger values are indica-
tive of more significant influence. Specifically, Dist1is de-
signed to trace back to the training data points that have the
most influence on the current prediction, Dist2focuses on
identifying those with the most influence on whether the
model makes correct predictions using the cross entropy
lossℓce, andDist3is utilized to pinpoint the training data
points with the least influence on the current prediction.
For evaluation objectives other than the influence func-
tion of specific test samples, relevant metrics are provided
within the corresponding experimental analysis part.
4.2. Experimental Results
DDM could be used for training data influence analy-
sis. By telling us the training points “responsible” for a
given prediction, influence functions reveal insights about
how models rely on and extrapolate from the training data.
For three different distance functions ( Dist1,Dist2and
Dist3), we calculate different weight matrix from Eq. 8
by replacing the corresponding distance function, obtain-
ingW1, W2, W3. And then we locate the correspond-
ingDi, where i= arg max iWi. The ablation study re-
11959
Table 2. Comparative experimental results with other works on
MNIST, CIFAR10 and CIFAR100 datasets, regarding Dist1in-
fluence.
Method MNIST CIFAR-10 CIFAR-100
Random Select 3.3 2.7 2.3
Koh et al. [21] 10.0 5.6 2.6
FASTIF [16] 9.8 6.5 2.4
Scaleup [38] 10.4 6.5 3.9
DDM 10.8 6.8 5.3
Table 3. Detecting useless training data for the target network.
Percentage 0% 1% 10% 20% 50%
Random Select 95.7 95.8 92.8 74.6 65.9
Koh et al. 95.7 95.9 93.7 81.5 74.3
FASTIF 95.7 95.5 94.1 79.6 74.0
Scaleup 95.7 96.0 95.2 82.9 73.3
DDM 95.7 96.2 95.9 85.4 79.3
garding the three types of influence functions is depicted
in Table 1, where ‘Random Select’ denotes that we ran-
domly choose Difrom K clusters; ‘Predict-based’ denotes
we choose the datapoint Diwith the highest prediction sim-
ilarity. ‘Cluster-Based’ denotes locating Diby using the
clustering strategy as we pre-process the dataset D, which
denotes the highest visual similarity; ‘DDM w/o cluster’
clusters DinKclusters by sequence number not by k-
means, ‘DDM-match’ denotes the DDM framework that
uses the gradient matching loss during the offline training
stage. From the table, we observe that:
• Methods categorized as ‘Predicted-based’ and
‘Clustering-based’ can serve as alternatives for evaluating
Dist1type inferences. While they turn to be less accurate
than our DDM. It further proves that visual similarity
between two images does not fully capture the influence
of one on the other in terms of model behavior [19].
In addition, they are limited in their ability to provide
a comprehensive analysis of Dist2andDist3. This
highlights the potential of our proposed DDL model to
evaluate a wider range of model behaviors.
• Comparing the results with ‘DDM w/o cluster’ and
‘DDM-full’, it becomes evident that the clustering strat-
egy offers a more accurate method for pinpointing influ-
ential training data.
• Upon comparing the results with ‘DDM-match’ and
‘DDM-full’, it is apparent that optimizing the synset with
gradient matching produces favorable outcomes on sim-
pler datasets like MNIST. However, as the dataset com-
plexity increases, this approach exhibits a decline in per-
formance, falling behind the optimization with reverse
gradient matching.
How do different target network architectures af-
ClassClassFigure 3. Comparison of the training data attribution weights cal-
culated form different network architectures. In the figure, we
show the class-wise weights.
fect DDM? We have conducted our proposed DDM frame-
work into several different network architectures, includ-
ing AlexNetIN, ResNet18 AP [17] and simple ViT [12].
We calculate the training data attribution weights for each
class of training data for measuring the model behaviors
onDist1. The test input is a batch of images with the
groundtruth label of ‘2’. The experimental results are con-
ducted on the MNIST dataset and the CIFAR-10 dataset,
which are depicted in Fig. 3. From the figure, observations
can be drawn that:
• All the networks with different architectures trace to the
similar source training data (with the highest value with
label ‘2’);
• For the simple classification task in MNIST, the training
data attribution matrices look similar among all the archi-
tectures;
• For a more difficult task in CIFAR10, the training data
attribution matrices look also similar in the trend, but vary
in the absolute weight values among all the architectures.
Comparing DDM performance with other works.
The comparative results with existing works are presented
in Table 2. We compare the Dist1influence with three
other works. To evaluate, we identify the most influential
data point and calculate the average distance metrics. It is
evident that our method demonstrates greater accuracy in
locating these influential data points.
DDM could be used as model diagnostic for low-
quality training samples. In addition to analyzing the
influence functions for specific test samples, the proposed
DDM also offers a comprehensive model of the overall
performance of the target network. We randomly sample
10% samples and calculate the The experimental results
are depicted in Table 3, which is conducted on MNIST
dataset. As depicted in the figure, the deletion of 10% of the
training data actually improves the network’s final perfor-
mance. Therefore, our proposed DDM framework succeeds
in model diagnostics by detecting and removing low-quality
training samples.
DDM meets the privacy protection demand. To sub-
stantiate our previous assertion that the proposed reverse
gradient matching enhances privacy protection, we con-
ducted a comparison between the distilled samples gener-
ated using traditional gradient matching and our novel re-
11960
GradientMatchingReverse GradientMatchingGradientMatchingReverse GradientMatching
MNIST DatasetCIFAR-100 DatasetFigure 4. Visualization of condensed 10 image/class with ConvNet for MNIST (a) and CIFAR-100 (b). We compare the visualization
results between gradient matching and reverse gradient matching. Each column represents a condensation of a cluster.
Table 4. The new trained network’s accuracies comparison. We
compare the networks fine-tuning with the proposed DDM and
gradient matching synthetic images.
Dataset Method Acc. ( θ0) Acc. ( θτ)
MNISTNormal 12.5 95.7
DDM-Match 12.6 85.0
DDM 0.6 95.7
CIFAR 10Normal 12.6 85.0
DDM-Match 12.6 40.2
DDM 15.5 85.0
CIFAR100Normal 2.2 56.1
DDM-Match 2.2 23.5
DDM 0.8 56.1
TinyImageNetNormal 1.4 37.5
DDM-Match 1.4 7.8
DDM 0.1 37.5
verse gradient matching, as illustrated in Fig. 4. As evi-
dent from the visualization, in gradient matching data dis-
tillation, the synthetic images retain the characteristic fea-
tures of the training set images, thus potentially revealing
training data through these conspicuous patterns, particu-
larly noticeable in the MNIST dataset. In contrast, in the
visualization results of our reverse gradient matching, the
distinctive features of the images are replaced by several in-
distinct patterns, akin to a form of obfuscation. This implies
that, especially in scenarios with privacy concerns, our pro-
posed DDM framework can be safely employed by directly
releasing the synset, providing enhanced privacy protection
for the original training data.
DDM could be used as a quick unlearn method. We
also assert that the proposed reverse gradient matching im-
proves matching performance, which is experimentally ver-
ified in Table 4. It’s worth noting that traditional gradient
matching begins by matching the initial state of the target
network, resulting in the same ‘Acc.( θ0)’ as normal train-ing. However, for more complex datasets (e.g., TinyIma-
geNet), it struggles to match the final performance of the
target network, ‘Acc. ( θτ)’. In contrast, our proposed DDM
commences from the final state of the target network and
also effectively matches the initial performance of the target
network. Thus, we contend that the proposed DDM signifi-
cantly enhances matching performance.
5. Conclusion
In this paper, we introduce a novel framework known as
DDM that facilitates a comprehensive analysis of training
data’s impact on a target machine learning model. The
DDM framework comprises two key stages: the offline
training stage and the online evaluation stage. During the
offline training stage, we propose a novel technique, reverse
gradient matching, to distill the influence of training data
into a compact synset. In the online evaluation stage, we
perturb the synset, enabling the rapid elimination of spe-
cific training clusters from the target network. This process
culminates in the derivation of an attribution matrix tailored
to the evaluation objectives. Overall, our DDM framework
serves as a potent tool for unraveling the behavior of ma-
chine learning models, thus enhancing their performance
and reliability.
Future research could extend the application of the DDM
framework to diverse machine learning tasks and datasets.
These applications could encompass fields as varied as nat-
ural language processing, reinforcement learning, computer
vision, and beyond. The versatility of DDM offers oppor-
tunities to gain deeper insights into model behaviors, data
quality, and training dynamics in these domains.
Acknowledgement
This project is supported by the Ministry of Education
Singapore, under its Academic Research Fund Tier 2
(Award Number: MOE-T2EP20122-0006), and the Na-
tional Research Foundation, Singapore, under its AI Sin-
gapore Programme (AISG Award No: AISG2-RP-2021-
023).
11961
References
[1] Andr ´e Altmann, Laura Tolos ¸i, Oliver Sander, and Thomas
Lengauer. Permutation importance: a corrected feature im-
portance measure. Bioinformatics , pages 1340–1347, 2010.
2
[2] Daniel W. Apley and Jingyu Zhu. Visualizing the effects of
predictor variables in black box supervised learning models.
Journal of the Royal Statistical Society: Series B (Statistical
Methodology) , 82, 2020. 2
[3] Daniel W Apley and Jingyu Zhu. Visualizing the effects of
predictor variables in black box supervised learning models.
Journal of the Royal Statistical Society Series B: Statistical
Methodology , 82(4):1059–1086, 2020. 1
[4] Juhan Bae, Nathan Ng, Alston Lo, Marzyeh Ghassemi, and
Roger B Grosse. If influence functions are the answer, then
what is the question? Advances in Neural Information Pro-
cessing Systems , 35:17953–17967, 2022. 2
[5] Lucas Bourtoule, Varun Chandrasekaran, Christopher A.
Choquette-Choo, Hengrui Jia, Adelin Travers, Baiwu Zhang,
David Lie, and Nicolas Papernot. Machine unlearning. IEEE
Symposium on Security and Privacy , pages 141–159, 2021.
2
[6] Jonathan Brophy and Daniel Lowd. Machine unlearning for
random forests. In International Conference on Machine
Learning , 2021. 2
[7] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-
biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakan-
tan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Lan-
guage models are few-shot learners. Advances in neural in-
formation processing systems , 33:1877–1901, 2020. 1
[8] Yinzhi Cao and Junfeng Yang. Towards making systems for-
get with machine unlearning. 2015 IEEE Symposium on Se-
curity and Privacy , pages 463–480, 2015. 2
[9] Rich Caruana, Yin Lou, Johannes Gehrke, Paul Koch, M.
Sturm, and No ´emie Elhadad. Intelligible models for health-
care: Predicting pneumonia risk and hospital 30-day read-
mission. Proceedings of the 21th ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Min-
ing, 2015. 2
[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
Toutanova. Bert: Pre-training of deep bidirectional
transformers for language understanding. arXiv preprint
arXiv:1810.04805 , 2018. 1
[11] Tian Dong, Bo Zhao, and Lingjuan Lyu. Privacy for free:
How does dataset condensation help privacy? In Interna-
tional Conference on Machine Learning , pages 5378–5396.
PMLR, 2022. 4
[12] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. arXiv preprint
arXiv:2010.11929 , 2020. 7
[13] Jerome H. Friedman. Greedy function approximation: A gra-
dient boosting machine. Annals of Statistics , 29:1189–1232,
2001. 2[14] Jerome H Friedman. Greedy function approximation: a gra-
dient boosting machine. Annals of statistics , pages 1189–
1232, 2001. 1
[15] Antonio A. Ginart, Melody Y . Guan, Gregory Valiant, and
James Y . Zou. Making ai forget you: Data deletion in ma-
chine learning. In NeurIPS , 2019. 2
[16] Han Guo, Nazneen Fatema Rajani, Peter Hase, Mohit
Bansal, and Caiming Xiong. Fastif: Scalable influence func-
tions for efficient model interpretation and debugging. arXiv
preprint arXiv:2012.15781 , 2020. 1, 2, 7
[17] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
Deep residual learning for image recognition. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition , pages 770–778, 2016. 7
[18] Yingzhe He, Guozhu Meng, Kai Chen, Jinwen He, and
Xingbo Hu. Deepobliviate: A powerful charm for eras-
ing data residual memory in deep neural networks. ArXiv ,
abs/2105.06209, 2021. 2
[19] Andrew Ilyas, Sung Min Park, Logan Engstrom, Guillaume
Leclerc, and Aleksander Madry. Datamodels: Predicting
predictions from training data. In Proceedings of the 39th
International Conference on Machine Learning , 2022. 2, 7
[20] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai,
James Wexler, Fernanda Viegas, et al. Interpretability be-
yond feature attribution: Quantitative testing with concept
activation vectors (tcav). In International conference on ma-
chine learning , pages 2668–2677. PMLR, 2018. 1
[21] Pang Wei Koh and Percy Liang. Understanding black-box
predictions via influence functions. In International confer-
ence on machine learning , pages 1885–1894. PMLR, 2017.
1, 2, 7
[22] Alex Krizhevsky. Learning multiple layers of features from
tiny images. 2009. 6
[23] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton.
Imagenet classification with deep convolutional neural net-
works. Communications of the ACM , 60:84 – 90, 2012. 6
[24] Yann LeCun, L ´eon Bottou, Yoshua Bengio, and Patrick
Haffner. Gradient-based learning applied to document recog-
nition. Proc. IEEE , 86:2278–2324, 1998. 6
[25] Saehyung Lee, Sanghyuk Chun, Sangwon Jung, Sangdoo
Yun, and Sungroh Yoon. Dataset condensation with con-
trastive signals. In International Conference on Machine
Learning , pages 12352–12364. PMLR, 2022. 2
[26] Songhua Liu and Xinchao Wang. Mgdd: A meta generator
for fast dataset distillation. In Advances in Neural Informa-
tion Processing Systems , 2023.
[27] Songhua Liu, Kai Wang, Xingyi Yang, Jingwen Ye, and Xin-
chao Wang. Dataset distillation via factorization. In Ad-
vances in Neural Information Processing Systems , 2022.
[28] Songhua Liu, Jingwen Ye, Runpeng Yu, and Xinchao Wang.
Slimmable dataset condensation. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 3759–3768, 2023. 2
[29] Scott M Lundberg and Su-In Lee. A unified approach to
interpreting model predictions. Advances in neural informa-
tion processing systems , 30, 2017. 1
11962
[30] Quoc Phong Nguyen, Bryan Kian Hsiang Low, and Patrick
Jaillet. Variational bayesian unlearning. Advances in Neural
Information Processing Systems , 33:16025–16036, 2020. 2
[31] Timothy Nguyen, Roman Novak, Lechao Xiao, and Jaehoon
Lee. Dataset distillation with infinitely wide convolutional
networks. Advances in Neural Information Processing Sys-
tems, 34:5186–5198, 2021. 2
[32] Garima Pruthi, Frederick Liu, Satyen Kale, and Mukund
Sundararajan. Estimating training data influence by tracing
gradient descent. Advances in Neural Information Process-
ing Systems , 33:19920–19930, 2020. 1
[33] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,
Chelsea V oss, Alec Radford, Mark Chen, and Ilya Sutskever.
Zero-shot text-to-image generation. In International Confer-
ence on Machine Learning , pages 8821–8831. PMLR, 2021.
1
[34] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
”why should i trust you?”: Explaining the predictions of any
classifier. Proceedings of the 22nd ACM SIGKDD Interna-
tional Conference on Knowledge Discovery and Data Min-
ing, 2016. 2
[35] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin.
” why should i trust you?” explaining the predictions of any
classifier. In Proceedings of the 22nd ACM SIGKDD interna-
tional conference on knowledge discovery and data mining ,
pages 1135–1144, 2016. 1
[36] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San-
jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy,
Aditya Khosla, Michael S. Bernstein, Alexander C. Berg,
and Li Fei-Fei. Imagenet large scale visual recognition chal-
lenge. International Journal of Computer Vision , 115:211–
252, 2014. 6
[37] Andrea Schioppa, Polina Zablotskaia, David Vilar, and
Artem Sokolov. Scaling up influence functions. In AAAI
Conference on Artificial Intelligence , 2021. 2
[38] Andrea Schioppa, Polina Zablotskaia, David Vilar, and
Artem Sokolov. Scaling up influence functions. In Proceed-
ings of the AAAI Conference on Artificial Intelligence , pages
8179–8186, 2022. 7
[39] Ayush Sekhari, Jayadev Acharya, Gautam Kamath, and
Ananda Theertha Suresh. Remember what you want to for-
get: Algorithms for machine unlearning. Advances in Neural
Information Processing Systems , 34, 2021. 2
[40] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das,
Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
Grad-cam: Visual explanations from deep networks via
gradient-based localization. In Proceedings of the IEEE in-
ternational conference on computer vision , pages 618–626,
2017. 1
[41] Ramprasaath R. Selvaraju, Abhishek Das, Ramakrishna
Vedantam, Michael Cogswell, Devi Parikh, and Dhruv Ba-
tra. Grad-cam: Visual explanations from deep networks via
gradient-based localization. International Journal of Com-
puter Vision , 128:336–359, 2019. 2
[42] Mateusz Staniak and Przemyslaw Biecek. Explanations of
model predictions with live and breakdown packages. arXiv
preprint arXiv:1804.01955 , 2018. 2[43] Ilia Sucholutsky and Matthias Schonlau. Soft-label dataset
distillation and text dataset distillation. In 2021 International
Joint Conference on Neural Networks (IJCNN) , pages 1–8.
IEEE, 2021. 2
[44] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic
attribution for deep networks. In International conference on
machine learning , pages 3319–3328. PMLR, 2017. 2
[45] Berk Ustun and Cynthia Rudin. Supersparse linear integer
models for optimized medical scoring systems. Machine
Learning , 102:349–391, 2015.
[46] Dennis Wei, Sanjeeb Dash, Tian Gao, and Oktay G ¨unl¨uk.
Generalized linear rule models. In ICML , 2019. 2
[47] Yinjun Wu, Edgar Dobriban, and Susan B. Davidson. Delta-
grad: Rapid retraining of machine learning models. In Inter-
national Conference on Machine Learning , 2020. 1
[48] Xingyi Yang and Xinchao Wang. Diffusion model as repre-
sentation learner. In IEEE/CVF International Conference on
Computer Vision , 2023. 1
[49] Jingwen Ye, Yifang Fu, Jie Song, Xingyi Yang, Songhua Liu,
Xin Jin, Mingli Song, and Xinchao Wang. Learning with re-
coverable forgetting. In European Conference on Computer
Vision , 2022. 2
[50] Jingwen Ye, Songhua Liu, and Xinchao Wang. Partial net-
work cloning. In 2023 IEEE/CVF Conference on Computer
Vision and Pattern Recognition (CVPR) , 2023. 2
[51] Ruonan Yu, Songhua Liu, and Xinchao Wang. Dataset dis-
tillation: A comprehensive review. In IEEE Transactions on
Pattern Analysis and Machine Intelligence , 2024. 2
[52] Matthew D Zeiler and Rob Fergus. Visualizing and under-
standing convolutional networks. In European conference on
computer vision , pages 818–833. Springer, 2014. 2
[53] Yingyan Zeng, Jiachen T Wang, Si Chen, Hoang Anh Just,
Ran Jin, and Ruoxi Jia. Modelpred: A framework for pre-
dicting trained model from training data. In 2023 IEEE
Conference on Secure and Trustworthy Machine Learning
(SaTML) , pages 432–449. IEEE, 2023. 2
[54] Bo Zhao and Hakan Bilen. Dataset condensation with differ-
entiable siamese augmentation. In International Conference
on Machine Learning , 2021. 2
[55] Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. Dataset
condensation with gradient matching. In Ninth International
Conference on Learning Representations 2021 , 2021. 2, 4
[56] Bolei Zhou, Aditya Khosla, `Agata Lapedriza, Aude Oliva,
and Antonio Torralba. Learning deep features for discrim-
inative localization. IEEE Conference on Computer Vision
and Pattern Recognition , pages 2921–2929, 2016. 2
[57] Yongchao Zhou, Ehsan Nezhadarya, and Jimmy Ba. Dataset
distillation using neural feature regression. arXiv preprint
arXiv:2206.00719 , 2022. 2
11963
