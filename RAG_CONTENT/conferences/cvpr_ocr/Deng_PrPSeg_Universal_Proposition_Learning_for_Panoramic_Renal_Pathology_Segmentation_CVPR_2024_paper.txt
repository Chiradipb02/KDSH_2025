PrPSeg: Universal Proposition Learning for Panoramic Renal Pathology
Segmentation
Ruining Deng1, Quan Liu1, Can Cui1, Tianyuan Yao1, Jialin Yue1, Juming Xiong1, Lining Yu1, Yifei
Wu1, Mengmeng Yin2, Yu Wang2, Shilin Zhao2, Yucheng Tang3, Haichun Yang2, Yuankai Huo1,2*
1. Vanderbilt University, 2. Vanderbilt Univeristy Medical Center, 3. NVIDIA Corp.
*contact author: yuankai.huo@vanderbilt.edu
Abstract
Understanding the anatomy of renal pathology is cru-
cial for advancing disease diagnostics, treatment evalua-
tion, and clinical research. The complex kidney system com-
prises various components across multiple levels, includ-
ing regions (cortex, medulla), functional units (glomeruli,
tubules), and cells (podocytes, mesangial cells in glomeru-
lus). Prior studies have predominantly overlooked the in-
tricate spatial interrelations among objects from clinical
knowledge. In this research, we introduce a novel univer-
sal proposition learning approach, called panoramic re-
nal pathology segmentation (PrPSeg), designed to segment
comprehensively panoramic structures within kidney by in-
tegrating extensive knowledge of kidney anatomy.
In this paper, we propose (1) the design of a com-
prehensive universal proposition matrix for renal pathol-
ogy, facilitating the incorporation of classification and
spatial relationships into the segmentation process; (2) a
token-based dynamic head single network architecture, with
the improvement of the partial label image segmentation
and capability for future data enlargement; and (3) an
anatomy loss function, quantifying the inter-object relation-
ships across the kidney.
1. Introduction
Digital pathology has revolutionized the field of pathol-
ogy [1], not only facilitating the transition from local micro-
scopes to remote monitoring for pathologists but also pro-
viding a significant opportunity for large-scale computer-
assisted quantification in pathology [5, 19, 41]. In the clin-
ical anatomy of renal pathology, there are different lev-
els of quantification necessary for disease diagnosis [42],
severity recognition [34], and treatment effectiveness eval-
uation [28], ranging from region-level objects (like medulla
and cortex) to functional units (glomerulus, tubules, ves-
sels, etc.) and even to individual cells within these units.These tasks, especially at the functional unit and cell lev-
els, are prone to errors and variability in human examina-
tion and require labor-intensive efforts [26, 47, 53]. There-
fore, achieving comprehensive quantification from regions
to cells is necessary in renal pathology, but it remains an
inevitably laborious task with manual human effort.
While many studies have developed pathological image
segmentation techniques for pixel-level tissue characteriza-
tion, particularly using deep learning methods [4, 12, 35,
44, 51], they still encounter three major limitations: (1) Cur-
rent multi-network and multi-head designs [11, 25, 27, 37,
48, 52] focus only on single tissue structures or structures at
similar scales, lacking a comprehensive approach to achieve
all-encompassing segmentation across different levels from
regions to cells. (2) These approaches require modifications
to their architectures when new classes are introduced, pre-
venting the reuse of existing backbones without significant
alterations; (3) Comprehensive semantic (multi-label) seg-
mentation and quantification on renal histopathological im-
ages remain challenging due to the intricate spatial relation-
ships among different tissue structures. The spatial relation-
ships between these different objects are illustrated in Fig-
ure 1. Understanding these interrelations in renal pathol-
ogy is crucial for achieving effective all-encompassing seg-
mentation, yet recent advancements in deep learning have
not fully incorporated this comprehensive modeling into the
training process, nor have they achieved panoramic seg-
mentation for the complete anatomy of the kidney.
To address these challenges, we introduce a token-based
dynamic head network designed to achieve panoramic renal
pathology segmentation (PrPSeg) by modeling the spatial
relationships among all objects. This approach allows for
the reuse of the same architectural framework, even when
the dataset size expands. A universal proposition matrix is
established to translate anatomical relationships into com-
putational modeling concepts. A anatomy loss is also pro-
posed to integrate spatial relationships into the model train-
This CVPR paper is the Open Access version, provided by the Computer Vision Foundation.
Except for this watermark, it is identical to the accepted version;
the final published version of the proceedings is available on IEEE Xplore.
11736
Glomerular tuftBowman’s capsule Efferent arterioleProximal tubeCortical collecting tubeCortex
MedullaDistal tubeLoop of HenleCollecting ductPeritubular capillariesArcuate veinArcuate arteryAfferent arterioleJuxtaglomerular apparatus
Outer medullaOuter stripsInner stripsInnermedullaMesangial cellEndothelial cellPodocyte cellParietal epithelial cell
Intercalated cellPrincipal cellEndothelial cellSmooth muscle cellPericytecella. Clinical Anatomy of Kidney Functional Units
RegionsUnitsCells
Medulla
Cortex
Glomerulus
TubulesGlomerular tuftBowman’s capsule Proximal tubuleDistal tubuleMesangial cellPodocyte cell0 MED1 COR2 DT3 PT4 CAP5 TUFT6 POD7 MES0 MED1 COR2 DT3 PT4 CAP5 TUFT6 POD7 MESSquare of OppositionAll S are PNo S are PSome S are PSome S are not PSubset,Superset
b. Hierarchical Semantic Taxonomy c. Universal Proposition MatrixFigure 1. Knowledge transformation from kidney anatomy to computational modeling – This figure demonstrates the transformation
of intricate clinical anatomical relationships within the kidney into a structured computational matrix. (a) Pathologists examine histopathol-
ogy following the kidney anatomy. (b) This study revisits such kidney anatomy with hierarchical semantic taxonomy. (c) The proposed
PrPSeg method further mathematically abstracts the semantic taxonomy as a universal proposition matrix. This matrix serves as a founda-
tion for our computational model, reflecting the complex interplay of anatomical elements in the kidney.
ing as a form of semi-supervised learning. To our knowl-
edge, this is the first deep learning algorithm to accomplish
panoramic segmentation in renal pathology, demonstrating
superior performance in all-encompassing segmentation.
The contributions of this paper are threefold:
• The design of a comprehensive universal proposition ma-
trix for renal pathology, facilitating the incorporation of
classification and spatial relationships into the segmenta-
tion process.
• The development of a token-based dynamic head in a sin-
gle network architecture, improving partial label image
segmentation.
• The formulation of an anatomy loss function, quantifying
the inter-object relationships across the kidney.
2. Relative Work
2.1. Renal Pathology Segmentation
Recent advancements in deep learning have positioned
Convolutional Neural Networks (CNNs) and Transformer-
based networks as leading methods for image segmentation,
particularly in renal pathology [15, 22]. Innovations in this
field have ranged from CNN cascades for sparse tissue seg-
mentation [16] to the deployment of AlexNet for pixel-wise
classification and detection [17]. Notably, multi-class learn-
ing approaches using SegNet-VGG16 and DeepLab v2 have
been implemented for detecting various glomerular struc-
tures and renal pathologies [7, 39]. In addition, instance
segmentation and Vision Transformers (ViTs) have begun
to find applications in this domain [18, 30, 43, 50].
However, most existing methods focus on segmenting
single tissue types or multiple structures at similar levels,
such as glomeruli and tubules [21, 32, 40]. Comprehensive
approaches capable of spanning from tissue region level tocell level remain unexplored. Moreover, some methods pri-
oritize disease-positive region segmentation over a holistic
understanding of kidney morphology [29, 38].
Recent methods utilize hierarchical information for se-
mantic segmentation [33, 36] or classification and predic-
tion [8]. However, these methods primarily focus on class-
based relationships between objects. While all objects have
a uniform resolution in natural images, this approach ne-
glects the emphasis on pixel-wise anatomical and spatial
relationships at multiple resolutions in kidney datasets.
Building upon these insights, our work introduces a
token-based approach, leveraging class-specific and scale-
specific tokens. This method is designed to capture hetero-
geneous features and employs semi-supervised learning to
understand pixel-wise spatial relationships across multiple
scales, achieving panoramic segmentation in renal pathol-
ogy.
2.2. Dynamic Single Network
While multi-head single network designs have been pro-
posed for multi-class renal pathology segmentation [6,
9, 14, 20], they often require dense multi-class annota-
tions. Given the labor-intensive nature of such annotations,
pathology data is frequently partially labeled. Additionally,
forming spatial correlations, such as subset/superset rela-
tionships, remains a challenge in multi-class uplsegmenta-
tion frameworks.
Recent developments in dynamic neural networks have
paved the way for more comprehensive segmentation us-
ing single multi-label networks, even with partially labeled
data [11, 52]. These networks dynamically generate neural
network parameters, adapting to various imaging contexts.
However, they predominantly rely on binary segmentation
approaches and do not fully integrate spatial correlations in
11737
Square of OppositionAll S are PNo S are PSome S are PSome S are not PSubset, Superset
Supervised class labelCurrent predictionSupersetSubset
=∪ L= DCE(,      )L= -DCE(        ,        )L= DCE(,      )Class iClass jMedulla
Cortex
Distal tubular
Proximal tubular
Glomerular capsule
Glomerulartufts
Podocyte
Mesangial
Superset0 MED1 COR2 DT3 PT4 CAP5 TUFT6 POD7 MES0 MED1 COR2 DT3 PT4 CAP5 TUFT6 POD7 MES
a. Renal Pathology Anatomical Rela;onshipRegionsUnitsCellsb. Universal Proposi;on Matrixc. Anatomy LossFigure 2. Universal proposition matrix with anatomy loss – This figure shows the key innovation of the proposed method. (a) Multi-
scale (region-level, unit-level, and cell-level) hierarchical semantic taxonomy is presented. (b) The proposed PrPSeg mathematically
models the semantic taxonomy as a universal proposition matrix, which delineates robust constraints and relationships between anatomical
entities. (c) We further encode the universal proposition matrix as a novel anatomy loss function, designed to operationalize the affirmative
and negatory relationships inherent in kidney anatomy.
their training processes.
Our work extends these concepts by translating spatial
correlations from anatomy into a programming model, rep-
resented as a matrix coupled with an anatomy-based loss
for semi-supervised learning. This strategy effectively har-
nesses the affirmative and negatory relationships in kidney
anatomy, enabling detailed and comprehensive segmenta-
tion. It enhances the model’s ability to distinguish and clas-
sify the complex structures within kidney, representing a
significant advancement in the field.
3. Method
3.1. Problem Formulation
This study aims to segment an array of anatomical concepts
in renal pathology, encapsulating three conceptual layers
— regions ( R1, R2), functional units ( F1, F2, F3, F4), and
cells ( C1, C2) — spanning 8 distinct objects.
Leveraging anatomical learning, our approach is tailored
to achieve comprehensive segmentation in renal pathology
by effectively interpreting both affirmative and negatory re-
lationships within the anatomical relationship.
The pipeline is composed of three integral components:
Universal proposition matrix: A meticulously crafted
universal proposition matrix is employed to elucidate the
anatomical relationships among various objects. This ma-
trix aids in enhancing structural understanding from an en-
gineering perspective, facilitating better cognition of thecomplex renal architecture.
Token-based dynamic head backbone: We have devel-
oped a token-based dynamic head backbone architecture
that is adept at interpreting class-aware and scale-aware
knowledge pertinent to renal pathology. This component
is pivotal in accommodating the extensibility requirements
posed by the introduction of new data, ensuring the model’s
adaptability and scalability.
Anatomy loss function: A novel anatomy loss function has
been formulated, which operationalizes the affirmative and
negatory relationships inherent in kidney anatomy. This
function is a critical element in achieving nuanced, all-
encompassing segmentation, bolstering the model’s ability
to discern and categorize the intricate structures within the
kidney.
3.2. Universal proposition matrix
Renal pathology encompasses regions (the medulla and cor-
tex), functional units (glomerulus, tubules, etc.), with corre-
sponding cellular structures. Pathologists analyze the mor-
phology of the kidney by examining the functional flow
through these heterostructures. Traditionally, each het-
erostructure undergoes isolated examination and quantifi-
cation to meet specific demands, often overlooking the
homostructures within each unit, such as podocyte cells,
mesangial cells in glomerular tufts. To enhance the un-
derstanding of the integrated kidney structure, we propose
transforming kidney anatomy into an anatomical relation-
11738
256, 322256, 642128, 128264, 256232, 5122
256, 322Image FeatureGAPDynamic Head Parameters 𝜃𝜑(162)High-level Image Feature (R)Global Average PoolingController
256, 12Proximal Tubular(PT, 10X) Prediction (P)
Dynamic HeadDynamic Head (𝜔)Image Feature (F)𝜔1𝜔2𝜔3Decoder Output (M)Class-aware Token (Tc)
GAP256, 322256, 642128, 128264, 256232, 5122d5,12dgap,12d4,12d3,12d2,12d1,12Scale-aware Token (Ts)Token-based Dynamic HeadFigure 3. Token-based dynamic head network architecture – This figure illustrates the architecture of the proposed PrPSeg method.
It incorporates a residual U-Net backbone, augmented with class-aware and scale-aware tokens. These tokens are integrated into each
block of the encoder, as well as the Global Average Pooling (GAP) block, ensuring a comprehensive understanding of both class and scale
features. Such features are aggregated by a fusion block to adaptively generate the parameters for a single dynamic segmentation head.
The proposed method is able to segment all hierarchical semantic anatomies using a single network.
ship map, using principles of affirmation and negation from
linguistic and grammatical concepts.
To translate these anatomy concepts into an engineer-
ing framework, we adopt Aristotle’s logic theory to develop
an anatomical map for renal pathology. Aristotle’s the-
ory examines the relationships between objects using four
fundamental categorical propositions. Upon closer inspec-
tion, complex propositions reveal themselves as collections
of simpler claims derived from these initial propositions.
Specifically, we utilize two terms from Aristotle’s theory:
(1) Universal Affirmation: “All S are P , ” and (2) Universal
Negation: “No S are P , ” , to universally assert properties for
all group members, indicating strong constraints and rela-
tionships. For example, in the context of two kidney struc-
tures, AandB, ifBis within A,Bis a subset of A, fol-
lowing the rule of Universal Affirmation. Conversely, if A
andBhave no inclusion relationship, they are mutually ex-
clusive, aligning with Universal Negation. These proposi-
tions are employed to construct an anatomical relationship
map representing the classification and spatial relationships
among renal pathology objects, as illustrated in Figure 2.
This anatomical relationship is characterized by:
Uniqueness: Each pair of objects is linked by a single
proposition. The expanding structure of the map, devoid
of cycles, ensures stable inheritance relationships from re-
gions down to cellular levels.
Transmissibility: Indirect relationships between objects
can be deduced from direct relationships, as established
by the two fundamental categorical propositions. Relation-
ships between objects not directly connected can be deter-
mined by combining propositions along their connecting
path.
Following the translation of this knowledge from clin-
ical anatomy to an engineering paradigm, we introduce a
universal proposition matrix, Mt∈Rn×n, to facilitate im-plementation in computational models. Here, nrepresents
the number of classes within the map. The matrix values
are defined in Equation (1):
Mt(i, j) =

1, ifI ⊆J
−1, ifI ⊇J
2, ifI ∩J=∅
0,otherwisei, j= 1,2, ..., n (1)
This matrix is designed to be extendable with the intro-
duction of new data.
3.3. Token-based Dynamic Head Network
Pathological image segmentation faces three main chal-
lenges: (1) Heterogeneous object annotations are often par-
tially labeled, with only one type of tissue annotated per
pathological image; (2) It is challenging to form anatomical
relationships (e.g. subset/superset relationships) in multi-
class segmentation; for example, it is difficult to simulta-
neously segment glomerular capsule, tufts, and cells that
share regions; (3) The annotation process on giga-pixel im-
ages is labor-intensive, leading to an ongoing data collec-
tion process with class extension. Therefore, a segmenta-
tion backbone optimized for binary segmentation of multi-
ple classes with spatial overlap, and adaptable to data en-
largement, is required. Previous designs, including multi-
head and dynamic-head, are suboptimal for partially labeled
learning and data extension, leading to changes in the back-
bone architecture and insufficient performance.
In this work, we propose a token-based dynamic head
backbone designed to maintain consistent model architec-
ture while accommodating a possibly increasing number
of segmentation classes (In Figure 4). The backbone can
be supervised with partially labeled data, understanding
anatomical relationships effectively. The entire architec-
11739
Token-based Dynamic HeadNetworkBackbone is the same when extend new classesClass-aware tokenScale-aware token……Dynamic Token Bank
Class 1Class 2Class N…IncreasingClassesEncoder+DynamictokensImage featuresControllerDynamicheadGNReLUConvGNReLUConv+Figure 4. Token-based dynamic head – This figure visualizes
the architecture of our proposed token-based dynamic head back-
bone. Central to our design is the ability to maintain a consistent
model architecture while dynamically accommodating an increas-
ing number of segmentation classes. This flexibility is achieved
by extending the dimensions of the tokens, rather than altering
the backbone structure. Key components include a dynamic token
bank with class-aware and scale-aware tokens, an encoder, and a
dynamic head network, all orchestrated to efficiently handle class
expansion without necessitating changes to the backbone.
ture is demonstrated in Figure 3. The backbone of our pro-
posed method is the Residual-U-Net from Omni-Seg [11],
chosen for its superior segmentation performance in re-
nal pathology. Instead of using dimensionally-changeable
one-hot vectors for class-aware encoding and scale-aware
encoding, we use dimensionally-stable class-aware tokens
(Tc∈Rn×d) and scale-aware tokens ( Ts∈R4×d) to com-
prehend the contextual information in the encoder ( E) of
the model. Here, dis the sum of the channel numbers of
blocks ( d1+d2+···+db+dgap) in the encoder. Each
interval of the channels represents level-specific features in
each level of the encoder. Each class has a one-dimensional
token tc∈R1×dto store class-specific knowledge at the
feature level among the whole dataset, while each magnifi-
cation has a one-dimensional token ts∈R1×dfor providing
scale-specific knowledge across four scales (5 ×, 10×, 20×,
and 40×). Inspired by the Vision Transformer [13], for an
image Iof class iwith magnification m, at the b-th encoder
block, the corresponding class token Tc(i)andTs(m)are
added to the current feature map ( eb−1) before being fed
into the current block ( Eb). This process is defined by the
following equation:
Indstart=b−1X
k=1dk,Indend=bX
k=1dk (2)
eb=Eb(Tc[i][Indstart:Indend]+
Ts[m][Indstart:Indend] +eb−1)(3)
With the class token Tcand scale token Ts, the encoder
captures domain-specific features in the image.To further integrate class-specific and scale-specific in-
formation into the embedded features, we combine the
last intervals of the class-token and scale token into the
low-dimensional feature embedding at the bottom of the
Residual-U-Net architecture. The image feature Fis sum-
marized by Global Average Pooling (GAP) and transformed
into a feature vector in Rdgap.dgapis the dimension of GAP
feature. Differing from Omni-Seg [11], which implements
a triple outer product to combine three vectors into a one-
dimensional vector via a flatten function, we use a single 2D
convolutional layer controller, φ, as a feature fusion block
to refine the fusion vector as the final controller for dynamic
head mapping:
ω=φ(GAP(F) +Tc[i][:−dgap] +Ts[i][:−dgap]; Θφ)
(4)
where GAP (F),Tc, and Tsare combined by the addition
operation, and Θφrepresents the number of parameters in
the dynamic head.
Following the approach of [11], a binary segmentation
network is used to achieve multi-label segmentation via a
dynamic filter. From the multi-label multi-scale modeling
described above, we derive joint low-dimensional image
feature vectors, class-specific tokens, and scale-specific to-
kens at an optimal segmentation magnification. These are
then mapped to control a lightweight dynamic head, spec-
ifying (1) the target tissue type and (2) the corresponding
pyramid scale.
The dynamic head consists of three layers. The first
two layers contain eight channels each, while the final layer
comprises two channels. We directly map parameters from
the fusion-based feature controller to the kernels in the 162-
parameter dynamic head to achieve precise segmentation
from multi-modal features. The filtering process is ex-
pressed by the following equation:
P= (((( M·ω1)·ω2)·ω3) (5)
where·denotes convolution, P∈R2×W×His the final pre-
diction, and WandHcorrespond to the width and height
of the dataset, respectively.
The benefits of the dynamic-token design are twofold:
(1) The backbone architecture remains stable and reusable
as new classes are introduced, which is advantageous for
incremental learning. (2) The binary segmentation scheme
allows the model to predict multiple classes with spatial
overlap, outperforming other multi-head and dynamic-head
designs.
3.4. Anatomy Loss Function
With the introduction of the universal proposition matrix
and token-based dynamic head architecture, we propose an
online semi-supervised anatomy learning strategy to incor-
porate spatial correlation into the training process for com-
11740
prehensive segmentation. For a given image Iwith a la-
beled class i, represented as Yi, we generate predictions
Y′
jfor another class jon the same image. We then use
the anatomical relationship to supervise the correlation be-
tween the supervised label Yiand the semi-supervised pre-
diction Y′
j: (1) If iis a superset of j,Y′
jshould not exceed
the region of Yi; conversely, (2) if iis a subset of j,Y′
j
should cover Yias comprehensively as possible; and (3) if i
is mutually exclusive with j, the overlap between YiandY′
j
should be minimized. The total anatomy loss is defined by
the following equations:
Lupl(i, j) =

DCE(1−Yi, Y′
j),ifMt(i, j) = 1
−DCE(Yi, Yi∪Y′
j),ifMt(i, j) =−1
DCE(Yi, Y′
j),ifMt(i, j) = 2
0,ifMt(i, j) = 0
(6)
where Mtis the anatomy matrix and DCE denotes the Dice
Loss. The total loss function is an aggregate of supervised
and semi-supervised losses, weighted by λupl.
L(i) =DCE(Yi, Y′
i) +BCE(Yi, Y′
i)
+λuplnX
j=1Lupl(i, j) (j̸=i)(7)
where BCE represents the Binary Cross-Entropy loss, and
Y′
iis the prediction for class i.
4. Data and Experiment
4.1. Data
Our model leverages an 8-class, partially labelled dataset
spanning various biological scales, from regions to cells.
The dataset’s structure is detailed in Table 1. We sourced
the human kidney dataset from three distinct resources:
Regions: Whole slide images of wedge kidney sections
stained with periodic acid-Schiff (PAS, n=138) were ob-
tained from from non-cancerous regions of nephrectomy
samples. The samples were categorized into several groups
based on clinical data, including normal adults (n=27), pa-
tients with hypertension (HTN, n=31), patients with dia-
betes (DM, n=4), patients with both hypertension and di-
abetes (n=14), normal aging individuals (age >65y, n=10),
individuals with aging and hypertension (n=36), and in-
dividuals with aging, hypertension, and diabetes (n=16).
These tissues were scanned at 20 ×magnification and man-
ually annotated in QuPath [2], delineating medulla and cor-
tex contours. The WSIs were downsampled to 5 ×magnifi-
cation and segmented into 1024 ×1024 pixel patches. Cor-
responding binary masks were derived from the contours.
Functional Units: Using 459 WSIs from NEPTUNE
study [3], encompassing 125 patients with minimal change
disease, we extracted 1,751 Regions of Interest (ROIs).
These ROIs were manually segmented to identify four kindsTable 1. Data collection
Class Patch # Size Scale Stain
Medulla 1619 102425× P
Cortex 3055 102425× P
DT 4615 256210× H,P,S,T
PT 4588 256210× H,P,S,T
Cap. 4559 25625× H,P,S,T
Tuft 4536 25625× H,P,S,T
Pod. 1147 512220× P
Mes. 789 512220× P
*DT is distal tubular; PT is proximal tubular;
*Cap. is glomerular capsule; Tuft is glomerular tuft;
*Pod. is podocyte cell; Mes. is mesangial cell.
*H is H &E; P is PAS; S is SIL; T is TRI.
of morphology objects with normal structure and method-
ology outlined in [27]. Each image, at a resolution of
3000×3000 pixels (40 ×magnification, 0.25 µmper pixel),
represented one of four tissue types stained with Hema-
toxylin and Eosin Stain(H&E), PAS, Silver Stain (SIL),
and Trichrome Stain (TRI). We treated these four stain-
ing methods as color augmentations and resized the im-
ages to 256 ×256 pixels, maintaining the original data splits
from [27].
Cells: We acquired 11 PAS-stained WSIs from nephrec-
tomy specimens with normal kidney function and morphol-
ogy, scanned at 20 ×magnification. These pathological
images were cropped into 512 ×512 pixel segments to fa-
cilitate cell labeling, following the annotation process de-
scribed in [10].
The dataset was partitioned into training, validation, and
testing sets at a 6:1:3 ratio across all classes, with splits con-
ducted at the patient level to prevent data leakage.
4.2. Experiment Details
The training process of our model was divided into two
distinct phases. In the initial phase, spanning the first 50
epochs, we employed a supervised learning strategy fo-
cused on minimizing binary dice loss and cross-entropy
loss. Subsequently, for the remaining epochs, both super-
vised and semi-supervised learning strategies were utilized,
incorporating anatomy loss to explore the spatial correlation
among multiple objects. In our experiments, λuplis 0.1.
All images were either randomly cropped or padded to a
uniform size of 512×512pixels prior to being fed into the
model in the training stage. We established 8 separate image
pools, each designated for different tissue types, to organize
training batches. This approach follows the image pooling
strategy from Cycle-GAN [54]. The batch size was set to 4,
while each image pool could accommodate up to 8 images.
Once an image pool accumulated more than the batch size,
11741
Table 2. Performance of deep learning based multi-class panoramic segmentation. Dice similarity coefficient scores (%) are reported.
Method BackboneRegions Functional units CellsAverage
Medulla Cortex DT PT Cap. Tufts Pod. Mes.
U-Nets [20] CNN 23.86 66.42 47.61 51.04 45.36 46.62 49.92 49.87 47.58
DeepLabV3 [39] CNN 41.70 61.26 63.92 65.31 72.82 81.93 49.92 49.87 60.84
Residual-U-Net [45] CNN 13.21 69.97 67.03 76.59 70.58 82.37 63.99 64.54 63.54
Multi-kidney [6] CNN 13.13 69.77 61.58 62.13 82.27 62.03 71.82 65.13 60.98
Omni-Seg [11] CNN 72.96 71.84 69.76 81.48 92.31 92.36 67.28 65.31 76.66
Segmenter [46] Transformer 56.38 67.34 54.81 69.14 67.16 66.78 49.92 49.87 60.18
SegFormer [49] Transformer 54.82 67.68 62.65 75.87 77.46 60.42 62.43 60.21 65.19
Unetr [24] Transformer 16.22 69.70 61.99 69.35 72.48 58.10 58.14 56.32 57.79
Swin-Unetr [23] Transformer 13.81 68.92 70.76 76.93 81.28 72.92 49.92 64.46 62.38
PrPSeg (Ours) CNN 72.38 72.64 72.45 85.27 94.23 94.40 70.98 66.96 78.66
*DT is distal tubular; PT is proximal tubular; Cap. is glomerular capsule
*Pod. is glomerular podocyte cell; Mes. is glomerular mesangial cell
ImageLabelU-NetDeepLabv3MedullaCortexDTTissue ObjectSegmentation Results in Different TissuesPTCAPTUFTResidual-U.Multi-KidneyOmni-SegSegmenterSegFormerUnetrSwin-UnetrPrPSeg*PodMes
Figure 5. Validation qualitative results – This figure shows the qualitative results of different approaches. The proposed method
achieved superior panoramic renal pathology segmentation on 8 classes range regions to cells with fewer false positives, false negatives,
and morphological errors.
the images were retrieved from the pool and input into the
network for processing. During each backpropagation step,
Binary Dice Loss and Cross-entropy Loss were combinedas the loss function in the supervised learning phase.
For weight optimization, we employed the Adam op-
timizer with an initial learning rate of 0.001 and a de-
11742
cay factor of 0.99. We also implemented general data
augmentation techniques, including Affine transformations,
Flip, Contrast adjustment, Brightness adjustment, Coarse
Dropout, Gaussian Blur, and Gaussian Noise. These aug-
mentations, sourced from the imgaug package [31], were
applied to the entire training dataset with a probability of
0.5.
Model selection was based on the mean Dice coefficient
score across 8 classes, evaluated on the validation dataset.
The best-performing models within the first 100 epochs
were then assessed on the testing dataset. Testing im-
ages were initially processed using either center-cropping
or non-overlapping tiling to attain the same uniform size
512×512pixels. For evaluation, these images were subse-
quently either center-cropped or re-aggregated to their orig-
inal dimensions. All experiments were conducted on a uni-
form platform, specifically a workstation equipped with an
NVIDIA RTX A6000 GPU.
5. Result
We conducted a comparative analysis of our proposed
Universal Proposition Learning approach against vari-
ous baseline models. These models include multi-class
segmentation architectures such as (1) U-Nets [20], (2)
DeepLabV3 [39], (3) Residual-U-Net [45], (4) a CNN-
based multi-class kidney pathology model [6], (5) Omni-
Seg [11], (6) Segmenter-ViT/16 [46], (7) SegFormer [49],
(8) Unetr [24], and (9) Swin-Unetr [23].
5.1. Panoramic Segmentation Performance
Table 2 and Figure 5 showcase the results from an 8-class
segmentation evaluation. Table 2 demonstrates that our pro-
posed method, PrPSeg, surpasses baseline models in most
evaluated metrics. Figure 5 further highlights the qualita-
tive superiority of our approach, evidenced by reduced in-
stances of false positives, false negatives, and morpholog-
ical errors. The Dice similarity coefficient (Dice: %, the
higher, the better) was employed as the primary metric for
quantitative performance assessment. The results indicate
that, while multi-head designs struggle with managing spa-
tial relationships between objects (e.g., subset/superset re-
lationships between the capsule and tuft), the dynamic-head
paradigm exhibits superior performance compared to other
methods.
5.2. Ablation Study
Table 3 showcases the enhancements brought about by our
proposed token-based design and learning strategy across
two different backbone architectures. The results indi-
cate that the token-based dynamic head design boosts the
model’s performance in segmenting all levels of objects.
With the integration of the token-based dynamic head ar-
chitecture and universal proposition learning, the proposedTable 3. Ablation study of different design. Dice similarity coeffi-
cient scores (%) are reported.
Backbone TDH UPL Regions Units Cells Average
Swin-Unetr [23] 41.37 75.47 57.19 62.38
Swin-Unetr [23] ✓ 68.55 82.70 49.90 70.97
Omni-Seg [11] 72.40 83.98 66.29 76.66
Omni-Seg [11] ✓ 72.43 86.39 66.49 77.89
PrPSeg (Ours) ✓ ✓ 72.51 86.58 68.97 78.66
*TDH is Token-based Dynamic Head
*UPL is Universal Proposition Learning
method exhibited superior performance across all consid-
ered metrics.
We also provide an ablation study for two data exten-
sion scenarios in the Appendix (A.1). The proposed PrPSeg
method is flexible to extend to new classes by merely up-
dating tokens and the adaptable proposition matrix, without
changing the backbone network, while demonstrating supe-
rior performance compared to baseline methods across all
seven new classes.
6. Conclusion
In this work, we have developed PrPSeg, a token-based
dynamic segmentation network, specifically crafted to fa-
cilitate panoramic renal pathology segmentation by effec-
tively modeling the spatial interconnections among diverse
anatomical structures. This innovative approach enables the
consistent use of the same architectural framework amidst
dataset expansions and introduces a universal proposition
matrix. This matrix adeptly transforms intricate anatomical
relationships into computational modeling paradigms. Fur-
thermore, we have introduced a novel anatomical loss func-
tion, integrating these spatial relationships into our model’s
training regimen through semi-supervised learning. To the
best of our knowledge, our algorithm is the first to achieve
comprehensive panoramic segmentation in the domain of
renal pathology. The integration of token-based dynamic
head design alongside our universal proposition learning
strategy, which meticulously maps anatomical relationships
into the realm of engineering programming, enhances the
model’s efficacy in all-encompassing segmentation.
7. Acknowledgement
This research was supported by NIH R01DK135597(Huo),
DoD HT9425-23-1-0003(HCY), NIH NIDDK
DK56942(ABF). This work was also supported by
Vanderbilt Seed Success Grant, Vanderbilt Discov-
ery Grant, and VISE Seed Grant. This research
was also supported by NIH grants R01EB033385,
R01DK132338, REB017230, R01MH125931, and
NSF 2040462. We extend gratitude to NVIDIA for
their support by means of the NVIDIA hardware
grant.
11743
References
[1] Jathin Bandari, Thomas W Fuller, Robert M Turner, and
Louis A D’Agostino. Renal biopsy for medical renal dis-
ease: indications and contraindications. Can J Urol , 23(1):
8121–6, 2016. 1
[2] Peter Bankhead, Maurice B Loughrey, Jos ´e A Fern ´andez,
Yvonne Dombrowski, Darragh G McArt, Philip D Dunne,
Stephen McQuaid, Ronan T Gray, Liam J Murray, Helen G
Coleman, et al. Qupath: Open source software for digital
pathology image analysis. Scientific reports , 7(1):1–7, 2017.
6
[3] Laura Barisoni, Cynthia C Nast, J Charles Jennette, Jeffrey B
Hodgin, Andrew M Herzenberg, Kevin V Lemley, Cather-
ine M Conway, Jeffrey B Kopp, Matthias Kretzler, Christa
Lienczewski, et al. Digital pathology evaluation in the mul-
ticenter nephrotic syndrome study network (neptune). Clin-
ical Journal of the American Society of Nephrology , 8(8):
1449–1459, 2013. 6
[4] T de Bel, Meyke Hermsen, Geert Litjens, and J Laak. Struc-
ture instance segmentation in renal tissue: a case study on
tubular immune cell detection. In Computational Pathology
and Ophthalmic Medical Image Analysis , pages 112–119.
Springer, 2018. 1
[5] Ewert Bengtsson, H ˚avard Danielsen, Darren Treanor,
Metin N Gurcan, Calum MacAulay, and B ´ela Moln ´ar.
Computer-aided diagnostics in digital pathology, 2017. 1
[6] Nassim Bouteldja, Barbara M Klinkhammer, Roman D
B¨ulow, Patrick Droste, Simon W Otten, Saskia Freifrau von
Stillfried, Julia Moellmann, Susan M Sheehan, Ron Ko-
rstanje, Sylvia Menzel, et al. Deep learning–based segmen-
tation and quantification in experimental kidney histopathol-
ogy. Journal of the American Society of Nephrology , 32(1):
52–68, 2021. 2, 7, 8
[7] Gloria Bueno, M Milagro Fernandez-Carrobles, Lucia
Gonzalez-Lopez, and Oscar Deniz. Glomerulosclerosis iden-
tification in whole slide images using semantic segmenta-
tion. Computer methods and programs in biomedicine , 184:
105273, 2020. 2
[8] Richard J. Chen, Chengkuan Chen, Yicong Li, Tiffany Y .
Chen, Andrew D. Trister, Rahul G. Krishnan, and Faisal
Mahmood. Scaling vision transformers to gigapixel images
via hierarchical self-supervised learning. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 16144–16155, 2022. 2
[9] Sihong Chen, Kai Ma, and Yefeng Zheng. Med3d: Trans-
fer learning for 3d medical image analysis. arXiv preprint
arXiv:1904.00625 , 2019. 2
[10] Ruining Deng, Yanwei Li, Peize Li, Jiacheng Wang, Lu-
cas W Remedios, Saydolimkhon Agzamkhodjaev, Zuhayr
Asad, Quan Liu, Can Cui, Yaohong Wang, et al. Democra-
tizing pathological image segmentation with lay annotators
via molecular-empowered learning. In International Confer-
ence on Medical Image Computing and Computer-Assisted
Intervention , pages 497–507. Springer, 2023. 6
[11] Ruining Deng, Quan Liu, Can Cui, Tianyuan Yao, Jun Long,
Zuhayr Asad, R Michael Womick, Zheyu Zhu, Agnes B
Fogo, Shilin Zhao, et al. Omni-seg: A scale-aware dynamicnetwork for renal pathological image segmentation. IEEE
Transactions on Biomedical Engineering , 2023. 1, 2, 5, 7, 8
[12] Huijun Ding, Zhanpeng Pan, Qian Cen, Yang Li, and Shifeng
Chen. Multi-scale fully convolutional network for gland seg-
mentation using three-class classification. Neurocomputing ,
380:150–161, 2020. 1
[13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,
Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,
Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-
vain Gelly, et al. An image is worth 16x16 words: Trans-
formers for image recognition at scale. arXiv preprint
arXiv:2010.11929 , 2020. 5
[14] Xi Fang and Pingkun Yan. Multi-organ segmentation over
partially labeled datasets with multi-scale feature abstrac-
tion. IEEE Transactions on Medical Imaging , 39(11):3619–
3629, 2020. 2
[15] Chunyue Feng and Fei Liu. Artificial intelligence in renal
pathology: Current status and future. Bosnian Journal of
Basic Medical Sciences , 2022. 2
[16] M Gadermayr, AK Dombrowski, BM Klinkhammer, P
Boor, and D Merhof. Cnn cascades for segmenting whole
slide images of the kidney. arxiv 2017. arXiv preprint
arXiv:1708.00251 . 2
[17] Jaime Gallego, Anibal Pedraza, Samuel Lopez, Georg
Steiner, Lucia Gonzalez, Arvydas Laurinavicius, and Glo-
ria Bueno. Glomerulus classification and detection based on
convolutional neural networks. Journal of Imaging , 4(1):20,
2018. 2
[18] Zeyu Gao, Bangyang Hong, Xianli Zhang, Yang Li, Chang
Jia, Jialun Wu, Chunbao Wang, Deyu Meng, and Chen Li.
Instance-based vision transformer for subtyping of papillary
renal cell carcinoma in histopathological image. In Medi-
cal Image Computing and Computer Assisted Intervention–
MICCAI 2021: 24th International Conference, Strasbourg,
France, September 27–October 1, 2021, Proceedings, Part
VIII 24 , pages 299–308. Springer, 2021. 2
[19] Jeremias Gomes, Jun Kong, Tahsin Kurc, Alba CMA Melo,
Renato Ferreira, Joel H Saltz, and George Teodoro. Building
robust pathology image analyses with uncertainty quantifica-
tion. Computer Methods and Programs in Biomedicine , 208:
106291, 2021. 1
[20] Germ ´an Gonz ´alez, George R Washko, and Ra ´ul San
Jos´e Est ´epar. Multi-structure segmentation from partially
labeled datasets. application to body composition measure-
ments on ct scans. In Image Analysis for Moving Or-
gan, Breast, and Thoracic Images , pages 215–224. Springer,
2018. 2, 7, 8
[21] Laxmi Gupta, Barbara Mara Klinkhammer, Peter Boor, Dorit
Merhof, and Michael Gadermayr. Iterative learning to make
the most of unlabeled and quickly obtained labeled data in
histology. In International Conference on Medical Imaging
with Deep Learning–Full Paper Track , 2018. 2
[22] Satoshi Hara, Emi Haneda, Masaki Kawakami, Kento
Morita, Ryo Nishioka, Takeshi Zoshima, Mitsuhiro
Kometani, Takashi Yoneda, Mitsuhiro Kawano, Shigehiro
Karashima, et al. Evaluating tubulointerstitial compartments
in renal biopsy specimens using a deep learning-based ap-
11744
proach for classifying normal and abnormal tubules. PloS
one, 17(7):e0271161, 2022. 2
[23] Ali Hatamizadeh, Vishwesh Nath, Yucheng Tang, Dong
Yang, Holger R Roth, and Daguang Xu. Swin unetr: Swin
transformers for semantic segmentation of brain tumors in
mri images. In International MICCAI Brainlesion Workshop ,
pages 272–284. Springer, 2021. 7, 8
[24] Ali Hatamizadeh, Yucheng Tang, Vishwesh Nath, Dong
Yang, Andriy Myronenko, Bennett Landman, Holger R
Roth, and Daguang Xu. Unetr: Transformers for 3d med-
ical image segmentation. In Proceedings of the IEEE/CVF
winter conference on applications of computer vision , pages
574–584, 2022. 7, 8
[25] Meyke Hermsen, Thomas de Bel, Marjolijn Den Boer, Eric J
Steenbergen, Jesper Kers, Sandrine Florquin, Joris JTH
Roelofs, Mark D Stegall, Mariam P Alexander, Byron H
Smith, et al. Deep learning–based histopathologic assess-
ment of kidney tissue. Journal of the American Society of
Nephrology , 30(10):1968–1979, 2019. 1
[26] John D Imig, Xueying Zhao, Ahmed A Elmarakby, and
Tengis Pavlov. Interactions between podocytes, mesangial
cells, and glomerular endothelial cells in glomerular dis-
eases. Frontiers in Physiology , page 488, 2022. 1
[27] Catherine P Jayapandian, Yijiang Chen, Andrew R
Janowczyk, Matthew B Palmer, Clarissa A Cassol, Miroslav
Sekulic, Jeffrey B Hodgin, Jarcy Zee, Stephen M Hewitt,
John O’Toole, et al. Development and evaluation of deep
learning–based segmentation of histologic structures in the
kidney cortex with multiple histologic stains. Kidney inter-
national , 99(1):86–101, 2021. 1, 6
[28] Jos ´eA Jim ´enez-Heffernan, M Auxiliadora Bajo, Cristian
Perna, Gloria del Peso, Juan R Larrubia, Carlos Gamallo,
Jos´eA S ´anchez-Tomero, Manuel L ´opez-Cabrera, and Rafael
Selgas. Mast cell quantification in normal peritoneum and
during peritoneal dialysis treatment. Archives of pathology
& laboratory medicine , 130(8):1188–1192, 2006. 1
[29] Tan Yee Jing, Nazahah Mustafa, Haniza Yazid, and Khairul
Shakir Ab Rahman. Segmentation of tumour regions for
tubule formation assessment on breast cancer histopathology
images. In Proceedings of the 11th International Conference
on Robotics, Vision, Signal Processing and Power Applica-
tions , pages 170–176. Springer, 2022. 2
[30] Jeremiah W Johnson. Automatic nucleus segmentation with
mask-rcnn. In Science and Information Conference , pages
399–407. Springer, 2019. 2
[31] Alexander B. Jung, Kentaro Wada, Jon Crall, Satoshi
Tanaka, Jake Graving, Christoph Reinders, Sarthak Ya-
dav, Joy Banerjee, G ´abor Vecsei, Adam Kraft, Zheng Rui,
Jirka Borovec, Christian Vallentin, Semen Zhydenko, Kil-
ian Pfeiffer, Ben Cook, Ismael Fern ´andez, Franc ¸ois-Michel
De Rainville, Chi-Hung Weng, Abner Ayala-Acevedo,
Raphael Meudec, Matias Laporte, et al. imgaug. https:
//github.com/aleju/imgaug , 2020. Online; ac-
cessed 01-Feb-2020. 8
[32] Shruti Kannan, Laura A Morgan, Benjamin Liang, McKen-
zie G Cheung, Christopher Q Lin, Dan Mun, Ralph G Nader,
Mostafa E Belghasem, Joel M Henderson, Jean M Francis,et al. Segmentation of glomeruli within trichrome images
using deep learning. Kidney international reports , 4(7):955–
962, 2019. 2
[33] Tsung-Wei Ke, Jyh-Jing Hwang, Yunhui Guo, Xudong
Wang, and Stella X. Yu. Unsupervised hierarchical semantic
segmentation with multiview cosegmentation and clustering
transformers. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , 2022. 2
[34] John A Kellum. Acute kidney injury. Critical care medicine ,
36(4):S141–S145, 2008. 1
[35] Neeraj Kumar, Ruchika Verma, Sanuj Sharma, Surabhi
Bhargava, Abhishek Vahadane, and Amit Sethi. A dataset
and a technique for generalized nuclear segmentation for
computational pathology. IEEE transactions on medical
imaging , 36(7):1550–1560, 2017. 1
[36] Liulei Li, Tianfei Zhou, Wenguan Wang, Jianwu Li, and Yi
Yang. Deep hierarchical semantic segmentation. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR) , pages 1246–1257, 2022. 2
[37] Yilong Li, Xingru Huang, Yaqi Wang, Zhaoyang Xu, Yibao
Sun, and Qianni Zhang. U-net ensemble model for segmen-
tation inhistopathology images. 2019. 1
[38] Zhenrong Lin, Jidong Li, Qipeng Yao, Haocheng Shen, and
Lihang Wan. Adversarial learning with data selection for
cross-domain histopathological breast cancer segmentation.
Multimedia Tools and Applications , 81(4):5989–6008, 2022.
2
[39] Brendon Lutnick, Brandon Ginley, Darshana Govind,
Sean D McGarry, Peter S LaViolette, Rabi Yacoub, Sanjay
Jain, John E Tomaszewski, Kuang-Yu Jen, and Pinaki Sarder.
An integrated iterative annotation technique for easing neural
network training in medical image analysis. Nature machine
intelligence , 1(2):112–119, 2019. 2, 7, 8
[40] Elise Marechal, Adrien Jaugey, Georges Tarris, Michel Pain-
davoine, Jean Seibel, Laurent Martin, Mathilde Funes de la
Vega, Thomas Crepin, Didier Ducloux, Gilbert Zanetta, et al.
Automatic evaluation of histological prognostic factors us-
ing two consecutive convolutional neural networks on kid-
ney samples. Clinical Journal of the American Society of
Nephrology , 17(2):260–270, 2022. 2
[41] David Marti-Aguado, Alejandro Rodr ´ıguez-Ortega, Claudia
Mestre-Alagarda, M ´onica Bauza, Elena Valero-P ´erez, Clara
Alfaro-Cervello, Salvador Benlloch, Judith P ´erez-Rojas, An-
tonio Ferr ´andez, Pilar Alemany-Monraval, et al. Digital
pathology: accurate technique for quantitative assessment of
histological features in metabolic-associated fatty liver dis-
ease. Alimentary Pharmacology & Therapeutics , 53(1):160–
171, 2021. 1
[42] Claire Mounier-Vehier, Christophe Lions, Patrick Devos,
Olivier Jaboureck, Serge Willoteaux, Alain Carre, and Jean-
Paul Beregi. Cortical thickness: an early morphological
marker of atherosclerotic renal disease. Kidney interna-
tional , 61(2):591–598, 2002. 1
[43] Cam Nguyen, Zuhayr Asad, and Yuankai Huo. Eval-
uating transformer-based semantic segmentation networks
for pathological image segmentation. arXiv preprint
arXiv:2108.11993 , 2021. 2
11745
[44] Jian Ren, Evita Sadimin, David J Foran, and Xin Qi. Com-
puter aided analysis of prostate histopathology images to
support a refined gleason grading system. In Medical Imag-
ing 2017: Image Processing , page 101331V . International
Society for Optics and Photonics, 2017. 1
[45] Massimo Salvi, Alessandro Mogetta, Alessandro Gambella,
Luca Molinaro, Antonella Barreca, Mauro Papotti, and Fil-
ippo Molinari. Automated assessment of glomerulosclerosis
and tubular atrophy using deep learning. Computerized Med-
ical Imaging and Graphics , 90:101930, 2021. 7, 8
[46] Robin Strudel, Ricardo Garcia, Ivan Laptev, and Cordelia
Schmid. Segmenter: Transformer for semantic segmenta-
tion. In Proceedings of the IEEE/CVF international confer-
ence on computer vision , pages 7262–7272, 2021. 7, 8
[47] Julia Wijkstr ¨om, Channa Jayasumana, Rajeewa Das-
sanayake, Nalin Priyawardane, Nimali Godakanda, Sisira
Siribaddana, Anneli Ring, Kjell Hultenby, Magnus
S¨oderberg, Carl-Gustaf Elinder, et al. Morphological
and clinical findings in sri lankan patients with chronic
kidney disease of unknown cause (ckdu): Similarities and
differences with mesoamerican nephropathy. PloS one , 13
(3):e0193056, 2018. 1
[48] Hao Wu, Shuchao Pang, and Arcot Sowmya. Tgnet: A
task-guided network architecture for multi-organ and tu-
mour segmentation from partially labelled datasets. In 2022
IEEE 19th International Symposium on Biomedical Imaging
(ISBI) , pages 1–5. IEEE, 2022. 1
[49] Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar,
Jose M Alvarez, and Ping Luo. Segformer: Simple and
efficient design for semantic segmentation with transform-
ers. Advances in Neural Information Processing Systems ,
34:12077–12090, 2021. 7, 8
[50] Shaoshuai Yan, Xiangsheng Huang, Wei Lian, and Caifang
Song. Self reinforcing multi-class transformer for kidney
glomerular basement membrane segmentation. IEEE Access ,
2023. 2
[51] Caihong Zeng, Yang Nan, Feng Xu, Qunjuan Lei, Fengyi
Li, Tingyu Chen, Shaoshan Liang, Xiaoshuai Hou, Bin Lv,
Dandan Liang, et al. Identification of glomerular lesions and
intrinsic glomerular cell types in kidney diseases via deep
learning. The Journal of pathology , 252(1):53–64, 2020. 1
[52] Jianpeng Zhang, Yutong Xie, Yong Xia, and Chunhua Shen.
Dodnet: Learning to segment multi-organ and tumors from
multiple partially labeled datasets. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern
Recognition , pages 1195–1204, 2021. 1, 2
[53] Yi Zheng, Clarissa A Cassol, Saemi Jung, Divya Veerapa-
neni, Vipul C Chitalia, Kevin YM Ren, Shubha S Bellur, Pe-
ter Boor, Laura M Barisoni, Sushrut S Waikar, et al. Deep-
learning–driven quantification of interstitial fibrosis in digi-
tized kidney biopsies. The American journal of pathology ,
191(8):1442–1453, 2021. 1
[54] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A
Efros. Unpaired image-to-image translation using cycle-
consistent adversarial networks. In Proceedings of the IEEE
international conference on computer vision , pages 2223–
2232, 2017. 6
11746
