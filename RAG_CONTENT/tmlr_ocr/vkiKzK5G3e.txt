Published in Transactions on Machine Learning Research (11/2023)
Neighborhood Gradient Mean: An Efficient Decentralized
Learning Method for Non-IID Data
Sai Aparna Aketi∗saketi@purdue.edu
Department of Electrical and Computer Engineering
Purdue University
Sangamesh Kodge∗skodge@purdue.edu
Department of Electrical and Computer Engineering
Purdue University
Kaushik Roy kaushik@purdue.edu
Department of Electrical and Computer Engineering
Purdue University
Reviewed on OpenReview: https: // openreview. net/ forum? id= vkiKzK5G3e
Abstract
Decentralized learning algorithms enable the training of deep learning models over large
distributed datasets, without the need for a central server. The current state-of-the-art de-
centralized algorithms mostly assume the data distributions to be Independent and Identi-
cally Distributed (IID). In practical scenarios, the distributed datasets can have significantly
different data distributions across the agents. This paper focuses on improving decentral-
ized learning on non-IID data with minimal compute and memory overheads. We propose
Neighborhood Gradient Mean (NGM) , a novel decentralized learning algorithm that modifies
the local gradients of each agent using self- and cross-gradient information. In particular,
the proposed method averages the local gradients with model-variant or data-variant cross-
gradients based on the communication budget. Model-variant cross-gradients are derivatives
of the received neighbors’ model parameters with respect to the local dataset. Data-variant
cross-gradient derivatives of the local model with respect to its neighbors’ datasets. The
data-variant cross-gradients are aggregated through an additional communication round.
We theoretically analyze the convergence characteristics of NGMand demonstrate its ef-
ficiency on non-IID data sampled from various vision and language datasets. Our exper-
iments demonstrate that the proposed method either remains competitive or outperforms
(by0−6%) the existing state-of-the-art (SoTA) decentralized learning algorithm on non-IID
data with significantly less compute and memory requirements. Further, we show that the
model-variant cross-gradient information available locally at each agent can improve the
performance on non-IID data by 2−20%without additional communication cost.
1 Introduction
The remarkable success of deep learning is mainly attributed to the availability of humongous amounts of
data and computing power. Large amounts of data are generated on a daily basis at different devices all over
the world which could be used to train powerful deep learning models. Collecting such data for centralized
processing is not practical because of communication and privacy constraints. To address this concern, a
new interest in developing distributed learning algorithms (Agarwal & Duchi, 2011) has emerged. Federated
learning (centralized learning) (Konecny et al., 2016) is a popular setting in the distributed machine learning
*These authors contributed equally to this work
1Published in Transactions on Machine Learning Research (11/2023)
paradigm, where the training data is kept locally at the edge devices and a global shared model is learned
by aggregating the locally computed updates through a coordinating central server. Such a setup requires
continuous communication with a central server which becomes a potential bottleneck (Haghighat et al.,
2020). This has motivated the advancements in decentralized machine learning.
Decentralized machine learning is a branch of distributed learning that focuses on learning from data dis-
tributed across multiple agents/devices. Unlike Federated learning, these algorithms assume that the agents
are connected peer to peer without a central server. It has been demonstrated that decentralized learning al-
gorithms (Lian et al., 2017) can perform comparably to centralized algorithms on benchmark vision datasets.
Lian et al. (2017) present Decentralised Parallel Stochastic Gradient Descent (D-PSGD) by combining SGD
withgossipaveragingalgorithm(Xiao&Boyd,2004). Further, theauthorsanalyticallyshowthattheconver-
gence rate of D-PSGD is similar to its centralized counterpart (Dean et al., 2012). Decentralized Momentum
Stochastic Gradient Descent (DMSGD) which introduces momentum to D-PSGD was proposed and analyzed
in Balu et al. (2021). Assran et al. (2019) introduce Stochastic Gradient Push (SGP) which extends D-PSGD
to directed and time-varying graphs. Tang et al. (2019); Koloskova et al. (2019) explore error-compensated
compression techniques (Deep-Squeeze and CHOCO-SGD) to reduce the communication cost of D-PSGD
significantly while achieving the same convergence rate as centralized algorithms. Aketi et al. (2021) com-
bined Deep-Squeeze with SGP to propose communication-efficient decentralized learning over time-varying
and directed graphs. Lu & De Sa (2020); Liu et al. (2020b); Zhao et al. (2022); Takezawa et al. (2023) also
explore communication compression in decentralized setups. Recently, Koloskova et al. (2020) proposed a
unified framework for the analysis of gossip-based decentralized SGD methods and provide the best-known
convergence guarantees.
The key assumption to achieve state-of-the-art performance by all the above-mentioned decentralized algo-
rithms is that the data is independent and identically distributed (IID) across the agents. In particular, the
data is assumed to be distributed in a uniform and random manner across the agents. This assumption does
not hold in most of the real-world applications as the data distributions across the agents are significantly
different (non-IID) based on the user pool (Hsieh et al., 2020). The effect of non-IID data in a peer-to-peer
decentralized setup is a relatively under-studied problem. There are only a few works that try to bridge the
performance gap between IID and non-IID data for a decentralized setup. Note that, we mainly focus on
a common type of non-IID data, widely used in prior works (Tang et al., 2018; Lin et al., 2021; Esfandiari
et al., 2021): a skewed distribution of data labels across agents. Tang et al. (2018) proposed D2algorithm
that extends D-PSGD to non-IID data. However, the algorithm was demonstrated on only a basic LeNet5
(LeCun et al., 1998) model and is not scalable to deeper models with normalization layers. SwarmSGD
proposed by Nadiradze et al. (2019) leverages random interactions between participating agents in a graph
to achieve consensus. Lin et al. (2021) replace local momentum with Quasi-Global Momentum (QGM) and
improve the test performance by 1−20%. However, the improvement in accuracy is only 1−2%in case
of highly skewed data distribution as shown in Aketi et al. (2022). Tracking mechanisms such as Gradient
Tracking (Di Lorenzo & Scutari, 2016; Pu & Nedić, 2021; Koloskova et al., 2021) and Momentum Tracking
(Takezawa et al., 2022) have been proposed to tackle non-IID data in decentralized settings at the cost of
2×communication overhead. Most recently, Esfandiari et al. (2021) proposed Cross-Gradient Aggregation
(CGA) and a compressed version of CGA (CompCGA), claiming state-of-the-art performance for decen-
tralized learning algorithms over completely non-IID data. CGA aggregates cross-gradient information, i.e.,
derivatives of its model with respect to its neighbors’ datasets through an additional communication round.
It then updates the model using projected gradients based on quadratic programming. CGA and CompCGA
require a very slow quadratic programming step (Goldfarb & Idnani, 1983) after every iteration for gradient
projection which is both compute and memory intensive. This work focuses on the following question: Can
we improve the performance of decentralized learning on non-IID data with minimal compute and memory
overhead?
In this paper, we propose Neighborhood Gradient Mean (NGM) algorithm with two variants to handle
non-IID data in peer-to-peer decentralized learning setups. Firstly, we classify the gradients at each agent
into three types, namely self-gradients, model-variant cross-gradients, and data-variant cross-gradients (see
Section 3). The self-gradients (or local gradients) are the derivatives computed at each agent on its model
parameters with respect to the local dataset. The model-variant cross-gradients are the derivatives of the
2Published in Transactions on Machine Learning Research (11/2023)
received neighbors’ model parameters with respect to the local dataset. These gradients are computed
locally at each agent after receiving the neighbors’ model parameters. Communicating the neighbors’ model
parameters is a necessary step in any gossip-based decentralized algorithm (Lian et al., 2017). The data-
variant cross-gradients are the derivatives of the local model with respect to its neighbors’ datasets. These
gradients are obtained through an additional round of communication. We then cluster the gradients into
a)model-variant cluster with self-gradients and model-variant cross-gradients, and b) data-variant cluster
with self-gradients and data-variant cross-gradients. Finally, the local gradients are replaced with the model-
variant cluster means in NGM mvwhere the communication budget is 1×, and with the data-variant cluster
means in NGM dvwhere the communication budget is 2×. The main motivation behind this modification is
to account for the high variation in the computed local gradients (and in turn the model parameters) across
the neighbors due to the non-IID nature of the data distribution.
The proposed NGM dvhas two rounds of communication at every iteration to send model parameters and
data-variant cross-gradients. This incurs 2×communication cost compared to traditional decentralized al-
gorithms (D-PSGD). To reduce this communication overhead, we show that NGM dvcan be combined with
error feedback-based compression methods to compress the additional round of cross-gradient communica-
tion. Note that NGM mvhas no communication overhead. We provide a detailed convergence analysis of the
proposed NGM dvalgorithm and show that the analysis can be trivially extended to NGM mv. We validate
the performance of the proposed algorithm on various datasets, model architectures, and graph topologies.
We compare the proposed algorithm with several baselines such as D-PSGD (Lian et al., 2017), QG-DSGDm
(Lin et al., 2021), Momentum Tracking (Takezawa et al., 2022), and CGA (Esfandiari et al., 2021). Our
experiments show that NGMcan achieve superior performance on non-IID data compared to the current
state-of-the-art approaches. We also report the order of communication, memory, and compute overheads
required for various decentralized algorithms as compared to D-PSGD.
Contributions: In summary, we make the following contributions.
•We propose the Neighborhood Gradient Mean ( NGM) algorithm with two variations for decentral-
ized learning on non-IID data. NGM mvutilizes self-gradients and model-variant cross-gradients to
improve the performance on non-IID data. NGM dvimproves this performance further by utilizing
self-gradients and data-variant cross-gradients at the cost of 2×communication overhead.
•We theoretically show that the convergence rate of NGMisO(1√
NK), which is consistent with the
state-of-the-art decentralized learning algorithms.
•NGM mvoutperforms the QG-DSGDm baseline by 2−20%without any communication overhead.
•NGM dveither remains competitive or outperforms by 0−6%with significantly less compute and
memory requirements compared to the current state-of-the-art at iso-communication.
2 Background
In this section, we provide the background on decentralized learning algorithms with peer-to-peer connec-
tions.
The main goal of decentralized machine learning is to learn a global model using the knowledge extracted
from the locally generated and stored data samples across Nedge devices/agents while maintaining pri-
vacy constraints. In particular, we solve the optimization problem of minimizing global loss function F(x)
distributed across Nagents as given in equation. 1.
min
x∈RdF(x) =1
NN/summationdisplay
i=1fi(x),
and fi(x) =Edi∈Di[Fi(x;di)]∀i(1)
This is typically achieved by combining stochastic gradient descent (Bottou, 2010) with global consensus-
based gossip averaging (Xiao & Boyd, 2004). The communication topology in this setup is modeled as a
3Published in Transactions on Machine Learning Research (11/2023)
graphG= ([N],E)with edges{i,j}∈Eif and only if agents iandjare connected by a communication link
exchanging the messages directly. We represent Nias the neighbors of iincluding itself. It is assumed that
the graphGis strongly connected with self-loops i.e., there is a path from every agent to every other agent.
The adjacency matrix of the graph Gis referred to as a mixing matrix Wwherewijis the weight associated
withtheedge{i,j}. Notethat, weight 0indicatestheabsenceofadirectedgebetweentheagents. Weassume
that the mixing matrix is doubly-stochastic and symmetric, similar to all previous works in decentralized
learning. For example, in a undirected ring topology, wij=1
3ifj∈{i−1,i,i+ 1}. Further, the initial
models and all the hyperparameters are synchronized at the beginning of the training. Algorithm. 2 in the
appendix describes the flow of D-PSGD with momentum. The convergence of the Algorithm. 2 assumes the
data distribution across the agents to be Independent and Identically Distributed (IID).
3 Neighborhood Gradient Mean
We propose the Neighborhood Gradient Mean (NGM) algorithm and a compressed version of NGMwhich
improve the performance of decentralized learning on non-IID data. We define the concepts of self-gradients
and cross-gradients below.
Self-Gradient: For an agent iwith the local dataset Diand model parameters xi, the self-gradient is the
gradient of the loss function fiwith respect to the model parameters xi, evaluated on mini-batch disampled
from dataset Di.
gii=∇xFi(xi;di) (2)
Cross-Gradient: For an agent iwith model parameters xiconnected to neighbor jthat has local dataset
Dj, the cross-gradient is the gradient of the loss function fjwith respect to the model parameters xi,
evaluated on mini-batch djsampled from dataset Dj.
gij=∇xFj(xi;dj) (3)
At each agent i, we further divide the cross-gradients into two categories. 1) Model-variant cross-gradients :
The derivatives that are computed locally using its local data on the neighbors’ model parameters ( gji). 2)
Data-variant cross-gradients : The derivatives (received through communication) of its model parameters on
the neighbors’ dataset ( gij). Note that an agent icomputes the cross-gradients gjithat act as model-variant
cross-gradients for iand as data-variant cross-gradients for j. In particular, the data-variant cross-gradient
ofii.e.,gijis computed by agent jusing its local data djafter receiving the model parameters xifromi
and is then communicated to agent iif needed.
3.1 The NGMalgorithm
The pseudo-code of the Neighborhood Gradient Mean ( NGM) is shown in Algorithm. 1. The overview of
the algorithm is illustrated in Figure. 5 of Appendix A.3.
The main contribution of the proposed NGMalgorithm is the local gradient manipulation step (line 12 in
Algorithm. 1). We first introduce a hyper-parameter αcalledNGM mixing weight which is either set to
0or1. In thekthiteration of NGM, each agent icalculates its self-gradient gii. Then, agent i’s model
parameters are transmitted to all other agents ( j) in its neighborhood, and the respective cross-gradients
are calculated by the neighbors. These cross-gradients are transmitted back to agent ithrough an additional
communication round if αis set to 1. At every iteration after the first communication round, each agent
ihas access to self-gradients ( gii) and model-variant cross-gradients. When αis set to 1, the agents get
access to data-variant cross-gradients through a second round of communication. Now, we group these
cross-gradients into two clusters: a) Model-variant cluster {gji∀j∈Ni}that includes self-gradients and
model-variant cross-gradients, and b) Data-variant cluster {gij∀j∈Ni}that includes self-gradients and
data-variant cross-gradients. The local gradients at each agent are replaced with either of the clusters’ mean
based onαvalue as shown in Equation. 4, which assumes a uniform mixing matrix ( wij= 1/m;m=|Ni|).
4Published in Transactions on Machine Learning Research (11/2023)
Algorithm 1 Neighborhood Gradient Mean ( NGM)
Input:Each agent i∈[1,N]initializes model weights xi
(0), step sizeη, momentum coefficient β, averaging
rateγ, mixing matrix W= [wij]i,j∈[1,N],NGMmixing weight α∈{0,1}, andIijare elements of N×N
identity matrix,Nirepresents neighbors of iincluding itself.
Each agent simultaneously implements the T RAIN( ) procedure
1.procedure TRAIN( )
2.fork=0,1,...,K−1do
3.di
k∼Di
4.gii
k=∇xfi(di
k;xi
k)
5. S ENDRECEIVE(xi
k)
6. foreach neighbor j∈{Ni−i}do
7.gji
k=∇xfi(di
k;xj
k)
8. ifα̸= 0: SENDRECEIVE(gji
k)
11. end
12./tildewidegi
k=/summationtext
j∈Ni[(1−α)wjigji
k+αwijgij
k]
13.vi
k=βvi
(k−1)−η/tildewidegi
k
14./tildewidexi
k=xi
k+vi
k
15.xi
(k+1)=/tildewidexi
k+γ/summationtext
j∈Ni(wij−Iij)xj
k
16. end
17.return
Whenαis set to zero, the proposed algorithm modifies the local gradient with model-variant cluster mean
and this is referred to as NGM mv. This version of the algorithm does not incur any communication overhead
Theα= 1version of the algorithm replaces local gradient with data-variant cluster mean and is referred
to asNGM dv. Settingαto any non-zero value requires an additional round of communication and we
experimentally determine that α= 1gives the best results (refer section. 6 for more details).
/tildewidegi
k= (1−α)/bracketleftig1
m/summationdisplay
j∈Nigji
k/bracketrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
(a) Model-variant cluster mean+α/bracketleftig1
m/summationdisplay
j∈Nigij
k/bracketrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
(b) Data-variant cluster mean(4)
The motivation for this modification is to reduce the variation of the computed local gradients across the
agents. In IID settings, the local gradients should statistically resemble the cross-gradients and hence simple
gossip averaging is sufficient to reach convergence. However, in the non-IID case, the local gradients across
the agents are significantly different due to the variation in datasets and hence the model parameters on
which the gradients are computed. The proposed algorithm reduces this variation in the local gradients as it
is equivalent to adding the bias term ϵforNGM mvand the bias term ωforNGM dvas shown in Equation. 5.
/tildewidegi
k=gii
k+ (1−α)/bracketleftig1
m/summationdisplay
j∈Ni(gji
k−gii
k)/bracketrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
model variance bias ϵi
k+α/bracketleftig1
m/summationdisplay
j∈Ni(gij
k−gii
k)/bracketrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
data variance bias ωi
k
ϵi
k=1
m/summationdisplay
j∈Ni/parenleftbig
∇xF(di
k;xj
k)−∇xF(di
k;xi
k)/parenrightbig
ωi
k=1
m/summationdisplay
j∈Ni/parenleftbig
∇xF(dj
k;xi
k)−∇xF(di
k;xi
k)/parenrightbig(5)
5Published in Transactions on Machine Learning Research (11/2023)
The bias term ϵcompensates for the difference in a neighborhood’s self-gradients caused due to variation
in the model parameters across the neighbors. Whereas, the bias term ωcompensates for the difference
in a neighborhood’s self-gradients caused due to variation in the data distribution across the neighbors.
We hypothesize and show through our experiments that the addition of one of these bias terms to the
local gradients improves the performance of decentralized learning on non-IID data by accelerating global
convergence.
4 Convergence Analysis of NGM
In this section, we provide a convergence analysis for NGM dv. We assume that the following statements
hold:
Assumption 1 - Lipschitz Gradients: Each function fi(x)is L-smooth.
Assumption 2 - Bounded Variance: The variance of the stochastic gradients is assumed to be bounded.
Ed∼Di||∇Fi(x;d)−∇fi(x)||2≤σ2∀i∈[1,N] (6)
||∇fi(x)−∇F (x)||2≤ζ2∀i∈[1,N] (7)
Assumption 3 - Doubly Stochastic Mixing Matrix: The mixing matrix Wis a real doubly stochastic
matrix with λ1(W) = 1and
max{|λ2(W)|,|λN(W)|}≤√ρ<1 (8)
whereλi(W)is theithlargest eigenvalue of W and ρis a constant.
The above assumptions are commonly used in most decentralized learning setups.
Lemma 1. Given assumptions 1-3, we define gi=∇Fi(x;d)and the NGM gradient update /tildewidegi. For alli,
we have:
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1(˜gi−gi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤4(σ2
N+ζ2) (9)
A complete proof for Lemma 1 can be found in Appendix. A.1. This lemma bounds the difference between
self-gradients and the proposed gradients in terms of inter- and intra-gradient variance bounds. The inter-
gradient variation bounded by ζ2determines the heterogeneity in the data distribution i.e., the non-IIDness.
The intra-gradient variation bounded by σ2determines the stochastic noise across the mini-batches within an
agent. Intuitively, thedistancebetweentheself-gradients giandtheNGM dvgradientupdate /tildewidegiincreaseswith
an increase in the degree of heterogeneity in data distribution which is expected. Note that the convergence
rate forNGM mvremains the same as CGA where E/bracketleftbig/vextenddouble/vextenddouble(˜gi−gi)/vextenddouble/vextenddouble2/bracketrightbig
is bounded by a positive constant which
is of the order of1
K.
Theorem 1 presents the convergence of the proposed NGM dvalgorithm and the proof is detailed in Ap-
pendix A.2.2
Theorem 1. (Convergence of NGM dvalgorithm) Given assumptions 1-3 and lemma 1, let step size ηsatisfy
the following conditions:
(1)η≤/radicalbig
4(1−√ρ)2+ 6(1−√ρ)(1−β)2−2(1−√ρ)
6L
(2) 1−Lη
2(/radicalbigg
1 +4
Lη−1)<β < 1
For allK≥1, we have
1
KK−1/summationdisplay
k=0E[||∇F (¯xk)||2]≤1
C1K(F(¯x0)−F∗) +C2(σ2
N+ζ2) +C3(σ2+ζ2)
(1−√ρ)2(10)
whereβ= momentum coefficient, ¯xk=1
N/summationtextN
i=1xi
k
6Published in Transactions on Machine Learning Research (11/2023)
C1=1
2(η
1−β−(1−β)
βL),C2=/parenleftig
10η2L(η2+β)
(1−β)3/parenrightig
/C1=20η2L2β(η2+β)
(1−β)2(ηβL−(1−β)2), andC3=14η3L3β
(1−β)2(ηβL−(1−β)2).
The result of the theorem. 1 shows that the magnitude of the average gradient achieved by the consensus
model is upper-bounded by the difference between the initial objective function value and the optimal value,
the sampling variance, and gradient variations across the agents representing data heterogeneity. A detailed
explanation of the constraints on step size and momentum coefficient is presented in the Appendix. A.2.3.
Further, we present a corollary to show the convergence rate of NGM dvin terms of the number of iterations.
Corollary 1. Suppose that the step size satisfies η=O/parenleftig/radicalig
N
K/parenrightig
and thatζ2=O/parenleftig
1
(1−√ρ)N/parenrightig
. For a sufficiently
largeK≥36NL2
r2,and
r=/radicalbig
4(1−√ρ)2+ 6(1−√ρ)(1−β)2−2(1−√ρ), we have, for some constant C > 0,
1
KK−1/summationdisplay
k=0E/bracketleftig
∥∇F (¯xk)∥2/bracketrightig
≤C/parenleftigg
1√
NK+1
K/parenrightigg
.
The proof for Corollary. 1 can be found in Appendix. A.2.4. Here, the constant Cdepended on the spectral
gapρ, stochastic noise bound σ2and the inter gradient variance bound ζ2. The bound on ζ2is the result
of the assumption that the graphs with higher connectivity (lower spectral gap) can tolerate more non-
IIDness. Corollary. 1 indicates that the proposed algorithm achieves linear speedup (with a convergence rate
ofO(1√
NK))whenKis sufficiently large. This convergence rate is similar to the well-known best result for
decentralized SGD algorithms in the literature as shown in Table. 1.
Table 1: Convergence rate comparison between decentralized learning algorithms.
Method Rate Assumption Simplified Rate
D-PSGDO/parenleftig
1+σ2
√
NK+N2σ2
K(1−ρ)+N2ζ2
K(1−√ρ)2/parenrightig
-O(1√
NK+1
K)
CGAO/parenleftig
1+σ2
√
NK+N(ζ2+σ2+ϵ2)
K(1−√ρ)2+ (√
K√
N+√
N√
K)ϵ2/parenrightig
ϵ2=O(1
K)O(1√
NK+1
K+1
K1.5+1
K2)
NGM dv(ours)O/parenleftig
1+σ2
√
NK+N(σ2+ζ2)
K(1−√ρ)2+√
N√
Kζ2/parenrightig
ζ2=O(1
(1−√ρ)N)O(1√
NK+1
K)
5 Experiments
In this section, we analyze the performance of the proposed NGM mv, andNGM dvtechniques and compare
them with the corresponding baseline i.e., D-PSGD algorithm (Lian et al., 2017), QG-DSGDm (Lin et al.,
2021), Momentum Tracking (Takezawa et al., 2022) and state-of-the-art CGA method (Esfandiari et al.,
2021).*
5.1 Experimental Setup
The efficiency of the proposed method is demonstrated through our experiments on a diverse set of datasets,
model architectures, tasks, topologies, and numbers of agents. We present the analysis on – (a) Datasets
(Appendix A.5): vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST and Imagenette (Husain, 2018))
and language datasets (AGNews (Zhang et al., 2015)). (b) Model architectures (Appendix A.6): 5-layer
CNN, VGG-11, ResNet-20, LeNet-5, MobileNet-V2, ResNet-18, BERT miniand DistilBERT base(c) Tasks:
Image and Text Classification. (d) Topologies: Ring, Chain, and Torus. (e) Number of agents: varying from
4 to 20. Note that we use low-resolution ( 32×32) images of the Imagenette dataset for the experiments in
Table. 3. The results for high resolution ( 224×224) Imagenette are presented in Table. 4.
*Our PyTorch code is available at https://github.com/aparna-aketi/neighborhood_gradient_clustering
7Published in Transactions on Machine Learning Research (11/2023)
We consider an extreme case of non-IID distribution where no two neighboring agents have the same class.
This is referred to as complete label-wise skew or 100% label-wise non-IIDness (Hsieh et al., 2020). In
particular, for a 10-class dataset such as CIFAR-10 - each agent in a 5-agent system has data from 2 distinct
classes, and each agent in a 10-agent system has data from a unique class. For a 20-agent system, two agents
thataremaximallyapartsharethesamplesbelongingtoaclass. Wereportthetestaccuracyoftheconsensus
model averaged over three randomly chosen seeds. The details of the hyperparameters for all the experiments
are present in Appendix. A.10. We compare the proposed method with iso-communication baselines. The
experiments on NGMmvare compared with D-PSGD and QG-DSGDm, NGMdvwith Momentum Tracking
and CGA. The communication cost for each experiment in this section is presented in Appendix A.9.
5.2 Results
Firstly, we evaluate variants of NGMand compare them with respective baselines in Table. 2, for training
different models trained on CIFAR-10 over various graph sizes and topologies. We observe that NGM mv
consistently outperforms QG-DSGDm for all models and graph sizes over ring topology with a significant
performance gain varying from 2−20%. For the torus topology, NGM mvoutperforms D-PSGD by 14−
18%and QG-DSGDm fails to converge. Our experiments show the superiority of NGM dvover CGA. The
performance gains are more pronounced when considering larger graphs (with 20 agents) and compact
models such as ResNet-20. We observe that CGA and NGMperform better than Momentum Tracking in
most cases. We further demonstrate the generalizability of the proposed method by evaluating it on various
image datasets (refer Table. 3) such as Fashion MNIST, and Imagenette and on challenging datasets such
as CIFAR-100. Table. 3, 4 show that NGM mvoutperforms QG-DSGDm by 1−18%across various datasets
whereasNGM dvremain competitive with an average improvement of ∼1%.
Table 2: Average test accuracy comparisons for CIFAR-10 with non-IID data using various architectures and
graph topologies. The results are averaged over three seeds where std is indicated.
Method Agents5layer CNN 5layer CNN VGG-11 ResNet-20
Ring Torus Ring Ring
5 76.00±1.44 - 67.04 ±5.36 82.13±0.84
D-PSGD 10 47.68 ±3.20 55.34±6.32 44.14±3.30 31.66±6.01
20 44.85±1.94 50.12±1.91 38.92±2.99 31.94±2.91
5 78.77±0.69 - 81.71 ±0.45 82.59±2.66
QG-DSGDm 10 47.83 ±3.39 14.48±0.50 57.77±0.33 46.09±7.90
20 46.57±4.80 17.25±5.81 32.32±7.61 44.78±3.39
5 82.20±0.34 - 83.65±0.38 85.88±0.58
NGM mv(ours) 10 67.43±1.15 73.84±0.33 59.92±2.12 66.02±2.86
20 58.80±1.30 64.55±1.16 52.70±1.63 50.74±2.36
5 80.34±0.67 - 79.62 ±7.42 85.65±0.30
Momentum Tracking 10 58.54 ±7.51 67.46±1.10 73.51±1.42 66.37±7.72
20 36.58±11.5 56.71±1.96 36.12±13.8 44.35±11.7
5 82.20±0.43 - 84.41 ±0.22 87.52±0.50
CGA 10 72.96 ±0.40 76.04±0.62 79.66±0.4679.98±1.23
20 69.88±0.84 73.21±0.27 79.30±0.12 75.13±1.56
5 83.36±0.65 - 85.15±0.58 88.52±0.19
NGM dv(ours) 10 75.34±0.30 78.53±0.56 79.55±0.30 84.02±0.44
20 73.36±0.88 75.11±0.07 79.43±0.62 81.26±0.69
To show the effectiveness of the proposed method across different modalities, we present results on the text
classification task in Table 4. We train on the BERT minimodel with the AGNews dataset distributed over
4 and 8 agents and DistilBert basedistributed over 4 agents. For NGM mv, we see a maximum improvement
of2.1% over the baseline D-PSGD algorithm. Even for the text classification task, we observe NGM dvto
be competitive with CGA. These observations are consistent with the results of the image classification
8Published in Transactions on Machine Learning Research (11/2023)
Table 3: Average test accuracy comparisons for various datasets with non-IID sampling trained over undi-
rected ring topology. The results are averaged over three seeds where std is indicated.
Method AgentsFashion MNIST CIFAR-100 Imagenette (32 ×32)
(LeNet-5) (ResNet-20) (MobileNet-V2)
D-PSGD5 86.43±0.14 44.66±5.23 47.09 ±9.20
10 75.49±0.32 19.03±13.27 32.81 ±2.18
QG-DSGDm5 89.28±0.52 49.60±3.30 43.70 ±2.80
10 84.38±0.58 41.28±0.61 17.80 ±2.66
NGM mv(ours)5 90.03±0.11 55.96±0.95 60.15 ±2.17
10 87.10±0.47 49.30±1.02 36.13 ±1.97
Momentum Tracking5 90.52±0.56 49.52±2.36 38.79 ±2.21
10 87.82±0.19 37.74±4.74 23.07 ±11.3
CGA5 90.03±0.39 56.43±2.39 72.82 ±1.25
10 87.61±0.30 53.61±1.07 61.97 ±0.58
NGM dv(ours)5 90.61±0.18 56.50±3.23 74.49 ±0.93
10 87.24±0.23 53.77±0.15 64.06 ±1.11
tasks. Finally, through this exhaustive set of experiments, we demonstrate that the NGM dvcan serve as a
simple plugin to boost the performance of decentralized learning on non-IID data without significant memory
and compute overheads. Further, NGM mvdemonstrates that locally available model-variant cross-gradient
information at each agent can be efficiently utilized to improve decentralized learning with no communication
overhead.
Table 4: Average test accuracy comparisons for AGNews dataset (left side of the table) and full resolution
(224×224) Imagenette dataset (right side of the table). The results are averaged over three seeds where std
is indicated.
MethodAGNews-BERT mini AGNews-DistilBERT baseImagenette (224×224)-ResNet-18
Agents = 4 Agents = 8 Agents = 4 Agents = 5
Ring Topology Ring Topology Ring Topology Chain Topology
D-PSGD 89.21 ±0.41 85.48±0.71 91.54 ±0.07 65.43±4.60 42.02±1.25
QG-DSGDm 87.38 ±5.29 76.61±3.63 93.55 ±0.23 74.22±2.30 43.35±4.57
NGM mv(ours) 89.40±0.13 87.58±0.07 93.60 ±0.12 78.26±0.67 47.87±0.99
Momentum Tracking 82.45 ±6.19 87.82±0.047 93.87 ±0.15 81.11±0.29 22.12±2.93
CGA 91.43 ±0.11 89.15±0.45 93.42±0.04 85.00±0.67 65.96±1.84
NGM dv(ours) 92.24±0.2989.02±0.39 94.11±0.01 85.85±0.60 67.77±1.76
(a)NGM mvon IID data
 (b)NGM mvon Non-IID data
 (c) Non-IID, ring topology
Figure 1: Average Validation loss of NGM mvduring training CIFAR-10 on a 5-layer CNN with 5 agents.
9Published in Transactions on Machine Learning Research (11/2023)
(a)NGM dvon IID data
 (b)NGM dvon Non-IID data
 (c) Non-IID, ring topology
Figure 2: Average Validation loss of NGM dvduring training CIFAR-10 on a 5-layer CNN with 5 agents.
(a) Model variance bias of NGM mv
 (b) Model variance bias of NGM dv
 (c) Data variance bias of NGM dv
Figure 3: Ablation study: CIFAR-10 dataset trained on a 5-layer CNN over ring graph 5 agents.
5.3 Analysis
Weempiricallyshowthegeneralizationcharacteristicsintermsofvalidationlossconvergencefortheproposed
algorithm on IID and Non-IID data in Figures. 1(a), 2(a), and Figures. 1(b), 2(b) respectively. For Non-IID
data, we observe that there is a slight difference in convergence (as expected) with a slower rate for sparser
topology (ring graph) compared to a denser counterpart (fully connected graph). Figure. 1(c), 2(c) shows
the comparison of the generalization characteristics of the NGM mvandNGM dvalgorithm with the respective
baselines. For the same decentralized setup, We observe that NGM mvandNGM dvhave lower validation loss
than D-PSGD and CGA respectively. Analysis for 10 agents is presented in Appendix A.7.
Then we proceed to analyze the model variance and data variance bias terms when training with various
decentralized methods. Figure. 3(a) shows that the model variance bias of NGM mvis much lower than of the
D-PSGD baseline resulting in the better performance of NGM mv. We then compare the model variance and
data variance bias terms of NGM dvwith CGA as shown in Figure. 3(b), and 3(c) respectively. We observe
that both the model variance and the data variance bias for NGM dvare significantly lower than CGA. This
is because CGA gives more importance to self-gradients as it updates in the descent direction that is close
to self-gradients and is positively correlated to data-variant cross-gradients. In contrast, NGMaccounts for
the biases directly and gives equal importance to self-gradients and data-variant cross-gradients, thereby
achieving superior performance. Further, Figure.4(a) presents the average consensus error i.e.,1
n||xi
k−¯xk||2
F
over time for training CIFAR-10 dataset on 5-layer CNN with respect to various algorithms. This empirically
shows that the proposed NGMalgorithm reaches the consensus at the same rate as CGA.
Additionally, we show that NGMcan be used in synergy with QGM (Lin et al., 2021) to further improve
the performance of decentralized learning on non-IID Data. Figure. 4(b) shows the test accuracy on the
CIFAR-10 dataset trained on ResNet-20 over ring topology. We observe that the QGM version of NGM mv
performs better than NGM mvby16−27%. Similarly, the QGM version of NGM dvperforms 1.3−2.5%
better than the local momentum version of NGM dv.
10Published in Transactions on Machine Learning Research (11/2023)
(a) Consensus Error with 5-layer CNN
over 5 agents
10 nodes 20 nodes405060708090 Test Accuracy (%)QG-DSGDm
ngm mv
ngm mv+QGM
ngm dv
ngm dv+QGM(b) Training ResNet-20 by combining
NGM with Quasi Global Momentum
(c) Ablation study on αwith 5-layer
CNN over 5 agents
Figure 4: Training CIFAR-10 distributed in a non-IID fashion on a ring topology
5.4 Communication Compression
In this section, we discuss the impact of communication compression on the proposed NGMalgorithm.
At every iteration, the NGM dvalgorithm involves two rounds of communication with the neighbors: 1)
communicate the model parameters, and 2) communicate the cross-gradients. This communication overhead
can be a bottleneck in a resource-constrained environment. Hence, we explore a compressed version of NGM
referred to as CompNGM using Error Feedback SGD (EF-SGD) (Karimireddy et al., 2019) to compress the
cross-gradients. CompNGM compresses the error-compensated cross-gradients from 32 bits (floating point
precision of arithmetic operations) to 1 bit by using scaled signed gradients. The pseudo-code for CompNGM
is shown in Algorithm. 3 in the Appendix. Additional results and analysis on CompNGM are presented in
the Appendix. A.4.
Table 5: Test Accuracy of CompNGM , Accuracy drop compared to NGM dvand communication reduction
in Giga Bytes compared to NGM dvfor various datasets trained on ring topology.
Dataset Model5 agents 10 agents
Acc ( %) Acc. Drop ( %) Comm. Drop (GB) Acc ( %) Acc. Drop ( %) Comm. Drop (GB)
Fashion MNIST LeNet-5 90.48±0.19 0.13 16.71 ( 1.94×)83.38±0.39 3.86 8.35 ( 1.94×)
CIFAR-10 ResNet-20 87.56±0.34 0.96 123.11 ( 1.94×)78.50±0.98 5.52 61.75 ( 1.94×)
CIFAR-100 ResNet-20 57.51±0.48 -1.01 100.49 ( 1.94×)43.07±0.32 10.7 50.27 ( 1.94×)
Imagenette (32×32)MobileNet-V2 72.91±1.06 1.58 99.89 ( 1.94×)61.91±2.10 2.15 49.98 ( 1.94×)
Table. 5 shows that CompNGM reduces the communication cost by 1.94×by trading off 0.1−1.57%test
accuracy for 5 agents and 2−10%test accuracy for 10 agents. This shows that NGMcan be combined with
communication compression techniques to achieve a trade-off between accuracy boost and communication
overhead. Further, NGMcan be combined with stronger compression methods such as EF21 (Richtárik
et al., 2021) to have a better trade-off between accuracy and communication cost.
5.5 Hardware Benefits
The proposed NGM dvalgorithm is superior in terms of memory and compute efficiency (see Table. 6 and
Appendix. A.8) while having equal communication cost as compared to CGA.NGM dvreplaces the com-
plicated quadratic projection step of CGA with a simple weighted averaging step. Since NGM dvinvolves
weighted averaging, an additional buffer to store the cross-gradients is not required. CGA stores all the cross-
gradients in a matrix form for quadratic programming projection of the local gradient. Therefore, NGMhas
no memory overhead compared to the baseline D-PSGD algorithm, while CGA requires additional memory
equivalent to the number of neighbors times model size. Moreover, the quadratic programming projection
step (Goldfarb & Idnani, 1983) in CGA is much more expensive in compute and latency than the weighted
averaging step of cross-gradients in NGM. Our evaluation clearly shows that NGMis superior to CGA in
terms of test accuracy, memory efficiency, compute efficiency, and latency.
11Published in Transactions on Machine Learning Research (11/2023)
Table 6: Comparison of communication, memory, and compute overheads per mini-batch compared to D-
PSGD.ms: model size, ni: number of neighbors, b: floating point precision, Q: compute for Quadratic
Programming, B: compute for Backward Pass. Note that O(Q)>>O(nims)(Nesterov & Todd, 1997)
Method Comm. Memory Compute
QG-DSGDm 0 O(ms)O(nims)
NGM mv 0 0 O(nims+niB)
Momentum Tracking O(nims)O(2ms)O(nims)
CGA O(nims)O(nims)O(Q+niB)
NGM dv O(nims)0O(nims+niB)
CompCGA O(nims
b)O(nims)O(Q+niB)
CompNGM O(nims
b)O(nims)O(nims+niB)
6 Discussion and Limitations
As mentioned in Section. 3.1, the NGMmixing weight αis either set to 0or1resulting in NGM mvorNGM dv
respectively. This implies that NGM mvutilizes model-variant cross-gradients whereas, NGM dvutilizes data-
variant cross-gradients. However, the NGM dvvariant of the algorithm has access to both model-variant and
data-variant cross-gradients. So, we conduct an ablation study mixing these two cross gradients by varying
NGMmixing weight αin the range of [0,1]. Figure. 4(c) depicts the change in average validation accuracy
withαand we observe that α= 1performs best. Further, Figure. 3(b) shows that the model variant bias
reduces for NGM dveven though it does not explicitly utilize the model-variant cross-gradients. We hypothe-
size that, in NGM dv, the use of data-variant cross-gradients for local updates followed by gossip averaging of
model parameters inherently adds model-variant cross-gradients reducing model variance. Hence, explicitly
mixing the two sets of cross-gradients is not necessary. In summary, for 1×communication constraints i.e.,
when agents do not have access to data-variant cross-gradients, NGM mveffectively utilizes locally available
model-variant cross-gradients to improve the accuracy. On the contrary, when 2×communication is allowed
(non-zeroα), the best performance is achieved by only utilizing the data-variant cross-gradients.
Table 7: Test Accuracy and Latency of ImageNet (non-IID) trained on ResNet-18 over 10-agent Ring. Note,
LM: Local Momentum, QGM: Quasi Global Momentum.
Trained for D-PSGD QG-DSGDm NGM mvNGM mvNGM mvMomentum CGA NGM dvNGM dv
60 epochs +LM + QGM Tracking + LM + QGM
Accuracy (%) 25.02 45.19 42.66 49.22 51.00 43.65 - 49.42 54.31
Epoch Time (min) 7.6 7.9 18.6 18.8 19.1 10.7 406 21.5 22.2
NGM mvhasonepotentiallimitationcomparedtoD-PSGDandQG-DSGDmi.e., computeoverhead. NGM mv
has to compute model-variant cross-gradients which requires every agent ito compute niadditional forward
and backward passes. However, NGM dvis significantly better in terms of latency, compute, and memory
requirements compared to CGA as it simplifies the complicated quadratic projection step. Running the
CGA algorithm on larger datasets like ImageNet is impractical due to the significant latency associated with
the quadratic projection step. Table. 7 reports the accuracy and latency of training ImageNet in a non-IID
fashion over a ring topology of 10 agents. We observe that CGA is ∼20×slower than NGM dvfor the
ImageNet dataset on ResNet-18. We estimate the training time for one simulation of CGA on ImageNet (90
epochs with 10-agent ring topology) to be around 26 days on 4 Nvidia A100s (80 GB) with Intel(R) Xeon(R)
Gold 6338 CPU. Further, it has been shown in the literature (Koloskova et al., 2019; Tang et al., 2019) that
the communication compression with error feedback only affects the higher-order terms of the convergence
rate. Hence, decentralized compression algorithms have linear speedup similar to D-PSGD. Following this,
our future efforts go towards showing that CompNGM has a similar convergence rate as NGM. We would
also like to explore efficient methods to compute cross-gradients for NGM.
12Published in Transactions on Machine Learning Research (11/2023)
7 Conclusion
Enabling decentralized training on non-IID data is key for ML applications to efficiently leverage the hu-
mongous amounts of user-generated private data. In this paper, we propose the Neighborhood Gradient
Mean(NGM) algorithm with two variants that improve decentralized learning on non-IID data. NGM mv
improves the performance of decentralized learning utilizing model-variant cross-gradients without any com-
munication overhead. NGM dvfurther increases these gains by operating on data-variant cross-gradients.
Additionally, we present a compressed version of our algorithm ( CompNGM ) to reduce the communication
overhead associated with data-variant cross-gradients of NGM dv. We theoretically analyze the convergence
characteristic and empirically validate the performance of the proposed techniques over different model ar-
chitectures, datasets, graph sizes, and topologies. Finally, we compare the proposed algorithms with the
current state-of-the-art decentralized learning algorithm on non-IID data and show superior performance
with significantly less compute and memory requirements setting the new state-of-the-art for decentralized
learning on non-IID data.
Authors’ Contributions:
Sai Aparna Aketi and Sangamesh Kodge, both worked on developing the algorithm. The experiments
for Computer Vision tasks were designed by Sai Aparna Aketi and the experiments for Natural Language
Processing tasks were designed by Sangamesh Kodge. The theory for the convergence analysis and consensus
error bounds was developed by Sai Aparna Aketi and was verified by Sangamesh Kodge. All the authors
contributed equally in writing and proofreading the paper.
Acknowledgments
This work was supported in part by, the Center for Brain-inspired Computing (C-BRIC), the Center for
the Co-Design of Cognitive Systems (COCOSYS), a DARPA-sponsored JUMP center, the Semiconductor
Research Corporation (SRC), the National Science Foundation, and DARPA ShELL.
References
Alekh Agarwal and John C Duchi. Distributed delayed stochastic optimization. Advances in neural infor-
mation processing systems , 24, 2011.
Sai Aparna Aketi, Amandeep Singh, and Jan Rabaey. Sparse-push: Communication-& energy-efficient de-
centralized distributed learning over directed & time-varying graphs with non-iid datasets. arXiv preprint
arXiv:2102.05715 , 2021.
Sai Aparna Aketi, Sangamesh Kodge, and Kaushik Roy. Low precision decentralized distributed training
over iid and non-iid data. Neural Networks , 2022. ISSN 0893-6080. doi: https://doi.org/10.1016/j.neunet.
2022.08.032.
Mahmoud Assran, Nicolas Loizou, Nicolas Ballas, and Mike Rabbat. Stochastic gradient push for distributed
deep learning. In International Conference on Machine Learning , pp. 344–353. PMLR, 2019.
Aditya Balu, Zhanhong Jiang, Sin Yong Tan, Chinmay Hedge, Young M Lee, and Soumik Sarkar. Decen-
tralized deep learning using momentum-accelerated consensus. In ICASSP 2021-2021 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP) , pp. 3675–3679. IEEE, 2021.
Léon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of COMP-
STAT’2010 , pp. 177–186. Springer, 2010.
Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Marc’aurelio Ranzato,
Andrew Senior, Paul Tucker, Ke Yang, et al. Large scale distributed deep networks. Advances in neural
information processing systems , 25, 2012.
13Published in Transactions on Machine Learning Research (11/2023)
JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova. Bert: Pre-trainingofdeepbidirectional
transformers for language understanding. arXiv preprint arXiv:1810.04805 , 2018.
Paolo Di Lorenzo and Gesualdo Scutari. Next: In-network nonconvex optimization. IEEE Transactions on
Signal and Information Processing over Networks , 2(2):120–136, 2016.
Yasaman Esfandiari, Sin Yong Tan, Zhanhong Jiang, Aditya Balu, Ethan Herron, Chinmay Hegde, and
Soumik Sarkar. Cross-gradient aggregation for decentralized learning from non-iid data. In International
Conference on Machine Learning , pp. 3036–3046. PMLR, 2021.
Donald Goldfarb and Ashok Idnani. A numerically stable dual method for solving strictly convex quadratic
programs. Mathematical programming , 27(1):1–33, 1983.
Arya Ketabchi Haghighat, Varsha Ravichandra-Mouli, Pranamesh Chakraborty, Yasaman Esfandiari, Saeed
Arabi, and Anuj Sharma. Applications of deep learning in intelligent transportation systems. Journal of
Big Data Analytics in Transportation , 2(2):115–145, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE conference on computer vision and pattern recognition , pp. 770–778, 2016.
Kevin Hsieh, Amar Phanishayee, Onur Mutlu, and Phillip Gibbons. The non-IID data quagmire of de-
centralized machine learning. In Proceedings of the 37th International Conference on Machine Learning ,
volume 119 of Proceedings of Machine Learning Research , pp. 4387–4398. PMLR, 13–18 Jul 2020.
Hamel Husain. Imagenette - a subset of 10 easily classified classes from the imagenet dataset.
https://github.com/fastai/imagenette , 2018.
Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi. Error feedback fixes signsgd
andothergradientcompressionschemes. In International Conference on Machine Learning , pp.3252–3261.
PMLR, 2019.
Anastasia Koloskova, Tao Lin, Sebastian U Stich, and Martin Jaggi. Decentralized deep learning with
arbitrary communication compression. arXiv preprint arXiv:1907.09356 , 2019.
Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified theory
of decentralized sgd with changing topology and local updates. In International Conference on Machine
Learning , pp. 5381–5393. PMLR, 2020.
Anastasiia Koloskova, Tao Lin, and Sebastian U Stich. An improved analysis of gradient tracking for
decentralized machine learning. Advances in Neural Information Processing Systems , 34:11422–11435,
2021.
Jakub Konecny, H Brendan McMahan, Daniel Ramage, and Peter Richtarik. Federated optimization: Dis-
tributed machine learning for on-device intelligence. arXiv preprint arXiv:1610.02527 , 2016.
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar (canadian institute for advanced research).
http://www.cs.toronto.edu/ kriz/cifar.html , 2014.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to docu-
ment recognition. Proceedings of the IEEE , 86(11):2278–2324, 1998.
Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. Can decentralized algorithms
outperform centralized algorithms? a case study for decentralized parallel stochastic gradient descent.
Advances in Neural Information Processing Systems , 30, 2017.
Tao Lin, Sai Praneeth Karimireddy, Sebastian Stich, and Martin Jaggi. Quasi-global momentum: Accelerat-
ing decentralized deep learning on heterogeneous data. In Proceedings of the 38th International Conference
on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp. 6654–6665. PMLR,
18–24 Jul 2021.
14Published in Transactions on Machine Learning Research (11/2023)
Hanxiao Liu, Andy Brock, Karen Simonyan, and Quoc Le. Evolving normalization-activation layers. In
H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin (eds.), Advances in Neural Information
Processing Systems , volume 33, pp. 13539–13550. Curran Associates, Inc., 2020a.
Xiaorui Liu, Yao Li, Rongrong Wang, Jiliang Tang, and Ming Yan. Linear convergent decentralized opti-
mization with compression. arXiv preprint arXiv:2007.00232 , 2020b.
Yucheng Lu and Christopher De Sa. Moniqua: Modulo quantized communication in decentralized sgd. In
International Conference on Machine Learning , pp. 6415–6425. PMLR, 2020.
Giorgi Nadiradze, Amirmojtaba Sabour, Dan Alistarh, Aditya Sharma, Ilia Markov, and Vitaly Aksenov.
Swarmsgd: Scalable decentralized sgd with local updates. arXiv preprint arXiv:1910.12308 , 2019.
Yu E Nesterov and Michael J Todd. Self-scaled barriers and interior-point methods for convex programming.
Mathematics of Operations research , 22(1):1–42, 1997.
Shi Pu and Angelia Nedić. Distributed stochastic gradient tracking methods. Mathematical Programming ,
187:409–457, 2021.
PeterRichtárik, IgorSokolov, andIlyasFatkhullin. Ef21: Anew, simpler, theoreticallybetter, andpractically
faster error feedback. Advances in Neural Information Processing Systems , 34:4384–4396, 2021.
Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2:
Inverted residuals and linear bottlenecks. In Proceedings of the IEEE conference on computer vision and
pattern recognition , pp. 4510–4520, 2018.
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of bert:
smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108 , 2019.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition.
arXiv preprint arXiv:1409.1556 , 2014.
Yuki Takezawa, Han Bao, Kenta Niwa, Ryoma Sato, and Makoto Yamada. Momentum tracking: Momentum
accelerationfor decentralizeddeep learning onheterogeneous data. arXiv preprint arXiv:2209.15505 , 2022.
Yuki Takezawa, Kenta Niwa, and Makoto Yamada. Communication compression for decentralized learning
with operator splitting methods. IEEE Transactions on Signal and Information Processing over Networks ,
2023.
Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. d2: Decentralized training over decentralized
data. In International Conference on Machine Learning , pp. 4848–4856. PMLR, 2018.
Hanlin Tang, Xiangru Lian, Shuang Qiu, Lei Yuan, Ce Zhang, Tong Zhang, and Ji Liu. Deepsqueeze:
Decentralization meets error-compensated compression. arXiv preprint arXiv:1907.07346 , 2019.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747 , 2017.
Lin Xiao and Stephen Boyd. Fast linear iterations for distributed averaging. Systems & Control Letters , 53
(1):65–78, 2004.
Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient momentum sgd
for distributed non-convex optimization. arXiv preprint arXiv:1905.03817 , 2019.
Xiang Zhang, Junbo Zhao, and Yann LeCun. Character-level convolutional networks for text classification.
Advances in neural information processing systems , 28, 2015.
Haoyu Zhao, Boyue Li, Zhize Li, Peter Richtárik, and Yuejie Chi. Beer: Fast o(1/t)rate for decentralized
nonconvex optimization with communication compression. Advances in Neural Information Processing
Systems, 35:31653–31667, 2022.
15Published in Transactions on Machine Learning Research (11/2023)
A Appendix
A.1 Proof of Lemma. 1
This section presents detailed proof for Lemma. 1. The NGMalgorithm modifies the local gradients as
follows
/tildewidegi= (1−α)/summationdisplay
j∈Niwjigji+α/summationdisplay
j∈Niwijgij=gi+/summationdisplay
j∈Niwij(gij−gi) (NGM dvusesα= 1)
/tildewidegi−gi=/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇Fi(x,di))
Now we prove the lemma. 1 by applying expectation to the above inequality
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1(˜gi−gi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇Fi(x,di))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(a)=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇Fi(x,di)−E[∇Fj(x,dj)−∇Fi(x,di)])/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(E[∇Fj(x,dj)−∇Fi(x,di)])/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(b)=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇fj(x))−(∇Fi(x,di)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(∇fj(x)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(c)=1
N2N/summationdisplay
i=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇fj(x))−(∇Fi(x,di)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij(∇fj(x)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(d)
≤1
N2N/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇Fj(x,dj)−∇fj(x)−(∇Fi(x,di)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+1
NN/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fj(x)−∇F (x) +∇F(x)−∇fi(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(e)
≤1
N2N/summationdisplay
i=1/summationdisplay
j∈Niwij4σ2+1
NN/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fj(x)−∇F (x) +∇F(x)−∇fi(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=4Nσ2
N2+1
NN/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fj(x)−∇F (x) +∇F(x)−∇fi(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(∵/summationdisplay
j∈Niwij= 1)
(f)
≤4σ2
N+1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij/parenleftbigg
2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fj(x)−∇F (x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fi(x)−∇F (x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg/parenrightbigg
(g)
≤4σ2
N+1
NN/summationdisplay
i=1/summationdisplay
j∈Niwij4ζ2
16Published in Transactions on Machine Learning Research (11/2023)
=4σ2
N+ 4ζ2
(a) identity E[||Z||2] = E[||Z−E[Z]||2] +E[||E[Z]||2]holds for any random vector Z; (b) the fact
E[∇Fi(x,di)] =∇fi(x); (c)∇Fi(x,di)−∇fi(x)are independent random vectors with 0 mean and
E[||/summationtextN
i=1Zi||] =/summationtextN
i=1E[||Zi||2]holds when Ziare independent with mean zero; (d) jensen’s inequality;
(e) follows from assumption 2 Ed∼Di||∇Fi(x;d)−∇fi(x)||2≤σ2∀i∈[1,N]; (f) the basic inequal-
ity||a1+a2||2≤2||a1||2+ 2||a2||2for any vectors a1,a2; and (g) follows from assumption 2 that
||∇fi(x)−∇F (x)||2≤ζ2∀i∈[1,N]
∴we have following bound given by lemma. 1: E[||/tildewidegi−gi||2]≤4(σ2
N+ζ2)
A.2 Convergence Analysis
In this section, we present the proof for our main theorem. 1 indicating the convergence of the proposed
NGM dvalgorithm. Before we proceed to the proof of the theorem, we present a lemma showing that NGM
achieves consensus among the different agents.
A.2.1 Bound for Consensus Error
Lemma 2. Given assumptions 1-3 and lemma 1, the distance between the average sequence iterate ¯xkand
the sequence iterates xk
i’s generated NGM (i.e., the consensus error of the proposed algorithm) is given by
K/summationdisplay
k=01
NN/summationdisplay
i=1E[||¯xk−xi
k||2]≤14η2(σ2+ζ2)
(1−β)2(1−√ρ)2K+6η2
(1−β)2(1−√ρ)K−1/summationdisplay
k=0E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2](11)
whereK≥1andβ∈[0,1)is the momentum coefficient.
To prove Lemma 2 and Theorem. 1, we follow the similar approach as (Esfandiari et al., 2021). Hence, we
also define the following auxiliary sequence along with Lemma 3
¯zk:=1
1−β¯xk−β
1−β¯xk−1 (12)
Wherek > 0andxkis obtained by multiplying the update law by1
N11⊤, (1is the column vector with
entries being 1).
¯vk=β¯vk−1−η1
NN/summationdisplay
i=1˜gi
k−1
¯xk=¯xk−1+¯vk(13)
Ifk= 0then ¯zk=¯xk. For the rest of the analysis, the initial value will be directly set to 0.
To prove Lemma. 2, we use the following facts.
¯zk+1−¯zk=−η
1−β1
NN/summationdisplay
i=1˜gi
k. (14)
K−1/summationdisplay
k=0∥¯zk−¯xk∥2≤η2β2
(1−β)4K−1/summationdisplay
k=0/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1˜gi
k/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
. (15)
Note that the proof for Eq. 14 and Eq. 15 can be found in (Esfandiari et al., 2021) as lemma-3 and lemma-4
respectively.
17Published in Transactions on Machine Learning Research (11/2023)
Before proceeding to prove Lemma 2, we introduce some key notations and facts that serve to characterize
the Lemma similar to (Esfandiari et al., 2021).
We define the following notations:
˜Gk≜[˜g1
k,˜g2
k,...,˜gN
k]
Vk≜[v1
k,v2
k,...,vN
k]
Xk≜[x1
k,x2
k,...,xN
k]
Gk≜[g1
k,g2
k,...,gN
k]
Hk≜[∇f1(x1
k),∇f2(x2
k),...,∇fN(xN
k)](16)
We can observe that the above matrices are all with dimension d×Nsuch that any matrix Asatisfies
∥A∥2
F=/summationtextN
i=1∥ai∥2, where aiis thei-th column of the matrix A. Thus, we can obtain that:
∥Xk(I−Q)∥2
F=N/summationdisplay
i=1∥xi
k−¯xk∥2. (17)
Define Q=1
N11⊤. For each doubly stochastic matrix W, the following properties can be obtained
(i)QW =WQ;
(ii) (I−Q)W=W(I−Q);
(iii)For any integer k≥1,∥(I−Q)W∥S≤(√ρ)k, where∥·∥Sis the spectrum norm of a matrix.(18)
LetAi,i∈{1,2,...,N}beNarbitrary real square matrices. It follows that
∥N/summationdisplay
i=1Ai∥2
F≤N/summationdisplay
i=1N/summationdisplay
j=1∥Ai∥F∥Aj∥F. (19)
We present the following auxiliary lemmas to prove the lemma. 2
Lemma 3. Let all assumptions hold. Let gibe the unbiased estimate of ∇fi(xi)at the point xisuch that
E[gi] =∇fi(xi), for alli∈[N] :={1,2,...,N}. Thus the following relationship holds
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1˜gi/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤10σ2
N+ 8ζ2+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
(20)
Proof for Lemma 3:
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1˜gi/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1(˜gi−gi+gi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1(˜gi−gi) +1
NN/summationdisplay
i=1gi/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
a
≤2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1(˜gi−gi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1gi/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
b
≤8(σ2
N+ζ2) +2σ2
N+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=10σ2
N+ 8ζ2+ 2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi(xi)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
18Published in Transactions on Machine Learning Research (11/2023)
(a) refers to the fact that the inequality ∥a+b∥2≤2∥a∥2+ 2∥b∥2. (b) The first term uses Lemma 1 and
the second term uses the conclusion of Lemma 1in (Yu et al., 2019).
Lemma 4. Let all assumptions hold. Let gibe the unbiased estimate of ∇fi(xi)at the point xisuch that
E[gi] =∇fi(xi), for alli∈[N] :={1,2,...,N}. Thus the following relationship holds
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble˜Gτ−Gτ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
≤4N(σ2+ζ2) (21)
Proof for Lemma 4 is similar to Lemma 1 and is as follows:
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble˜Gτ−Gτ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
=N/summationdisplay
i=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇Fi(x,di))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
=N/summationdisplay
i=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈Niwij(∇Fj(x,dj)−∇fj(x))−(∇Fi(x,di)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+N/summationdisplay
i=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/summationdisplay
j∈Niwij(∇fj(x)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤N/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇Fj(x,dj)−∇fj(x)−(∇Fi(x,di)−∇fi(x))/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
+N/summationdisplay
i=1/summationdisplay
j∈NiwijE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble∇fj(x)−∇F (x) +∇F(x)−∇fi(x)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤4N(σ2+ζ2) (follows from assumption 2)
The properties shown in Eq. 18 and 19 have been well established and in this context, we skip the proof
here. We are now ready to prove Lemma 2.
Proof for Lemma 2: Since Xk=Xk−1W+Vkwe have:
Xk(I−Q) =Xk−1(I−Q)W+Vk(I−Q) (22)
Applying the above equation ktimes we have:
Xk(I−Q) =X0(I−Q)Wk+k/summationdisplay
τ=1Vτ(I−Q)Wk−τX0=0=k/summationdisplay
τ=1Vτ(I−Q)Wk−τ(23)
As¯Vk=β¯Vk−1−η1
N/summationtextN
i=1˜Gi
k−1V0=0=−η1
N/summationtextN
i=1˜Gi
k−1, we can get:
Xk(I−Q) =−ηk/summationdisplay
τ=1τ−1/summationdisplay
l=0˜Glβτ−1−l(I−Q)Wk−τ
=−ηk/summationdisplay
τ=1τ−1/summationdisplay
l=0˜Glβτ−1−lWk−τ(I−Q)−ηk−1/summationdisplay
n=1˜Gn[k/summationdisplay
l=n+1βl−1−nWk−1−n(I−Q)
=−ηk−1/summationdisplay
τ=01−βk−τ
1−β˜Gτ(I−Q)Wk−1−τ.(24)
19Published in Transactions on Machine Learning Research (11/2023)
Therefore, for k≥1, we have:
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleXk(I−Q)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
=η2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−β˜Gτ(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
a
≤2η2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−β(˜Gτ−Gτ)(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
I+
2η2E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−βGτ(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
II(25)
(a) follows from the inequality ∥A+B∥2
F≤2∥A∥2
F+ 2∥B∥2
F.
We develop upper bounds of the term I:
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−β(˜Gτ−Gτ)(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
a
≤k−1/summationdisplay
τ=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1−βk−τ
1−β(˜Gτ−Gτ)(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
b
≤1
(1−β)2k−1/summationdisplay
τ=0ρk−1−τE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble˜Gτ−Gτ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
c
≤4
(1−β)2k−1/summationdisplay
τ=0ρk−1−τN(σ2+ζ2)d
≤4N(σ2+ζ2)
(1−β)2(1−ρ)
(26)
(a) follows from Jensen’s inequality. (b) follows from the inequality |1−βk−τ
1−β| ≤1
1−β. (c) follows from
Lemma 2 and Frobenius norm. (d) follows from Assumption 3.
We then proceed to find the upper bound for term II.
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−βGτ(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
a
≤k−1/summationdisplay
τ=0k−1/summationdisplay
τ′=0E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble1−βk−τ
1−βGτ(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble
F/vextenddouble/vextenddouble/vextenddouble/vextenddouble1−βk−τ
1−βGτ′(I−Q)Wk−1−τ′/vextenddouble/vextenddouble/vextenddouble/vextenddouble
F/bracketrightbigg
≤1
(1−β)2k−1/summationdisplay
τ=0k−1/summationdisplay
τ′=0ρ(k−1−τ+τ′
2)E/bracketleftbigg
∥Gτ∥F∥Gτ′∥F/bracketrightbigg
b
≤1
(1−β)2k−1/summationdisplay
τ=0k−1/summationdisplay
τ′=0ρ(k−1−τ+τ′
2)/parenleftbigg1
2E[∥Gτ∥2
F] +1
2E[∥Gτ′∥2
F]/parenrightbigg
=1
(1−β)2k−1/summationdisplay
τ=0k−1/summationdisplay
τ′=0ρ(k−1−τ+τ′
2)E[∥Gτ∥2
F]
c
≤1
(1−β)2(1−√ρ)k−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥Gτ∥2
F]
(27)
(a) follows from Eq. 19. (b) follows from the inequality xy≤1
2(x2+y2)for any two real numbers x,y. (c)
is derived using/summationtextk−1
τ1=0ρk−1−τ1+τ
2≤ρk−1−τ
2
1−√ρ.
20Published in Transactions on Machine Learning Research (11/2023)
We then proceed with finding the bounds for E[∥Gτ∥2
F]:
E[∥Gτ∥2
F] =E[∥Gτ−Hτ+Hτ−HτQ+HτQ∥2
F]
≤3E[∥Gτ−Hτ∥2
F] + 3E[∥Hτ(I−Q)∥2
F] + 3E[∥HτQ∥2
F]
a
≤3Nσ2+ 3Nζ2+ 3E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2](28)
(a) holds because E[∥HτQ∥2
F]≤E[∥1
N/summationtextN
i=1∇fi(xi
τ)∥2]
Substituting (28) in (27):
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
τ=01−βk−τ
1−βGτ(I−Q)Wk−1−τ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
≤1
(1−β)2(1−√ρ)k−1/summationdisplay
τ=0ρ(k−1−τ
2)/bracketleftbigg
3Nσ2+ 3Nζ2+ 3NE[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]/bracketrightbigg
≤3N(σ2+ζ2)
(1−β)2(1−√ρ)2+3N
(1−β)2(1−√ρ)k−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]
(29)
substituting (29) and (26) into the main inequality (25):
E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleXk(I−Q)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
≤8η2N(σ2+ζ2)
(1−β)2(1−ρ)+2η2
(1−β)2(1−√ρ)/parenleftbigg3N(σ2)
1−√ρ+3N(ζ2)
1−√ρ+
3Nk−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]/parenrightbigg
=2η2
(1−β)2/parenleftbigg4N(σ2+ζ2)
1−ρ+3Nσ2
(1−√ρ)2+3Nζ2
(1−√ρ)2/parenrightbigg
+
6Nη2
(1−β)2(1−√ρ)k−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]
≤14Nη2
(1−β)2/parenleftbiggσ2
(1−√ρ)2+ζ2
(1−√ρ)2/parenrightbigg
+6Nη2
(1−β)2(1−√ρ)k−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]
(30)
Summing over k∈{1,...,K−1}and noting that E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleX0(I−Q)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
= 0:
K−1/summationdisplay
k=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleXk(I−Q)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
≤CK+6Nη2
(1−β)2(1−√ρ)K−1/summationdisplay
k=1k−1/summationdisplay
τ=0ρ(k−1−τ
2)E[∥1
NN/summationdisplay
i=1∇fi(xi
τ)∥2]
≤CK+6Nη2
(1−β)2(1−√ρ)K−1/summationdisplay
k=01−ρ(K−1−k
2)
1−√ρE[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2]
≤CK+6Nη2
(1−β)2(1−√ρ)K−1/summationdisplay
k=0E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2](31)
21Published in Transactions on Machine Learning Research (11/2023)
WhereC=14Nη2
(1−β)2/parenleftbigg
σ2
(1−√ρ)2+ζ2
(1−√ρ)2/parenrightbigg
.
Dividing both sides by N:
K−1/summationdisplay
k=11
NE/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddoubleXk(I−Q)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
F/bracketrightbigg
≤14η2
(1−β)2/parenleftbiggσ2
(1−√ρ)2+ζ2
(1−√ρ)2/parenrightbigg
K+
6η2
(1−β)2(1−√ρ)K−1/summationdisplay
k=0E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2](32)
Hence, we obtain the following as the lemma. 2:
K−1/summationdisplay
k=01
NN/summationdisplay
i=1E/bracketleftbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble¯xk−xi
k/vextenddouble/vextenddouble/vextenddouble/vextenddouble2/bracketrightbigg
≤14η2(σ2+ζ2)
(1−β)2(1−√ρ)2K+6η2
(1−β)2(1−√ρ)K−1/summationdisplay
k=0E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2](33)
A.2.2 Proof for Theorem. 1
Proof:Using the L-smoothness properties for Fwe have:
E[F(¯zk+1)]≤E[F(¯zk)] +E[⟨∇F(¯zk),¯zk+1−¯zk⟩] +L
2E[∥¯zk+1−¯zk∥2] (34)
Using Eq. 14 we have:
E[⟨∇F(¯zk),¯zk+1−¯zk⟩] =−η
1−βE[⟨∇F(¯zk),1
NN/summationdisplay
i=1˜gi
k⟩] =
−η
1−βE[⟨∇F(¯zk)−∇F (¯xk),1
NN/summationdisplay
i=1˜gi
k⟩]
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
T1−η
1−βE[⟨∇F(¯xk),1
NN/summationdisplay
i=1˜gi
k⟩]
/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
T2(35)
We proceed by bounding T1:
−η
1−βE[⟨∇F(¯zk)−∇F (¯xk),1
NN/summationdisplay
i=1˜gi
k⟩]
(i)
≤(1−β)
2βLE[∥∇F (¯zk)−∇F (¯xk)∥2] +βLη2
2(1−β)3E[∥1
NN/summationdisplay
i=1˜gi
k∥2]
(ii)
≤(1−β)L
2βE[∥¯zk−¯xk∥2] +βLη2
2(1−β)3E[∥1
NN/summationdisplay
i=1˜gi
k∥2](36)
(i) holds as⟨a,b⟩≤1
2∥a∥2+1
2∥b∥2where a=√
1−β√
βL(∇F(¯zk)−∇F (¯xk))andb=−η√
βL
(1−β)3
21
N/summationtextN
i=1˜gi
k. and
(ii) uses the fact that Fis L-smooth.
22Published in Transactions on Machine Learning Research (11/2023)
We split the term T2as follows:
⟨∇F (¯xk),1
NN/summationdisplay
i=1˜gi
k⟩=⟨∇F (¯xk),1
NN/summationdisplay
i=1/parenleftbig
˜gi
k−gi
k+gi
k/parenrightbig
⟩=
⟨∇F (¯xk),1
NN/summationdisplay
i=1/parenleftbig
˜gi
k−gi
k/parenrightbig
⟩
/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright
T3+⟨∇F (¯xk),1
NN/summationdisplay
i=1gi
k⟩
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
T4(37)
Now, We first analyze the term T3:
−η
(1−β)E[⟨∇F (¯xk),1
NN/summationdisplay
i=1/parenleftbig
˜gi
k−gi
k/parenrightbig
⟩]
≤(1−β)
2βLE[∥∇F (¯xk)∥2] +η2βL
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k−gi
k)∥2](38)
This holds as⟨a,b⟩≤1
2∥a∥2+1
2∥b∥2where a=−√
1−β√
βL∇F(¯xk)andb=η√
βL
(1−β)3
21
N/summationtextN
i=1(˜gi
k−gi
k).
Analyzing the term T4:
E/bracketleftbigg
⟨∇F (¯xk),1
NN/summationdisplay
i=1gi
k⟩/bracketrightbigg
=E/bracketleftbigg
⟨∇F(¯xk),1
NN/summationdisplay
i=1∇fi(xi
k)⟩/bracketrightbigg
(39)
Using the equity ⟨a,b⟩=1
2[∥a∥2+∥b∥2−∥a−b∥2], we have :
⟨∇F (¯xk),1
NN/summationdisplay
i=1∇fi/parenleftbig
xi
k/parenrightbig
⟩=1
2/parenleftigg
∥∇F (¯xk)∥2+∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2−∥∇F (¯xk)−1
NN/summationdisplay
i=1∇fi(xi
k)∥2/parenrightigg
a
≥1
2/parenleftigg
∥∇F (¯xk)∥2+∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2−L21
NN/summationdisplay
i=1∥¯xk−xi
k∥2/parenrightigg (40)
(a) holds because ∥∇F (¯xk)−1
N/summationtextN
i=1∇fi(xi
k)∥2=∥1
N/summationtextN
i=1∇fi(¯xk)−1
N/summationtextN
i=1∇fi(xi
k)∥2≤
1
N/summationtextN
i=1∥∇fi(¯xk)−∇fi(xi
k)∥2≤1
N/summationtextN
i=1L2∥¯xk−xi
k∥2.
Substituting (40) into (39), we have
E/bracketleftbigg
⟨∇F (¯xk),1
NN/summationdisplay
i=1gi
k⟩/bracketrightbigg
≥1
2/parenleftigg
E[∥∇F (¯xk)∥2] +E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2]−L21
NN/summationdisplay
i=1E[∥¯xk−xi
k∥2]/parenrightigg
(41)
Substituting (38), (41) into (37), we have
−η
1−βE[⟨∇F(¯xk),1
NN/summationdisplay
i=1˜gi
k⟩]≤/parenleftig(1−β)
2βL−η
2(1−β)/parenrightig
E[∥∇F (¯xk)∥2] +η2βL
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k−gi
k)∥2]
−η
2(1−β)E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2] +ηL2
2(1−β)1
NN/summationdisplay
i=1E[∥¯xk−xi
k∥2]
(42)
23Published in Transactions on Machine Learning Research (11/2023)
Now, finally substituting (42), (36) into (35), we have
E[⟨∇F(¯zk),¯zk+1−¯zk⟩]≤(1−β)L
2βE[∥¯zk−¯xk∥2] +βLη2
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k)∥2] +/parenleftbigg(1−β)
2βL−η
2(1−β)/parenrightbigg
E[∥∇F (¯xk)∥2]−η
2(1−β)E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2] +η2βL
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k−gi
k)∥2] +ηL2
2(1−β)1
NN/summationdisplay
i=1E[∥¯xk−xi
k∥2]
(43)
Equation. 14 states that:
E[∥¯zk+1−¯zk∥2] =η2
(1−β)2E[∥1
NN/summationdisplay
i=1˜gi
k∥2]. (44)
Substituting (43), (44) in (34):
E[F(¯zk+1)]≤E[F(¯zk)] +(1−β)L
2βE[∥¯zk−¯xk∥2] +βLη2
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k)∥2] +/parenleftbigg(1−β)
2βL−η
2(1−β)/parenrightbigg
E[∥∇F (¯xk)∥2]−η
2(1−β)E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2] +η2βL
2(1−β)3E[∥1
NN/summationdisplay
i=1(˜gi
k−gi
k)∥2]+
ηL2
2(1−β)1
NN/summationdisplay
i=1E[∥¯xk−xi
k∥2] +η2
(1−β)2E[∥1
NN/summationdisplay
i=1˜gi
k∥2].
We find the bound for E[∥∇F (¯xk)∥2]by rearranging the terms and dividing by C1=η
2(1−β)−(1−β)
2βL:
E[∥∇F (¯xk)∥2]≤1
C1/parenleftbigg
E[F(¯zk)]−E[F(¯zk+1)]/parenrightbigg
+/tildewideC2E[∥1
NN/summationdisplay
i=1(˜gi
k)∥2] +/tildewideC3E[∥¯zk−¯xk∥2]
−/tildewideC6E[∥1
NN/summationdisplay
i=1∇fi(xi
k)∥2] +/tildewideC4E[∥1
NN/summationdisplay
i=1(˜gi
k−gi
k)∥2] +/tildewideC5
NN/summationdisplay
i=1E[∥¯xk−xi
k∥2]
Where/tildewideC2=/parenleftig
βLη2
2(1−β)3+η2L
(1−β)2/parenrightig
/C1,/tildewideC3=(1−β)L
2β/C1,/tildewideC4=η2βL
2(1−β)3/C1,/tildewideC5=ηL2
2(1−β)/C1,/tildewideC6=η
2(1−β)/C1.
Summing over k∈{0,1,...,K−1}:
K−1/summationdisplay
k=0E/bracketleftig
∥∇F (¯xk)∥2/bracketrightig
≤1
C1/parenleftbigg
E[F(¯z0)]−E[F(¯zk)]/parenrightbigg
−/tildewideC6K−1/summationdisplay
k=0E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi/parenleftbig
xi
k/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+/tildewideC2K−1/summationdisplay
k=0E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1˜gi
k/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2

+/tildewideC3K−1/summationdisplay
k=0E/bracketleftig
∥¯zk−¯xk∥2/bracketrightig
+/tildewideC4K−1/summationdisplay
k=0E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1/parenleftbig
˜gi
k−gi
k/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+/tildewideC5K−1/summationdisplay
k=01
NN/summationdisplay
l=1E/bracketleftig/vextenddouble/vextenddouble¯xk−xi
k/vextenddouble/vextenddouble2/bracketrightig
Substituting Lemma 1, Lemma 2, Lemma 3 and Equation. 15 into the above equation, we have:
24Published in Transactions on Machine Learning Research (11/2023)
K−1/summationdisplay
k=0E/bracketleftig
∥∇F (¯xk)∥2/bracketrightig
≤1
C1/parenleftbigg
E[F(¯z0)]−E[F(¯zk)]/parenrightbigg
−/parenleftbigg
/tildewideC6−2/tildewideC2−2/tildewideC3η2β2
(1−β)4−/tildewideC56η2
(1−β)2(1−√ρ)/parenrightbigg
K−1/summationdisplay
k=0E
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
NN/summationdisplay
i=1∇fi/parenleftbig
xi
k/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
+/parenleftbigg
/tildewideC2+/tildewideC3η2β2
(1−β)4/parenrightbigg/parenleftbigg10σ2
N+ 8ζ2/parenrightbigg
K+ 4/tildewideC4/parenleftbiggσ2
N+ζ2/parenrightbigg
K
+/tildewideC514η2(σ2+ζ2)
(1−β)2(1−√ρ)2K
Dividing both sides by Kand considering the fact that ¯z0=¯x0and/parenleftbigg
/tildewideC6−2/tildewideC2−2/tildewideC3η2β2
(1−β)4−
/tildewideC56η2
(1−β)2(1−√ρ)/parenrightbigg
≥0:
1
KK−1/summationdisplay
k=0E/bracketleftig
∥∇F (¯xk)∥2/bracketrightig
≤1
C1K/parenleftbigg
F(¯x0)−F⋆/parenrightbigg
+/parenleftbigg
/tildewideC2+/tildewideC3η2β2
(1−β)4/parenrightbigg/parenleftbigg10σ2
N+ 8ζ2/parenrightbigg
+ 4/tildewideC4/parenleftbiggσ2
N+ζ2/parenrightbigg
+/tildewideC514η2(σ2+ζ2)
(1−β)2(1−√ρ)2
≤1
C1K(F(¯x0)−F⋆) +/parenleftbigg
10/tildewideC2+ 10/tildewideC3η2β2
(1−β)4+ 4/tildewideC4/parenrightbigg/parenleftbiggσ2
N+ζ2/parenrightbigg
+/tildewideC514η2(σ2+ζ2)
(1−β)2(1−√ρ)2
≤1
C1K(F(¯x0)−F∗) +/parenleftbigg
10/tildewideC2+ 10/tildewideC3η2β2
(1−β)4+ 4/tildewideC4/parenrightbigg
(σ2
N+ζ2) +/tildewideC514η2(σ2+ζ2)
(1−β)2(1−√ρ)2
Now, we simplify the coefficients:
10/tildewideC2+ 10/tildewideC3η2β2
(1−β)4+ 4/tildewideC4≤/parenleftbigg10η2L(η2+β)
(1−β)3/parenrightbigg
/C1=20η2L2β(η2+β)
(1−β)2(ηβL−(1−β)2)
/tildewideC514η2
(1−β)2=14η3L3β
(1−β)2(ηβL−(1−β)2)
Now we redefine the coefficients:
C2=20η2L2β(η2+β)
(1−β)2(ηβL−(1−β)2)
C3=14η3L3β
(1−β)2(ηβL−(1−β)2)
Therefore we arrive at the bound given by the theorem. 1:
1
KK−1/summationdisplay
k=0E[||∇F (¯xk)||2]≤1
C1K(F(¯x0)−F∗) +C2(σ2
N+ζ2) +C3(σ2+ζ2)
(1−√ρ)2(45)
A.2.3 Discussion on the Step Size
In the proof of Theorem 1, we assumed the following /tildewideC6−2/tildewideC2−2/tildewideC3η2β2
(1−β)4−/tildewideC56η2
(1−β)2(1−√ρ)≥0.
The above equation is true under the following conditions:
(i)C1>0
(ii) 1−4L
(1−β)2η−6L2
(1−β)2(1−√ρ)η2≥0
25Published in Transactions on Machine Learning Research (11/2023)
Solving the first inequality gives us β >1−Lη
2(/radicalig
1 +4
Lη−1).
We can simply this further by using the Taylor series approximation i.e.,1
Lη<β < 1ifη>4
L
Now, solving the second inequality, combining the fact that η>0, we have then the specific form of η∗
η∗=/radicalbig
4(1−√ρ)2+ 6(1−√ρ)(1−β)2−2(1−√ρ)
6L.
Therefore, the step size ηis defined as
η≤/radicalbig
4(1−√ρ)2+ 6(1−√ρ)(1−β)2−2(1−√ρ)
6L
A.2.4 Proof for Corollary 1
We assume that the step size ηisO(√
N√
K)andζ2isO(1√
K). Given this assumption, we have the following
C1=O(√
N√
K),/tildewideC2=O(√
N√
K),/tildewideC3=O(√
K√
N),/tildewideC4=O(√
N√
K),/tildewideC5=O(1),
This implies that
C2=O(√
N√
K),C3=O(N
K)
Now we proceed to find the order of each term in Equation. 45. To do that we first point out that
F(¯x0)−F∗
C1K=O/parenleftig1√
NK/parenrightig
.
For the remaining terms we have,
C2σ2
N=O/parenleftig1√
NK/parenrightig
, C 2ζ2=O/parenleftig√
N
K/parenrightig
C3σ2
(1−√ρ)2=O/parenleftigN
K/parenrightig
, C 3ζ2
(1−√ρ)2=O/parenleftigN
K1.5/parenrightig
Therefore, by omitting the constant Nin this context, there exists a constant C > 0such that the overall
convergence rate is as follows:
1
KK−1/summationdisplay
k=0E/bracketleftig
∥∇F (¯xk)∥2/bracketrightig
≤C/parenleftigg
1√
NK+1
K+1
K1.5/parenrightigg
, (46)
which suggests when Kis sufficiently large, NGMenables the convergence rate of O(1√
NK).
A.3 Decentralized Learning Setup
The traditional decentralized learning algorithm (d-psgd) is described as Algorithm. 2. For the decentralized
setup, we use an undirected ring and undirected torus graph topologies with a uniform mixing matrix. The
undirected ring topology for any graph size has 3 peers per agent including itself and each edge has a weight
of1
3. The undirected torus topology with 10 agents has 4 peers per agent including itself and each edge has
a weight of1
4. The undirected torus topology 20 agents have 5 peers per agent including itself and each edge
has a weight of1
5. Finally, Figure 5 depicts the overview of the proposed NGMalgorithm. Note that we do
not have step 4 of the Figure 5 in NGM mvalgorithm.
26Published in Transactions on Machine Learning Research (11/2023)
X1
D1
X2
D2
X3
D3
X4
D4
X2
 X4
 X1
 X3
X2
 X4
 X3
 X1 Communicate model 
parameters2
X1
 X2
 X3
 X4 Model update -Local 6
Model update -Global 7
 X1
 X2
 X3
 X4Self Gradients
1 G11 G22 G33 G44 
Compute model -variant 
cross -gradients 3
G41
G21G12
G32G23
G43G34
G14
Receive data -variant 
cross -gradients 4
G14
G12G22
G23G32
G34G43
G41
Gradient Aggregation
(mean)54-agent Ring Topolog y
Neighborhood 
Gradient 
Clustering
Figure 5: NGMalgorithm overview. In the proposed algorithm, (1) each agent computes self-gradients of
model parameters on its own data set; (2) each agent sends its model parameters to its neighbors; (3) each
agent computes the model-variant cross-gradients of its neighbors’ models on its own data set; (4) each agent
receives the data-variant cross-gradients from its neighbors; (5) update the local gradient using the mean
of self-gradients and cross-gradients ; (6) update the model parameter using local SGD step with updated
gradients; (7) and update the model parameter using global gossip averaging step.
Algorithm 2 Decentralized Peer-to-Peer Training ( D-PSGD with momentum)
Input:Each agent i∈[1,N]initializes model weights xi
(0), step sizeη, averaging rate γ, mixing matrix
W= [wij]i,j∈[1,N], andIijare elements of N×Nidentity matrix.
Each agent simultaneously implements the T RAIN( ) procedure
1.procedure TRAIN( )
2.fork=0,1,...,K−1do
3.di
k∼Di// sample data from training dataset.
4.gi
k=∇xfi(di
k;xk
i) // compute the local gradients
5.vi
k=βvi
(k−1)−ηgi
k // momentum step
6./tildewidexi
k=xi
k+vi
k // update the model
7. S ENDRECEIVE(/tildewidexi
k) // share model parameters with neighbors N(i).
8.xi
(k+1)=/tildewidexi
k+γ/summationtext
j∈Ni(wij−Iij)/tildewidexj
k// gossip averaging step
9.end
10.return
27Published in Transactions on Machine Learning Research (11/2023)
A.4 CompNGM
The section presents the pseudocode for CompNGM (compressed version of NGM dv) in Algorithm 3. The
NGM dvalgorithm at every iteration involves two rounds of communication with the neighbors: 1) communi-
cate the model parameters, and 2) communicate the cross-gradients. This communication overhead can be a
bottleneck in a resource-constrained environment. Hence we propose a compressed version of NGM dvusing
Error Feedback SGD (EF-SGD) (Karimireddy et al., 2019) to compress gradients. We compress the error-
compensatedself-gradientsandcross-gradientsfrom32bits(floatingpointprecisionofarithmeticoperations)
to 1 bit by using scaled signed gradients. The error between the compressed and non-compressed gradient
of the current iteration is added as feedback to the gradients in the next iteration before compression.
Tables. 8, 9, 10 compare the proposed CompNGM with CompCGA and show that our method outperforms
CompCGA. We also analyze the impact of compression on consensus error, validation loss, and validation
accuracy with respect to communication bits in the top panel of Figure. 6. We present the consensus error,
validation loss, and validation accuracy with respect to epochs in the bottom panel of Figure. 6. Note
that epochs are proxies for communication rounds. In Figure. 6 each epoch contains 157 communication
rounds. For the Figure. 6 experiment, we use a step-lr scheduler for the learning rate schedule whereas the
experiments in Tables. 8, 9, 10 use the multistep-lr scheduler. We observe that both for iso-communication
cost and iso-epochs, NGM dvperforms better than CompNGM in terms of validation accuracy.
Algorithm 3 Compressed Neighborhood Gradient Mean ( CompNGM )
Input:Each agent i∈[1,N]initializes model weights xi
(0), step sizeη, averaging rate γ, dimension of the
gradientd, mixing matrix W= [wij]i,j∈[1,N],NGMmixing weight α, andIijare elements of N×Nidentity
matrix.
Each agent simultaneously implements the T RAIN( ) procedure
1.procedure TRAIN( )
2.fork=0,1,...,K−1do
3.di
k∼Di// sample data from training dataset
4.gii
k=∇xfi(di
k;xi
k) // compute the local self-gradients
5.pii
k=gii
k+eii
k // error compensation for self-gradients
6.δii
k= (||pii
k||1/d)sgn(pii) // compress the compensated self-gradients
7.eii
k+1=pii
k−δii
k // update the error variable
8. S ENDRECEIVE(xi
k) // share model parameters with neighbors N(i)
9. foreach neighbor j∈{N(i)−i}do
10. gji
k=∇xfi(di
k;xj
k) // compute neighbors’ cross-gradients
11. pji
k=gji
k+eji
k// error compensation for cross-gradients
12. δji
k= (||pji
k||1/d)sgn(pji
k) // compress the compensated cross-gradients
13. eji
k+1=pji
k−δji
k// update the error variable
14. ifα̸= 0do
15. S ENDRECEIVE(δji
k) // share compressed cross-gradients between iandj
16. end
17. end
18./tildewidegi
k= (1−α)/summationtext
j∈Niwjiδji
k+α/summationtext
j∈Niwijδij
k// modify local gradients
19.vi
k=βvi
(k−1)−η/tildewidegi
k // momentum step
20./tildewidexi
k=xi
k+vi
k // update the model
21.xi
(k+1)=/tildewidexi
k+γ/summationtext
j∈Ni(wij−Iij)xj
k// gossip averaging step
22. end
23.return
28Published in Transactions on Machine Learning Research (11/2023)
Table 8: Average test accuracy comparisons for CIFAR-10 with non-IID data using various architectures and
graph topologies. The results are averaged over three seeds where std is indicated.
Method Agents5layer CNN 5layer CNN VGG-11 ResNet-20
Ring Torus Ring Ring
5 82.00±0.25 - 83.65 ±0.41 86.73±0.34
CompCGA 10 71.41 ±0.94 75.95±0.41 73.96±0.31 73.63±0.55
20 68.15±0.79 71.71±0.54 73.72±2.74 66.34±0.98
5 82.91±0.21 - 84.03±0.32 87.56±0.34
CompNGM (ours) 10 74.36±0.42 77.82±0.20 77.02±0.14 78.50±0.98
20 71.46±0.85 73.62±0.74 73.76±0.20 72.62±0.71
Table 9: Average test accuracy comparisons for various datasets with non-IID sampling trained over undi-
rected ring topology. The results are averaged over three seeds where std is indicated.
Method AgentsFashion MNIST CIFAR-100 Imagenette(32x32)
(LeNet-5) (ResNet-20) (MobileNet-V2)
CompCGA5 90.45±0.34 55.74±0.33 72.76±0.44
10 81.62±0.37 38.84±0.54 59.92±0.72
CompNGM (ours)5 90.48±0.19 57.51±0.48 72.91±1.06
10 83.38±0.39 43.07±0.32 61.91±2.10
Table 10: Average test accuracy comparisons for AGNews dataset (left side of the table) and full resolution
(224×224) Imagenette dataset (right side of the table). The results are averaged over three seeds where std
is indicated.
Method AGNews-BERT mini AGNews-DistilBERT baseImagenette (224×224)-ResNet-18
Agents = 4 Agents = 8 Agents = 4 Agents = 5
Ring Topology Ring Topology Ring Topology Chain Topology
CompCGA 91.05 ±0.29 88.91±0.25 93.54±0.03 84.65±0.57 62.93±1.33
CompNGM (ours) 91.24±0.43 89.01±0.13 93.50±0.16 85.44±0.10 62.64±0.85
A.5 Datasets
In this section, we give a brief description of the datasets used in our experiments. We use a diverse set of
datasets each originating from a different distribution of images to show the generalizability of the proposed
techniques.
CIFAR-10: CIFAR-10 (Krizhevsky et al., 2014) is an image classification dataset with 10 classes. The
image samples are colored (3 input channels) and have a resolution of 32×32. There are 50,000training
samples with 5000samples per class and 10,000test samples with 1000samples per class.
CIFAR-100: CIFAR-100 (Krizhevsky et al., 2014) is an image classification dataset with 100 classes.
The image samples are colored (3 input channels) and have a resolution of 32×32. There are 50,000
training samples with 500samples per class and 10,000test samples with 100samples per class. CIFAR-100
classification is a harder task compared to CIFAR-10 as it has 100 classes with very less samples per class
to learn from.
Fashion MNIST: Fashion MNIST (Xiao et al., 2017) is an image classification dataset with 10 classes.
The image samples are in greyscale (1 input channel) and have a resolution of 28×28. There are 60,000
training samples with 6000samples per class and 10,000test samples with 1000samples per class.
Imagenette: Imagenette(Husain,2018)isa10-classsubsetoftheImageNetdataset. Theimagesamplesare
colored (3 input channels) and have a resolution of 224×224. There are 9469training samples with roughly
950samples per class and 3925test samples. We conduct our experiments on two different resolutions of
29Published in Transactions on Machine Learning Research (11/2023)
(a) Consensus error vs Communication
bits
(b) Validation loss vs Communication
bits
(c) Validation accuracy vs Communica-
tion bits
(d) Consensus error vs Epochs
 (e) Validation loss vs Epochs
 (f) Validation accuracy vs Epochs
Figure 6: Consensus error, validation loss, and validation accuracy against communication bits (top panel)
and epochs (bottom panel) for training CIFAR-10 (non-IID) on ResNet-20 architecture over a ring topology
with 10 agents.
the Imagenette dataset – a) a resized low resolution of 32×32and, b) a full resolution of 224×224. The
Imagenette experimental results reported in Table. 3 use the low-resolution images whereas experimental
results in Table. 4 use the full resolution images.
AGNews: We use AGNews (Zhang et al., 2015) dataset for Natural Language Processing (NLP) task.
This is a text classification dataset where the given text news is classified into 4 classes, namely "World",
"Sport", "Business" and "Sci/Tech". The dataset has a total of 120000 and 7600 samples for training and
testing respectively, which are equally distributed across each class.
A.6 Network Architecture
We replace ReLU+BatchNorm layers of all the model architectures with EvoNorm-S0 (Liu et al., 2020a) as
it was shown to be better suited for decentralized learning on non-IID data (Lin et al., 2021).
5 layer CNN: The 5-layer CNN consists of 4 convolutional with EvoNorm-S0 (Liu et al., 2020a) as an
activation-normalizationlayer, 3max-poolinglayers, andonelinearlayer. Inparticular, ithas2convolutional
layers with 32 filters, a max pooling layer, then 2 more convolutional layers with 64 filters each followed by
another max pooling layer and a dense layer with 512 units. It has a total of 76Ktrainable parameters.
VGG-11: We modify the standard VGG-11 (Simonyan & Zisserman, 2014) architecture by reducing the
number of filters in each convolutional layer by 4×and using only one dense layer with 128 units. Each con-
volutional layer is followed by EvoNorm-S0 as the activation-normalization layer and it has 0.58Mtrainable
parameters.
ResNet-20: For ResNet-20 (He et al., 2016), we use the standard architecture with 0.27Mtrainable pa-
rameters except that BatchNorm+ReLU layers are replaced by EvoNorm-S0.
30Published in Transactions on Machine Learning Research (11/2023)
LeNet-5: For LeNet-5 (LeCun et al., 1998), we use the standard architecture with 61,706trainable param-
eters.
MobileNet-V2: We use the the standard MobileNet-V2 (Sandler et al., 2018) architecture used for CIFAR
dataset with 2.3Mparameters except that BatchNorm+ReLU layers are replaced by EvoNorm-S0.
ResNet-18: For ResNet-18 (He et al., 2016), we use the standard architecture with 11Mtrainable param-
eters except that BatchNorm+ReLU layers are replaced by EvoNorm-S0.
BERT mini:For BERT mini(Devlin et al., 2018) we use the standard model from the paper. We restrict the
sequence length of the model to 128. The model used in the work hence has 11.07Mparameters.
DistilBERT base:For DistilBERT base(Sanh et al., 2019) we use the standard model from the paper. We
restrict the sequence length of the model to 128. The model used in the work hence has 66.67Mparameters.
(a)NGM dvon IID data
 (b)NGM dvon non-IID data
 (c) Non-IID for ring topology
Figure 7: Validation loss for CIFAR-10 dataset trained on a 10 agents ring graph with 5-layer CNN.
A.7 Analysis for 10 Agents
We show the convergence characteristics of the proposed NGM dvalgorithm over IID and Non-IID data
sampled from the CIFAR-10 dataset in Figure. 7(a), and 7(b) respectively. For Non-IID distribution, we
observe that there is a slight difference in convergence rate (as expected) with a slower rate for sparser
topology (undirected ring graph) compared to its denser counterpart (fully connected graph). Figure. 7(c)
shows the comparison of the convergence characteristics of the NGM dvtechnique with the current state-
of-the-art CGA algorithm. We observe that NGM dvhas lower validation loss than CGA for the same
decentralized setup indicating its superior performance over CGA. We also plot the model variance and data
variance bias terms for both NGM dvand CGA techniques as shown in Figure. 8(a), and 8(b) respectively.
We observe that both model variance and data variance bias for NGM dvare significantly lower than CGA.
A.8 Resource Comparison
The communication cost, memory overhead, and compute overhead for various decentralized algorithms are
shown in Table. 6. The D-PSGD, QG-DSGDm, and NGM mvalgorithms require each agent to communicate
model parameters of size mswith all the nineighbors for the gossip averaging step and hence has a commu-
nication cost ofO(nims). In the case of NGM dvand CGA, there is an additional communication round for
sharing data-variant cross gradients apart from sharing model parameters for the gossip averaging step. So,
both these techniques incur a communication cost of O(2nims)and therefore an overhead of O(nims)com-
pared to D-PSGD. Momentum Tracking also needs additional communication to communicate the tracking
variable. CompNGM compresses the additional round of communication involved with NGM dvfrombbits
to1bit. This reduces the communication overhead from O(nims)toO(nims
b).
CGA algorithm stores all the received data-variant cross-gradients in the form of a matrix for the quadratic
projection step. Hence, CGA has a memory overhead of O(nims)compared to D-PSGD. NGM dvdoes not
require any additional memory as it averages the received data-variant cross-gradients into the self-gradient
31Published in Transactions on Machine Learning Research (11/2023)
(a) Average L1 norm of ϵ.
 (b) Average L1 norm of ω.
Figure 8: Average L1 norm of model variance bias and data variance bias for 10 agents trained on CIFAR-10
dataset with 5 layer CNN architecture over an undirected ring topology.
Table 11: Memory overheads for various methods trained on different model architectures with CIFAR-10
dataset over undirected ring topology with 2 neighbors per agent.
ArchitectureCGANGM dvCompCGA CompNGM
(MB) (MB) (MB) (MB)
5 layer CNN 0.58 0 0.58 0.60
VGG-11 4.42 0 4.42 4.56
ResNet-20 2.28 0 2.28 2.15
buffer. The compressed version of NGM dvrequires an additional memory of O(nims)to store the error
variableseji(refer Algorith. 3). CompCGA also needs to store error variables along with the projection
matrix of compressed gradients. Therefore, CompCGA has a memory overhead of O(nims+nims
b). Note
that memory overhead depends on the type of graph topology and model architecture but not on the size
of the graph. The memory overhead for different model architectures trained on undirected ring topology is
shown in Table. 11
The computation of the cross-gradients (in both CGA and NGM algorithms) requires niforward and back-
ward passes through the deep learning model at each agent. This is reflected as O(niB)in the compute
overhead in Table. 6. We assume that the compute effort required for the backward pass is twice that of the
forward pass. CGA algorithm involves quadratic programming projection step (Goldfarb & Idnani, 1983) to
update the local gradients. Quadratic programming solver (quadprog) uses Goldfarb/Idnani dual algorithm.
CGA uses quadratic programming to solve the following (Equation 47 -see Equation 5a in (Esfandiari et al.,
2021)) optimization problem in an iterative manner:
minu1
2uTGGTu+gTGTu
s.t.u≥0(47)
where G is the matrix containing cross-gradients, g is the self-gradient, and the optimal gradient direction
g∗in terms of the optimal solution of the above equation u∗isg∗=GTu∗+g. The above optimization takes
multiple iterations, resulting in compute and time complexity of polynomial(degree ≥2) order. In contrast,
NGM involves a simple averaging step that requires O(nims)addition operations.
A.9 Communication Cost
In this section we present the communication cost per agent in terms of Gigabytes of data transferred
during the entire training process (refer Tables. 12, 13, 15, 14). The D-PSGD and NGM mvhave the lowest
32Published in Transactions on Machine Learning Research (11/2023)
communication cost ( 1×). We emphasize that NGM mvoutperforms D-PSGD in decentralized learning
over label-wise non-IID data for the same communication cost. NGM dvand CGA have 2×communication
overhead compared to D-PSGD where as CompNGM and CompCGA have 1.03×communication overhead
compared to D-PSGD. The compressed versions of NGM dvand CGA compress the second round of cross-
gradient communication to 1 bit. We assume the full-precision cross-gradients to be of 32-bit precision and
hence the CompNGM reduces the communication cost by 32×compared to NGM dv.
Table 12: Communication costs per agent in GBs for experiments in Table 2 and 8
Method Agents5layer CNN 5layer CNN VGG-11 ResNet-20
Ring Torus Ring Ring
D-PSGD, 5 17.75 - 270.64 127.19
QG-DSGDm and 10 8.92 13.38 135.86 63.84
NGM mv 20 4.50 6.65 68.48 32.18
Momentum Tracking, 5 35.48 - 541.05 254.27
CGA and 10 17.81 26.72 271.50 127.59
NGM dv 20 8.98 17.95 136.72 64.25
CompCGA 5 18.31 - 279.09 131.16
and 10 9.20 13.79 140.10 65.84
CompNGM 20 4.64 9.28 70.61 33.18
Table 13: Communication costs per agent in GBs for experiments in Table 3 and 9
Method AgentsFashion MNIST CIFAR-100 Imagenette
(LeNet-5) (ResNet-20) (MobileNet-V2)
D-PSGD, QG-DSGDm and 5 17.25 103.74 103.12
NGM mv 10 8.61 51.89 51.60
Momentum Tracking, 5 34.50 207.47 206.23
CGA and NGM dv(ours) 10 17.23 103.79 103.19
CompCGA and 5 17.79 106.98 106.34
CompNGM (ours) 10 8.88 53.52 53.21
Table 14: Communication costs per agent in GBs for experiments in Table 4 and 10(right)
Method Ring topology chain topology
D-PSGD, QG-DSGDm and and NGM mv 501.98 401.59
Momentum Tracking, CGA and NGM dv 1003.96 803.17
CompCGA and CompNGM 517.67 414.14
Table 15: Communication costs per agent in GBs for experiments in Table 4 and 10 (left)
MethodBERT mini DistilBERT base
Agents = 4 Agents = 8 Agents = 4
D-PSGD, QG-DSGDm and NGM mv 234.30 118.20 1410.39
Momentum Tracking, CGA and NGM dv486.59 236.40 2820.77
CompCGA and CompNGM 241.6 121.89 1454.46
A.10 Hyper-parameters
This section presents the hyper-parameters for the experimental results presented in Sec. 5. All the experi-
ments were run for three randomly chosen seeds. We decay the step size by 10x after 50% and 75% of the
training for all the experiments except for figures. To generate the figures, the simulations are run for 300
33Published in Transactions on Machine Learning Research (11/2023)
Table16: Hyper-parametersusedforCIFAR-10withnon-IIDdatausingvariousmodelarchitecturepresented
in Table 2 and 8
5 Layer CNN VGG-11 ResNet-20
Method Agents Ring Torus Ring Torus
(n) ( β,η,γ) (β,η,γ) (β,η,γ) (β,η,γ)
5 ( 0.0,0.1,1.0)− (0.0,0.01,1.0) ( 0.0,0.1,1.0)
D-PSGD 10 ( 0.0,0.1,1.0) ( 0.0,0.1,1.0) ( 0.0,0.01,1.0) ( 0.0,0.1,1.0)
20 ( 0.0,0.1,1.0) ( 0.0,0.1,1.0) ( 0.0,0.01,1.0) ( 0.0,0.1,1.0)
5 ( 0.9,0.01,1.0)− (0.9,0.01,1.0) ( 0.9,0.1,1.0)
QG-DSGDm 10 ( 0.9,0.01,1.0) (0.9,0.005,0.1) (0.9,0.01,1.0) ( 0.9,0.1,1.0)
20 ( 0.9,0.01,1.0) (0.0,0.005,0.1) (0.9,0.01,1.0) ( 0.9,0.1,1.0)
5 ( 0.0,0.1,1.0)− (0.9,0.01,1.0) ( 0.0,0.1,1.0)
NGM mv 10 ( 0.0,0.1,1.0) ( 0.0,0.1,1.0) ( 0.0,0.01,1.0) ( 0.0,0.1,1.0)
20 ( 0.0,0.1,1.0) ( 0.0,0.1,1.0) ( 0.0,0.01,1.0) ( 0.0,0.1,1.0)
5 ( 0.9,0.01,1.0)− (0.9,0.01,1.0) ( 0.9,0.1,1.0)
Momentum Tracking 10 ( 0.9,0.01,1.0) ( 0.9,0.01,1.0) ( 0.9,0.01,1.0) ( 0.9,0.1,1.0)
20 ( 0.9,0.01,1.0) ( 0.0,0.01,1.0) ( 0.9,0.01,1.0) ( 0.9,0.1,1.0)
5 ( 0.9,0.01,0.1)− (0.9,0.1,0.5) ( 0.9,0.1,1.0)
CGA and NGM dv 10 ( 0.9,0.01,0.5) ( 0.9,0.01,0.1) ( 0.9,0.1,0.5) ( 0.9,0.1,1.0)
20 ( 0.9,0.01,0.5) ( 0.9,0.01,0.1) ( 0.9,0.1,0.5) ( 0.9,0.1,1.0)
5 ( 0.9,0.01,0.1)− (0.9,0.01,0.1) (0.9,0.01,0.1)
CompCGA and CompNGM 10 ( 0.9,0.01,0.5) ( 0.9,0.01,0.1) ( 0.9,0.01,0.1) (0.9,0.01,0.1)
20 ( 0.9,0.01,0.5) ( 0.9,0.01,0.1) ( 0.9,0.01,0.1) (0.9,0.01,0.1)
epochs with the StepLR scheduler where the learning rate is decayed by 0.981 after every epoch. We have
used a momentum of 0.9 for all QG-DSGDm, Momentum Tracking, CGA, and NGM dvexperiments. How-
ever, for D-PSGD and NGM mv, the momentum is set to either 0.9 or 0.0 based on the validation accuracy.
The averaging rate is always set to 1.0for the Momentum Tracking algorithm.
Hyper-parameters for CIFAR-10 : All the experiments that involve 5-layer (Table. 2) have stopping
criteria set to 100 epochs. We decay the step size by 10×in multiple steps at 50thand75thepoch. All the
experiments for the CIFAR-10 dataset trained on VGG-11 and ResNet-20 (Table. 2) have stopping criteria
set to 200 epochs. We decay the step size by 10×in multiple steps at 100thand150thepoch. Table 16
presents the β,η, andγcorresponding to the momentum, step size, and gossip averaging rate.
Hyper-parameters used for Table. 3: All the experiments in Table. 3 have stopping criteria set to 100
epochs. We decay the step size by 10×in multiple steps at 50thand75thepoch. Table 17 presents the
β,η, andγcorresponding to the momentum, step size, and gossip averaging rate. For all the experiments
related to Fashion MNIST and Imagenette (low resolution of (32×32)), we use a mini-batch size of 32 per
agent. For all the experiments related to CIFAR-100, we use a mini-batch size of 20 per agent. For all the
experiments, we use a mini-batch size of 32 per agent.
Hyper-parameters used for Table. 4 (right): All the experiments in Table. 4 (right) have stopping
criteria set to 100 epochs. We decay the step size by 10×at50th,75thepoch. Table 18 (right) presents the
β,η, andγcorresponding to the momentum, step size, and gossip averaging rate. For all the experiments,
we use a mini-batch size of 32 per agent.
Hyper-parameters used for Table. 4 (left): All the experiments in Table. 4 (left) have stopping criteria
set to 3 epochs. We decay the step size by 10×at2ndepoch. Table 18 (left) presents the β,η, andγ
corresponding to the momentum, step size, and gossip averaging rate. For all the experiments, we use a
mini-batch size of 32 per agent on the AGNews dataset.
Hyper-parameters used for Table. 7: All the experiments in Table. 7 have stopping criteria set to 60
epochs. The initial learning rate is set to 0.01 and is decayed by 10×at20th,40th,54thepoch. For all the
experiments, we use a mini-batch size of 64 per agent. The values used for the learning rate, momentum
coefficient, and averaging rate are presented in Table. 19.
34Published in Transactions on Machine Learning Research (11/2023)
Table 17: Hyper-parameters used for Table. 3 and 9
MethodAgents Fashion MNIST CIFAR-100 Imagenette
(n) ( β,η,γ) ( β,η,γ) (β,η,γ)
D-PSGD5 ( 0.0,0.01,1.0) ( 0.0,0.1,1.0) ( 0.0,0.1,1.0)
10 ( 0.0,0.01,1.0) ( 0.0,0.1,1.0) ( 0.0,0.1,1.0)
QG-DSGDm5 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.9,0.01,1.0)
10 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.9,0.01,1.0)
NGM mv5 ( 0.9,0.01,1.0) ( 0.0,0.1,1.0) ( 0.0,0.1,1.0)
10 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.0,0.1,1.0)
Momentum Tracking5 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.9,0.01,1.0)
10 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.9,0.01,1.0)
CGA and NGM dv5 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.0,0.01,0.5)
10 ( 0.9,0.01,1.0) ( 0.9,0.1,1.0) ( 0.0,0.01,0.5)
CompCGA and CompNGM5 ( 0.9,0.01,0.1) ( 0.9,0.01,0.1) (0.0,0.01,0.1)
10 ( 0.9,0.01,0.1) ( 0.9,0.01,0.1) (0.0,0.01,0.5)
Table 18: Hyper-parameters used for Table. 4 and 10
MethodBERT mini DistilBERT base Imagenette (ResNet-18)
Agents = 4 Agents = 8 Agents = 4 Ring topology Chain topology
(β,η,γ) (β,η,γ) (β,η,γ) (β,η,γ) (β,η,γ)
D-PSGD ( 0.0,0.01,1.0) ( 0.0,0.01,1.0) ( 0.0,0.01,1.0)(0.0,0.01,1.0) ( 0.0,0.01,1.0)
QG-DSGDm ( 0.9,0.01,1.0) ( 0.9,0.01,1.0) ( 0.9,0.01,1.0)(0.9,0.01,1.0) ( 0.9,0.01,1.0)
NGM mv(ours) ( 0.0,0.01,1.0) ( 0.0,0.01,1.0) ( 0.9,0.01,1.0)(0.9,0.01,1.0) ( 0.0,0.01,1.0)
Momentum Tracking ( 0.9,0.005,1.0) (0.9,0.01,1.0) ( 0.9,0.01,1.0)(0.9,0.01,1.0) ( 0.9,0.01,1.0)
CGA ( 0.9,0.01,0.5) ( 0.9,0.01,0.5) ( 0.9,0.01,0.5)(0.9,0.01,0.5) ( 0.9,0.01,0.1)
NGM dv (0.9,0.01,0.5) ( 0.9,0.01,0.5) ( 0.9,0.01,0.5)(0.9,0.01,0.5) ( 0.9,0.01,0.1)
CompCGA ( 0.9,0.01,0.5) ( 0.9,0.01,0.5) ( 0.9,0.01,0.5)(0.9,0.01,0.1) ( 0.9,0.01,0.1)
CompNGM (0.9,0.01,0.5) ( 0.9,0.01,0.5) ( 0.9,0.01,0.5)(0.9,0.01,0.1) ( 0.9,0.01,0.1)
Table 19: hyperparameters for Table. 7.
Trained for D-PSGD QG-DSGDm NGM mvNGM mvNGM mvNGM dvNGM dv
60 epochs +LM + QGM + LM + QGM
Learning rate ( η) 0.01 0.01 0.01 0.01 0.01 0.01 0.01
Momentum coefficient ( β) 0.0 0.9 0.0 0.9 0.9 0.9 0.9
Averaging rate ( γ) 0.5 1.0 0.5 1.0 1.0 1.0 1.0
35