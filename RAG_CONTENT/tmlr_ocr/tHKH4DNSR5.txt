Published in Transactions on Machine Learning Research (10/2024)
Equivariant Symmetry Breaking Sets
YuQing Xie xyuqing@mit.edu
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
Tess Smidt tsmidt@mit.edu
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
Reviewed on OpenReview: https: // openreview. net/ forum? id= tHKH4DNSR5
Abstract
Equivariant neural networks (ENNs) have been shown to be extremely effective in applica-
tionsinvolvingunderlyingsymmetries. ByconstructionENNscannotproducelowersymme-
try outputs given a higher symmetry input. However, symmetry breaking occurs in many
physical systems and we may obtain a less symmetric stable state from an initial highly
symmetric one. Hence, it is imperative that we understand how to systematically break
symmetry in ENNs. In this work, we propose a novel symmetry breaking framework that
is fully equivariant and is the first which fully addresses spontaneous symmetry breaking.
We emphasize that our approach is general and applicable to equivariance under any group.
To achieve this, we introduce the idea of symmetry breaking sets (SBS). Rather than re-
design existing networks, we design sets of symmetry breaking objects which we feed into
our network based on the symmetry of our inputs and outputs. We show there is a natural
way to define equivariance on these sets, which gives an additional constraint. Minimiz-
ing the size of these sets equates to data efficiency. We prove that minimizing these sets
translates to a well studied group theory problem, and tabulate solutions to this problem
for the point groups. Finally, we provide some examples of symmetry breaking to demon-
strate how our approach works in practice. The code for these examples is available at
https://github.com/atomicarchitects/equivariant-SBS .
1 Introduction
Equivariant neural networks have emerged as a promising class of models for domains with latent symmetry
(Wang et al., 2022a). This is especially useful for scientific and geometric data, where the underlying
symmetries are often well known. For example, the coordinates of a molecule may be different under
rotations and translations, but the molecule remains the same. Traditional neural networks must learn this
symmetry through data augmentation or other training schemes. In contrast, equivariant neural networks
already incorporate these symmetries and can focus on the underlying physics. ENNs have achieved state-of-
the-art results on numerous tasks including molecular dynamics, molecular generation, and protein folding
(Batatia et al., 2022; Batzner et al., 2022; Daigavane et al., 2023; Ganea et al., 2021; Hoogeboom et al.,
2022; Jia et al., 2020; Jumper et al., 2021; Liao & Smidt, 2022).
A consequence of the symmetries built-in to ENNs is that their outputs must have equal or higher symmetry
than their inputs (Smidt et al., 2021). However, we frequently encounter situations where we desire a
lower symmetry output given a higher symmetry input. We refer to an input-output pair where the output
has lower symmetry as a symmetry breaking sample. Such symmetry breaking samples occur frequently in
physical systems. In physics, these are classified into two types: explicit symmetry breaking and spontaneous
symmetrybreaking(Castellanietal.,2003). Inexplicitsymmetrybreaking, thegoverninglawsaremanifestly
asymmetric explaining the symmetry breaking samples while in spontaneous symmetry breaking the laws
1Published in Transactions on Machine Learning Research (10/2024)
are symmetric but we still observe symmetry breaking samples. Notably, in spontaneous symmetry breaking
there are multiple correct outputs for a given input and we have a modified form of equivariance. We expand
on this in Section 2.
One class of approaches conducive for explicit symmetry breaking is learning to break symmetry. For
example, Smidt et al. (2021) showed that the gradients of the loss function can be used to learn a symmetry
breaking order parameter. This lets us identify what type of missing asymmetry is needed to correctly
model the results. Another related approach is approximate and relaxed equivariant networks (Huang et al.,
2023; van der Ouderaa et al., 2022; Wang et al., 2023; 2022b). These networks have similar architectures to
equivariant models, but allow nontrivial weights in the layers to break equivariance. Hence, they can learn
how much symmetry to preserve to fit the data distribution. However, since these methods explicitly break
equivariance, they are not appropriate for spontaneous symmetry breaking. If all symmetrically related
lower symmetry outputs are equally likely in the data, then relaxed networks will see the distribution as
symmetric and fail to break symmetry. Further, since equivariance is broken, the method is not guaranteed
to behave properly when shown data transformed under the group.
In the case of spontaneous symmetry breaking, there exist some works which partially solve the problem.
Balachandar et al. (2022) design a symmetry detection algorithm and an orientation aware linear layer
for mirror plane symmetries. However, the scope of their methods are specific to mirror symmetries and
point cloud data. Finally, Kaba & Ravanbakhsh (2023) take the approach of defining a relaxed version
of equivariance which takes input symmetry into account. They derive modified constraints linear layers
would need to satisfy for this relaxed equivariance and argue such models can give lower symmetry outputs.
However, they mention these conditions do not reduce as easily as for the usual equivariant linear layers.
Further this method still does not provide a mechanism to sample all possible outputs.
Our work focuses on the spontaneous symmetry breaking case. This case is extremely important as sponta-
neous symmetry breaking occurs in many physical phenomena (Beekman et al., 2019). Hence the widespread
adoption of machine learning techniques for scientific applications will inevitably run into symmetry breaking
issues. Examples of existing applications which may run into difficulties include crystal distortion, predict-
ing ground state solutions from Hamiltonians, and solving PDEs (Jafary-Zadeh et al., 2019; Lewis et al.,
2024; Lino et al., 2022). In the crystal distortion case, there are distortions from high symmetry to low
symmetry structures (Kay & Vousden, 1949). The lowest energy states of physical systems (ground states
of the Hamiltonian) are often low symmetry and famously explains the Higgs mechanism for giving particles
mass (Higgs, 1964). Finally, Karman vortex sheets are a well known example of symmetry breaking in fluid
simulations (Tang & Aubry, 1997).
In this work, we provide the first general solution for the spontaneous symmetry breaking problem in equiv-
ariant networks. We identify that the key difficulty is how to allow equivariant networks to output a set of
valid lower symmetry outputs. Similar to Smidt et al. (2021), we use the natural idea of providing additional
symmetry breaking parameters as input to the model. However, rather than learning these parameters, we
show that we can sample them from a symmetry breaking set (SBS) that we design based only on the input
and output symmetries. In particular, we prove that minimizing the size of the equivariant SBSs is equivalent
to a fundamental group theory question. We emphasize that this fully characterizes how to efficiently break
symmetry with equivariant SBSs for any group. Counter-intuitively, we find that it is sometimes beneficial
to break more symmetry than needed.
The main features of our method are the following:
1.Equivariance: Our framework is fully equivariant. That we can achieve this is a key point of this
work and allows simulation of spontaneous symmetry breaking.
2.Simple to implement: Our approach only requires a designing a set of additional inputs into an
equivariant network. We have fully characterized the design of such sets.
3.Generalizability: We emphasize that our characterization of SBSs applies to any groups.
2Published in Transactions on Machine Learning Research (10/2024)
We would like to point out that to achieve our results, we assume we can detect the symmetry of our input
and outputs. Further, there is the more general problem of treating symmetrically related outputs as the
same in our loss. We discuss these limitations in Appendix D.
The rest of this paper is organized as follows. In Section 2 we formalize the symmetry breaking problem,
the distinction between explicit and spontaneous symmetry breaking, and the type of task performed in the
spontaneous symmetry breaking setting. In Section 3, we examine the case where we break all symmetries
of our input. We motivate the idea of a SBS and show that imposing equivariance leads to an additional
constraint of closure under the normalizer. The intuition is that the normalizer characterizes all orientations
of our data which do not change its symmetry. Next, we translate bounds on the size of the equivariant SBSs
into the purely group theoretical problem of finding complements. We have tabulated these complements
in Appendix F for the point groups. In Section 4, we generalize to the case where we may still share some
symmetries with our input. In Section 5 we describe how to construct SBSs in an actual implementation.
Having fully described our framework, we then highlight how our method relates to prior symmetry breaking
works in Section 6. Finally, in Section 7, we introduce examples of symmetry breaking and demonstrate how
our method works in practice.
Notation and background: An overview of the notation and common symbols used can be found in
Appendix A. A brief overview of mathematical concepts needed in the paper can be found in Appendix B
and an overview of ENNs can be found in Appendix C.
2 Symmetry breaking problem
Here, we make precise what we mean by a symmetry breaking and the issue it poses for equivariant neural
networks. We begin with the following observation first made in Smidt et al. (2021).
Lemma 2.1. LetXandYbe spaces equipped with a group action of G. We can choose an equivariant
f:X→Ysuch thatf(x) =yonly if Stab G(y)≥Stab G(x).
See Appendix E.1 for a generalization of this lemma and a proof.
Hence, the output of an equivariant function must have at least the symmetry of the input. This motivates
the following definition of symmetry breaking at the individual sample level.
Definition 2.2 (Symmetry breaking sample) .LetGbe a group. A sample with input xand output yis
symmetry breaking with respect to GifStab G(y)̸≥Stab G(x).
Lemma 2.1 tells us a symmetry breaking sample with respect to Gcan never be perfectly modeled by a
G-equivariant function. In experimental samples, we may have random noise in our observations of our
outputs which causes samples to be symmetry breaking. In such cases equivariance is beneficial since it
can help remove the noise. However, in some cases we truly have a symmetry breaking sample even with a
perfectmeasurement. Inphysics thisis classified into two cases: explicit symmetry breakingand spontaneous
symmetry breaking. In the following discussion, it is useful to view the underlying model as a set valued
function. A typical function f:X→Ycan be thought of as a set valued function F:X→P (Y)defined
asF(x) ={f(x)}. Note that if there is an action of GonY, one can naturally define an action on P(Y)
such thatU⊆Ytransforms as gU={gu:u∈U}. Hence there is a natural way to define equivariance of
set valued functions.
In explicit symmetry breaking, the underlying physics of the system is asymmetric. For example, there may
be an unknown electric field which breaks rotation symmetry.
Definition 2.3 (Explicit symmetry breaking) .LetGbe a group. A function F:X→P (Y)which is not
G-equivariant explicitly symmetry breaks G.
In such cases using an equivariant function actually prevents us from learning the true function.
In spontaneous symmetry breaking, the underlying physics of the system is symmetric, however there is a
set of stable lower symmetry outputs which are equally likely.
3Published in Transactions on Machine Learning Research (10/2024)
Definition 2.4 (Spontaneous symmetry breaking (SSB) function) .LetGbe a group with actions defined
on spacesX,Y. LetF:X→P(Y)beG-equivariant. We say Fspontaneous symmetry breaks at xif there
is somey∈F(x)such that Stab G(x)>Stab G(y).
Thekeythingsherearethatthesetvaluedfunction Fisequivarianteventhoughindividualobservedsamples
(x,y)fory∈F(x)may be symmetry breaking. Hence, our problem becomes the following.
Problem: How does one create an equivariant architecture which can output a set of possibly lower sym-
metry outputs?
2.1 Examples of explicit and spontaneous symmetry breaking
2.1.1 Double well potential
The double well potential is a classic example of symmetry breaking in physics. Consider a 1-dimensional
energy potential defined as U(x) =x4−2x2+ 1. Note that this system has reflection symmetry about x= 0
since substituting x→−xdoes not change the potential
U(−x) = (−x)4−2(−x)2+ 1 =x4−2x2+ 1 =U(x).
Figure 1: A classic double well potential of x4−2x2+ 1. Clearly this potential has reflection symmetry. The
two minima are x= 1andx=−1.
In physics we often care about finding the ground state solutions which corresponds to the value of x
minimizing any given potential. In the potential above, we see that
U(x) =x4−2x2+ 1 = (x2−1)2= (x−1)2(x+ 1)2
so there two global minima at x=±1. However, individually these minima break reflection symmetry
since 1̸=−1. Hence if our sample consists of input potential U(x)(perhaps encoded using polynomial
coefficients) and output x= 1, then it is a symmetry breaking sample with respect to reflection. Similarly
the input-output pair of U(x),x=−1would also be a symmetry breaking sample.
Note that by Lemma 2.1, a network equivariant to reflection across x= 0would be unable to directly output
the minima. Such a network realizes that 1and−1are symmetric and would return the average of 0.
Perhaps in some cases, we decide to only consider positive solutions. In this case we explicitly break
the reflection symmetry and methods such as finding order parameters and relaxed equivariance learn to
break such symmetry Huang et al. (2023); van der Ouderaa et al. (2022); Smidt et al. (2021); Wang et al.
(2022b; 2023). Since these learned functions are not equivariant, they are explicitly symmetry breaking by
Definition 2.3.
However, in many other cases both solutions are valid. In this case, the set {1,−1}of minima is actually
invariant under reflection but the individual solutions we want are not. We would satisfy Definition 2.4 since
4Published in Transactions on Machine Learning Research (10/2024)
for a set-valued function returning both minima we remain equivariant, while picking either of the individual
minima gives a symmetry breaking sample.
2.1.2 Ferromagnetism
A good physical example of symmetry breaking is ferromagnetism. Individual atoms in such materials have
a magnetic dipole moment and due to strong interaction between neighboring atoms, the moments tend to
align at cool enough temperatures Aharoni (2000). Hence, if we heat and cool a ferromagnetic material, we
obtain regions where the dipole moments of individual atoms align. These regions are known as magnetic
domains. Because the dipoles are aligned, there is a net magnetic moment in the domain which breaks
rotational symmetry.
In the presence of a strong external magnetic field B, the moments of the magnetic domains tend to align
with the external field. This is an example of explicit symmetry breaking since the external field explicitly
breaks rotational symmetry. From the perspective of Definition 2.3 we have a non-equivariant function since
we prefer the direction which aligns with the external field.
However, if there is no external magnetic field, the direction of the magnetic moment in each domain is
uniformly random. This is an example of spontaneous symmetry breaking, the governing laws are symmetric
yet we observe asymmetry in the individual domains. From the perspective of Definition 2.4 we have a set
of vectors in all orientations as valid moments and we do not need to break equivariance. However choosing
a particular moment would give a symmetry breaking sample.
These two cases are depicted in Figure 2.
(a) Explicit symmetry breaking
 (b) Spontaneous symmetry breaking
Figure 2: (a) Example of explicit symmetry breaking. Magnetic moment in domains align with a strong
external magnetic field B. The external field explicitly breaks symmetry of the system. (b) Example
of spontaneous symmetry breaking. Presence of a moment in each domain breaks rotational symmetry.
However, there is no magnetic field so governing laws of the system are symmetric. Consequently the
observed moments are uniformly random in orientation.
3 Fully broken symmetry
First, we consider the case where we break all symmetry of our input. Here, our desired outputs yshare no
symmetry with x. In other words Stab S(y) ={e}. This will lay the foundation for analyzing the general
case of partially broken symmetry. Let the symmetry group of our data xbeS.
5Published in Transactions on Machine Learning Research (10/2024)
3.1 Symmetry breaking set (SBS)
When there is symmetry breaking there are multiple equally valid symmetrically related outputs. The
purpose of a symmetry breaking object is to allow an equivariant network to pick one of them. In principle,
we want all symmetrically related outputs to be equally likely so it makes sense to think of a set Bof
symmetry breaking objects we sample from.
For anys∈Sandb∈B, sincesbis symmetrically related to bit is natural to also include it in B. Hence,
acting with son the elements of Bshould leave the set unchanged. Further, for any b∈B, the stabilizer
Stab S(b)must be trivial since we want to break all symmetries of our input. This is exactly the definition
of a free group action of SonB. Hence, we define a symmetry breaking set as follows.
Definition 3.1 (Symmetry breaking set) .LetSbe a symmetry group. Let Bbe a set of elements which S
acts on. Then Bis a symmetry breaking set (SBS) if the action of SonBis a free action.
3.2 Equivariant SBS
However, the above definition of an SBS is insufficient when considering equivariance. Here, we show that
we need the stronger constraint of closure under the normalizer.
To illustrate the problem, consider a network which is SO(3)equivariant and a triangular prism aligned
so that the triangular faces are parallel to the xyplane. Suppose our task was just to pick a point of the
prism. A naive way to break the symmetry is to have an ordered pair of unit vectors. The first vector is in
thexyplane and points towards one of the triangle vertices. The second vector points up or down in the z
direction, corresponding to the upper or lower triangle.
(a)
 (b)
Figure 3: (a) Naive way to break symmetry in a triangular prism where one vector points to a vertex of a
triangle and a second vector points to the lower or outer triangle. (b) A rotated version of the triangular
prism in. Note that the same symmetry breaking objects now point to edges of the triangle rather than
vertices. However, both prisms have the exact same symmetry elements.
However, consider the same prism but rotated 180◦aroundz. We can check that the symmetry groups are
exactly the same so we want the same SBS. But the symmetry breaking objects are related differently. In
the second prism, the first vector points to an edge rather than a vertex. For equivariance, our symmetry
breaking objects should be related to both prisms in the same way. So our choice of SBS was not equivariant.
Here, one may simply choose a canonical orientation and decide that we will rotate the original SBS by 180◦
in the latter case. However, our input may be arbitrarily complicated, and it may be hard to decide on a
canonicalization. Further, canonicalization may introduce discontinuities. Hence, we would like to construct
SBSs to be only dependent on the symmetry of our data, not how our data is represented. To understand
exactly what additional condition is necessary, we need to carefully investigate how the symmetry breaking
scheme works.
Letfbe ourG-equivariant function and xbe our input data. Suppose we know the symmetry Sof our
input. Let Bbe some set with a group action of Gdefined on it. We would like to obtain our set of
symmetry breaking objects based on just information about the input symmetry. So suppose we have a
functionσ: Sub(G)→P (B)that does so. This function takes in a subgroup symmetry and gives a SBS
composed of elements from B. Then the symmetry breaking step happens when we take a random sample b
6Published in Transactions on Machine Learning Research (10/2024)
Figure 4: Diagram of how we might structure our symmetry breaking scheme. From our data x, we may
obtain its symmetry S. ThisSis then fed into a function σwhich gives us the set of symmetry breaking
objects needed. We sample a bfrom this set breaking the symmetry of our input and feed this balong with
the inputxinto our equivariant function f. Finally we obtain an output ywhich has lower symmetry than
the inputx.
from the SBS. This symmetry breaking object is then fed into our equivariant function, allowing it to break
symmetry. A diagram of this process is shown in Figure 4.
Certainly, since we break the symmetry of our input data, we break equivariance. However, imagine we
give our function all possible symmetry breaking objects and collect at the end the set Yof all outputs our
model gives. This process shown in Figure 5 would then not need to break any symmetry. This is because
all outputs as a set has the same symmetry as the input. Hence we can impose equivariance on our process.
Figure 5: Diagram of how we break symmetry, but now we keep all possible outputs.
It is well known that the composition of equivariant functions remains equivariant. Hence, we just need
to impose equivariance on σ. In order to do so, we must understand how the input and output transform.
Suppose we act on our data with some group element g∈G. Then it becomes gx. SinceSis the symmetry
of our original data, we find gx=gsx= (gsg−1)(gx)for anys∈S. So the symmetry of the transformed
data isgSg−1. Hence, the input of σtransforms as conjugation. Next, recall the output of σis some subset
Bof elements of B. Since there is a group action for Gdefined on B, we can define an action on Bby just
acting on its elements and forming a new set. Figure 6 shows how our procedure would change if it were
equivariant, and we act on our input by some group element g.
Figure 6: Diagram of what happens when we act on the input with some group element g.
7Published in Transactions on Machine Learning Research (10/2024)
We can now clearly see the issue. The input into σtransforms under conjugation, and the stabilizer of a
subgroup under conjugation is precisely the definition of the normalizer NG(S). However, in many cases
NG(S)is a supergroup of S. Therefore by Lemma E.1, our SBS not only needs to be invariant under S, but
also be invariant under NG(S). See Appendix E.2 for a more formal justification.
Hence, we will call a SBS equivariant if it can be the output of an equivariant σ. The intuition above tells
us this amounts to closure under the normalizer NG(S).
Definition 3.2 (Equivariant symmetry breaking sets) .LetSbe a subgroup symmetry of a group GandB
be a set with an action of Gdefined on it. Let B⊂Bbe a SBS. Then BisG-equivariant if∀g∈NG(S)we
haveB=gB.
3.3 Ideal case and complement of normal subgroups
Now that we know how to equivariantly break a symmetry, we would like to understand how to do so
efficiently. Intuitively, we expect a smaller SBS to be better. If we have a larger SBS, multiple symmetry
breaking objects map to the same output so the network needs to learn that these are the same. Reducing
the SBS would decrease the equivalences our network needs to learn. In the ideal case, exactly one symmetry
breaking parameter corresponds to each output. Since our outputs are related by symmetry transformations
(transitive) under S, this corresponds to the equivariant SBS being transitive under S. It turns out, we can
equate constructing ideal equivariant SBSs to the constructing complements of normal subgroups. A slightly
weaker version of this statement can be found in Theorem 3.1.4 of Kurzweil & Stellmacher (2004).
Theorem 3.3. LetGbe a group and Sa subgroup. Let Bbe aG-equivariant SBS for S. Then it is possible
to choose an ideal Bif and only if Shas a complement in NG(S).
Ifbis an element where Stab NG(S)(b)is a complement of SinNG(S), then OrbS(b)is an idealG-equivariant
SBS.
Remark 3.4.It turns out the complement if it exists is isomorphic to NG(S)/S. We can intuitively think of
NG(S)/Sas giving all possible orientations of our data such that its symmetry remains unchanged.
The proof of this theorem is in Appendix E.3. Finding complements of normal subgroups is a well studied
group theory problem Kurzweil & Stellmacher (2004). For the point groups, which are the finite subgroups
ofO(3), we have tabulated the complements if they exist in Appendix F.
The intuition for this theorem comes from the following observation. Essentially equivariant SBSs consist of
orbits ofNG(S). By the orbit-stabilizer theorem, we can reduce the size of an orbit by making an element b
generating the orbit more symmetric. However, bmust still fully break the symmetry of S. The complement,
if it exists, is essentially the maximal symmetry bcan have while still breaking the symmetry of S.
3.4 Nonideal equivariant SBSs
In the case where we cannot achieve an ideal equivariant SBS, we would still like to characterize how efficient
it is. To do this, we define what we call the degeneracy of an equivariant SBS. In general, each orbit under
Sgives us one SBS which can be matched one to one to our outputs.
Definition 3.5 (Degeneracy) .LetBbe aG-equivariant SBS for S. We define the degeneracy to be
DegS(B) =|B/S|.
Note that an ideal equivariant SBS Bideal(if it exists) has exactly 1orbit ofS, soDegS(Bideal) = 1. We
would also like to understand how small we can make the degeneracy if we cannot make it 1. It turns out
Theorem 3.3 allows us to convert this to a group theory problem.
Corollary 3.6. LetGbe a group and Sa subgroup. Let Mbe such that S≤M≤NG(S). LetBbe a
G-equivariant SBS for Swhich is transitive under NG(S). Then it is possible to choose Bsuch that every
S-orbit is also a M-orbit if and only if Shas a complement in M. In particular,
DegS(B)≤|NG(S)/M|.
8Published in Transactions on Machine Learning Research (10/2024)
See Appendix E.4 for a proof. In the ideal case we can make Mto beNG(S)so the above formula gives an
degeneracy of 1as expected.
4 Partially broken symmetry
We can now use our framework for full symmetry breaking to understand the case of partial symmetry
breaking. In this case, our desired output may share some nontrivial subgroup symmetry K≤Swith
our input. Note the case of K=1corresponds to full symmetry breaking and K=Scorresponds to no
symmetry breaking.
4.1 Partial SBS
Similar to the full symmetry breaking case, we would like to create a set of objects which we can use to
break our symmetry. Now we can relax the restriction of free action. Intuitively, we can allow our symmetry
breaking objects to share symmetry with our input, as long as it is lower symmetry than our outputs.
However, the symmetrically related outputs may be invariant under different subgroups of S. Recall that if
some element ygets transformed to sy, its stabilizer Kgets transformed to sKs−1. Hence, the stabilizers
of the outputs are the subgroups conjugate to KunderSdenoted as ClS(K). Based on this intuition, we
can define partial SBS as follows.
Definition 4.1 (Partial SBSs) .LetSbe a symmetry group and Ka subgroup of S. LetPbe a set of
elements with an action by S. ThenPis aK-partial SBS if for any p∈P, there exists some K′∈ClS(K)
such thatK′≥Stab S(p).
Certainly, a full SBS is a partial one as well since the stabilizers of all its elements under Sis the trivial
group. In general, we can always break more symmetry than needed and still obtain our desired output.
However, it is useful to consider the case where we only break the necessary symmetries. Counter-intuitively,
we discuss in Section 4.5 that this turns out to not always be optimal.
Definition 4.2 (Exact partial SBS) .LetSbe a group and Ka subgroup of S. LetPbe aK-partial SBS
forS. We sayPis exact if for all p∈P, we have Stab S(p)∈ClS(K).
4.2 Equivariant partial SBS
Similar to before, we define equivariant partial SBSs. The idea is the same, but now we need to identify the
symmetry of the input and the set of conjugate symmetries for the output. Define
SubCl(G) ={(S,ClS(K)) :S∈Sub(G),K≤S}.
LetPbe a set with a group action of Gdefined on it. As before, the idea is that we have an function
π: SubCl(G)→P (P)which outputs our partial SBS. The condition of equivariance for our partial SBS is
imposing equivariance on π.
Figure 7: Diagram of how we perform partial symmetry breaking. Here, we need to specify not just the
symmetry of our input but also the symmetries of our output. Since any of our outputs are equally valid, it
only makes sense to specify the set of conjugate subgroups ClS(K)our outputs are symmetric under.
9Published in Transactions on Machine Learning Research (10/2024)
The symmetry breaking scheme is depicted in Figure 7. As before, we can impose equivariance on this
diagram. We need to know how ClS(K)transforms. Note that if our input gets acted by g, we expect the
outputs to also get acted by g. SinceKis the stabilizer of one of the outputs, we expect Kto transform to
gKg−1. Hence we have the transformation
ClS(K)→ClgSg−1(gKg−1).
Similar to before, by Lemma E.1 we need the output of πto also be invariant under the stabilizer of the input.
Noting that the normalizer is defined as the stabilizer of Sunder conjugation, we can define a generalized
normalizer as the stabilizer of S,ClS(K).
Figure 8: Diagram of how our symmetry scheme changes when we transform our input by some group
elementg∈G.
Definition 4.3 (Generalized normalizer) .Define the generalized normalizer NG(S,K)to be
NG(S,K) ={g:gKg−1∈ClS(K),g∈NG(S)}.
We can now define equivariant partial SBSs using closure under this generalized normalizer. See Ap-
pendix E.5 for a more formal justification.
Definition 4.4 (Equivariant partial SBSs) .LetSbe a subgroup symmetry of a group G. LetPbe a
K-partial SBS. Then Pbreaks the symmetry G-equivariantly if∀g∈NG(S,K)we haveP=gP.
Note that closure under NG(S,K)is a weaker condition than closure under NG(S). Hence any equivariant
full SBS is also an equivariant K-partial SBS for any K.
4.3 Ideal equivariant partial SBS
Similartothefullsymmetrybreakingcase, weideallywouldliketohaveaonetoonecorrespondencebetween
elements in our equivariant SBS and our symmetrically related outputs. For this to happen, we clearly need
our SBS to be exact and for our SBS to be transitive under S. We can generalize Theorem 3.3 to obtain a
necessary and sufficient condition to have an ideal equivariant partial SBS.
Theorem 4.5. LetGbe a group and SandKbe subgroups K≤S≤G. LetPbe aG-equivariant K-
partial SBS. Then we can choose an ideal P(exact and transitive under S) if and only if NS(K)/Khas a
complement in NNG(S,K)(K)/K.
Ifpis an element such that Stab NG(S,K)(p)/Kis a complement of NS(K)/KinNNG(S,K)(K)/K, then
OrbS(p)is an idealG-equivariant K-partial SBS
See Appendix E.6 for a proof.
4.4 Nonideal equivariant partial SBS
Similar to the full symmetry breaking case, when we cannot achieve an ideal equivariant partial SBS we want
to characterize how efficient our nonideal partial SBS is. Again, the idea is that in the nonideal case, our
network needs to map multiple symmetry breaking objects to the same output. We define the degeneracy
ofPto quantify this multiplicity.
10Published in Transactions on Machine Learning Research (10/2024)
Definition 4.6 (Degeneracy) .LetGbe a group, Sbe a subgroup, and Ka subgroup of S. LetPbe a
G-equivariant K-partial SBS for S. LetTbe a transversal of S/K. LetPtbe such that every p∈Pis
uniquely written as p=tptfor somet∈Tandpt∈Pt. Then we define
DegS,K(P) =|Pt|.
The intuition for this definition is that Ptis the set of objects which together with our input may get mapped
to some output yby our equivariant network. In other words, we have f(x,Pt) ={y}for equivariant fand
all otherPget mapped to different symmetrically related outputs. Without loss of generality assume yhas
Stab S(y) =K. Then for any symmetrically related output ty(wheret∈T), we can see from equivariance
offthatf(x,tP t) ={ty}. It is now clear that the size of Ptcounts how many symmetry breaking objects
must be mapped to the same output.
Note that in the case K=1,S/K =SsoPtjust consists of representatives from P/S. So this reduces to
the degeneracy defined for full SBS. Also, note that in the ideal case, there is exactly one symmetry breaking
object for each output. So degeneracy is 1in that case.
We would like to derive bounds on the degeneracy of our equivariant partial SBSs. Similar to the full SBS
case, we use Theorem 4.5 to convert this into a group theory question.
Corollary 4.7. LetGbe a group, Sa subgroup, and Ka subgroup of S. LetK′be a subgroup of KandM
a subgroup of NG(S,K)∩NG(S,K′)which contains S. SupposePis aG-equivariant K-partial SBS for S
which is transitive under NG(S,K). We can choose Psuch that Stab S(p)∈ClNG(S,K)(K′)for allpand all
S-orbits inPare alsoM-orbits if and only if NS(K′)/K′has a complement in NM(K′)/K′. Further, such
aPhas
DegS,K(P)≤|K/K′|·|NG(S,K)/M|.
See Appendix E.7 for a proof.
4.5 Optimality of exact partial symmetry breaking
Note that in the previous section, we have been very careful to allow our partial SBS to break more symmetry
thanneeded. Intuitively, wewouldliketosaythatitisalwaysoptimaltobreakdownexactlytothesymmetry
of our output. That is, we only need to consider exact partial SBSs.
Certainly, ignoring any equivariance constraints, given any non-exact K-partial SBS, we can construct an
exactK-partial SBS by picking an element bwith Stab S(b)≤Kand identifying its orbit under Ktogether
as one partial symmetry breaking object p=Kb. We construct the orbit of punder action by Sas our
K-partial SBS.
We might expect that some modification of this construction can convert any non-exact equivariant K-
partial SBS into an exact equivariant K-partial symmetry breaking one. Naively, we just take the orbit of
the elements in the construction above under NG(S,K)to obtainG-equivariance. However, in Appendix G
we come up with an explicit example where no exact equivariant K-partial SBS is smaller than the best
equivariant full SBS.
5 Constructing SBSs
Now that we have fully characterized what equivariant symmetry breaking sets are, we show how to construct
them. We focus on G=O(3)in this section though the ideas here are applicable for other groups as well.
5.1 Expressing subgroups
First, it is important to have a way of expressing subgroup of G, the group we want to be equivariant under.
The subgroups of O(3)are well studied and have been completely classified Hahn et al. (1983). In particular,
11Published in Transactions on Machine Learning Research (10/2024)
there are 7 infinite axial families of finite point groups and 7 additional finite ones. There are only 5 infinite
subgroups which are closed. However, the names of these subgroups do not specify how they are “oriented"
inO(3). Hence, we propose to represent the subgroups in the following way. We first choose a canonical
orientation of the classified point groups.
Figure 9: Two identical triangular prisms differing by a rotation. Both have symmetry D6hby name, however
the actual symmetry axes differ.
A standard choice is inspired by the Hermann-Mauguin naming scheme for point groups. For the 7 infinite
series of axial groups, we choose to align the high order symmetry axis along the z-axis. If in addition there
are 2-fold rotations, we choose one of them to be along the x-axis. If there are no 2-fold rotations but there
are mirror plane parallel to the z-axis, we choose the yz-plane to be in the group. Of the remaining 7 point
groups, 5 are cubic groups. For these we can choose the cube they leave invariant to have sides perpendicular
to one of the x,y,zaxes. Finally, the remaining 2 point groups are the icosahedral groups with and without
inversion. For these we can choose to align a 5-fold axis with the z-axis and a 3-fold axis with the x-axis.
Next, for any point group Swith arbitrary alignment, there is always some g∈O(3)(in fact we can always
pickg∈SO(3)) such that g−1Sgbrings it to the canonical orientations defined above. Hence, we can always
express an arbitrary point group Sas a pairg,name (S)of a rotation and the name of the group.
To generalize to arbitrary groups, we note that the point groups classify the classes of conjugate subgroups
ClO(3)(S)ofO(3). Hence for general G, we need to classify the corresponding classes of conjugate subgroups
ClG(S)and choose a canonical representative for each class in order to apply scheme outlined in this section.
5.2 Representing a set of conjugate subgroups
In the partial symnmetry breaking case, we also provide a set of conjugate subgroups. Similar to our notation
ClS(K), we can specify a set of conjugate subgroups with (S,K), where subgroups SandKare represented
in the way described previously.
5.3 Representing a SBS
The idea is very simple. We start with some object which breaks enough symmetry for our task. To satisfy
the equivariance condition of closure under the normalizer or generalized normalized, we can simply take the
orbit as our SBS or partial SBS. In principle a SBS can consist of multiple such orbits, but we can always
only use one orbit as a SBS and multiple orbits increase the degeneracy. Hence we assume all our SBSs
consist of one orbit and we can fully specify a SBS as a pair (b,N)wherebis a symmetry breaking object
andNis a group over which we take the orbit of b.
In the case of finite group N, we can explicitly compute the elements in the orbit. However, if Nis infinite
then this does not work. In practice, it is usually enough that we can sample lower symmetry outputs.
Hence, it suffices to be able to sample the SBS which we can do by sampling an element from N.
5.4 Constructing an equivariant full SBS
We would like to construct a full SBS given an input symmetry S= (g,name (S)). However, we want to do
so in an equivariant way. One way to achieve this is to first consider only any input group in its canonical
orientation and construct a SBS Bfor it. Then simply returning gBwould guarantee that our construction
12Published in Transactions on Machine Learning Research (10/2024)
is equivariant. Hence, we just need to construct a canonical SBS for each possible point group. Note that
this can be viewed as a case of equivariance by canonicalization Kaba et al. (2023).
Note an equivariant full SBS needs closure under a normalizer. If we work with O(3)equivariance, we simply
look up the normalizer NO(3)(S)from Table 4. If we are equivariant under some subgroup G⊂O(3)then
we note that NG(S) =NO(3)(S)∩Gwhich can be used to compute the desired normalizer. All that remains
is how to specify a canonical symmetry breaking object for each point group in canonical orientation. If
we have such an object, then we obtain the following algorithm for creating equivariant full SBSs. Let
Normalizers be a function which takes in a name of a point group and gives the corresponding normalizer
classified in Table 4.
Algorithm 1 Equivariant full SBS
Input
S Symmetry of input expressed as pair (g,name (S))
b Canonical symmetry breaking object
Output
B Symmetry breaking set expressed as a pair (b′,N)
(n,name (NO(3)(S)))←Normalizers [name (S)]
N←(gn,name (NO(3)(S)))
return (gb,N )
In general, the choice of a canonical symmetry breaking object is flexible. To satisfy the definition, one just
needs the corresponding object for name (S)to not share any symmetries with S= (e,name (S)). However,
as discussed in Section 3.3, an ideal SBS should be more efficient than a nonideal one. Hence, if possible
we would like to pick such an object so that it generates an ideal SBS. Theorem 3.3 tells us exactly the
conditions needed to choose an ideal SBS. In particular, we would need the additional condition that bhave
the symmetry of a complement Hwhile not having the symmetry of S. We fully characterized the relevant
cases in Appendix F.
5.5 Constructing equivariant partial SBS
In the partial symmetry breaking case, we want to obtain a partial SBS from the symmetry of the input
and the set of conjugate subgroup symmetries of the outputs. Importantly, note that we want closure under
NG(S,K)rather than under NG(S). To compute NG(S,K), we use the following fact.
Lemma 5.1. We have the following formula
NG(S,K) =S(NG(S)∩NG(K)).
See Appendix E.8 for a proof.
Thus we get the following algorithm for computing an equivariant partial SBS.
We emphasize that for any K′<K, aK′-partial SBS can also serve as a K-partial SBS since we can always
break more symmetry than needed. In particular, a full SBS often suffices for simplicity.
Similar to the full SBS case, we have flexibility in choosing our canonical object used to generate the partial
SBS. To satisfy the definition, all we need is for Stab G(p)≤K′for someK′∈ClS(K). An ideal partial SBS
is desirable, especially if we wish to ensure we do not break any extra symmetry. The condition given by
Theorem 4.5 is more complicated. However, if we have a FindComplement function, we can automate the
processoffindingasymmetryanobjectwhichgeneratesanidealpartialSBSshouldhave. Here, let Quotient
be a function which returns a quotient group and a mapping from cosets to elements of the quotient group.
We have the following algorithm which returns a pair of subgroups (H,K )such that if phasH≤Stab O(3)(p)
andStab S(p) =Kthenpgenerates an ideal partial SBS.
13Published in Transactions on Machine Learning Research (10/2024)
Algorithm 2 Equivariant partial SBS from object
Input
S Symmetry of input expressed as pair (gS,name (S))
ClS(K)Set of conjugate subgroups expressed as (S,K) = ((gS,name (S)),(gK,name (K)))
p Canonical partial symmetry breaking object
Output
P Symmetry breaking set expressed as a pair (p′,N)
N1←Normalizers [name (S)]
(n,name (N2))←Normalizers [name (K)]
N2←(g−1
SgKn,name (N2))
N←N1∩N2
N←(e,name (S))N
N←gSNg−1
S
return (gSp,N)
Algorithm 3 Ideal partial SBS generating object symmetry
Input
S Symmetry of input expressed as pair (gS,name (S))
ClS(K)Set of conjugate subgroups expressed as (S,K) = ((gS,name (S)),(gK,name (K)))
Output
H Symmetry needed for object pto generate ideal partial SBS
N1←Normalizers [name (S)]
(n,name (N2))←Normalizers [name (K)]
N2←(g−1
SgKn,name (N2))
N←N1∩N2
N′←(e,name (S))∩N2
(Q1,ϕ)←Quotient [N,(g−1
SgK,K)]
Q2←ϕ(N′)
C←FindComplement [Q1,Q2]
ifCexiststhen
(h,name (H))←ϕ−1(C)
return ((gSh,name (H)),K)
else
returnNone
end if
14Published in Transactions on Machine Learning Research (10/2024)
5.6 Using a symmetry breaking object
In general, one has the freedom to decide how to incorporate a symmetry breaking object into their model.
Thisisoftendependentonwhichequivariantarchitectureweapplyourframeworktoandinfluencesthechoice
of a canonical symmetry breaking object. For example, if we consider images and rotational symmetry, one
natural choice isto add an additional imagechannel for the symmetry breaking object. In this case onewould
naturally choose to use an asymmetric image as the canonical symmetry breaking object. In the experiments
section, we apply our framework to equivariant message passing graph neural networks (GNNs). In that case
we can insert the symmetry breaking object as an additional node feature and specify the representation it
transforms as.
6 Relation to other works
Having fully described our framework, it is useful to briefly discuss how our method relates to existing
symmetry breaking works.
6.1 Adaption of explicit symmetry breaking methods
In Smidt et al. (2021), an additional symmetry breaking object is learned from the data. Similarly in relaxed
equivariant networks, we learn additional nontrivial weights which we can often interpret as an additional
symmetry breaking object (Huang et al., 2023; van der Ouderaa et al., 2022; Wang et al., 2022a;b; 2023). It
is therefore natural to ask how these learned symmetry breaking objects relate to our framework.
In the case where we apply the method of Smidt et al. (2021) to a single symmetry breaking sample x,y, then
we obtain some additional input bwhich lets an equivariant model output ywhen given input x. As long as
there is an action of Gon the learned symmetry breaking object b, we can adapt it to form an equivariant
SBS by taking an orbit under NG(S)(or onlyNG(S,K)). In fact with a suitable group transformation we
may simply adopt them as canonical symmetry breaking objects for Algorithms 1 and 2.
However, these learned symmetry breaking objects will in general not generate an ideal SBS. The procedure
of Smidt et al. (2021) uses gradients of a G-invariant loss. Since the loss depends on both x,y, we can view
the obtained symmetry breaking object as coming from some G-equivariant function b=h(x,y). Hence,b
will have the symmetry of Stab G(x)∩Stab G(y)which is why it can help our equivariant model break the
symmetry of input x. In fact, this means that we always will obtain an exact SBS in the partial symmetry
breaking case. However, our Theorem 3.3 and 4.5 tells us bmay need additional symmetry to generate an
ideal SBS which Smidt et al. (2021) does not guarantee.
6.2 Relation to spontaneous symmetry breaking methods
In the work of Balachandar et al. (2022), symmetry breaking is done through introducing nonequivariant
components in their architecture. In particular, their symmetry detection algorithm generates a vector
perpendicular to the mirror plane and hence can be modified to construct a SBS by taking positive and
negative values of the vector.
The framework outlined by Kaba & Ravanbakhsh (2023) advocates for a notion of relaxed equivariance
where rather than f(gx) =gf(x)we instead just have f(gx) =g′f(x)for someg′∈gStab G(x) =gS. In
Definition 2.4, we argue we should consider a set-valued function F:X→Yand impose equivariance for
group action on the set. By restricting to a specific member of the output set, we would obtain a function
f:X→Yso thatf(x)∈F(x). It is not hard to show that such an fsatisfies the relaxed equivariance
of Kaba & Ravanbakhsh (2023). This can be implemented by modifying Algorithm 1 so we pick a specific
b∈Brather than returning the entire SBS B.
Finally, a natural attempt for breaking symmetry is simply noise injection (Liu et al., 2019; Locatello et al.,
2020). Noise which is isotropic with respect to group Gcan be viewed as a SBS, however, we expect our
network would need to learn to map multiple (possibly infinite) input, noise pairs to the same output.
A motivation of our work is that by using knowledge of input and output symmetry, we can reduce this
15Published in Transactions on Machine Learning Research (10/2024)
degeneracy and we characterize exactly how to analyze this with Corollaries 3.6 and 4.7. In many cases, we
can even have the ideal degeneracy of 1. However, we would like to point out that our theoretical results
also let us prove we sometimes cannot do better than noise. For example, we can use Theorem F.1 and
Corollary 3.6 to show that for G=SO(2), any full symmetry breaking scheme using only input symmetry
must have infinite degeneracy.
7 Experiments
Here, we provide some example tasks where we apply our framework of full symmetry breaking and partial
symmetry breaking to an equivariant message passing GNN. We consider the cases where we can find an
ideal equivariant SBS or partial SBS. This section serves primarily as a proof of concept for how our approach
works in practice. Note that while these examples only have a single type of input in training for simplicity,
this is by no means a restriction of our framework. In general one simply uses the given symmetry of the
inputs and outputs in partial symmetry breaking in addition to the algorithms from Section 5 to choose
what specific symmetry breaking object to use. This lets us work with multiple types of inputs and input
symmetries with the same model.
7.1 Full symmetry breaking: triangular prism
7.1.1 Task
For an example of full symmetry breaking, we consider the task of picking a vertex of a triangular prism,
similar to that described in Section 3.2.
Input:Graph with 6 nodes with edges given by the edges of the prism and position features at the nodes
corresponding to the positions of the vertices. We add an additional pseudoscalar feature of magnitude 1.
Input symmetry: The prism with only the position features has D3hsymmetry, but the addition of
pseudoscalar features reduces this to D3symmetry.
Output: Vector which points from the center of the prism to one of the vertices. Note that there is a set of
equally valid outputs.
Output symmetry: Nonzero vectors have C∞vsymmetry where the high symmetry axis is aligned along
the vector.
We note that the there is no shared symmetry between the output and input if we include the pseudoscalar
feature on the prism. Hence, this is an example of a full symmetry breaking task. Further, this is a
spontaneous symmetry breaking task because as we rotate the prism, the set of valid vectors rotate as well.
7.1.2 Architecture
We apply our framework to the default equivariant message passing GNN implemented in the e3nnpytorch
library Geiger & Smidt (2022). Each layer consists of the equivariant 3D steerable convolutions followed by
gatednonlinearitiesdescribedinWeileretal.(2018). Nodefeaturesinthisnetworkareseparatedinto3types,
position features, node features, and node attributes. The position features are used for point convolutions
and node attributes are permanent features which remain through all message layers. Naturally, we input
the positions of the prism vertices as position features. We input the pseudoscalar feature as a shared node
attribute for all vertices. Similarly, to implement the input of a symmetry breaking object, we also add it
as a shared node attribute for all vertices.
We speicify the irreps of the hidden features in our model up to l= 2of both parities and use up to l= 4
spherical harmonics for point convolution filters. Further for the radial network, we use a 3 layer fully
connected network with 16 hidden features in each layer. In the final layer, we specify a odd node l= 1
(vector) feature. We take the sum of the final output vectors as the model output.
16Published in Transactions on Machine Learning Research (10/2024)
7.1.3 Symmetry breaking set
In this case, it turns out one can set the vector (√
3/2,1/2,0)as a canonical symmetry breaking object and it
will generate an ideal SBS. See Appendix H.1.1 for details on why this choice works. Following Algorithm 1,
we see that we will obtain a set of unit vectors parallel to an edge of the triangular faces of the prism as our
SBS.
7.1.4 Results
(a)
 (b)
Figure 10: (a) Output (red) generated by our model and symmetry breaking object (blue) given. (b) The
set of all the outputs generated by our model if we feed in all symmetry breaking objects.
Since our framework is equivariant, we fix the orientation of the prism in training.
We first fix a choice of one symmetry breaking object from our equivariant SBS and one of the vertices of the
triangular prism. We then give the chosen symmetry breaking object as the additional input to our model
and train the model to match the vector from the center of the prism to the chosen vertex using MSE loss.
An example of the result of this training is shown in Figure 10a. We also observe that no matter which pair
of vertex and symmetry breaking object we pick, our equivariant network is able to learn the vector pointing
that that vertex. In practice, this means that we can match any of our symmetry breaking objects with a
single observed output.
Once trained on one pair of symmetry breaking object and vertex, the equivariance of our GNN means that
inputting the other symmetry breaking objects in our SBS gives the other symmetrically related outputs.
This is shown in Figure 10b.
Further, rather than picking one vertex, we also tried modifying our loss so that we compute the MSE loss
for all choices of vertex and take the minimum. Hence, our network can learn which vertex to pair with
each symmetry breaking object. In this prism example, our pairing is random. This method of taking the
minimum loss is especially useful when we have multiple instances of symmetry breaking in our data.
Finally, in Appendix H.1.2 we demonstrate that a non-equivariant SBS fails as described in Section 3.2 and
in Appendix H.1.3 we demonstrate the degeneracy of nonideal SBS compared to an ideal one as described
in Section 3.4.
17Published in Transactions on Machine Learning Research (10/2024)
7.2 Partial symmetry breaking: octagon to rectangle
7.2.1 Task
For an example of partial symmetry breaking, we consider the task of deforming an octagon to a rectangle.
Input:Graph with 8 nodes with edges corresponding to the edges of the octagon and position features at
nodes corresponding to positions of the vertices. We add an additional pseudoscalar feature of magnitude 1.
Input symmetry: The octagon with only the position features has D8hsymmetry, but the addition of
pseudoscalar features reduces this to D8symmetry.
Output: Graph with 8 nodes with edges corresponding to the edges of the octagon and position features
at nodes corresponding to new positions of the vertices. The positions are such that 4 of the vertices which
form the shape of a rectangle remain unchanged and the remaining 4 vertices are shifted so their positions
coincide with the nearest of the 4 vertices. Note that there is a set of equally valid outputs.
Output symmetry: Output graph has D2hsymmetry.
We note that the shared symmetry between the input and output is D2compared to the D8symmetry of
the input. Hence, we may apply our partial SBS framework here. The reason for forcing D8symmetry by
adding chirality is to demonstrate that each step in Algorithm 3 in general is a nontrivial operation.
7.2.2 Architecture
WeusethesamedefaultequivariantmessagepassingGNNimplementedasfortheprismcase. Thesymmetry
breakingobjectisadifferenttypeofrepresentation, sowespecifydifferentirrepsforthesharednodeattribute
for all vertices to input the symmetry breaking object. In addition, we keep the final output irreps as a
vector at all nodes, but rather than averaging them, we now interpret them as a displacement to generate
new positions for the distorted octagon.
7.2.3 Symmetry breaking set
In this case, choosing (0,0,1,0,0)for al= 2irrep as a canonical partial symmetry breaking object generates
an ideal partial symmetry breaking set. See Appendix H.2.1 The resulting SBS from Algorithm 2 is the set
ofl= 2harmonics “parallel” to the edges of the octagon.
7.2.4 Results
Similar to the prism case, we try training by matching a specific symmetry breaking object to a rectangle
distortion. When the symmetry breaking object and rectangle are compatible (share the same symmetries),
thenourmodelhasnoproblemlearningtodeformtheoctagonintotherectangle. ThisisshowninFigures11a
and 11b. An interesting failure case occurs when we try to match a symmetry breaking object and rectangle
with incompatible symmetries. This is shown in Figure 11c. Here, the D2symmetry of the rectangle and of
the symmetry breaking object are misaligned. As a result, our model predicts an output which has symmetry
ofD4which is the group generated when we include the symmetry elements of both the target rectangle
and the symmetry breaking object. Hence, the resulting shape is a square.
As with the triangular prism case, we also tried letting the model choose which rectangle to deform to given
a symmetry breaking object. In this case, our model computes loss separately for all 4 possible rectangle
distortions and takes the minimum. We note that for a given symmetry breaking object, 2 of the possible
rectangles are symmetrically compatible while 2 are not. Over 200 random initializations, we find roughly
30%of the time our model attempts to match symmetrically incompatible symmetry breaking objects to a
rectangle. This is better than the 50%we would expect if it matches pairs randomly.
18Published in Transactions on Machine Learning Research (10/2024)
(a)
 (b)
(c)
Figure 11: (a) Output (blue) of our model when we match a symmetry breaking object with a compatible
rectangle. (b) Output (blue) of our model when we match a symmetry breaking object with a different
compatible rectangle. (c) Output (blue) when we match a symmetry breaking object with an incompatible
rectangle (green). Note the square has symmetries of both the symmetry breaking object and the target
rectangle.
7.3 BaTiO 3phase transitions
7.3.1 Task
Finally, we demonstrate our framework on a more realistic example. For this, we examine the crystal
structure of barium titanate (BaTiO 3). Specifically, as we decrease temperature, there is a phase transition
from a high space-group symmetry Pm¯3mstate to a lower space-group symmetry P4mmstate at 403K Kay
& Vousden (1949); Oliveira et al. (2020); Woodward (1997). The high and low symmetry states are shown
in Figures 12a and 12b respectively. Note that the real distortions are rather small and hard to see visually.
Table 1 provides some numerical quantities which help distinguish the two. In particular, there are 3 distinct
Ti-O-Ti bond angles in a primitive cell, 2 of which are distorted equally to 171.80◦in the low symmetry
structure. This bent angle is shown more clearly in the schematic in Figure 12b.
Input:Graph with 5 nodes corresponding to the atoms in a primitive cell of BaTiO 3. We have position
features corresponding to the positions of the atoms in the cell. We fix the unit cell to be a cube with sides
4Å, close to the size of the real cells.
Input symmetry: The high symmetry structure has a space group symmetry of Pm¯3m. Ignoring trans-
lational symmetries, this corresponds to Ohpoint group symmetry (denoted as m¯3min Hermann-Maugin
notation). Note the symmetry is already listed in the materials project database Jain et al. (2013).
Output: Graph with 5 nodes corresponding to the atoms in a primitive of BaTiO 3. We have position
features corresponding to the positions of the atoms in the cell. We fix the unit cell to be a cube with sides
4Å, close to the size of the real cells.
Output symmetry: The high symmetry structure has a space group symmetry of P4mm. Ignoring
translational symmetries, this corrsponds to C4vpoint group symmetry (denoted as 4mmin Hermann-
Maugin notation). Note the symmetry is already listed in the materials project database Jain et al. (2013).
The input and output share D4hsymmetry compared to the Ohsymmetry of the input. Hence may apply
our partial symmetry breaking framework here.
19Published in Transactions on Machine Learning Research (10/2024)
(a)
(b)
Figure 12: (a) Initial high symmetry crystal structure of BaTiO 3. Left is an actual plot of the crystal
structure and right is a side-on schematic. (b) Target low symmetry crystal structure of BaTiO 3. Left is an
actual plot of the distorted crystal structure and right is a side-on schematic with exaggerated distortion.
The angle of the bent bond is 171.80◦.
7.3.2 Architecture
We use the same default equivariant message passing GNN implemented as for the previous examples. Here,
we also input atom type as an additional node feature using one hot encoding. Similar to the octagon
example, have vector features at each node as output and interpret it as the displacement to generate the
distorted structure. We can choose a SBS consisting of a single vector so we have an additional vector as
node attribute to input a symmetry breaking object. Finally, since crystals are periodic, we modified the
network to include periodicity when computing relative displacement vectors.
20Published in Transactions on Machine Learning Research (10/2024)
7.3.3 Symmetry breaking set
Note thatOhhas itself as normalizer in O(3)so the symmetry completely determines orientation. Hence
any object sharing C4vsymmetry works for generating an ideal equivariant partial SBS. A simple choice
consists of vectors (odd parity l= 1object) pointing along the 4-fold rotation axes.
7.3.4 Results
As shown in Figure 13 and Table 1, our model is able to learn to distort the crystal structure appropriately
when given an appropriate symmetry breaking object. Without such an input the model cannot provide any
distortions. In additional, we computed some additional invariant quantities of the crystal structures and
we see that these invariants for the output structure of the model with a SB object matches the invariants
for the target lower symmetry structure.
Figure 13: Distorted crystal structure generated by our model when given a symmetry breaking object shown
on the right in blue.
Table 1: Values of various quantities which help distinguish the high symmetry and low symmetry structures.
Our models here try to distort the high symmetry structure to the low symmetry one.
Structure Bond length average Bond length variance Ti-O-Ti
High symmetry 2 0 180◦
Low symmetry 2.003417 0.01392 171.80◦
Model (no SBS) 2 0 180◦
Model (SB object (1,0,0)) 2.003417 0.01392 171.80◦
8 Conclusion
We formalize the problem equivariant neural networks face in the spontaneous symmetry breaking setting.
We propose the idea of equivariant symmetry breaking sets which allows ENNs to sample or generate
all possible symmetrically related outputs given a highly symmetric input. Importantly, we show that
minimizing these sets is intimately connected to a well studied group theory problem, and tabulate solutions
for the ideal case for the point groups. We then demonstrate how our symmetry breaking framework works
in practice on example problems.
21Published in Transactions on Machine Learning Research (10/2024)
One future direction is to include translations and tabulate complements for the space groups in their re-
spective normalizers. This would be particularly useful for crystallography applications. Another direction
is to automate finding stabilizers for partial symmetry breaking objects. In addition, our method assumes
we can efficiently detect the symmetry of our input and outputs. Designing fast symmetry detection algo-
rithms would also be extremely beneficial. Finally, designing efficient loss functions which do not punish
symmetrically related outputs would be useful for any network dealing with spontaneous symmetry breaking.
Acknowledgments
WethankthehelpfuldiscussionswithRobinWalters, ElyssaHofgard, andRuiWangforframingthedifferent
types of symmetry breaking.
YuQingXie was supported by theMIT College of Computingfellowship and the NationalScience Foundation
Graduate Research Fellowship under Grant No. DGE-1745302. Tess Smidt was supported by DOE ICDI
grant DE-SC0022215.
References
Amikam Aharoni. Introduction to the Theory of Ferromagnetism , volume 109. Clarendon Press, 2000.
Sidhika Balachandar, Adrien Poulenard, Congyue Deng, and Leonidas Guibas. Breaking the symmetry:
Resolving symmetry ambiguities in equivariant neural networks. In NeurIPS 2022 Workshop on Symmetry
and Geometry in Neural Representations , 2022.
Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Ortner, and Gábor Csányi. Mace: Higher or-
der equivariant message passing neural networks for fast and accurate force fields. Advances in Neural
Information Processing Systems , 35:11423–11436, 2022.
Simon Batzner, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P Mailoa, Mordechai Kornbluth,
Nicola Molinari, Tess E Smidt, and Boris Kozinsky. E (3)-equivariant graph neural networks for data-
efficient and accurate interatomic potentials. Nature communications , 13(1):2453, 2022.
AronBeekman,LoukRademaker,andJaspervanWezel. Anintroductiontospontaneoussymmetrybreaking.
SciPost Physics Lecture Notes , pp. 011, 2019.
Martin Bokeloh, Alexander Berner, Michael Wand, H-P Seidel, and Andreas Schilling. Symmetry detection
using feature lines. In Computer Graphics Forum , volume 28, pp. 697–706. Wiley Online Library, 2009.
Elena Castellani et al. On the meaning of symmetry breaking. Symmetries in physics: Philosophical reflec-
tions, pp. 321–334, 2003.
Taco Cohen and Max Welling. Group equivariant convolutional networks. In International conference on
machine learning , pp. 2990–2999. PMLR, 2016a.
Taco S Cohen and Max Welling. Steerable cnns. In International Conference on Learning Representations ,
2016b.
Taco S Cohen, Mario Geiger, Jonas Köhler, and Max Welling. Spherical cnns. In International Conference
on Learning Representations , 2018.
Taco S Cohen, Mario Geiger, and Maurice Weiler. A general theory of equivariant cnns on homogeneous
spaces.Advances in neural information processing systems , 32, 2019.
David F Crouse. On implementing 2d rectangular assignment algorithms. IEEE Transactions on Aerospace
and Electronic Systems , 52(4):1679–1696, 2016.
Ameya Daigavane, Song Kim, Mario Geiger, and Tess Smidt. Symphony: Symmetry-equivariant point-
centered spherical harmonics for molecule generation. arXiv preprint arXiv:2311.16199 , 2023.
22Published in Transactions on Machine Learning Research (10/2024)
Mildred S Dresselhaus, Gene Dresselhaus, and Ado Jorio. Group theory: application to the physics of
condensed matter . Springer Science & Business Media, 2007.
David Steven Dummit and Richard M Foote. Abstract algebra , volume 3. Wiley Hoboken, 2004.
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolutional neural
networks for equivariance to lie groups on arbitrary continuous data. In Proceedings of the 37th Interna-
tional Conference on Machine Learning , pp. 3165–3176, 2020.
Octavian-Eugen Ganea, Xinyuan Huang, Charlotte Bunne, Yatao Bian, Regina Barzilay, Tommi S Jaakkola,
and Andreas Krause. Independent se (3)-equivariant models for end-to-end rigid protein docking. In
International Conference on Learning Representations , 2021.
GAP.GAP – Groups, Algorithms, and Programming, Version 4.12.2 . The GAP Group, 2022. URL
https://www.gap-system.org .
Mario Geiger and Tess Smidt. e3nn: Euclidean neural networks. arXiv preprint arXiv:2207.09453 , 2022.
Theo Hahn, Uri Shmueli, and JC Wilson Arthur. International tables for crystallography , volume 1. Reidel
Dordrecht, 1983.
Allen Hatcher. Algebraic Topology . Cambridge University Press, 2002.
Peter W Higgs. Broken symmetries and the masses of gauge bosons. Physical review letters , 13(16):508,
1964.
Emiel Hoogeboom, Vıctor Garcia Satorras, Clément Vignac, and Max Welling. Equivariant diffusion for
molecule generation in 3d. In International conference on machine learning , pp. 8867–8887. PMLR, 2022.
Ningyuan Teresa Huang, Ron Levie, and Soledad Villar. Approximately equivariant graph networks. In
Thirty-seventh Conference on Neural Information Processing Systems , 2023.
Mehdi Jafary-Zadeh, Khoong Hong Khoo, Robert Laskowski, Paulo S Branicio, and Alexander V Shapeev.
Applying a machine learning interatomic potential to unravel the effects of local lattice distortion on the
elastic properties of multi-principal element alloys. Journal of Alloys and Compounds , 803:1054–1062,
2019.
Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson Richards, Stephen Dacek,
Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand Ceder, et al. Commentary: The materials project:
A materials genome approach to accelerating materials innovation. APL materials , 1(1), 2013.
Weile Jia, Han Wang, Mohan Chen, Denghui Lu, Lin Lin, Roberto Car, E Weinan, and Linfeng Zhang.
Pushing the limit of molecular dynamics with ab initio accuracy to 100 million atoms with machine
learning. In SC20: International conference for high performance computing, networking, storage and
analysis, pp. 1–14. IEEE, 2020.
John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn
Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure
prediction with alphafold. Nature, 596(7873):583–589, 2021.
Sékou-Oumar Kaba and Siamak Ravanbakhsh. Symmetry breaking and equivariant neural networks. In
NeurIPS 2023 Workshop on Symmetry and Geometry in Neural Representations , 2023.
Sékou-Oumar Kaba, Arnab Kumar Mondal, Yan Zhang, Yoshua Bengio, and Siamak Ravanbakhsh. Equiv-
ariance with learned canonicalization functions. In International Conference on Machine Learning , pp.
15546–15566. PMLR, 2023.
Herbert Frederick Kay and P Vousden. Xcv. symmetry changes in barium titanate at low temperatures and
their relation to its ferroelectric properties. The London, Edinburgh, and Dublin Philosophical Magazine
and Journal of Science , 40(309):1019–1040, 1949.
23Published in Transactions on Machine Learning Research (10/2024)
Yosi Keller and Yoel Shkolnisky. An algebraic approach to symmetry detection. In ICPR (3) , pp. 186–189,
2004.
E Koch and W Fischer. Normalizers of point groups. International Tables for Crystallography , pp. 904–905,
2006.
RisiKondorandShubhenduTrivedi. Onthegeneralizationofequivarianceandconvolutioninneuralnetworks
totheactionofcompactgroups. In International Conference on Machine Learning , pp.2747–2755.PMLR,
2018.
Hans Kurzweil and Bernd Stellmacher. The theory of finite groups: an introduction , volume 1. Springer,
2004.
R Jeffrey Largent, William F Polik, and JR Schmidt. Symmetrizer: algorithmic determination of point
groups in nearly symmetric molecules. Journal of Computational Chemistry , 33(19):1637–1642, 2012.
LauraLewis, Hsin-YuanHuang, VietTTran, SebastianLehner, RichardKueng, andJohnPreskill. Improved
machinelearningalgorithmforpredictinggroundstateproperties. nature communications ,15(1):895,2024.
Yi-Lun Liao and Tess Smidt. Equiformer: Equivariant graph attention transformer for 3d atomistic graphs.
InThe Eleventh International Conference on Learning Representations , 2022.
Mario Lino, Stathi Fotiadis, Anil A Bharath, and Chris D Cantwell. Multi-scale rotation-equivariant graph
neural networks for unsteady eulerian fluid dynamics. Physics of Fluids , 34(8), 2022.
Jenny Liu, Aviral Kumar, Jimmy Ba, Jamie Kiros, and Kevin Swersky. Graph normalizing flows. Advances
in Neural Information Processing Systems , 32, 2019.
Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob
Uszkoreit, Alexey Dosovitskiy, and Thomas Kipf. Object-centric learning with slot attention. Advances
in neural information processing systems , 33:11525–11538, 2020.
Niloy J Mitra, Leonidas J Guibas, and Mark Pauly. Partial and approximate symmetry detection for 3d
geometry. ACM Transactions on Graphics (ToG) , 25(3):560–568, 2006.
Marisa C Oliveira, Renan AP Ribeiro, Elson Longo, Maurício RD Bomio, Fabiana V Motta, and Sergio R
de Lazaro. Temperature dependence on phase evolution in the batio3 polytypes studied using ab initio
calculations. International Journal of Quantum Chemistry , 120(1):e26054, 2020.
Tess E Smidt, Mario Geiger, and Benjamin Kurt Miller. Finding symmetry breaking order parameters with
euclidean neural networks. Physical Review Research , 3(1):L012002, 2021.
Shaojie Tang and Nadine Aubry. On the symmetry breaking instability leading to vortex shedding. Physics
of Fluids , 9(9):2550–2561, 1997.
Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick Riley. Tensor
field networks: Rotation-and translation-equivariant neural networks for 3d point clouds. arXiv preprint
arXiv:1802.08219 , 2018.
Tycho van der Ouderaa, David W Romero, and Mark van der Wilk. Relaxing equivariance constraints with
non-stationary continuous filters. Advances in Neural Information Processing Systems , 35:33818–33830,
2022.
DianWang, JungYeonPark, NeelSortur, LawsonLSWong, RobinWalters, andRobertPlatt. Thesurprising
effectiveness of equivariant models in domains with latent symmetry. In The Eleventh International
Conference on Learning Representations , 2022a.
Rui Wang, Robin Walters, and Rose Yu. Approximately equivariant networks for imperfectly symmetric
dynamics. In International Conference on Machine Learning , pp. 23078–23091. PMLR, 2022b.
24Published in Transactions on Machine Learning Research (10/2024)
Rui Wang, Robin Walters, and Tess Smidt. Relaxed octahedral group convolution for learning symmetry
breaking in 3d physical systems. In NeurIPS 2023 AI for Science Workshop , 2023.
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3d steerable cnns:
Learning rotationally equivariant features in volumetric data. Advances in Neural Information Processing
Systems, 31, 2018.
Patrick M Woodward. Octahedral tilting in perovskites. i. geometrical considerations. Acta Crystallographica
Section B: Structural Science , 53(1):32–43, 1997.
25Published in Transactions on Machine Learning Research (10/2024)
Table of Contents
A Notation and commonly used symbols 27
B Group theory 28
C Equivariant neural networks 30
D Limitations 31
D.1 Symmetry detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
D.2 Loss functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
E Proofs 32
E.1 Proof of Lemma 2.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
E.2 Formal justification of Definition 3.2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
E.3 Proof of Theorem 3.3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
E.4 Proof of Corollary 3.6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
E.5 Justification of Definition 4.4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
E.6 Proof of Theorem 4.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
E.7 Proof of Corollary 4.7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
E.8 Proof of Lemma 5.1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
F Classification of full symmetry breaking cases for O(3) 36
F.1 Normalizer: Kh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
F.2 Normalizer: D∞h. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
F.3 Normalizer: D(2n)h. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
F.4 Normalizer: Ih. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
F.5 Normalizer: Oh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
G Equivariant full SBS better than exact partial SBS 40
H Experiments 41
H.1 Triangular prism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
H.2 Octagon to rectangle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
H.3 BaTiO 3experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
26Published in Transactions on Machine Learning Research (10/2024)
A Notation and commonly used symbols
Here, we present the notation we use throughout this paper and the typical variable names.
Table 2: Notation used throughout this paper
Stab G(x)Stabilizer of an element xunder a group G
NG(S)Normalizer of group Sin groupG
ClG(S)Set of groups obtained by conjugating group Swith elements in G
OrbG(x)Orbit of an element xunder action by elements of group G
P(X)Set of all subsets of X
G/SWhenGis a group, this is the set of left cosets. If Sis a normal subgroup, this also
denotes the quotient group
X/SWhenXis a set, this is the equivalence classes induced by action of SonX
S≤GIfSandGare groups, this denotes that Sis a subgroup of G
f|XFunctionfwith domain restricted to X
Table 3: Commonly used symbols
GGroup our network is equivariant under
1Used to denote the trivial group
eIdentity element of a group
xInput
yOutput
SSymmetry of our input, more precisely Stab G(x)
KSymmetry of our output, more precisely Stab S(y)
BFull symmetry breaking set
PPartial symmetry breaking set
27Published in Transactions on Machine Learning Research (10/2024)
B Group theory
Group theory is the mathematical language used to describe symmetries. Here, we present a brief overview of
concepts from group theory we need to both define equivariance, and to understand our proposed symmetry
breaking scheme. For a more comprehensive treatment of group theory, we refer to standard textbooks
Dresselhaus et al. (2007); Dummit & Foote (2004); Kurzweil & Stellmacher (2004). We begin by defining
what a group is.
Definition B.1 (Group).LetGbe a nonempty set equipped with a binary operator ·:G×G→G. This
is a group if the follwing group axioms are satsfied
1. Associativity: For all a,b,c∈G, we have (a·b)·c=a·(b·c)
2. Identity element: There is an element e∈Gsuch that for all g∈Gwe havee·g=g·e=g
3. Inverse element: For all g∈G, there is an inverse g−1∈Gsuch thatg·g−1=g−1·g=efor identity
e.
Some examples of groups include the group of rotation matrices with matrix multiplication as the group
operation, the group of integers under addition, and the group of positive reals under multiplication. One
very important group is the group of automorphisms on a vector space. This group is denoted GL(V)and
we can think of it as the group of invertible matrices.
While abstractly groups are interesting on their own, we care about using them to describe symmetries.
Intuitively, the group elements abstractly represent the symmetry operations. In order to understand what
these actions are, we need to define a group action.
Definition B.2 (Group action) .LetGbe a group and Ωa set. A group action is a function α:G×Ω→Ω
such thatα(e,x) =xandα(g,α(h,x)) =α(gh,x )for allg,h∈Gandx∈Ω.
Often, we may want to relate two groups to each other. This is done using group homomorphisms, a mapping
which preserves the group structure.
DefinitionB.3 (Grouphomomorphismandisomorphism) .LetGandHbegroups. Agrouphomomorphism
is a function f:G→Hsuch thatf(u·v) =f(u)·f(v)for allu,v∈G. A group homomorphism is an
isomorphism if fis a bijection.
Because there are many linear algebra tools for working with matrices, it is particular useful to relate
arbitrary groups to groups consisting of matrices. Such a homomorphism together with the vector space the
matrices act on is a group representation.
Definition B.4 (Group representation) .LetGbe a group and Va vector space over a field F. A group
representation is a homomorphism ρ:G→GL(V)taking elements of Gto autmorphisms of V.
Given any representation, there are often orthogonal subspaces which do not interact with each other. If
this is the case, we can break our representation down into smaller pieces by restricting to these subspaces.
Hence, it is useful to consider the representations which cannot be broken down. These are known as the
irreducible representations (irreps) and often form the building blocks of more complex representations.
Definition B.5 (Irreducible representation) .LetGbe a group, Va vector space, and ρ:G→GL(V)a
representation. A representation is irreducible if there is no nontrivial proper subspace W⊂Vsuch that
ρ|Wis a representation of Gover spaceW.
There has been much work on understanding the irreps of various groups and many equivariant neural
network designs use this knowledge.
One natural question is whether there is a subset of group elements which themselves form a group under
the same group operation. Such a subset is a called a subgroup.
Definition B.6 (Subgroup) .LetGbe a group and S⊆G. IfStogether with the group operation of G·
satisfy the group axioms, then Sis a subgroup of Gwhich we denote as S≤G.
28Published in Transactions on Machine Learning Research (10/2024)
One particular feature of a subgroup is that we can use them to decompose our group into disjoint chunks
called cosets.
Definition B.7 (Cosets).LetGbe a group and Sa subgroup. The left cosets are sets obtained by
multiplying Swith some fixed element of Gon the left. That is, the left cosets are for all g∈G
gS={gs:s∈S}.
We denote the set of left cosets as G/S. The right cosets are defined similarly except we multiply with a
fixed element of Gon the right. That is, the right cosets are for all g∈G
Sg={sg:s∈S}.
We denote the set of right cosets as G\S.
In general, the left and right cosets are not the same. However, for some subgroups they are the same. Those
subgroups are called normal subgroups.
Definition B.8 (Normal subgroup) .LetGbe a group and Na subgroup. Then Nis a normal subgroup
if for allg∈G, we havegNg−1=N.
It turns out that given a normal subgroup, one can construct a group operation on the cosets. The resulting
group is called a quotient group.
Definition B.9 (Quotient group) .LetGbe a group and Na normal subgroup. One can define a group
operation on the cosets as aN·bN= (a·b)N. The resulting group is called the quotient group and is denoted
G/N.
For subgroups Swhich are not normal in G, it is often useful to consider a subgroup of Gcontaining S
whereSis in fact normal. The largest such subgroup is called the normalizer.
Definition B.10 (Normalizer) .LetGbe a group and Sa subgroup. The normalizer of SinGis
NG(S) ={g:gSg−1=S}.
Similar to orthogonal vector spaces, one can imagine an analogous notion for groups. These are called
complement subgroups.
Definition B.11 (Complement) .LetGbe a group and Sa subgroup. A subgroup His a complement of
Sif for allg∈G, we haveg=shfor somes∈Sandh∈HandS∩H={e}.
It turns out that if Sis a normal subgroup of GandHis a complement, then His isomorphic to the quotient
group.
Finally, it is useful to define what we mean by symmetry of an object. These are all group elements which
leave the object unchanged and is called the stabilizer.
Definition B.12 (Stabilizer) .LetGbe a group, Ωsome set with an action of Gdefined on it, and u∈Ω.
The stabilizer of uis all elements of Gwhich leave uinvariant. That is
Stab G(u) ={g:gu=u,g∈G}.
One can check that the stabilizer is indeed a subgroup. Closely related to the stabilizer is the orbit. This is
all the values we get when we act with our group on some object.
Definition B.13 (Orbit).LetGbe a group, Ωsome set with an action of Gdefined on it, and u∈Ω. The
orbit ofuis the set of all values obtained when we act with all elements of Gon it. That is,
OrbG(u) ={gu:g∈G}=Gu.
It turns out one can show that the stabilizer of elements in the orbit are related. This relation turns out to
be conjugation which we define below.
Definition B.14 (Conjugate subgroups) .LetSandS′be subgroups of G. We saySandS′are conjugate
inGif there is some g∈Gsuch thatS=gS′g−1. We denote the set of all conjugate subgroups by
ClG(S) ={gSg−1:g∈G}.
29Published in Transactions on Machine Learning Research (10/2024)
C Equivariant neural networks
Here, we give a brief overview of equivariant neural networks. For a more in depth coverage of the general
theory and construction of equivariance, we refer to works such as Cohen et al. (2019); Finzi et al. (2020);
Kondor & Trivedi (2018). We emphasize that the symmetry breaking techniques presented in the paper
apply to any equivariant architecture.
We first define equivariance.
Definition C.1 (Equivariance) .LetGbe a group with actions on spaces XandY. A function f:X→Y
is said to be equivariant if for all x∈Xandg∈Gwe have
f(gx) =gf(x).
Intuitively, we can interpret this as rotating the input giving the same result as just rotating the output.
It is easy to check that the composition of equivariant functions is still an equivariant function. Hence,
equivariant neural networks are designed using a composition of equivariant layers.
There has been considerable study into how one should design equivariant layers. One approach is to modify
convolutional filters by transforming them with the elements of our group Cohen & Welling (2016a). This
approachisknownasgroupconvolutionandisbasedontheintuitionthatconvolutionalfiltersaretranslation
equivariant. In group convolution, one interprets our data as a signal over some domain. The first layer is
a lifting convolution which transforms our data into a signal over the group. The remaining layers then just
convolve this signal with filters which are also signals over the group.
One can further use group theory tools to break down the convolutional filters into irreps. This leads to
steerable convolutional networks Cohen & Welling (2016b). These can be extended and used to parameterize
continuous filters which can be used for infinite groups Cohen et al. (2018). It turns out the irreps of the
group are natural data types for equivariant networks. Further, we can express the convolutions as tensor
products of irreps. We can think of equivariant operations as being composed of tensor products of irreps,
linear mixing of irreps, and scaling by invariant quantities. Combining these, we get tensorfield networks
which works on point clouds and is rotation equivariant Thomas et al. (2018). In this paper, we demonstrate
our method using networks built from the e3nnframework for O(3)equivariance Geiger & Smidt (2022).
30Published in Transactions on Machine Learning Research (10/2024)
D Limitations
D.1 Symmetry detection
To use our procedure, we do assume knowledge of the symmetries of the inputs and outputs to our network.
In the full symmetry breaking framework, we only need the symmetry of the input. In the partial symmetry
breaking framework, we need the symmetry of both the input and the output. However, we argue that this
is not a major concern.
First, symmetry detection is a well studied problem and there are many algorithms exist for various types of
data Bokeloh et al. (2009); Keller & Shkolnisky (2004); Largent et al. (2012); Mitra et al. (2006). Further,
sometimes the symmetries of the inputs and outputs are already known. This is especially true for crystallo-
graphic data Jain et al. (2013). In addition, because we only need the symmetry to design equivariant SBSs,
we only need to perform symmetry detection once. This can simply be incorporated as a preprocessing step
for our data.
Further, we want to emphasize that our framework can be used to prove whether knowledge of input sym-
metry is beneficial. We prove in Lemma F.1 that no finite subgroups of SO(2)have complement in their
normalizer (which is also just SO(2)). Combined with Corollary 3.6 this actually implies the degeneracy of
anySO(2)-equivariant SBS for cyclic groups is infinite. Hence, we cannot do much better than a something
like noise injection, which introduces asymmetry without knowledge of input symmetry.
D.2 Loss functions
While this work focuses on allowing equivariant networks to produce a set of lower symmetry outcomes,
it turns out another important problem is designing appropriate loss functions. Suppose we only have one
example input output pair x,ywhereyshares no symmetries with x. In this case there is no problem. We
can fix any b∈Band train to minimize a simple MAE loss ||f(x,b)−y||2for example.
However, suppose we observe x,yandx,y′in the data where y′=syands∈S= Stab G(x). Then suppose
we try to minimize MSE loss ||f(x,b)−y||2+||f(x,b′)−y′||2, whereb′=s′b. Then by equivariance, the
second term in the loss is
||f(x,b′)−y′||2=||f(x,s′b)−y′||2=||s′f(x,b)−sy||2=||f(x,b)−s′−1sy||2.
So in fact we see we must choose s′=s. So with multiple input output pairs and a simple loss directly
comparing outputs such as MSE, we have a problem pairing symmetry breaking objects with outputs.
However, suppose instead our loss was chosen such that loss (y,y′) =loss (y,y)is small ify′=syfor any
s∈S. Then even if our network outputs syinstead ofywhen given some symmetry breaking object b, we
do not punish it. Hence, this pairing problem would not exist. A simple version of such a loss would be to
compute the MSE for all possible symmetrically related outputs and take the closest one
loss (f(x,b),y) = min
s∈S(||f(x,b)−sy||2).
This is what we use for our experimental examples in this work. However, this can be inefficient for large or
infiniteSand designing appropriate loss functions in such cases remains an open question.
31Published in Transactions on Machine Learning Research (10/2024)
E Proofs
E.1 Proof of Lemma 2.1
LemmaE.1. LetXandYbe spaces equipped with a group action of G. Suppose the action on Xis transitive.
We can choose a G-equivariant f:X→Ysuch thatf(u) =yif and only if Stab G(y)≥Stab G(u). Further
this uniquely defines f.
Proof.First suppose we did have f(u) =y. For anyg∈Stab G(u), we have by equivariance of fthat
gy=f(gu) =f(u) =y.
Sog∈Stab G(y).
Next, suppose Stab G(y)≥Stab G(u). For anyx∈X, there is some r∈Gso thatx=ru. Let us pick exactly
one suchrfor eachXand form a set R. Hence any xis uniquely written as x=ruforr∈R. Define
f(x) =f(ru) =ry.
We claimfis equivariant. For any g∈Gandx∈X, letx=ruandgx=r′ufor somer,r′∈R. Then,
f(gx) =f(gru) =f(r′u) =r′y.
But note that gx=r′uimpliesr′−1gx=r′−1gru=u. Sor′−1gr∈Stab G(u)≤Stab G(y). Hence, we also
haver′−1gry=y. So,
f(gx) =r′y=r′(r′−1gry) =gry=gf(x).
Hence,fis equivariant.
Finally, for uniqueness, suppose f,f′are two equivariant functions such that f(u) =f′(u) =y. Then by
equivariance, for any x=gu∈Xwe have
f(x) =f(gu) =gy=f′(gu) =f′(x).
E.2 Formal justification of Definition 3.2
We can justify Definition 3.2 by characterizing exactly when σcan be equivariant. This leads to the following
proposition.
Proposition E.2. LetGbe a group and Sbe a subgroup of G. LetB∈P(B)be a set where there is
some group action of Gdefined on B. Then there exists an equivariant σ|ClG(S): ClG(S)→P(B)such that
σ|ClG(S)=Bif and only if nB=Bfor alln∈NG(S).
Proof.Note that ClG(S)is a set where action by conjugation is a transitive one. Also note by definition
that Stab G(S)for this action is precisely the definition of a normalizer NG(S). Then by Lemma E.1, we see
such a function exists if and only Bis also symmetric under NG(S).
E.3 Proof of Theorem 3.3
Theorem 3.3. LetGbe a group and Sa subgroup. Let Bbe aG-equivariant SBS for S. Then it is possible
to choose an ideal Bif and only if Shas a complement in NG(S).
Proof.SupposeBis transitive under Sand pickb∈B. Consider the stabilizer group Stab NG(S)(b). For
anyg∈NG(S), by transitivity under Swe must have gb=sbfor somes∈S. So,s−1gu=uimplying that
h=s−1g∈Stab NG(S)(b). So we find that we can write any gasg=shfor somes∈Sandh∈Stab NG(S)(u)
so
NG(S) =S·Stab NG(S)(u).
32Published in Transactions on Machine Learning Research (10/2024)
But note that since Bis symmetry breaking, S∩Stab NG(S)(u) ={e}. Hence, Stab NG(S)(u)is indeed a
complement.
For the converse, suppose His a complement of SinNG(S). We claim B=NG(S)/His the equivariant
SBS we desire. Note that clearly by construction, this is closed under NG(S)so we satisfy the equivariance
condition. Further, note that Stab S(H) = Stab NG(S)(H)∩S=H∩S={e}. SinceBis transitive under
NG(S), stabilizers of all other elements are obtained by conjugation and hence also trivial. Hence, it is
indeed symmetry breaking. Finally, any g∈NG(S)is uniquely written as shfor somes∈S,h∈Hso
gH=shH =sH. SoBis transitive under Sas well.
E.4 Proof of Corollary 3.6
Corollary 3.6. LetGbe a group and Sa subgroup. Let Mbe such that S≤M≤NG(S). LetBbe a
G-equivariant SBS for Swhich is transitive under NG(S). Then it is possible to choose Bsuch that every
M-orbit is also transitive under Sif and only if Shas a complement in M. In particular, such a Bhas
DegS(B)≤|NG(S)/M|.
Proof.Suppose we have such a Band pick any b∈B. By transitivity of the orbit under S, we haveMb=Sb.
LetB′=Mb. We can check that this is in fact an ideal M-equivariant SBS for S. That it is a symmetry
breaker follows since Bis symmetry breaking. That it is M-equivariant and transitive follows since Mb=Sb
andNM(S) =M. By Theorem 3.3 this implies Shas a complement in M.
Next, suppose we have a complement of SinM. By Theorem 3.3 we can construct B′which is an ideal
M-equivariant SBS for S. We can lift this to a G-equivariant SBS for Sby just taking B=NG(S)B′.
Finally, to compute the order, we note that every S-orbit is also a Morbit. Since Bis transitive under
NG(S), there are at most |NG(S)/M|number ofM-orbits and hence only that many S-orbits. So
DegS(B)≤|NG(S)/M|.
E.5 Justification of Definition 4.4
Similar to the full SBS case, we can justify Definition 4.4 by characterizing exactly when an equivariant π
can exist. This leads to the following proposition.
Proposition E.3. LetGbe a group, Sa subgroup of G, andKa subgroup of S. LetPbe a set with a group
action ofGdefined on it and P⊂P. There exists an equivariant π|OrbG((S,ClS(K))): Orb G((S,ClS(K)))→
P(P)such thatπ|OrbG((S,ClS(K)))((S,ClS(K))) =Pif and only if NG(S,K)leavesPinvariant.
Proof.By Lemma E.1, we need Pto be closed under the stabilizer of the input. But the generalized
normalizer NG(S,K)is precisely this stabilizer.
E.6 Proof of Theorem 4.5
Theorem 4.5. LetGbe a group and SandKbe subgroups K≤S≤G. LetPbe aG-equivariant K-
partial SBS. Then we can choose an ideal P(exact and transitive under S) if and only if NS(K)/Khas a
complement in NNG(S,K)(K)/K.
Proof.LetP=Suwhereuhas symmetry Stab S(u) =K. We can define an action of any coset NG(S,K)/K
onuas just the action of a coset representative on u. This is consistent since uis invariant under K. In
particular, note that Kis a normal subgroup of NS(K)soNS(K)/Kis a quotient group. Let B′=
(NS(K)/K)u. Sinceuis in aK-partial SBS, we must have su̸=ufor anys∈S−K. Hence, for any coset
gK∈NS(K)/K,gu̸=uifg /∈K. Therefore, B′must be a SBS for NS(K)/K.
33Published in Transactions on Machine Learning Research (10/2024)
Next, consider any coset gKinNNG(S,K)(K)/K. Then we know gu∈Susogu=sufor somes∈S.
SinceKwas a symmetry of u,gKg−1=sKs−1is a symmetry of gu=su. So the stabilizer of sumust
besKs−1=K. Hence,smust be in NS(K). Therefore the action of gKonugives us an element of
B′= (NS(K)/K)u. HenceB′isNNG(S,K)(K)/K-equivariant.
By Theorem 3.3, the existence of an ideal NNG(S,K)(K)/K-equivariant SBS for NS(K)/Kimplies that
NS(K)/Khas a complement in NNG(S,K)(K)/K.
For the converse direction, suppose that Ais a complement of NS(K)/KinNNG(S,K)(K)/K. Note the
elements of Aare cosets of Kso we can define a set of elements of NG(S,K)as
H=/uniondisplay
C∈AC.
DefineP= Orb S(H). We claim that Pis a transitive exact equivariant partial SBS.
We first show that Pis exactK-partial symmetry breaking. Consider s∈S. We can write
sH=/uniondisplay
C∈AsC=/uniondisplay
C∈sAC.
Now we see if s∈K, then since Kis the identity in the quotient group sA=A. HencesH=Hin this case.
Ifs∈NS(K)−K, thensKis not the identity in NS(K)/K. ButAis a complement so sA̸=Aimplying
sH̸=H. Finally, if s /∈NS(K)thensK /∈NNG(S,K)(K)/K. SosH̸⊂NNG(S,K)(K). ButH⊂NNG(S,K)(K)
sosH̸=H. Hence, Stab S(H) =Kand since the rest of Pis just the orbit of H, stabilizers of the other
elements are in ClS(K). Hence,Pas we constructed is an exact K-partial SBS.
For equivariance consider any n∈NG(S,K)giving a coset
nH=/uniondisplay
C∈AnC=/uniondisplay
C∈nAC.
Ifn∈NNG(S,K)(K)then since Ais a complement, (nK) = (sK)(aK)for somesK∈NS(K)/Kand
aK∈A, sonA= (nK)A= (sK)(aK)A= (sK)A=sAfor somes∈NS(K)⊂S. Hence,nH=sHfor
somes∈S. Ifn /∈NNG(S,K)(K), then there is some sso thatnKn−1=sKs−1. Therefore, s−1nKn−1s=K
sos−1n∈NNG(S,K). But we saw before that this means there is some s′such thats−1nH=s′H. Thus,
nH=ss′Handss′∈S. SonH∈PsoPis indeed closed under action by NG(S,K).
E.7 Proof of Corollary 4.7
Corollary 4.7. LetGbe a group, Sa subgroup, and Ka subgroup of S. LetK′be a subgroup of KandM
a subgroup of NG(S,K)∩NG(S,K′)which contains S. SupposePis aG-equivariant K-partial SBS for S
which is transitive under NG(S,K). We can choose Psuch that Stab S(p)∈ClNG(S,K)(K′)for allpand all
M-orbits inPare transitive under Sif and only if NS(K′)/K′has a complement in NM(K′)/K′. Further,
such aPhas
DegS,K(P)≤|K/K′|·|NG(S,K)/M|.
Proof.Suppose we had such a P. Pick some p∈Psuch that Stab S(p) =K′. SinceM-orbits are transitive
underS, we haveMp=Sp. LetP′=Mp. We can check then that this is a M-equivariant set. Further,
sinceM⊂NG(S,K′), we see that this is an exact K′-partial symmetry breaking set. Hence, it is an ideal
M-equivariant K′-partial SBS. Also note that since M⊂NG(S,K′), we haveM=NM(S,K′). So by
Theorem 4.5, NS(K′)/K′must have a complement in NM(K′)/K′.
Conversely, suppose NS(K′)/K′has a complement in NM(K′)/K′. Again, we note M=NM(S,K′)so by
Theorem 4.5 we have an ideal M-equivariant K′-partial SBS for S. We can lift this to G-equivariance by
taking the orbit under NG(S,K).
To see the order of such a P, we consider the S-orbits. Let Tbe a transversal of S/K. For each S-orbit,
we can pick some pin that orbit so that Stab S(p)≤K. We put the elements of Kpin ourPt. Within
34Published in Transactions on Machine Learning Research (10/2024)
eachS-orbit, any p′can be written as spfor somes∈Sand anysis uniquely written as s=tkfor some
t∈Tandk∈K. Sop′=tkp. However, note that any other s′wherep′=s′p=spcan be written
ass′=sk′for somek′∈Stab S(p). Hence,p′is uniquely written as p′=t(kp)sincekk′p=kp. So
eachS-orbit contributes |K/Stab S(p)|elements to Pt. However, since Stab S(p)∈ClNG(S,K)(K′), we must
have|K/Stab S(p)|=|K/K′|. Finally, we know each S-orbit is also an M-orbit, since Pis transitive under
NG(S,K), there are at most |NG(S,K)/M|differentS-orbits. So
DegS,K(P) =|Pt|≤|K/K′|·|NG(S,K)/M|.
E.8 Proof of Lemma 5.1
Lemma 5.1. We have the following formula
NG(S,K) =S(NG(S)∩NG(K)).
Proof.For anyn∈NG(S,K), by definition we must have nKn−1=sKs−1for somes∈S. Hence,
s−1nKn−1s=Ksos−1n∈NG(K). Further, clearly s∈NG(S)andn∈NG(S)so alsos−1n∈NG(S).
Therefore,s−1n∈NG(S)∩NG(K). Son=s(s−1n)∈S(NG(S)∩NG(K)). Hence
NG(S,K)⊆S(NG(S)∩NG(K)).
Next, consider any n′=sn∈S(NG(S)∩NG(K))wheres∈S,n∈NG(S)∩NG(K). Sinces∈NG(S),n∈
NG(S)clearlysn∈NG(S).Further, we find
snK(sn)−1=s(nKn−1)s−1=sKs−1∈ClS(K).
Therefore by definition sn∈NG(S,K). So also
S(NG(S)∩NG(K))⊆NG(S,K).
Hence, we find that
NG(S,K) =S(NG(S)∩NG(K)).
35Published in Transactions on Machine Learning Research (10/2024)
F Classification of full symmetry breaking cases for O(3)
Here we tabulate the cases for full symmetry breaking for the finite subgroups of O(3). These are the
point groups and the normalizers are tabulated in the International Tables for Crystallography in Her-
mann–Mauguin notation Koch & Fischer (2006). We have translated these to Schönflies notation in Table 4.
Table 4: Normalizers of the point groups in Schönflies notation. Note we have the equivalences C1= 1,
S2=Ci,C1h=C1v=Cs,D1=C2,D1h=C2v,D1d=C2h.
Normalizer: Groups:
Kh 1,Ci
D∞h Cn,S2n,Cnh∀n≥2;Cs
D(2n)hCnv,Dnd,Dnh∀n≥2;Dn∀n≥3
Ih I,Ih
Oh D2,D2h,T,Td,Th,O,Oh
In the following subsections we do casework by normalizers. For each, subgroup with a given normalizer, we
give a valid complement by name if it exists. In some normalizers, the name of a subgroup is not sufficient
to identify it. This is because there are multiple copies of subgroups with that name in the normalizer. In
such cases, we must identify which copy of the subgroup we care about. To do so, we give the normalizers
in terms of a group presentation found with the help of GAP. Group presentations are essentially a set of
generators and relations among the generators. We can then specify any specific subgroups of the normalizer
using the generators of the normalizer.
F.1 Normalizer: Kh
All the groups with this normalizer do have complements. Note that in Schönflies notation, Khis just the
entire group O(3). The only subgroups with O(3)as normalizer are the trivial group C1and inversion Ci.
Clearly for the trivial group the complement is O(3). For inversion, the complement is just SO(3).
Table 5: Groups with normalizer Kh=O(3)and their complements.
Group Complement
1Kh=O(3)
CiK=SO(3)
F.2 Normalizer: D∞h
Unfortunately, most of the groups in this case have no complements. We provide a proof of this fact here.
We begin by showing no nontrivial cyclic group has a complement in C∞(which isSO(2)in Schönflies
notation).
Table 6: Groups with normalizer D∞hand their complements.
Group Complement
Cs C∞v,D∞
Cn,S2n,Cnh∀n≥2None
Lemma F.1. LetCnbe a cyclic group of order n≥2which is embedded in C∞. Note that it is a normal
subgroup since all groups here are abelian. Then Cndoes not have a complement in C∞.
36Published in Transactions on Machine Learning Research (10/2024)
Proof.1Suppose there was a complement H. By definition, for any g∈C∞we haveg=chfor unique
h∈Handc∈Cn.
Next, note that C∞is a divisible group. In particular, for any g∈C∞, there exists some g′such that
g= (g′)n. Letg′be uniquely written as h′c′for someh′∈Handc′∈Cn. Then we have
g= (c′h′)n= (c′)n(h′)n= (h′)n
where we noted (c′)n=e. Sogis uniquely written as g=chforc=eandh= (h′)n. But this holds for all
gso all elements of C∞are just elements of H. This contradicts the fact that H∩Cn={e}.
Proof.2For those familiar with exact sequences, one can consider the following alternative proof. Consider
short exact sequence
1→Cn→C∞→C∞/Cn→1.
We can check that C∞/Cn∼=C∞. Existence of a complement for Cnimplies the above sequence is split,
which by the splitting lemma Hatcher (2002) implies C∞∼=C∞⊕Cn, a contradiction.
We can now extend the lemma above to there being no complement of any cyclic group in D∞(which is
O(2)in Schönflies notation).
Lemma F.2. LetCnbe a cyclic group of order n≥2which is embedded in D∞such that the rotation
axis aligns with the infinite rotation axis in D∞. Note that it is a normal subgroup since all groups here are
abelian. Then Cndoes not have a complement in D∞.
Proof.Suppose there was a complement H. ConsiderH′=H∩C∞. Clearly, we have H′∩Cn={e}. Next,
for anyg∈C∞, there is unique c∈Cnandh∈Hsuch thatg=ch. Buth=c−1g∈C∞soh∈H′. SoH′
is a complement of CninC∞. But this contradicts Lemma F.1.
Finally, we can prove that no subgroups except for Csin this case have complements. Note here that Khis
justO(3)andKjustSO(3)in Schönflies notation.
Theorem F.3. Consider any point group Awhich has normalizer D∞hinKh. IfAhas a nontrivial pure
rotation, then it has no complement in D∞h.
Proof.First, note that Khis the direct product of Kand inversion Ci. SupposeAhad a complement H.
We can split A=Ae⊔AiwhereAe=A∩Kis the subgroup of pure rotations and Aiis a coset consisting
of elements with an inversion. Similarly, we can split H=He⊔HiandD∞h=D∞⊔Diinto subgroups of
pure rotations and coset of elements with inversions.
We claim the elements of G=AeHeform a group. Consider any a,a′∈Aeandh,h′∈He. SinceAis a
normal subgroup of D∞h=AH, we havehA=Ahsoha′=a′′hfor somea′′∈A. But since h,a′∈K, we
havea′′h∈Ksoa′′∈K. Hencea′′∈Ae. Therefore,
(ah)(a′h′) =a(ha′)h′=a(a′′h)h′= (aa′′)(hh′)∈AeHe.
SoG=AeHeis a group.
Next, since His a complement of A, clearlyAe∩He={e}. SinceG≤AH=D∞h, anyg=ahfor unique
a∈Aandh∈Hwhich by construction of Garea∈Aeandh∈He. SoHeis certainly a complement of
AeinG.
Now, we claim either G=D∞orG=C∞. For anyg∈D∞, sinceHis a complement, there is a unique
a∈Aandh∈Hsuch thatg=ah. In particular, we note we must either have a∈Aeandh∈Heor
a∈Aiandh∈Hito have the right inversion parity. One possibility is G=AeHe=D∞. For the other
possibility, suppose D∞−Gis nonempty. Fix g∈D∞−Gand consider any g′∈D∞−G. Theng=ah
andg′=a′h′wherea,a′∈Aiandhh′∈Hi. Now, note that a−1a′is the combination of 2 elements with
odd parity in isoa−1a′∈Ae. Next, since Ais a normal subgroup, we have h−1A=Ah−1and in particular,
37Published in Transactions on Machine Learning Research (10/2024)
h−1a−1a′=a′′h−1for somea′′∈A. But since hhas odd parity and a−1a′has even parity in inversion, a′′
must have even parity in inversion. Hence, we have
g−1g′= (ah)−1(a′h′) =h−1a−1a′h′=a′′(h−1h′).
Sinceh,h′both have odd parity, h′′=h−1h′has even parity so in fact g−1g′=a′′h′′wherea′′∈Aeand
h′′∈He. Therefore, g−1g′∈GsoD∞−G=gGis just aG-coset ofD∞. We can similarly also show that
D∞−G=Gg. Now, we claim gG∩C∞=ϕ. Suppose not. Then there is some c∈gG∩C∞. SinceC∞
is a divisible group, there is some c′wherec= (c′)2. But we must have (c′)2∈G, a contradiction. Hence
gG∩C∞=ϕsoG∩C∞=C∞. To conclude, we must have g∈D∞−C∞and it is clear gC∞would
generate the remaining elements in D∞. SoG=C∞in this case.
From Table 4, we can see that Aemust in fact be a nontrivial cyclic group. But then the above implies that
Heis a complement of this cyclic group in either G=D∞orG=C∞, which contradict Lemma F.2 and
Lemma F.1 respectively. So Acannot have a complement in D∞h.
F.3 Normalizer: D(2n)h
All groups with this normalizer do have complements. We list the subgroup and its complement in Table 7.
One presentation of D(2n)his
⟨a,b,m|a2n,b2,m2,(ab)2,(am)2,(bm)2⟩.
Figure 14 depicts an example of a D10hobject. The element acorrespond to a 2π/10rotation about the
blue vertical axis, bcorresponds to a πrotation about the red axis, and mcorresponds to a reflection across
the mirror plane shown in orange.
Figure 14: Object with symmetry D10h. We can identify generator aas the 10-fold rotation about the blue
axis, generator bas the 2-fold rotation about the red axis, and mas the reflection over the plane shown in
orange.
38Published in Transactions on Machine Learning Research (10/2024)
Table 7: Groups with normalizer D(2n)hand their complements.
Group Generators of group Complement Generators of a complement
Cnv a2,m C2v am,bm
Dnda2,abm,m Cs bm
Dnh a2,b,m Cs am
Dn a2,b C2v am,bm
F.4 Normalizer: Ih
This case is simple, we either have IorIh. Clearly we just need to add inversion to get a complement in the
former case and in the latter case we can just take the trivial group.
Table 8: Groups with normalizer Ihand their complements.
Group Complement
I Ci
Ih 1
F.5 Normalizer: Oh
All subgroups in this case have complements as well. One presentation of Ohis
⟨a,b,i|a4,b4,i2,(aba)2,(ab)3,iaia−1,ibib−1⟩.
Here,aandbareπ/2rotations about perpendicular axes and iis just inversion.
Table 9: Groups with normalizer Ohand their complements.
Group Generators of group Complement Generators of a complement
D2 a2,b2D3d ab,ba2,i
D2h a2,b2,i D3 ab,ba2
T ab,ba S4 a2b,i
Td ab,ba,ai C2 a2b
Th ab,ba,i C2 a2b
O a,b Ci i
Oh a,b,i 1 ϕ
39Published in Transactions on Machine Learning Research (10/2024)
G Equivariant full SBS better than exact partial SBS
We provide an outline of the construction of the counterexample. It is easiest to explain this by introducing
the concept of a wreath product on groups.
Definition G.1 (Wreath product) .LetHbe a group with a group action on some set Ω. LetAbe another
group. We can define a direct product group indexed by Ωas the set of sequences (aω)ω∈Ωwhereaω∈A.
The action of HonΩinduces a semidirect product by reindexing. In particular, for all h∈Hand sequences
inAΩwe define
h·(aω)ω∈Ω= (ah−1ω)ω∈Ω.
The resulting group is the unrestricted wreath product and denoted as AWrΩH.
If rather than a direct product group AΩ, we restrict ourselves to a direct sum where all but finitely many
elements in our sequence is not the identity, then we get the restricted wreath product denoted as AwrΩH.
Note that the direct sum and direct product are the same for finite Ωso the restricted and unrestricted
wreath products also coincide in those cases.
Considerthe space Ω ={1,−1}andan actionof D4onΩcorresponding tothe A2representation. Intuitively,
if we think of D4as the rotational symmetries of a square in the xy-plane, this corresponds to how the z
coordinate transforms by flipping signs. Define a group G′asG′=C2wrΩD4. This is a group of order 32
and is SmallGroup(32,28) in the Small Groups library GAP. One presentation of this group is
⟨a,b,c|a2,b4,(ab)4,c2,bcb−1c,(ac)4⟩. (1)
In this presentation, we can interpret a,bas generators of D4andcas the generator one copy of C2.
Consider the group G=G′×G′defined using the direct product. We can write generators of Gas
a1,b1,c1,a2,b2,c2corresponding to two copies of those in the presentation given in equation 1 where gener-
ators with different indices commute. Define Sas the subgroup generated by a1,b2
1,c1,a2,b2
2,c2andKas
the subgroup generated by c1c2.
Wecancheckthat NG(S) =NG(S,K) =G. Itisalsonothardtocheckthat a1b1,a2b2generateacomplement
forSinG. Hence, by Theorem 3.3, we know that an ideal G-equivariant SBS is possible for S. Hence, we
know the size of the equivariant full SBS is |S|= 256.
Next, suppose we wanted a G-equivariant exact partial SBS. We can always generate this partial SBS by
taking the orbit of some element punder action by NG(S,K) =Gwhere Stab S(p) =K. We claim we must
also have Stab G(p) =K. Suppose not, then there must be some g∈Stab G(p)such thatg /∈S. However,
we can check through casework or brute force that for all such g, eithergKg−1̸=Korg2∈S−K. But
would mean that there are elements not in Kwhich stabilize psoStab S(p)̸=K, a contradiction. Hence, no
suchgcan exist so Stab G(p) =K. Finally, by Orbit-Stabilizer theorem, this means the set must have size
|P|=|OrbG(p)|=|G|/|Stab G(p)|= (82·24)/2 = 512. This is larger than the equivariant full SBS.
In our supplementary material, we provide a script in GAP which verifies our claims above. In particular
it performs a brute force check that Stab S(p) =Kimplies Stab G(p) =Kfor the group G,S,Kdescribed
above.
40Published in Transactions on Machine Learning Research (10/2024)
H Experiments
We provide some additional details on our experiments here. We also provide our code for running these
experiments in the supplementary material.
H.1 Triangular prism
H.1.1 Obtaining an ideal SBS
(a)
 (b)
Figure 15: (a) Triangular prism with D3symmetry and patterned cylinder with D6hsymmetry. The gen-
erators are a,b,mwhereais a2π/6rotation about the blue axis, bis aπrotation about the red axis, and
mis a reflection across the orange plane. (b) An ideal symmetry breaking set for the triangular prism. A
complement of D3inD6his generated by the mirror planes shown here in yellow and purple. The vector
in red is a symmetry breaking object with this complement as stabilizer. The orbit of this vector under the
normalizer generates the other vectors shown in black.
Table 7 tells us D3is generated by a2,band that a complement His generated by am,bm.By Theorem 3.3,
we know that if we can pick some object vwith stabilizer Stab D6h(v) =H, then the orbit of vunderD3
gives an ideal equivariant SBS. The symmetry axis for aandbare depicted in Figure 15a and correspond
to thezandxaxes in the canonical orientation. The generators am,bmof the complement are depicted as
mirror planes in yellow and purple in Figure 15b.
In this case, we can see that the vector at the intersection of the mirror planes has the symmetries of the
complement. This is depicted as the red vector in Figure 15b. One can further check it shares no symmetries
with the triangular prism. The other 5arrows in black are the other symmetry breaking objects we obtain
by taking the orbit of the red arrow under action by D6h. In the canonical orientation, this red vector
normalized to unit length is
(cos(π/6),sin(π/6),0) = (√
3/2,1/2,0).
41Published in Transactions on Machine Learning Research (10/2024)
H.1.2 Nonequivariant SBS
In addition to using an equivariant SBS as presented in the main paper, we also tried training with the
non-equivariant SBS described in Section 3.2. Recall that the symmetry breaking objects here are a vector
pointing to one of the vertices of the triangle projected in the xyplane and a vector pointing up or down
corresponding to which triangle we pick from. We fix one pair of vectors as our symmetry breaking object
and train our equivariant model to match it with a vertex.
As shown in Figure 16a, our model is able to complete this. However, rotating the prism by 180◦and feeding
this rotated prism along with our symmetry breaking object, we find that our model outputs a vector which
does not point to any vertex. This is shown in Figure 16b. Contrast this with the equivariant case in
Figures 16c and 16d where our model still produces a vector which points to a vertex of the prism.
H.1.3 Nonideal SBS
We can modify the nonequivariant SBS into an equivariant one by adding the additional objects needed for
closure under the normalizer. Doing so we see there are 2 S-orbits in this nonideal equivariant SBS shown
in Figure 17. This corresponds to a degeneracy of 2as defined in Section H.1.3.
From the discussion in Section 3.4, we expect this SBS to be less efficient than an ideal one. We first train
using only a symmetry breaking object from one of the S-orbits. We see that when given objects from that
orbit, the network correctly outputs vectors pointing to vertices of the prism but fails when given objects
from the other S-orbit. However, if we use objects from both orbits in training, the output vectors point to
vertices when given objects from either S-orbit. Hence, we need to use at minimum 2 symmetry breaking
objects during training to guarantee correct behavior for all objects in the SBS compared to only needing
one example to train for an ideal SBS.
42Published in Transactions on Machine Learning Research (10/2024)
(a)
 (b)
(c)
 (d)
Figure 16: (a) Output (red) generated by our model and symmetry breaking object (blue) given that is
chosen from a non-equivariant SBS (b) Output (red) generated by our model and symmetry breaking object
(blue) given when our prism is rotated by 180◦(c) Output (red) generated by our model and symmetry
breaking object (blue) given that is chosen from an equivariant SBS (d) Output (red) generated by our
model and symmetry breaking object (blue) given when our prism is rotated by 180◦
43Published in Transactions on Machine Learning Research (10/2024)
(a)S-orbit 1
 (b)S-orbit 2
Figure 17: (a) S-orbit corresponding to the original nonequivariant SBS (b) Additional S-orbit needed which
makes the set closed under the normalizer.
44Published in Transactions on Machine Learning Research (10/2024)
Table 10: Results of training using a nonideal equivariant SBS. If we only see one of the S-orbits in training,
the network fails on the unseen orbits. If we see both S-orbits then the network behaves correctly.
Seen in training Outputs
S-orbit 1S-orbit 2 S-orbit 1 S-orbit 2
Yes No
No Yes
Yes Yes
45Published in Transactions on Machine Learning Research (10/2024)
H.2 Octagon to rectangle
H.2.1 Obtaining an ideal partial SBS
In this scenario, we want G-equivariance for G=O(3)and we have S=D8and partial symmetry K=D2.
(a)
 (b)
Figure 18: (a) Octagon with D8symmetry we input and patterned cylinder with NG(S,K) =D8hsymmetry.
The generators are a2,b,mwherea2is a2π/8rotation about the blue axis, bis aπrotation about the red
axis, andmis a reflection across the orange plane. (b) A symmetry breaking object which generates an
ideal partial SBS. Note that in addition to the D2symmetry, this object is also symmetric under reflections
across the purple and yellow planes.
WefollowAlgorithm3tounderstandwhatsymmetryacanonicalsymmetrybreakingobjectneedstogenerate
an ideal partial SBS. First, we note S= (e,D 8)andK= (e,D 2). The first few steps are straightforward
and we can evaluate them directly.
Operation Evaluated
N1←Normalizers [(S)] Normalizers [D8] = (e,D 16h)
(n,(N2)))←Normalizers [(K)] Normalizers [D2] = (e,D 4h)
N2←(g−1
SgKn,(N2)) ( e,D 4h)
N←N1∩N2 (e,D 16h)∩(e,D 4h) = (e,D 4h)
N′←(e,(S))∩N2 (e,D 8)∩(e,D 4h) = (e,D 4)
The next step is
(Q1,ϕ)←Quotient [N,(g−1
SgK,(K))]
where we need to create a quotient group. Here we note a presentation of N= (e,D 4h)is
⟨a,b,m|a4,b2,m2,(ab)2,(am)2,(bm)2⟩.
The normal subgroup (g−1
SgK,(K)) = (e,D2)then consists of e,a2,b,a2b. Hence we can set the cosets
X={a,a3,ab,a3b}Y={m,a2m,bm,a2bm}
46Published in Transactions on Machine Learning Research (10/2024)
and we can check these generate the quotient group and we have relations X2=Y2= (XY)2=e. Hence
we have
Q1=⟨X,Y|X2,Y2,(XY)2⟩.
Finally, setting
ϕ(a) =ϕ(a3) =ϕ(ab) =ϕ(a3b) =X
ϕ(m) =ϕ(a2m) =ϕ(bm) =ϕ(a2bm) =Y
defines our homomorphism ϕ.
The next step is
Q2←ϕ(N′).
We noteN′= (e,D 4)which is generated by a,b. We can find that ϕ(a) =Xandϕ(b) =ϕ((a3)(ab)) =
ϕ(a3)ϕ(ab) =X2=e. Hence,
Q2=⟨X|X2⟩.
The next step is
C←FindComplement [Q1,Q2]
which in this case one can check to be generated by Y. This gives
C=⟨Y|Y2⟩.
SinceCexists, the next step is
(h,(H))←ϕ−1(C).
The elements of Caree,Yand from the definition of ϕ, we can see that ϕ−1(C)consists of the elements
ϕ−1(e) ={e,a2,b,a2b}ϕ−1(Y) ={m,a2m,bm,a2bm}.
We can check that the group consisting of these elements is in fact generated by a2,b,mwhich is (e,D 2h).
Hence
(h,(H)) = (e,D2h).
If an object has this symmetry then it can generate an idea partial SBS. In this case a simple choice is a
l= 2object of even parity. This is depicted in Figure 18b. If we align it to the xaxis, this would correspond
to(0,0,1,0,0)using real spherical harmonic conventions. Applying Algorithm 2 we would obtain the set of
l= 2objects “parallel” to an edge of the octagon.
H.3 BaTiO 3experiment
H.3.1 Atom matching algorithm
We would like to predict atom distortions. However, our data consists of atom coordinates in the initial and
target structures not necessarily in the same order. Hence, we need an algorithm to match similar atoms
together so we know how much they are distorted. This process is complicated by the fact that we have
periodic boundary conditions with periodicity determined by lattice vectors and that our atoms may be
translated within the lattice. We assume our structures are given in the same rotational orientation.
For our algorithm, we use the insight that the distorted atom should still have similar vectors to neighboring
atoms. Hence, we can compute a signature for an atom aby taking the difference of the positions of that
atom and all other atoms in the lattice. We call the set of position differences for atom afrom all other
atoms the signature σaofa. Note in our implementation, we also separate out the atom types in addition
to the position differences.
Next, we need a way to compare signatures. Suppose we had atom afrom the initial structure and atom a′
from the target structure. Certainly, if they are different atom types, we assign a cost of ∞to this pairing.
47Published in Transactions on Machine Learning Research (10/2024)
Otherwise, we look at their signatures. However, we actually need to optimally pair the other atoms to do
so. For a pair of atoms bandb′from the initial and target structures, we can give a cost of ∞if they are
different atoms and σa[b]−σa′[b′]otherwise. If the atoms are similar, this should be small, but it may also
be shifted by lattice parameters from the smallest it could be. So we just look at all small lattice shifts L
and set the smallest ||σa[b]−σa′[b′] +L||2as the cost of pairing b,b′. This gives a cost matrix Mb,b′. With
all the costs, we can run the matching algorithm in Crouse (2016) to match the atoms. The cost of the
assignment is the difference in the signatures of a,a′.
Finally, we can match the atoms using the comparison of signatures. We create a cost matrix where Ca,a′is
the difference in signatures of a,a′from the initial and target structures. We then run another iteration of
the algorithm from Crouse (2016) to find our matching.
Because we only ever use differences of atoms, this matching algorithm is independent of translations.
H.3.2 Translation invariant loss
In the previous experiments, we could simply use a MSE loss of the vector differences. However, for crystals
we wanted to have a loss which is invariant under translation. We realize that our matching algorithm in
fact produces such a loss. By storing the matching information, we can effectively compute the same loss
without having to run the matching algorithm every time. This is what we use to evaluate our model.
48Published in Transactions on Machine Learning Research (10/2024)
H.3.3 Symmetrically related outputs
(a)
 (b)
(c)
 (d)
(e)
 (f)
Figure 19: Distortions of a highly symmetric crystal structure of BaTiO 3when provided with each of the
possible symmetry breaking objects in our ideal equivariant partial SBS.
49Published in Transactions on Machine Learning Research (10/2024)
Table 11: Values of various quantities which help distinguish the high symmetry and low symmetry struc-
tures. Our models here try to distort the high symmetry structure to the low symmetry one.
Structure SB object Bond length average Bond length variance Ti-O1-Ti Ti-O2-Ti Ti-O3-Ti
High symmetry 2 0 180◦180◦180◦
Low symmetry 2.003417 0.01392 180◦171.80◦171.80◦
Model None 2 0 180◦180◦180◦
Model (1,0,0) 2.003417 0.01392 180◦171.80◦171.80◦
Model (−1,0,0) 2.003417 0.01392 180◦171.80◦171.80◦
Model (0,1,0) 2.003417 0.01392 171.80◦180◦171.80◦
Model (0,−1,0) 2.003417 0.01392 171.80◦180◦171.80◦
Model (0,0,1) 2.003417 0.01392 171.80◦171.80◦180◦
Model (0,0,−1) 2.003417 0.01392 171.80◦171.80◦180◦
50