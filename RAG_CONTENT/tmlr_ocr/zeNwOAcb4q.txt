Estimating Transition Matrix with Diffusion Models
for Instance-Dependent Label Noise
Anonymous Author(s)
Affiliation
Address
email
Abstract
Learning with noisy labels is a common problem in weakly supervised learning, 1
where the transition matrix approach is a prevalent method for dealing with label 2
noise. It estimates the transition probabilities from a clean label distribution to a 3
noisy label distribution and has garnered continuous attention. However, existing 4
transition matrix methods predominantly focus on class-dependent noise, making 5
it challenging to incorporate feature information for learning instance-dependent 6
label noise. This paper proposes the idea of using diffusion models for estimating 7
transition matrix in the context of instance-dependent label noise. Specifically, we 8
first estimate grouped transition matrices through clustering. Then, we introduce 9
a process of adding noise and denoising with the transition matrix, incorporating 10
features extracted by unsupervised pre-trained models. The proposed method 11
enables the estimation of instance-dependent transition matrix and extends the 12
application of transition matrix method to a broader range of noisy label data. 13
Experimental results demonstrate the significant effectiveness of our approach on 14
both synthetic and real-world datasets with instance-dependent noise. The code 15
will be open sourced upon acceptance of the paper. 16
1 Introduction 17
For classification problems with given labels, deep neural networks have demonstrated significant 18
improvements compared to traditional methods in recent years [ 25]. The efficacy of deep neural 19
networks heavily relies on the accuracy of the labels. Directly incorporating polluted erroneous labels 20
into network learning can result in the network fitting the noise, potentially severely impacting the 21
predictive performance of the network [ 8]. However, in reality, obtaining accurate annotated data can 22
be prohibitively expensive, and a substantial amount of data comes from the Internet or is annotated 23
by non-expert annotators, inevitably containing noisy labels. Therefore, researching and promoting 24
methods to mitigate the damage to models and make them more robust in the face of label noise data 25
is a highly worthwhile problem to investigate, known as the problem of learning with noisy labels 26
[23, 10, 34, 1]. 27
Different approaches have been proposed to address the problem of label noise. One category 28
[31,22] involves the design of specialized loss functions or network structures to enhance the model’s 29
robustness against noisy labels. Another major category focuses on sample selection [ 2,10,14], 30
where samples are partitioned into a set of clean samples and a set of contaminated noisy samples 31
based on the magnitude of the loss or the similarity of extracted features. The labels of the noisy 32
samples are then modified or their weights are reduced, followed by learning using semi-supervised 33
methods. Sample selection methods are currently mainstream and have achieved promising results. 34
However, the selection process relies heavily on intuition and lacks theoretical support. Additionally, 35
the sample selection procedure is often complex and computationally intensive. In contrast, another 36
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.Figure 1: Diffusion Model for Transition Matrix.
significant category of methods is the transition matrix method [ 34,17,12,42], which estimates the 37
transition probabilities from the clean label distribution to the noisy label distribution. This class 38
of methods reveals the generation process of noisy labels and exhibits statistical consistency, often 39
accompanied by theoretical analyses as methodological support. As a result, they have garnered 40
continuous attention and occupy an important position in various algorithms for learning with noisy 41
labels. 42
In transition matrix methods, accurate estimation of the transition matrix is crucial. If an accurate 43
estimation of the transition matrix can be obtained, along with the observed data for estimating the 44
posterior distribution of the noisy labels, it is possible to infer the distribution of clean labels for 45
neural network learning. Previous transition matrix methods [ 34,17,39] have mainly focused on 46
class-dependent label noise, where a single transition matrix is estimated for all samples, which is 47
typically straightforward. However, for instance-dependent label noise and complex real-world data, 48
the label transition probabilities for each sample are not entirely identical. The transition matrix often 49
depends on the specific features of individual samples, requiring the estimation of a separate transition 50
matrix for each sample. However, in most cases, a single observed label corresponds to each sample 51
in the dataset, making it an identifiability problem to estimate a separate transition matrix for each 52
sample [ 20]. Although some methods [ 33,41,15] have utilized separate small networks to generate 53
the transition matrix or divided the data into groups to transform it into a grouped class-dependent 54
scenario, there still exist significant estimation errors and a lack of incorporating features effectively 55
into the estimation of the transition matrix. 56
To better incorporate the feature information of images into the estimation of the transition matrix, 57
this work employs conditional diffusion models. The diffusion model originates from generative 58
models and has been widely applied in various computer vision tasks in recent years [ 36,7], showing 59
remarkable results. The proposed method revolves around the core idea of replacing image samples in 60
the original diffusion process with a transition matrix. The matrix undergoes a process of adding noise 61
and denoising, where the denoising step incorporates the sample features extracted by a pre-trained 62
model as conditions. This generates a feature-dependent transition matrix. The constructed diffusion 63
module is illustrated in Figure 1. Additionally, considering the assumption that instance-dependent 64
label noise is usually correlated with features [ 6], clustering methods are utilized at the feature level 65
to group samples. Preliminary estimations of the transition matrices are obtained for each group, 66
which are then incorporated into the diffusion module for learning. The overall framework of the 67
method is depicted in Figure 2. 68
The subsequent sections are organized as follows. Section 2 presents an in-depth review of the 69
relevant works. In Section 3, we introduce our proposed model framework. Section 4 outlines 70
the experimental analysis conducted on diverse synthetic and real-world noisy datasets, along with 71
comparisons against other existing methods. Finally, we provide concluding in Section 5. The 72
primary contributions of this paper can be summarized as follows: 73
•We propose a method that utilizes diffusion models to add noise and denoise on the transition 74
matrix, incorporating image features extracted through pre-trained encoder. 75
•By combining the transition matrix-based diffusion model with feature-based clustering, we 76
establish a framework capable of addressing instance-dependent label noise problems. 77
2Figure 2: The overall framework of DTM.
•Our method demonstrates significant improvements over other transition matrix methods on 78
both synthetic and real-world noisy datasets, and it achieves comparable performance to 79
state-of-the-art methods. 80
2 Related Works 81
2.1 Transition Matrix Methods 82
Most previous methods for estimating transition matrix in the presence of label noise have primarily 83
focused on class-dependent noise scenarios, simplifying the estimation process. Methods such as 84
[24,34] assume the existence of anchor points to identify the transition matrix. [ 17] and [ 39] 85
introduce different regularization techniques to relax the anchor point assumption. Additionally, 86
[26,38] apply techniques such as meta-learning to estimate the transition matrix, but these approaches 87
may require more clean data and computational resources. While these methods are effective for 88
handling class-dependent label noise, they are not suitable for instance-dependent noise or real-world 89
noisy data. 90
However, estimating an individual transition matrix for each sample without additional assumptions 91
or multiple noisy labels is infeasible [ 20]. To approximate the estimation of the instance-dependent 92
transition matrix, [ 9] utilize an adaptation layer that estimates the transition matrix based on the 93
output of each sample. [ 37] employs a separate network to estimate the transition matrix based on 94
Bayesian labels. Some methods, such as [ 33,30,41], employ clustering to learn part-dependent 95
or group-dependent matrices, which can be viewed as a compromise between instance-dependent 96
and class-dependent methods. Other approaches, including [ 6,12], utilize the similarity in the 97
feature space to aid in learning the transition matrix. Although these instance-dependent transition 98
matrix methods achieve identifiability through specialized treatments, they have not effectively 99
utilized feature information in the learning process, resulting in errors in estimating feature-dependent 100
transition matrices. 101
2.2 Diffusion Models 102
Diffusion models, as generative models, have played a significant role in computer vision [ 36,7]. 103
Prominent examples include DDPM [ 11], DDIM [ 27], score matching methods [ 28], and methods 104
based on stochastic differential equations [ 29]. Diffusion models and their variants have been applied 105
to various computer vision tasks such as image generation, image-to-image translation, text-to-image 106
generation, among others. However, their application to the problem of label noise is relatively novel. 107
To the best of our knowledge, only one existing work [ 3] has utilized diffusion models for addressing 108
this problem. However, this work treats labels as the output of the diffusion model, which limits 109
their expressive power due to the low dimension of the labels. Moreover, it overly relies on directly 110
incorporating image features as conditions in the label generation process, which depends heavily on 111
3pre-trained models and may not be as reasonable as incorporating them into the transition matrix that 112
reveals the process of noise generation. Experimental results also support this perspective. 113
3 Method 114
In this section, we present the definitions of symbols and introduce our method of using Diffusion 115
models to construct the Transition Matrix (DTM). 116
3.1 Preliminaries 117
LetX ⊂Rdbe the input image space, Y={1,2,···, C}be the label space, where Cis the number 118
of classes. Random variables (X, Y),(X,˜Y)∈ X × Y denote the underlying data distributions 119
with true and noisy labels respectively. In general, we can not observe the latent true data samples 120
D={(xi, yi)}N
i=1, but can only obtain the corrupted data ˜D={(xi,˜yi)}N
i=1, where ˜y∈ Y is the 121
noisy label corrupted from the true label y, while denote corresponding one-hot label as yand˜y. 122
Transition matrix methods use a matrix T(x)∈[0,1]C×Cto represent the probability from clean 123
label to noisy label, where the ij-th entry of the transition matrix is the probability that the instance 124
xwith the clean label icorrupted to a noisy label j. The matrix satisfies the requirement that the 125
sum of each rowPC
j=1Tij(x)is1, and usually has the requirement for Tii(x)>Tij(x),∀j̸=i. 126
LetP(Y|X=x) = [P(Y= 1|X=x),···, P(Y=C|X=x)]⊤be the clean class-posterior 127
probability and P(˜Y|X=x) = [ P(˜Y= 1|X=x),···, P(˜Y=C|X=x)]⊤be the noisy 128
class-posterior probability, the formula can be write as: 129
P(˜Y|X=x) =T(x)⊤P(Y|X=x). (1)
By estimating the transition matrix and the noisy class-posterior probability, the clean class-posterior 130
probability can be inferred by 131
P(Y|X=x) =T(x)−⊤P(˜Y|X=x), (2)
where the symbol −⊤denotes the transpose of the inverse matrix. 132
The majority of existing methods [ 24,10,17] focus on studying the class-dependent and instance- 133
independent transition matrix, i.e., T(x)≡Tfor∀x. However, these methods are not applicable to 134
instance-dependent noise scenarios where the transition matrix T(x)varies with respect to the input 135
X. The main focus of our work is to utilize the feature information from input images to construct a 136
instance-dependent transition matrix T(x). 137
3.2 Diffusion Model for Transition Matrix 138
We adopt the classic DDPM model [ 11] from diffusion models as a reference to perform noise 139
addition and denoising on the transition matrix. The diagram is illustrated in Figure 1. 140
For the forward diffusion process beginning with transition matrix T0∼q(T), the process of 141
gradually adding noise is obtained according to the following Markov process: 142
q(Tm|Tm−1) =N
Tm;p
1−βmTm−1, βmI
, (3)
form= 1,2,···, M, where we use Mto replace T, which is usually used in other diffusion models, 143
in above equation for distinguishing from the symbol of transition matrix T. 144
We aim to make the distribution of q(TM)approach a standard normal distribution N(0,I)and 145
through TMto conduct the reverse denoising process by fitting a neural network µθto fit the 146
disttibution: 147
pθ(Tm−1|Tm) =N
Tm−1;µθ(Tm,x, fp, m),˜βmI
, (4)
where define ˜βm=1−¯αm−1
1−¯αmβm, αm= 1−βm,¯αm=Qm
i=1αi. The fpin equation (4) denotes the 148
pre-trained encoder for feature extraction. 149
4The diffusion model can be learned by optimizing the evidence lower bound: 150
LELBO =Eq"
LM+MX
m>1Lm−1+L0#
, (5)
where 151
L0=−logpθ(T0|T1),
Lm−1=DKL(q(Tm−1|Tm,T0)∥pθ(Tm−1|Tm)),
LM=DKL(q(TM|T0)∥pθ(TM)).(6)
Similar to the derivation and simplification process of DDPM, when a pre-trained encoder fpis 152
provided along with the training data incorporating the initial transition matrix T, the learning 153
algorithm for the diffusion model is presented in Algorithm 1. 154
Algorithm 1 Diffusion Model for Transition Matrix
Input: Training data {xi,Ti}N
i=1, pre-trained encoder fp.
while not converged do
Sample (x0,T0)from data
Sample m∼ {1,···, M}
Sample noise ϵ∼ N(0,I)
Take gradient descent step on the loss:
∇θϵ−ϵθ √¯αmT0+√
1−¯αmϵ,x0, fp, m2
end while
Next, for each image x, we can sample the corresponding transition matrix T(x)as shown in 155
Algorithm 2. 156
Algorithm 2 Sample for Transition Matrix
Sample TM∼ N(0,I)
form=M,···,1do
z∼ N(0,I)ift >1, elsez=0
Tm−1=1√αm
Tm−1−αm√1−¯αmϵθ(Tm,x, fp, m)
+σmz
end for
Output: T0
3.3 Feature-Dependent Framework 157
From Algorithm 1, it can be observed that there are two components of the diffusion process that 158
need to be provided in advance: the pre-trained encoder fpand the initial input T(x). 159
The pre-trained encoder fpcan be obtained through self-supervised learning or directly using the 160
large model like CLIP. In our experiments, we employ the commonly used SimCLR [ 4] method in 161
contrastive learning as the feature extraction model. 162
On the other hand, the part involving the transition matrix T(x)used for learning the diffusion 163
model is also related to the pre-trained encoder fp. Based on the assumption that the noise transition 164
probability depends on image features, we adopt a group-dependent transition matrix as the initial 165
input. We perform clustering algorithms at the feature extraction level fp(x), using the K-means 166
method in our experiments, to group the image data. Then, based on the method V olMinNet [ 17], we 167
train class-dependent transition matrices for each group and obtain the initial transition matrix T(x) 168
for each image x, which is then used as input in Algorithm 1. It is worth to note that the initial T(x) 169
used as input for the diffusion process does not require different for each x. However, the denoising 170
process of the diffusion model will further incorporate the feature information into the learning of the 171
transition matrix. 172
5After obtaining the instance-dependent estimated transition matrix T(x), the neural network can be 173
learned to fit the clean label distribution by the loss function: 174
L=1
NNX
i=1ℓ 
T(xi)⊤fϕ(xi),˜yi
, (7)
where fϕ(·) :X → ∆C−1(∆C−1⊂[0,1]Cis the C-dimensional simplex) is a differentiable 175
function represented by a neural network with parameters ϕandℓis a loss function usually using 176
cross-entropy (CE) loss. 177
The schematic diagram of the proposed framework is shown in Figure 2, and the pseudocode is 178
presented in Algorithm 3. 179
Algorithm 3 A framework of DTM
Input: Training set {(xi,yi)}N
i=1, pre-trained encoder fp, diffusion model ϵθ, classification neural
network fϕ.
1:Utilize input data to train fpor directly utilizing fpto extract features.
2:Perform K-means on feature space and estimate the transition matrix for each group to get data
{xi,Ti}N
i=1.
3:Train the diffusion model ϵθwith Algorithm 1.
4:Sample instance-dependent train matrix T(x)for any input image xiwith Algorithm 2.
5:Update the parameters of the classification network by incorporating the transition matrix T(xi)
into equation (7).
Output: Network parameters ϕ.
3.4 Matrix Transformation 180
Considering that the transition matrix typically require the sum of each rowPC
j=1Tij(x)is1, and 181
forTii(x)>Tij(x),∀j̸=i, we employ a transformation during the update learning process in our 182
practical experiments. 183
We utilize a C×Cweight matrix W= (wij)to assist in the process. Denote matrix Aas 184
Aii= 1 + σ(wii)for all i∈ {1,2, . . . , C }andAij=σ(wij)for all i̸=jwhere σis the sigmoid 185
function. Then we do the normalization Tij=AijPC
k=1Akjto get the transition matrix T. 186
Through this transformation, we ensure that the learned transition matrix has row sums equal to 1 and 187
that the diagonal elements are the largest in each row. In practical experiments, we apply the diffusion 188
modeling discussed in subsection 3.2 to the matrix W, and then transform it into the transition matrix 189
Tfor application. To simplify the notation, we uniformly use the term of transition matrix Wto 190
represent it, unless it leads to singularity. 191
4 Experiments 192
In this section, we present experimental findings to showcase the effectiveness of our proposed 193
method compared to other methods. We evaluate our approach on both synthetic instance-dependent 194
noisy datasets and real-world noisy datasets. 195
4.1 Datasets 196
We conduct experiments on following image classification datasets: CIFAR-10 and CIFAR-100 [ 13], 197
CIFAR-10N and CIFAR-100N [ 32], Clothing1M [ 35], Webvision and ILSVRC12 [ 16]. Among 198
them, CIFAR-10 and CIFAR-100 both have 32 ×32×3 color images including 50,000 training 199
images and 10,000 test images. CIFAR-10 has 10 classes while CIFAR-100 has 100 classes. We 200
generate instance-dependent noisy data on CIFAR-10 and CIFAR-100 with noise rates ranging from 201
10% to 50%, following the same generation method as in [ 33]. CIFAR-10N has three annotated 202
labels, namely Random1, Random 2 and Random 3. The "Aggregate" is the aggregation of three noisy 203
labels by majority voting, and the "Worst" is the dataset with the worst case. For CIFAR-100N, each 204
6image contains a coarse label and a fine label given by a human annotator. Clothing1M is a real-world 205
dataset consisting of 1 million training images, consisting of 14 categories. WebVision contains 2.4 206
million images crawled from the websites using the 1,000 concepts in ImageNet ILSVRC12, but only 207
the first 50 classes of the Google image subset are used in our experiments. For the validation set 208
selection in our BTR method, we randomly sampled 10 samples from each observed class for each 209
dataset to form the validation set, while the remaining samples were used for the training set. 210
4.2 Experimental Setup 211
For the pre-trained model, we employ the commonly used SimCLR model [ 4] from contrastive 212
learning, which directly performs self-supervised learning on input images without utilizing additional 213
datasets. For the diffusion model, we follow the setup similar to DDPM [ 11] to set β1= 10−4, βM= 214
0.02and utilize a similar U-Net network architecture but we reduce the Mfrom 1000 to 10 to 215
accelerate the learning process. As for the classification network, it may vary depending on the 216
specific dataset. More specifically, for CIFAR-10/10N, we use ResNet-18 as the backbone network 217
with batch size 128 and learning rate 0.05. For CIFAR-100/100N, we use ResNet-34 network 218
with batch size 128, learning rate 0.02. For clothing1M, we use a ResNet-50 pre-trained with 10 219
epochs, batch size 64, learning rate 0.002 for network and divided by 10 after the 5th epoch. We use 220
InceptionResNetV2 network on Webvision, with 100 epochs, batch size 32, learning rate 0.02 for 221
network and divided by 10 after the 30th and 60th epoch. For clustering, we utilize the K-means 222
method, where the number of clusters is set to 10 times the number of classes in the datasets. For 223
the initialization of transition matrix, the update method and setting are consistent with [ 17]. While 224
the updates for other parameters are performed using the stochastic gradient descent optimization 225
method. 226
Table 1: Test accuracy with instance-dependent noise on CIFAR-10/100.
CIFAR-10
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 88.86±0.23 86.93±0.17 82.42±0.44 76.68±0.23 58.93±1.54
V olMinNet 89.97±0.57 87.01±0.64 83.80±0.67 79.52±0.83 61.90±1.06
PeerLoss 90.89±0.07 89.21±0.63 85.70±0.56 78.51±1.23 59.08±1.05
BLTM 90.45±0.72 88.14±0.66 84.55±0.48 79.71±0.95 63.33±2.75
PartT 90.32±0.15 89.33±0.70 85.33±1.86 80.59±0.41 64.58±2.86
MEIDTM 92.91±0.07 92.26±0.25 90.73±0.34 85.94±0.92 73.77±0.82
SOP 93.58±0.31 93.07±0.45 92.42±0.43 89.83±0.77 82.52±0.97
CC 95.24±0.20 93.68±0.12 93.31±0.46 94.97±0.09 91.19±0.34
LRA 95.87±0.42 94.70±0.28 93.79±0.40 92.72±0.29 90.95±0.43
DTM 96.45±0.17 95.90±0.21 95.14±0.20 94.82±0.31 92.04±0.42
CIFAR-100
IDN-10% IDN-20% IDN-30% IDN-40% IDN-50%
CE 66.55±0.23 63.94±0.51 61.97±1.16 58.70±0.56 56.63±0.69
V olMinNet 67.78±0.62 66.13±0.47 61.08±0.90 57.35±0.83 52.60±1.31
PeerLoss 65.64±1.07 63.83±0.48 61.64±0.67 58.30±0.80 55.41±0.28
BLTM 68.42±0.42 66.62±0.85 64.72±0.64 59.38±0.65 55.68±1.43
PartT 67.33±0.33 65.33±0.59 64.56±1.55 59.73±0.76 56.80±1.32
MEIDTM 69.88±0.45 69.16±0.16 66.76±0.30 63.46±0.48 59.18±0.16
SOP 74.09±0.52 73.13±0.46 72.14±0.46 68.98±0.58 64.24±0.86
CC 80.52±0.22 79.61±0.19 77.34±0.31 76.58±0.25 72.68±0.36
LRA 81.20±0.16 80.53±0.29 78.22±0.19 76.55±0.31 72.97±0.51
DTM 82.96±0.25 82.04±0.32 80.87±0.45 78.56±0.60 74.85±0.56
4.3 Comparison Methods 227
In our experiments, we included the following common transition matrix and baseline methods as 228
comparison: (1) V olMinNet [ 17], (2) PeerLoss [ 21] (3) BLTM [ 37], (4) PartT [ 33], (5) MEIDTM 229
[6], as well as state-of-the-art methods for learning with noisy labels: (6) Co-teaching [ 10], (7) ELR+ 230
[18], (8) DivideMix [ 14], (9) SOP and SOP+ [ 19], (10) PGDF [ 5], (11) CC [ 40], (12) LRA [ 3] 231
with SimCLR as encoder similarly. 232
7Table 2: Test accuracy on CIFAR-10N and CIFAR-100N.
CIFAR-10N CIFAR-100N
Aggregate Random 1 Random 2 Random 3 Worst Noisy
Co-teaching 91.20±0.13 90.33±0.13 90.30±0.17 90.15±0.18 83.83±0.13 60.37±0.27
ELR+ 94.83±0.10 94.43±0.41 94.20±0.24 94.34±0.22 91.09±1.60 66.72±0.07
DivideMix 95.01±0.71 95.16±0.19 94.89±0.23 95.03±0.20 92.56±0.42 71.13±0.48
SOP+ 95.61±0.13 95.28±0.13 95.31±0.10 95.39±0.11 93.24±0.21 67.81±0.23
PGDF 95.35±0.12 94.95±0.21 94.78±0.34 94.92±0.28 94.22±0.29 67.76±0.35
CC 95.63±0.21 95.11±0.31 94.93±0.37 95.09±0.21 94.24±0.40 71.21±0.22
LRA 94.57±0.23 94.19±0.17 94.38±0.42 94.02±0.32 93.20±0.59 70.96±0.53
DTM 96.13±0.17 95.98±0.22 96.01±0.28 95.78±0.34 94.93±0.21 72.51±0.30
4.4 Experimental Results on Synthetic Datasets 233
We primarily validated our proposed method DTM against previous instance-based transition matrix 234
methods on synthetic CIFAR-10/100 noise datasets. These methods mainly focus on estimating the 235
transition matrix and some methods applicable to instance-dependent label noise. We performed 5 236
independent runs for each experimental configuration, and the average values and standard deviations 237
of each experiment are presented in Table 1. 238
The results demonstrate that our proposed DTR method outperforms other methods of the same 239
category across various noise rates. It is evident that traditional transition matrix methods for class- 240
dependent noise as V olMinNet exhibit subpar performance when handling instance-dependent noise. 241
While even advanced transition matrix methods for instance-dependent label noise such as BLTM, 242
ParT and MEIDTM, still show significant gaps compared to our method. 243
Furthermore, as the noise rates increase, the test accuracy of existing transition matrix methods 244
significantly decline. This is particularly pronounced in the case of CIFAR-100 with 50% instance- 245
dependent noise (IDN) data, where all transition matrix methods achieve test accuracy below 60%. 246
In contrast, our proposed DTR method achieves a remarkable test accuracy of 74.85%, showcasing 247
its exceptional performance. That demonstrates relatively robust performance of DTM with only a 248
slight decrease as the noise rate increases. 249
This experiment clearly demonstrates that there is a significant performance gap between previous 250
transition matrix methods and other advanced techniques, such as CC and LRA, when dealing with 251
instance-dependent noise problems. However, the experimental results indicate that our proposed 252
method DTM, which incorporates the diffusion model into the estimation of the transition matrix, 253
outperforms these advanced techniques, except for the case of 40% noise in CIFAR-100, where 254
our method slightly underperforms CC. It is evident that by leveraging the diffusion modeling to 255
estimate the transition matrix, we effectively incorporate the image’s feature information, leading to a 256
substantial improvement in the effectiveness of the transition matrix. 257
4.5 Experimental Results on Real-World Datasets 258
In addition to synthetic datasets, we also applied our method to real-world datasets and compared it 259
with other state-of-the-art techniques for handling label noise problems. The results are presented in 260
Table 2 and Table 3. 261
Table 3: Test accuracy on Clothing1M, Webvision and ILSVRC12.
Clothing1M Webvision ILSVRC12
Co-teaching 69.2 63.6 61.5
ELR+ 74.81 77.78 70.29
DivideMix 74.76 77.32 75.20
SOP+ 74.98 77.60 75.29
PGDF 75.19 81.47 75.45
CC 75.40 79.36 76.08
LRA 75.32 80.05 76.64
DTM 75.57 81.95 77.55
8The results demonstrate that regardless of the type of noise labels, whether it is aggregated, random, 262
or the worst-case scenario in CIFAR-10N, as well as in CIFAR-100N with more label categories, 263
our method consistently achieves the best results in handling real-world noise. When dealing with 264
large datasets like Clothing1M and complex image datasets like Webvision, DTM also performs 265
comparably to other state-of-the-art methods. 266
Through extensive experiments on five real-world datasets and the rusults on synthetic datasets above, 267
our method outperforms the LRA method, which also utilizes the diffusion model for label noise 268
problems. The LRA method models label diffusion with fewer dimensional information and lacks the 269
rationale of our method, which considers noise generation from a transfer probability distribution 270
perspective. The experiments demonstrate that our method achieves better learning performance by 271
effectively integrating the transition matrix with the diffusion model. 272
4.6 Ablation Study 273
Besides the aforementioned experiments, we conducted ablation studies on proposed DTM method 274
to assess the importance of each component. Table 4 presents the comparative results under 20% 275
and 40% instance-dependent noise rates, where "w/o" denotes "without". We conducted ablation 276
experiments on three components of our method, they are diffusion module, pre-trained encoder 277
module, and clustering module respectively. "w/o diffusion" indicates directly using the features 278
extracted by the pre-trained model for the classification task with the transition matrix. "w/o pre-train" 279
means not extracting features through self-supervised learning and directly utilizing the classification 280
network with the diffusion model. "w/o clustering" indicates that the initial transition matrix used for 281
the diffusion model is the same for all samples. 282
Table 4: Ablation study of DTR. The data in the table represents the test accuracy.
CIFAR-10 CIFAR-100
IDN-0.2 IDN-0.4 IDN-0.2 IDN-0.4
w/o pre-train 90.52 83.61 66.17 61.79
w/o clustering 92.25 88.35 71.93 66.47
w/o diffusion 93.74 91.66 79.82 73.51
DTR 95.90 94.82 82.04 78.56
From the results in Table 4, it can be observed that regardless of which component of diffusion 283
module, pre-trained encoder module and clustering module is missing, the performance is consistently 284
weaker compared to the original DTM. This indicates that each module plays a crucial role in our 285
method. Our approach effectively combines the transition matrix, diffusion model, and pre-trained 286
feature extraction, leading to significant improvements. 287
5 Conclusion 288
In this paper, we propose a method that models the transition matrix using diffusion models, incorpo- 289
rating the feature information extracted by a pre-trained encoder into the estimation of the transition 290
matrix. This approach enables the model to handle instance-dependent label noise with a wider range 291
of applicability. Experimental results on both synthetic and real-world noisy datasets demonstrate the 292
effectiveness of our proposed method. 293
References 294
[1]Görkem Algan and Ilkay Ulusoy. Image classification with deep learning in the presence of 295
noisy labels: A survey. Knowledge-Based Systems , 215:106771, 2021. 296
[2]Devansh Arpit, Stanisław Jastrz˛ ebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, 297
Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. 298
A closer look at memorization in deep networks. In International Conference on Machine 299
Learning , pages 233–242. PMLR, 2017. 300
9[3]Jian Chen, Ruiyi Zhang, Tong Yu, Rohan Sharma, Zhiqiang Xu, Tong Sun, and Changyou Chen. 301
Label-retrieval-augmented diffusion models for learning from noisy labels. arXiv preprint 302
arXiv:2305.19518 , 2023. 303
[4]Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework 304
for contrastive learning of visual representations. In International Conference on Machine 305
Learning , pages 1597–1607. PMLR, 2020. 306
[5]Wenkai Chen, Chuang Zhu, and Mengting Li. Sample prior guided robust model learning to 307
suppress noisy labels. In Joint European Conference on Machine Learning and Knowledge 308
Discovery in Databases , pages 3–19. Springer, 2023. 309
[6]De Cheng, Tongliang Liu, Yixiong Ning, Nannan Wang, Bo Han, Gang Niu, Xinbo Gao, 310
and Masashi Sugiyama. Instance-dependent label-noise learning with manifold-regularized 311
transition matrix estimation. In Proceedings of the IEEE/CVF Conference on Computer Vision 312
and Pattern Recognition , pages 16630–16639, 2022. 313
[7]Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu, and Mubarak Shah. Diffusion 314
models in vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 315
2023. 316
[8]Amit Daniely and Elad Granot. Generalization bounds for neural networks via approximate 317
description length. Advances in Neural Information Processing Systems , 32, 2019. 318
[9]Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adapta- 319
tion layer. In International Conference on Learning Representations , 2016. 320
[10] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi 321
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. 322
Advances in Neural Information Processing Systems , 31, 2018. 323
[11] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances 324
in Neural Information Processing Systems , 33:6840–6851, 2020. 325
[12] Zhimeng Jiang, Kaixiong Zhou, Zirui Liu, Li Li, Rui Chen, Soo-Hyun Choi, and Xia Hu. An 326
information fusion approach to learning with instance-dependent label noise. In International 327
Conference on Learning Representations , 2021. 328
[13] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 329
2009. 330
[14] Junnan Li, Richard Socher, and Steven CH Hoi. Dividemix: Learning with noisy labels as 331
semi-supervised learning. arXiv preprint arXiv:2002.07394 , 2020. 332
[15] Shikun Li, Xiaobo Xia, Hansong Zhang, Yibing Zhan, Shiming Ge, and Tongliang Liu. Esti- 333
mating noise transition matrix with label correlations for noisy multi-label learning. Advances 334
in Neural Information Processing Systems , 35:24184–24198, 2022. 335
[16] Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. Webvision database: 336
Visual learning and understanding from web data. arXiv preprint arXiv:1708.02862 , 2017. 337
[17] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end 338
label-noise learning without anchor points. In International Conference on Machine Learning , 339
pages 6403–6413. PMLR, 2021. 340
[18] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early- 341
learning regularization prevents memorization of noisy labels. Advances in Neural Information 342
Processing Systems , 33:20331–20342, 2020. 343
[19] Sheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by over- 344
parameterization. In International Conference on Machine Learning , pages 14153–14172. 345
PMLR, 2022. 346
[20] Yang Liu, Hao Cheng, and Kun Zhang. Identifiability of label noise transition matrix. In 347
International Conference on Machine Learning , pages 21475–21496. PMLR, 2023. 348
10[21] Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing 349
noise rates. In International Conference on Machine Learning , pages 6226–6236. PMLR, 2020. 350
[22] Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Erfani, and James Bailey. 351
Normalized loss functions for deep learning with noisy labels. In International Conference on 352
Machine Learning , pages 6543–6553. PMLR, 2020. 353
[23] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning 354
with noisy labels. Advances in Neural Information Processing Systems , 26, 2013. 355
[24] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. 356
Making deep neural networks robust to label noise: A loss correction approach. In Proceedings 357
of the IEEE Conference on Computer Vision and Pattern Recognition , pages 1944–1952, 2017. 358
[25] Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian, Yudong Tao, Maria Presa Reyes, Mei- 359
Ling Shyu, Shu-Ching Chen, and Sundaraja S Iyengar. A survey on deep learning: Algorithms, 360
techniques, and applications. ACM Computing Surveys (CSUR) , 51(5):1–36, 2018. 361
[26] Jun Shu, Qian Zhao, Zongben Xu, and Deyu Meng. Meta transition adaptation for robust deep 362
learning with noisy labels. arXiv preprint arXiv:2006.05697 , 2020. 363
[27] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv 364
preprint arXiv:2010.02502 , 2020. 365
[28] Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data 366
distribution. Advances in Neural Information Processing Systems , 32, 2019. 367
[29] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and 368
Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv 369
preprint arXiv:2011.13456 , 2020. 370
[30] Jialu Wang, Yang Liu, and Caleb Levy. Fair classification with group-dependent label noise. In 371
Proceedings of the 2021 ACM conference on fairness, accountability, and transparency , pages 372
526–536, 2021. 373
[31] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross 374
entropy for robust learning with noisy labels. In Proceedings of the IEEE/CVF International 375
Conference on Computer Vision , pages 322–330, 2019. 376
[32] Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning 377
with noisy labels revisited: A study using real-world human annotations. arXiv preprint 378
arXiv:2110.12088 , 2021. 379
[33] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, 380
Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent 381
label noise. Advances in Neural Information Processing Systems , 33:7597–7610, 2020. 382
[34] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi 383
Sugiyama. Are anchor points really indispensable in label-noise learning? Advances in Neural 384
Information Processing Systems , 32, 2019. 385
[35] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive 386
noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer 387
Vision and Pattern Recognition , pages 2691–2699, 2015. 388
[36] Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, 389
Bin Cui, and Ming-Hsuan Yang. Diffusion models: A comprehensive survey of methods and 390
applications. ACM Computing Surveys , 56(4):1–39, 2023. 391
[37] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. Estimating 392
instance-dependent bayes-label transition matrix using a deep neural network. In International 393
Conference on Machine Learning , pages 25302–25312. PMLR, 2022. 394
11[38] LIN Yong, Renjie Pi, Weizhong Zhang, Xiaobo Xia, Jiahui Gao, Xiao Zhou, Tongliang Liu, 395
and Bo Han. A holistic view of label noise transition matrix in deep learning and beyond. In 396
The Eleventh International Conference on Learning Representations , 2022. 397
[39] Yivan Zhang, Gang Niu, and Masashi Sugiyama. Learning noise transition matrix from only 398
noisy labels via total variation regularization. In International Conference on Machine Learning , 399
pages 12501–12512. PMLR, 2021. 400
[40] Ganlong Zhao, Guanbin Li, Yipeng Qin, Feng Liu, and Yizhou Yu. Centrality and consistency: 401
two-stage clean samples identification for learning with instance-dependent noisy labels. In 402
European Conference on Computer Vision , pages 21–37. Springer, 2022. 403
[41] Zhaowei Zhu, Yiwen Song, and Yang Liu. Clusterability as an alternative to anchor points 404
when learning with noisy labels. In International Conference on Machine Learning , pages 405
12912–12923. PMLR, 2021. 406
[42] Zhaowei Zhu, Jialu Wang, and Yang Liu. Beyond images: Label noise transition matrix 407
estimation for tasks with lower-quality features. In International Conference on Machine 408
Learning , pages 27633–27653. PMLR, 2022. 409
12NeurIPS Paper Checklist 410
1.Claims 411
Question: Do the main claims made in the abstract and introduction accurately reflect the 412
paper’s contributions and scope? 413
Answer: [Yes] 414
Justification: The main content and contributions of the work are reflected in the abstract 415
and introduction. 416
Guidelines: 417
•The answer NA means that the abstract and introduction do not include the claims 418
made in the paper. 419
•The abstract and/or introduction should clearly state the claims made, including the 420
contributions made in the paper and important assumptions and limitations. A No or 421
NA answer to this question will not be perceived well by the reviewers. 422
•The claims made should match theoretical and experimental results, and reflect how 423
much the results can be expected to generalize to other settings. 424
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 425
are not attained by the paper. 426
2.Limitations 427
Question: Does the paper discuss the limitations of the work performed by the authors? 428
Answer: [Yes] 429
Justification: In the experimental section, we analyze the applicability and limitations of our 430
method. 431
Guidelines: 432
•The answer NA means that the paper has no limitation while the answer No means that 433
the paper has limitations, but those are not discussed in the paper. 434
• The authors are encouraged to create a separate "Limitations" section in their paper. 435
•The paper should point out any strong assumptions and how robust the results are to 436
violations of these assumptions (e.g., independence assumptions, noiseless settings, 437
model well-specification, asymptotic approximations only holding locally). The authors 438
should reflect on how these assumptions might be violated in practice and what the 439
implications would be. 440
•The authors should reflect on the scope of the claims made, e.g., if the approach was 441
only tested on a few datasets or with a few runs. In general, empirical results often 442
depend on implicit assumptions, which should be articulated. 443
•The authors should reflect on the factors that influence the performance of the approach. 444
For example, a facial recognition algorithm may perform poorly when image resolution 445
is low or images are taken in low lighting. Or a speech-to-text system might not be 446
used reliably to provide closed captions for online lectures because it fails to handle 447
technical jargon. 448
•The authors should discuss the computational efficiency of the proposed algorithms 449
and how they scale with dataset size. 450
•If applicable, the authors should discuss possible limitations of their approach to 451
address problems of privacy and fairness. 452
•While the authors might fear that complete honesty about limitations might be used by 453
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 454
limitations that aren’t acknowledged in the paper. The authors should use their best 455
judgment and recognize that individual actions in favor of transparency play an impor- 456
tant role in developing norms that preserve the integrity of the community. Reviewers 457
will be specifically instructed to not penalize honesty concerning limitations. 458
3.Theory Assumptions and Proofs 459
Question: For each theoretical result, does the paper provide the full set of assumptions and 460
a complete (and correct) proof? 461
13Answer: [NA] 462
Justification: The focus of the work is on application and does not include a theoretical 463
proof component. 464
Guidelines: 465
• The answer NA means that the paper does not include theoretical results. 466
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 467
referenced. 468
•All assumptions should be clearly stated or referenced in the statement of any theorems. 469
•The proofs can either appear in the main paper or the supplemental material, but if 470
they appear in the supplemental material, the authors are encouraged to provide a short 471
proof sketch to provide intuition. 472
•Inversely, any informal proof provided in the core of the paper should be complemented 473
by formal proofs provided in appendix or supplemental material. 474
• Theorems and Lemmas that the proof relies upon should be properly referenced. 475
4.Experimental Result Reproducibility 476
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 477
perimental results of the paper to the extent that it affects the main claims and/or conclusions 478
of the paper (regardless of whether the code and data are provided or not)? 479
Answer: [Yes] 480
Justification: The paper provides a detailed description of the model construction and the 481
specifics of the experimental data. 482
Guidelines: 483
• The answer NA means that the paper does not include experiments. 484
•If the paper includes experiments, a No answer to this question will not be perceived 485
well by the reviewers: Making the paper reproducible is important, regardless of 486
whether the code and data are provided or not. 487
•If the contribution is a dataset and/or model, the authors should describe the steps taken 488
to make their results reproducible or verifiable. 489
•Depending on the contribution, reproducibility can be accomplished in various ways. 490
For example, if the contribution is a novel architecture, describing the architecture fully 491
might suffice, or if the contribution is a specific model and empirical evaluation, it may 492
be necessary to either make it possible for others to replicate the model with the same 493
dataset, or provide access to the model. In general. releasing code and data is often 494
one good way to accomplish this, but reproducibility can also be provided via detailed 495
instructions for how to replicate the results, access to a hosted model (e.g., in the case 496
of a large language model), releasing of a model checkpoint, or other means that are 497
appropriate to the research performed. 498
•While NeurIPS does not require releasing code, the conference does require all submis- 499
sions to provide some reasonable avenue for reproducibility, which may depend on the 500
nature of the contribution. For example 501
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 502
to reproduce that algorithm. 503
(b)If the contribution is primarily a new model architecture, the paper should describe 504
the architecture clearly and fully. 505
(c)If the contribution is a new model (e.g., a large language model), then there should 506
either be a way to access this model for reproducing the results or a way to reproduce 507
the model (e.g., with an open-source dataset or instructions for how to construct 508
the dataset). 509
(d)We recognize that reproducibility may be tricky in some cases, in which case 510
authors are welcome to describe the particular way they provide for reproducibility. 511
In the case of closed-source models, it may be that access to the model is limited in 512
some way (e.g., to registered users), but it should be possible for other researchers 513
to have some path to reproducing or verifying the results. 514
5.Open access to data and code 515
14Question: Does the paper provide open access to the data and code, with sufficient instruc- 516
tions to faithfully reproduce the main experimental results, as described in supplemental 517
material? 518
Answer: [No] 519
Justification: Upon acceptance of our paper, we will provide open-source code. The data we 520
used is from commonly available open-source datasets. 521
Guidelines: 522
• The answer NA means that paper does not include experiments requiring code. 523
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 524
public/guides/CodeSubmissionPolicy ) for more details. 525
•While we encourage the release of code and data, we understand that this might not be 526
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 527
including code, unless this is central to the contribution (e.g., for a new open-source 528
benchmark). 529
•The instructions should contain the exact command and environment needed to run to 530
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 531
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 532
•The authors should provide instructions on data access and preparation, including how 533
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 534
•The authors should provide scripts to reproduce all experimental results for the new 535
proposed method and baselines. If only a subset of experiments are reproducible, they 536
should state which ones are omitted from the script and why. 537
•At submission time, to preserve anonymity, the authors should release anonymized 538
versions (if applicable). 539
•Providing as much information as possible in supplemental material (appended to the 540
paper) is recommended, but including URLs to data and code is permitted. 541
6.Experimental Setting/Details 542
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 543
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 544
results? 545
Answer: [Yes] 546
Justification: The experimental section of the paper provides details of the model and data. 547
Guidelines: 548
• The answer NA means that the paper does not include experiments. 549
•The experimental setting should be presented in the core of the paper to a level of detail 550
that is necessary to appreciate the results and make sense of them. 551
•The full details can be provided either with the code, in appendix, or as supplemental 552
material. 553
7.Experiment Statistical Significance 554
Question: Does the paper report error bars suitably and correctly defined or other appropriate 555
information about the statistical significance of the experiments? 556
Answer: [Yes] 557
Justification: We conducted multiple repeated experiments to validate our approach and 558
performed ablation experiments. 559
Guidelines: 560
• The answer NA means that the paper does not include experiments. 561
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 562
dence intervals, or statistical significance tests, at least for the experiments that support 563
the main claims of the paper. 564
•The factors of variability that the error bars are capturing should be clearly stated (for 565
example, train/test split, initialization, random drawing of some parameter, or overall 566
run with given experimental conditions). 567
15•The method for calculating the error bars should be explained (closed form formula, 568
call to a library function, bootstrap, etc.) 569
• The assumptions made should be given (e.g., Normally distributed errors). 570
•It should be clear whether the error bar is the standard deviation or the standard error 571
of the mean. 572
•It is OK to report 1-sigma error bars, but one should state it. The authors should 573
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 574
of Normality of errors is not verified. 575
•For asymmetric distributions, the authors should be careful not to show in tables or 576
figures symmetric error bars that would yield results that are out of range (e.g. negative 577
error rates). 578
•If error bars are reported in tables or plots, The authors should explain in the text how 579
they were calculated and reference the corresponding figures or tables in the text. 580
8.Experiments Compute Resources 581
Question: For each experiment, does the paper provide sufficient information on the com- 582
puter resources (type of compute workers, memory, time of execution) needed to reproduce 583
the experiments? 584
Answer: [Yes] 585
Justification: We list the relevant details in the experimental section. 586
Guidelines: 587
• The answer NA means that the paper does not include experiments. 588
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 589
or cloud provider, including relevant memory and storage. 590
•The paper should provide the amount of compute required for each of the individual 591
experimental runs as well as estimate the total compute. 592
•The paper should disclose whether the full research project required more compute 593
than the experiments reported in the paper (e.g., preliminary or failed experiments that 594
didn’t make it into the paper). 595
9.Code Of Ethics 596
Question: Does the research conducted in the paper conform, in every respect, with the 597
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 598
Answer: [Yes] 599
Justification: We submitted the paper following the NeurIPS Code of Ethics. 600
Guidelines: 601
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 602
•If the authors answer No, they should explain the special circumstances that require a 603
deviation from the Code of Ethics. 604
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 605
eration due to laws or regulations in their jurisdiction). 606
10.Broader Impacts 607
Question: Does the paper discuss both potential positive societal impacts and negative 608
societal impacts of the work performed? 609
Answer: [Yes] 610
Justification: We discuss the positive implications of our work and ensure it does not have 611
any negative societal impact. 612
Guidelines: 613
• The answer NA means that there is no societal impact of the work performed. 614
•If the authors answer NA or No, they should explain why their work has no societal 615
impact or why the paper does not address societal impact. 616
16•Examples of negative societal impacts include potential malicious or unintended uses 617
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 618
(e.g., deployment of technologies that could make decisions that unfairly impact specific 619
groups), privacy considerations, and security considerations. 620
•The conference expects that many papers will be foundational research and not tied 621
to particular applications, let alone deployments. However, if there is a direct path to 622
any negative applications, the authors should point it out. For example, it is legitimate 623
to point out that an improvement in the quality of generative models could be used to 624
generate deepfakes for disinformation. On the other hand, it is not needed to point out 625
that a generic algorithm for optimizing neural networks could enable people to train 626
models that generate Deepfakes faster. 627
•The authors should consider possible harms that could arise when the technology is 628
being used as intended and functioning correctly, harms that could arise when the 629
technology is being used as intended but gives incorrect results, and harms following 630
from (intentional or unintentional) misuse of the technology. 631
•If there are negative societal impacts, the authors could also discuss possible mitigation 632
strategies (e.g., gated release of models, providing defenses in addition to attacks, 633
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 634
feedback over time, improving the efficiency and accessibility of ML). 635
11.Safeguards 636
Question: Does the paper describe safeguards that have been put in place for responsible 637
release of data or models that have a high risk for misuse (e.g., pretrained language models, 638
image generators, or scraped datasets)? 639
Answer: [NA] 640
Justification: There are no concerns in this regard regarding this work. 641
Guidelines: 642
• The answer NA means that the paper poses no such risks. 643
•Released models that have a high risk for misuse or dual-use should be released with 644
necessary safeguards to allow for controlled use of the model, for example by requiring 645
that users adhere to usage guidelines or restrictions to access the model or implementing 646
safety filters. 647
•Datasets that have been scraped from the Internet could pose safety risks. The authors 648
should describe how they avoided releasing unsafe images. 649
•We recognize that providing effective safeguards is challenging, and many papers do 650
not require this, but we encourage authors to take this into account and make a best 651
faith effort. 652
12.Licenses for existing assets 653
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 654
the paper, properly credited and are the license and terms of use explicitly mentioned and 655
properly respected? 656
Answer: [Yes] 657
Justification: The data and code used in our work are all publicly available and open-source. 658
Guidelines: 659
• The answer NA means that the paper does not use existing assets. 660
• The authors should cite the original paper that produced the code package or dataset. 661
•The authors should state which version of the asset is used and, if possible, include a 662
URL. 663
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 664
•For scraped data from a particular source (e.g., website), the copyright and terms of 665
service of that source should be provided. 666
•If assets are released, the license, copyright information, and terms of use in the 667
package should be provided. For popular datasets, paperswithcode.com/datasets 668
has curated licenses for some datasets. Their licensing guide can help determine the 669
license of a dataset. 670
17•For existing datasets that are re-packaged, both the original license and the license of 671
the derived asset (if it has changed) should be provided. 672
•If this information is not available online, the authors are encouraged to reach out to 673
the asset’s creators. 674
13.New Assets 675
Question: Are new assets introduced in the paper well documented and is the documentation 676
provided alongside the assets? 677
Answer: [NA] 678
Justification: The paper currently does not include any new assets. 679
Guidelines: 680
• The answer NA means that the paper does not release new assets. 681
•Researchers should communicate the details of the dataset/code/model as part of their 682
submissions via structured templates. This includes details about training, license, 683
limitations, etc. 684
•The paper should discuss whether and how consent was obtained from people whose 685
asset is used. 686
•At submission time, remember to anonymize your assets (if applicable). You can either 687
create an anonymized URL or include an anonymized zip file. 688
14.Crowdsourcing and Research with Human Subjects 689
Question: For crowdsourcing experiments and research with human subjects, does the paper 690
include the full text of instructions given to participants and screenshots, if applicable, as 691
well as details about compensation (if any)? 692
Answer: [NA] 693
Justification: The paper does not involve crowdsourcing nor research with human subjects. 694
Guidelines: 695
•The answer NA means that the paper does not involve crowdsourcing nor research with 696
human subjects. 697
•Including this information in the supplemental material is fine, but if the main contribu- 698
tion of the paper involves human subjects, then as much detail as possible should be 699
included in the main paper. 700
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 701
or other labor should be paid at least the minimum wage in the country of the data 702
collector. 703
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 704
Subjects 705
Question: Does the paper describe potential risks incurred by study participants, whether 706
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 707
approvals (or an equivalent approval/review based on the requirements of your country or 708
institution) were obtained? 709
Answer: [NA] 710
Justification: The paper does not involve crowdsourcing nor research with human subjects. 711
Guidelines: 712
•The answer NA means that the paper does not involve crowdsourcing nor research with 713
human subjects. 714
•Depending on the country in which research is conducted, IRB approval (or equivalent) 715
may be required for any human subjects research. If you obtained IRB approval, you 716
should clearly state this in the paper. 717
•We recognize that the procedures for this may vary significantly between institutions 718
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 719
guidelines for their institution. 720
•For initial submissions, do not include any information that would break anonymity (if 721
applicable), such as the institution conducting the review. 722
18