Under review as submission to TMLR
Node-Level Diﬀerentially Private Graph Neural Networks
Anonymous authors
Paper under double-blind review
Abstract
Graph Neural Networks (GNNs) are a popular technique for modelling graph-structured
data and computing node-level representations via aggregation of information from the
neighborhood of each node. However, this aggregation implies increased risk of revealing
sensitive information, as a node can participate in the inference for multiple nodes. This
implies that standard privacy preserving machine learning techniques, such as diﬀerentially
private stochastic gradient descent (DP-SGD) – which are designed for situations where
each data point participates in the inference for one point only – either do not apply,
or lead to inaccurate models. In this work, we formally deﬁne the problem of learning
GNN parameters with node-level privacy, and provide an algorithmic solution with a strong
diﬀerential privacy guarantee. We employ a careful sensitivity analysis and provide a non-
trivial extension of the privacy-by-ampliﬁcation technique to the GNN setting. An empirical
evaluation on standard benchmark datasets demonstrates that our method is indeed able
to learn accurate privacy–preserving GNNs which outperform both private and non-private
methods that completely ignore graph information.
1 Introduction
Graph Neural Networks (GNNs) (Kipf & Welling, 2016; Veličković et al., 2018; Hamilton et al., 2017; Gilmer
et al., 2017) are powerful modeling tools that capture structural information provided by a graph. Conse-
quently, they have become popular in a wide array of domains such as the computational sciences (Ktena
et al., 2018; Ahmedt-Aristizabal et al., 2021; McCloskey et al., 2019), computer vision (Wang et al., 2019),
and natural language processing (Yao et al., 2019). GNNs have become an attractive solution for modeling
users interacting with each other; each user corresponds to a node of the graph and the user-level interactions
correspond to edges in the graph. Thus, GNNs are popular for solving a variety of recommendation and
ranking tasks, where it is challenging to obtain and store user data (Fan et al., 2019; Budhiraja et al., 2020;
Levy et al., 2021). However, such GNN-based solutions are challenging to deploy as they are susceptible to
leaking highly sensitive private information of users. Standard ML models – without GNN-style neighbor-
hood data aggregation – are already known to be highly susceptible to leakage of sensitive information about
the training data (Carlini et al., 2019). The risk of leakage of private information is even higher in GNNs
as each prediction is based on the node itself and aggregated data from its neighborhood. As depicted in
Figure 1, there are two types of highly-sensitive information about an individual node that can be leaked in
the GNN setting:
•the features associated with the node,
•the labels associated with the node, and,
•the connectivity (relational) information of the node in the graph.
Inthiswork, westudytheproblemofdesigningalgorithmstolearnGNNswhilepreserving node-levelprivacy.
We use diﬀerential privacy as the notion of privacy (Dwork et al., 2006) of a node, which requires that the
algorithm should learn roughly similar GNN parameters despite the replacement of an entire node and all
the data points associated with that node. Our proposed method preserves the privacy of the features of
1Under review as submission to TMLR
Message 
Passing GNN 
Figure 1: In a GNN, every node participates in the predictions for neighbouring nodes, intro-
ducing new avenues for privacy leakage. The user corresponding to the center node and all of
their private information is highlighted in blue.
each node, their labels as well as their connectivity information. Our method adapts the standard DP-SGD
method (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016) to the node-level privacy setting.
DP-SGD is an extension of standard SGD (stochastic gradient descent) that bounds per-user contributions
to the batched gradient by clipping per-example gradient terms. However, standard analysis of DP-SGD
does not directly extend to GNNs, as each per-example gradient term in GNNs can depend on private data
frommultiple nodes . The key technical contribution of our work is two-fold:
•We propose a graph neighborhood sampling scheme that enables a careful sensitivity analysis for
DP-SGD in multi-layer GNNs.
•We extend the standard privacy by ampliﬁcation technique for DP-SGD in multi-layer GNNs, where
one per-example gradient term can depend on multiple users.
Together, this allows us to learn the parameters of a GNN with strong node-level privacy guarantees, as
evidenced by empirical results on benchmark datasets in Section 6.
2 Related Work
Diﬀerentially Private SGD (DP-SGD) (Song et al., 2013; Bassily et al., 2014; Abadi et al., 2016) has been
used successfully to train neural network models to classify images (Abadi et al., 2016) and text (Anil et al.,
2021), by augmenting the standard paradigm of gradient-based training to be diﬀerentially private. Edge-
level privacy in GNNs ensures that the existence of an edge does not impact the output signiﬁcantly (Wu
et al., 2021b; Epasto et al., 2022). However, such methods do not protect the entirety of each node’s private
data, and hence provide much weaker privacy guarantees. Private GNNs have also been studied from the
perspective of local privacy (Sajadmanesh & Gatica-Perez, 2020; Sajadmanesh et al., 2022), where each node
performs its share of the GNN computation locally and sends noisy versions of its data to neighbouring
nodes so as to learn shared weights. However, such an algorithm needs to correct for the bias in both the
features and labels. Crucially, the analysis of this method only applies to GNNs with linear neighborhood
aggregation functions. In contrast, the methods we propose can be employed with a large class of GNN
models called ‘message-passing’ GNNs, described in Section 3. (Wu et al., 2021a) utilizes private GNNs for
recommendation systems, but their method assumes a bipartite graph structure, and cannot be naturally
extended to homogeneous graphs. Other approaches employ federated learning (Zhou et al., 2020), but only
guarantee that the GNN neighbourhood aggregation step is diﬀerentially private, which is insuﬃcient to
guarantee node-level privacy as we have deﬁned above. Finally, several papers provide privacy-preserving
GNNs (Shan et al., 2021) but these do not use the formal notion of DP and provide signiﬁcantly weaker
privacy guarantees. Note that the general concept of node-level diﬀerential privacy has been studied before
2Under review as submission to TMLR
(Kasiviswanathan et al., 2013; Blocki et al., 2012; Raskhodnikova & Smith, 2016; Karwa et al., 2011; Borgs
etal.,2015;2018). Thesemethodsgenerallyestimateglobalgraph-levelstatisticsanddonotsupportlearning
methods such as GNNs. In contrast, our approach predicts local node-level statistics (such as the label of a
node) while preserving node-level privacy.
3 Problem Formulation and Preliminaries
Consider a graph dataset G= (V,E,X,Y)withdirectedgraphG= (V,E)represented by a adjacency matrix
A∈{0,1}n×n.nis the number of nodes in G,Vdenotes the node set, Edenotes the edge set. Each node v
in the graph is equipped with a feature vector Xv∈Rd;X∈Rn×ddenotes the feature matrix. Y∈Rn×Q
is the label matrix and yvis the label for the v-th node over Qclasses. Note that many of the labels in
the label vector can be missing, which models the semi-supervised setting. In particular, we assume that
node labels yvare only provided for a subset of nodes Vtr⊂V, called the training set. We are interested in
predicting labels for the remaining nodes in the graph.
Traditional Machine Learning Models : Traditional non-graph based methods such as multi-layer per-
ceptrons (MLPs) perform predictions independently for each node:
/hatwideyv=MLP(Xv;Θ) (1)
We see that the prediction by the MLP for node vonly depend on the node’s feature vector Xvand the
model parameters Θ.
Graph Neural Networks : In contrast, a graph neural network (GNN) uses the relational information
between the nodes of the graph, which is captured by the adjacency matrix A. To generate the prediction
for a nodev, the GNN uses features from other nodes uin the local graph neighbourhood of v. Each layer
in a GNN captures and aggregates features from a larger neighbourhood. Mathematically, a r-layer GNN1
can be generally represented by the following operations:
/hatwideyv=GNN(A,X,v;Θ) :=fdec(fagg({fenc(Xu)|Ar
vu/negationslash= 0})) (2)
where/hatwideyvis the prediction from the GNN for a given node v,fencis the encoder function that encodes node
features with parameters Θenc,faggis the neighborhood aggregation function with parameters Θagg,fdecis
the prediction decoder function with parameters Θdec, and Θ := (Θ enc,Θagg,Θdec). Thus, we can represent
anr-layer GNN by an aggregation over the local r-hop neighborhood of each node. This neighborhood can
be represented as a subgraph of Grooted at the node.
Given the graph dataset G, the goal is to learn parameters of a GNN while preserving privacy of individual
nodes.
While our results apply to most classes of GNN models (Hamilton et al., 2017; Veličković et al., 2018; Xu
et al., 2018), for simplicity, we focus on Graph Convolutional Network (GCN) (Kipf & Welling, 2016) with
additional results for the Graph Isomorphism Network (GIN) (Xu et al., 2018) and the Graph Attention
Network (GAT) (Veličković et al., 2018) in the Appendix. Thus, ‘learning’ a GNN is equivalent to ﬁnding
parameters Θ := (Θ enc,Θagg,Θdec)that minimize a suitable loss:
Θ∗= arg min
ΘL(G,Θ) :=/summationdisplay
v∈V/lscript(/hatwideyv;yv), (3)
where/lscript:RQ×Q→Ris a standard loss function such as categorical or sigmoidal cross-entropy.
Deﬁnition 1 (Adjacent Graph Datasets) .Two graph datasets GandG/primeare said to be node-level adjacent
if one can be obtained by adding or removing a node (with its features, labels and associated edges) to the
other. That is, GandG/primeare exactly the same except for the v-th node, i.e., Xv,yvandAvdiﬀer in the
two datasets.
1This is sometimes referred to as a r-hop GNN in the literature.
3Under review as submission to TMLR
Informally,Ais said to be node-level diﬀerentially-private if the addition or removal of a node in A’s input
does not aﬀectA’s output signiﬁcantly.
Deﬁnition 2 (Node-level Diﬀerential Privacy (Kasiviswanathan et al., 2013)) .Consider any randomized
algorithmAthat takes as input a graph dataset. Ais said to be (α,γ)node-level Rényi diﬀerentially-
private(Mironov, 2017a) if, for every pair of node-level adjacent datasets GandG/prime:Dα(A(G)/bardblA(G/prime))≤γ
where the Rényi divergence Dαof orderαbetween two random variables PandQis deﬁned as
Dα(P/bardblQ) =1
α−1lnEx∼Q/bracketleftBig
P(x)
Q(x)/bracketrightBigα
.
Note that we use Rényi diﬀerentially-private (RDP) (Mironov, 2017a) as the formal notion of diﬀerential
privacy (DP), as it allows for tighter composition of DP across multiple steps. This notion is closely related
to the standard (ε,δ)-diﬀerential privacy (Dwork et al., 2006); Proposition 3 of Mironov (2017a) states that
any(α,γ)-RDP mechanism also satisﬁes (γ+log 1/δ
α−1,δ)-diﬀerential privacy for any δ∈(0,1). Thus, we seek
to ﬁnd Θby optimizing Equation 3 while ensuring RDP.
Deﬁnition 3. TheK-restricted node-level sensitivity ∆K(f)of a function fdeﬁned on graph datasets
is∆K(f) = maxG,G/primenode-level adjacent
in-deg (G),in-deg (G/prime)≤K/bardblf(G)−f(G/prime)/bardbl2.
Deﬁnition 4. We deﬁne the clipping operator ClipC(.)for any vector or matrix vas:ClipC(v) =
min/parenleftBig
1,C
/bardblv/bardblF/parenrightBig
·v., where/bardbl·/bardblFdenotes the Frobenius norm.
4 Sampling Subgraphs with Occurrence Constraints
To bound the sensitivity of the mini-batch gradient in Algorithm 4, we must carefully bound the maximum
number of occurrences of any node in the graph across all training subgraphs. To ensure that these con-
straints are met for any r-layer GNN, we propose SAMPLE−SUBGRAPHS (Algorithm 3) to output a set of
training subgraphs. In short, we ﬁrst subsample the edgelists of each node with SAMPLE−EDGELISTS
(Algorithm 1), such that each node shows up at maximum Ktimes over all edge lists. Then in
RECURSIVE−NEIGHBORHOOD (Algorithm 2), we recursively compute the r-depth neighborhood by using
the sampled edgelists and the (r−1)-depth neighborhood. Note that the 0-depth neighborhood is simply
the node itself. This subsampled r-depth neighborhood forms the subgraph for each node.
Note that the common practice (Hamilton et al., 2017) of sampling to restrict the out-degree of every node
is insuﬃcient to provide such a guarantee, as the in-degree of a node (and hence, the number of occurrences
of that node in other subgraphs) can be very large. Once the model parameters have been learnt, no
restrictions are needed at inference time. This means GNN predictions for the ‘test’ nodes can use the entire
neighborhood information.
Algorithm 1: SAMPLE−EDGELISTS : Sampling the Adjacency Matrix with In-Degree Constraints
Data:GraphG= (V,E,X,Y), Training set Vtr, Maximum in-degree K.
Result: Set of sampled edgelists Evfor each node v∈V.
forv∈Vdo
Construct the incoming edgelist over training set: REv←{u|(u,v)∈Eandu∈Vtr}
Sample incoming edgelists. Each edge is sampled independently with a probability p=K
2|REv|:
REv←sample (REv)
The nodes with in-degree greater than Kare dropped from all edgelists.
end
forv∈Vdo
Reverse incoming edgelists to get sampled edgelists Ev:Ev←{u|v∈REu}
end
return{Ev|v∈V}.
Lemma 1 (SAMPLE−SUBGRAPHS Satisﬁes Occurrence Constraints) .LetGbe any graph with set of
training nodes Vtr. Then, for any K,r≥0, the number of occurrences of any node in the set of training
4Under review as submission to TMLR
Algorithm 2: RECURSIVE−NEIGHBORHOOD : Recursively Computing Node Neighborhoods upto
Depth
Data:Root node v, Edgelists E, Maximum depth r.
Result: SubgraphSvrepresenting the r-depth neighborhood rooted at v.
Ifr= 0,return{v}.
Add edges from vto its neighbours’ subgraphs:
Sv←{v}∪{RECURSIVE−NEIGHBORHOOD (u,E,r−1)|u∈Ev}
returnSv.
Algorithm 3: SAMPLE−SUBGRAPHS : Sampling Local Neighborhoods with Occurrence Constraints
Data:GraphG= (V,E,X,Y), Training set Vtr, Maximum in-degree K, GNN layers r.
Result: Set of subgraphs Svfor each node v∈Vtr.
Obtain the set of sampled edgelists: E←SAMPLE−EDGELIST (G,Vtr,K)
forv∈Vtrdo
Sv←RECURSIVE−NEIGHBORHOOD (v,E,r)
end
return{Sv|v∈Vtr}.
subgraphs SAMPLE−SUBGRAPHS (G,Vtr,K,r )is bounded above by N(K,r), where:
N(K,r) =r/summationdisplay
i=0Ki=Kr+1−1
K−1∈Θ(Kr)
In the interest of space, we have supplied the proof of Lemma 1 in Appendix A.
5 Learning Graph Neural Networks (GNNs) via DP-SGD
Algorithm 4: DP-GNN (SGD): Training Diﬀerentially Private Graph Neural Networks with SGD
Data:GraphG= (V,E,X,Y), GNN model GNN, Number of GNN layers r, Training set Vtr, Loss
functionL, Batch size m, Maximum in-degree K, Learning rate η, Clipping threshold C, Noise
standard deviation σ, Maximum training iterations T.
Result: GNN parameters ΘT.
Note thatVtris the subset of nodes for which labels are available (see Paragraph 1 of Section 3).
Construct the set of training subgraphs with Algorithm 3: Str←SAMPLE−SUBGRAPHS (G,Vtr,K,r ).
Initialize Θ0randomly.
fort= 0toTdo
Sample setBt⊆Strof sizemuniformly at random from all subsets of Str.
Compute the update term utas the sum of the clipped gradient terms in the mini-batch Bt:
ut←/summationtext
Sv∈BtClipC(∇Θ/lscript(GNN(A,X,v;Θt);yv))
Add independent Gaussian noise to the update term: ˜ut←ut+N(0,σ2I)
Update the current estimate of the parameters with the noisy update: Θt+1←Θt−η
m˜ut
end
In this section, we describe a variant of DP-SGD (Bassily et al., 2014) designed speciﬁcally for GNNs, and
show that our method guarantees node-level DP (Deﬁnition 2). Assuming we are running a r-layer GNN, we
ﬁrst subsample the local r-hop neighborhood of each node to ensure that each node has a bounded number of
neighbors and inﬂuences a small number of nodes. Next, similar to the standard mini-batch SGD technique,
we sample a subset Btofmsubgraphs chosen uniformly at random from the set Strof training subgraphs.
In contrast to the standard mini-batch SGD, that samples points with replacement for constructing a mini-
batch, our method samples mini-batch Btuniformly from the set of all training subgraphs. This distinction
is important for our privacy ampliﬁcation result. Once we sample the mini-batch, we apply the standard
5Under review as submission to TMLR
DP-SGD procedure of computing the gradient over the mini-batch, clipping the gradient and adding noise
to it, and then use the noisy gradients for updating the parameters.
However, DP-SGD requires each update to be diﬀerentially private. In standard settings where each gradient
term in the mini-batch corresponds to only one point, we only need to add O(C)noise – where Cis the
clipping norm of the gradient – to ensure privacy. However, in the case of GNNs with node-level privacy,
perturbing one node/point /hatwidevcan have impact on the loss terms corresponding to all its neighbors. Thus,
to ensure the privacy of each update, we add noise according to the sensitivity of aggregated gradient:
∇ΘL(Bt;Θt) :=/summationtext
Sv∈BtClipC(∇Θ/lscript(GNN(A,X,v;Θt);yv))with respect to any individual node /hatwidev, which
we bound via careful subsampling of the input graph. In traditional DP-SGD, a crucial component in getting
a better privacy/utility trade-oﬀ over just adding noise according to the sensitivity of the minibatch gradient,
is privacy ampliﬁcation by sampling (Kasiviswanathan et al., 2008; Bassily et al., 2014). This says that if an
algorithmAisε-DP on a data set D1, then on a random subset D2⊆D1it satisﬁes roughly|D2|
|D1|(eε−1)-DP.
Unlike traditional ERM problems, we cannot directly use this result in the context of GNNs. The reason is
again that on two adjacent data sets, multiple loss terms corresponding to /hatwidevand itsr-hop neighborsN(r)
/hatwidevget
modiﬁed. To complicate things further, the minibatch Btthat gets selected may only contain a small random
subset ofN(r)
/hatwidev. To address these issues, we provide a new privacy ampliﬁcation theorem (Theorem 1). To
prove the theorem, we adapt (Feldman et al., 2018, Lemma 25) – that shows a weak form of convexity of
Rényi divergence – for our speciﬁc instance, and provide a tighter bound by exploiting the special structure
in our setting along with the above bound on sensitivity.
Theorem 1 (Ampliﬁed Privacy Guarantee for any r-Layer GNN) .Consider the loss function Lof the form:
L(G,Θ) =/summationdisplay
v∈Vtr/lscript(GNN(A,X,v;Θt);yv).
Recall,Nis the number of training nodes Vtr,Kis the maximum in-degree of the input graph, ris the
number of GNN layers, and mis the batch size. For any choice of the noise standard deviation σ >0and
clipping threshold C, every iteration tof Algorithm 4 is (α,γ)node-level Rényi DP, where:
γ=1
α−1lnEρ/bracketleftbigg
exp/parenleftbigg
α(α−1)·2ρ2C2
σ2/parenrightbigg/bracketrightbigg
, ρ∼Hypergeometric/parenleftbigg
N,Kr+1−1
K−1,m/parenrightbigg
.
Hypergeometric denotes the standard hypergeometric distribution (Forbes et al., 2011). By the standard
composition theorem for Rényi Diﬀerential Privacy (Mironov, 2017a), over Titerations, Algorithm 4 is
(α,γT )node-level Rényi DP, where γandαare deﬁned above.
In the interest of space, we have supplied the proof of Theorem 1 in Appendix B.
Remark 1 : Roughly, for a 1-layer GNN with m/greatermuchK, the above bound implies σ=O(mK/N )noise to be
added per update step to ensure Rényi DP with α=O(1)andγ=O(1). Note that the standard DP-SGD
style privacy ampliﬁcation results do not apply to our setting as each gradient term can be impacted by
multiple nodes.
Remark 2 : We provide node-level privacy, which means that our method preserves the neighborhood
information of every node. But, we require a directed graph structure, so that changing a row in the
adjacency matrix does not impact any other part of the matrix. This is a natural assumption in a variety of
settings. For example, when the graph is constructed by ‘viewership’ data in social networks, following the
rule that edge (v,v/prime)exists iﬀ user vviewed a post from user v/prime.
Remark 3 : The careful reader may notice that the sampling procedure ensures that the number of gradient
terms aﬀected by the removal of a single node is bounded. A natural question to ask is then, can we directly
use group privacy guarantees provided by RDP for our analysis? The answer is yes; however, the resulting
bounds are much weaker, because the privacy guarantee of group privacy scales exponentially with the size of
the group (Mironov, 2017b), which is N(K,r)here. In comparison, Theorem 1 guarantees that the privacy
guarantee scales only linearly with N(K,r).
6Under review as submission to TMLR
Remark 4 : For a similar reason as Remark 3, and since privacy ampliﬁcation by subsampling requires
uniform sampling over all nodes (and their corresponding subgraphs) and not edges, one cannot use group
privacy guarantees with edge-level diﬀerentially private GNNs to obtain an equivalent of Theorem 1.
Remark 5 : We similarly adapt a DP version of the Adam (Kingma & Ba, 2014) optimizer to the GNN
setting, called DP-GNN (Adam), with the same privacy guarantees as DP-GNN (SGD).
Computational Complexity : The computational cost and memory requirements of Algorithm 4 is similar
to standard DP-SGD which requires computing per-example gradients which are then clipped. Computation
of these gradients slows down training by approximately 10times (Subramani et al., 2020) compared to the
base model. Accelerating DP training is an active area of research (Bu et al., 2021).
Privacy at Inference Time : Theorem 1 guarantees that the GNN parameters Θthat are learnt via
Algorithm 4 preserve privacy. However, unlike standard ML models where prediction for each point depends
only on the model parameters Θand the point itself, the privacy of Θdoes not imply that inference using a
GNN model will be privacy preserving. In general, the inference about node vcan reveal information about
its neighborsNv. Broadly, there are two settings where we can infer labels for a given node while preserving
privacy:
1.Transductive Setting : Each node has access to the features of its neighbors. In this setting,
the aggregation of features from the neighbors does not lead to any privacy loss. Several real-world
problems admit such a setting: for example, in social networks where any user has access to a variety
of activities/documents/photos of their friends (neighbors). See Section 6.1 for a description of the
exact setting we consider for our empirical studies.
2.Inductive Setting : Training and test graph datasets are disjoint. In this setting, the goal is to
privately learn Θusing the training graph, that can be ‘transferred’ to the test graphs. Additionally,
the feature information is shared publicly within test graph dataset nodes. A variety of problems
can be modeled by this setting: organizations can be represented by a graph over its employees, with
the goal to learn a private ranking/recommendation model that can easily be adapted for completely
distinct organizations. Section 6.2 discusses empirical studies in this setting.
3. Node features are completely private. In this setting, a node vdoes not have direct access to the
features of its neighbors Nv. Here, the standard GCN model is not directly applicable, but we can
still apply GCNs by aggregating the neighborhood features with noise. Generally, the resulting
prediction for a node would be meaningful only if the degree of the node is reasonably large.
6 Experimental Results
In this section, we present empirical evaluation of our method on standard benchmark datasets for large
graphs from the Open Graph Benchmark (OGB) suite (Hu et al., 2020) and GraphSAGE (Hamilton et al.,
2017), and evaluate our method in both transductive and inductive settings. The goal is to demonstrate that
our method (DP-GNN) can indeed learn privacy preserving GNNs accurately. In particular, we benchmark
the following methods:
•DP-GCN : Our DP-GNN method (Algorithm 4) applied to a 1-layer GCN (in the transductive and
inductive settings) and a 2-layer GCN (in the inductive settings) with an MLP as the encoder and
the decoder.
•GCN: A1-layer GCN (in transductive and inductive settings) and a 2-layer GCN (in inductive
settings) with MLP as the encoder and decoder. In general, this non-private GCN model bounds
the maximum accuracy we can hope to achieve from our DP-GCN model.
•MLP: A standard multi-layer perceptron (MLP) architecture on the raw node features as proposed
in prior works (Hu et al., 2020), which does not utilize any graph information.
•DP-MLP : A DP version of a standard MLP trained using DP-Adam.
7Under review as submission to TMLR
Sampling Input Graphs: Theorem 1 requires an upper bound Kon the in-degree of the training nodes
in the input graph G. For this reason, we subsample the input graph Gwith Algorithm 1. In Section 6.4,
we show that the performance of DP-GNN models is not overly sensitive to the choice of K.
Gradient Clipping: For DP-GNN and DP-MLP, we perform layer-wise gradient clipping: the gradients
corresponding to the encoder, aggregation and decoder functions are clipped independently with diﬀerent
clipping thresholds. For each layer, the clipping threshold Cin Algorithm 4 is chosen as the 75th percentile of
gradient norms for that layer at initialization on the training data. For simplicity, we perform this estimation
of the clipping threshold in a non-private manner, as has been done in previous research (Abadi et al., 2016).
We set the noise for each layer σsuch that the noise multiplier λ=σ
2C·N(K,r)is identical for each layer,
whereσ/λis essentially the sensitivity. It is not hard to observe that the overall privacy cost only depends
onλ.
Model Selection: We select the ﬁnal model hyperparameters based on the performance on the validation
set (separate from the test set). Training was performed until the privacy budget was exhausted. We report
the mean and standard deviation of the ﬁnal model performance on the test set over nine independent runs
in Table 1 and Table 2 in the transductive and inductive settings respectively.
Currently, practitioners can not use sensitive graph information in data-critical scenarios, and have to com-
pletely discard GNN-based models due to privacy concerns . Below, we demonstrate that DP-GNN is able
to provide more accurate solutions than standard methods that completely discard the graph information,
while guaranteeing node-level privacy.
6.1 Results in the Transductive Setting
Table 1:Test performance of DP-GCN in the transductive setting, with privacy budget ε≤10.
Model ogbn-arxiv ogbn-products ogbn-mag reddit
Accuracy Accuracy Accuracy F1-Score
GCN (1-layer) 67.759 ±0.394 75.893±0.479 34.074±0.42 94.074±0.07
DP-GCN(Adam) 61.133 ±0.288 67.299±0.103 28.373±0.297 91.888±0.145
DP-GCN(SGD) 62.382 ±0.94 66.698±0.038 26.785±0.931 89.474±0.11
MLP 55.236 ±0.298 61.157±0.313 27.121±0.239 72.347±0.13
DP-MLP 50.803 ±0.167 56.006±0.132 25.26±0.068 69.041±0.075
We ﬁrst study the ‘transductive’ setting where the features of the test nodes are available during training.
At inference time, each node has access to the features of its neighbors. Recall that we focus on 1-layer
GNNs in this setting. Table 1 compares the performance of DP-GCN against baselines on the ogbn-arxiv,
ogbn-products, ogbn-mag and reddit-transductive datasets. Overall, we observe that our proposed method
DP-GCN signiﬁcantly outperforms the non-private MLP (which does not use any graph information) and
private DP-MLP (which does not use any graph information but trained using standard DP-Adam) baselines
on all of the datasets and with a privacy budget of ε≤12. For example, for ogbn-arxiv and ogbn-products,
our method DP-GCN (SGD) is about 6% more accurate than MLP and 10% more accurate than DP-MLP.
For reddit, our method is about 20% more accurate than MLP and DP-MLP. Figure 2 provides a comparison
of epsilon (privacy guarantee) versus test set performance for the three benchmark datasets. As the privacy
budget increases in Figure 2, the performance gap between DP-GCN and the baseline MLP and DP-MLP
widens. On all datasets, DP-GCN (Adam) outperforms both MLP and DP-MLP for a privacy budget of
ε≤12.
Typically, for training non-convex learning models with user-level DP, ε≤10has become a popular
choice (Papernot et al., 2020; Kairouz et al., 2021). As the problem is more challenging in the case of
GNNs – multiple nodes can aﬀect inference for a given node and we intend to protect privacy at the node-
level – a higher εseems like a reasonable choice to encourage reasonable solutions. Note that our algorithms
satisfy stronger Rényi DP properties (Mironov, 2017a), which provide additional protection over traditional
(ε,δ)-DP guarantees.
8Under review as submission to TMLR
2 4 6 8 10
Epsilon (Privacy Parameter)40455055606570T est Accuracy
(a) ogbn-arxiv
5 6 7 8 9 10 11 12
Epsilon (Privacy Parameter)45505560657075T est Accuracy (b) ogbn-products
0 2 4 6 8 10 12
Epsilon (Privacy Parameter)101520253035T est Accuracy
GCN
DP-GCN
MLP
DP-MLP
(c) ogbn-mag
0 2 4 6 8 10 12
Epsilon (Privacy Parameter)405060708090T est Accuracy GCN (2-layer)
DP-GCN (1-layer)
DP-GCN (2-layer)
MLP
DP-MLP (d) reddit-disjoint
Figure 2: (a), (b), (c): Performance of the 1-layer DP-GCN models and baselines with respect to privacy
budgetεon ogbn-arxiv, ogbn-products and ogbn-mag datasets. (d): Performance of the 1-layer and 2-layer
DP-GCN models on the reddit-disjoint dataset.
9Under review as submission to TMLR
6.2 Results in the Inductive Setting
Table 2:Test performance of DP-GCN in the inductive setting, with privacy budget ε≤12.
Model ogbn-arxiv-disjoint ogbn-arxiv-clustered reddit-disjoint
Accuracy Accuracy F1-Score
GCN (2-layer) 60.609 ±0.305 56.932 ±0.814 93.775 ±0.11
GCN (1-layer) 60.568 ±0.413 54.188 ±0.717 92.646 ±0.126
DP-GCN (2-layer) 54.667±0.182 41.215 ±1.081 90.788 ±0.124
DP-GCN (1-layer) 55.155±0.365 39.713 ±0.613 87.711 ±0.195
MLP 55.349 ±0.239 37.764 ±0.956 72.272 ±0.124
DP-MLP 52.27 ±0.257 31.639 ±1.538 69.541 ±0.074
Now, we consider the more challenging ‘inductive’ setting where the test dataset (the nodes and the graph)
are completely disjoint from the training data nodes and the associated graph. This models ‘multi-enterprise’
situations where the graph over users of one enterprise is completely disjoint from the graph over the users of
another enterprise. To conduct these experiments, we divide the nodes into three splits – training, validation
and test – and remove all inter-split edges to partition the graph into disjoint subgraphs. We report results
on three datasets: ogbn-arxiv-disjoint (where inter-split edges in ogbn-arxiv have been removed), ogbn-
arxiv-clustered (where agglomerative clustering2is perfomed on the original ogbn-arxiv dataset to partition
the nodes) and reddit-disjoint (where inter-split edges in reddit-transductive have been removed). We also
investigate 2-layer DP-GCNs in this setting. Once the DP-GNN parameters have been learnt privately over
the training graph, we assume that the test graph and test nodes are available non-privately to the inference
algorithm. Table 2 presents accuracy of our DP-GNN method with 1-layer and 2-layer GCN models on three
datasets. We observe that both 1-layer and 2-layer DP-GCNs are signiﬁcantly more accurate than MLP and
DP-MLP models which completely ignore the graph features.
6.3 Results with other GNN Architectures
As mentioned in Section 5, the DP-GNN training mechanisms can be used with most r-layer GNN architec-
tures. We experiment with two more GNN architectures, namely GIN (Xu et al., 2018) and GAT (Veličković
et al., 2018) in both transductive (Table 3) and inductive (Table 4) settings.
WeobservethatDP-GNNperformswellacrossdiﬀerentarchitecturesinbothprivacysettings, outperforming
MLP and DP-MLP baselines in all cases. For both the inductive and transductive settings, we observe that
GIN performs similarly to GCN, and DP-GIN again has similar performance as DP-GCN. On the ogbn-
arxiv-clustered dataset, however, both 1-layer and 2-layer DP-GIN models perform much better than their
DP-GCN counterparts.
Table 3:Test accuracy of DP-GIN and DP-GAT on the transductive ogbn-arxiv dataset with
a privacy budget of ε≤10.
Model Non-Private GNN DP-GNN
Accuracy Accuracy
GCN 67.759 ±0.394 61.133±0.288
GIN 66.934±0.498 59.611±0.383
GAT 65.444±0.465 56.01±0.303
MLP 55.236±0.298 50.803±0.167
6.4 Ablation Studies
Batch size m: As has been noted in other DP-SGD works (Abadi et al., 2016; Bagdasaryan et al., 2019;
McMahan et al., 2018), we observe that increasing the batch size improves the performance of the learnt
2See Appendix E for dataset details.
10Under review as submission to TMLR
Table 4:Test performance of DP-GIN in the inductive setting, with privacy budget ε≤12.
Model ogbn-arxiv-disjoint ogbn-arxiv-clustered reddit-disjoint
Accuracy Accuracy F1-Score
GIN (2-layer) 60.02 ±0.657 54.239 ±1.699 93.102 ±0.199
GIN (1-layer) 59.215 ±0.313 51.834 ±1.284 92.681 ±0.18
DP-GIN (2-layer) 54.966±0.45 40.658 ±1.106 89.342 ±0.165
DP-GIN (1-layer) 56.23±0.126 41.919 ±1.002 89.648 ±0.156
MLP 55.349 ±0.239 37.764 ±0.956 72.272 ±0.124
DP-MLP 52.27 ±0.257 31.639 ±1.538 69.541 ±0.074
Table 5:Accuracy of GCN and DP-GCN on the ogbn-arxiv dataset with diﬀerent batch sizes,
with DP-GCN privacy budget as ε≤12.
Batch Size GCN (AGCN)DP-GCN (ADP-GCN )AGCN−ADP-GCN
2500 68.809 53.514 15.295
5000 68.577 59.893 8.684
10000 68.562 62.343 6.219
20000 68.393 62.995 5.398
40000 68.208 63.430 4.778
Full-Batch 68.047 63.662 4.385
DP-GNN model. As described in Appendix E, we ﬁnd that a batch size of 5000to10000to work reasonably
well for training DP-GNNs across datasets.
Maximum In-Degree K: Compared to the batch size m, the maximum in-degree Khas less of an eﬀect
on both non-private and private models trained on ogbn-arxiv, as Table 6 shows. There is still a trade-
oﬀ: a smaller degree Kmeans lesser diﬀerentially private noise added at each update step, but also fewer
neighbours for each node to aggregate information from during training. As mentioned previously, this
degree constraint only applies to the training nodes. As described in Appendix E, we ﬁnd that a maximum
degreeKof around 10to work reasonably well across datasets.
7 Conclusions and Future Work
In this work, we proposed a method to privately learn multi-layer GNN parameters, that outperforms
both private and non-private baselines that do not utilize graph information. Our method ensures node-
level diﬀerential privacy, by a careful combination of sensitivity analysis of the gradients and a privacy
ampliﬁcation result extended to the GNN setting. We believe that our work is a ﬁrst step in the direction of
designingpowerfulGNNswhilepreservingprivacy. Somepromisingavenuesforfutureworkincludeextending
theDP-GNNmethodtolearnnon-localGNNs, guaranteeinginference-timeprivacywithdiﬀerentiallyprivate
neighborhood aggregation, addressing fairness issues, and understanding utility bounds for GNNs with node-
level privacy.
Table 6:Accuracy of GCN and DP-GCN on the ogbn-arxiv dataset with diﬀerent in-degrees,
with DP-GCN privacy budget as ε≤12.
Degree GCN (AGCN)DP-GNN (ADP-GCN )AGCN−ADP-GCN
3 67.931 62.413 5.518
5 68.003 62.830 5.173
7 67.622 62.884 4.738
10 67.615 62.534 5.081
20 68.185 61.506 6.679
30 68.241 60.528 7.713
11Under review as submission to TMLR
2 4 6 8 10 12
Epsilon (Privacy Parameter)102030405060T est AccuracyBatch Size
2500
5000
10000
20000
40000
90941
(a) Varying Batch Size m
6 8 10 12 14 16 18 20
Epsilon (Privacy Parameter)404550556065Test AccuracyDegree
3
5
7
10
20
30 (b) Varying Maximum Degree K
Figure 3: Ablation studies on DP-GCN on the ogbn-arxiv dataset. (a) shows privacy-utility curves
for diﬀerent batch sizes of DP-GCN, such that the scale of the DP noise added per update step is the same.
(b) shows privacy-utility curves for varying maximum in-degree Kfor the DP-GCN. In both analyses, the
other hyperparameters are kept ﬁxed.
References
Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and
Li Zhang. Deep Learning with Diﬀerential Privacy. In Proceedings of the 2016 ACM SIGSAC Confer-
ence on Computer and Communications Security , CCS ’16, pp. 308–318, New York, NY, USA, 2016.
Association for Computing Machinery. ISBN 9781450341394. doi: 10.1145/2976749.2978318. URL
https://doi.org/10.1145/2976749.2978318 . 1, 2, 6, 6.4
David Ahmedt-Aristizabal, Mohammad Ali Armin, Simon Denman, Clinton Fookes, and Lars Petersson.
Graph-Based Deep Learning for Medical Diagnosis and Analysis: Past, Present and Future. arXiv preprint
arXiv:2105.13137 , 2021. 1
Rohan Anil, Badih Ghazi, Vineet Gupta, Ravi Kumar, and Pasin Manurangsi. Large-Scale Diﬀerentially
Private BERT. CoRR, abs/2108.01624, 2021. URL https://arxiv.org/abs/2108.01624 . 2
Eugene Bagdasaryan, Omid Poursaeed, and Vitaly Shmatikov. Diﬀerential privacy has disparate impact on
model accuracy. Advances in Neural Information Processing Systems , 32:15479–15488, 2019. 6.4, C
Raef Bassily, Adam Smith, and Abhradeep Thakurta. Private Empirical Risk Minimization: Eﬃcient Al-
gorithms and Tight Error Bounds. In Proc. of the 2014 IEEE 55th Annual Symp. on Foundations of
Computer Science (FOCS) , pp. 464–473, 2014. 1, 2, 5
Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheﬀet. Diﬀerentially private data analysis of social
networks via restricted sensitivity, 2012. URL https://arxiv.org/abs/1208.4586 . 2
Christian Borgs, Jennifer T. Chayes, and Adam Smith. Private Graphon Estimation for Sparse Graphs,
2015. 2
ChristianBorgs, JenniferChayes, AdamSmith, andIliasZadik. RevealingNetworkStructure, Conﬁdentially:
Improved Rates for Node-Private Graphon Estimation, 2018. 2
Zhiqi Bu, Sivakanth Gopi, Janardhan Kulkarni, Yin Tat Lee, Judy Hanwen Shen, and Uthaipon Tan-
tipongpipat. Fast and memory eﬃcient diﬀerentially private-SGD via JL projections. In A. Beygelzimer,
Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Sys-
tems, 2021. URL https://openreview.net/forum?id=WwZbupAKWo . 5
12Under review as submission to TMLR
Amar Budhiraja, Gaurush Hiranandani, Darshak Chhatbar, Aditya Sinha, Navya Yarrabelly, Ayush Choure,
Oluwasanmi Koyejo, and Prateek Jain. Rich-Item Recommendations for Rich-Users: Exploiting Dynamic
and Static Side Information, 2020. 1
Nicholas Carlini, Chang Liu, Úlfar Erlingsson, Jernej Kos, and Dawn Song. The Secret Sharer: Evaluat-
ing and Testing Unintended Memorization in Neural Networks. In 28th USENIX Security Symposium
(USENIX Security 19) , pp. 267–284, Santa Clara, CA, August 2019. USENIX Association. ISBN 978-1-
939133-06-9. URL https://www.usenix.org/conference/usenixsecurity19/presentation/carlini .
1
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating Noise to Sensitivity in
Private Data Analysis. In Shai Halevi and Tal Rabin (eds.), Theory of Cryptography , pp. 265–284, Berlin,
Heidelberg, 2006. Springer Berlin Heidelberg. ISBN 978-3-540-32732-5. 1, 3
Alessandro Epasto, Vahab Mirrokni, Bryan Perozzi, Anton Tsitsulin, and Peilin Zhong. Diﬀerentially private
graphlearningviasensitivity-boundedpersonalizedpagerank, 2022. URL https://arxiv.org/abs/2207.
06944. 2
Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. Graph neural networks for
social recommendation. In The World Wide Web Conference , pp. 417–426, 2019. 1
Vitaly Feldman, Ilya Mironov, Kunal Talwar, and Abhradeep Thakurta. Privacy Ampliﬁcation by Iteration.
In59th Annual IEEE Symp. on Foundations of Computer Science (FOCS) , pp. 521–532, 2018. 5, 5
Ferdinando Fioretto, Cuong Tran, and Pascal Van Hentenryck. Decision Making with Diﬀerential Privacy
under a Fairness Lens. CoRR, abs/2105.07513, 2021. URL https://arxiv.org/abs/2105.07513 . C
C. Forbes, M. Evans, N. Hastings, and B. Peacock. Statistical Distributions . Wiley, 2011. ISBN
9781118097823. URL https://books.google.co.in/books?id=YhF1osrQ4psC . 1, B
Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural Message
Passing for Quantum Chemistry. CoRR, abs/1704.01212, 2017. URL http://arxiv.org/abs/1704.
01212. 1
Josef Hadar and William R. Russell. Rules for ordering uncertain prospects. The American Economic
Review, 1969. ISSN 00028282. B
William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive Representation Learning on Large Graphs.
CoRR, abs/1706.02216, 2017. URL http://arxiv.org/abs/1706.02216 . 1, 3, 4, 6
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta,
and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. arXiv preprint
arXiv:2005.00687 , 2020. 6
Matthew Jagielski, Michael J. Kearns, Jieming Mao, Alina Oprea, Aaron Roth, Saeed Shariﬁ-Malvajerdi,
and Jonathan R. Ullman. Diﬀerentially Private Fair Learning. CoRR, abs/1812.02696, 2018. URL
http://arxiv.org/abs/1812.02696 . C
Peter Kairouz, Brendan Mcmahan, Shuang Song, Om Thakkar, Abhradeep Thakurta, and Zheng Xu.
Practical and Private (Deep) Learning Without Sampling or Shuﬄing. In Marina Meila and Tong
Zhang (eds.), Proceedings of the 38th International Conference on Machine Learning , volume 139 of
Proceedings of Machine Learning Research , pp. 5213–5225. PMLR, 18–24 Jul 2021. URL https:
//proceedings.mlr.press/v139/kairouz21b.html . 6.1
Vishesh Karwa, Sofya Raskhodnikova, Adam Davison Smith, and Grigory Yaroslavtsev. Private analysis of
graph structure. Proceedings of the VLDB Endowment , 4(11):1146–1157, August 2011. ISSN 2150-8097.
2
13Under review as submission to TMLR
Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam D. Smith.
What Can We Learn Privately? In 49th Annual IEEE Symp. on Foundations of Computer Science
(FOCS), pp. 531–540, 2008. 5
Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs
with node diﬀerential privacy. In Amit Sahai (ed.), Theory of Cryptography , pp. 457–476, Berlin, Heidel-
berg, 2013. Springer Berlin Heidelberg. ISBN 978-3-642-36594-2. 2, 2
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014. 5, D, E
Thomas N. Kipf and Max Welling. Semi-Supervised Classiﬁcation with Graph Convolutional Networks.
CoRR, abs/1609.02907, 2016. URL http://arxiv.org/abs/1609.02907 . 1, 3
Soﬁa Ira Ktena, Sarah Parisot, Enzo Ferrante, Martin Rajchl, Matthew Lee, Ben Glocker, and Daniel
Rueckert. Metric learning with spectral graph convolutions on brain connectivity networks. NeuroImage ,
169:431–442, 2018. 1
Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, and Ananda Theertha
Suresh. Learning with User-Level Privacy. CoRR, abs/2102.11845, 2021. URL https://arxiv.org/abs/
2102.11845 . 1
Kevin McCloskey, Ankur Taly, Federico Monti, Michael P Brenner, and Lucy J Colwell. Using attribution to
decode binding mechanism in neural network models for chemistry. Proceedings of the National Academy
of Sciences , 116(24):11624–11629, 2019. 1
H. Brendan McMahan, Galen Andrew, Ulfar Erlingsson, Steve Chien, Ilya Mironov, Nicolas Papernot, and
Peter Kairouz. A general approach to adding diﬀerential privacy to iterative training procedures, 2018.
URL https://arxiv.org/abs/1812.06210 . 6.4
Ilya Mironov. Rényi diﬀerential privacy. In 2017 IEEE 30th Computer Security Foundations Symposium
(CSF), pp. 263–275. IEEE, 2017a. 2, 3, 1, 6.1, B, B
Ilya Mironov. Renyi Diﬀerential Privacy. CoRR, abs/1702.07476, 2017b. URL http://arxiv.org/abs/
1702.07476 . 5
Nicolas Papernot, Steve Chien, Shuang Song, Abhradeep Thakurta, and Ulfar Erlingsson. Making the
Shoe Fit: Architectures, Initializations, and Tuning for Learning with Privacy, 2020. URL https://
openreview.net/forum?id=rJg851rYwH . 6.1
Sofya Raskhodnikova and Adam Smith. Lipschitz Extensions for Node-Private Graph Statistics and the
Generalized Exponential Mechanism. In 2016 IEEE 57th Annual Symposium on Foundations of Computer
Science (FOCS) , pp. 495–504, 2016. doi: 10.1109/FOCS.2016.60. 2
Sina Sajadmanesh and Daniel Gatica-Perez. When Diﬀerential Privacy Meets Graph Neural Networks.
CoRR, abs/2006.05535, 2020. URL https://arxiv.org/abs/2006.05535 . 2
Sina Sajadmanesh, Ali Shahin Shamsabadi, Aurélien Bellet, and Daniel Gatica-Perez. Gap: Diﬀerentially
private graph neural networks with aggregation perturbation, 2022. URL https://arxiv.org/abs/2203.
00949. 2
Chuanqiang Shan, Huiyun Jiao, and Jie Fu. Towards Representation Identical Privacy-Preserving Graph
Neural Network via Split Learning. CoRR, abs/2107.05917, 2021. URL https://arxiv.org/abs/2107.
05917. 2
Shuang Song, Kamalika Chaudhuri, and Anand D Sarwate. Stochastic gradient descent with diﬀerentially
private updates. In 2013 IEEE Global Conference on Signal and Information Processing , pp. 245–248.
IEEE, 2013. 1, 2
14Under review as submission to TMLR
Pranav Subramani, Nicholas Vadivelu, and Gautam Kamath. Enabling fast diﬀerentially private sgd via
just-in-time compilation and vectorization, 2020. URL https://arxiv.org/abs/2010.09063 . 5
Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Liò, and Yoshua Bengio.
Graph Attention Networks, 2018. 1, 3, 6.3
Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic
Graph CNN for Learning on Point Clouds. Acm Transactions On Graphics) , 38(5):1–12, 2019. 1
Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie. FedGNN: Federated Graph Neural
Network for Privacy-Preserving Recommendation. CoRR, abs/2102.04925, 2021a. URL https://arxiv.
org/abs/2102.04925 . 2
Fan Wu, Yunhui Long, Ce Zhang, and Bo Li. LinkTeller: Recovering Private Edges from Graph Neural
Networks via Inﬂuence Analysis, 2021b. 2
Depeng Xu, Wei Du, and Xintao Wu. Removing disparate impact on model accuracy in diﬀerentially private
stochastic gradient descent. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining , KDD ’21, pp. 1924–1932, New York, NY, USA, 2021. Association for Computing
Machinery. ISBN 9781450383325. doi: 10.1145/3447548.3467268. URL https://doi.org/10.1145/
3447548.3467268 . C
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How Powerful are Graph Neural Networks?
CoRR, abs/1810.00826, 2018. URL http://arxiv.org/abs/1810.00826 . 3, 6.3
Liang Yao, Chengsheng Mao, and Yuan Luo. Graph convolutional networks for text classiﬁcation. In
Proceedings of the AAAI Conference on Artiﬁcial Intelligence , volume 33, pp. 7370–7377, 2019. 1
Jun Zhou, Chaochao Chen, Longfei Zheng, Xiaolin Zheng, Bingzhe Wu, Ziqi Liu, and Li Wang. Privacy-
Preserving Graph Neural Network for Node Classiﬁcation. CoRR, abs/2005.11903, 2020. URL https:
//arxiv.org/abs/2005.11903 . 2
15Under review as submission to TMLR
Appendix
A Proof that SAMPLE−SUBGRAPHS Satisﬁes Node Occurrence Constraints
For clarity, we restate Lemma 1 below.
Lemma. LetGbe any graph with set of training nodes Vtr. Then, for any K,r≥0, the number of
occurrences of any node in the set of training subgraphs SAMPLE−SUBGRAPHS (G,Vtr,K,r )is bounded
above byN(K,r), where:
N(K,r) =r/summationdisplay
i=0Ki=Kr+1−1
K−1∈Θ(Kr)
Proof.Fix anyK≥0. We proceed by induction on r. The proof for r= 0, whereSvis simply{v}, is
obvious. In this case, every node voccurs only in its own subgraph Sv, and hence, N(K,r) =K1−1
K−1= 1.
For any node vand anyr≥0, letSr(v)be the set of all subgraphs in SAMPLE−SUBGRAPHS (G,Vtr,K,r )
in whichvoccurs. Then, the hypothesis is that |Sr(v)|≤N(K,r)for anyv.
Assume that the given hypothesis holds for some r. We will now show that our hypothesis holds for r+ 1
as well, proving our claim via induction for all r≥0.
Fix a node v∈V. Then, from the deﬁnition of RECURSIVE−NEIGHBORHOOD (Algorithm 2), if Su/prime∈
Sr+1(v), then there must exist usuch thatu∈Eu/primeandSu∈Sr(v). Informally, if vwas already in the
r-depth neighborhood of u, and there exists an edge from u/primetouafter subsampling, then vwill be in the
r+ 1-depth neighborhood of u/prime.
By the guarantee of SAMPLE−EDGELISTS (Algorithm 1), the number of nodes such that u∈Eu/primeis atmost
K, any node uis present in atmost Kedgelists, since its (sampled) in-degree is bounded by K. By the
inductive hypothesis, there are atmost N(K,r)−1such nodes usuch thatSu∈Sr(v).
Combining the two upper bounds, and including the subgraph Sv(to whichvalways belongs), we can derive
the upper bound matching the inductive hypothesis for r+ 1:
|Sr+1(v)|≤N(K,r+ 1) =K·(N(K,r)−1) + 1 =Kr+2−1
K−1.
B Proof of Privacy Ampliﬁcation by Subsampling Result for DP-GNN
We provide a detailed proof for Theorem 1 in this section.
Lemma 2 (Node-Level Sensitivity of any r-Layer GNN) .LetGbe any graph such that the maximum in-
degree ofGis bounded by K≥0. LetVtrbe the training set of nodes. Let Btbe any choice of munique
subgraphs fromStr=SAMPLE−SUBGRAPHS (G,Vtr,K,r ). For each node v∈Vtr, let ˆyvbe the prediction
from anr-layer GNNwhen run on the subgraph Sv∈Str. Now,/hatwideyv:=GNN(Sv,X,v;Θ). Consider the loss
functionLof the form:L(G,Θ) =/summationtext
v∈V/lscript(/hatwideyv;yv).Consider the following quantity utfrom Algorithm 4:
ut(G) =/summationdisplay
v∈BtClipC(∇Θ/lscript(/hatwideyv;yv))
Then, the following inequality holds:
∆K(ut)<2C·N(K,r) = 2C·Kr+1−1
K−1.
Proof.LetGbe any graph such that the in-degrees of all nodes in Gare bounded by K≥0. LetVtrbe
the training set of nodes. Consider a graph G/primeformed by removing all of the data (features, labels and
connections) of a single node /hatwidevfromG, so thatGandG/primeare node-level adjacent.
16Under review as submission to TMLR
Let us deﬁne the two sets of subgraphs from GandG/primeas follows:
Str=SAMPLE−SUBGRAPHS (G,Vtr,K,r )
S/prime
tr=SAMPLE−SUBGRAPHS (G/prime,Vtr,K,r )
Then, the only subgraphs which have changed between StrandS/prime
trare only those subgraphs in which
/hatwidevoccurred in, that is, Sr(v)from the proof of Lemma 1. Further, from Lemma 1, there are atmost
N(K,r) =Kr+1−1
K−1such subgraphs.
We wish to bound the /lscript2-norm of the following quantity:
ut(G)−ut(G/prime)
For convenience, for any node v, we denote the corresponding gradient terms ∇Θ/lscriptvand∇Θ/lscript/prime
vas:
∇Θ/lscriptv=∇Θ/lscript(GNN(Sv,X,v;Θ);yv) =∇Θ/lscript(/hatwideyv;yv)
∇Θ/lscript/prime
v=∇Θ/lscript(GNN(S/prime
v,X/prime,v;Θ);yv) =∇Θ/lscript(/hatwidey/prime
v;yv)
Thus, it is clear that the only gradient terms ∇Θ/lscriptvaﬀected when adding or removing node /hatwidev, are those
corresponding to the subgraphs in Sr(v):
ut(G)−ut(G/prime) =/summationdisplay
Sv∈(Bt∩Sr(v))ClipC(∇Θ/lscriptv)−ClipC(∇Θ/lscript/prime
v)
In the worst case, all of the subgraphs in Sr(v)occur inBt. Each of the gradient terms are clipped to have
/lscript2-normC. Hence, the triangle inequality gives us:
/bardblClipC(∇Θ/lscriptv)−ClipC(∇Θ/lscript/prime
v)/bardblF≤/bardblClipC(∇Θ/lscriptv)/bardblF+/bardblClipC(∇Θ/lscriptv)/bardblF= 2C.
Thus:
/bardblut(G)−ut(G/prime)/bardblF≤2C·N(K,r) = 2C·Kr+1−1
K−1.
The same reasoning applies to the case when G/primeis formed by a addition of a new node /hatwidevto the graph G.
AsGandG/primewere an arbitrary pair of node-level adjacent graphs, the proof is complete.
Lemma 3 (Un-ampliﬁed Privacy Guarantee for Each Iteration of Algorithm 4) .Every iteration tof Algo-
rithm 4 is (α,γ)node-level Rényi DP where γ=α·(∆K(ut))2
2σ2.
Proof.Follows directly from Mironov (2017a, Corollary 3).
Lemma 4 (Distribution of Loss Terms Per Minibatch) .For any iteration tin Algorithm 4, consider the
minibatchBtof subgraphs. For any subset Sofdunique subgraphs, deﬁne the random variable ρas|S∩Bt|.
Then, the distribution of ρfollows the hypergeometric distribution Hypergeometric (N,d,m ):
ρi=P[ρ=i] =/parenleftbigd
i/parenrightbig/parenleftbigN−d
m−i/parenrightbig
/parenleftbigN
m/parenrightbig,
whereNis the number of nodes in the training set Vtrand|Bt|=mis the batch size.
Lemma 5 (AdaptationofLemma25fromFeldmanetal.(2018)) .Letµ0,...,µnandν0,...,νnbe probability
distributions over some domain Zsuch that: Dα(µ0/bardblν0)≤ε0, ..., Dα(µn/bardblνn)≤εn, for some given
ε0,...,εn.
Letρbe a probability distribution over [n] ={0,...,n}. Denote by µρ(respectively, νρ) the probability
distribution over Zobtained by sampling ifromρand then outputting a random sample from µi(respectively,
νi). Then:
Dα(µρ/bardblνρ)≤lnEi∼ρ/bracketleftBig
eεi(α−1)/bracketrightBig
=1
α−1lnn/summationdisplay
i=0ρieεi(α−1).
17Under review as submission to TMLR
Lemma 6. Letρ,ρ/primebe sampled from the hypergeometric distribution: ρ∼Hypergeometric (N,k,m ),ρ/prime∼
Hypergeometric (N,k/prime,m),such thatk≥k/prime. Then,ρstochastically dominates ρ/prime:Fρ/prime(i)≥Fρ(i)for alli∈R,
whereFρ(respectively, Fρ/prime) is the cumulative distribution function (CDF) of ρ(respectively, ρ/prime).
For clarity, we restate Theorem 1 below.
Theorem (Ampliﬁed Privacy Guarantee for any r-Layer GNN) .Consider the loss function Lof the form:
L(G,Θ) =/summationdisplay
v∈Vtr/lscript(GNN(A,X,v;Θt);yv).
Recall,Nis the number of training nodes Vtr,Kis the maximum in-degree of the input graph, ris the
number of GNN layers, and mis the batch size. For any choice of the noise standard deviation σ >0and
clipping threshold C, every iteration tof Algorithm 4 is (α,γ)node-level Rényi DP, where:
γ=1
α−1lnEρ/bracketleftbigg
exp/parenleftbigg
α(α−1)·2ρ2C2
σ2/parenrightbigg/bracketrightbigg
, ρ∼Hypergeometric/parenleftbigg
N,Kr+1−1
K−1,m/parenrightbigg
.
Hypergeometric denotes the standard hypergeometric distribution (Forbes et al., 2011). By the standard
composition theorem for Rényi Diﬀerential Privacy (Mironov, 2017a), over Titerations, Algorithm 4 is
(α,γT )node-level Rényi DP, where γandαare deﬁned above.
Proof of Theorem 1. At a high-level, Lemma 2 tells us that a node can participate in N(K,r) =Kr+1−1
K−1
training subgraphs from Str, in the worst case. However, on average, only a fraction of these subgraphs will
be sampled in the mini-batch Bt, as Lemma 4 indicates. We use the knowledge of the exact distribution of
the number of subgraphs sampled in Btprovided by Lemma 4 with Lemma 5 to get a tighter bound on the
Rényi divergence between the distributions of ˜utover node-level adjacent graphs. Finally, Lemma 6 allows
us to make the above bound independent of the actual node being removed, giving our ﬁnal result.
LetGbe any graph with training set Vtr. LetG/primebe formed by removing a single node /hatwidevfromG, soGand
G/primeare node-level adjacent.
For convenience, for any node v, we denote the corresponding gradient terms ∇Θ/lscriptvand∇Θ/lscript/prime
vas:
∇Θ/lscriptv=∇Θ/lscript(GNN(Sv,X,v;Θ);yv) =∇Θ/lscript(/hatwideyv;yv)
∇Θ/lscript/prime
v=∇Θ/lscript(GNN(S/prime
v,X/prime,v;Θ);yv) =∇Θ/lscript(/hatwidey/prime
v;yv)
LetSr(v)be the set of all subgraphs in SAMPLE−SUBGRAPHS (G,Vtr,K,r )in whichvoccurs.
ut(G)−ut(G/prime) =/summationdisplay
Sv∈(Bt∩Sr(/hatwidev))ClipC(∇Θ/lscriptv)−ClipC(∇Θ/lscript/prime
v).
Using the notation from Algorithm 4, we have:
˜ut(G) =ut(G) +N(0,σ2I)
˜ut(G/prime) =ut(G/prime) +N(0,σ2I)
We need to show that Dα(˜ut(G)/bardbl˜ut(G/prime))≤γ.
From the above equation, we see that the sensitivity of utdepends on the number of subgraphs in Sr(v)
that are present in Bt. Letρ/primebe the distribution over {0,1,...|Sr(v)|}of the number of subgraphs in
Sr(v)present inBt, that is,ρ/prime=|Sr(v)∩Bt|. Lemma 4 then gives us that the distribution of ρ/primeis:
ρ/prime∼Hypergeometric (N,Sr(v),m).In particular, when ρ/prime=i, exactlyisubgraphs are sampled in Bt. Then,
following Lemma 2, ∆K(ut|ρ/prime=i)<2iC.Thus, conditioning on ρ/prime=i, we see that every iteration is
(α,γi)node-level Rényi DP, by Lemma 3 where γi=α·2i2C2/σ2.
18Under review as submission to TMLR
Deﬁne the distributions µiandνifor eachi∈ {0,...,|Sr(v)|}, as follows: µi= [˜ut(G)|ρ/prime=i],νi=
[˜ut(G/prime)|ρ/prime=i]. ThenDα(µi/bardblνi)≤γi. For the mixture distributions µρ/prime=˜ut(G)andνρ/prime=˜ut(G/prime),
Lemma 5 now tells us that:
Dα(˜ut(G)/bardbl˜ut(G/prime)) =Dα(µρ/prime/bardblνρ/prime)
≤1
α−1lnEi∼ρ/prime[exp (γi(α−1))]
=1
α−1lnE[f(ρ/prime)].
where:
f(ρ/prime) = exp/parenleftbigg
α(α−1)·2ρ/prime2C2
σ2/parenrightbigg
.
Deﬁne another distribution ρas:
ρ∼Hypergeometric (N,N (K,r),m)
whereN(K,r) =Kr+1−1
K−1is the upper bound on |Sr(v)|from Lemma 1. By Lemma 6, ρstochastically
dominates ρ/prime. As non-decreasing functions preserve stochastic dominance (Hadar & Russell, 1969), f(ρ)
stochastically dominates f(ρ/prime), and hence E[f(ρ/prime)]≤E[f(ρ)].It follows that:
Dα(˜ut(G)/bardbl˜ut(G/prime))≤1
α−1lnE[f(ρ)]
=1
α−1lnEρ/bracketleftbigg
exp/parenleftbigg
α(α−1)·2ρ2C2
σ2/parenrightbigg/bracketrightbigg
=γ.
The theorem now follows from the fact that the above holds for an arbitrary pair of node-level adjacent
graphsGandG/prime.
C Class-wise Analysis of Learnt Models
To better understand the performance of the private model as compared to the non-private baseline for
our considering setting of multi-class classiﬁcation at a node-level, we compare the accuracy of these two
models for each dataset at a class-wise granularity. These results are illustrated in Figure 4. We empirically
observe that the performance of the private model degrades as the frequency of training data points for
a particular class decreases. This indicates that the model is able to classify data points of ‘frequent’
classes with reasonable accuracy, but struggles with classiﬁcation accuracy on the data points of ‘rarer’
classes. This observation is in line with previous claims from (Bagdasaryan et al., 2019; Fioretto et al., 2021)
that diﬀerentially-private models generally perform disparately worse on under-represented classes. While
methods (Jagielski et al., 2018; Xu et al., 2021) have been developed for improving the fairness of DP-SGD,
their extension to the GNN setting represents an important direction for future work.
19Under review as submission to TMLR
0 5 10 15 20 25 30 35 40
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: GCN (Non-Private Model)
0 5 10 15 20 25 30 35 40
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: DP-GNN (Private Model)
GCN
DP-GNN
(a) ogbn-arxiv
0 5 10 15 20 25 30 35 40 4547
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: GCN
0 5 10 15 20 25 30 35 40 4547
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: DP-GNN
GCN
DP-GNN (b) ogbn-products
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: GCN (Non-Private Model)
Class # (Ordered by Frequency)0.00.20.40.60.81.0AccuracyMethod: DP-GNN (Private Model)
GCN 
DP-GNN 
(c) ogbn-mag
Figure 4: Comparison of class-wise test accuracies of the non-private GCN model and private
DP-GCN model on all datasets, ordered by the decreasing frequency of occurrence of classes
in the training data from left to right. The dotted lines indicate the overall (‘micro’) accuracy for each
model.
20Under review as submission to TMLR
D Learning Graph Convolutional Networks (GCN) via DP-Adam
In Algorithm 5, we provide the description of DP-Adam, which adapts Algorithm 4 to use the popular Adam
(Kingma & Ba, 2014) optimizer, instead of SGD. The privacy guarantee and accounting for Algorithm 5 is
identical to that of Algorithm 4, since the DP clipping and noise addition steps are identical.
Algorithm 5: DP-GNN (Adam): Diﬀerentially Private Graph Neural Network with Adam
Data:GraphG= (V,E,X,Y), GNN deﬁnition GNN, Training set Vtr, Loss functionL, Batch size m,
Maximum degree K, Learning rate η, Clipping threshold C, Noise standard deviation σ,
Maximum training iterations T, Adam hyperparameters (β1,β2).
Result: GNN parameters ΘT.
Note thatVtris the subset of nodes for which labels are available (see Paragraph 1 of Section 3).
Construct the set of training subgraphs with Algorithm 3: Str←SAMPLE−SUBGRAPHS (G,Vtr,K,r ).
Initialize Θ0randomly.
fort= 0toTdo
Sample setBt⊆Strof sizemuniformly at random from all subsets of Str.
Compute the update term utas the sum of the clipped gradient terms in the mini-batch Bt:
ut←/summationdisplay
Sv∈BtClipC(∇Θ/lscript(GNN(A,X,v;Θt);yv))
Add independent Gaussian noise to the gradient term: ˜ut←ut+N(0,σ2I)
Update ﬁrst and second moment estimators with the noisy gradient, correcting for bias:
ft←β1·ft−1+ (1−β1)·˜ut
st←β2·st−1+ (1−β2)·(˜ut⊙˜ut)
/hatwideft←ft
1−βt
1
/hatwidest←st
1−βt
2
Update the current estimate of the parameters with the noisy estimators:
Θt+1←Θt−η
m/hatwideft/radicalbig
/hatwides2
t+ε
end
E Reproducibility
Ouropen-sourcedpipelineforsamplinggraphdatasetsandtrainingDP-GNNandtheotherbaselinemodelsis
available at (URL to be provided on paper acceptance, currently anonymized and uploaded as supplementary
material). All experiments were run on TPU v2 Donuts (2x2 and 4x4 topology).
Data:Table 7 provides details about the node classiﬁcation benchmark datasets used in this work: ogbn-
arxiv, ogbn-products, ogbn-mag3, and reddit4.
Models: We use the following ‘inverse-degree’ normalization of the adjacency matrix for all GCN models:
/hatwideA= (d+I)−1(A+I).We use a variant of the original GAT architecture, utilizing dot-product attention
instead of additive attention, with 10attention heads. Adam (Kingma & Ba, 2014) with β1= 0.9and
β2= 0.999, and SGD optimizers were used for training all methods for each of the datasets. A latent
3Obtained from https://ogb.stanford.edu/docs/nodeprop/ .
4Obtained from http://snap.stanford.edu/graphsage/ . Available preprocessed at this Google Drive link.
21Under review as submission to TMLR
Table 7:Statistics of datasets used in our experiments.
Dataset Nodes Avg. Degree Features Classes Train/Val/Test Split
ogbn-arxiv 169,343 13.7 128 40 0.54/0.18/0.28
ogbn-arxiv-disjoint 169,343 5.5 128 40 0.54/0.18/0.28
ogbn-arxiv-clustered5169,343 13.0 128 40 0.67/0.18/0.15
ogbn-products 2,449,029 50.5 100 47 0.08/0.02/0.90
ogbn-mag 736,389 21.7 128 349 0.85/0.09/0.05
reddit 232,965 99.6 602 41 0.66/0.10/0.24
reddit-disjoint 232,965 54.4 602 41 0.66/0.10/0.24
size of 256was used for the encoder, GNN and decoder layers. Additionally, the best hyperparameters
corresponding to each experiment to reproduce the results in the main paper are reported in the tables
below.
lrrefers to the learning rate, nencrefers to the number of layers in the encoder MLP, ndecrefers to the
number of layers in the decoder MLP, λrefers to the noise multiplier, and Krefers to the maximum degree.
Table 9:Hyperparameters for models in Table 1.
Model Dataset lrBatch Size Activation nencndecλ K
GCNogbn-arxiv 0.002 1,000 ReLU 2 2 - 30
ogbn-products 0.001 1,000 ReLU 2 1 - 30
ogbn-mag 0.001 1,000 ReLU 2 2 - 10
reddit 0.001 1,000 ReLU 2 2 - 10
DP-GCN (Adam)ogbn-arxiv 0.003 10,000 Tanh 1 2 2 7
ogbn-products 0.005 10,000 Tanh 1 2 1 10
ogbn-mag 0.001 10,000 Tanh 2 2 2 10
reddit 0.002 10,000 Tanh 2 2 1 10
DP-GCN (SGD)ogbn-arxiv 1.0 10,000 Tanh 2 1 2 7
ogbn-products 2.0 40,000 Tanh 1 1 2 5
ogbn-mag 1.0 10,000 ReLU 1 2 1 10
reddit 0.1 10,000 Tanh 1 2 1 10
MLPogbn-arxiv 0.001 1,000 ReLU 2 1 - -
ogbn-products 0.001 1,000 ReLU 1 2 - -
ogbn-mag 0.01 1,024 ReLU 2 1 - -
reddit 0.001 1,000 ReLU 1 1 - -
DP-MLPogbn-arxiv 0.003 10,000 Tanh 1 2 1 0
ogbn-products 0.002 10,000 ReLU 1 2 1 10
ogbn-mag 0.001 10,000 ReLU 2 2 1 10
reddit 0.001 10,000 Tanh 1 2 1 10
6Indices indicating the split for each node available at this Google Drive link. ‘0’ indicates the train split, ‘1’ indicates the
validation split, and ‘2’ indicates the test split.
22Under review as submission to TMLR
Table 10: Hyperparameters for models in Table 2.
Model Dataset lrBatch Size Activation nencndecλ K
GCN (2-layer)ogbn-arxiv-disjoint 0.001 1,000 ReLU 1 1 - 30
ogbn-arxiv-clustered 0.001 1,000 ReLU 1 2 - 10
reddit-disjoint 0.001 1,000 ReLU 2 2 - 10
GCN (1-layer)ogbn-arxiv-disjoint 0.001 1,000 ReLU 1 2 - 7
ogbn-arxiv-clustered 0.001 1,000 ReLU 1 1 - 30
reddit-disjoint 0.001 1,000 ReLU 2 2 - 10
DP-GCN (2-layer)ogbn-arxiv-disjoint 0.003 20,000 Tanh 1 1 2 3
ogbn-arxiv-clustered 0.002 20,000 Tanh 2 1 4 3
reddit-disjoint 0.002 20,000 Tanh 1 1 2 3
DP-GCN (1-layer)ogbn-arxiv-disjoint 0.002 20,000 Tanh 1 2 4 7
ogbn-arxiv-clustered 0.002 20,000 Tanh 2 2 4 10
reddit-disjoint 0.001 10,000 Tanh 2 2 1 10
MLPogbn-arxiv-disjoint 0.001 1,000 ReLU 2 1 - -
ogbn-arxiv-clustered 0.002 1,000 ReLU 1 2 - -
reddit-disjoint 0.001 1,000 ReLU 1 1 - -
DP-MLPogbn-arxiv-disjoint 0.003 10,000 Tanh 1 2 1 10
ogbn-arxiv-clustered 0.003 10,000 Tanh 2 2 1 10
reddit-disjoint 0.001 10,000 Tanh 1 2 1 10
Table 11: Hyperparameters for models in Table 3.
Architecture Method lrBatch Size Activation nencndecλ K
GCNNon-Private GNN 0.002 1,000 ReLU 2 2 - 30
DP-GNN 0.003 10,000 Tanh 1 2 2 7
GINNon-Private GNN 0.003 1,000 ReLU 2 1 - 30
DP-GNN 0.003 10,000 Tanh 1 1 1 7
GATNon-Private GNN 0.001 1,000 Tanh 2 2 - 30
DP-GNN 0.004 20,000 Tanh 1 2 2 7
MLPNon-Private MLP 0.001 1,000 ReLU 2 1 - -
DP-MLP 0.003 10,000 Tanh 1 2 1 -
Table 12: Hyperparameters for models in Table 4.
Model Dataset lrBatch Size Activation nencndecλ K
GIN (2-layer)ogbn-arxiv-disjoint 0.001 1,000 ReLU 1 2 - 3
ogbn-arxiv-clustered 0.001 1,000 ReLU 2 2 - 30
reddit-disjoint 0.001 1,000 ReLU 2 2 - 10
GIN (1-layer)ogbn-arxiv-disjoint 0.002 1,000 ReLU 2 1 - 30
ogbn-arxiv-clustered 0.001 1,000 ReLU 2 1 - 30
reddit-disjoint 0.001 1,000 ReLU 2 1 - 10
DP-GIN (2-layer)ogbn-arxiv-disjoint 0.002 20,000 Tanh 2 2 2 3
ogbn-arxiv-clustered 0.002 10,000 Tanh 1 2 1 3
reddit-disjoint 0.001 10,000 Tanh 1 1 1 3
DP-GIN (1-layer)ogbn-arxiv-disjoint 0.004 20,000 Tanh 1 2 2 7
ogbn-arxiv-clustered 0.004 10,000 Tanh 1 1 1 10
reddit-disjoint 0.001 10,000 Tanh 2 2 1 10
MLPogbn-arxiv-disjoint 0.001 1,000 ReLU 2 1 - 10
ogbn-arxiv-clustered 0.002 1,000 ReLU 1 2 - 10
reddit-disjoint 0.001 1,000 ReLU 1 1 - 10
DP-MLPogbn-arxiv-disjoint 0.003 10,000 Tanh 1 2 1 10
ogbn-arxiv-clustered 0.003 10,000 Tanh 2 2 1 10
reddit-disjoint 0.001 10,000 Tanh 1 2 1 10
23