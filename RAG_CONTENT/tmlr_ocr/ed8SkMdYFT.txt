Published in Transactions on Machine Learning Research (11/2023)
Understanding the robustness difference between stochastic
gradient descent and adaptive gradient methods
Avery Ma ama@cs.toronto.edu
University of Toronto
Vector Institute
Yangchen Pan yangchen.pan@eng.ox.ac.uk
University of Oxford
Amir-massoud Farahmand farahmand@cs.toronto.edu
University of Toronto
Vector Institute
Reviewed on OpenReview: https: // openreview. net/ forum? id= ed8SkMdYFT
Abstract
Stochastic gradient descent (SGD) and adaptive gradient methods, such as Adam and
RMSProp, have been widely used in training deep neural networks. We empirically show
that while the difference between the standard generalization performance of models trained
using these methods is small, those trained using SGD exhibit far greater robustness un-
der input perturbations. Notably, our investigation demonstrates the presence of irrele-
vant frequencies in natural datasets, where alterations do not affect models’ generalization
performance. However, models trained with adaptive methods show sensitivity to these
changes, suggesting that their use of irrelevant frequencies can lead to solutions sensitive
to perturbations. To better understand this difference, we study the learning dynamics
of gradient descent (GD) and sign gradient descent (signGD) on a synthetic dataset that
mirrors natural signals. With a three-dimensional input space, the models optimized with
GD and signGD have standard risks close to zero but vary in their adversarial risks. Our
result shows that linear models’ robustness to ℓ2-norm bounded changes is inversely pro-
portional to the model parameters’ weight norm: a smaller weight norm implies better
robustness. In the context of deep learning, our experiments show that SGD-trained neural
networks have smaller Lipschitz constants, explaining the better robustness to input per-
turbations than those trained with adaptive gradient methods. Our source code is available
athttps://github.com/averyma/opt-robust .
1 Introduction
Adaptive gradient methods, such as Adam (Kingma & Ba, 2015) and RMSProp (Hinton et al., 2012), are
a family of popular techniques to optimize machine learning (ML) algorithms. They are an extension of
the traditional gradient descent method, which uses the gradient of a differentiable objective function to
update the model’s parameters in the direction that improves the objective. To speed up the optimization
procedure, the adaptive gradient methods introduce a coordinate-wise learning rate to adjust the update for
each parameter based on its individual gradient. Previous empirical work investigates the difference in the
standard generalization between models trained using SGD and adaptive gradient methods (Wilson et al.,
2017; Agarwal et al., 2020), while recent efforts have focused on understanding the implicit bias of SGD
(Gunasekar et al., 2017; Soudry et al., 2018; Lyu & Li, 2020) and adaptive gradient algorithms (Qian &
Qian, 2019; Wang et al., 2021).
1Published in Transactions on Machine Learning Research (11/2023)
40 50 60 70 80 90
Acc. under Gaussian perturbations (%)80.082.585.087.590.092.595.097.5100.0Standard test acc. (%)MNIST
FashionMNISTCIFAR10
CIFAR100SVHN
Caltech101ImagenetteSGD
RMSProp
Adam
50 55 60 65 70 75 80 85
Acc. under 2-bounded attacks (%)
MNIST
FashionMNISTCIFAR10
CIFAR100SVHN
Caltech101Imagenette
30 40 50 60 70
Acc. under -bounded attacks (%)
MNIST
FashionMNIST
CIFAR10
CIFAR100SVHN
Caltech101Imagenette
Figure 1: Comparison between models trained using SGD, Adam, and RMSProp across seven
benchmarkdatasets. Eachcoloredtripletdenotesmodelsonthesamedataset. Modelstrainedbydifferent
algorithms have similar standard generalization performance, but there is a distinct robustness difference
as measured by the test data accuracy under Gaussian noise, ℓ2andℓ∞bounded adversarial perturbations
(Croce & Hein, 2020). Results are averaged over three independent model initializations and trainings.
Nevertheless, our result shows that in practice such a gap in the standard generalization is relatively small,
in contrast to the difference between the robustness of models trained using those algorithms. While more
ML-based systems are deployed in the real world, the models’ robustness, their ability to maintain their
performance when faced with noisy or corrupted inputs, has become an important criterion. There is a large
volume of literature on developing specialized methods to improve the robustness of neural networks (Silva
& Najafirad, 2020), yet practitioners still simply use standard methods to train their models. In fact, a
recent survey shows that only 3 of the 28 organizations have developed their ML-based systems with the
improvement in robustness in mind (Kumar et al., 2020). Therefore, this motivates us to understand the
effect of optimizers on the robustness of models obtained in the standard training regime. In particular,
we focus on models trained using SGD and adaptive gradient methods. Note that our primary focus lies in
understanding the robustness difference, and robustification falls outside the scope of our work.
1.1 The Robustness Difference between Models Trained by Different Algorithms
As a first step, we compare how models, trained with SGD, Adam, and RMSProp, differ in their standard
generalization and robustness on seven benchmark datasets (LeCun, 1998; Xiao et al., 2017; Krizhevsky &
Hinton, 2009; Netzer et al., 2011; Howard; Fei-Fei et al., 2004). In our experiments, we evaluate standard
generalization using the accuracy of the trained classifier on the original test dataset. To measure robustness,
we consider the classification accuracy on the test dataset perturbed by Gaussian noise, ℓ2andℓ∞bounded
adversarial perturbations (Croce & Hein, 2020). We follow the default Pytorch configuration to train all
the models and sweep through a wide range of learning rates. The final model is selected with the highest
validation accuracy. Models are trained in a vanilla setting in which data augmentations are limited to
random flipping. Additional discussions on batch normalization (Ioffe & Szegedy, 2015), data augmentation,
optimizationschedules, andnetworkdesignsaredetailedinAppendixB.AppendixCpresentscomprehensive
results from the experiment depicted in Figure 1, including the approach for selecting perturbations for each
dataset. While our primary experiments are centered around models based on convolutional neural networks,
within the computer vision domain, we also extend our analysis to include results from experiments on Vision
Transformers (Dosovitskiy et al., 2021) and an audio dataset (Warden, 2018). The results of these additional
experiments are consistent with the findings presented in this section and are detailed in Appendix C.
Additionally, visualizations of the perturbations can be found in Appendix G.
Figure 1 compares the models trained with SGD and the adaptive gradient methods, pointing to two impor-
tant observations. First, the relatively small vertical differences among the three models, on a given dataset,
show that the models have similar standard generalization performance despite being trained by different al-
gorithms. On the other hand, we observe, under all three types of perturbations, a large horizontal span with
SGD always positioned on the far right side among the three. This indicates that models trained by SGD
significantly outperform models trained by the other two in terms of their robustness against perturbations.
2Published in Transactions on Machine Learning Research (11/2023)
1.2 Contributions
Previous optimization work often studies how the structure of the dataset affects the dynamics of learning.
For example, some focus on a dataset with different feature strengths (Amari et al., 2021; Pezeshki et al.,
2021), while others assume a linearly separable dataset (Wilson et al., 2017; Gunasekar et al., 2017; Soudry
et al., 2018). In our work, we investigate how the frequency characteristics of the dataset impact the
robustness of models trained by SGD and adaptive gradient methods. We make the following contributions:
•We demonstrate that natural datasets contain irrelevant frequencies, which, when removed, have
negligible effects on standard generalization performance (Sec. 3.1).
•Wealsoobservethatneuralnetworkstrainedbydifferentalgorithmscanhaveverydifferentrobustness
against perturbations in the direction of the irrelevant frequencies (Sec. 3.2).
•Those observations lead to our claim that models only need to learn how to correctly use relevant
information in the data to optimize the training objective, and because their use of the irrelevant
information is under-constrained, it can lead to solutions sensitive to perturbations (Sec. 3).
•Our analysis of linear models on least square regression shows that linear models’ robustness to ℓ2-
norm bounded changes is inversely proportional to the model parameters’ weight norm: a smaller
weight norm implies better robustness (Sec. 4.1).
•We study the learning dynamics of GD and signGD, a memory-free version of Adam and RMSProp,
with linear models. With a three-dimensional input space, the analysis shows that models optimized
with GD exhibit a smaller weight norm compared to their signGD counterparts (Sec. 4.2).
•To generalize this result in the deep learning setting, we demonstrate that neural networks trained
by Adam and RMSProp often have a larger Lispchitz constant and, consequently, are more prone to
perturbations (Sec. 5).
Specifically, in the analysis of linear models, we design a least square regression task using a synthetic dataset
whose frequency representation mimics the natural datasets. This setting allows us to i) mathematically
define the standard and adversarial population risks, ii) design a learning task that has multiple optima for
the standard population risk, each with a different adversarial risk, and iii) theoretically analyze the learning
dynamics of various algorithms.
2 Background
In this section, we briefly review the essential background to help understand our work. Specifically, we
discuss formulations of adaptive gradient methods, previous work on the adversarial robustness of the model,
and methods of representing signals in the frequency domain.
2.1 Optimizations with Adaptive Gradient Algorithms
Considertheempiricalriskminimizationproblemwithanobjectiveoftheform L(w) =1
N/summationtextN
n=1ℓ(Xn,Yn;w),
wherew∈Rdis a vector of weights of a model, {(Xn,Yn)}N
n=1is the training dataset and ℓ(x,y;w)is the
point-wise loss quantifying the performance of the model on data point (x,y). A common approach in
training machine learning models is to reduce the loss via SGD which iteratively updates the model based
on a mini-batch of data points drawn uniformly and independently from the training set:
g(w) =1
|B|/summationdisplay
n∈B∇wℓ(Xn,Yn;w), (1)
whereB ⊂ { 1,...,N}denotes the minibatch and has a size of |B| ≪N. The update rule of SGD is
w(t+ 1) =w(t)−η(t)g(w(t)), whereη(t)∈R+denotes the learning rate.1
1From this point forward, subscripts denote vector/matrix coordinates, and numbers in parentheses denote update iterations
unless otherwise specified.
3Published in Transactions on Machine Learning Research (11/2023)
Afamilyofadaptivegradientmethodshasbeenusedtoacceleratetrainingbyupdatingthemodelparameters
based on a coordinate-wise scaling of the original gradients. Methods such as Adam and RMSprop have
demonstrated significant acceleration in training deep neural networks (Wilson et al., 2017). Many adaptive
gradient methods can be written as
m(t+ 1) =β1g(w(t)) + (1−β1)m(t)
v(t+ 1) =β2g(w(t))2+ (1−β2)v(t)
w(t+ 1) =w(t)−η(t)m(t+ 1)/radicalbig
v(t+ 1) +ϵ, (2)
whereg(w(t))is the stochastic estimate of gradient used by SGD (1), mandvare the first and second-
order memory terms with their strength specified by β1andβ2, andϵis a small constant used to avoid
division-by-zero. Such a general form has been widely used to study the dynamics of adaptive gradient
algorithm (Wilson et al., 2017; da Silva & Gazeau, 2020; Ma et al., 2022b). For example, Adam corresponds
toβ1,β2∈(0,1), and RMSProp is recovered when β1= 1andβ2∈(0,1). Notice that such updates rely
on the history of past gradients, and this makes the precise understanding and analysis of adaptive gradient
methods more challenging (Duchi et al., 2011). Recent work analyzes the learning dynamics of adaptive
gradient methods by separately considering the direction and the magnitude of the update (Kingma & Ba,
2015; Balles & Hennig, 2018; Ma et al., 2022b). As a simple example, to demonstrate how adaptive gradient
methods can potentially accelerate learning compared to the vanilla SGD, consider a memory-free version of
(2) withβ1=β2= 1andϵ= 0. It is easy to see that the update rule in (2) becomes sign gradient descent:
w(t+ 1) =w(t)−η(t) sign(g(w(t)))
=w(t)−⃗ η(t)⊙g(w(t)), (3)
where⊙denotes Hadamard product, ⃗ η(t)∈Rdis a coordinate-wise learning rate based on the absolute value
of the weight, i.e., ⃗ η(t) =η(t)
|g(w(t))|. Therefore, ⃗ η(t)accounts for the magnitude of the weight and a larger
learning rate is used for parameters with smaller gradients.
In general, gradient-sign-based optimization methods are not successful in training deep learning models
(Riedmiller & Braun, 1993; Ma et al., 2022b), nevertheless, methods such as signGD can shed light on the
learning dynamics of adaptive gradient methods (Karimi et al., 2016; Balles & Hennig, 2018; Moulay et al.,
2019). For example, recent work by Ma et al. (2022b) studies the behavior of adaptive gradient algorithms
in the continuous-time limit. They demonstrate that under a fixed β1andβ2, the memory effect for both
Adam and RMSprop diminishes and the continuous-time limit of the two algorithms follows the dynamics
of signGD flow. In this work, the deep learning models on which we observe the robustness difference are
trained using Adam and RMSProp, with the exception of Sec. 4, where we focus on signGD, a memory-free
version of Adam and RMSProp, and gradient descent to help us understand the robustness gap between
models trained using SGD and adaptive gradient methods in a simple setting.
2.2 Robustness of ML Models
An important assumption of most modern ML models is that samples from the training and testing dataset
are independent and identically distributed (i.i.d.); however, samples collected in the real world rarely come
from an identical distribution as the training data, as they are often subject to noise. It is known that
ML models can achieve impressive success on the original testing dataset, but exhibit a sharp drop in
performance under perturbations (Szegedy et al., 2014). Such an observation has posed concerns about the
potentialvulnerabilitiesforreal-worldMLapplicationssuchashealthcare(Qayyumetal.,2020), autonomous
driving(Dengetal.,2020)andaudiosystems(Lietal.,2020). Models’robustnessperformancehasbecomean
important secondary metric in the empirical evaluation of new training methods, such as data augmentations
(Zhang et al., 2018; Hendrycks et al., 2020; Verma et al., 2019; Ma et al., 2022a) and robust optimization
techniques (Zhai et al., 2021). Generally, the robustness property of models is assessed by examining the
model performance under multiple perturbations (Ding et al., 2020; Shen et al., 2021; Kuang et al., 2018). A
widevarietyofapproacheshavebeenproposedtoimprovetherobustnessofthemodelthroughregularizations
4Published in Transactions on Machine Learning Research (11/2023)
(Goodfellow et al., 2015; Simon-Gabriel et al., 2019; Wen et al., 2020; Ma et al., 2020; Foret et al., 2021;
Wei et al., 2023), data augmentation (Madry et al., 2018; Rebuffi et al., 2021; Gowal et al., 2021; Ma et al.,
2022a), and novel network architectures (Wu et al., 2021; Ma et al., 2021; Huang et al., 2021). However,
most industry practitioners are yet to come to terms with improving security in developing ML systems
(Kumar et al., 2020). Since SGD, Adam, and RMSProp have been the go-to optimizer in both academic
and industrial settings, this motivates us to understand the robustness of models trained by them and built
on the standard training pipelines, i.e., minimizing some losses on the original training set.
2.3 Frequency Representation of Signals
Natural signals are highly structured (Schwartz & Simoncelli, 2001). They often consist of statistically signif-
icant (or insignificant) patterns with a large amount of predictability (or redundancy). Such a phenomenon
has been observed in both natural images (Ruderman, 1994; Simoncelli, 1997; Huang & Mumford, 1999)
and natural audio signals (McAulay & Quatieri, 1986; Attias & Schreiner, 1996; Turner, 2010). To under-
stand the structure of signals and identify patterns from them, one technique is to decompose the signal
into multiples of “harmonics” or “overtones”: a superposition of periodic waves with varying amplitudes and
in varying phases. For example, Fourier (1822) first proposed to analyze complicated heat equations using
well-understood trigonometric functions, a method now called the Fourier transformation. This new repre-
sentation allows us to precisely study the structure and the magnitude of any repeating patterns presented in
the original waveform. For the understanding of digital signals, such a process is called discrete-time signal
processing (Oppenheim et al., 2001).
Many discrete harmonic transformations exist, such as the discrete Fourier transform, the discrete co-
sine transform (DCT) (Ahmed et al., 1974) and the wavelet transform (Mallat, 1999). The analysis in
this work utilizes the type-II DCT, but other techniques can be applied as well and we expect simi-
lar results. Concretely, consider a d-dimensional signal x∈Rdin the spatial domain. The same sig-
nal can be alternatively represented as a discrete sum of amplitudes multiplied by its cosine harmonics:
˜xk=/summationtextd−1
j=0xjcos/bracketleftbigπ
d/parenleftbig
j+1
2/parenrightbig
k/bracketrightbig
fork= 0,...,d−1, where the transformed signal ˜xhas a frequency-domain
representation.2Because DCT is linear, it can be carried out using a matrix operation, i.e., ˜x=Cx, where
Cis ad×dDCT transformation matrix with values specified by
C(d)
kj=/radicalbiggαk
dcos/bracketleftbiggπ
d/parenleftbigg
j+1
2/parenrightbigg
k/bracketrightbigg
, (4)
whereα0= 1andαk= 2fork>0. In particular, ˜xcan be written as a matrix-vector product between the
transformation matrix Cand the column vector x:

˜x0
˜x1
...
˜xd−1
=
/radicalig
1
d/radicalig
1
d···/radicalig
1
d/radicalig
2
dcosπ(2(0)+1)(1)
2d/radicalig
2
dcosπ(2(1)+1)(1)
2d···/radicalig
2
dcosπ(2(d−1)+1)(1)
2d
............/radicalig
2
dcosπ(2(0)+1)(d−1)
2d/radicalig
2
dcosπ(2(1)+1)(d−1)
2d···/radicalig
2
dcosπ(2(d−1)+1)(d−1)
2d

x0
x1
...
xd−1
.(5)
Notice that Cis a real orthogonal matrix whose rows consists of periodic cosine bases with increasing fre-
quencies. Therefore, the absolute value of ˜xat a particular dimension indicates the magnitudes of the
corresponding basis function, and a higher dimension in ˜xmeans the basis function is of higher frequency.
Another important property of DCT is its invertibility. That is, signals in the frequency domain can be con-
verted back to the spatial-temporal domain via the inverse DCT (iDCT): x=C−1˜x=C⊤˜x. In the example
above, we discussed one-dimensional DCT which is applied to vectors and is used in the linear analysis in
Sec. 4. Transformations on images require two-dimensional DCT and can be done using ˜x=CxC⊤, where
x,˜x∈Rd×d, andCis defined in (4); and the inverse two-dimensional DCT is x=C⊤˜xC. For more details
on two-dimensional DCT, we refer the reader to Pennebaker & Mitchell (1992).
Previousworkanalyzesthesensitivityofneuralnetworkclassifiersbyexaminingthefrequencycharacteristics
of various types of perturbations, with an emphasis on understanding how data augmentation affects the
2Indices range from 0tod−1, as zero-frequency is commonly used to refer to a signal with a constant everywhere.
5Published in Transactions on Machine Learning Research (11/2023)
robustness of the model (Yin et al., 2019). In our work, the frequency interpretation of signals is an integral
part of understanding the robustness difference between models trained by SGD and adaptive gradient
methods. This perspective allows us to study the structure of complex signals using well-understood periodic
basis functions such as cosines and understand the energy distribution of signals by examining the amplitude
of the basis function. In particular, the energy of a discrete signal xis defined as E(x) =/summationtextd−1
i=0|xi|2, and
by Parseval’s theorem, is equivalent to the sum of squared amplitudes across all the bases, i.e., E(x) =
E(˜x) =/summationtextd−1
i=0|˜xi|2. Natural images are primarily made of low-frequency signals3: a high concentration
of energy in the low-frequency harmonics renders the amplitude of the higher-frequency harmonics almost
negligible (Tolhurst et al., 1992; Schaaf & Hateren, 1996), as shown in Figure 8 in Appendix G. Moreover,
we show in Sec. 3.1 that there exist frequencies in natural datasets, which if removed from the training data,
do not affect the standard generalization performance of the model. Based on this observation, in Sec. 4, we
construct a synthetic dataset that mimics the characteristics of natural signals, and it allows us to study the
learning dynamics of various optimization algorithms in a controlled setting.
3 A Claim on How Models Use Irrelevant Frequencies
Why do models trained by different optimization algorithms behave similarly in the standard setting where
the training and the test inputs are i.i.d., while they perform drastically differently when faced with noisy or
corrupted data? To answer this question, we first observe that there is irrelevant information in the natural
dataset (Observation I), and attenuating them from the training input has negligible effects on the standard
generalization of the model. This leads to our claim:
Claim 3.1. To optimize the standard training objective, models only need to learn how to correctly use rele-
vant information in the data. Their use of irrelevant information in the data, however, is under-constrained
and can lead to solutions sensitive to perturbations.
Because of this, by targeting the perturbations toward the subset of the signal that contains irrelevant
information, we notice that models trained by different algorithms exhibit very different performance changes
(Observation II).
3.1 Observation I: Irrelevant Frequencies in Natural Signals
Previous work demonstrated that the magnitude of the frequency components in natural images decreases
as the frequency increases, and this decrease follows a1
f2relationship (Ruderman, 1994; Wainwright &
Simoncelli, 1999). In Figure 8 of Appendix G, we make the observation on several common vision datasets
that the distribution of spectral energy heavily concentrates at the low end of the frequency spectrum and
decays quickly towards higher frequencies. The spectral sensitivity of the human eyes is limited (Gross,
2005), so patterns with low magnitudes and high frequencies are not important from the perspective of
human observers, as they appear to us as nearly invisible and unintuitive information in the scene (Schwartz
& Simoncelli, 2001; Schwartz, 2004). For machines, image-processing methods have long exploited the fact
that most of the content-defining information in natural images is represented in low frequencies, and the
high-frequency signal is redundant, irrelevant, and is often associated with noise (Wallace, 1991; Guo et al.,
2020; Sharma et al., 2019).
Similarly, the notion of irrelevant frequencies also exists when training a neural network classifier. One
way to illustrate this is by taking a supervised learning task, removing the irrelevant information from the
training input, and then assessing the model’s performance using the original test data. We observe that
when modifying the training dataset by removing subsets of the signal with low spectral energy (Figure 2a)
or high frequencies (Figure 2b), there is a negligible effect on models’ classification accuracy on the original
test data. In Appendix D, we explain how images are modified in detail, and visualizations of the modified
images are included in Appendix G. In both settings after reducing more than half of the DCT basis vectors
to zeroes in the training data, the model’s generalization ability remains strong. This observation suggests
there is a considerable amount of irrelevant information in naturally occurring data from the perspective of
3We will always use the term “high” or “low” frequency on a relative scale.
6Published in Transactions on Machine Learning Research (11/2023)
0 10 30 50 70 90
p: percentage of DCT bases removed based on its magnitude8090Accuracy on the  
 original test set (%)
MNIST
FashionMNIST
CIFAR10
CIFAR100
SVHN
Caltech101
Imagenette
a. Parts of the signal with low spectral energy is irrelevant.
0 10 30 50 70 90
p: percentage of DCT bases removed based on its frequency80859095Accuracy on the  
 original test set (%)
 b. Parts of the signal with high-frequency basis is irrelevant.
Figure 2: Irrelevant frequencies exist in the natural data. Accuracy on the original test set remains
high when the training inputs are modified by removing parts of the signal with a) low spectrum energy
and b) high frequencies. Stars represent test accuracy on models trained using the original training input.
In setting a), training images are filtered based on the magnitude of the DCT basis. Specifically, parts of
the image with DCT bases that have a magnitude in the bottomp
100-th percentile are removed, so a large
pmeans more information is discarded. In setting b), training images are low-pass filtered, and pdenotes
the percentage of the high-frequency components that are discarded in the training data. We explain the
formulation of the two settings in Appendix D. Examples of the modified inputs are included in Appendix G.
a neural network classifier, and such information is often featured with low spectrum energy or lives at the
high end of the frequency spectrum.
This observation leads to the first part of Claim 3.1. That is, models only need to learn how to correctly
use the crucial class-defining information from the training data to optimize the training objective. On the
other hand, the extent to which they utilize irrelevant information in the data is not well-regulated. This
can be problematic and lead to solutions sensitive to perturbations. In Sec. 4, we validate Claim 3.1 using
a linear regression analysis with a synthetic dataset that contains irrelevant information. We demonstrate
there exist multiple optima of the training objective and those solutions can all correctly use the relevant
information in the data, but the way they exclude irrelevant information from computing the output is
different. Specifically, a robust model disregards irrelevant information by assigning a weight of zero to it,
but a non-robust model has certain non-zero weights which, when combined with the irrelevant information
in the input, yield a net-zero effect in the output. In this case, although the two models are indistinguishable
under the original training objective, the non-robust model will experience a reduction in model performance
should this irrelevant information become corrupted at test time.
3.2 Observation II: Model Robustness along Irrelevant Frequencies
Let us now focus on the second part of the claim. If models’ responses to perturbations along the irrelevant
frequenciesexplaintheirrobustnessdifference, thenweshouldexpectasimilaraccuracydropbetweenmodels
when perturbations are along relevant frequencies, but a much larger accuracy drop on less robust models
when test inputs are perturbed along irrelevant frequencies. Consider the robustness of the models when
the test data are corrupted with Gaussian noise: the perturbation along each spatial dimension is i.i.d and
drawn from a zero-mean Gaussian distribution with finite variance. This type of noise is commonly referred
to as the additive white Gaussian noise, where white refers to the property that the noise has uniform
power across the frequency spectrum (Diebold, 1998). Nevertheless, the previous discussion suggests that
noise along different frequencies does not have an equal impact on the models’ output. To verify this, we
assess the impact on model accuracy by perturbing only specific frequency ranges of the test inputs with
band-limited Gaussian noise.
To construct the band-limited Gaussian noise, we first follow the previous work (Wang et al., 2020) to group
DCT basis vectors based on their distance to the 0-frequency DC term and divide the entire DCT spectrum
into ten bands where each band occupies the same number of DCT bases. This is to ensure an identical ℓ2
norm among all the perturbations. Denote the binary mask of the i-th band by using M(i)∈{0,1}d×d, its
7Published in Transactions on Machine Learning Research (11/2023)
Dividing the DCT frequency
spectrum into ten bands
x(0)
x(1)
. . .
x(8)
x(9)
0123456789
Figure 3: Visualization of the band-limited Gaussian perturbations. The DCT spectrum is divided
into ten equally sized bands to generate band-limited Gaussian perturbations. Denote them by using ∆x(i),
wherei∈{0,1,...,9}. The frequency represented in the spectrum plot increases from the top-left (lowest
frequency) to the bottom-right corner (highest frequency). Therefore, as the band moves towards higher
frequencies, perturbations exhibit more high-frequency checkerboard patterns.
0 2 4 6 8
Perturbed frequency band (r)0.00.20.40.60.81.01.21.4Accuracy change under 
 band-limited perturbations (%)MNIST: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0.0000.0250.0500.0750.1000.1250.1500.1750.200Loss change under 
 band-limited perturbationsMNIST: Freq contribution to loss change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)024681012Accuracy change under 
 band-limited perturbations (%)CIFAR100: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0.00.51.01.52.02.5Loss change under 
 band-limited perturbationsCIFAR100: Freq contribution to loss change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0.00.51.01.52.02.53.03.5Accuracy change under 
 band-limited perturbations (%)Imagenette: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0.000.050.100.150.20Loss change under 
 band-limited perturbationsImagenette: Freq contribution to loss change
SGD
Adam
RMSProp
Figure 4: The effect of band-limited Gaussian perturbations on the model. Perturbations from the
lowest band, i.e., ∆x(0), have a similar effect on all the models, despite being trained by different algorithms
and exhibiting different robustness properties. On the other hand, models’ responses vary significantly when
the perturbation focuses on higher frequency bands. The results are averaged over three independently
initialized and trained models, and the shaded area indicates the standard error among the three models.
corresponding band-limited Gaussian noise is ∆x(i)=C⊤(M(i)⊙δ)C, whereδ∼N(0,σ2Id×d)andCis the
DCT transformation matrix defined in (4). Figure 3 illustrates how the frequency bases are grouped into ten
equally sized bands and examples of the band-limited Gaussian noise. Denote the perturbations by using
∆x(i), with ∆x(0)and∆x(9)representing the lowest and the highest band, respectively. To investigate the
effect of the perturbation ∆x(i)on the models, we measure the change in classification accuracy when the
test inputs are perturbed by ∆x(i):
1
NN/summationdisplay
n=1I{F(Xn) =Yn}−1
NKN/summationdisplay
n=1K/summationdisplay
k=1I/braceleftig
F(Xn+ ∆x(i)
k) =Yn/bracerightig
, (6)
whereFis a neural network classifier, {(Xn,Yn)}N
n=1represents the test dataset, each test input is perturbed
by i.i.d sampled ∆x(i)
kand the subscript kis used to differentiate between Kinstances of the randomly
sampled noise; and we use K= 10in our experiments. It is important to realize in (6) that the additive
noise ∆xis applied to the spatial signal X, although we are limiting the frequency band of the noise.
Figure 4 demonstrates how the classification accuracy degrades under different band-limited Gaussian noises
on MNIST, CIFAR100, and Imagenette; and results on the other datasets are included in Appendix G.
First, notice that the perturbation from the lowest band ∆x(0)has a similar impact on all the models
regardless of the algorithm they are trained by. There is however a noticeable difference in how models
trained by SGD and adaptive gradient methods respond to perturbations from higher frequency bands. On
models trained by SGD, the flattened curve implies that the effect of high-frequency perturbations on the
generalization performance quickly diminishes to zero, suggesting that models are not sensitive to changes
along the dimensions of irrelevant frequencies. Contrarily on models trained by the two adaptive gradient
methods, we observe a difference in the way models respond to perturbations of higher frequency bands. On
CIFAR100, for example, the two models are highly vulnerable to Gaussian perturbations from bands 5 to
8Published in Transactions on Machine Learning Research (11/2023)
7. This observation shows that when models, during their training phase, do not have mechanisms in place
to limit their use of irrelevant frequencies, their performance can be compromised if data along irrelevant
frequencies become corrupted at test time.
Onecanalsoobservethatmodels’responsestohigh-frequencyGaussianperturbationsvariesamongdatasets.
This can be attributed to the fact that (ir-)relevant frequencies are most likely going to be a unique char-
acteristic for a particular dataset. We do not expect a dataset that solely consists of hand-written digits
to share the same (ir-)relevant frequencies as one that consists of real-world objects. Moreover, the dimen-
sion (image resolution) of inputs for a given dataset matters, as a higher dimension potentially can allow
more irrelevant frequencies. Therefore, we emphasize that the goal of our work is not to identify the exact
(ir-)relevant frequencies among datasets. Rather, the analysis is built on the presence of irrelevant frequen-
cies in the dataset, especially towards the higher end of the frequency spectrum, and how models differ in
their robustness when trained by different algorithms. In the next section, we investigate the reason for such
a robustness difference by studying how the irrelevant frequencies affect the learning dynamics of GD and
signGD under a synthetic linear regression task.
4 Linear Regression Analysis with an Over-parameterized Model
In this section, we study the learning dynamics of GD and signGD on least squares regression with linear
models to understand why models trained using the two algorithms have the same standard generalization
performance but exhibit different robustness against perturbations. On a synthetic dataset that emulates
the energy distribution of natural datasets in the frequency domain, we design a learning task that has
multiple optima for the standard population risk, each with a different adversarial risk. We analyze the
weight adaptation under GD and signGD in both spatial and frequency domains and show that training
with signGD can result in larger weights associated with irrelevant frequencies, resulting in models with a
higher adversarial risk. Our result verifies claim 3.1. We report the main results here and defer the full
derivations to Appendix E.
4.1 Problem Setup
Consider a linear model f(x,w) =⟨w, x⟩withx,w∈Rd, wherewandxare the weight and the signal
represented in the spatial domain, respectively. Since the DCT transformation matrix Cis an orthogonal
matrix whose rows and columns are unit vectors, an alternative way to represent this model is:
f(x,w) =⟨w, x⟩=w⊤x=w⊤C⊤Cx=⟨˜w,˜x⟩=f(˜x,˜w),
where ˜wand˜xare the exact same weight and signal but are now represented in the frequency domain. This
means that for linear models, computing the output of the model can be carried out in either domain as long
as we use the matching representation of the signal and the weight. The goal of the linear analysis is to study
the learning dynamics of different algorithms in a synthetic and controlled environment where one can clearly
define the frequency-domain signal-target (ir)relevance to help understand the behavior of models in more
complex settings. For this reason, let ˜w∗denote the frequency-domain representation of the true model that
is used to interact with the input ˜xand generate the target: y= ˜x⊤˜w∗, where ˜w∗= ( ˜w∗
0,˜w∗
2,..., ˜w∗
d−1)⊤.
We consider the squared error pointwise loss, which can be equally formulated in both domains:
ℓ(x,y;w) =1
2|f(x,w)−y|2
=1
2|⟨x, w⟩−⟨x, w∗⟩|2andℓ(˜x,y; ˜w) =1
2|f(˜x,˜w)−y|2
=1
2|⟨˜x,˜w⟩−⟨ ˜x,˜w∗⟩|2.
Denote the error between the learned weight and the true weight at iteration tbye(t) =w(t)−w∗, and the
standard risk by Rs(w) =E[ℓ(X,Y ;w)]. In a similar way, those terms can be represented in the frequency
domain as ˜e(t) = ˜w(t)−˜w∗andRs( ˜w) =E/bracketleftbig
ℓ(˜X,Y ; ˜w)/bracketrightbig
. Now we are ready to explain the design philosophy
behind the synthetic dataset, the structure of the true model ˜w∗, and particularly, with regard to robustness,
the ideal model that minimizes the effect of perturbations.
9Published in Transactions on Machine Learning Research (11/2023)
Suppose that ˜Xfollows a Gaussian distribution N(˜µ,˜Σ). For analytical tractability, we consider ˜µ= 0and
a diagonal structure of ˜Σ, i.e., ˜Σ =diag(˜σ2
0,...,˜σ2
d−1). This implies that in the spatial domain, Xfollows
a Gaussian distribution N(0,Σ)where Σ =C⊤˜ΣC. In Appendix E.1, we provide examples of the spatial-
domain structure of the data, when we define the distribution directly in the frequency domain. In Sec. 3,
we demonstrate that natural datasets exhibit a particular energy profile where signals contain irrelevant
informationrepresentedbyhigh-frequencyandlow-amplitudewaves. Toemulatethissettingwithasynthetic
dataset, we define frequencies that are (ir)relevant in generating the target. Let Iirrel⊆{1,2,...,d−1}and
Irel={0,1,2,...,d−1}−Iirreldenote the set of irrelevant and relevant frequencies, respectively. Recall
that the goal is to make high-frequency components of the dataset irrelevant, so we exclude the DC term
(0/∈Iirrel) when considering irrelevant frequencies, as it is the lowest frequency possible. Next, we specify
the energy distribution of the synthetic dataset. The expected energy of a random signal following such a
distribution is
E/bracketleftbig
E(˜X)/bracketrightbig
=E/bracketleftiggd−1/summationdisplay
i=0|˜Xi|2/bracketrightigg
=d−1/summationdisplay
i=0E/bracketleftbig˜X2
i/bracketrightbig
=d−1/summationdisplay
i=0˜σ2
i. (7)
We assume that ˜σ2
i= 0ifi∈Iirrel, meaning the irrelevant frequencies of the data from the synthetic dataset
have zero energy contributions. The purpose of this is to imitate the behavior of real-world datasets, where
the high-frequency components have a negligible impact on the overall energy of the signal.
To see how having irrelevant frequencies affect the structure of the true model, notice that the definition of
the synthetic dataset implies ˜Xi= 0for alli∈Iirrel. This means that the true target value does not depend
on those irrelevant frequencies. Clearly, this linear model is over-paramaterized because one only needs to
specify ˜w∗
ifor alli∈Irelto establish the signal-target relationship.
The objective of the standard risk with such a synthetic dataset is not strictly convex, i.e., there are multiple
minimizers with zero standard risk, as the value of ˜w∗
ifor alli∈Iirrelhas no impact on the model output.
For clarity, let us define ˜W∗={˜w∗:Rs( ˜w∗) = 0}as the set that includes all standard risk minimizers.
Having multiple standard risk minimizers is the result of over-parametrization; however, there is a unique
solution that achieves zero standard risk and makes the model immune to any perturbations parallel to the
directions of the irrelevant frequencies, and it corresponds to having zero weight at irrelevant frequencies:
˜w∗
i= 0for alli∈Iirrel: Define such a robust standard risk minimizer as ˜wR∈˜W∗, we have
˜wR
i≜/braceleftbigg˜w∗
ifor alli∈Irel
0otherwise.(8)
Note that we use ˜w∗to denote any arbitrary standard minimizers in ˜W∗. To see why ˜wRis the most robust
standard minimizer, we introduce the adversarial risk to capture the worst-case performance of the model
under anℓ2-constrained perturbation. Similar to the squared error loss, the adversarial risk can also be
equally formulated in both domains:
Ra(w)≜E(X,Y)/bracketleftbigg
max
||∆x||2≤ϵℓ(X+ ∆x,Y;w)/bracketrightbigg
andRa( ˜w)≜E(˜X,Y)/bracketleftbigg
max
||∆˜x||2≤ϵℓ(˜X+ ∆˜x,Y; ˜w)/bracketrightbigg
,
where the ℓ2-constraint with a size of ϵhas an equivalent effect in both domains. To understand the
adversarial risk from a frequency-domain perspective, let us focus on Ra( ˜w):
Ra( ˜w) =E˜X/bracketleftbigg
max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+⟨∆˜x,˜w⟩/vextendsingle/vextendsingle2/bracketrightbigg
, (9)
where we focus on the expectation over ˜X, asYis replaced with/angbracketleftbig˜X,˜w∗/angbracketrightbig
. Notice that the maximization
is inside the expectation. This means that we are finding a separate perturbation for each input. Therefore,
the maximizer, ∆˜x∗, of a given ˜Xwithin the expectation in (9) is
∆˜x∗≜arg max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+⟨∆˜x,˜w⟩/vextendsingle/vextendsingle2=ϵsign[/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
]˜w
||˜w||2. (10)
10Published in Transactions on Machine Learning Research (11/2023)
Now knowing the worst-case perturbation to any ˜X, we can continue the derivation in (9) with
Ra( ˜w) =1
2E˜X/bracketleftbigg/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+ϵsign[/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
]∥˜w∥2/vextendsingle/vextendsingle2/bracketrightbigg
=1
2/summationdisplay
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2+ϵ/radicaligg
2
π/summationdisplay
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2∥˜w∥2+ϵ2
2∥˜w∥2
2. (11)
Finding the exact minimizer to (11) is more involved. Without doing that however, it is obvious that for an
arbitrary standard risk minimizer ˜w∗from ˜W∗, we can evaluate (11) at ˜w∗and obtain its the adversarial
risk as
Ra( ˜w∗) =ϵ2
2||˜w∗||2
2, (12)
where the first two terms in (11) become zero at any fixed standard risk minimizer. This shows that the
robustness of the standard risk minimizers against ℓ2-bounded perturbations is inversely proportional to the
norm of the linear model. That is, a smaller norm implies better robustness. Recall that when evaluating
the standard risk of the model, the weights associated with irrelevant frequencies do not matter, since they
are never used in computing the output of the model. On the contrary, the ||˜w∗||2
2term in (12) implies that
those weights matter when considering the robustness of the model under perturbations. It is not difficult
to see that the minimum adversarial risk can be achieved on a unique standard risk minimizer ˜wR(8).
Therefore, in the over-parameterized linear regression setting, a standard risk minimizer with a minimum
norm is preferred when considering the robustness of the model, and a model with zero weight at irrelevant
frequencies is the most robust solution among the standard risk minimizers. With this example, we verify
Claim 3.1. While standard risk minimizers can correctly use the relevant information of the data, their use
of irrelevant information is under-constrained. This can result in significant weight assigned to irrelevant
frequencies, making models more susceptible to perturbations.
Next, we study the learning dynamics of GD and signGD and demonstrate that the solutions found by GD
and signGD differ in the weight of the irrelevant frequencies. This causes the solutions found by the two
algorithms to have a similar standard population risk, but behave very differently under perturbations.
4.2 Analysis on the Learning Dynamics of GD and signGD
We now analyze the weight adaptation of a linear model under GD and signGD, and experimentally verify
our results. Our analysis shows that for the over-parameterized linear model, GD finds solutions with a
standard risk of exactly zero, and signGD finds solutions with a standard risk close to zero. However, they
have different robustness properties. In the presence of irrelevant frequencies, GD is more likely to converge
to a solution that is less sensitive to perturbations along the direction of irrelevant frequencies, whereas
signGD is more likely to converge to solutions that are more prone to such perturbations.
4.2.1 GD Dynamics
Let us start with GD in the spatial domain. Suppose that we initialize the weights in the spatial domain as
w(0) =W∼N(0,ΣW)where ΣW∈Rd×d. Similar to how both ˜XandXfollow a Gaussian distribution, the
frequencyrepresentationoftheinitializedweightalsofollowsaGaussiandistribution: ˜w(0) = ˜W∼N(0,˜ΣW)
where ˜ΣW=CΣWC⊤. To train the model, we use GD on the population risk:
w(t+ 1)←w(t)−η∇wRs(w(t)). (13)
The gradient computed using the population risk is ∇wRs(w(t)) =E/bracketleftbig
XX⊤/bracketrightbig
e(t) = Σe(t), and the learning
dynamics of GD in the spatial domain can be captured using:
e(t+ 1) =w(t+ 1)−w∗=w(t)−w∗−ηΣe(t) = (I−ηΣ)t+1e(0). (14)
This shows that the learned weight converges to the optimal weight w∗at a rate depending on Σ. To see
the GD dynamics in the frequency domain, we can simply perform DCT on both sides of (14):
˜e(t+ 1) =C(I−ηΣ)t+1e(0) = (I−η˜Σ)t+1˜e(0), (15)
11Published in Transactions on Machine Learning Research (11/2023)
where ˜Σis the covariance of ˜x. It is easy to see that no weight adaptation happens for the irrelevant
frequencies because ˜σ2
i= 0for alli∈Iirrel. As ˜Σis diagonal, choosing the learning rate ηsuch that
ηmaxi∈{0,...,d−1}˜Σii<1, we get that the asymptotic solution is
˜wGD
i≜lim
t→∞˜wi(t) =/braceleftbigg
˜w∗
ifor alli∈Irel
˜wi(0)otherwise.(16)
That is, the initial random weights at the irrelevant frequencies do not change. Using (12), we have
Ra(˜wGD) =ϵ2
2||˜wGD||2
2=ϵ2
2

/summationdisplay
i∈Irel˜w∗2
i+/summationdisplay
j∈Iirrel˜wj(0)2

. (17)
Comparing the standard risk minimizer found by GD with the robust standard risk minimizer in (8), we
notice that the GD solution is not the most robust among all standard risk minimizers, as it is sensi-
tive to perturbations along irrelevant frequencies. Suppose that the initialized weight in the frequency
domain is randomly sampled from N(0,σ2Id×d), and the signal-target relationship is determined by a hand-
ful of relevant frequencies. Taking the expectation of (17) over the randomly initialized weight, we have
E˜w(0)/bracketleftbig
Ra(˜wGD)/bracketrightbig
≈O(ϵ2dσ2), so the adversarial risk can be quite significant if there is a large number of
irrelevant frequencies, i.e., |Irel|≪dand|Iirrel|≈d.
This example shows that the GD solution is sensitive to initialization. Because there is no mechanism in
place to actively ensure that the weights associated with these irrelevant frequencies become zero, GD is not
forcing the initial weights to go to zero at those frequencies. One solution is to include the weight norm as a
penalty term along with the original optimization objective, but this can result in learning a biased solution.
Another simple fix is to initialize the weight at exactly 0. This robustifies the GD solution by initializing
those irrelevant weights at the most robust state.
4.2.2 SignGD Dynamics
AdaptivegradientalgorithmslikeAdamandRMSProputilizehistoricalgradientinformationasamomentum
mechanismforupdatingmodelparameters, therebyexpeditingthelearningprocess. However, itisimportant
to note that their acceleration is not solely attributable to this feature, nor is their adaptiveness limited to it.
In (3), we have demonstrated how signGD, a memory-free version of Adam and RMSProp, can adaptively
adjust the update using a coordinate-wise learning rate. Although signGD is not a suitable choice for
training deep neural networks (Riedmiller & Braun, 1993; Ma et al., 2022b), examining its behavior can
provide insights into the learning dynamics of other adaptive gradient methods (Karimi et al., 2016; Balles
& Hennig, 2018; Moulay et al., 2019). Additionally, in Sec. 4.2.3, we empirically justify the use of signGD
as a suitable alternative in understanding the learning dynamics of Adam and RMSProp.
Again, let us start with signGD in the spatial domain. The update rule using the population risk takes the
sign of the gradient computed using the population risk
w(t+ 1)←w(t)−ηsign[∇wRs(w)], (18)
and its learning dynamics in the spatial domain is
e(t+ 1) =w(t+ 1)−w∗=e(t)−ηsign[Σe(t)]. (19)
Unlike the GD dynamics in (14), (19) shows that the behavior of signGD depends on the sign of Σe(t),
and this means that when |[Σe(t)]i|≪1, training using signGD can accelerate the learning along the i-th
dimension. Although we can obtain Σfrom Σ =C⊤˜ΣC, the structure of Σis subject to variation based on
˜Σ, so it is difficult to find an analytical solution for the dynamics of the model trained under signGD, such
as (14) where we have a closed form for e(t)as a function of e(0)for models trained under GD. This means
that analyzing the signGD dynamics is limited to studying its step-by-step update based on the sign of the
entries in Σe(t).
12Published in Transactions on Machine Learning Research (11/2023)
The signGD learning dynamics in the frequency domain can be obtained by taking the DCT transformation
on both sides of (19):
˜e(t+ 1) = ˜e(t)−ηCsign[Σe(t)] = ˜e(t)−ηCsign[C⊤˜Σ˜e(t)], (20)
where the error and the covariance terms inside of the sign are also transformed into their frequency-domain
representations. Equation 20 shows that analyzing the behavior of signGD in the frequency domain requires
knowing the sign of the entries in C⊤˜Σ˜e(t). This term can be understood as an inverse DCT transformation
of˜Σ˜e(t), and with a diagonal structure of ˜Σ, we know that ˜Σ˜e(t) =/bracketleftbig
˜σ2
0,...,˜σ2
d−1/bracketrightbig⊤⊙˜e(t). However, similar
to the situation in (19), the sign of the entries in C⊤˜Σ˜e(t)is dependent on ˜e(t)at different steps, so obtaining
an analytical solution for the frequency-domain dynamics is also challenging.
In both (19) and (20), we see that understanding the signGD dynamics for any general ˜Σcan be complicated.
Thus, we focus on a structure of ˜Σthat simplifies the analysis but still allows us to understand why training
with signGD results in vulnerable models. In particular, we consider a data distribution where ˜X∼N(˜µ=
0,˜Σ =diag/braceleftbig
˜σ2
0,˜σ2
1,0/bracerightbig
). This definition implies that the data distribution contains irrelevant information at
the highest frequency basis and we have ˜X2= 0for all datapoints.
Now, we continue with signGD learning dynamics in the frequency domain from (20). Let us denote A(t) =√
3
3˜σ2
0˜e0(t)andB(t) =√
2
2˜σ2
1˜e1(t), andC=C(3)follows the DCT transformation matrix defined in (4). With
some algebraic manipulation, we have
˜e(t+ 1) = ˜e(t)−η
√
3
3(sign[A(t) +B(t)] + sign[A(t)] + sign[A(t)−B(t)])√
2
2(sign[A(t) +B(t)]−sign[A(t)−B(t)])√
6
6sign[A(t) +B(t)]−√
6
3sign[A(t)] +√
6
6sign[A(t)−B(t)]
, (21)
and we include its complete derivation in Appendix E.7. With this particular choice of ˜Σ, (21) shows that
weight adaptation depends on the sign of three terms: A(t),A(t) +B(t)andA(t)−B(t). In Table 9 of
Appendix E.8, we study the learning dynamics of signGD by analyzing all 27 sign combinations and their
corresponding updates. We report the main results here and defer the detailed analysis to Appendix E.8.
With a constant learning rate of η, the asymptotic signGD solution converges to an O(η)neighborhood of
the standard risk minimizer:
lim sup
t→∞|˜wi(t)−˜w∗
i|=O(η), (22)
wherei∈{0,1}. In particular, we demonstrate that ˜w0oscillates in an O(η)neighborhood of ˜w∗
0. Consider
Tas the first iteration after which ˜w0starts oscillating, and define ∆ ˜w2as the sum of all the updates in ˜w2
up to theT-th iteration. The limiting behavior of ˜w2under signGD update is
lim sup
t→∞|˜w2(t)|=|˜w2(T) +O(η)|=|˜w2(0) + ∆ ˜w2+O(η)|, (23)
where ˜w2(0)is the weight at initialization. This means that after Titerations, for all t′>T,˜w2(t′)stays in
anO(η)neighborhood of ˜w2(T). As such, we have the asymptotic solution found by signGD:
˜wsignGD= [ ˜w∗
0,˜w∗
1,˜w2(0) + ∆ ˜w2]⊤+O(η). (24)
From the perspective of training under the standard risk, the signGD solution is close to the optimum.
Specifically, its standard risk is
Rs(˜wsignGD) =E/bracketleftbig
ℓ(˜X,Y ;˜wsignGD)/bracketrightbig
=1
2E/bracketleftig/angbracketleftbig˜X,˜wsignGD−˜w∗/angbracketrightbig2/bracketrightig
=O((˜σ2
0+ ˜σ2
1)η2).(25)
Note that the standard risk of the GD solution is exactly zero; and by choosing a sufficiently small learning
rateη, the standard risk of the signGD solution can also be close to zero as well. However, their adversarial
risks are very different. Specifically, the adversarial risk of the asymptotic signGD solution is
Ra(˜wsignGD) =ϵ2
2||˜wsignGD||2
2=ϵ2
2/braceleftig
˜w∗2
0+ ˜w∗2
1+ ( ˜w2(0) + ∆ ˜w2)2/bracerightig
. (26)
13Published in Transactions on Machine Learning Research (11/2023)
We can compare it with the adversarial risk of the asymptotic solution found by GD under the same setup:
Ra(˜wGD) =ϵ2
2/braceleftbig
˜w∗2
0+ ˜w∗2
1+ ˜w2(0)2/bracerightbig
. (27)
It can be observed that the main difference between the two adversarial risks in (26) and (27) arises from the
difference in weights learned at the irrelevant frequency. Since their use of irrelevant frequency in the data
is under-constrained, neither algorithm can reduce ˜w2to zero, thereby neither solution is the most robust
standard risk minimizer. As discussed in Sec. 4.2.1, the GD solution is sensitive to weight initialization.
Before understanding the ∆ ˜w2term in the signGD solution, we first introduce two assumptions on the
synthetic dataset that serve to better emulate the distribution found in the natural dataset. Consider a
dataset with a strong task-relevant correlation between the relevant frequency component of the data and the
target, a realistic scenario as we discussed in Sec. 3.2. In this case, |˜w∗
0|and|˜w∗
1|can be large. Additionally,
with a weight initialization around zero, such as in methods by He et al. (2015) and Glorot & Bengio
(2010), the initial error |˜e0(0)|and|˜e1(0)|can be large and close to |˜w∗
0|and|˜w∗
1|when|˜w∗
0|≫| ˜w0(0)|
and|˜w∗
1|≫| ˜w1(0)|. Moreover, it is discussed in Sec. 3.1 and later supported empirically in Figure 8 of
Appendix G that the distribution of spectral energy heavily concentrates at the low end of the frequency
spectrum and decays quickly towards higher frequencies. Since ˜σ2
iis interpreted as the expected energy of
a random variable at the i-th frequency, it is reasonable to expect that˜σ2
1
˜σ2
0<1
3.
With the two assumptions, we demonstrate that ∆ ˜w2is proportional to |˜w∗
0|or|˜w∗
1|depending on the
initialization of|A(0)|and|B(0)|. In particular, we have
|∆ ˜w2|≈/braceleftigg√
3C|˜w∗
0|if|A(0)|<|B(0)|
3√
2˜σ2
1
2˜σ2
0C|˜w∗
1|if|A(0)|>|B(0)|,(28)
whereC∈[√
6
6,√
6
3]. To quantitatively understand the robustness difference between solutions found by the
two algorithms, we consider the ratio between the adversarial risk of the standard risk minimizers found
by GD (27) and signGD (26) with a three-dimensional input space. We observe that the solution found by
signGD is more sensitive to perturbations compared to the GD solution:
Ra(˜wsignGD)
Ra(˜wGD)≈

1 +C3˜w∗2
0
˜w∗2
0+ ˜w∗2
1if|A(0)|<|B(0)|
1 +C4˜w∗2
1
˜w∗2
0+ ˜w∗2
1if|A(0)|>|B(0)|,(29)
where1
2≤C3≤2and3
4˜σ4
1
˜σ4
0≤C4≤3˜σ4
1
˜σ4
0. Given that this ratio is always greater than 1, the linear model
obtained through GD is always more robust against ℓ2-bounded perturbations in comparison to the model
obtained from signGD.
4.2.3 Empirical Validation
To validate our analysis, in Figure 5 we create a three-dimensional dataset using (˜σ2
0,˜σ2
1,˜σ2
2) =
(0.01,0.0025,0), and ( ˜w∗
0,˜w∗
1,˜w∗
0) = (5,10,0), and compare the dynamics of the frequency-domain weight
error on models trained by GD, Adam, RMSProp, and signGD. All models are initialized with the same
weight and are trained using a fixed learning rate of 0.01. At each training iteration, we sample 1000 data
points and compute the gradient based on the sampled data. We want to clarify that even though we analyze
the weight update dynamics in both frequency and spatial domains, the actual training still takes place in
the spatial domain.
In (15), we show that the GD solution ˜wGD
i(t)converges to ˜w∗
iwith a rate of 1−η˜σ2
i. Therefore, when ˜σ2
iis
small, learning can be particularly slow for weights associated with the i-th frequency, as shown in Figure 5a.
On the other hand, notice in Table 9 that |˜e0|gets reduced by at least√
3
3regardless of the magnitude of ˜σ2
0
for signGD. This means that the magnitude of ˜σ2
idoes not directly affect the convergence speed. Instead,
the relative magnitude between A(t)andB(t)determines the frequency which receives priority during the
learning process. As a result, we observe an acceleration for models trained by signGD.
14Published in Transactions on Machine Learning Research (11/2023)
100101102103104105
Training iteration (t)012345
|e0(t)|
GD
Adam
RMSProp
SignGD
100101102103104105
Training iteration (t)0246810
|e1(t)|
100101102103104105
Training iteration (t)012345
|e2(t)|
|e2| grows till e0 begins
oscillating around 0
|e2| cannot be corrected
a. Dynamics of the error term
100101102103104105
Training iteration (t)0246
s(t)
GD
Adam
RMSProp
SignGD
100101102103104105
Training iteration (t)050100123141150
a(t)
b. The standard population risk Rsand the adversarial population risk Ra
Figure 5: Comparing (a) the learning dynamics, (b) the standard and adversarial population
risk of linear models trained by GD, Adam, RMSProp, and signGD. We create a three-dimensional
dataset created using (˜σ2
0,˜σ2
1,˜σ2
2) = (0.01,0.0025,0), and ( ˜w∗
0,˜w∗
1,˜w∗
2) = (5,10,0). All models are initialized
with the same weight ( ˜w0(0),˜w1(0),˜w2(0)) = (0.01,−0.01,0.02)and trained using a fixed learning rate
of0.01.(a) Dynamics of the error term. During the signGD training process, the error along the
irrelevant frequency grows until ˜e0starts to oscillate around 0. In our example, the green highlighted areas in
the figure correspond to the iterations before ˜e0starts to oscillate, and the red areas show that the error along
the irrelevant frequency cannot be corrected. (b) The standard population risk and the adversarial
population risk ( ϵ=√
2).We notice that despite all models can reach zero standard population risk, their
adversarial population risks are different. The adversarial population risk of models trained by adaptive
gradient methods is higher than the one from the model trained by GD, indicating lower robustness.
Next, we observe that the error trajectory for the model trained by signGD closely resembles the one from
the model trained by Adam for ˜e0and˜e1. In the analysis of signGD, we show that |˜e2|increases till|˜e0|starts
oscillating in O(η). Figure 5a shows that this pattern can be observed in models trained by Adam as well.
This shows that signGD is a suitable alternative to understanding the learning dynamics of models under the
proposed linear regression task. For models trained by GD, since there is no update on the weight associated
with the irrelevant frequency, ˜e2remains at the initialized value throughout training. To demonstrate the
weight adaptation under signGD, we divide the training into two phases, as highlighted by two background
colors. The green area indicates that |˜e0|decreases and|˜e2|increases in the meanwhile. Once oscillation
begins for|˜e0|,|˜e2|can no longer be corrected. This behavior corresponds to the purple area in Figure 5a.
InFigure5b, wecomparethestandardpopulationriskandtheadversarialpopulationriskofdifferentmodels.
We notice that despite all models reaching near zero standard population risk, their adversarial population
riskisdifferent. Inparticular, theadversarialpopulationriskofmodelstrainedbyadaptivegradientmethods
is higher than the one from the model trained by GD, indicating lower robustness. Choosing ϵ=√
2in (12),
the adversarial risk of those standard risk minimizers is exactly the squared ℓ2norm of the weight. With
our choice of initialization, the resulting |A(0)|and|B(0)|are0.0289and0.0177respectively. This means
that the ratio between the two adversarial risks isRa(˜wsignGD)
Ra(˜wGD)∈[1.04,1.15]according to (29), and this aligns
with the ratio of 1.146obtained empirically from the experiments.
This simple problem illustrates how the optimization algorithms and an over-parameterized model might
interact, and learning with signGD can lead to a solution that is more prone to perturbations. In this
section, we focus on analyzing the robustness of the solution from a frequency domain perspective, that is,
15Published in Transactions on Machine Learning Research (11/2023)
Table 1:Comparing the upper bound on the Lipschitz constant and the averaged robust accu-
racy of neural networks trained by SGD, Adam, and RMSProp. We follow (Gouk et al., 2021) to
compute the Lipschitz constants of each layer in isolation and multiply them together to establish an upper
bound on the constant of the entire network. Notice that across all selected datasets, models trained by SGD
have a considerably smaller upper bound compared to models trained by Adam and RMSProp. In Figure 1,
we demonstrate the robustness of the neural networks under Gaussian noise, ℓ2andℓ∞bounded adversarial
perturbations (Croce & Hein, 2020). Here, we average the accuracy across the perturbations and get a single
score quantifying the model’s robustness. All results are averaged over three independently initialized and
trained models.
Dataset MNIST Fashion CIFAR10 CIFAR100 SVHN Caltech101 Imagenette
/producttextl
i=1L(ϕi)SGD 3.80 3.83 26.81 40.41 22.65 18.53 23.99
Adam 5.75 8.12 28.70 41.87 30.45 26.20 28.55
RMSProp 6.21 5.11 37.75 41.71 28.31 45.84 27.11
Averaged
Robust Acc.SGD 77.97% 77.95% 63.21% 55.65% 69.08% 71.42% 67.59%
Adam 65.64% 67.60% 57.71% 45.25% 65.60% 55.03% 58.86%
RMSProp 63.54% 71.34% 56.47% 47.55% 65.37% 53.16% 57.98%
the behavior of ˜wwith an input perturbation of ∆˜x. In Appendix E.9, we present a spatial interpretation of
the result and demonstrate how signals with irrelevant frequencies contain spatially redundant dimensions.
5 Connecting the Norm of Linear Models to the Lipschitzness of Neural Networks
The takeaway from the over-parameterized linear regression analysis is that among all standard risk mini-
mizers, the minimum norm solution is the most robust one. That is, a smaller weight norm implies better
robustness. This suggests a connection between the weight norm and model robustness. Nonetheless, the
major limitation of the analysis is that it is designed for a linear model. In this section, we generalize such
a connection to the deep learning setting and verify it using the robustness of neural networks trained by
different algorithms.
One major obstacle is that the notion of weight norm as defined for linear models is not generally applicable
to neural networks. However, we can still relate the weight of a network to its sensitivity with respect to
changes in the input space. Consider a single-layer ReLU-activated feedforward network with x∈Rdand
W∈RD×d. With a perturbation of ∆x∈Rdconstrained by the vector ℓp-norm, the maximum change in
the model output as measured by the same norm can be bounded using
∥ReLU (W(x+ ∆x))−ReLU (Wx)∥p≤∥W∆x∥p≤∥W∥p∥∆x∥p, (30)
where∥W∥pdenotes the vector ℓp-norm induced matrix norm of the weight Wand is referred to as the
Lipschitz constant of this single-layer model.
Consider the ℓpvector norm, for all x1,x2∈R, a function fis said to be Lipschitz continuous if
||f(x1)−f(x2)||p≤L||x1−x2||p, for some real-valued Lipschitz constant L≥0.4Indeed, the Lipschitz
constant of a function with respect to inputs captures how sensitive the model is in relation to changes in
the input space.
In the single-layer model example, its Lipschitz constant is exactly the matrix norm of the weight. More
generally, consider the feed-forward neural network as a series of function compositions:
f(x) = (ϕl◦ϕl−1◦...◦ϕ1)(x),
4Any value of Lsatisfying the Lipschitz condition is considered a valid Lipschitz constant. For the sake of clarity, we will
refer to the smallest (optimal) Lipschitz constant as L.
16Published in Transactions on Machine Learning Research (11/2023)
where each ϕiis a linear operation, an activation function, or a pooling operation. A particularly useful
property of the Lipschitz function is that the composition of Lipschitz functions with Lipschitz constant
L1,L2,...,LNw.r.t. the same norm is also Lipschitz with an upper-bound on the Lipschitz constant
L≤L1L2...LN. Denoting the Lipschitz constant of function fasL(f), we can establish an upper bound on
the Lipschitz constant for the entire feed-forward neural network using
L(f)≤l/productdisplay
i=1L(ϕi). (31)
As such, for a multi-layer neural network that comprises repeated layers of linear operation followed by
non-linear activation, we can upper bound the change in model output with respect to the change in the
input space by multiplying the operator norms of the weights. It is important to realize that (31) is not a
tight upper bound, and in fact, computing the exact Lipschitz constant of the neural network is NP-hard
(Virmaux & Scaman, 2018). Nonetheless, this approach allows us to draw connections between the weight
and the robustness of the model in the context of neural networks.
Results in Sec. 4 indicate that linear models trained by signGD have larger weight norms, indicating less
robustness. Therefore, we expect in the deep learning setting that neural networks trained by SGD are more
robust, as they have a smaller Lipschitz upper bound, as shown in Figure 1. To verify this, we follow the
techniques in Gouk et al. (2021) and compute an upper bound on the Lipschitz constant of the same neural
networks trained by SGD, Adam, and RMSProp in Figure 1. Results are shown in Table 1. The result
shows that across all datasets and architectures, models trained by SGD have a smaller upper bound on
the Lipschitz constant compared to models trained by the two adaptive gradient methods. In Figure 1, we
demonstrate the robustness of the neural networks under Gaussian noise, ℓ2andℓ∞bounded adversarial
perturbations (Croce & Hein, 2020). In Table 1, we average the accuracy across the perturbations and get
a single score quantifying the model’s robustness. We observe that a smaller upper bound on the Lipschitz
constant of a neural network implies better robustness against perturbations.
6 Conclusions
In this paper, we highlighted the robustness difference between models trained by SGD and adaptive gradient
methods, particularly Adam and RMSProp. To understand this phenomenon, we leveraged a frequency-
domainanalysis,anddemonstratedthatnaturaldatasetscontainfrequenciesthatareirrelevanttominimizing
the standard training loss. Empirically, through a band-limited perturbation analysis on neural networks
trained on common vision datasets, we showed that models trained by the adaptive gradient method utilize
the statistics in the irrelevant frequency, and thus they experience a huge drop in performance when the
same statistics become corrupted. Analytically, on a synthetic linear regression task where the dataset was
designed to contain target-irrelevant frequencies, we showed that while both GD and signGD can find the
solution with standard risks close to zero, the adversarial risk of the asymptotic solution found by signGD
can be larger than that of GD. Such results from the linear analysis explained the observation in Figure 1 and
suggested that a smaller model parameters’ weight norms may indicate a larger model robustness. Finally,
in the deep learning setting, we showed that models trained by SGD have a noticeably smaller Lipschitz
constant than those trained by Adam and RMSProp.
Our work has some limitations. First, when conducting a theoretical analysis of various optimizers, we
opted for signGD as a simpler alternative to Adam and RMSProp. Second, our focus was primarily on
linear models. However, it is crucial to acknowledge that deep neural networks inherently possess non-linear
characteristics, which limit the depth of insights derived from linear models. Therefore, one promising future
direction is to incorporate tools such as neural tangent kernels (Jacot et al., 2018), which provide a deeper
understanding of network dynamics. Third, our analysis focuses on optimization algorithms along with the
standard objective function. We can also study the effect of optimizer with alternative objectives that are
designedtoimprovetherobustnessofthemodel(Simon-Gabrieletal.,2019;Wenetal.,2020;Maetal.,2020;
Foret et al., 2021). For instance, the effect of adversarial training using perturbations similar to the Fast
Gradient Sign Method (FGSM) under the linear regression setup has been studied by Ma et al. (2020). In
17Published in Transactions on Machine Learning Research (11/2023)
linear classification, Wei et al. (2023) showed that minimizing the sharpness-aware loss (SAM) (Foret et al.,
2021) can lead to robust models. Further discussions on this study can be found in Appendix F. Another
promising direction for future research is to analyze model robustness by coupling various optimization
algorithms with different optimization objectives.
Acknowledgments
Avery Ma acknowledges the funding from the Natural Sciences and Engineering Research Council (NSERC)
through the Canada Graduate Scholarships – Doctoral (CGS D) program. Amir-massoud Farahmand ac-
knowledges the funding from the CIFAR AI Chairs program, as well as the support of the NSERC through
the Discovery Grant program (2021-03701). Yangchen Pan acknowledges the support from the Turing AI
World Leading Fellow. Resources used in preparing this research were provided, in part, by the Province of
Ontario, the Government of Canada through CIFAR, and companies sponsoring the Vector Institute. We
would like to also thank the members of the Adaptive Agents Lab who provided feedback on a draft of this
paper.
References
Naman Agarwal, Rohan Anil, Elad Hazan, Tomer Koren, and Cyril Zhang. Disentangling adaptive gradient
methods from learning rates. arXiv preprint arXiv:2002.11803 , 2020. 1
Nasir Ahmed, T Natarajan, and Kamisetty R Rao. Discrete cosine transform. In IEEE transactions on
Computers , 1974. 5
Shun-ichi Amari, Jimmy Ba, Roger Grosse, Xuechen Li, Atsushi Nitanda, Taiji Suzuki, Denny Wu, and
Ji Xu. When does preconditioning help or hurt generalization? In International Conference on Learning
Representations (ICLR) , 2021. 3
Hagai Attias and Christoph Schreiner. Temporal low-order statistics of natural sounds. In Advances in
Neural Information Processing Systems (NeurIPS) , 1996. 5
LukasBallesandPhilippHennig. DissectingAdam: Thesign,magnitudeandvarianceofstochasticgradients.
InInternational Conference on Machine Learning (ICML) , 2018. 4, 12
PhilippBenz, ChaoningZhang, AdilKarjauv, andInSoKweon. Revisitingbatchnormalizationforimproving
corruption robustness. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
Vision (WACV) , 2021a. 25
PhilippBenz, ChaoningZhang, andInSoKweon. Batchnormalizationincreasesadversarialvulnerabilityand
decreases adversarial transferability: A non-robust feature perspective. In Proceedings of the International
Conference on Computer Vision (ICCV) , 2021b. 25
FrancescoCroceandMatthiasHein. Reliableevaluationofadversarialrobustnesswithanensembleofdiverse
parameter-free attacks. In International Conference on Machine Learning (ICML) , 2020. 2, 16, 17, 25,
26, 56, 57
André Belotto da Silva and Maxime Gazeau. A general system of differential equations to model first-order
adaptive algorithms. In Journal of Machine Learning Research (JMLR) , 2020. 4
Wei Dai, Chia Dai, Shuhui Qu, Juncheng Li, and Samarjit Das. Very deep convolutional neural networks for
raw waveforms. In IEEE International cConference on Acoustics, Speech and Signal Processing (ICASSP) ,
2017. 24, 25
Yao Deng, Xi Zheng, Tianyi Zhang, Chen Chen, Guannan Lou, and Miryung Kim. An analysis of adversarial
attacks and defenses on autonomous driving models. In IEEE International Conference on Pervasive
Computing and Communications (PerCom) , 2020. 4
Francis X Diebold. Elements of forecasting . Thomson South-Western, 1998. 7
18Published in Transactions on Machine Learning Research (11/2023)
Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and Ruitong Huang. MMA training: Direct
input space margin maximization through adversarial training. In International Conference on Learning
Representations (ICLR) , 2020. 4
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Un-
terthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil
Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International
Conference on Learning Representations (ICLR) , 2021. 2, 24
JohnDuchi, EladHazan, andYoramSinger. Adaptivesubgradientmethodsforonlinelearningandstochastic
optimization. In Journal of Machine Learning Research (JMLR) , 2011. 4
LiFei-Fei, RobFergus, andPietroPerona. Learninggenerativevisualmodelsfromfewtrainingexamples: An
incremental Bayesian approach tested on 101 object categories. Computer Vision and Pattern Recognition
Workshop , 2004. 2
Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for
efficiently improving generalization. In International Conference on Learning Representations (ICLR) ,
2021. 5, 17, 18, 45
Joseph Fourier. Théorie analytique de la chaleur (The Analytic Theory of Heat) . 1822. 5
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural networks.
InInternational Conference on Artificial Intelligence and Statistics (AISTATS) , 2010. 14, 43
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
InInternational Conference on Learning Representations (ICLR) , 2015. 5
Henry Gouk, Eibe Frank, Bernhard Pfahringer, and Michael J Cree. Regularisation of neural networks by
enforcing Lipschitz continuity. Machine Learning , 2021. 16, 17
Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, and Timothy A
Mann. Improving robustness using generated data. In Advances in Neural Information Processing Systems
(NeurIPS) , 2021. 5
Herbert Gross. Handbook of Optical Systems: Fundamentals of Technical Optics . 2005. 6
SuriyaGunasekar, BlakeEWoodworth, SrinadhBhojanapalli, BehnamNeyshabur, andNatiSrebro. Implicit
regularization in matrix factorization. In Advances in Neural Information Processing Systems (NeurIPS) ,
2017. 1, 3
ChuanGuo, JaredSFrank, andKilianQWeinberger. Lowfrequencyadversarialperturbation. In Proceedings
of the Conference on Uncertainty in Artificial Intelligence (UAI) , 2020. 6
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-
level performance on ImageNet classification. In Proceedings of the International Conference on Computer
Vision (ICCV) , 2015. 14, 43
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In
Proceedings of the European Conference on Computer Vision (ECCV) , 2016. 24
DanHendrycks,NormanMu,EkinDogusCubuk,BarretZoph,JustinGilmer,andBalajiLakshminarayanan.
AugMix: A simple data processing method to improve robustness and uncertainty. In International
Conference on Learning Representations (ICLR) , 2020. 4
Geoffrey Hinton, Nitish Srivastava, and Kevin Swersky. Neural networks for machine learning lecture 6a:
overview of mini-batch gradient descent. 2012. 1
Jeremy Howard. Imagenette. URL https://github.com/fastai/imagenette/ . 2
19Published in Transactions on Machine Learning Research (11/2023)
Hanxun Huang, Yisen Wang, Sarah Erfani, Quanquan Gu, James Bailey, and Xingjun Ma. Exploring
architectural ingredients of adversarially robust deep neural networks. In Advances in Neural Information
Processing Systems (NeurIPS) , 2021. 5
Jinggang Huang and David Mumford. Statistics of natural images and models. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition (CVPR) , 1999. 5
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander Madry.
Adversarial examples are not bugs, they are features. In Advances in Neural Information Processing
Systems (NeurIPS) , 2019. 46
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing
internal covariate shift. In International Conference on Machine Learning (ICML) , 2015. 2
Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and generalization
in neural networks. 2018. 17
Hamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-gradient
methods under the Polyak-Łojasiewicz condition. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases , 2016. 4, 12
DiederikPKingmaandJimmyBa. Adam: Amethodforstochasticoptimization. In International Conference
on Learning Representations (ICLR) , 2015. 1, 4
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. 2009. 2
Kun Kuang, Peng Cui, Susan Athey, Ruoxuan Xiong, and Bo Li. Stable prediction across unknown envi-
ronments. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &
Data Mining , 2018. 4
RamShankarSivaKumar, MagnusNyström, JohnLambert, AndrewMarshall, MarioGoertzel, AndiComis-
soneru, Matt Swann, and Sharon Xia. Adversarial machine learning-industry perspectives. In IEEE
Security and Privacy Workshops (SPW) , 2020. 2, 5
Yann LeCun. The MNIST database of handwritten digits. http://yann. lecun. com/exdb/mnist/ , 1998. 2
Zhuohang Li, Cong Shi, Yi Xie, Jian Liu, Bo Yuan, and Yingying Chen. Practical adversarial attacks against
speaker recognition systems. In Proceedings of the 21st International Workshop on Mobile Computing
Systems and Applications , 2020. 4
Kaifeng Lyu and Jian Li. Gradient descent maximizes the margin of homogeneous neural networks. In
International Conference on Learning Representations (ICLR) , 2020. 1
Avery Ma, Fartash Faghri, Nicolas Papernot, and Amir-massoud Farahmand. SOAR: Second-order adver-
sarial regularization. arXiv preprint arXiv:2004.01832 , 2020. 5, 17
Avery Ma, Aladin Virmaux, Kevin Scaman, and Juwei Lu. Improving hierarchical adversarial robustness of
deep neural networks. arXiv preprint arXiv:2102.09012 , 2021. 5
Avery Ma, Nikita Dvornik, Ran Zhang, Leila Pishdad, Konstantinos G Derpanis, and Afsaneh Fazly. SAGE:
Saliency-guided mixup with optimal rearrangements. In British Machine Vision Conference (BMVC) ,
2022a. 4, 5
Chao Ma, Lei Wu, and Weinan E. A qualitative study of the dynamic behavior for adaptive gradient
algorithms. In Mathematical and Scientific Machine Learning (MSML) , 2022b. 4, 12
AleksanderMadry, AleksandarMakelov, LudwigSchmidt, DimitrisTsipras, andAdrianVladu. Towardsdeep
learning models resistant to adversarial attacks. In International Conference on Learning Representations
(ICLR), 2018. 5
Stéphane Mallat. A wavelet tour of signal processing . Elsevier, 1999. 5
20Published in Transactions on Machine Learning Research (11/2023)
Robert McAulay and Thomas Quatieri. Speech analysis/synthesis based on a sinusoidal representation. In
IEEE Transactions on Acoustics, Speech, and Signal Processing , 1986. 5
Emmanuel Moulay, Vincent Léchappé, and Franck Plestan. Properties of the sign gradient descent algo-
rithms.Information Sciences , 2019. 4, 12, 32
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading dig-
its in natural images with unsupervised feature learning. In Neurips Workshop on Deep Learning and
Unsupervised Feature Learning , 2011. 2
Alan V Oppenheim, John R Buck, and Ronald W Schafer. Discrete-time signal processing . Pearson, 2001. 5
William B Pennebaker and Joan L Mitchell. JPEG: Still image data compression standard . Springer Science
& Business Media, 1992. 5
Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and Guillaume
Lajoie. Gradient starvation: A learning proclivity in neural networks. In Advances in Neural Information
Processing Systems (NeurIPS) , 2021. 3
Adnan Qayyum, Junaid Qadir, Muhammad Bilal, and Ala Al-Fuqaha. Secure and robust machine learning
for healthcare: A survey. In IEEE Reviews in Biomedical Engineering , 2020. 4
Qian Qian and Xiaoyuan Qian. The implicit bias of adagrad on separable data. In Advances in Neural
Information Processing Systems (NeurIPS) , 2019. 1
Sylvestre-Alvise Rebuffi, Sven Gowal, Dan A Calian, Florian Stimberg, Olivia Wiles, and Timothy Mann.
Data augmentation can improve robustness. In Advances in Neural Information Processing Systems
(NeurIPS) , 2021. 5
Sashank J Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond. In International
Conference on Learning Representations (ICLR) , 2018. 24
Martin Riedmiller and Heinrich Braun. A direct adaptive method for faster backpropagation learning: The
RPROP algorithm. In IEEE international conference on neural networks , 1993. 4, 12
Daniel L Ruderman. The statistics of natural images. Network: computation in neural systems , 1994. 5, 6
A. van der Schaaf and J.H. van Hateren. Modelling the power spectra of natural images: statistics and
information. Vision research , 1996. 6
Odelia Schwartz and Eero P Simoncelli. Natural signal statistics and sensory gain control. Nature neuro-
science, 2001. 5, 6
Steven H Schwartz. Visual perception: A clinical orientation . McGraw-Hill Medical Pub. Division, 2004. 6
Yash Sharma, Gavin Weiguang Ding, and Marcus Brubaker. On the effectiveness of low frequency pertur-
bations. In Proceedings of the International Joint Conferences on Artificial Intelligence (IJCAI) , 2019.
6
Zheyan Shen, Jiashuo Liu, Yue He, Xingxuan Zhang, Renzhe Xu, Han Yu, and Peng Cui. Towards out-of-
distribution generalization: A survey. arXiv preprint arXiv:2108.13624 , 2021. 4
Samuel Henrique Silva and Peyman Najafirad. Opportunities and challenges in deep learning adversarial
robustness: A survey. arXiv preprint arXiv:2007.00753 , 2020. 2
Carl-Johann Simon-Gabriel, Yann Ollivier, Leon Bottou, Bernhard Schölkopf, and David Lopez-Paz. First-
order adversarial vulnerability of neural networks and input dimension. In International Conference on
Machine Learning (ICML) , 2019. 5, 17
Eero P Simoncelli. Statistical models for images: Compression, restoration and synthesis. In Conference on
Signals, Systems, and Computers , 1997. 5
21Published in Transactions on Machine Learning Research (11/2023)
Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, and Nathan Srebro. The implicit bias
of gradient descent on separable data. In Journal of Machine Learning Research (JMLR) , 2018. 1, 3
Andreas Peter Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross Wightman, Jakob Uszkoreit, and Lu-
cas Beyer. How to train your vit? data, augmentation, and regularization in vision transformers. In
Transactions on Machine Learning Research (TMLR) , 2022. 26
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob
Fergus. Intriguing properties of neural networks. In International Conference on Learning Representations
(ICLR), 2014. 4
David J Tolhurst, Yoav Tadmor, and Tang Chao. Amplitude spectra of natural images. Ophthalmic and
Physiological Optics , 1992. 6
Richard E Turner. Statistical models for natural sounds . PhD thesis, UCL (University College London),
2010. 5
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, David Lopez-Paz, and
Yoshua Bengio. Manifold Mixup: Better representations by interpolating hidden states. In International
Conference on Learning Representations (ICLR) , 2019. 4
Aladin Virmaux and Kevin Scaman. Lipschitz regularity of deep neural networks: analysis and efficient
estimation. In Advances in Neural Information Processing Systems (NeurIPS) , 2018. 17
Martin J Wainwright and Eero Simoncelli. Scale mixtures of gaussians and the statistics of natural images.
InAdvances in Neural Information Processing Systems (NeurIPS) , 1999. 6
Gregory K Wallace. The JPEG still picture compression standard. Communications of the ACM , 1991. 6
Bohan Wang, Qi Meng, Wei Chen, and Tie-Yan Liu. The implicit bias for adaptive optimization algorithms
on homogeneous neural networks. In International Conference on Machine Learning (ICML) , 2021. 1
Haohan Wang, Xindi Wu, Zeyi Huang, and Eric P Xing. High-frequency component helps explain the
generalization of convolutional neural networks. In Proceedings of the IEEE Conference on Computer
Vision and Pattern Recognition (CVPR) , 2020. 7
Haotao Wang, Aston Zhang, Shuai Zheng, Xingjian Shi, Mu Li, and Zhangyang Wang. Removing batch
normalization boosts adversarial training. In International Conference on Machine Learning (ICML) ,
2022. 25
Pete Warden. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv preprint
arXiv:1804.03209 , 2018. 2, 24, 27
Zeming Wei, Jingyu Zhu, and Yihao Zhang. Sharpness-aware minimization alone can improve adversarial
robustness. In ICML Workshop on New Frontiers in Adversarial Machine Learning , 2023. 5, 18, 45, 46
Yuxin Wen, Shuai Li, and Kui Jia. Towards understanding the regularization of adversarial robustness on
neural networks. In International Conference on Machine Learning (ICML) , 2020. 5, 17
Ashia C Wilson, Rebecca Roelofs, Mitchell Stern, Nati Srebro, and Benjamin Recht. The marginal value of
adaptive gradient methods in machine learning. In Advances in Neural Information Processing Systems
(NeurIPS) , 2017. 1, 3, 4
Boxi Wu, Jinghui Chen, Deng Cai, Xiaofei He, and Quanquan Gu. Do wider neural networks really help
adversarial robustness? In Advances in Neural Information Processing Systems (NeurIPS) , 2021. 5
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: a novel image dataset for benchmarking
machine learning algorithms. arXiv preprint arXiv:1708.07747 , 2017. 2
22Published in Transactions on Machine Learning Research (11/2023)
Dong Yin, Raphael Gontijo Lopes, Jon Shlens, Ekin Dogus Cubuk, and Justin Gilmer. A Fourier perspective
onmodelrobustnessincomputervision. In Advances in Neural Information Processing Systems (NeurIPS) ,
2019. 6
Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. DORO: Distributional and outlier robust
optimization. In International Conference on Machine Learning (ICML) , 2021. 4
Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric Xing, Laurent El Ghaoui, and Michael Jordan. Theo-
retically principled trade-off between robustness and accuracy. In International Conference on Machine
Learning (ICML) , 2019. 27
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. Mixup: Beyond empirical risk
minimization. In International Conference on Learning Representations (ICLR) , 2018. 4
Haoran Zhu, Boyuan Chen, and Carter Yang. Understanding why vit trains badly on small datasets: An
intuitive perspective. arXiv preprint arXiv:2302.03751 , 2023. 25
23Published in Transactions on Machine Learning Research (11/2023)
A Summary of the Supplementary Material
The supplementary material is organized as follows. In Appendix B, we first describe the data augmentation,
the exact optimization schedule, and the model architectures used to train the models. In Appendix C, we
describe the complete generalization and robustness results in Table 3 and how they are used to generate
Figure 1. In Appendix D, we discuss how the training inputs are modified when making the observations
in Sec. 3. In Appendix E, we provide additional detail on the linear analysis in Sec. 4. In Appendix F,
we discuss how our analysis relates to the sharpness-aware minimization (SAM). Finally, in Appendix G,
we provide additional figures including visualization of the perturbed images, the modified images used in
Sec. 3.1, and the frequency sensitivity comparison in Sec. 3.2.
B Training Details
Data augmentation: In our paper, we study how the presence of irrelevant information in the dataset
affects the robustness of the model when trained by different algorithms. We approach this problem from a
frequency-domain perspective. Specifically, we leverage the structure and energy profile of the dataset in the
frequency domain. While data augmentation methods are widely used in training machine learning models
to improve generalization and reduce overfitting, understanding how those methods affect the datasets in
the frequency domain requires additional analysis tailored for each augmentation method. Therefore, on
FashionMNIST, CIFAR10, CIFAR100, Caltech101, and Imagenette, training inputs are augmented with
random horizontal flipping, a method that does not change the frequency profile of the image.
Optimization schedule: For all models, we use the following default PyTorch (v1.12.1) optimization
settings. For SGD, we disable all of the following mechanism: dampening, weight decay, and Nesterov. For
Adam, we use the default values of β1= 0.9β2= 0.999,ϵ= 10−8and disable weight decay and disable
AMSgrad (Reddi et al., 2018). For RMSProp, we use default values of α= 0.99,ϵ= 10−8, and disable
momentum and disable centered RMSProp which normalizes the gradient by an estimation of its variance.
All models are trained for 200 epochs. In Table 2, we list the initial learning rate. The learning rate decreases
by a factor of 0.1 at epoch 100 and 150.
Table 2:Experiment setup: the initial learning rate and the definition of neural networks in this paper.
Dataset Optimization Initial Learning Rate
MNISTSGD 0.1
Adam 0.0005
RMSProp 0.0005
FashionMNISTSGD 0.1
Adam 0.0005
RMSProp 0.0005
CIFAR10SGD 0.2
Adam 0.0002
RMSProp 0.0005
CIFAR100SGD 0.3
Adam 0.0005
RMSProp 0.0005
SVHNSGD 0.2
Adam 0.0002
RMSProp 0.0002
Caltech101SGD 0.05
Adam 0.0002
RMSProp 0.001
ImagenetteSGD 0.1
Adam 0.0002
RMSProp 0.0002
Speech CommmandsSGD 0.1
Adam 0.1
RMSProp 0.1Dataset Structure
MNIST
FashionMnistConv(1, 16, 4) - ReLU -
Conv(16, 32, 4) - ReLU -
FN(21632, 100) - FN(100, 10) - SM(10)
CIFAR10
CIFAR100
SVHN
Caltech101
ImagenettePreActResNet18 (He et al., 2016)
ViT-B/16 (Dosovitskiy et al., 2021)
Speech Commands M5 (Dai et al., 2017)
Model architecture: For MNIST and FashionMNIST, we use a ReLU-activated, two-layer convolutional
neural network ending with two fully-connected layers. For CIFAR10, CIFAR100, SVHN, Caltech101, and
Imagenette, we use PreActResNet18 (He et al., 2016) and Vision Transformers (ViT-B/16) (Dosovitskiy
et al., 2021). For the Speech Commands dataset (Warden, 2018), we use the M5 network architecture
24Published in Transactions on Machine Learning Research (11/2023)
defined by Dai et al. (2017). See Table 2 for details of all architectures used in this paper. We denote
Conv(i,o,k) as a convolution layer having iinput channels, ooutput channels with kbykfilters, FN( i,o)
as a fully-connect layer with iinput channels and ooutput channels, and SM( o) as the soft-max layer with
ooutput. The stride for all convolution layers is 1. The main experiments in our work are centered around
models based on convolutional neural networks, within the computer vision domain. Additional results from
using ViT-B/16 and on the Speech Commands dataset can be found in Table 5 and Table 6, respectively.
Batch normalization: We concentrate on a particular aspect of the training process: the selection of
optimizers. Our aim is to shed light on how this critical component influences the robustness of trained
models. It has been recently shown that the use of batch normalization (BN) can also affect the robustness
of the model (Benz et al., 2021b;a; Wang et al., 2022). Consequently, to maintain focus on the impact of
optimizers, we have omitted BN in the training phase for the experiments leading to the results in Figure 1
and the analysis in Sec. 3. However, to show that our conclusions remain valid for models with BN, we have
included additional results that incorporate BN in Table 4.
C Results on Standard Generalization and Model Robustness
Main results: Table 3 summarizes the result on the standard generalization ability and robustness proper-
ties of the models trained by SGD, Adam, and RMSProp on seven vision datasets. All results are averaged
over three independently initialized and trained models. To evaluate standard generalization, we measure
the classification accuracy of the models on the testing data. To capture model robustness, we measure the
classification accuracy of the models on the testing data perturbed using Gaussian perturbations, ℓ2and
ℓ∞-bounded perturbations (Croce & Hein, 2020). Perturbations with varying degrees of severity are included
in the evaluation to ensure the observation of the robustness difference is not limited to perturbations with
any particular parameters. The degree of severity is determined by the variance of the Gaussian perturbation
and anℓ2andℓ∞norm for the attacks. We select those parameters so the range of the accuracy differences
between models is similar across different datasets. Particularly, the highlighted results in Table 3 are in a
similar range, so we use them to plot Figure 1. We also ensure that the original image semantics remains in
the perturbed images, and we provide a visualization of the perturbed images in Figure 17 to 19.
Finally, for CIFAR100 and Caltech101, because of the large number of classes in the dataset, we use the
top-5 classification accuracy to plot Figure 1 as the results are within a range similar to other datasets with
10 classes. The observation of the similar standard generalization and different robustness holds on both
top-1 and top-5 accuracy.
C.1 Results on Models with Batch Normalization Enabled
When BN layers are activated in PreActResNet18, we observe that the models exhibit similar standard gen-
eralization performance, yet the robustness difference between SGD and adaptive gradient methods remains
evident. This observation is in line with the results presented in Table 3, where BN layers are disabled.
Notably, the accuracy of models with BN enabled is significantly lower compared to their BN-disabled coun-
terparts under almost all types of perturbations, particularly under stronger perturbations. This finding
aligns with the results from the previous work (Benz et al., 2021b;a; Wang et al., 2022).
C.2 Results on Vision Transformers
In addition to the network designs considered in Table 2, we extend our work to ViT in order to verify
whether similar observations can be drawn on other neural network architectures.
It is important to note that the dataset utilized in our paper is significantly smaller in size compared to
larger datasets such as Imagenet and JFT-300M. Recent research, such as the work by Zhu et al. (2023), has
shown that ViT tends to generalize poorly on small datasets when trained from scratch. In particular, Zhu
et al. (2023) empirically demonstrated that ViT and ResNet learn distinct representations on small datasets
while converging to similar representations on larger datasets.
25Published in Transactions on Machine Learning Research (11/2023)
Table 3:Results on standard generalization and robustness of models trained by SGD, Adam,
and RMSProp. We evaluate the model robustness on the testing data perturbed using Gaussian perturba-
tions,ℓ2andℓ∞-bounded perturbations (Croce & Hein, 2020). We include various severity of perturbations
to better capture the model robustness. Models trained by SGD are the most robust against the three types
of perturbations across all datasets. The highlighted results are used in Figure 1, as they are in relatively
similar ranges. Results are averaged over three independently initialized and trained models.
Dataset Optimization TestGaussian perturbations ℓ2-bounded attack ℓ∞-bounded attack
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 0.7ϵ= 1.0ϵ= 0.05ϵ= 0.07ϵ= 0.1
MNISTSGD 98.72 98.59 97.94 95.64 93.00 87.33 66.33 87.53 71.93 31.50
Adam 99.05 98.86 96.76 89.33 92.33 86.00 54.67 85.40 52.93 8.77
RMSProp 98.90 98.70 97.02 90.63 91.67 83.00 50.00 82.73 50.00 7.33
σ2= 0.001σ2= 0.005σ2= 0.01ϵ= 0.1ϵ= 0.5ϵ= 0.7ϵ= 0.01ϵ= 0.03ϵ= 0.05
FashionMNISTSGD 91.20 90.49 87.78 84.30 82.33 24.33 12.33 67.23 22.30 4.17
Adam 90.98 89.91 85.03 78.91 70.33 6.00 0.33 53.57 5.33 0.00
RMSProp 91.15 90.09 85.23 78.69 72.67 15.93 4.67 62.67 16.33 1.67
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR10SGD 90.16 87.35 74.13 68.66 67.40 37.57 16.30 53.93 21.27 0.93
Adam 90.73 86.93 67.50 58.54 64.03 29.60 11.10 50.57 13.93 0.20
RMSProp 90.46 86.25 70.03 61.52 60.10 25.47 8.87 47.87 14.03 0.33
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR100(top1)SGD 59.76 56.88 46.26 41.28 28.47 12.93 5.90 18.80 5.57 1.17
Adam 61.10 55.30 31.54 24.92 24.30 7.13 1.87 14.43 2.47 0.33
RMSProp 60.36 56.46 36.42 29.50 28.90 10.47 2.83 17.90 3.47 0.20
CIFAR100(top5)SGD 84.67 81.77 72.84 67.53 80.30 70.20 59.90 75.30 61.70 39.53
Adam 85.41 81.37 58.11 49.54 80.53 66.73 52.77 74.70 53.70 33.43
RMSProp 85.18 81.66 62.71 54.44 80.93 68.57 54.10 74.60 59.10 34.10
σ2= 0.001σ2= 0.003σ2= 0.005ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
SVHNSGD 96.11 95.68 94.47 93.81 85.53 63.60 39.63 80.67 49.83 17.03
Adam 96.48 96.03 94.04 91.46 80.77 57.83 35.93 78.93 47.50 12.43
RMSProp 96.42 95.91 94.07 91.87 81.13 57.90 34.10 76.93 46.33 11.30
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
Caltech101(top1)SGD 70.80 68.13 57.67 43.46 58.77 47.03 35.17 48.27 27.87 4.70
Adam 72.32 58.34 19.88 8.55 57.70 44.47 29.60 45.47 22.03 2.63
RMSProp 73.82 69.38 51.34 33.17 37.80 11.30 2.80 14.77 1.93 0.03
Caltech101(top5)SGD 85.96 84.84 77.57 67.16 85.30 84.43 79.00 83.97 75.47 52.27
Adam 88.08 79.48 38.55 19.67 82.03 80.67 77.63 83.97 72.07 45.87
RMSProp 88.37 85.90 72.19 52.74 80.20 63.40 45.93 63.97 41.33 23.90
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
ImagenetteSGD 89.44 84.83 67.23 50.21 70.70 44.13 21.33 47.23 14.33 0.37
Adam 89.75 71.84 29.05 17.72 65.30 31.53 11.83 39.43 6.23 0.07
RMSProp 89.77 73.25 28.28 17.16 62.30 30.27 11.27 38.40 6.20 0.03
Therefore, weperformfine-tuningonapre-trainedViT-B/16. Amongthedatasetsweconsidered, Imagenette
is a 10-class subset of the Imagenet-1k dataset, making it especially suitable for the fine-tuning task, since
the publicly available ViT checkpoint was pre-trained on Imagenet-1k. Also, it is important to note that
the pretrained models were originally trained using Adam. In our fine-tuning process, we treat ViT as a
feature extractor (i.e., no weight update on the transformer encoder), with a focus on fine-tuning the Multi-
Layer Perceptrons (MLP) head. Our approach follows prior work (Steiner et al., 2022) and incorporates the
three different optimizers, each fine-tuned for 10 epochs. We initiated the fine-tuning process with an initial
learning rate of 0.01, followed by a cosine decay learning rate schedule and a linear warmup. Throughout
this process, we maintained a fixed batch size of 512.
To evaluate the robustness of the fine-tuned models, we maintained the exact same perturbation strengths,
including the variance of Gaussian noise and ϵfor adversarial perturbations, as used in Table 3. The results
can be found in Table 5. We draw three observations.
26Published in Transactions on Machine Learning Research (11/2023)
Table 4:Results on standard generalization and robustness of models trained with BN enabled.
We follow the exact optimization configuration as the ones used in generating Table 3. The only modification
is thatBN is enabled .
Dataset Optimization TestGaussian perturbations ℓ2-bounded attack ℓ∞-bounded attack
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR10SGD 92.24 86.91 55.23 43.29 64.84 27.86 6.96 48.64 9.14 0.04
Adam 93.38 85.67 50.41 39.11 56.5 15.96 2.63 37.7 3.8 0
RMSProp 93.57 86.97 52.09 39.86 55.93 15.16 2.23 37.7 3.76 0
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR100SGD 72.24 57.99 26.08 19.23 34.36 10.2 3.63 21.3 4.8 0.2
Adam 71.36 55.85 24.55 18.23 27.56 6.66 1.73 15.26 2.9 0.23
RMSProp 70.99 56.13 24.56 18.03 23.8 5.1 1.1 13.7 2 0.1
σ2= 0.001σ2= 0.003σ2= 0.005ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
SVHNSGD 94.16 95.81 94.96 92.90 81.73 60.56 41.96 76.13 49.26 15.3
Adam 96.62 96.09 93.96 91.19 80.13 47.76 21.86 72.36 32.76 4.36
RMSProp 96.44 94.86 93.75 91.02 79.86 48.43 22.16 72.36 33.7 3.96
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
Caltech101SGD 78.61 72.69 45.38 25.87 61.23 44.03 23.03 46.80 13.13 0.83
Adam 79.58 62.21 21.08 10.35 56.76 34.46 13.06 37.3 5.66 0.23
RMSProp 75.56 69.89 45.38 23.13 58.6 44.6 20.5 42.6 11.3 0.6
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
ImagenetteSGD 89.35 76.67 46.18 28.27 73.43 42.96 17.56 48.93 14.33 0.03
Adam 91.88 67.29 24.30 14.92 67.66 24.06 3.06 31.4 6.23 0
RMSProp 91.93 67.02 23.79 15.43 68.76 26.1 4.1 33.66 6.20 0
Table 5:Results on standard generalization and robustness of ViT-B/16 fined-tuned on the
Imagenette dataset.
Model Optimization TestGaussian perturbations ℓ2-bounded attack ℓ∞-bounded attack
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
ViT-b/16SGD 99.18 99.05 96.16 91.25 6.2 0 0 1.3 0 0
Adam 99.93 99.51 94.43 88.59 5.1 0 0 0.7 0 0
RMSProp 99.92 99.54 95.38 89.91 5 0 0 0.8 0 0
First, all models fine-tuned with the three different optimizers achieve near 100%test accuracy, a substantial
improvement from the 89%accuracy when training from scratch using PreActResNet18. This significant
boost in standard generalization highlights the effectiveness of fine-tuning with ViT. Second, we observe
that the fine-tuned models exhibit a notable increase in robustness to Gaussian noise. However, they are
highly vulnerable to adversarial perturbations. This observation is consistent with the results from existing
literature (Zhang et al., 2019), where a trade-off is often present between standard accuracy and adversarial
robustness. Finally, we make a similar observation on the robustness difference between models fine-tuned
with the three optimizers, where models fine-tuned with SGD exhibited greater robustness to both Gaussian
noise and adversarial perturbations when compared to models fine-tuned using Adam and RMSProp.
C.3 Results with an Audio Dataset
Besidesthevisiondomain, weextendourworktotheaudiodomainsinceaudiosignalsofferafrequency-based
interpretation as well. We include additional results in Table 6, which compare the standard generalization
androbustnesspropertiesofanaudioclassifiertrainedontheSpeechCommandsdataset(Warden,2018). We
focus on the PreActResNet18 architectures and all models are trained for 200 epochs, with an initial learning
rate of 0.1 and learning rate decay by a factor of 0.1 at epoch 100 and 150. We consider the accuracy of
27Published in Transactions on Machine Learning Research (11/2023)
Table 6:Results on standard generalization and robustness of models on an audio classification
task on the Speech Commands dataset.
Dataset Optimization TestGaussian perturbations ℓ2-bounded attack ℓ∞-bounded attack
σ2= 0.001σ2= 0.003σ2= 0.005ϵ= 0.01ϵ= 0.05ϵ= 0.1ϵ= 0.0001ϵ= 0.0005ϵ= 0.001
Speech
CommandsSGD 85.14 55.76 39.88 33.42 70.01 20.31 9.81 75.6 36.71 13.47
Adam 85.47 54.73 38.87 31.95 60.74 17.87 8.49 71.97 29.2 10.15
RMSProp 84.67 52.37 36.59 27.94 59.57 19.04 8.88 70.50 30.95 11.01
Table 7:Results on standard generalization and robustness of models trained by SGD without
and with momentum (0.9).
Dataset Optimization TestGaussian perturbations ℓ2-bounded attack ℓ∞-bounded attack
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR10SGD 90.16 87.35 74.13 68.66 67.40 37.57 16.30 53.93 21.27 0.93
SGD-m 89.79 87.28 73.207 66.783 67.1 38.067 15.9 55.667 20.233 0.6333
σ2= 0.001σ2= 0.005σ2= 0.007ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
CIFAR100SGD 59.76 56.88 46.26 41.28 28.47 12.93 5.90 18.80 5.57 1.17
SGD-m 56.08 55.03 44.97 40.03 29.2 12.4 5.7 19.7 6.5 0.8
σ2= 0.001σ2= 0.003σ2= 0.005ϵ= 0.1ϵ= 0.2ϵ= 0.3ϵ=1
255ϵ=2
255ϵ=4
255
SVHNSGD 96.11 95.68 94.47 93.81 85.53 63.60 39.63 80.67 49.83 17.03
SGD-m 96.14 95.71 94.44 92.80 82.7 60.53 39.03 77.33 49.26 15.96
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
Caltech101SGD 70.80 68.13 57.67 43.46 58.77 47.03 35.17 48.27 27.87 4.70
SGD-m 69.89 67.77 55.77 41.34 54.86 43.36 31.06 44.16 23.9 3.133
σ2= 0.01σ2= 0.05σ2= 0.1ϵ= 0.5ϵ= 1.0ϵ= 1.5ϵ=1
255ϵ=2
255ϵ=4
255
ImagenetteSGD 89.44 84.83 67.23 50.21 70.70 44.13 21.33 47.23 14.33 0.37
SGD-m 88.69 85.05 68.58 51.15 75.53 49.2 24.53 56.43 17.76 0.2
models under Gaussian- and adversarially-perturbed test sets. Manual verification was conducted to ensure
that the noisy audio phrase could still be recognizable.
Results demonstrate that despite similar test accuracy, the models trained using SGD exhibit greater robust-
ness when compared to the other two optimization methods. These insights provide valuable context to the
generalizability of our initial observations, offering a more comprehensive understanding of how optimizers
perform in the context of different data modalities.
C.4 Results with Momentum-enabled SGD
Additional results with momentum-enabled SGD (SGD-m) are included in Table 7. We maintain the exact
same optimization configuration as that is used for generating the SGD results presented in Table 3, and the
only variation is an additional momentum term with a coefficient of β= 0.9. The result shows that models
optimized by both vanilla SGD and SGD-m exhibit similar trends in terms of generalization and robustness.
D Modifying the Training Inputs in Sec.3.1
We demonstrate irrelevant frequencies in two settings: i) DCT basis vectors with a low magnitude are
irrelevant and ii) high-frequency DCT bases are irrelevant. In Figure 9 to 15, we visualize the original
images and the modified images used in Sec. 3.1.
To understand how the modified training images are generated, we use Φnrg(x,p)with 0<p< 100to denote
the operation that modifies the input image xby removing the DCT basis vectors whose magnitudes are in
the bottomp
100-th percentile. We use Mnrg(x,p)to denote the binary mask used in the process. Consider
an imagex∈Rd×d, the entire process can be formulated as
Φnrg(x,p) =C(˜x⊙Mnrg(x,p))C⊤,
28Published in Transactions on Machine Learning Research (11/2023)
Table 8:Examples of the synthetic data distribution in the frequency and the spatial domain.
˜Σ Frequency-domain Representation Spatial-domain Representation
diag/braceleftbig
˜σ2
0,0,0/bracerightbig
(˜X0,0,0) (/radicalbig
1
3˜X0,/radicalbig
1
3˜X0,/radicalbig
1
3˜X0)
diag/braceleftbig
0,˜σ2
1,0/bracerightbig
(0,˜X1,0) (/radicalbig
1
2˜X1,0,−/radicalbig
1
2˜X1)
diag/braceleftbig
0,0,˜σ2
2/bracerightbig
(0,0,˜X2) (/radicalbig
1
6˜X2,−/radicalbig
2
3˜X2,+/radicalbig
1
6˜X2)
diag/braceleftbig
0,˜σ2
1,˜σ2
2/bracerightbig
(0,˜X1,˜X2) (/radicalbig
1
2˜X1+/radicalbig
1
6˜X2,−/radicalbig
2
3˜X2,−/radicalbig
1
2˜X1+/radicalbig
1
6˜X2)
diag/braceleftbig
˜σ2
0,0,˜σ2
2/bracerightbig
(˜X0,0,˜X2) (/radicalbig
1
3˜X0+/radicalbig
1
6˜X2,/radicalbig
1
3˜X0−/radicalbig
2
3˜X2,/radicalbig
1
3˜X0+/radicalbig
1
6˜X2)
diag/braceleftbig
˜σ2
0,˜σ2
0,0/bracerightbig
(˜X0,˜X1,0) (/radicalbig
1
3˜X0+/radicalbig
1
2˜X1,/radicalbig
1
3˜X0,/radicalbig
1
3˜X0−/radicalbig
1
2˜X1)
diag/braceleftbig
˜σ2
0,˜σ2
1,˜σ2
2/bracerightbig
(˜X0,˜X1,˜X2) (/radicalbig
1
3˜X0+/radicalbig
1
2˜X1+/radicalbig
1
6˜X2,/radicalbig
1
3˜X0−/radicalbig
2
3˜X2,/radicalbig
1
3˜X0−/radicalbig
1
2˜X1+/radicalbig
1
6˜X2)
where⊙is the element-wise product and Cis the DCT transformation matrix. The binary mask Mnrg∈
{0,1}d×dis defined as
Mnrg(x,p) =/braceleftbigg1if|˜xi,j|>ϕ(˜x,p)
0otherwise,
whereϕ(˜x,p)∈Rcomputes thep
100-th percentile in |˜x|. Therefore, DCT basis vectors with a magnitude
smaller than the threshold are first discarded in ˜x, and then this filtered ˜xis converted back to the spatial
domain.
Similarly, we use Φfreq(x,p)to denote the operation that modifies the input image xby removing the DCT
basis vectors whose frequency are in the highestp
100-th percentile. We use Mfreq(p)to denote the binary
mask used in the process. This operation can be formulated as
Φfreq(x,p) =C(˜x⊙Mfreq(p))C⊤,
whereMfreq∈{0,1}d×dis defined as:
Mfreq(p) =/braceleftbigg
1ifi2+j2>p
100√
2d
0otherwise,
andi,jare frequency bases. Notice that Mfreqonly depends on the size of the image, whereas Mnrgdepends
on the input xsince we identify the threshold value in |˜x|. Examples of the modified images and the
modification process are shown in Appendix G.
E Linear Regression Analysis
E.1 Understanding the Synthetic Dataset
The goal of the linear analysis is to study the learning dynamics of different algorithms on a synthetic dataset
where one can clearly define the frequency-domain signal-target (ir)relevance. This motivates us to directly
define the distribution of the input signal in the frequency domain. In Sec. 4, we consider ˜Xfollows a
Gaussian distribution N(˜µ,˜Σ), and for analytical tractability, we consider ˜µ= 0and a diagonal structure of
˜Σ, i.e., ˜Σ =diag(˜σ2
0,...,˜σ2
d−1). Admittedly, it is quite unconventional to define the data distribution directly
in the frequency domain, so we provide a few examples in Table 8 to illustrate the structure of the input
data in both representations.
Similar to Sec. 4.2.2, we focus on a low dimensional setting with d= 3. The first six rows in Table 8 represent
the scenario when there are zero variances in ˜Σ. Notice the notion of irrelevant information in the data is
different in the two representations. In the frequency domain, an irrelevant frequency indicates that the data
has a value of zero at the particular frequency. In the spatial domain, having irrelevant frequency means
that there are redundant dimensions in the spatial representation of the data because the value of data at
some dimensions can be fully predictable by knowing the values of data at some other dimensions.
29Published in Transactions on Machine Learning Research (11/2023)
E.2 Derivation of Equation 9
The adversarial risk under an ℓ2-norm bounded perturbation with a size of ϵis
Ra( ˜w)≜E(˜X,Y)/bracketleftbigg
max
||∆˜x||2≤ϵℓ(˜X+ ∆˜x,Y; ˜w)/bracketrightbigg
=E(˜X,Y)/bracketleftbigg
max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsinglef(˜X+ ∆˜x,˜w)−Y/vextendsingle/vextendsingle2/bracketrightbigg
=E˜X/bracketleftbigg
max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsingle/angbracketleftbig˜X+ ∆˜x,˜w/angbracketrightbig
−/angbracketleftbig˜X,˜w∗/angbracketrightbig/vextendsingle/vextendsingle2/bracketrightbigg
=E˜X/bracketleftbigg
max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+⟨∆˜x,˜w⟩/vextendsingle/vextendsingle2/bracketrightbigg
,
where we focus on the expectation over ˜X, asYis replaced with/angbracketleftbig˜X,˜w∗/angbracketrightbig
.
E.3 Derivation of Equation 10
Given a r.v. ˜X, we define ∆˜x∗to be the maximizer of the term inside the expectation of (9):
∆˜x∗≜arg max
||∆˜x||2≤ϵ1
2/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+⟨∆˜x,˜w⟩/vextendsingle/vextendsingle2.
To maximize this term, we need the two inner product terms to have the same sign. This means
∆˜x∗= sign[/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
]arg max
||∆˜x||2≤ϵ|⟨∆˜x,˜w⟩|2.
For the remaining argmax term, we can first use the Cauchy-Schwarz inequality to obtain
max
||∆˜x||2≤ϵ|⟨∆˜x,˜w⟩|2≤max
||∆˜x||2≤ϵ∥∆˜x∥2
2∥˜w∥2
2=ϵ2∥˜w∥2
2,
which leads to
arg max
||∆˜x||2≤ϵ|⟨∆˜x,˜w⟩|2=ϵ˜w
∥˜w∥2.
Finally, we have
∆˜x∗=ϵsign[/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
]˜w
||˜w||2.
E.4 Derivation of Equation 11
The adversarial risk is
Ra( ˜w) =1
2E˜X/bracketleftbigg/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
+ϵsign[/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig
]||˜w||2/vextendsingle/vextendsingle2/bracketrightbigg
=1
2E˜X/bracketleftbigg/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig2+ 2ϵ/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig/vextendsingle/vextendsingle||˜w||2+ϵ2||˜w||2
2/bracketrightbigg
=1
2/summationdisplay
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2+ϵE˜X/bracketleftbigg/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig/vextendsingle/vextendsingle/bracketrightbigg
||˜w||2+ϵ2
2||˜w||2
2.
To compute the expectation, we first denote Z=/summationtext
i∈Irel˜Xi( ˜wi−˜w∗
i). Because ˜σ2
i= 0for alli∈Iirrel, this
allows us to ignore those irrelevant frequencies in the summation in Z. This leads us to
E˜X/bracketleftbigg/vextendsingle/vextendsingle/angbracketleftbig˜X,˜w−˜w∗/angbracketrightbig/vextendsingle/vextendsingle/bracketrightbigg
=EZ/bracketleftbigg
|Z|/bracketrightbigg
.
30Published in Transactions on Machine Learning Research (11/2023)
SinceZis a linear combination of zero-mean Gaussian r.v.’s, this makes it also a zero-mean Gaussian r.v,
i.e.,E[Z] = 0. The variance of Zis
σ2
Z=E[Z2]−E[Z]2
=E/bracketleftbigg/summationdisplay
i∈Irel/summationdisplay
j∈Irel,i̸=j/bracketleftbigg
˜Xi˜Xj( ˜wi−˜w∗
i)( ˜wj−˜w∗
j)/bracketrightbigg
+/summationdisplay
i∈Irel/bracketleftbigg
˜X2
i( ˜wi−˜w∗
i)2/bracketrightbigg/bracketrightbigg
=E/bracketleftbigg/summationdisplay
i∈Irel/bracketleftbigg
˜X2
i( ˜wi−˜w∗
i)2/bracketrightbigg/bracketrightbigg
=/summationdisplay
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2,
where the expectation on the cross-multiplication term is zero because ˜Xiand ˜Xjare independent r.v.’s.
This means Z∼N(0,σ2
Z)withσ2
Z=/summationtext
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2. Therefore, EZ/bracketleftbigg
|Z|/bracketrightbigg
is the expectation of a folded
normal distribution:
EZ/bracketleftbigg
|Z|/bracketrightbigg
=σZ/radicalbigg
2
π=/radicaligg
2
π/summationdisplay
i∈Irel˜σ2
i( ˜wi−˜w∗
i)2.
E.5 Derivations of the GD Dynamics: Equation 14 and Equation 15
The gradient computed using the population risk is ∇wRs(w(t)) =E/bracketleftbig
XX⊤/bracketrightbig
e(t) = Σe(t), and the learning
dynamics of GD in the spatial domain can be captured using:
e(t+ 1) =w(t+ 1)−w∗
=w(t)−η∇wRs(w(t))−w∗
=w(t)−w∗−ηΣe(t)
=e(t)−ηΣe(t)
= (I−ηΣ)e(t)
= (I−ηΣ)t+1e(0).
This shows that the learned weight converges to the optimal weight w∗at a rate depending on Σ. To see
the GD dynamics in the frequency domain, we can simply perform DCT on both sides of (14):
˜e(t+ 1) =C(I−ηΣ)t+1e(0)
=C(I−ηΣ)t+1C⊤˜e(0)
=C(I−ηΣ)tC⊤C(I−ηΣ)C⊤˜e(0)
=C(I−ηΣ)t−1C⊤C(I−ηΣ)C⊤C(I−ηΣ)C⊤˜e(0)
=/bracketleftbig
C(I−ηΣ)C⊤/bracketrightbigt+1˜e(0)
= (I−ηCΣC⊤)t+1˜e(0)
= (I−η˜Σ)t+1˜e(0),
where ˜Σis the covariance of ˜x.
E.6 Derivation of the signGD Dynamics for any ˜Σ: Equation 19 and Equation 20
The signGD learning dynamics in the spatial domain is
e(t+ 1) =w(t+ 1)−w∗
=w(t)−ηsign[∇wRs(w)]−w∗
=e(t)−ηsign[Σe(t)].
31Published in Transactions on Machine Learning Research (11/2023)
The signGD learning dynamics in the frequency domain are obtained by taking the DCT transformation on
both sides of (19):
˜e(t+ 1) = ˜e(t)−ηCsign[Σe(t)]
= ˜e(t)−ηCsign[C⊤˜ΣCC⊤˜e(t)]
= ˜e(t)−ηCsign[C⊤˜Σ˜e(t)].
E.7 Derivation of the signGD Dynamics for ˜Σ =diag/braceleftbig
˜σ2
0,˜σ2
1,0/bracerightbig
: Equation 21
To understand ˜e(t+ 1)with our specific choice of Σ =C⊤˜ΣCand˜Σ =diag/braceleftbig
˜σ2
0,˜σ2
1,0/bracerightbig
, first notice that the
DCT transformation matrix C=C(3)follows the definition in (4):
C=
/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
2
3cosπ
6/radicalig
2
3cosπ
2/radicalig
2
3cos5π
6/radicalig
2
3cosπ
3/radicalig
2
3cosπ/radicalig
2
3cos5π
3
=
/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
1
20−/radicalig
1
2/radicalig
1
6−/radicalig
2
3/radicalig
1
6
.
Denote/radicalig
1
3˜σ2
0˜e0(t)and/radicalig
1
2˜σ2
1˜e1(t)by usingA(t)andB(t), respectively. Putting it all together, we have:
˜e(t+ 1) = ˜e(t)−ηCsign[C⊤˜ΣCe(t)]
= ˜e(t)−ηCsign[C⊤˜Σ˜e(t)]
= ˜e(t)−η
/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
1
20−/radicalig
1
2/radicalig
1
6−/radicalig
2
3/radicalig
1
6
sign

/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
1
20−/radicalig
1
2/radicalig
1
6−/radicalig
2
3/radicalig
1
6
⊤
˜σ2
0˜e0(t)
˜σ2
1˜e1(t)
0


= ˜e(t)−η
/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
1
20−/radicalig
1
2/radicalig
1
6−/radicalig
2
3/radicalig
1
6

sign/bracketleftig/radicalig
1
3˜σ2
0˜e0(t) +/radicalig
1
2˜σ2
1˜e1(t)/bracketrightig
sign/bracketleftig/radicalig
1
3˜σ2
0˜e0(t)/bracketrightig
sign/bracketleftig/radicalig
1
3˜σ2
0˜e0(t)−/radicalig
1
2˜σ2
1˜e1(t)/bracketrightig

= ˜e(t)−η
/radicalig
1
3/radicalig
1
3/radicalig
1
3/radicalig
1
20−/radicalig
1
2/radicalig
1
6−/radicalig
2
3/radicalig
1
6

sign[A(t) +B(t)]
sign[A(t)]
sign[A(t)−B(t)]

= ˜e(t)−η
√
3
3(sign[A(t) +B(t)] + sign[A(t)] + sign[A(t)−B(t)])√
2
2(sign[A(t) +B(t)]−sign[A(t)−B(t)])√
6
6sign[A(t) +B(t)]−√
6
3sign[A(t)] +√
6
6sign[A(t)−B(t)]
.
E.8 Understanding the Dynamics of signGD with ˜Σ =diag/braceleftbig
˜σ2
0,˜σ2
1,0/bracerightbig
Previous work has shown that for strictly convex problems with a unique minimum, the signGD solution
converges to the minimum under a sequence of decaying learning rate: limt→∞η(t) = 0(Moulay et al., 2019).
In this section, we follow Sec. 4.2.1 where the GD dynamics is studied under a constant learning rate and
investigate the behavior of signGD under a fixed η. Compared to the asymptotic GD solution that converges
exactly to the standard risk minimizer, we demonstrate that the asymptotic signGD solution converges to
anO(η)neighborhood of the standard risk minimizer.
For the rest of this section, we first perform a partition-based analysis to study the learning dynamics of ˜e0
and˜e1in Appx. E.8.1. Proposition E.4 summarizes how the value of weight changes in different partitions,
32Published in Transactions on Machine Learning Research (11/2023)
Table 9:Learning dynamics of signGD. The dynamics of the error term in the frequency domain can be
written in a tabular format and the exact update depends on the initialized weight ˜w(0)and the true model
˜w∗. We useA(t)andB(t)to denote√
3
3˜σ2
0˜e0(t)and√
2
2˜σ2
1˜e1(t), respectively. Invalid sign combinations are
denoted by using n/a.
No. sign[A(t)] sign[A(t) +B(t)] sign[A(t)−B(t)] ˜e(t+ 1) |A(t)|vs.|B(t)|
1 1 1 1 ˜ e(t)−η/bracketleftbig√
3,0,0/bracketrightbig⊤|A(t)|>|B(t)|
2 1 1 −1 ˜ e(t)−η/bracketleftbig√
3
3,√
2,−√
6
3/bracketrightbig⊤|A(t)|<|B(t)|
3 1 1 0 ˜ e(t)−η/bracketleftbig
2√
3
3,√
2
2,−√
6
6/bracketrightbig⊤|A(t)|=|B(t)|
4 1−1 1 ˜ e(t)−η/bracketleftbig√
3
3,−√
2,−√
6
3/bracketrightbig⊤|A(t)|<|B(t)|
n/a 1−1 −1 n/a n/a
n/a 1−1 0 n/a n/a
5 1 0 1 ˜ e(t)−η/bracketleftbig
2√
3
3,−√
2
2,−√
6
6/bracketrightbig⊤|A(t)|=|B(t)|
n/a 1 0 −1 n/a n/a
n/a 1 0 0 n/a n/a
n/a−1 1 1 n/a n/a
6−1 1 −1 ˜ e(t)−η/bracketleftbig
−√
3
3,√
2,√
6
3/bracketrightbig⊤|A(t)|<|B(t)|
n/a−1 1 0 n/a n/a
7−1−1 1 ˜ e(t)−η/bracketleftbig
−√
3
3,−√
2,√
6
3/bracketrightbig⊤|A(t)|<|B(t)|
8−1−1 −1 ˜ e(t)−η/bracketleftbig
−√
3,0,0/bracketrightbig⊤|A(t)|>|B(t)|
9−1−1 0 ˜ e(t)−η/bracketleftbig
−2√
3
3,−√
2
2,√
6
6/bracketrightbig⊤|A(t)|=|B(t)|
n/a−1 0 1 n/a n/a
10−1 0 −1 ˜ e(t)−η/bracketleftbig
−2√
3
3,√
2
2,√
6
6/bracketrightbig⊤|A(t)|=|B(t)|
n/a−1 0 0 n/a n/a
n/a 0 1 1 n/a n/a
11 0 1 −1 ˜ e(t)−η/bracketleftbig
0,√
2,0/bracketrightbig⊤|A(t)|<|B(t)|
n/a 0 1 0 n/a n/a
12 0−1 1 ˜ e(t)−η/bracketleftbig
0,−√
2,0/bracketrightbig⊤|A(t)|<|B(t)|
n/a 0−1 −1 n/a n/a
n/a 0−1 0 n/a n/a
n/a 0 0 1 n/a n/a
n/a 0 0 −1 n/a n/a
13 0 0 0 Optimal |A(t)|=|B(t)|= 0
and the weight adaptation of ˜e0and˜e1is summarized in Corollary E.6. Based on the corollary, we analyze
thedynamicsof ˜e2inAppx.E.8.2. Lastly, wefocusonthedifferencesbetweentheadversarialriskofsolutions
found by GD and signGD in Appx. E.8.3.
E.8.1 Dynamics of ˜e0and˜e1under signGD
With our choice of ˜Σ, (21) shows that weight adaptation depends on the sign of three terms: A(t),A(t)+B(t)
andA(t)−B(t). This allows us to study the learning dynamics of signGD by analyzing the three terms in
Table 9. There are 27 sign combinations in total; however, not all of them are valid. For example, consider
the combination with sign[A(t)] = 1,sign[A(t) +B(t)] =−1. Those two conditions imply that B(t)<0
and|A(t)|<|B(t)|, and this means that sign[A(t)−B(t)]must be positive. This makes the entry with
sign[A(t)−B(t)] =−1invalid, as shown in the fifth row in Table 9. We denote those entries with invalid
sign combinations as n/a.
Notice in (21) that the weight adaptation under signGD depends on the dynamics of A(t)andB(t), and
they are functions of ˜e0(t)and˜e1(t)respectively, so let us first focus on understanding the weight adaptation
at the first two frequency bases.
33Published in Transactions on Machine Learning Research (11/2023)
There are 13 possible updates in Table 9. Notice that the non-zero updates are always in the direction to
reduce|˜e0(t)|and|˜e1(t)|, and the step size depends on the magnitude of |A(t)|and|B(t)|. To simplify the
analysis, let us focus on the updates on AandBinstead. For example, in updates 1 and 8, decreasing |˜e0|
by√
3ηis equivalent to decreasing |A|by˜σ2
0η.
Now take note of the limited number of update magnitudes for |A|, specifically ˜σ2
0η,2˜σ2
0η
3, and˜σ2
0η
3, which
correspond to updating |˜e0|by√
3η,2√
3
3η, and√
3
3η, respectively. Similarly, |B|has only two update
magnitudes, namely ˜σ2
1ηand˜σ2
1η
2, which correspond to updating |˜e1|with√
2ηand√
2
2η, respectively. This
observation leads to the following proposition.
Proposition E.1. Suppose the initial weight w(0)∼µare sampled from probability density µ, then neither
AnorB(˜e0nor˜e1) can be reduced to exactly 0 almost surely.
Proof.Due to the limited number of update magnitudes, reducing |A|and|B|to 0 requires their initial value
to be exactly some integer multiplication of those updates. However, with the initial weight sampled from
probability density µ, the probability of the initial values of AandBbeing the exact integer multiple of the
possible update is 0.
Next, we introduce the following lemma to understand the dynamics of A(t).
Lemma E.2. Consider the update rule x(t+ 1) = x(t)−sign[x(t)]∆(t), wherex∈R,
∆(t)∈{∆1,∆2,..., ∆max}and0<∆1<∆2<···<∆max. Then there exists tsuch that|x(t)|≤∆max.
Moreover, whenever |x(t)|≤∆max, the rest of the sequence stays ∆max-bounded, i.e.,|x(t′)|≤∆maxfor all
t′≥t.
Proof.In the following, we provide a proof for the case when x(0)>0. A proof with x(0)<0can be done
in a similar way. The proof can be divided into two parts.
1. Let us denote the sequence of {x(0),x(1),...,x (t)}by{x(t)}. First, we prove that there exists a tsuch
that|x(t)|≤∆max.
Ifx(t)>∆max, thenx(t+ 1) =x(t)−∆(t)≥x(t)−∆max>0.
Consider{x(t)}withx(t′)>∆maxfor allt′∈{0,1,...,t}, we havex(t′+ 1) =x(t′)−∆(t′)<x(t′). This
means that for any x(t)>∆max, the sequence{x(t)}is decreasing.
We prove, by contradiction, that there exists a tsuch that|x(t)|<∆max. Suppose that such a tdoes not
exist, then one of the two cases must happen.
1.x(t)>∆maxfor allt.
2.∃ksuch thatx(0)>x(1)>···>x(k)>∆max, butx(k+ 1)<−∆max.
For case 1, since x(t)>∆max, we know that{x(t)}is decreasing and bounded from below, so we have
x(t)→x∗≥∆maxast→∞. This means that limt→∞x(t) = limt→∞x(t+ 1) =x∗.
Using the update rule, we have
lim
t→∞x(t+ 1) = lim
t→∞x(t)−∆(t) sign(x(t))
= lim
t→∞x(t)−∆(t)
=x∗−∆(t),
orx∗=x∗−∆(t), which is impossible because ∆(t)>0.
For case 2, by the assumption of the case, we have x(k+ 1) =x(k)−∆(k)<−∆max, which is not possible
becausex(k)>∆max.
The same approach can be applied to prove the case when xis initialized with a negative value, i.e., x(0)<0.
34Published in Transactions on Machine Learning Research (11/2023)
The first part of the proof shows that there exists a tsuch that|x(t)|≤∆max.
2. Next, we show that for any tsuch that|x(t)|≤∆max, we have|x(t+ 1)|≤∆max.
When 0≤x(t)≤∆max, we have
x(t+ 1) =x(t)−∆(t)≥−∆maxandx(t+ 1) =x(t)−∆(t)≤x(t)≤∆max.
When−∆max≤x(t)≤0, we have
x(t+ 1) =x(t) + ∆(t)≤∆maxandx(t+ 1) =x(t) + ∆(t)≥x(t)≥−∆max.
This means that −∆max≤x(t+ 1)≤∆max, and this results holds for any tsuch that|x(t)|≤∆max.
To combine the two parts of the proof, consider the first of such t, i.e.,t= min{t:|x(t)|≤∆max}. We can
prove, by mathematical induction, that |x(t′)|≤∆maxfor allt′≥t.
The following proposition describes the behavior of A(t)under signGD.
Proposition E.3. There exists tsuch that|A(t′)|≤˜σ2
0ηfor allt′>t.
Proof.Table 9 shows that there is always a non-zero update in the direction to reduce |A(t)|, so we can
define the dynamics of A(t)as
A(t+ 1) =A(t)−sign[A(t)]∆(t),
where ∆(t)∈/braceleftig
˜σ2
0η
3,2˜σ2
0η
3,˜σ2
0η/bracerightig
. Lemma E.2 with ∆max= ˜σ2
0ηproves the proposition.
Proposition E.3 implies that once |A|drops below ˜σ2
0η, it remains below ˜σ2
0ηfor all future iterations. Com-
bining Proposition E.3 with the update directions of Ain Table 9, we know that Awill begin oscillating
around zero. However, there are some limitations of Proposition E.3. First, we do not know when exactly
the oscillation starts: whether it starts immediately following the first iteration when |A|≤˜σ2
0ηor from
some iterations after it. Second, the characteristics of this oscillation (periodic or non-periodic) are un-
known. Answers to these questions can improve our understanding of the behavior of A, and later become
particularly useful in developing the asymptotic signGD solution of ˜e2, which is important because it leads
to the adversarial risk of the signGD solution.
Because the update for B(t)can be zero when |A(t)|>|B(t)|, Lemma E.2 is not suitable to understand the
dynamics of B, as the lemma requires that all step sizes be greater than zero. Nevertheless, Proposition E.3
allows us to narrow down the range of Aand we can partition the set of all possible values of AandB.
By analyzing the dynamics of AandBin those partitions, we can develop the standard and adversarial
population risk of the asymptotic signGD solution under a constant learning rate η.
Let us first divide the set of values of (A,B)into partitions based on the value of |A|, and then divide those
partitions into smaller subpartitions based on the relative magnitude of |A|and|B|. Such a partitioning
process is illustrated in Figure 6.
•R1=/braceleftig
(A,B) :2˜σ2
0η
3<|A|<˜σ2
0ηandB∈(−∞,∞)/bracerightig
,
–R11={(A,B) : (A,B)∈R1and|A|<|B|},
–R12={(A,B) : (A,B)∈R1and|A|>|B|},
•R2=/braceleftig
(A,B) :˜σ2
0η
3<|A|<2˜σ2
0η
3andB∈(−∞,∞)/bracerightig
,
–R21={(A,B) : (A,B)∈R2and|A|<|B|},
–R22=/braceleftbig
(A,B) : (A,B)∈R2and|A|>|B|and/vextendsingle/vextendsingleA+ ˜σ2
0η/vextendsingle/vextendsingle>|B|and/vextendsingle/vextendsingleA−˜σ2
0η/vextendsingle/vextendsingle>|B|/bracerightbig
,
–R23=/braceleftbig
(A,B) : (A,B)∈R2and|A|>|B|and/parenleftbig/vextendsingle/vextendsingleA+ ˜σ2
0η/vextendsingle/vextendsingle<|B|or/vextendsingle/vextendsingleA−˜σ2
0η/vextendsingle/vextendsingle<|B|/parenrightbig/bracerightbig
,
35Published in Transactions on Machine Learning Research (11/2023)
Figure 6: Analyzing the dynamics of AandBby partitioning the set of values of (A,B)in
[−˜σ2
0η,˜σ2
0η]×R.Such a set is first divided into partitions R1,R2andR3based on the value of |A|. Then,
we consider Rs={R22,R31,R32,R33,R34}as the stationary subpartitions, because once (A(t),B(t))∈Rs,
the sequence remains in the stationary subpartitions. Also, we consider Rt={R11,R12,R21,R23}as the
transient subpartitions, because any (A(t),B(t))∈Rtwill soon enter one of the stationary subpartitions,
that is, there exists t′≥tsuch that (A(t′),B(t′))∈Rs. We consider ˜σ2
0= ˜σ2
1= 1andη= 1in this figure.
•R3=/braceleftig
(A,B) :|A|<˜σ2
0η
3andB∈(−∞,∞)/bracerightig
,
–R31={(A,B) : (A,B)∈R3and|A|>|B|},
–R32=/braceleftig
(A,B) :/uniontext
k∈Zeven−{0}/braceleftbig
(A,B)∈R3and|A|>/vextendsingle/vextendsingleB+k˜σ2
1η/vextendsingle/vextendsingle/bracerightbig/bracerightig
,
–R33=/braceleftig
(A,B) :/uniontext
k∈Zodd/braceleftig
(A,B)∈R3and|A|+/vextendsingle/vextendsingleB+k˜σ2
1η/vextendsingle/vextendsingle<˜σ2
0η
3/bracerightig/bracerightig
,
–R34=R3−(R31∪R32∪R33),
where ZoddandZevenare the set of odd and even integers, respectively.
There are nine non-overlapping subpartitions. We call R22,R31,R32,R33andR34thestationary subpar-
titions and denote Rs={R22,R31,R32,R33,R34}. They are called stationary subpartitions because once
(A(t),B(t))∈Rs, the sequence remains in the stationary subpartition. On the other hand, we call R11,R12,
R21,R23thetransient subpartitions and denote Rt={R11,R12,R21,R23}. They are called the transient
subpartitions because any (A(t),B(t))∈Rtwill soon enter one of the stationary subpartitions, that is, there
existst′≥tsuch that (A(t′),B(t′))∈Rt. The dynamics of AandBcan be summarized in the following
proposition.
Proposition E.4.
Transient subpartitions: For each of R∈Rt, considertsuch that (A(t),B(t))∈R, then there exists
t′> tsuch that (A(t′),B(t′))∈Rs. The transition of (A(t),B(t))fromRttoRshappens at most 3
iterations after t; specifically, it corresponds to the scenario of (A(t),B(t))∈R11,(A(t+ 1),B(t+ 1))∈R23,
(A(t+ 2),B(t+ 2))∈R21, and finally (A(t+ 3),B(t+ 3))∈R3.
Stationary subpartitions: For each of R∈Rs, considertsuch that (A(t),B(t))∈R. For anyt′≥t,
|A(t′)|≤2˜σ2
0η
3andA(t′)shows 2-periodic behavior switching between positive and negative signs, that is, for
anyi∈Z≥0, we haveA(t+ 2i) =A(t)andsign(A(t+ 2i)) = sign(A(t)) =−sign(A(t+ 2i+ 1)). To be more
specific about each stationary subpartition, we have
36Published in Transactions on Machine Learning Research (11/2023)
1. For each of R∈{R22,R31}, considertsuch that (A(t),B(t))∈R. For anyt′≥t,|B(t′)|≤˜σ2
1η
andB(t′)remains constant, that is, B(t′) =B(t).
2. For each of R∈{R32,R33}, considertsuch that (A(t),B(t))∈R.
(a) There exists ¯t>tsuch that (A(¯t),B(¯t))∈R31. Denote the smallest ¯tas¯t∗.
(b) For any ¯t∗>t′≥t, we have|B(t′+ 1)|=|B(t′)|−sign[B(t′)].
(c) For any t′≥¯t∗,|B(t′)|≤˜σ2
1ηandB(t′)remains constant, that is, B(t′) =B(t).
3. Consider tsuch that (A(t),B(t))∈R34.
(a) For any t′≥t,(A(t′),B(t′))remains in R34.
(b) There exists ¯t>tsuch that for any ¯t>t′≥t, the sign of B(t′)remains constant.
(c) For any t′≥¯t,|B(t′)| ≤ ˜σ2
1ηandB(t′)shows 2-periodic behavior switching between
positive and negative signs, that is, for any i∈Z≥0, we have B(¯t+ 2i) =B(¯t)and
sign(B(¯t+ 2i)) = sign(B(¯t)) =−sign(B(¯t+ 2i+ 1)).
Proof.From Proposition E.3, we know that from an arbitrary (A(0),B(0)),|A|will drop below ˜σ2
0ηunder
the signGD update, which means that (A,B)must enter one of the subpartitions. This allows us to continue
analyzing the behavior of (A(t),B(t))by assuming it enters one of the subpartitions at iteration t.
Analysis of R11:For any (A(t),B(t))inR11, we know that A(t+ 1) =A(t)−sign[A(t)]˜σ2
0η
3. This means
that˜σ2
0η
3<|A(t+ 1)|<2˜σ2
0η
3, so(A(t+ 1),B(t+ 1))is inR2and we can study its dynamics using R2.
Analysis of R12:For any (A(t),B(t))inR12, we know that A(t+ 1) =A(t)−sign[A(t)]˜σ2
0η. This means
that|A(t+ 1)|<˜σ2
0η
3. Therefore, (A(t+ 1),B(t+ 1))is inR3and we can analyze its dynamics using R3.
Analysis of R21:For any (A(t),B(t))inR21, we know that A(t+ 1) =A(t)−sign[A(t)]˜σ2
0η
3. This means
that|A(t+ 1)|<˜σ2
0η
3. Therefore, (A(t+ 1),B(t+ 1))is inR3and we can analyze its dynamics using R3.
Dynamics of (A,B)inR22andR23:For any (A(t),B(t))inR22andR23, we haveA(t+ 1) =A(t)−
sign[A(t)]˜σ2
0ηandB(t+ 1) =B(t), so we know that˜σ2
0η
3<|A(t+ 1)|<2˜σ2
0η
3.
Analysis of R22:For any (A(t),B(t))inR22, we have|A(t+ 1)|>|B(t+ 1)|. This means that
(A(t+ 1),B(t+ 1))remainsinR22, andwehave A(t+2) =A(t+1)−sign[A(t+1)]˜σ2
0ηandB(t+2) =B(t+1),
which means that (A(t+ 2),B(t+ 2))returns to the starting position at (A(t),B(t)). In fact, for any t′≥t,
A(t′)shows 2-periodic behavior switching between positive and negative signs and B(t′)remains constant,
that is, for any i∈Z≥0, we haveA(t+ 2i) =A(t),sign(A(t+ 2i)) = sign(A(t)) =−sign(A(t+ 2i+ 1)), and
B(t+ 2i+ 1) =B(t+ 2i) =B(t).
Analysis of R23:For any (A(t),B(t))inR23, by the definition of subpartition, we have that
|A(t+ 1)|<|B(t+ 1)|, so (A(t+ 1),B(t+ 1))is inR21. This means that (A(t+ 2),B(t+ 2))is inR3
and we can analyze its dynamics using partition R3.
Analysis of R31:For any (A(t),B(t))inR31, we know that A(t+ 1) =A(t)−sign[A(t)]˜σ2
0ηand
B(t+ 1) =B(t). This means that2˜σ2
0η
3<|A(t+ 1)|<˜σ2
0η. Since|A(t+ 1)|>|B(t+ 1)|=|B(t)|, we have
thatB(t+ 2) =B(t+ 1)andA(t+ 2) =A(t+ 1)−sign[A(t+ 1)]˜σ2
0η, which means that (A(t+ 2),B(t+ 2))
returns to the starting position at (A(t),B(t)). Therefore, for any t′≥t,A(t′)shows 2-periodic behavior
switching between positive and negative signs and B(t′)remains constant, that is, for any i∈Z≥0, we have
A(t+ 2i) =A(t),sign(A(t+ 2i)) = sign(A(t)) =−sign(A(t+ 2i+ 1)), andB(t+ 2i+ 1) =B(t+ 2i) =B(t).
Dynamics of AinR32,R33andR34:The behavior of AinR32,R33andR34is the same. For any
(A(t),B(t))in{R32,R33,R34}, we know that
A(t+ 1) =A(t)−sign[A(t)]˜σ2
0η
3andB(t+ 1) =B(t)−sign[B(t)]˜σ2
1η. (32)
37Published in Transactions on Machine Learning Research (11/2023)
This means that|A(t+ 1)|<˜σ2
0η
3, so(A(t+1),B(t+1))remains inR3. For anyt′≥t,A(t′)shows 2-periodic
behavior switching between positive and negative signs, that is, for any i∈Z≥0, we have
A(t+ 2i) =A(t)and sign(A(t+ 2i)) = sign(A(t)) =−sign(A(t+ 2i+ 1)). (33)
The behavior of Bis different across the three subpartitions, so we analyze them separately.
Analysis of R32:Because all subpartitions are non-overlapping, for any (A(t),B(t))inR32, there exists a
uniquek∈Zeven−{0}such thatA(t)andB(t)satisfies|A(t)|>/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle. Next, we show that starting
from any (A(t),B(t))inR32, after|k|iterations of signGD update, we have |A(t+|k|)|>|B(t+|k|)|, which
means that (A(t+|k|),B(t+|k|))is inR31.
This can be proved by showing that |A(t+|k|)|=|A(t)|and|B(t+|k|)|=/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle. For anyt′≥t,
A(t′)shows 2-periodic behavior, and because kis an even number, we have |A(t+|k|)|=|A(t)|.
Since/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle>0andB(t+ 1) =B(t)−sign[B(t)]˜σ2
1η, we know that the sign of Bremains the same
for the next|k|−1updates. This means that
B(t+|k|) =B(t)−|k|−1/summationdisplay
i=0sign[B(t+i)]˜σ2
1η=B(t)−|k|sign[B(t)]˜σ2
1η.
By the definition of the subpartition, we have˜σ2
0η
3>/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle; and this is true if and only if B(t)and
khave opposite signs because kis a non-zero even integer. Therefore, we have
|B(t+|k|)|=/vextendsingle/vextendsingleB(t)−|k|sign[B(t)]˜σ2
1η/vextendsingle/vextendsingle
=/vextendsingle/vextendsingleB(t)−|k|(−sign[k])˜σ2
1η/vextendsingle/vextendsingle
=/vextendsingle/vextendsingleB(t) +|k|sign[k]˜σ2
1η/vextendsingle/vextendsingle
=/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle.
Analysis of R33:Similarly, for any (A(t),B(t))inR33, there exists a unique k∈Zoddsuch thatA(t)
andB(t)satisfies|A(t)|+/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle<˜σ2
0η
3. Again, we show that starting from any (A(t),B(t))inR33,
after|k|iterations of signGD update, (A(t+|k|),B(t+|k|))is inR31. This can be proved by showing that
˜σ2
0η
3−|A(t)|≤|A(t+|k|)|and/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle=|B(t+|k|)|.
First, by using the same analysis of/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingleinR32, we have/vextendsingle/vextendsingleB(t) +k˜σ2
1η/vextendsingle/vextendsingle=|B(t+|k|)|. Next, the
behavior of A(t)follows (32), which means that for any t′≥t,A(t′)shows 2-periodic behavior, and because
kis an odd number, we have |A(t+|k|)−A(t)|=|A(t+ 1)−A(t)|=˜σ2
0η
3.
Also, we have|A(t+|k|)−A(t)|≤|A(t+|k|)|+|A(t)|, which means that˜σ2
0η
3≤|A(t+|k|)|+|A(t)|, or
˜σ2
0η
3−|A(t)|≤|A(t+|k|)|. Combining with the definition of the subpartition, we have
|B(t) +|k||<˜σ2
0η
3−|A(t)|≤|A(t+|k|)|.
Therefore, startingfromany (A(t),B(t))inR33, after|k|iterationsofsignGDupdates, wehave |A(t+|k|)|>
|B(t+|k|)|, which together with the fact that |A(t+|k|)|<˜σ2
0η
3as shown before, implies that (A(t+
|k|),B(t+|k|))is inR31.
Analysis of R34:Finally, we prove, by contradiction, that for any (A(t),B(t))inR34, there is no t′> t
such that (A(t′),B(t′))inR31. Suppose that (A(t′),B(t′))entersR31, thenk≜t′−tmust be either an odd
number or an even number. By the definition of the subpartition, if kis a non-zero even number, it means
that (A(t),B(t))must be in R32; whereas if kis an odd number, it means that (A(t),B(t))must be in R33.
Neither is possible since all subpartitions are non-overlapping, so for any (A(t),B(t))inR34,(A(t′),B(t′))
remains in R34for allt′≥t. This means that there will always be a non-zero update on B, and this allows
us to apply Lemma E.2. For any (A(t),B(t))inR34, there exists tsuch that|B(t′)|≤˜σ2
1ηfor allt′≥t.
38Published in Transactions on Machine Learning Research (11/2023)
Combining Proposition E.1 and the dynamics of (A,B)in the stationary subpartitions described in Propo-
sition E.4, we have the following remark.
Remark E.5. The asymptotic solution of Aoscillates in [−2˜σ2
0η
3,2˜σ2
0η
3], which is a tighter bound compared to
the one in Proposition E.3. The asymptotic solution of Beither remains constant in [−˜σ2
1η,˜σ2
1η](1 and 2c in
Proposition E.4) or oscillates in [−˜σ2
1η,˜σ2
1η](3c in Proposition E.4). Since A(t)andB(t)denote√
3
3˜σ2
0˜e0(t)
and√
2
2˜σ2
1˜e1(t), respectively, this means that lim supt→∞|˜e0(t)|=2√
3
3η, and lim supt→∞|˜e1(t)|=√
2η,
Fromthedynamicsof (A,B)inthetransientsubpartitionsdescribedinPropositionE.4, wehavethefollowing
corollary.
Corollary E.6. Suppose that ˜e0enters [−√
3η,√
3η]at iteration t, thenAstarts exhibiting a 2-periodic
oscillation at most 3 iterations after t. This means that the maximum difference between the number of
positive and negative A’s after iteration tis 2:/vextendsingle/vextendsingle/summationtext∞
i=t+1I{sign[A(i)] = 1}−I{sign[A(i)] =−1}/vextendsingle/vextendsingle≤2.
E.8.2 Dynamics of ˜e2under signGD
We are now ready to analyze the dynamics of ˜e2through the behavior of ˜e0and ˜e1. Particularly, we
demonstrate that the final value of |˜e2|is affected by the magnitude of |˜e0(0)|and|˜e1(0)|. First, notice that
theupdatedirectionalong ˜e2followstheoppositeofthesignof ˜e0, andateveryiterationwhen |A(t)|≤|B(t)|,
there is a non-zero weight adaptation for ˜e2. Once the oscillation begins for ˜e0, the dynamics of ˜e0and˜e2
become similar. Consider Tas the first iteration when |˜e0|drops below√
3η. We then have
lim sup
t→∞|˜e2(t)|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle˜e2(T) +η∞/summationdisplay
t=T+1/braceleftbigg
I{|A(t)|<|B(t)|}−√
6
3+I{|A(t)|=|B(t)|}−√
6
6/bracerightbigg
sign[˜e0(t)]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤|˜e2(T)|+√
6
3η/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle∞/summationdisplay
t=T+1sign[˜e0(t)]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤|˜e2(T)|+2√
6
3η, (34)
where we use Corollary E.6 to upper bound the absolute value of the summation of the sign of ˜e0after the
T-th iteration in the last inequality. This means that after Titerations, ˜e2stays in an O(η)neighborhood of
˜e2(T); in other words, ˜w2stays in an O(η)neighborhood of ˜w2(T). Also, notice that (34) does not include
I{|A(t)|>|B(t)|}since ˜e2is updated only when |A(t)|≤|B(t)|, as shown in Table 9.
Define ∆ ˜w2as the sum of all the updates in ˜w2up to theT-th iteration:
∆ ˜w2≜ηT−1/summationdisplay
t=0/braceleftbigg
I{|A(t)|<|B(t)|}−√
6
3+I{|A(t)|=|B(t)|}−√
6
6/bracerightbigg
sign[˜e0(t)], (35)
which leads to
lim sup
t→∞|˜w2(t)|=|˜w2(T) +O(η)|=|˜w2(0) + ∆ ˜w2+O(η)|, (36)
where ˜w2(0)is the weight at initialization.
Putting (36) together with Remark E.5, the asymptotic solution found by signGD is
˜wsignGD=/bracketleftbig˜w∗
0,˜w∗
1,˜w2(0) + ∆ ˜w2/bracketrightbig⊤+O(η). (37)
39Published in Transactions on Machine Learning Research (11/2023)
From the perspective of training under the standard risk, the signGD solution is close to the optimum.
Specifically, its standard risk is
Rs(˜wsignGD) =E/bracketleftbig
ℓ(˜X,Y ;˜wsignGD)/bracketrightbig
=1
2E/bracketleftig/angbracketleftbig˜X,˜wsignGD−˜w∗/angbracketrightbig2/bracketrightig
=1
2/parenleftig
E/bracketleftbig˜X2
0/bracketrightbig
(˜wsignGD
0−˜w∗
0)2+E/bracketleftbig˜X2
1/bracketrightbig
(˜wsignGD
1−˜w∗
1)2/parenrightig
(38)
=1
2/parenleftbig
˜σ2
0O(η2) + ˜σ2
1O(η2)/parenrightbig
=O((˜σ2
0+ ˜σ2
1)η2),
where E/bracketleftbig˜X0˜X1/bracketrightbig
= 0in (38) due to the diagonality of ˜Σ. Note that the standard risk of the GD solution is
exactly zero; and by choosing a small learning rate η, the standard risk of the signGD solution can be close
to zero as well. However, their adversarial risks are very different. Specifically, the adversarial risk of the
asymptotic signGD solution is
Ra(˜wsignGD) =ϵ2
2||˜wsignGD||2
2=ϵ2
2/braceleftbig
˜w∗2
0+ ˜w∗2
1+ ( ˜w2(0) + ∆ ˜w2)2+O(η2)/bracerightbig
. (39)
Consider a sufficiently small learning rate: η≪min{˜w∗
0,˜w∗
1,˜w2(0)+∆ ˜w2}. This means that the contribution
fromO(η2)inRa(˜wsignGD)is negligible. Then the adversarial risk of the signGD solution becomes
Ra(˜wsignGD) =ϵ2
2/braceleftbig
˜w∗2
0+ ˜w∗2
1+ ( ˜w2(0) + ∆ ˜w2)2/bracerightbig
. (40)
We can compare it with the adversarial risk of the asymptotic solution found by GD under the same setup:
Ra(˜wGD) =ϵ2
2/braceleftbig
˜w∗2
0+ ˜w∗2
1+ ˜w2
2(0)/bracerightbig
. (41)
The main difference between the two adversarial risks in (40) and (41) is the difference in weights learned
at the irrelevant frequency. Since their use of irrelevant frequency in the data is under-constrained, neither
algorithm can reduce ˜w2to zero, thereby neither solution is the most robust standard risk minimizer. The
GD solution is sensitive to weight initialization. To understand the ∆ ˜w2term in the signGD solution, first
recall that Tdenotes the first iteration when |˜e0|drops below√
3η(or|A|drops below ˜σ2
0η), and from
Corollary E.6 we know that ˜w0starts oscillation at most 3 iterations after T. Recall in (36) that O(η)has
been utilized to account for the maximum sign variations, this means that we can consider oscillations which
begin immediately after the T-th update. Suppose that ηis small so the sign of ˜e0would not change before
the oscillation starts, then we have
|∆ ˜w2|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleηT−1/summationdisplay
t=0/braceleftbigg
I{|A(t)|<|B(t)|}−√
6
3+I{|A(t)|=|B(t)|}−√
6
6/bracerightbigg
sign[˜e0(t)]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleηT−1/summationdisplay
t=0/braceleftbigg
I{|A(t)|<|B(t)|}−√
6
3+I{|A(t)|=|B(t)|}−√
6
6/bracerightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle,
which leads to
|∆ ˜w2|=CηT−1/summationdisplay
t=0I{|A(t)|≤|B(t)|}, (42)
whereCdenotes some value between√
6
6and√
6
3, which correspond to always using the smaller and the
larger updates, respectively.
40Published in Transactions on Machine Learning Research (11/2023)
E.8.3 Dynamics of |∆ ˜w2|under signGD
There are two factors that can affect the magnitude of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}in (42): 1) the relative
magnitudes between ˜σ2
0and˜σ2
1, and 2) the initial values of |˜e0|and|˜e1|, or equivalently, the initial values
of|A|and|B|. To analyze this, we divide the set of values of (|A(t)|,|B(t)|)into several partitions: the
set of [0,˜σ2
0η]×RandR×[0,˜σ2
0η]is partitioned into P1andP2, and the set of [˜σ2
0η,∞)×[˜σ2
0η,∞)is
partitioned differently based on the value of˜σ2
1
˜σ2
0. Consider a line that travels through the point of (˜σ2
0η,˜σ2
0η)
and has a slope of 3˜σ2
1
˜σ2
0. The ratio between ˜σ2
0and ˜σ2
1is particularly useful in analyzing |∆ ˜w2|because
understanding the position of (|A(0)|,|B(0|)relative to such a line can lead to the value of |B(T−1)|, that
is, the value of|B|before the oscillation of |A|begins. Since|B|is updated only when |A|≤|B|, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}=|B(0)|−|B(T−1)|
˜σ2
1η. The definitions of partitions are
•P1=/braceleftbig
(A,B) :|A|<˜σ2
0η/bracerightbig
,
•P2=/braceleftbig
(A,B) :|A|>˜σ2
0ηand|B|<˜σ2
0η/bracerightbig
,
•When˜σ2
1
˜σ2
0>1
3,
–P3=/braceleftig
(A,B) : ˜σ2
0η<|A|<˜σ2
0
3˜σ2
1(|B|+ (3˜σ2
1−˜σ2
0)η)/bracerightig
,
∗P31=/braceleftbig
(A,B) : (A,B)∈P3and|A|+ ˜σ2
0η>|B|/bracerightbig
,
–P4=/braceleftig
(A,B) : ˜σ2
0η<|B|<3˜σ2
1
˜σ2
0|A|−(3˜σ2
1−˜σ2
0)η/bracerightig
,
∗P41=/braceleftbig
(A,B) : (A,B)∈P4and|B|<|A|<2˜σ2
0η/bracerightbig
,
∗P42=

(A,B) : (A,B)∈P4and|A|>|B|and2˜σ2
0η<|A|<|B|+(3˜σ2
1−˜σ2
0)η
3˜σ2
1
˜σ2
0+ ˜σ2
0η

,
•When˜σ2
1
˜σ2
0<1
3,
–P5=/braceleftbig
(A,B) : ˜σ2
0η<|A|<|B|/bracerightbig
,
–P6=/braceleftbig
(A,B) : ˜σ2
0η<|B|<|A|/bracerightbig
.
An illustration of partitions is provided in Figure 7, where the two plots demonstrate the two different ways
of dividing the set of [˜σ2
0η,∞)×[˜σ2
0η,∞)based on the value of˜σ2
1
˜σ2
0. The connection between the values of
(|A(0)|,|B(0)|)and the size of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}is summarized in the next proposition.
Proposition E.7. DenoteTas the iteration when |˜e0|drops below√
3η. The value of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}depends on the relative magnitude between ˜σ2
0and ˜σ2
1, and the initial values of
|A|and|B|. Specifically, we have
T−1/summationdisplay
t=0I{|A(t)|≤|B(t)|}=

0 if(|A(0)|,|B(0)|)∈(P1/uniontextP2)
T if˜σ2
1
˜σ2
0>1
3and (|A(0)|,|B(0)|)∈P3
|B(0)|
˜σ2
1η+ [−2˜σ2
0
˜σ2
1,−˜σ2
0
˜σ2
1]if˜σ2
1
˜σ2
0>1
3and (|A(0)|,|B(0)|)∈P4
T if˜σ2
1
˜σ2
0<1
3and (|A(0)|,|B(0)|)∈P5
|B(0)|−˜σ2
0η
1
3˜σ2
0ηif˜σ2
1
˜σ2
0<1
3and (|A(0)|,|B(0)|)∈P6.
Proof.
We divide the analysis into two main parts: when˜σ2
1
˜σ2
0>1
3and˜σ2
1
˜σ2
0<1
3, corresponding to the left and right
figures in Figure 7. For each case, we analyze the behavior of (A,B)within the partition.
41Published in Transactions on Machine Learning Research (11/2023)
Figure 7: Analyzing the value of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}in (42) by partitioning the set of values
of(|A(t)|,|B(t)|), and the relative magnitude between ˜σ2
0and ˜σ2
1determines the partitions on
which the analysis is based. Specifically, the analysis is based on partitions P1,P2,P3andP4,
when˜σ2
1
˜σ2
0>1
3(left), and on P1,P2,P5andP6, when˜σ2
1
˜σ2
0<1
3(right). The three smaller subpartitions are
subsets of the main partition, i.e., P31⊂P3andP41,P42⊂P4, and they are used in the analysis of P4.
The value of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}when (|A(0)|,|B(0)|)is initialized in each partition is summarized in
Proposition E.7. The two plots are created with ˜σ2
0= ˜σ2
1(left) and ˜σ2
0= 9˜σ2
1(right), respectively. Note that
those values are chosen for illustration purposes and do not affect the generality of the result. In both plots,
the red dashed line corresponds to |B(t)|= 3˜σ2
1
˜σ2
0|A(t)|−(3˜σ2
1−˜σ2
0)ηfor|A(t)|∈(˜σ2
0η,∞), and the yellow
dashed line corresponds to |B(t)|=|A(t)|. The pink dashed line is parallel to the red dashed line with a
horizontal gap of ˜σ2
0η.
Analysis of P1:For any (|A(0)|,|B(0)|)inP1, since|A(0)|is already below ˜σ2
0η, we haveT= 1becauseA
remains in P1. This means that/summationtextT−1
t=0I{|A(t)|≤|B(t)|}= 0.
Analysis of P2:For any (|A(0)|,|B(0)|)inP2,|A|decreases until it drops below ˜σ2
0η, while|B|remains
the same. This means that |A|remains smaller than |B|, so we have I{|A(t)|≤|B(t)|}= 0for allt∈
{0,...,T−1}. Therefore, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}= 0.
Next, thepartitionsofthesetof [˜σ2
0η,∞]×[˜σ2
0η,∞]aredefineddifferentlybasedonthevaluesof˜σ2
1
˜σ2
0compared
to1
3. This is because when˜σ2
1
˜σ2
0>1
3, it is possible for any (|A(t)|,|B(t)|)satisfying|A(t)|<|B(t)|, there
existst′> tsuch that|A(t′)|>|B(t′)|. In other words, (|A|,|B|)can oscillate above and below the line
defined by|A|=|B|, and this makes analyzing (42) difficult. However, when˜σ2
1
˜σ2
0<1
3, any (|A(t)|,|B(t)|)
that satisfies|A(t)|<|B(t)|will stay above the line defined by |A|=|B|, and this means that |A|will always
get updated by˜σ2
0η
3and|B|will always get updated by ˜σ2
1η. Because of this different behavior, we analyze
these two cases separately by defining different partitions. This corresponds to the left and right figures in
Figure 7. When˜σ2
1
˜σ2
0>1
3, the set of [˜σ2
0η,∞]×[˜σ2
0η,∞]is partitioned into P3andP4.
Analysis of P3:By definition, any (|A(t)|,|B(t)|)inP3satisfies 3˜σ2
1
˜σ2
0|A(t)|<|B(t)|+ (3˜σ2
1−˜σ2
0)η. Starting
from any (|A(0)|,|B(0)|)inP3, the values of|A|and|B|decrease at a rate of1
3˜σ2
0ηand˜σ2
1η, respectively, and
this means that two sides of the inequality decrease at the same rate. Hence, the sequence (|A(t)|,|B(t)|)
remains in P3for all 0≤t < T−1. This means that I{|A(t)|≤|B(t)|}= 1for allt∈{0,...,T−1}.
Therefore, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}=T.
Analysis of P4:Since (|A(T−1)|,|B(T−1)|)must be in P1, we can understand the value
of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}by considering how any (|A(0)|,|B(0)|)inP4is transitioned to
(|A(T−1)|,|B(T−1)|)inP1. Also, starting from any (|A(t)|,|B(t)|)inP4, we know that |A(t)|−
|A(t+ 1)|>0and|B(t)|−|B(t+ 1)| ≥ 0; hence, the transition from P4toP1must be described in
42Published in Transactions on Machine Learning Research (11/2023)
one of the following scenarios.
Transition to P2then toP1:In this case, the value of |B|must first drop below ˜σ2
0η. Since|B|decreases
only when|A|≤|B|, this means that, regardless of the initial value of |A|, the same number of updates is
required to reduce |B(0)|to˜σ2
0η, which is|B(0)|−˜σ2
0η
˜σ2
1η, and in each update, the condition I{|A(t)|≤|B(t)|}
is satisfied.
Transition to P1directly: For any (|A(t)|,|B(t)|)inP4that satisfies|B(t)|>|A(t)|(above the yellow
dashed line in Figure 7), since the values of |A|and|B|decrease at a rate of1
3˜σ2
0ηand˜σ2
1η, respectively,
(|A(t+ 1)|,|B(t+ 1)|)cannot cross the red dashed line which has a slope of 3˜σ2
1
˜σ2
0. Now let us consider any
(|A(t)|,|B(t)|)inP4that satisfies|B(t)|<|A(t)|(below the yellow dashed line). In this case, |A|decreases
by˜σ2
0η, and the only scenario where (|A(T−1)|,|B(T−1)|)ends up inP1is when ˜σ2
0η<|A(T−2)|<2˜σ2
0η.
That is, (|A(T−2)|,|B(T−2)|)is inP42. When this happens, we have ˜σ2
0η <|B(T−2)|<2˜σ2
0η;
and because there is no update in |B(T−2)|, we have ˜σ2
0η <|B(T−1)|<2˜σ2
0η. Therefore, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}∈[|B(0)|−2˜σ2
0η
˜σ2
1η,|B(0)|−˜σ2
0η
˜σ2
1η].
Transition to P3then toP1:Let us first consider the transition from P4toP3. Consider t′such that
(|A(t)|,|B(t)|)is inP4for0≤t < t′and(|A(t′)|,|B(t′)|)is inP3. Following the above analysis (direct
transition to P1), we know that (|A(t′−1)|,|B(t′−1)|)must satisfy|A(t′−1)|>|B(t′−1)|, wheret′−1
is the iteration before transitioning to P3. Also, we know that |A(t′−1)|>2˜σ2
0ηotherwise (|A(t′)|,|B(t′)|)
would be in P1. The last condition for such a transition to happen is that the horizontal distance from
|B(t′−1)|to the line of|B|= 3˜σ2
1
˜σ2
0|A|−(3˜σ2
1−˜σ2
0)η(the red dashed line) must be smaller than ˜σ2
0η. That
is,(|A(t′−1)|,|B(t′−1)|)is inP41, and (|A(t′)|,|B(t′)|)is inP31. After the transition to P3, the values
of|A|and|B|decrease at a rate of1
3˜σ2
0ηand˜σ2
1η, respectively, and |B(T−1)|has a range of [˜σ0η,2˜σ0η].
Therefore, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}∈[|B(0)|−2˜σ2
0η
˜σ2
1η,|B(0)|−˜σ2
0η
˜σ2
1η].
When˜σ2
1
˜σ2
0<1
3, the set of [˜σ2
0η,∞]×[˜σ2
0η,∞]is partitioned into P5andP6, as shown in the right figure of
Figure 7.
Analysis of P5:Starting from any (|A(0)|,|B(0)|)inP5, the values of|A|and|B|decrease at a rate
of1
3˜σ2
0ηand ˜σ2
1η, respectively. However, since˜σ2
1
˜σ2
0<1
3, there will not be any 0≤t≤T−1where
|A(t)|>|B(t)|. This means that I{|A(t)|≤|B(t)|}= 1for allt∈{0,...,T−1}. Therefore, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}=T.
Analysis of P6:Starting from any (|A(0)|,|B(0)|)inP6, the values of|A|decreases until it becomes
smaller than|B(0)|. Suppose that this happens at iteration t′, that is,|A(t′)|<|B(0)|. Starting from
(|A(t′)|,|B(t′)|)inP5,|A|starts to decrease by˜σ2
0η
3and|B|starts to decrease by ˜σ2
1η. Since˜σ2
1
˜σ2<1
3, this
means that (|A(t)|,|B(t)|)stays inP5fort∈{t′,...,T−2}, until it goes to P1when|A(T−1)|<˜σ2
0η.
Therefore, we know that the total change in |A|sincet′-th iteration is|A(t′)|−˜σ2
0η=|B(0)|−˜σ2
0η. Since
|A|can only be updated by the amount of˜σ2
0η
3inP5, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}=|B(0)|−˜σ2
0η
1
3˜σ2
0η.
We now use this analysis on the behavior of/summationtextT−1
t=0I{|A(t)|≤|B(t)|}to compute|∆ ˜w2|, which plays a role
in the adversarial risk of signGD, as shown in (40). For the initial values of (|A|,|B|)to be inP1andP2,
the initial errors must be small. However, consider a dataset with a strong task-relevant correlation between
the relevant frequency component of the data and the target, a realistic scenario as we discussed in Sec. 3.2.
In this case,|˜w∗
0|and|˜w∗
1|can be large. Additionally, with a weight initialization around zero, such as in
methods by He et al. (2015) and Glorot & Bengio (2010), the initial error |˜e0(0)|and|˜e1(0)|can be large
and close to|˜w∗
0|and|˜w∗
1|when|˜w∗
0|≫| ˜w0(0)|and|˜w∗
1|≫| ˜w1(0)|. Because of this, it is less likely for the
initial values of|A(0)|and|B(0)|to be in the P1partition in Proposition E.7.
Moreover, it is discussed in Sec. 3.1 and later supported empirically in Figure 8 of Appendix G that the
distribution of spectral energy heavily concentrates at the low end of the frequency spectrum and decays
quickly towards higher frequencies. Since ˜σ2
iis interpreted as the expected energy of a random variable at
43Published in Transactions on Machine Learning Research (11/2023)
thei-th frequency, it is reasonable to expect that˜σ2
1
˜σ2
0<1
3and this allows us to further narrow down to
initialization of (|A|,|B|)inP5andP6.
The proportional relationship between the size of (42) and the magnitude of |˜e0|and|˜e1|when˜σ2
1
˜σ2
0<1
3and
(|A|,|B|)is initialized in P5orP6can be described in the following proposition.
Proposition E.8. Suppose that the ratio between ˜σ2
0and˜σ2
1satisfies˜σ2
1
˜σ2
0<1
3. The magnitude of |∆ ˜w2|
depends on the initial values of |˜e0|and|˜e1|, and the resulting |A(0)|and|B(0)|. Specifically, we have
|∆ ˜w2|=/braceleftigg√
3C|˜e0(0)|if|A(0)|<|B(0)|
3√
2˜σ2
1
2˜σ2
0C|˜e1(0)|if|A(0)|>|B(0)|,(43)
whereC∈[√
6
6,√
6
3]and we neglect the contribution from η.
Proof.From Proposition E.7, under the assumption that˜σ2
1
˜σ2
0<1
3, we have/summationtextT−1
t=0I{|A(t)|≤|B(t)|}=T
when (|A(0)|,|B(0)|)∈P5, and this means that |∆ ˜w2|=CηTfrom (42). This also implies that for
t∈{0,...,T−1}, we have|A(t)|<|B(t)|and|A(t)|=|A(0)|−t
3˜σ2
0η.
SinceTis defined as the number of iteration required to reduce |A(0)|to˜σ2
0η,Tis|A(0)|−˜σ2
0η
1
3˜σ2
0η, and we have
|∆ ˜w2|=CηT =Cη|A(0)|−˜σ2
0η
1
3˜σ2
0η= 3C√
3
3˜σ2
0|˜e0(0)|−˜σ2
0η
˜σ2
0=C(√
3|˜e0(0)|−3η).
From Proposition E.7, when˜σ2
1
˜σ2
0<1
3and(|A(0)|,|B(0)|)is inP6, we have
|∆ ˜w2|=Cη|B(0)|−˜σ2
0η
1
3˜σ2
0η= 3C√
2
2˜σ2
1|˜e1(0)|−˜σ2
0η
˜σ2
0=C(3√
2˜σ2
1
2˜σ2
0|˜e1(0)|−3η).
Since the initial error |˜e0(0)|and|˜e1(0)|are close to|˜w∗
0|and|˜w∗
1|, (43) can be written as
|∆ ˜w2|≈/braceleftigg√
3C|˜w∗
0|if|A(0)|<|B(0)|
3√
2˜σ2
1
2˜σ2
0C|˜w∗
1|if|A(0)|>|B(0)|(44)
Now we can consider the ratio between the adversarial risk of the standard risk minimizers found by GD
(41) and signGD (40) with a three-dimensional input space. We observe that the solution found by signGD
is more sensitive to perturbations compared to the GD solution:
Ra(˜wsignGD)
Ra(˜wGD)=˜w∗2
0+ ˜w∗2
1+ ( ˜w2(0) + ∆ ˜w2)2
˜w∗2
0+ ˜w∗2
1+ ˜w2
2(0)≈1 +∆ ˜w2
2
˜w∗2
0+ ˜w∗2
1,
where we neglect the contribution from ˜w2(0)in the approximation since we have assumed that the values
of|˜w∗
0|and|˜w∗
1|are large compared to the initialized weight |˜w(0)2|. This leads to
Ra(˜wsignGD)
Ra(˜wGD)≈

1 +C3˜w∗2
0
˜w∗2
0+ ˜w∗2
1if|A(0)|<|B(0)|
1 +C4˜w∗2
1
˜w∗2
0+ ˜w∗2
1if|A(0)|>|B(0)|,
where1
2≤C3≤2and3
4˜σ4
1
˜σ4
0≤C4≤3˜σ4
1
˜σ4
0.
44Published in Transactions on Machine Learning Research (11/2023)
E.9 From Irrelevant Frequencies to Spatially Redundant Dimensions
We have demonstrated that when the use of irrelevant frequency is under-constrained, optimizing the stan-
dard training objective can lead to solutions with zero standard risk but are sensitive to perturbations. This
section offers a spatial interpretation of the findings, where we illustrate that signals with irrelevant frequen-
cies contain spatially redundant dimensions when transformed into the spatial domain. Both interpretations
can be used to explain the vulnerability of the solutions.
To illustrate the concept of redundancy in the spatial domain, consider the synthetic dataset with the
distribution defined in Sec. 4.2.2 and the data has a structure of/braceleftbig
(˜X0,˜X1,0)/bracerightbig
in the frequency domain.
Taking the DCT transformation of ˜X, we see that the spatial representation of the same dataset is
/braceleftigg
(/radicalbigg
1
3˜X0+/radicalbigg
1
2˜X1,/radicalbigg
1
3˜X0,/radicalbigg
1
3˜X0−/radicalbigg
1
2˜X1)/bracerightigg
,
where ˜X0and ˜X1are random variables with frequency interpretations. In the spatial domain, redundancy
refers to the existence of dimensions that are highly correlated with each other. The example mentioned
above illustrates that the presence of a single irrelevant frequency in the data distribution corresponds to
the existence of one redundant dimension in the spatial domain. Specifically, within this three-dimensional
dataset, it is possible to express any dimension as a linear combination of the values at the other two
dimensions.
This translation between spectral irrelevance and spatial redundancy can also be observed in the learned
weight. Consider a standard risk minimizer ˜w∗= ( ˜w∗
0,˜w∗
1,0), whose frequency-domain representation is
w∗= (/radicalbigg
1
3w∗
0+/radicalbigg
1
2w∗
1,/radicalbigg
1
3w∗
0,/radicalbigg
1
3w∗
0−/radicalbigg
1
2w∗
1).
Because of the irrelevance from ˜w2, there are multiple other standard risk minimizers. In the spatial domain,
this means w∗+ ˜w2⃗ w2with⃗ w2= (/radicalig
1
6,−/radicalig
2
3,/radicalig
1
6)and any choice of ˜w2∈Ris still a valid standard risk
minimizer.5When the model trained by signGD has a large weight at ˜w2, this implies a large ˜w2for the
weight in the spatial domain. Because ⃗ w2andw∗are orthogonal, we have ∥w∗+ ˜w2⃗ w2∥2=∥w∗∥2+|˜w2|,
therefore, the weight norm increases as ˜w2gets large, and from (12), models are more vulnerable.
It is important to realize that having irrelevant frequencies is merely a sufficient condition for having spatially
redundant features, but is not a necessary condition. For example, rearranging the dimensions of xandw∗
in the above example still preserves the spatial redundancy in the dataset, and there are still infinitely many
standard risk minimizers. However, it no longer guarantees zero entries in ˜xand ˜w∗.
F Future Direction: Studying Model Robustness under Different Optimization
Objectives
The Sharpness-Aware Minimization (SAM) objective, proposed by Foret et al. (2021), has demonstrated
improvements in model robustness both in settings with noisy training labels and against adversarial per-
turbations (Wei et al., 2023).
Understanding the dynamics of the sharpness-aware loss, especially under different optimization algorithms,
can be more involved. Without doing so, notice that the SAM objective in Foret et al. (2021) includes an
ℓ2regularization term on the weight norm. That is, training with the SAM objective penalizes models for
having large weight norms. This is in line with our findings presented in Sec. 4, where we demonstrate that
a minimum norm standard risk minimizer achieves the most robust standard risk minimizer.
Recent work by Wei et al. (2023) focused on linear models with classification and demonstrated that mini-
mizingℓSAMalone can lead to adversarially robust models. They designed a synthetic dataset based on the
5The(/radicalbig1
6,−/radicalbig2
3,/radicalbig1
6)vector is the DCT basis for the ˜w2term, i.e., C⊤(0,0,˜w2) = ˜w2(/radicalbig1
6,−/radicalbig2
3,/radicalbig1
6).
45Published in Transactions on Machine Learning Research (11/2023)
hypothesis of the robust and non-robust features (Ilyas et al., 2019), and theoretically demonstrated on the
linear classification that minimizing the sharpness-aware loss alone can result in models with larger weight
on the robust features.
An important distinction to highlight between our analysis and that of Wei et al. (2023) is that, while both
work theoretically analyze the adversarial robustness of linear models, our work focuses on models obtained
via different optimization algorithms , while Wei et al. (2023) focuses on models under different optimization
objectives . In our setting, under the same optimization objective, there exist multiple optimal solutions
where their standard risks are identical, but their adversarial risks are different. On the other hand, in
the setting of Wei et al. (2023), each objective has its own optimal solution. These solutions differ not
just in adversarial robustness but also in their standard generalization performance. The two directions
–optimization objectives and algorithms– are orthogonal, and the choice of an objective is independent of
the choice of optimization algorithm. Understanding how models, trained under robustification objectives,
behave when paired with various optimization algorithms is a promising avenue for future directions.
G Additional figures
In Figure 8, we visualize the energy distribution of various datasets containing natural images. Each dataset
contains four plots. The (i,j)coordinate in the first plot represents1
N/summationtextN
n=1|˜xn;(i,j)|, whereNis the
number of training images, ˜xnis the DCT transformation of xn, and ˜xn;(i,j)denotes the amplitude of the
(i,j)-th basis in the n-th sample. In the second plot, we visualize the diagonal values from the first plot:/braceleftig
1
N/summationtextN
n=1|˜xn;(i,i)|/bracerightig
i=0,...,d−1. We observe across all datasets that there is a high concentration of energy in
thelow-frequencyharmonicsandtheamplitudeofthehigher-frequencyharmonicsbecomesalmostnegligible.
Therefore, we repeat the first two plots in the natural log scale ( loge). The (i,j)coordinate in the third plot
represents1
N/summationtextN
n=1log|˜xn;(i,j)|. In the fourth plot, we visualize/braceleftig
1
N/summationtextN
n=1log|˜xn;(i,i)|/bracerightig
i=0,...,d−1.
46Published in Transactions on Machine Learning Research (11/2023)
0 10 200
5
10
15
20
25Spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25
(i,i)-th DCT Frequency Basis0123Magnitude of spectral energy
0 10 200
5
10
15
20
25Log scale spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25
(i,i)-th DCT Frequency Basis3
2
1
01Log scale magnitude of 
 spectral energy
123
3
2
1
01
a. MNIST
0 10 200
5
10
15
20
25Spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25
(i,i)-th DCT Frequency Basis02468Magnitude of spectral energy
0 10 200
5
10
15
20
25Log scale spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25
(i,i)-th DCT Frequency Basis4
2
02Log scale magnitude of 
 spectral energy
2468
3
2
1
012
b. FashionMNIST
0 10 20 300
10
20
30Spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis051015Magnitude of spectral energy
0 10 20 300
10
20
30Log scale spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis4
2
02Log scale magnitude of 
 spectral energy
51015
4
2
02
c. CIFAR10
0 10 20 300
10
20
30Spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis051015Magnitude of spectral energy
0 10 20 300
10
20
30Log scale spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis4
2
02Log scale magnitude of 
 spectral energy
51015
4
2
02
d. CIFAR100
0 10 20 300
10
20
30Spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis051015Magnitude of spectral energy
0 10 20 300
10
20
30Log scale spectral energy distribution 
 averaged over all training inputs
0 5 10 15 20 25 30
(i,i)-th DCT Frequency Basis6
4
2
02Log scale magnitude of 
 spectral energy
51015
6
4
2
02
e. SVHN
0 100 2000
50
100
150
200Spectral energy distribution 
 averaged over all training inputs
0 50 100 150 200
(i,i)-th DCT Frequency Basis020406080100Magnitude of spectral energy
0 100 2000
50
100
150
200Log scale spectral energy distribution 
 averaged over all training inputs
0 50 100 150 200
(i,i)-th DCT Frequency Basis6
4
2
024Log scale magnitude of 
 spectral energy
20406080
6
4
2
024
f. Caltech101
0 100 2000
50
100
150
200Spectral energy distribution 
 averaged over all training inputs
0 50 100 150 200
(i,i)-th DCT Frequency Basis020406080Magnitude of spectral energy
0 100 2000
50
100
150
200Log scale spectral energy distribution 
 averaged over all training inputs
0 50 100 150 200
(i,i)-th DCT Frequency Basis4
2
024Log scale magnitude of 
 spectral energy
20406080
4
2
024
g. Imagenette
Figure 8: Illustration of the spectral energy distribution in natural data. Distribution of the
spectral energy heavily concentrates at low frequencies and decays exponentially towards higher frequencies.
47Published in Transactions on Machine Learning Research (11/2023)
x
 |x|
 log|x|
12345
6
4
2
0
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.00250.00500.00750.0100
0.00.20.40.60.81.0
0.0250.0500.0750.100
0.00.20.40.60.81.0
0.010.020.030.04
0.00.20.40.60.81.0
0.050.100.15
0.00.20.40.60.81.0
0.0250.0500.0750.100
0.00.20.40.60.81.0
0.050.100.150.20
0.00.20.40.60.81.0
0.050.100.15
0.00.20.40.60.81.0
0.10.20.3
0.00.20.40.60.81.0
0.10.20.30.4
0.00.20.40.60.81.0
0.20.40.6
0.00.20.40.60.81.0
b. Modified Image.
Figure 9: Examples of modified images used in Observation I. (MNIST) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
48Published in Transactions on Machine Learning Research (11/2023)
x
|x|
 log|x|
2.55.07.510.012.5
8
6
4
2
02
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.0010.0020.003
0.00.20.40.60.81.0
0.010.020.030.04
0.00.20.40.60.81.0
0.010.020.03
0.00.20.40.60.81.0
0.050.100.15
0.00.20.40.60.81.0
0.020.040.06
0.00.20.40.60.81.0
0.10.2
0.00.20.40.60.81.0
0.050.100.15
0.00.20.40.60.81.0
0.10.20.30.4
0.00.20.40.60.81.0
0.10.20.30.4
0.00.20.40.60.81.0
0.20.4
0.00.20.40.60.81.0
b. Modified Image.
Figure 10: Examples of modified images used in Observation I. (FashionMNIST) We use a thresh-
old value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and
their freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both
linear and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are
in the bottom threshold percentage (row 1), the differences between the modified images and the original
image (row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images mod-
ified by removing high-frequency DCT basis vectors (row 4), the differences between the modified images
and the original image (row 5) and the binary mask used to remove the DCT basis: black means removed
(row 6). Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in
row 3 differs from images to images.
49Published in Transactions on Machine Learning Research (11/2023)
x
 |x|
 log|x|
246
8
6
4
2
0
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.010.020.03
0.00.20.40.60.81.0
0.020.040.06
0.00.20.40.60.81.0
0.0250.0500.0750.100
0.00.20.40.60.81.0
0.050.100.150.20
0.00.20.40.60.81.0
0.10.2
0.00.20.40.60.81.0
0.20.40.6
0.00.20.40.60.81.0
0.20.40.6
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
b. Modified Image.
Figure 11: Examples of modified images used in Observation I. (CIFAR10) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
50Published in Transactions on Machine Learning Research (11/2023)
x
|x|
 log|x|
2.55.07.510.012.5
6
4
2
02
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.020.040.06
0.00.20.40.60.81.0
0.10.20.3
0.00.20.40.60.81.0
0.10.2
0.00.20.40.60.81.0
0.20.40.6
0.00.20.40.60.81.0
0.20.4
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
b. Modified Image.
Figure 12: Examples of modified images used in Observation I. (CIFAR100) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
51Published in Transactions on Machine Learning Research (11/2023)
x
 |x|
 log|x|
2468
8
6
4
2
02
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.0050.0100.015
0.00.20.40.60.81.0
0.010.020.03
0.00.20.40.60.81.0
0.020.04
0.00.20.40.60.81.0
0.0000.0250.0500.0750.100
0.00.20.40.60.81.0
0.0250.0500.0750.100
0.00.20.40.60.81.0
0.10.2
0.00.20.40.60.81.0
0.10.2
0.00.20.40.60.81.0
0.20.4
0.00.20.40.60.81.0
0.20.40.60.8
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
b. Modified Image.
Figure 13: Examples of modified images used in Observation I. (SVHN) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
52Published in Transactions on Machine Learning Research (11/2023)
x
|x|
 log|x|
20406080100
10.0
7.5
5.0
2.5
0.02.5
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.0000.0050.010
0.00.20.40.60.81.0
0.000.020.04
0.00.20.40.60.81.0
0.000.020.040.060.08
0.00.20.40.60.81.0
0.000.050.100.150.20
0.00.20.40.60.81.0
0.000.050.100.150.20
0.00.20.40.60.81.0
0.10.20.30.4
0.00.20.40.60.81.0
0.00.20.4
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
b. Modified Image.
Figure 14: Examples of modified images used in Observation I. (Caltech101) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
53Published in Transactions on Machine Learning Research (11/2023)
x
|x|
 log|x|
20406080100
7.5
5.0
2.5
0.02.5
a. Original Image.
nrg(x,10)
 nrg(x,30)
 nrg(x,50)
 nrg(x,70)
 nrg(x,90)
|x nrg(x,10)|×10
|x nrg(x,30)|×10
|x nrg(x,50)|×10
|x nrg(x,70)|×10
|x nrg(x,90)|×10
Mnrg(x,10)
 Mnrg(x,30)
 Mnrg(x,50)
 Mnrg(x,70)
 Mnrg(x,90)
freq(x,10)
 freq(x,30)
 freq(x,50)
 freq(x,70)
 freq(x,90)
|x freq(x,10)|×10
|x freq(x,30)|×10
|x freq(x,50)|×10
|x freq(x,70)|×10
|x freq(x,90)|×10
Mfreq(10)
 Mfreq(30)
 Mfreq(50)
 Mfreq(70)
 Mfreq(90)
0.0000.0050.0100.015
0.00.20.40.60.81.0
0.000.050.10
0.00.20.40.60.81.0
0.000.050.10
0.00.20.40.60.81.0
0.00.10.20.30.4
0.00.20.40.60.81.0
0.00.10.20.3
0.00.20.40.60.81.0
0.00.20.40.6
0.00.20.40.60.81.0
0.20.40.6
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.20.40.60.81.0
0.00.20.40.60.81.0
0.00.20.40.60.81.0
0.00.20.40.60.81.0
b. Modified Image.
Figure 15: Examples of modified images used in Observation I. (Imagenette) We use a threshold
value of threshold ={10,30,50,70,90}to modify images based on its magnitude of DCT basis and their
freqequency basis. In a), we show the original image xand the magnitude of its DCT basis |˜x|in both linear
and log scale. In b), we show images modified by removing DCT basis vectors whose magnitudes are in the
bottom threshold percentage (row 1), the differences between the modified images and the original image
(row 2), the binary mask used to remove the DCT basis: black means removed (row 3), images modified by
removing high-frequency DCT basis vectors (row 4), the differences between the modified images and the
original image (row 5) and the binary mask used to remove the DCT basis: black means removed (row 6).
Notice that the masks in row 6 only depends on the dimension of the images, whereas the masks in row 3
differs from images to images.
54Published in Transactions on Machine Learning Research (11/2023)
0 2 4 6 8
Perturbed frequency band (r)0.02.55.07.510.012.515.017.520.0Accuracy change under 
 band-limited perturbations (%)FashionMNIST: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0123456Loss change under 
 band-limited perturbationsFashionMNIST: Freq contribution to loss change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)012345678Accuracy change under 
 band-limited perturbations (%)CIFAR10: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0.00.20.40.60.81.01.21.4Loss change under 
 band-limited perturbationsCIFAR10: Freq contribution to loss change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)010203040Accuracy change under 
 band-limited perturbations (%)SVHN: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)010203040Loss change under 
 band-limited perturbationsSVHN: Freq contribution to loss change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)0102030405060Accuracy change under 
 band-limited perturbations (%)Caltech101: Freq contribution to acc change
SGD
Adam
RMSProp
0 2 4 6 8
Perturbed frequency band (r)050100150200Loss change under 
 band-limited perturbationsCaltech101: Freq contribution to loss change
SGD
Adam
RMSProp
Figure 16: The effect of band-limited Gaussian perturbations on the model (additional figures).
Perturbations from the lowest band, i.e., ∆x(0), have a similar effect on all the models, despite being trained
by different algorithms and exhibiting different robustness properties. On the other hand, models’ responses
vary significantly when the perturbation focuses on higher frequency bands.
MNIST
 FashionMNIST
CIFAR10
 CIFAR100
SVHN
 Caltech101
Imagenette
Figure 17: Images perturbed by additive Gaussian white noise with different variance. For each
dataset, we select the largest variance value from Table 3.
55Published in Transactions on Machine Learning Research (11/2023)
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
MNIST
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 FashionMNIST
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
CIFAR10
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 CIFAR100
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
SVHN
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 Caltech101
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
Imagenette
Figure 18: Images perturbed by ℓ2-norm bounded adversarial perturbation (Croce & Hein,
2020).We select the largest ϵvalue from Table 3 to generate ℓ2bounded perturbations for images in each
dataset. We also compare perturbations generated using models trained by different algorithms.
56Published in Transactions on Machine Learning Research (11/2023)
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
MNIST
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 FashionMNIST
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
CIFAR10
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 CIFAR100
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
SVHN
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
 Caltech101
Perturbed inputs based 
on SGD-trained model
Perturbed inputs based 
on Adam-trained model
Perturbed inputs based 
on RMSProp-trained model
Imagenette
Figure 19: Images perturbed by ℓ∞-norm bounded adversarial perturbation (Croce & Hein,
2020).We select the largest ϵvalue from Table 3 to generate ℓ∞bounded perturbations for images in each
dataset. We also compare perturbations generated using models trained by different algorithms.
57