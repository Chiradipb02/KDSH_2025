Published in Transactions on Machine Learning Research (02/2023)
Mean-field analysis for heavy ball methods: Dropout-
stability, connectivity, and global convergence
Diyuan Wu diyuan.wu@ista.ac.at
Institute of Science and Technology Austria (ISTA)
Vyacheslav Kungurtsev kunguvya@fel.cvut.cz
Czech Technical University
Marco Mondelli marco.mondelli@ista.ac.at
Institute of Science and Technology Austria (ISTA)
Reviewed on OpenReview: https: // openreview. net/ forum? id= gZna3IiGfl
Abstract
The stochastic heavy ball method (SHB), also known as stochastic gradient descent (SGD)
with Polyak’s momentum, is widely used in training neural networks. However, despite the
remarkable success of such algorithm in practice, its theoretical characterization remains
limited. In this paper, we focus on neural networks with two and three layers and provide
a rigorous understanding of the properties of the solutions found by SHB: (i)stability
after dropping out part of the neurons, (ii)connectivity along a low-loss path, and (iii)
convergence to the global optimum. To achieve this goal, we take a mean-field view and
relatetheSHBdynamicstoacertainpartialdifferentialequationinthelimitoflargenetwork
widths. Thismean-fieldperspectivehasinspiredarecentlineofworkfocusingonSGDwhile,
in contrast, our paper considers an algorithm with momentum. More specifically, after
proving existence and uniqueness of the limit differential equations, we show convergence to
the global optimum and give a quantitative bound between the mean-field limit and the SHB
dynamics of a finite-width network. Armed with this last bound, we are able to establish
the dropout-stability and connectivity of SHB solutions.
1 Introduction
Neural networks are one of the most popular modeling tools in machine learning tasks. In practice, they
can be effectively trained by gradient-based methods, and are usually overparameterized. However, despite
the empirical success of various training algorithms, it is still not well understood why such algorithms have
good convergence properties, given that the optimization landscape is known to be highly non-convex and to
contain spurious local minima (Auer et al., 1996; Safran & Shamir, 2018; Yun et al., 2019). A popular line
of work starting from (Mei et al., 2018; Chizat & Bach, 2018; Rotskoff & Vanden-Eijnden, 2018; Sirignano
& Spiliopoulos, 2020a) has proposed a new regime to analyze the behavior of stochastic gradient descent
(SGD), namely, the mean-field regime. The idea is that, as the number of neurons of the network grows, the
SGD training dynamics converges to the solution of a certain Wasserstein gradient flow. This perspective
has facilitated the study of architectures with multiple layers (Araújo et al., 2019; Lu et al., 2020; Nguyen &
Pham, 2020; Fang et al., 2021), and it has provided a path to rigorously understand a number of properties,
including convergence towards a global optimum (Mei et al., 2018; Chizat & Bach, 2018; Javanmard et al.,
2020; Pham & Nguyen, 2021a), dropout-stability and connectivity (Shevchenko & Mondelli, 2020), and
implicit bias (Williams et al., 2019; Chizat & Bach, 2020; Shevchenko et al., 2022).
Optimization with momentum, e.g., the heavy ball method (Polyak, 1964) or Adam (Kingma & Ba, 2015), is
widely used in practice (Sutskever et al., 2013). However, all the aforementioned works consider the vanilla
1Published in Transactions on Machine Learning Research (02/2023)
SGD algorithm and, in general, the theoretical understanding of algorithms with momentum has lagged
behind. To address this gap, the recent paper by Krichene et al. (2020) defines a mean-field limit for the
stochastic heavy ball (SHB) method – also known as SGD with Polyak’s momentum – in a two-layer setup.
In particular, the convergence to the mean-field limit is proved, as well as that the solution of the mean-field
equation approaches a global optimum in the large time limit. However, Krichene et al. (2020) leave as
an open problem finding a quantitative bound between the infinite-width limit and the finite-width neural
network, and the analysis is restricted to two-layer networks.
In this paper, we define a mean-field limit for the heavy ball method applied to two-layer and three-layer
networks. We show global convergence in the three-layer setting, and give quantitative bounds for networks
with finite widths. This last result opens the way to providing a rigorous understanding of effects commonly
observed in practice, such as the connectivity of solutions via low-loss paths (Goodfellow & Vinyals, 2015;
Garipov et al., 2018; Draxler et al., 2018; Entezari et al., 2022). More specifically, our main contributions
can be summarized as follows:
1. Weshowexistenceanduniquenessofthemean-fielddifferentialequationscapturingtheSHBtraining
for two-layer and three-layer networks (Theorem 4.1).
2. We give non-asymptotic convergence results of the SHB dynamics of a finite-width neural network to
the corresponding mean-field limit (Theorem 5.1 for two layers, and Theorem 5.2 for three layers).
Our bounds are dimension-free in the sense that the layer widths are not required to scale with the
input dimension.
3. We discuss how SHB solutions can be connected via a simple piece-wise linear path, along which
the increase in loss vanishes as the width of the network grows (Section 6). This is a consequence
of the stability against dropout displayed by the parameters found by SHB, which in turn follows
from Theorems 5.1-5.2.
4. Finally, by exploiting a universal approximation property enjoyed by the activation function, we
prove a global convergence result for three-layer networks, under certain assumptions on the mode
of convergence of the dynamics (Theorem 7.2).
Organization of the paper. After discussing the related work in Section 2, the details concerning the
network architecture and SHB training are presented in Section 3. In Section 4, we define the mean-field
limit for both two-layer and three-layer networks, and we show that such limits exist and are unique. Next, in
Section 5, we prove our quantitative convergence bounds between the discrete SHB dynamics and the mean-
field limit. As an application of these bounds, we discuss the dropout-stability and connectivity displayed
by the SHB solutions in Section 6. In Section 7, we prove global convergence for the three-layer mean-field
differential equation. In Section 8, we show the results of some numerical experiments that illustrate the
dropout stability of the SHB solution. Finally, we discuss future directions in Section 9.
2 Related work
Mean-field analysis for two-layer networks. A quantitative convergence result of the SGD dynamics
towards a mean-field limit was presented in (Mei et al., 2018). This bound was refined to be independent
of the input dimension in (Mei et al., 2019), which also considers a setting where both layers are trained.
Our approach extends this line of work to the heavy-ball method. Because of the presence of momentum, in
this case the mean-field limit is described by a second-order differential equation (instead of the first-order
one capturing the SGD dynamics). The mean-field limit for heavy-ball methods was first considered in
(Krichene et al., 2020), which deals with a setting regularized by noise and does not provide quantitative
bounds. The recent work by Schuh (2022) gives non-asymptotic guarantees, but the argument crucially
relies on the presence of additive Gaussian noise. Global optimality of SGD was proved by Chizat & Bach
(2018) in the noiseless setting, using the homogeneity of the activation and under an additional convergence
assumption. This assumption is not needed in the noisy case, as the mean-field dynamics is a Wasserstein
gradient flow for a strongly convex free-energy functional (Mei et al., 2019). Convergence rates have been
2Published in Transactions on Machine Learning Research (02/2023)
obtained by exploiting displacement convexity (Javanmard et al., 2020) or via the log-Sobolev constant of
the stationary measure (Chizat, 2022; Nitanda et al., 2022). For heavy ball methods, although the limiting
dynamics does not yield a gradient flow structure, the rate of convergence has been studied in the noisy case
(Hu et al., 2019; Kazeykina et al., 2020; Schuh, 2022). For a noiseless dynamics, the explicit characterization
of the convergence rate is an open problem.
Mean-field analysis for multi-layers networks. The case of neural networks with more than two layers
presents additional challenges in regards to defining and characterizing a mean-field limit. Here, we follow
the “neuronal embedding” framework (Nguyen & Pham, 2020; Pham & Nguyen, 2021a) to define a mean-
field limit for the heavy ball method in a three-layer setting. The key idea is to introduce a certain fixed
product probability space at initialization, and regard the weights as deterministic functions which evolve
during training over this fixed probability space. Other approaches have been proposed as well: Sirignano &
Spiliopoulos (2020a) give asymptotic results for three-layer networks, which require taking the large-width
limits in a specific sequential order; Fang et al. (2021) focus on the dynamics of the features, rather than
on that of the weights; Araújo et al. (2019) consider neural networks with more than four layers, with un-
trained first and last layer, and their result depends on the degeneracy phenomenon of middle layers under
i.i.d. initialization. This degeneracy consists in the fact that all the weights in the middle layers (except
the second and second-to-last) remain i.i.d., hence the corresponding neurons compute the same function.
Pham & Nguyen (2021a) show global optimality of the mean-field dynamics in the noiseless case in the large
time limit, under a convergence assumption in the same spirit of Chizat & Bach (2018). While the global
convergence in Chizat & Bach (2018) crucially relies on the homogeneity of the activation, Pham & Nguyen
(2021a) exploit a universal approximation property, similarly to Lu et al. (2020). For deeper networks,
a key technical hurdle is due to the degeneracy phenomenon mentioned above, which prevents universal
approximation. To address this issue, Nguyen & Pham (2020) employ a different initialization, and Lu et al.
(2020); Fang et al. (2021) use skip connections.
For multi-layer networks, it is also possible to define a mean-field limit beyond the parameterization con-
sidered in the aforementioned works, see Hajjar et al. (2021); Chen et al. (2022). In particular, Hajjar
et al. (2021) consider the regime of so called integrable parameterizations , which is a modification of the
maximum-update parameterization proposed by Yang & Hu (2021). Furthermore, Chen et al. (2022) provide
a convergence result for three-layer networks, where the first layer is random and fixed.
Additional related work on optimization with momentum. A recent line of work has considered
training neural networks in the neural tangent kernel (NTK) regime (or lazy regime) (Jacot et al., 2018;
Chizat et al., 2019). Here, the weights of the neural networks stay close to their initialization, so that the
network is well approximated by its linearization and the convergence is related to the smallest eigenvalue
of the NTK, see e.g. (Du et al., 2019; Allen-Zhu et al., 2019; Montanari & Zhong, 2020; Bombari et al.,
2022) and references therein. This type of analysis has been adapted to the heavy ball method by Wang
et al. (2021) and to other adaptive methods by Wu et al. (2019). However, we remark that, unlike in the
mean-field regime, neural networks are unable to perform feature learning in the NTK regime (Yang & Hu,
2021). Beyond the training of neural networks, momentum-based stochastic gradient descent algorithms and
their continuous variants have been widely studied in optimization: the continuous limit of these methods
is studied in (Su et al., 2014; Wibisono et al., 2016; Shi et al., 2021), and such dynamics are known to be
closely related to sampling methods such as MCMC (Ma et al., 2021).
3 Problem setup
3.1 Network architecture
We consider neural networks with two and three layers. In the two-layer case, the network has nneurons
and inputx∈RD:
H1(x,j;W) =w1(j)Tx, j∈[n],
f(x;W) =1
nn/summationdisplay
j=1w2(j)σ(H1(x,j;W)).(1)
3Published in Transactions on Machine Learning Research (02/2023)
Here, we use the short-hand [n] :={1,...,n}and, forj∈[n], the parameters of the j-th neuron are denoted
byθ(j) = (w1(j),w2(j)), withw1(j)∈RDandw2(j)∈R. In the three-layer case, the network has n1and
n2neurons in the first and second hidden layer, respectively:
H1(x,j1;W) =w1(j1)Tx, j 1∈[n1],
H2(x,j2;W) =1
n1n1/summationdisplay
j1=1w2(j1,j2)σ1(H1(x,j1;W)), j 1∈[n1], j2∈[n2],
f(x;W) =1
n2n2/summationdisplay
j2=1w3(j2)σ2(H2(x,j2;W)).(2)
Here,x∈RD,w1(j1)∈RD,w2(j1,j2)∈Randw3(j2)∈R. In both cases, we use Wto denote the collection
of all parameters: in two-layer case W∈Rn(D+1), and in three-layer case W∈Rn1D+n2n1+n2.
3.2 Training algorithm
Our training data z= (x,y)is generated i.i.d. from a distribution D. The neural network is trained to
minimize the population risk function R(W) =Ez[R(y,f(x;W))]via the following one-pass stochastic
heavy ball (SHB) method:
W(k+ 1) =W(k) +β(W(k)−W(k−1))−η/hatwide∇WR(y(k),f(x(k);W(k))), (3)
where we use /hatwide∇WR(y(k),f(x(k);W))to denote the scaled gradient, and the scaling factors for each pa-
rameter are specified below. This is a one-pass method in the sense that, at each step, we sample a new
data pointz(k)independent from the previous ones.The requirements on the loss function R(y,ˆy)are con-
tained in (A1) (see Assumption 3.1) and (B1) (see Assumption 3.3) for networks with two and three layers,
respectively. In particular, we require R(y,ˆy)to be differentiable with respect to its second argument and
to have a bounded derivative. We also remark that, for the convergence to the mean field limit (Theorem
5.1 and 5.2), the convexity of the loss is not required. In contrast, to obtain the global convergence result of
Theorem 7.2, we need to additionally assume that R(y,ˆy)is convex in the second argument, as mentioned
in the statement of the theorem.
Letγbe a constant which does not depend on the network width or on the step size of gradient descent.
Then, in order to define a continuous-time ODE for the heavy ball method, we pick β= (1−γε)andη=ε2,
so the one-pass SHB method can be equivalently written as follows:
W(k+ 1) =W(k) +r(k),
r(k) = (1−γε)(W(k)−W(k−1))−ε2/hatwide∇WR(y(k),f(x(k);W(k))). (4)
A similar formulation is common in the literature, see for example (Shi et al., 2021, Eq. 1.2)1. The
corresponding continuous ODE, also studied in (Krichene et al., 2020, equation 6), is given by
∂tW(t) =r(t), ∂tr(t) =−γr(t)−/hatwide∇WR(W(t)), (5)
where we recall that /hatwide∇WR(W(t))denotes the scaled gradient. We remark that there are different ways
to derive a continuous dynamics from (3), and (4) is obtained by applying the Euler scheme based on the
second-order Taylor expansion. The corresponding ODE (5) is denoted as the low-resolution ODE by Shi
et al. (2021). It is an interesting and challenging task to analyze other types of ODEs associated to the SHB
method, for example the high-resolution ODE proposed by Shi et al. (2021). We leave this to future works.
We also remark that a similar formulation of the continuous counterpart of heavy ball methods with fixed
momentum is considered in (Kovachki & Stuart, 2021; Kunin et al., 2021).
1Note that in (Shi et al., 2021, Eq. 1.2), β=1−γϵ
1+γϵ, while here we let β= 1−γε. The two choices are basically the same
whenεis small.
4Published in Transactions on Machine Learning Research (02/2023)
We conclude this part by discussing the scaling factors for the gradient in (4). In the two-layer case, we have
/hatwide∇WR(y,f(x;W)) =/parenleftbig
(∆W
1(x,j;W))j∈[n],(∆W
2(x,j;W))j∈[n]/parenrightbig
, (6)
where
∆W
2(x,j;W) :=n∂w2(j)R(y,f(x;W)) =∂2R(y,f(x;W))σ(H1(x,j;W)),
∆W
1(x,j;W) :=n∇w1(j)R(y,f(x;W)) =∂2R(y,f(x;W))w2(j)σ′(H1(x,j;W))x.(7)
In the three-layer case, we have
/hatwide∇WR(y,f(x;W)) =/parenleftbig
(∆W
1(x,j1;W))j1∈[n1],(∆W
2(x,j1,j2;W))j1∈[n1],j2∈[n2],(∆W
3(x,j2;W))j2∈[n2]/parenrightbig
,(8)
where
∆W
3(x,j2;W) :=n2∂w3(j2)R(y,f(x;W)) =∂2R(y,f(x;W))σ2(H2(x,j2;W)),
∆H
2(x,j2;W) :=n2∂H2(x,j2;W)R(y,f(x;W)) =∂2R(y,f(x;W))w3(j2)σ′
2(H2(x,j2;W)),
∆W
2(x,j1,j2;W) :=n1n2∂w2(j1,j2)R(y,f(x;W)) = ∆H
2(x,j2;W)σ1(H1(x,j1;W)),
∆H
1(x,j1;W) :=n1∂H1(x,j1;W)R(y,f(x;W)) =1
n2n2/summationdisplay
j2=1∆H
2(x,j2;W)w2(j1,j2)σ′
1(H1(x,j1;W)),
∆W
1(x,j1;W) :=n1∇w1(j1)R(y,f(x;W)) = ∆H
1(x,j1;W)x.(9)
One can interpret this as indicating that in the two-layer case, the scaling factor is n. In the three-layer
case, the scaling factor is n2for the third layer, n1×n2for the second layer, and n1for the first layer. This
choice of the scaling factors ensures that each component of the gradients is of order 1(i.e., independent of
the layer widths n,n 1,n2). In the following sections, we will use w1(t,j)orw1(k,j)to represent the weights
at timetor time step k. The same notation also applies to w2,w3.
3.3 Assumptions
Our assumptions are rather standard in the mean-field literature and appear e.g. in (Mei et al., 2018; 2019;
Nguyen & Pham, 2020; Pham & Nguyen, 2021a). We write such assumptions separately for networks with
two and three layers.
Assumption 3.1. We make the following assumptions for the training of a two-layer network:
(A1) (Boundedness) There exists a universal constant K > 0such that∥σ∥∞,∥σ′∥∞,∥σ′′∥∞≤K. The
data distribution Dis such that, almost surely, |y|,∥x∥2≤K. Furthermore,|∂2R(y,f(x;W))|is
K-Lipschitz continuous in f(x;W)andK-bounded for any W.
(A2) (Initialization of weights) At initialization, w1(0,j),w2(0,j)i.i.d.∼ρ0, whereρ0is such thatw1(0,j)
isK2-sub-Gaussian, and |w2(0,j)|≤Kalmost surely.
(A3) (Initialization of momentum) We assume that r(0) = 0.
In order to state the assumption for a three-layer neural network, we first define the notion of i.i.d. initial-
ization.
Definition 3.2. We say that the three-layer neural network (2) has i.i.d. initialization from ρ1
0×ρ2
0×ρ3
0, if:
w1(0,j1)i.i.d.∼ρ1
0, w 2(0,j1,j2)i.i.d.∼ρ2
0, w 3(0,j2)i.i.d.∼ρ3
0, j 1∈[n1], j 2∈[n2]. (10)
In short, i.i.d. initialization means both cross-layer and in-layer independence.
Assumption 3.3. We make the following assumptions for the training of a three-layer network:
5Published in Transactions on Machine Learning Research (02/2023)
(B1) (Boundedness) There exists a universal constant K > 0such that∥σ1∥∞,∥σ′
1∥∞,∥σ′′
1∥∞,∥σ2∥∞,
∥σ′
2∥∞,∥σ′′
2∥∞≤K. The data distribution Dis such that|y|,∥x∥2≤Kalmost surely. Furthermore,
σ′
2(x)̸= 0for allx,|∂2R(y,f(x;W))|isK-Lipschitz continuous with respect to the second argument
andK-bounded for any W.
(B2) (Initialization of weights) w1(0,j1),w2(0,j1,j2),w3(0,j2)have an i.i.d. initialization from ρ1
0×ρ2
0×
ρ3
0. Furthermore, w1(0,j1)isK2-sub-Gaussian, and |w2(0,j1,j2)|,|w3(0,j2)|≤Kalmost surely.
(B3) (Initialization of momentum) We assume that r(0) = 0.
In the initialization of two-layer networks, ρ0is not required to be a product measure, that is,
w1(0,j),w2(0,j)are not required to be independent from each other. In other words, we do not assume
cross-layer independence, but only in-layer independence. However, in the three-layer case, we need to as-
sume both cross-layer independence and in-layer independence, and it turns out later that the cross-layer
independence is critical for proving our global convergence result.
The requirements above hold e.g. for tanhor sigmoid activation function, and logistic or Huber loss. The
assumption that ∂2R(y,f(x;W))isK-bounded does not hold for the square loss. However, we expect the
same results proved in this paper to hold also for the square loss, provided that the assumptions are modified
as in Mei et al. (2019) (for the two-layer case) and in Nguyen & Pham (2020) (for the three-layer case). In
fact, it suffices that ∂2R(y,f(x;W))is bounded with high probability, and then the arguments are similar.
Finally, we remark that the boundedness of the initialization w2(0,j)andw2(0,j1,j2),w3(0,j2)is purely
to simplify the proof, which can be generalized to a K2-sub-Gaussian initialization. In particular, one can
bound the sub-Gaussian norm of the weights, and then the absolute value of the weights will also be bounded
with high probability.
4 Derivation of the mean-field limit
Two-layer networks. The idea is that the output of the network can be viewed as an expectation over the
empirical distribution of the weights, that is:
f(x;W) =1
nn/summationdisplay
j=1w2(j)σ1(w1(j)Tx) =Eθ∼ˆρθσ⋆(x;θ),
whereW={θ(j) :j∈[n]}andθ(j) = (w1(j),w2(j)). Furthermore, we define σ⋆(x;θ(j)) =
w2(j)σ(w1(j)Tx)and/hatwideρθ=1
n/summationtextn
j=1δθ(j). Thus, the evolution of the parameters θ(t)according to (5)
can be viewed as the evolution of /hatwideρθ(t)according to a certain distributional dynamics induced by (5).
Since we assume i.i.d. initialization, as the number of neurons n− →∞, we expect that /hatwideρθ(0)− →ρ0. In this
limit, the distributional dynamics induced by (5), can be described by a certain ODE, with initial condition
ρ0. Let
f(x;ρ) :=Eθ∼ρσ⋆(x;θ), R (z;ρ) :=R(y,f(x;ρ)), R (ρ) :=EzR(y,f(x;ρ)),
/hatwideΨ(z,θ;ρ) :=δR(z,ρ)
δρ(θ), Ψ(θ;ρ) :=δR(ρ)
δρ(θ) =Ez/hatwideΨ(z,θ;ρ).(11)
Here,f(·;ρ) :RD→R;R(·;ρ) :RD+1→R,R(·) :P2(RD+1)→R, whereP2(RD+1)denotes the space of
probability measures on RD+1with finite second moment; ˆΨ(·,·;ρ) :RD+1×RD+1→R;Ψ(·;ρ) :RD+1→R.
Then, we define the mean-field ODE associated to the heavy ball method as
dθ(t) =r(t)dt, dr(t) =/parenleftbig
−γr(t)−∇θΨ(θ(t);ρθ(t))/parenrightbig
dt. (12)
Three-layernetworks. Amongthevariousapproachestodefineamean-fieldlimitformulti-layernetworks,
wefollowthe“neuronalembedding”frameworkproposedin(Nguyen&Pham,2020;Pham&Nguyen,2021a)
6Published in Transactions on Machine Learning Research (02/2023)
to capture the dynamics of SGD training. We briefly summarize the key ideas, and then discuss how to
obtain the mean-field limit for the stochastic heavy ball method.
Consider a three-layer neural network of the form (2) with weights w1(0,j1),w2(0,j1,j2),w3(0,j2)obtained
via an i.i.d. initialization from ρ1×ρ2×ρ3, according to Definition 3.2. Then, in (Pham & Nguyen, 2021a,
Proposition 7), it is proved that there exists a product probability space (Ω1×Ω2,F1×F 2,P1×P2)and
functionsw1(0,·) : Ω 1− →RD,w2(0,·,·) : Ω 1×Ω2− →R,w3(0,·) : Ω 2− →Rsuch that, for any n1,n2,
{w1(0,C1(j1)),w2(0,C1(j1),C2(j2)),w3(0,C2(j2)),forj1∈[n1],j2∈[n2]}
d={w1(0,j1),w2(0,j1,j2),w3(0,j2),forj1∈[n1],j2∈[n2]},
whered=denotes equality in distribution, C1(j1)i.i.d.∼P1,C2(j2)i.i.d.∼P2, forj1∈[n1],j2∈[n2]. Here,
the tuple{(Ω1×Ω2,F1×F 2,P1×P2),w1(0,·),w2(0,·,·),w3(0,·)}is called a neuronal embedding . With a
slight abuse of notation, we use w1,w2,w3to denote also the functions w1(0,·),w2(0,·,·),w3(0,·). In later
sections, we refer to the functions when we write w1(0,c1),w2(0,c1,c2),w3(0,c2), while we refer to the
weights of the neural network when we write w1(0,j1),w2(0,j1,j2),w3(0,j2).
At this point, we are ready to define the mean-field ODE for the heavy ball method. This ODE tracks the
functionsw1(0,·),w2(0,·,·),w3(0,·):
dw3(t,c2) =r3(t,c2)dt, dr 3(t,c2) = (−γr3(t,c2)−Ez∆W
3(z,c2;W(t)))dt,
dw2(t,c1,c2) =r2(t,c1,c2)dt, dr 2(t,c1,c2) = (−γr2(t,c1,c2)−Ez∆W
2(z,c1,c2;W(t)))dt,
dw1(t,c1) =r1(t,c1)dt, d r1(t,c1) = (−γr1(t,c1)−Ez∆W
1(z,c1;W(t)))dt,(13)
wherec1∈Ω1,c2∈Ω2aredummyvariablesand W(t)referstothecollectionofweights (w1(t),w2(t),w3(t)).
The output of the neural network under the mean-field limit (13) is described via the following forward pass:
H1(x,c1;W(t)) =w1(t,c1)Tx, c 1∈Ω1,
H2(x,c2;W(t)) =EC1∼P1w2(t,C1,c2)σ1(H1(x,C1;W(t))), c 2∈Ω2,
f(x;W(t)) =EC2∼P2w3(t,C2)σ2(H2(x,C2;W(t))).(14)
Furthermore, the quantities ∆W
3,∆W
2,∆W
1appearing in (13) are described via the backward pass:
∆W
3(z,c2;W(t)) :=∂2R(y;f(x;W(t)))σ2(H2(x,c2;W(t))),
∆H
2(z,c2;W(t)) :=∂2R(y;f(x;W(t)))w3(t,c2)σ′
2(H2(x,c2;W(t))),
∆W
2(z,c1,c2;W(t)) := ∆H
2(z,c2;W(t))σ1(H1(x,c1;W(t))),
∆H
1(z,c1;W(t)) :=EC2∆H
2(x,C2;W(t))w2(t,c1,C2)σ′
1(H1(x,c1;W(t))),
∆W
1(z,c1;W(t)) := ∆H
1(x,c1;W(t))x.(15)
For convenience, we will also use the lighter notation H1(t,x,c1),H2(t,x,c2),∆W
3(t,z,c2),∆H
2(t,z,c2),
∆W
2(t,z,c1,c2),∆H
1(t,z,c1),∆W
1(t,z,c1)to denote the quantities H1(x,c1;W(t)),H2(x,c1;W(t)),
∆W
3(z,c2;W(t)),∆H
2(z,c2;W(t)),∆W
2(z,c1,c2;W(t)),∆H
1(z,c1;W(t)),∆W
1(z,c1;W(t)), respectively.
We note that the neuronal embedding framework can recover the distributional dynamics for two-layer
networks as a special case (see (Nguyen & Pham, 2020, Corollary 22) for more details). It is also possible
to define the mean-field limit for three-layer neural networks directly as a distributional dynamics (Araújo
et al., 2019; Sirignano & Spiliopoulos, 2020a), although this approach may require additional assumptions
(namely, first and last layer not trained, see Araújo et al. (2019)).
At this point, we are ready to prove the existence and uniqueness of the mean-field differential equations.
Theorem 4.1. For anyt <∞, we have: (i) Under Assumption 3.1, there exists a unique solution of the
mean-field PDE (12).
(ii) Under Assumption 3.3, there exists a unique solution of the mean-field ODE (13).
7Published in Transactions on Machine Learning Research (02/2023)
The proof of Theorem 4.1 follows from the analysis of a Picard type of iteration (Sznitman, 1991), and it
is deferred to Appendix B. We note that Krichene et al. (2020) consider a mean-field limit for two-layer
networks in which an additional Brownian motion is applied to the momentum term. This extra noise term
– together with the additional assumption (A5) (see p. 8 of Krichene et al. (2020)) – allows them to prove
the existence and uniqueness of the mean-field limit for any t∈[0,∞]. This includes the existence and
uniqueness of the limiting point (for t=∞). In contrast, Theorem 4.1 proves the existence and uniqueness
of the solution for any finite t, and we do not have guarantees on the limiting point.
5 Convergence to the mean-field limit
5.1 Two-layer networks
We recall that the mean-field ODE is defined in (12), and the SHB dynamics can be expressed as
θSHB(k+ 1,j) =θSHB(k,j) + (1−γε)(θSHB(k,j)−θSHB(k−1,j))−ε2∇θ/hatwideΨ(z(k),θSHB(k,j);ρθ
SHB(k)),
(16)
whereθSHB(k,j)denotes the parameter associated to the j-th neuron at step k,/hatwideΨis defined in (11),
andρθ
SHB(k) =1
n/summationtextn
j=1δθSHB(k,j)denotes the empirical distribution of the parameters {θSHB(k,j)}j∈[n].
We couple the mean-field ODE (12) and the SHB dynamics (16), in the sense that they share the same
initialization: θ(0)∼ρθ(0)andθSHB(0,j)i.i.d.∼ρθ(0). Let us define the following distance metric that
measures the difference between the mean-field dynamics and the SHB dynamics:
DT(θ,θSHB) = max
j∈[n]sup
t∈[0,T]∥θSHB(⌊t/ε⌋,j)−θ(t)∥2. (17)
Theorem 5.1. Let Assumption 3.1 hold. Consider the mean-field ODE (12), the SHB dynamics (16) and
the distance metric (17). Then, with probability at least 1−exp(−δ2),
DT(θ,θSHB)≤K(γ,T)/parenleftigg/parenleftbig√logn+δ/parenrightbig
√n+√ε(/radicalbig
D+ logn+δ)/parenrightigg
, (18)
whereK(γ,T)is a constant depending only on γ,T.
We remark that the RHS of (18) is also an upper bound on supt∈[0,T]W2(ρθ(t),ρθ
SHB(⌊t/ε⌋)), which follows
directly from the definition of the Wasserstein W2distance.
Theorem 5.1 gives a quantitative characterization of the approximation error between the mean-field limit
and the stochastic heavy ball dynamics. In particular, it shows that this approximation error scales roughly
as/radicalbig
logn/n+/radicalbig
ε(D+ logn), i.e., it vanishes as the number of neurons ngrows large and the step size
ε=o(1/√D+ logn). We remark that the bound in (18) is dimension-free in the sense that ndoes not
need to scale with the input dimension D. This is aligned with the bound provided for SGD by Mei et al.
(2019) which is also dimension-free.Note that the order of the upper bound O(1√n)is tight due to large
deviation theory. This implies that it is not possible to improve the corresponding dropout stability and
connectivity guarantees (see Section 6), in terms of the number of neurons/input dimension. This means
that the behavior of SGD and SHB is similar, as both algorithms are optimal in this regard. The constant
K(γ,T)scales rather poorly in T, i.e.,K(γ,T) =O(eeT). This is a common shortcoming for “propagation
of chaos”-type arguments: for example, in Mei et al. (2018; 2019), the scaling of the bound in TisO(eT).
An interesting open problem is to improve such dependence, e.g., by using ideas from Schuh (2022).
To the best of our knowledge, Theorem 5.1 provides the first consistency guarantee of the mean-field limit
(12). In the noisy case, a similar (although non-quantitative) guarantee is proved by Krichene et al. (2020).
The injection of noise in the dynamics often simplifies the analysis and it allows to prove stronger results
8Published in Transactions on Machine Learning Research (02/2023)
(e.g., existence and uniqueness of the limit). However, the noiseless dynamics is particularly interesting,
since Brownian noise is typically notadded in practice while training.
At the technical level, in order to deal with the second order dynamics arising from the heavy ball method,
we exploit a second order Gronwall’s lemma (cf. Lemma F.3) and use the Euler scheme to discretize the
continuous dynamics. The detailed proof is provided in Appendix C.
5.2 Three-layer networks
We recall that the mean-field ODE is defined in (13), and the SHB dynamics can be expressed as
wSHB
3(k+ 1,j2) =wSHB
3(0,j2) + (1−γε)(wSHB
3(k,j2)−wSHB
3(k−1,j2))−ε2∆W
3(z(k),j2;WSHB(k)),
wSHB
2(k+ 1,j1,j2) =wSHB
2(0,j1,j2) + (1−γε)(wSHB
2(k,j1,j2)−wSHB
2(k−1,j1,j2))
−ε2∆W
2(z(k),j1,j2;WSHB(k)),
wSHB
1(k+ 1,j1) =wSHB
1(0,j1) + (1−γε)(wSHB
1(k,j1)−wSHB
1(k−1,j1))−ε2∆W
1(z(k),j1;WSHB(k)),
(19)
whereWSHB(k) =/parenleftbig
(wSHB
1(k,j1))j1∈[n1],(wSHB
2(k,j1,j2))j1∈[n1],j2∈[n2],(wSHB
3(k,j2))j2∈[n2]/parenrightbig
,z(k)is the
data point sampled at time step k, and ∆W
1,∆W
2,∆W
3are defined in (9).
Before stating our result, let us discuss how to couple the SHB dynamics (19) and the mean-field ODE (13).
First, sample a finite neural network w.r.t. the neuronal embedding, i.e., C1(j1)i.i.d.∼P1,C2(j2)i.i.d.∼P2,
forj1∈[n1],j2∈[n2]andw1(0,·),w2(0,·,·),w3(0,·). Givenw1(0,·),w2(0,·,·),w3(0,·), let the mean-field
ODE (13) evolve, thus obtaining w1(t,·),w2(t,·,·),w3(t,·). Next, initialize the weights corresponding to
the SHB evolution according to the initialization of the mean-field ODE, i.e., wSHB
1(0,j1) =w1(0,C1(j1)),
wSHB
2(0,j1,j2) =w2(0,C1(j1),C2(j2))andwSHB
3(0,j2) =w3(0,C2(j2)), and let them evolve according to
SHB dynamics (19), thus obtaining wSHB
1(k,j1),wSHB
2(k,j1,j2),wSHB
3(k,j2). Finally, we define the following
distance metric that measures the difference between the mean-field and the SHB dynamics:
DT(W,WSHB) = max
j1∈[n1],j2∈[n2]sup
t∈[0,T]max{∥w1(t,C1(j1))−wSHB
1(⌊t/ε⌋,j1)∥2,
|w2(t,C1(j1),C2(j2))−wSHB
2(⌊t/ε⌋,j1,j2)|,
|w3(t,C2(j2))−wSHB
3(⌊t/ε⌋,j2)|}.(20)
Theorem 5.2. Let Assumption 3.3 hold. Consider the coupled the SHB dynamics (19) and mean-field ODE
(13), and the distance metric (20). Then, with probability at least 1−exp(−δ2),
DT(W,WSHB)≤K(γ,T)/parenleftigg/parenleftbig√lognmax+δ/parenrightbig
√nmin+√ε(/radicalbig
D+ logn1n2+δ)/parenrightigg
, (21)
wherenmax= max{n1,n2},nmin= min{n1,n2}, andK(γ,T)is a constant depending only on γ,T.
For three layers, Theorem 5.2 gives that the approximation error scales roughly as/radicalbig
lognmax/nmin+/radicalbig
ε(D+ logn1n2), i.e., it vanishes as long as n1,n2both grow large, with nmax =o(enmin)andε=
o(1/√D+ logn1n2). As in the two-layer case, the bound is dimension-free (in the sense that n1,n2do
not need to scale with D), andK(γ,T) =O(eeT). We remark that the scaling of the bound in Tis also a
shortcoming of the existing analysis for SGD in (Pham & Nguyen, 2021a). The detailed proof is provided
in Appendix D.
6 Consequences of the mean-field analysis: Dropout stability and connectivity
The mean-field perspective put forward in this paper leads to a precise characterization of the SHB train-
ing dynamics. In particular, Theorems 5.1-5.2 offer a provable justification to two remarkable properties
exhibited by solutions obtained via gradient-based methods, namely, dropout-stability andconnectivity . The
9Published in Transactions on Machine Learning Research (02/2023)
fact that solutions (often resulting from algorithms that use momentum) can be connected via simple paths
with low loss was empirically observed in (Garipov et al., 2018; Draxler et al., 2018), and this property was
related to dropout-stability by Kuditipudi et al. (2019). In (Shevchenko & Mondelli, 2020), it was shown
that SGD solutions enjoy dropout-stability and connectivity and, by combining this analysis with Theorems
5.1-5.2, similarly strong guarantees can be obtained for heavy ball methods. We will keep the discussion at
an informal level, as the details are similar to those in (Shevchenko & Mondelli, 2020).
Let’s start with the two-layer case. Given a non-empty set A⊂[n], we say that WisϵD-dropout stable if
|R(W)−Rdrop(W;A)|≤ϵD, (22)
whereRdrop(W;A)is obtained by replacing the two-layer network f(x;W)defined in (1) with the dropout
network
f(x;WA) =1
|A|/summationdisplay
j∈Aw2(j)σ(w1(j)Tx), (23)
whereWA= (w1(j),w2(j))j∈Aand|A|denotes the cardinality of the set A. Similarly, in the three-layer
case, given two non-empty sets A1⊂[n1],A2⊂[n2], the dropout network is given by
H2(x,j2;WA1,A2) =1
|A1|/summationdisplay
j1∈A1w2(j1,j2)σ1(w1(j1)Tx),
f(x;WA1,A2) =1
|A2|/summationdisplay
j2∈A2w3(j2)σ2(H2(x,j2;WA1,A2)),(24)
andϵD-dropout stability is defined analogously. Furthermore, we say that two solutions WandW′are
ϵC-connected if there exists a continuous path in parameter space that starts at W, ends atW′and along
which the population risk is upper bounded by max{R(W),R(W′)}+ϵC.
At this point, the quantitative convergence result to the mean-field limit provided by Theorem 5.1 and
5.2 leads to a quantitative bound on the dropout stability and connectivity of the solutions found by the
stochastic heavy ball method. We remark that proving only the consistency of the mean-field limit, as done
in (Krichene et al., 2020, Theorem 1), does not suffice to obtain such guarantees on the structure of the
SHB solution. In particular, for two-layer networks, after k≤⌊T/ε⌋steps of the iteration (16), the resulting
parameters are ϵD-dropout stable and ϵC-connected, where
ϵD≤K(γ,T)
/parenleftig/radicalbig
log|A|+δ/parenrightig
/radicalbig
|A|+√ε(/radicalbig
D+ logn+δ)
,
ϵC≤K(γ,T)/parenleftigg/parenleftbig√logn+δ/parenrightbig
√n+√ε(/radicalbig
D+ logn+δ)/parenrightigg
,(25)
with probability at least 1−exp(−δ2). HereK(γ,T)is a universal constant depending only on γ,Tas before.
Similarly, for three-layer networks, after k≤⌊T/ε⌋steps of the iteration (19), the resulting parameters are
ϵD-dropout stable and ϵC-connected, where
ϵD=K(γ,T)/parenleftigg/parenleftbig√logAmax+δ/parenrightbig
√Amin+√ε(/radicalbig
D+ logn1n2+δ)/parenrightigg
,
ϵC=K(γ,T)/parenleftigg/parenleftbig√lognmax+δ/parenrightbig
√nmin+√ε(/radicalbig
D+ logn1n2+δ)/parenrightigg
,(26)
with probability at least 1−exp(−δ2). Here,Amax= max{|A1|,|A2|},Amin= min{|A1|,|A2|},nmax=
max{n1,n2}andnmin= min{n1,n2}. We remark that the path connecting the two solutions can be
explicitly constructed as in (Kuditipudi et al., 2019; Shevchenko & Mondelli, 2020). More specifically, this
10Published in Transactions on Machine Learning Research (02/2023)
path is piece-wise linear, and the number of linear segments is a fixed constant. We also note that the
bounds for multi-layer networks in (Shevchenko & Mondelli, 2020) exhibit a linear dependence on the input
dimensionD. In contrast, our bounds (25)-(26) are dimension-free.
Finally, let us highlight that our mean-field viewpoint can shed light on the thought-provoking conjecture in
(Entezari et al., 2022), where it is empirically observed that, after a suitable permutation, the solutions of
the optimization algorithm enjoy linearconnectivity. In fact, Theorems 5.1 and 5.2 show that, by running
the corresponding SHB training algorithm multiple times, all the resulting solutions satisfy (18) and (21),
respectively. This implies that, after a permutation of the neurons, the distance between such solutions
can also be upper bounded by the RHS of (18) and (21), hence the linear connectivity is an immediate
consequence of this closeness among the solutions.
7 Global convergence of the mean-field ODE for three-layer networks
In order to show the global convergence result, we first need to make some extra assumptions.
Assumption 7.1. We make the following additional assumptions for the training of a three-layer neural
network:
(C1) (Universal approximation property of the activation) σ1exhibits a universal approximation property,
that is:{σ1(⟨w,·⟩) :w∈RD}has dense span in L2(Dx), whereDxdenotes thex-marginal of the
data distribution D.
(C2) (Full support at initialization) ρ1
0has full support.
(C3) (Mode of convergence) The mean-field ODE (13) converges to the limit/parenleftbig
w1(∞,c1),w2(∞,c1,c2),w3(∞,c2)/parenrightbig
. Formally, we have that
EC1,C2[(1 +|w3(∞,C2)|)·|w3(∞,C2)|·|w2(∞,C1,C2)|·∥w1(t,C1)−w1(∞,C1)∥2]t− →∞−−−−→ 0,
EC1,C2[(1 +|w3(∞,C2)|)·|w3(∞,C2)|·|w2(t,C1,C2)−w2(∞,C1,C2)|]t− →∞−−−−→ 0,
EC2[(1 +|w3(∞,C2)|)·|w3(t,C2)−w3(∞,C2)|]t− →∞−−−−→ 0,
ess sup
C1EC2[|Ez∆W
2(t,z,C1,C2)|]t− →∞−−−−→ 0,
Pr [w3(∞,C2)̸= 0]>0.
The universal approximation property is the key assumption to obtain a global convergence result. This
requirement is mild, since most activation functions used in practice are universal approximators. The
assumption on full support is also mild, since widely used initialized schemes (e.g., He’s or LeCun’s initial-
ization) employ a Gaussian distribution, which indeed has full support. The assumption on the mode of
convergence is purely technical, and it is an open question whether it can be relaxed.More specifically, part
(C3) is needed because of the lack of entropic and moment regularization, which makes it difficult to charac-
terize the limiting points of the noiseless mean-field dynamics. We note that the uniform convergence of the
gradient (the fourth assumption in (C3)) could be replaced by Morse-Sard type of regularity assumptions
(see (Nguyen & Pham, 2020, Section 8)). We remark that these requirements also appear in Pham & Nguyen
(2021a), with the exception of Pr [w3(∞,C2)̸= 0]>0, which is needed to handle the heavy ball dynamics.
Theorem 7.2. Let Assumptions 3.3 and 7.1 hold, and assume further that R(y,f(x;W))is convex in
f(x;W). LetW(t)be the solution of the mean-field ODE (13). Then, we have that
lim
t− →∞EzR(y,f(x;W(t))) = inf
ˆy:RD− →REzR(y,/hatwidey(x)). (27)
ThedetailedproofisdeferredtoAppendixE,andweprovidehereasketch. First, weshowadegeneracyprop-
erty for the mean-field ODE, i.e., there exist deterministic functions w∗
1(·,·) :R≥0×RD− →RD,w∗
2(·,·,·,·) :
11Published in Transactions on Machine Learning Research (02/2023)
(a) Two-layer networks
 (b) Three-layer networks
Figure 1: Dropout error plotted as a function of the network width. The log-logplot is close to be linear,
matching the behavior of our theoretical predictions of Section 6.
R≥0×RD×R×R− →R,w∗
3(·,·) :R≥0×R− →Rsuch that
w1(t,C1) =w∗
1(t,w1(0,C1)),
w2(t,C1,C2) =w∗
2(t,w1(0,C1),w2(0,C1,C2),w3(0,C2)),
w3(t,C2) =w∗
3(t,w3(0,C2)).
Next, we show that, for any finite t,w∗
1(·,·)is continuous in both arguments and w1(t,C1)has full support.
Finally, the convergence to the global minimum is obtained by combining the argument that w1(t,C1)is full
support for all finite twith the assumption on the mode of convergence.
Theorem 7.2 is rather different from the global convergence result for the heavy ball method presented in
(Krichene et al., 2020). In fact, Krichene et al. (2020) consider a noisydynamics, and show the convergence
of the mean-field ODE to the global minimum of a certain free energy, which represents an entropic regular-
ization of the loss function. In this setup, the convergence is guaranteed by the noise term in the dynamics
and by the regularization term in the free energy functional. In contrast, we consider a noiseless dynamics
and do not prove its convergence. Instead, we show that, when the mean-field ODE converges, it must do so
towards the global minimum of the un-regularized loss function. At the technical level, our proof strategy
is an adaptation to the heavy ball case of the argument for SGD in (Pham & Nguyen, 2021a), which also
crucially relies on the universal approximation property of the activation function. A similar idea was first
proposed in (Lu et al., 2020), and it also appears e.g. in (Fang et al., 2021). However, our contribution is
the first to tackle the case of optimization with momentum.
8 Numerical results
Experimental setup. We train a two-layer and a three-layer fully connected neural network in the mean-
field regime on the MNIST dataset. The training algorithm is stochastic gradient descent with momentum,
and we evaluate the dropout stability of the learnt models. For the two-layer network, we take the width
n= 100×2k, wherek∈{1,..., 7}; for the three-layer network, we take n1=n2=nand use the same grid
forn. We use the PyTorch default initialization, pick the learning rate εto be 0.05 and the momentum to
be 0.9 (which implies that γ= 2). We rescale the learning rate, so that the scaling of the gradient does not
depend onn, as required by our theory. The batch size is 100 and we train for 25 epochs, which means that
the neural network is trained for 15000steps (each epoch contain 600steps and there are 25epochs). For
each model, we perform 10i.i.d. experiments and report their average. We compute the population loss for
both the original network and the dropout network, obtained by randomly dropping out half of the neurons.
For each experiment, we take 10 random dropout networks and report the average population loss.
12Published in Transactions on Machine Learning Research (02/2023)
Experimental results. In Figure 1, we plot the logof the dropout error defined in (22) as a function
of the number of neurons in each layer. Different curves correspond to different numbers of trained epochs.
Two remarks are in order. First, the dependence of the dropout error on the time of the dynamics is rather
mild (and, hence, our bounds on the constant K(γ,T)appear to be pessimistic). Second, the dropout error
scales as an inverse polynomial in the width, in agreement with (25)-(26).
9 Discussion and future direction
In this paper, we consider neural networks with two and three layers, and analyze the dynamics of stochastic
gradient descent with momentum – also known as the stochastic heavy ball method (SHB) – from a mean-
field viewpoint. After showing the existence and uniqueness of the mean-field limit, we provide a quantitative
convergence result of the discrete SHB dynamics of a finite-width neural network to the corresponding limit
differential equation, thus solving a problem raised by Krichene et al. (2020). Then, we exploit the power of
our mean-field perspective by (i)proving that the solutions found by SHB enjoy desirable properties, such
as dropout stability and connectivity, and (ii)showing a global convergence result for three-layer networks.
Atthetechnicallevel, ourproofstrategiesbuildontheworkbyMeietal.(2019)andPham&Nguyen(2021a)
for neural networks with two and three layers, respectively. However, these papers focus on vanilla SGD,
and dealing with SHB requires a number of delicate technical results. In particular, (i)we establish several
boundedness and smoothness properties of the mean-field dynamics, (ii)we track various new quantities
and exploit a second-order Gronwall lemma (Pachpatte’s inequality) to bound them, (iii)we perform a
discretization of the particle dynamics which is different from the SGD case, and (iv)we prove a key
measurability property for the second-order dynamics, which characterizes the dependency between layers
during training. Our strategy is tailored to the stochastic heavy ball method, but similar ideas could
potentially be applied also to Nesterov’s accelerated method, due to the similarity in the continuous limit.
Thestudyofotherpopulartrainingalgorithms(e.g., Adam)mostlikelyrequiresanentirelydifferenttechnical
analysis, whose investigation is left as an interesting open problem.
Let us conclude by discussing some extensions and future directions.
Beyond three layers and fully connected networks. While it should be possible to extend our analysis
of SGD with momentum to feed-forward networks with more than three layers, it remains unclear how to
obtain global convergence guarantees in a more general setup. In fact, this is an open problem even for the
caseofoptimizationwithoutmomentum, see(Nguyen&Pham,2020, Section5). Wealsonotethat, although
we only consider fully connected networks, our analysis could be generalized to other architectures, such as
convolutional neural networks (CNNs) or ResNets, by slightly modifying the assumption. In particular, for
CNNs, if we replace inner products by convolutions and let norn1,n2be the number of filters in each layer,
our analysis can be directly applied. For ResNets, the presence of the skip connection modifies the backward
path, and the mean-field limit would need to reflect this modification.
“Central limit theorem”-type of results. Theorems 5.1-5.2 belong to a “law of large numbers”-type
of results, in the sense that they show how close is the SHB dynamics to the mean-field limit. A parallel
line of work has studied the distribution of the perturbation of the finite-width neural network around its
mean-field limit, see (Chen et al., 2020; Sirignano & Spiliopoulos, 2020b) for two-layer networks, and (Pham
& Nguyen, 2021b) for multi-layer ones. However, all the existing results concern the vanilla SGD algorithm,
and understanding how momentum can affect such a distribution is an interesting future direction.
Convergence of noisy dynamics. In this work, we consider a noiseless dynamics, and the global con-
vergence result for three-layer networks follows from the universality of the activation function. In contrast,
in the noisy case, the mean-field limit for a two-layer network is an under-damped mean-field Langevin
dynamics, whose convergence follows from the convexity of a related free-energy functional (Krichene et al.,
2020). In a multi-layer setup, the free energy is not convex, which makes it challenging to obtain global
convergence.
Comparison between SGD and heavy ball methods. Motivated by the observation that, in practice,
adding momentum helps to generalize better (Sutskever et al., 2013), an exciting avenue for future research
is to exploit the structure of the mean-field limit to draw insights concerning the solution found by heavy
13Published in Transactions on Machine Learning Research (02/2023)
ball methods. While the recent work by Jelassi & Li (2022) theoretically proved the improvements in
generalization error provided by momentum under certain settings, we are not aware about whether such
results hold in the mean-field training regime. A key difficulty here is that, for the noiseless dynamics, global
convergence is not guaranteed in general, let alone an explicit characterization of the stationary solution. To
circumvent this issue, one option may be to consider a suitably regularized noisy dynamics, which admits
a stationary solution in a Gibbs form, in the limit of vanishingly small noise and regularization. Finally,
heavy ball methods are known to enjoy faster rates of convergence in the convex setting. Thus, establishing
a convergence rate for the mean-field dynamics is an exciting avenue for future research.
Acknowledgements
D. Wu and M. Mondelli are partially supported by the 2019 Lopez-Loreta Prize. V. Kungurtsev was sup-
ported by the OP VVV project CZ.02.1.01/0.0/0.0/16_019/0000765 "Research Center for Informatics".
References
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-
parameterization. In International Conference on Machine Learning , pp. 242–252, 2019.
Luigi Ambrosio, Elia Brué, and Daniele Semola. Lectures on optimal transport . Springer, 2021.
William F Ames and BG Pachpatte. Inequalities for differential and integral equations , volume 197. Elsevier,
1997.
Dyego Araújo, Roberto I Oliveira, and Daniel Yukimura. A mean-field limit for certain deep neural networks.
arXiv preprint arXiv:1906.00193 , 2019.
P. Auer, M. Herbster, and M. Warmuth. Exponentially many local minima for single neurons. In Neural
Information Processing Systems (NIPS) , 1996.
Simone Bombari, Mohammad Hossein Amani, and Marco Mondelli. Memorization and optimization in deep
neural networks with minimum over-parameterization. In Advances in Neural Information Processing
Systems, 2022.
Zhengdao Chen, Grant Rotskoff, Joan Bruna, and Eric Vanden-Eijnden. A dynamical central limit theorem
for shallow neural networks. In Advances in Neural Information Processing Systems , volume 33, pp.
22217–22230, 2020.
Zhengdao Chen, Eric Vanden-Eijnden, and Joan Bruna. A functional-space mean-field theory of partially-
trained three-layer neural networks. arXiv preprint arXiv:2210.16286 , 2022.
Lénaïc Chizat. Mean-field langevin dynamics : Exponential convergence and annealing. Transactions on
Machine Learning Research , 2022.
Lénaïc Chizat and Francis Bach. On the global convergence of gradient descent for over-parameterized
models using optimal transport. In Advances in Neural Information Processing Systems , volume 31, 2018.
Lénaïc Chizat and Francis Bach. Implicit bias of gradient descent for wide two-layer neural networks trained
with the logistic loss. In Conference on Learning Theory , pp. 1305–1338, 2020.
Lénaïc Chizat, Edouard Oyallon, and Francis Bach. On lazy training in differentiable programming. In
Advances in Neural Information Processing Systems , volume 32, 2019.
Felix Draxler, Kambis Veschgini, Manfred Salmhofer, and Fred Hamprecht. Essentially no barriers in neural
network energy landscape. In International Conference on Machine Learning , pp. 1308–1317, 2018.
Simon S. Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes over-
parameterized neural networks. In International Conference on Learning Representations , 2019.
14Published in Transactions on Machine Learning Research (02/2023)
Rahim Entezari, Hanie Sedghi, Olga Saukh, and Behnam Neyshabur. The role of permutation invariance
in linear mode connectivity of neural networks. In International Conference on Learning Representations ,
2022.
Cong Fang, Jason Lee, Pengkun Yang, and Tong Zhang. Modeling from features: a mean-field framework
for over-parameterized deep neural networks. In Conference on learning theory , pp. 1887–1936. PMLR,
2021.
Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P. Vetrov, and Andrew G. Wilson. Loss
surfaces, mode connectivity, and fast ensembling of DNNs. In Advances in Neural Information Processing
Systems, pp. 8789–8798, 2018.
Ian J. Goodfellow and Oriol Vinyals. Qualitatively characterizing neural network optimization problems. In
International Conference on Learning Representations , 2015.
Karl Hajjar, Lénaïc Chizat, and Christophe Giraud. Training integrable parameterizations of deep neural
networks in the infinite-width limit. arXiv preprint arXiv:2110.15596 , 2021.
Kaitong Hu, Zhenjie Ren, David Siska, and Lukasz Szpruch. Mean-field langevin dynamics and energy
landscape of neural networks. arXiv preprint arXiv:1905.07769 , 2019.
Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and generalization
in neural networks. In Advances in Neural Information Processing Systems , volume 31, 2018.
Adel Javanmard, Marco Mondelli, and Andrea Montanari. Analysis of a two-layer neural network via
displacement convexity. The Annals of Statistics , 48(6):3619–3642, 2020.
Samy Jelassi and Yuanzhi Li. Towards understanding how momentum improves generalization in deep
learning. In International Conference on Machine Learning , pp. 9965–10040, 2022.
Anna Kazeykina, Zhenjie Ren, Xiaolu Tan, and Junjian Yang. Ergodicity of the underdamped mean-field
langevin dynamics. arXiv preprint arXiv:2007.14660 , 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Confer-
ence on Learning Representations , 2015.
Nikola B Kovachki and Andrew M Stuart. Continuous time analysis of momentum methods. Journal of
Machine Learning Research , 22(17):1–40, 2021.
Walid Krichene, Kenneth F Caluya, and Abhishek Halder. Global convergence of second-order dynamics in
two-layer neural networks. arXiv preprint arXiv:2007.06852 , 2020.
Rohith Kuditipudi, Xiang Wang, Holden Lee, Yi Zhang, Zhiyuan Li, Wei Hu, Rong Ge, and Sanjeev Arora.
Explaining landscape connectivity of low-cost solutions for multilayer nets. In Advances in neural infor-
mation processing systems , volume 32, 2019.
Daniel Kunin, Javier Sagastuy-Brena, Surya Ganguli, Daniel LK Yamins, and Hidenori Tanaka. Neural me-
chanics: Symmetry and broken conservation laws in deep learning dynamics. In International Conference
on Learning Representations , 2021.
Yiping Lu, Chao Ma, Yulong Lu, Jianfeng Lu, and Lexing Ying. A mean field analysis of deep resnet and
beyond: Towards provably optimization via overparameterization from depth. In International Conference
on Machine Learning , pp. 6426–6436, 2020.
Yi-An Ma, Niladri S Chatterji, Xiang Cheng, Nicolas Flammarion, Peter L Bartlett, and Michael I Jordan.
Is there an analog of Nesterov acceleration for gradient-based MCMC? Bernoulli , 27(3):1942–1992, 2021.
Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape of two-layer
neural networks. Proceedings of the National Academy of Sciences , 115(33):E7665–E7671, 2018.
15Published in Transactions on Machine Learning Research (02/2023)
Song Mei, Theodor Misiakiewicz, and Andrea Montanari. Mean-field theory of two-layers neural networks:
dimension-free bounds and kernel limit. In Conference on Learning Theory , pp. 2388–2464, 2019.
Andrea Montanari and Yiqiao Zhong. The interpolation phase transition in neural networks: Memorization
and generalization under lazy training. arXiv preprint arXiv:2007.12826 , 2020.
Phan-Minh Nguyen and Huy Tuan Pham. A rigorous framework for the mean field limit of multilayer neural
networks. arXiv preprint arXiv:2001.11443 , 2020.
Atsushi Nitanda, Denny Wu, and Taiji Suzuki. Convex analysis of the mean field langevin dynamics. arXiv
preprint arXiv:2201.10469 , 2022.
Huy Tuan Pham and Phan-Minh Nguyen. Global convergence of three-layer neural networks in the mean
field regime. In International Conference on Learning Representations , 2021a.
Huy Tuan Pham and Phan-Minh Nguyen. Limiting fluctuation and trajectorial stability of multilayer neural
networks with mean field training. In Advances in Neural Information Processing Systems , volume 34, pp.
4843–4855, 2021b.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. Ussr computational
mathematics and mathematical physics , 4(5):1–17, 1964.
Grant M. Rotskoff and Eric Vanden-Eijnden. Neural networks as interacting particle systems: Asymptotic
convexity of the loss landscape and universal scaling of the approximation error. In Advances in Neural
Information Processing Systems , volume 32, 2018.
Itay Safran and Ohad Shamir. Spurious local minima are common in two-layer ReLU neural networks. In
International Conference on Machine Learning , 2018.
Katharina Schuh. Global contractivity for langevin dynamics with distribution-dependent forces and uniform
in time propagation of chaos. arXiv preprint arXiv:2206.03082 , 2022.
Aleksandr Shevchenko, Vyacheslav Kungurtsev, and Marco Mondelli. Mean-field analysis of piecewise linear
solutions for wide relu networks. Journal of Machine Learning Research , 23(130), 2022.
Alexander Shevchenko and Marco Mondelli. Landscape connectivity and dropout stability of SGD solutions
for over-parameterized neural networks. In International Conference on Machine Learning , pp. 8773–8784,
2020.
Bin Shi, Simon S Du, Michael I Jordan, and Weijie J Su. Understanding the acceleration phenomenon via
high-resolution differential equations. Mathematical Programming , pp. 1–70, 2021.
Justin Sirignano and Konstantinos Spiliopoulos. Mean field analysis of neural networks: A law of large
numbers. SIAM Journal on Applied Mathematics , 80(2):725–752, 2020a.
Justin Sirignano and Konstantinos Spiliopoulos. Mean field analysis of neural networks: A central limit
theorem. Stochastic Processes and their Applications , 130(3):1820–1852, 2020b.
Weijie Su, Stephen Boyd, and Emmanuel Candes. A differential equation for modeling Nesterov’s accelerated
gradient method: theory and insights. In Advances in neural information processing systems , volume 27,
2014.
Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and
momentum in deep learning. In International Conference on Machine Learning , pp. 1139–1147, 2013.
Alain-Sol Sznitman. Topics in propagation of chaos. In Paul-Louis Hennequin (ed.), Ecole d’Eté de Proba-
bilités de Saint-Flour XIX , pp. 165–251. Springer Berlin Heidelberg, 1991.
Jun-Kun Wang, Chi-Heng Lin, and Jacob D. Abernethy. A modular analysis of provable acceleration via
Polyak’s momentum: Training a wide ReLU network and a deep linear network. In International Confer-
ence on Machine Learning , pp. 10816–10827, 2021.
16Published in Transactions on Machine Learning Research (02/2023)
Andre Wibisono, Ashia C Wilson, and Michael I Jordan. A variational perspective on accelerated methods
in optimization. Proceedings of the National Academy of Sciences , 113(47):E7351–E7358, 2016.
Francis Williams, Matthew Trager, Claudio Silva, Daniele Panozzo, Denis Zorin, and Joan Bruna. Gradient
dynamics of shallow univariate ReLU networks. In Advances in Neural Information Processing Systems ,
volume 32, 2019.
Xiaoxia Wu, Simon S Du, and Rachel Ward. Global convergence of adaptive gradient methods for an
over-parameterized neural network. arXiv preprint arXiv:1902.07111 , 2019.
Greg Yang and Edward J Hu. Tensor programs IV: Feature learning in infinite-width neural networks. In
International Conference on Machine Learning , pp. 11727–11737, 2021.
Chulhee Yun, Suvrit Sra, and Ali Jadbabaie. Small nonlinearities in activation functions create bad local
minima in neural networks. In International Conference on Learning Representations (ICLR) , 2019.
Organization of the appendix. In Appendix A, we provide some a-priori estimates that will be useful
in the following arguments. In Appendix B, we prove Theorem 4.1, namely, the existence and uniqueness
of the mean-field limit for two-layer and three-layer networks, respectively. In Appendix C and D, we prove
Theorems 5.1 and 5.2, which show the convergence of the SHB dynamics to the corresponding mean-field
limit for two-layer and three-layer networks. Finally in Appendix E, we prove Theorem 7.2, which is the
global convergence result in the three-layer setup.
A A-priori estimates
A.1 Two-layer networks
Lemma A.1. Assume that (A1) - (A3) hold, and let f(x;ρ),Ψ(θ;ρ),∇θΨ(θ;ρ)be defined in (11). Then,
for any fixed T, there exist universal constants K,K 2(γ,T), where the latter depends only on γ,T, such that
the following results hold.
1. (Boundedness) We have that, for any θ,ρ,
f(x;ρ)≤KEρ|w2|,
|Ψ(θ;ρ)|≤K|w2|, (28)
∥∇θΨ(θ;ρ)∥2≤K(1 +|w2|).
2. (Boundedness for mean-field ODE) We have that, for any t≤T,w2(t)as governed by (12) satisfies
|w2(t)|≤K2(γ,T). (29)
3. (Lipschitz continuity):
|Ψ(θ;ρ)−Ψ(θ′;ρ′)|≤K(1 +|w2|) (|w2−w′
2|+∥w1−w′
1∥2+W2(ρ,ρ′)),(30)
∥∇θΨ(θ;ρ)−∇θΨ(θ′;ρ′)∥2≤K(1 +|w2|) (|w2−w′
2|+∥w1−w′
1∥2+W2(ρ,ρ′)).(31)
Proof. 1. By the definition and assumption (A1), we have that
|f(x;ρ)|=|Eρw2σ(wT
1x)|≤KEρ|w2|,
|Ψ(θ;ρ)|≤|Ez/bracketleftbig
∂2R(y,f(x;ρ))σ(wT
1x)/bracketrightbig
|·|w2|≤K|w2|,
|∇w2Ψ(θ;ρ)|=|Ez/bracketleftbig
∂2R(y,f(x;ρ))σ(wT
1x)/bracketrightbig
|≤K,
∥∇w1Ψ(θ;ρ)∥2=∥Ez/bracketleftbig
∂2R(y,f(x;ρ))w2σ′(wT
1x)x/bracketrightbig
∥2≤K|w2|.
17Published in Transactions on Machine Learning Research (02/2023)
2. By writing down the integral form of the ODE, we have
|w2(t)|≤|w2(0)|+γ/integraldisplayT
0(|w2(s)|+|w2(0)|)ds+/integraldisplayT
0/integraldisplays
0|∇w2Ψ(θ(u);ρ(u))|duds
≤(K+KT+KT2) +γ/integraldisplayT
0|w2(s)|ds
≤(K+KT+KT2)eγT.
By settingK2(γ,T) := (K+KT+KT2)eγT, the proof of (29) is complete.
3. For the Lipschitz continuity argument, we have
Ψ(θ;ρ) =Ez/bracketleftbig
∂2R(y,f(x;ρ))w2σ(wT
1x)/bracketrightbig
,
∇θΨ(θ;ρ) =/parenleftbigg
Ez/bracketleftbig
∂2R(y,f(x;ρ))w2σ′(wT
1x)x/bracketrightbig
Ez/bracketleftbig
∂2R(y,f(x;ρ))σ(wT
1x)/bracketrightbig/parenrightbigg
.
Thus,
|Ψ(θ;ρ)−Ψ(θ′;ρ′)|≤K|w2|∥w1−w′
1∥+K|w2−w′
2|+K|w2||Eθ∼ρσ(x;θ)−Eθ∼ρ′σ(x;θ)|.(32)
We define the Bounded Lipschitz (BL) divergence as follows:
dBL(ρ,ρ′) = sup{|Eθ∼ρf(θ)−Eθ∼ρ′f(θ)|:|f|≤1,∥f∥Lip≤1}.
We have the following relationship between the BL-divergence and the Wasserstein distance (see for
example (Chizat & Bach, 2018, Appendix A) for more details):
dBL(ρ,ρ′)≤W 2(ρ,ρ′).
Hence,
|Eρσ(x;θ)−Eρ′σ(x;θ)|≤KdBL(ρ,ρ′)≤KW2(ρ,ρ′),
which implies that the RHS of (32) is upper bounded by
K|w2|(∥w1−w′
1∥2+W2(ρ,ρ′)) +K|w2−w′
2|≤K(1 +|w2|) (|w2−w′
2|+∥w1−w′
1∥2+W2(ρ,ρ′))
This concludes the proof of (30). The Lipschitz continuity of ∇θΨ(θ;ρ)follows from the same
argument.
A.2 Three-layer networks
Lemma A.2. Assume that (B1)-(B2) hold, and let H2,f,∆W
1,∆W
2,∆W
3,∆H
1,∆H
2be defined in (14) and
(15). Then, for any fixed T, and given a neuronal embedding
{(Ω1×Ω2,F1×F 2,P1×P2),w1(0,·),w2(0,·,·),w3(0,·)},
there exists a universal constant Kand universal constants K3,2(γ,T),K3,3(γ,T)only depending on γ,T
such that the following results hold.
1. (Boundedness) We have that, for any W,z, for anyt∈[0,T]and for any c1∈Ω1,c2∈Ω2,
•|f(x;W(t))|≤Kess supC2|w3(t,C2)|
•H2(x,c2;W(t))|≤Kess supC1,C2|w2(t,C1,C2)|
•|∆W
3(z,c2;W(t))|≤K
18Published in Transactions on Machine Learning Research (02/2023)
•|∆H
2(z,c2;W(t))|≤Kess supC2|w3(t,C2)|
•|∆W
2(z,c1,c2;W(t))|≤K/parenleftbig
ess supC1,C2|w2(t,C1,C2)|/parenrightbig
ess supC2|w3(t,C2)|
•|∆H
1(x,c1;W(t))|≤Kess sup
C2|w3(t,C2)|ess sup
C1,C2|w2(t,C1,C2)|
•∥∆W
1(x,c1;W(t))∥2≤Kess supC2|w3(t,C2)|ess supC1,C2|w2(t,C1,C2)|
2. (Boundedness for mean-field ODE) We have that, for any t≤T,
ess sup
C2|w3(t,C2)|≤K3,3(γ,T),ess sup
C1,C2|w2(t,C1,C2)|≤K3,2(γ,T). (33)
3. (Lipschitz continuity) We have that, for any t≤T,
•|H1(x,c1;W(t))−H1(x,c1;˜W(t))|≤K∥w1(t,c1)−˜w1(t,c1)∥2
•|H2(x,c2;W(t))−H2(x,c2;˜W(t))|
≤Kess sup
C1(|w2(t,C1,c2)|∥w1(t,C1)−˜w1(t,C1)∥2+|w2(t,C1,c2)−˜w2(t,C1,c2)|)
•|f(x;W(t))−f(x;˜W(t))|
≤Kess sup
C1,C2(|w3(t,C2)|·|w2(t,C1,C2)|·∥w1(t,c1)−˜w1(t,c1)∥2
+|w3(t,c2)|·|w2(t,c1,c2)−˜w2(t,c1,c2)|+|w3(t,c2)−˜w3(t,c2)|)
•|∆W
3(z,c2;W(t))−∆W
3(z,c2;˜W(t))|
≤K/parenleftbig
|H2(x,c2;W(t))−H2(x,c2;˜W(t))|+|f(x;W(t))−f(x;˜W(t))|/parenrightbig
•|∆H
2(z,c2;W(t))−∆H
2(z,c2;˜W(t))|
≤K|w3(t,c2)|·|H2(x,c2;W(t))−H2(x,c2;˜W(t))|+K|w3(t,c2)−˜w3(t,c2)|
+K|w3(t,c2)|·|f(x;W(t))−f(x;˜W(t))|
•|∆W
2(z,c1,c2;W(t))−∆W
2(z,c1,c2;˜W(t))|
≤K|∆H
2(x,c2;W(t))−∆H
2(z,c2;˜W(t))|
+K|∆H
2(z,c2;W(t))|·∥w1(t,c1)−˜w1(t,c1)∥2
•∥∆W
1(z,c1;W(t))−∆W
1(z,c1;˜W(t))∥2
≤K|EC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
|·∥w1(t,c1)−˜w1(t,c1)∥2
+K|EC2/bracketleftbig
∆H
2(z,C2;˜W(t)) ˜w2(t,c1,C2)−∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
|.
Proof. 1. By the definition and assumption (B1), we have
•|f(x;W(t))|=|EC2w3(t,C2)σ2(H2(t,x,C2))|
≤K|EC2w3(t,C2)|≤ess sup
C2|w3(t,C2)|
•|H2(x,c2;W(t))|=|EC1w2(t,C1,c2)σ1(H1(t,x,C1))|
≤ess sup
C1,C2|w2(t,C1,C2)σ1(H1(x,C1;W(t)))|
≤Kess sup
C1,C2|w2(t,C1,C2)|
•|∆W
3(x,c2;W(t))|=|∂2R(y;f(x;W(t)))σ2(H2(x,c2;W(t)))|≤K
•|∆H
2(x,c2;W(t))|=|∂2R(y;f(x;W(t)))w3(t,c2)σ′
2(H2(x,c2;W(t)))|
≤ess sup
C2|w3(t,C2)σ′
2(H2(x,C2;W(t)))|≤Kess sup
C2|w3(t,C2)|
•|∆W
2(x,c1,c2;W(t))|=|∆H
2(x,c2;W(t))σ2(H1(x,c1;W(t)))|
≤Kess sup
C2|∆H
2(x,C2;W(t))|≤Kess sup
C2|w3(t,C2)|
19Published in Transactions on Machine Learning Research (02/2023)
•|∆H
1(x,c1;W(t))|=|EC2∆H
2(x,C2;W(t))w2(t,c1,C2)σ′
1(H1(x,c1;W(t)))|
≤ess sup
C2|∆H
2(x,C2;W(t))|ess sup
C1,C2|w2(t,C1,C2)|ess sup
C1|σ′
1(H1(x,C1;W(t)))|
≤Kess sup
C2|w3(t,C2)|ess sup
C1,C2|w2(t,C1,C2)|
•∥∆W
1(x,c1;W(t))∥2=∥∆H
1(x,c1;W(t))x∥2≤ess sup
C1|∆H
1(x,C1;W(t))|∥x∥2
≤Kess sup
C2|w3(t,C2)|ess sup
C1,C2|w2(t,C1,C2)|
2. We have that, for any t≤T,
|w3(t,c2)|≤|w3(0,c2)|+γ/integraldisplayt
0(|w3(0,c2)|+|w3(s,c2)|)ds
+/integraldisplayt
0/integraldisplays
0|Ex∆W
3(u,x,c2)|duds
≤K+KγT +KT2+γ/integraldisplayt
0|w3(s,c2)|ds
≤(K+KγT +KT2)eγT:=K3,3(γ,T),
which readily gives the first claim. Next, we write
|w2(t,c1,c2)|≤|w2(0,c1,c2)|+γ/integraldisplayt
0(|w2(0,c1,c2)|+|w2(s,c1,c2)|)ds
+/integraldisplayt
0/integraldisplays
0|Ex∆W
2(x,c1,c2;W(u))|duds
≤K+KγT +γ/integraldisplayt
0|w2(s,c1,c2)|ds+K3,3(γ,T)T2,
which by Gronwall’s lemma, implies that
ess sup
C1,C2|w2(t,C1,C2)|≤(K+KγT +K3,3(γ,T)T2)eKT:=K3,2(γ,T).
3. For the Lipschitz continuity argument, we have
•|H1(x,c1;W(t))−H1(x,c1;˜W(t))|=|xT(w1(t,c1)−˜w1(t,c1))|
≤K∥w1(t,c1)−˜w1(t,c1)∥2
•|H2(x,c2;W(t))−H2(x,c2;˜W(t))|
=|EC1w2(t,C1,c2)σ1(w1(t,C1)Tx)−EC1˜w2(t,C1,c2)σ1(˜w1(t,C1)Tx)|
≤Kess sup
C1(|w2(t,C1,c2)|∥w1(t,C1)−˜w1(t,C1)∥2+|w2(t,C1,c2)−˜w2(t,C1,c2)|)
•|f(x;W(t))−f(x;˜W(t))|
≤|EC2w3(t,C2)σ2(H2(x,C2;W(t)))−EC2˜w3(t,C2)σ2(H2(x,C2;˜W(t)))|
≤Kess sup
C1,C2(|w3(t,C2)|·|w2(t,C1,C2)|·∥w1(t,C1)−˜w1(t,C1)∥2
+|w3(t,C2)|·|w2(t,C1,C2)−˜w2(t,C1,C2)|+|w3(t,C2)−˜w3(t,C2)|)
•|∆W
3(z,c2;W(t))−∆W
3(z,c2;˜W(t))|
=|∂2R(y,f(x,W(t)))
·σ2(H2(x,c2;W(t)))−∂2R(y,f(x,˜W(t)))σ2(H2(x,c2;˜W(t)))|
≤K/parenleftbig
|H2(x,c2;W(t))−H2(x,c2;˜W(t))|+|f(x;W(t))−f(x;˜W(t))|/parenrightbig
20Published in Transactions on Machine Learning Research (02/2023)
•|∆H
2(z,c2;W(t))−∆H
2(z,c2;˜W(t))|
=|∂2R(y,f(x,W(t)))w3(t,c2)σ′
2(H2(x,c2;W(t)))
−∂2R(y,f(x,˜W(t))) ˜w3(t,c2)σ′
2(H2(x,c2;˜W(t)))|
≤K|w3(t,c2)|·|H2(x,c2;W(t))−H2(x,c2;˜W(t))|+K|w3(t,c2)−˜w3(t,c2)|
+K|w3(t,c2)|·|f(x;W(t))−f(x;˜W(t))|
•|∆W
2(z,c1,c2;W(t))−∆W
2(z,c1,c2;˜W(t))|
=|∆H
2(z,c2;W(t))σ1(w1(t,c1)Tx)−∆H
2(z,c2;˜W(t))σ1(˜w1(t,c1)Tx)|
≤K|∆H
2(x,c2;W(t))−∆H
2(z,c2;˜W(t))|
+K|∆H
2(z,c2;W(t))|·∥w1(t,c1)−˜w1(t,c1)∥2
•∥∆W
1(z,c1;W(t))−∆W
1(z,c1;˜W(t))∥2
≤K|EC2∆H
2(z,C2;W(t))w2(t,c1,C2)σ′
1(w1(t,c1)Tx)
−EC2∆H
2(z,C2;˜W(t))w2(t,c1,C2)σ′
1(˜w1(t,c1)Tx)|
≤K|EC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
|·∥w1(t,c1)−˜w1(t,c1)∥2
+K|EC2/bracketleftbig
∆H
2(z,C2;˜W(t)) ˜w2(t,c1,C2)−∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
|.
B Existence and uniqueness of the mean-field limit
B.1 Two-layer networks
In this section, we prove the existence and uniqueness of the mean-field limit for two-layer networks. We
recall the mean-field ODE again here:
dθ(t) =r(t)dt,
dr(t) =/parenleftbig
−γr(t)−∇θΨ(θ(t);ρθ(t))/parenrightbig
dt. (34)
The proof follows from constructing a Picard type of iteration, similarly to (Sirignano & Spiliopoulos, 2020a,
Section 4), (Javanmard et al., 2020, Theorem C.4). Below is an adaptation of the strategy in (Sznitman,
1991, Theorem 1.1). We first write the integral form of the mean-field ODE:
θ(t) =θ(0)−γ/integraldisplayt
0(θ(s)−θ(0))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θ(u);ρθ(u))duds, (35)
r(t) =r(0)−γ(θ(t)−θ(0))−/integraldisplayt
0Ψ(θ(s);ρθ(s))ds, (36)
whereρ(t)is the law of (θ(t),r(t)), and we use ρθ(t),ρr(t)to denote the θandrmarginals, respectively.
We define the space P2(RD×RD)to be the space of probability measures on RD×RDequipped with
Wasserstein metric W2, and we have ρ(t)∈P 2(RD×RD). We define the space C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
to
be the space of continuous maps ρ(·;T) : [0,T]→P 2(RD×RD). We omitTwhen there’s no confusion. The
space is equipped with the following metric: dT(ρ1,ρ2) = supt∈[0,T]W2(ρ1(t),ρ2(t)).
Note that the space/parenleftbig
P2(RD×RD),W2/parenrightbig
is a complete space (Ambrosio et al., 2021, Theorem 8.7). Thus
for any fixed 0<T <∞, the space/parenleftbig
C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
×dT/parenrightbig
is also complete.
Next, we define the operator HT(·,θ(0)) :C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
→C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
as follows:
HT(ρ1;θ(0)) :=/tildewideρ,/tildewideρ(t) :={Law(/tildewideθ(t),/tildewider(t))}t≤T
/tildewideθ(t) =θ(0)−γ/integraldisplayt
0(/tildewideθ(s)−θ(0))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(/tildewideθ(u);ρθ
1(u))duds, (37)
21Published in Transactions on Machine Learning Research (02/2023)
whereθ(0)denotes the parameters of the mean-field ODE (35) at initialization, which means that the
stochastic process we defined in (37) is coupled with the mean-field ODE.
Note that the ρθ
1(t)in (37) is no longer the law of /tildewideθ(t), but the input distribution. We use HT(ρ(t))to
denoteHT(ρ;θ(0))(t), that is the distribution of the solution (37) at time t. We omitθ(0)when there is no
confusion. The definition of HTcan be interpreted as follows: it maps ρ∈C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
as input
to output the law of (θ(t),r(t))which evolves according to the stochastic process induced by the probability
measureρ(t).
It is easy to see that the fixed point of HTis the solution of the non-linear dynamics (35). Thus, our goal
is to show that there exist a T0such thatHT0has unique fixed point, or equivalently that HT0is a strict
contraction.
Proposition B.1. Under Assumptions (A1)-(A2), there exists a T0only depending on K,γand a
C(T0)∈(0,1)such that, for all ρ1,ρ2∈C/parenleftbig
[0,T0],P2(RD×RD)/parenrightbig
with the same initialization (θ1(0),r1(0)) =
(θ2(0),r2(0)), we have:
dT0(HT0(ρ1),HT0(ρ2))≤C(T0)dT0(ρ1,ρ2).
Proof.We first fix any 0< T <∞, and the space C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
. Given ρ1,ρ2∈
C/parenleftbig
[0,T],P2(RD×RD)/parenrightbig
, we define two dynamics as follows:
θ1(t) =θ1(0)−γ/integraldisplayt
0(θ1(s)−θ1(0))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θ1(u);ρθ
1(u))duds,
θ2(t) =θ2(0)−γ/integraldisplayt
0(θ2(s)−θ2(0))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θ2(u);ρθ
2(u))duds.
whereθ1(t) =/parenleftig
w(1)
1,w(1)
2/parenrightig
andθ2(t) =/parenleftig
w(2)
1,w(2)
2/parenrightig
. We want to upper bound the difference between these
two dynamics, which will give us an upper bound on
dT(HT(ρ1),HT(ρ2)).
For allt∈[0,T], we have
∥θ1(t)−θ2(t)∥2≤γ/integraldisplayt
0∥θ1(s)−θ2(s)∥2ds
+/integraldisplayt
0/integraldisplays
0∥∇θΨ(θ1(u);ρθ
1(u))−∇θΨ(θ2(u);ρθ
2(u))∥2duds.
Now, by Lemma A.1, we have that
∥∇θΨ(θ1(t);ρθ
1(t))−∇θΨ(θ2(t);ρθ
2(t))∥2
≤K(1 +|w(1)
2(t)|)/parenleftig
|w(1)
2(t)−w(2)
2(t)|+∥w(1)
1(t)−w(2)
1(t)∥2+W2(ρθ
1(t),ρθ
2(t))/parenrightig
≤2K(1 +K2(γ,T))/parenleftbigg
∥θ1(t)−θ2(t)∥2+ max
s∈[0,T]W2(ρθ
1(s),ρθ
2(s))/parenrightbigg
,
whereθi(t) = (w(i)
1(t),w(i)
2(t)), fori∈1,2. Thus, we have that:
∥θ1(t)−θ2(t)∥2≤2K(1 +K2(γ,T))T2max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)) +γ/integraldisplayt
0∥θ1(s)−θ2(s)∥2ds
+ 2K(1 +K2(γ,T))/integraldisplayt
0/integraldisplays
0∥θ1(u)−θ2(u)∥2duds.
22Published in Transactions on Machine Learning Research (02/2023)
Similarly for∥r1(t)−r2(t)∥2, we have that:
∥r1(t)−r2(t)∥2≤γ/integraldisplayt
0∥r1(s)−r2(s)∥2ds+/integraldisplayt
0∥Ψ(θ1(s);ρθ
1(s))−Ψ(θ2(s);ρθ
2(s))∥2ds
≤2K(1 +K2(γ,T))Tmax
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)) +γ/integraldisplayt
0∥r1(s)−r2(s)∥2ds
+ 2K(1 +K2(γ,T))/integraldisplayt
0∥θ1(s)−θ2(s)∥2ds.
Putting these two results together we have:
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbigg
θ1(t)
r1(t)/parenrightbigg
−/parenleftbigg
θ2(t)
r2(t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤∥θ1(t)−θ2(t)∥2+∥r1(t)−r2(t)∥2
≤4K(1 +K2(γ,T))T2max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t))
+γ/integraldisplayt
0(∥θ1(s)−θ2(s)∥2+∥r1(s)−r2(s)∥2)ds
+ 4K(1 +K2(γ,T))/integraldisplayt
0/integraldisplays
0∥θ1(u)−θ2(u)∥2duds
≤4K(1 +K2(γ,T))T2max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)) + 2γ/integraldisplayt
0/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbigg
θ1(s)
r1(s)/parenrightbigg
−/parenleftbigg
θ2(s)
r2(s)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2ds
+ 4K(1 +K2(γ,T))/integraldisplayt
0/integraldisplays
0/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbiggθ1(u)
r1(u)/parenrightbigg
−/parenleftbiggθ2(u)
r2(u)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2duds.
By Corollary F.4, we have that:
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbiggθ1(t)
r1(t)/parenrightbigg
−/parenleftbiggθ2(t)
r2(t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
≤4K(1 +K2(γ,T))T2/parenleftbigg
1 + exp/parenleftbigg4γ2+ 4K(1 +K2(γ,T))T
2γ/parenrightbigg/parenrightbigg
max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)).
Thus, we have that
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/parenleftbiggθ1(t)
r1(t)/parenrightbigg
−/parenleftbiggθ2(t)
r2(t)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤T2K(γ,T) max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)),
which implies that
max
t∈[0,T]W2(HT(ρ1(t)),HT(ρ2(t)))≤T2K(γ,T) max
t∈[0,T]W2(ρθ
1(t),ρθ
2(t)),
where we set K(γ,T) = 4K(1 +K2(γ,T))/parenleftig
1 + exp4γ2+4K(1+K2(γ,T))T
4γ/parenrightig
.
LetC(T) =T2K(γ,T). Then, we could always find a T0such thatC(T0)<1sinceC(0) = 0andC(T)is
continuous in T, which finishes our proof.
By Banach’s fixed point theorem, there exist a T0>0such that the mean-field ODE has a unique solution
in time interval [0,T0]. Now, we show the existence and uniqueness of the solution of the mean-field ODE
for any time period [0,T].
Theorem B.2. Under Assumptions (A1)-(A2), for any T >0, there exists a unique solution for the mean-
field ODE (12) in the interval [0,T].
Proof.The idea is to separate the time interval [0,T]into subintervals of length T0, that is, we consider the
intervals [0,T0],[T0,2T0],...,[⌊T
T0⌋T0,T]. Note that the contraction property we proved in Proposition B.1
only depends on the length of the time interval, so the proof can be done recursively. That is:
23Published in Transactions on Machine Learning Research (02/2023)
1. In the interval [0,T0], (12) with initialization (θ(0),r(0))has a unique solution {ρ(t)}t∈[0,T0].
2. In the interval [T0,2T0], we consider (12) with initial distribution ρ(T0), and it has a unique solution
{ρ(t)}t∈[T0,2T0].
3. Recursively do the above steps until the interval [⌊T
T0⌋T0,T].
Thus we have that, for any T >0, there exists a unique solution for (12) in the interval [0,T].
B.2 Three-layer networks
In this section, we prove the existence and the uniqueness of the mean-field ODE (13). The integral form of
the mean-field ODE is given by
w3(t,c2) =w3(0,c2)−γ/integraldisplayt
0(w3(s,c2)−w3(0,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(u,x,c2)duds, (38)
w2(t,c1,c2) =w2(0,c1,c2)−γ/integraldisplayt
0(w2(s,c1,c2)−w2(0,c1,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
2(u,z,c1,c2)duds,(39)
w1(t,c1) =w1(0,c1)−γ/integraldisplayt
0(w1(s,c1)−w1(0,c1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(u,z,c1)duds. (40)
In order to prove the existence and the uniqueness, we follow the same Picard’s iteration arguments as for
the two-layers case. We first define the following norm:
∥W∥T= max ess sup
C1,C2sup
t∈[0,T]{|w2(t,C1,C2)|,|w3(t,C2)|}. (41)
Next, we define the following metric for two sets of mean-field parameters:
DT(W,W′) = max ess sup
C1,C2sup
t∈[0,T]/braceleftbig
∥w′
1(t,C1)−w1(t,C1)∥2,
|w′
2(t,C1,C2)−w2(t,C1,C2)|,|w′
3(t,C2)−w3(t,C2)|/bracerightbig
. (42)
Note that the metric we define above is not the metric induced by the norm, since in the definition of the
norm we only require the boundedness of w2andw3.
We define the following functional space of the mean-field parameters:
WT(W(0)) ={{/tildewiderW(t)}t∈[0,T]:∥/tildewiderW∥T<∞,/tildewiderW(0) =W(0)}, (43)
which means that all the /tildewiderW∈WT(W(0))have the same initialization W(0). By Lemma A.2, we know
that:
ess sup
C1,C2|w2(t,C1,C2)|≤K3,2(γ,T), ess sup
C1,C2|w3(t,C2)|≤K3,3(γ,T). (44)
It is easy to see that the space WT(W(0))is complete w.r.t. the metric DT(W,W′). Let us define the
operatorHT:WT(W(0))− →WT(W(0))as follows:
Input:{W(t)}t∈[0,T]
24Published in Transactions on Machine Learning Research (02/2023)
Output:{/tildewiderW(t)}t∈[0,T], such that:
/tildewidew3(t,c2) =w3(0,c2)−γ/integraldisplayt
0(w3(s,c2)−w3(0,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(x,c2;W(u))duds (45)
/tildewidew2(t,c1,c2) =w2(0,c1,c2)−γ/integraldisplayt
0(w2(s,c1,c2)−w2(0,c1,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
2(z,c1,c2;W(u))duds
(46)
/tildewidew1(t,c1) =w1(0,c1)−γ/integraldisplayt
0(w1(s,c1)−w1(0,c1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(z,c1;W(u))duds. (47)
We aim to show the following proposition.
Proposition B.3. Under Assumptions (B1)-(B3), there exists a T0only depending on K,γandC(T0)∈
(0,1), such that, for all W1,W2∈WT(W(0)), we have:
DT0(HT0(W1),HT0(W2))≤C(T0)DT0(W1,W2). (48)
Proof of Proposition B.3. For simplicity of notation, we denote the output of HT(W1)to be/tildewiderW1, which is
composed of/tildewidew1
3,/tildewidew1
2,/tildewidew1
1. The output of HT(W2)is denoted similarly.
By the definition of the mean-field ODE, we have that, for any t≤T,
|/tildewidew1
3(t,c2)−/tildewidew2
3(t,c2)|≤γ/integraldisplayt
0|w1
3(s,c2)−w2
3(s,c2)|ds
+/integraldisplayt
0/integraldisplays
0Ez|∆W
3(x,c2;W1(u))−∆W
3(x,c2;W2(u))|duds,
|/tildewidew1
2(t,c1,c2)−/tildewidew2
2(t,c1,c2)|≤γ/integraldisplayt
0|w1
2(s,c1,c2)−w2
2(s,c1,c2)|ds
+/integraldisplayt
0/integraldisplays
0Ez|∆W
2(x,c1,c2;W1(u))−∆W
2(x,c1,c2;W2(u))|duds,
∥/tildewidew1
1(t,c1)−/tildewidew2
1(t,c1)∥2≤γ/integraldisplayt
0∥w1
1(s,c1)−w2
1(s,c1)∥2ds
+/integraldisplayt
0/integraldisplays
0Ez∥∆W
1(x,c1;W1(u))−∆W
1(x,c1;W2(u))∥2duds.
By Lemma A.2, we have that:
max{Ez|∆W
3(x,c2;W1(u))−∆W
3(x,c2;W2(u))|,
Ez|∆W
2(x,c1,c2;W1(u))−∆W
2(x,c1,c2;W2(u))|,
Ez∥∆W
1(x,c1;W1(u))−∆W
1(x,c1;W2(u))∥2}≤K(γ,T)Du(W1,W2).
Thus, we have:
Dt(/tildewiderW1,/tildewiderW2)≤γ/integraldisplayt
0Ds(W1,W2)ds+K(γ,T)/integraldisplayt
0/integraldisplays
u=0Du(W1,W2)duds
≤(γt+t2)K(γ,T)Dt(W1,W2),
which implies that
DT(/tildewiderW1,/tildewiderW2)≤(γT+T2)K(γ,T)DT(W1,W2). (49)
Since (γT+T2)K(γ,T) = 0whenT= 0, and (γT+T2)K(γ,T)is continuous in T, we can pick a T0such
that (γT0+T2
0)K(γ,T0)<1, which finishes the proof.
25Published in Transactions on Machine Learning Research (02/2023)
SinceWT(W(0))is complete, by Banach’s fixed point theorem, there exists a unique fixed point for the
operatorHT0, which implies that the mean-field ODE (13) has a unique solution in [0,T0]. By following
the same argument of the proof of Theorem B.2 (separate the interval [0,T]into sub-intervals of length T0
and successively apply Proposition B.3 to each of them), we readily obtain our main result concerning the
existence and uniqueness of (13) in [0,T].
Theorem B.4. Under Assumptions (B1)-(B3), for any T >0, there exists a unique solution for the mean-
field ODE (13) in the interval [0,T].
C Convergence to the mean-field limit – Two-layer networks
In this section, we prove the convergence to the mean-field limit for two-layer neural networks (Theorem
5.1). Our proof’s structure is inspired from Mei et al. (2019). Before going into the arguments, we first recall
the definition of the mean-field ODE and the stochastic heavy ball method (SHB) for two-layer networks.
Then, we define two auxiliary dynamics: the particle dynamics (PD) and the heavy ball dynamics (HB).
First, recall the mean-field ODE as follows:
dθ(t) =r(t)dt,
dr(t) =/parenleftbig
−γr(t)−∇θΨ(θ(t);ρθ(t))/parenrightbig
dt, (50)
and the corresponding integral form
θ(t) =θ(0)−γ/integraldisplayt
0(θ(s)−θ(0))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θ(u);ρθ(t))duds. (51)
The SHB dynamics is as follows:
θSHB(k+ 1,j) =θSHB(k,j) + (1−γε)(θSHB(k,j)−θSHB(k−1,j))−ε2∇θ/hatwideΨ(z,θSHB(k,j);ρθ
SHB(k)),
∀j∈[n],
(52)
whereρθ
SHB(k) =1
n/summationtextn
j=1δθ(k,j)is the empirical distribution.
In order to describe the convergence to mean-field limit, we define the following particle dynamics (PD):
dθPD(t,j) =rPD(t,j)dt
drPD(t,j) =/parenleftbig
−γrPD(t,j)−∇θΨ(θPD(t,j);ρθ
PD(t))/parenrightbig
dt,∀j∈[n], (53)
whereρθ
PD(t) =1
n/summationtextn
j=1δθPD(t,j)is the empirical distribution at time t. Furthermore, the heavy ball (HB)
dynamics is defined as
θHB(k+ 1,j) =θHB(k,j) + (1−γε)(θHB(k,j)−θHB(k−1,j))−ε2∇θΨ(θHB(k,j);ρθ
HB(k)),∀j∈[n].
(54)
We remark that (52), (53) and (54) have the same initialization, that is :
θPD(0,j) =θHB(0,j) =θSHB(0,j),∀j∈[n].
Define the following distance metrics:
DT(θ,θPD) := max
j∈[n]sup
t∈[0,T]/vextenddouble/vextenddoubleθPD(t,j)−θ(t,j)/vextenddouble/vextenddouble
2, (55)
DT(θPD,θHB) := max
j∈[n]sup
t∈[0,T]/vextenddouble/vextenddoubleθHB(⌊t/ε⌋,j)−θPD(t,j)/vextenddouble/vextenddouble
2, (56)
DT,ε(θHB,θSHB) := max
j∈[n]max
k∈⌊T/ε⌋∥θHB(k,j)−θSHB(k,j)∥2. (57)
26Published in Transactions on Machine Learning Research (02/2023)
C.1 Bound between mean-field ODE and particle dynamics
Inthissection, weboundthedifferencebetweenthemean-fieldODEdefinedin(51)andtheparticledynamics
defined in (53), whose integral form is as follows:
θPD(t,j) =θPD(0,j)−γ/integraldisplayt
0(θPD(s,j)−θPD(0,j))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θPD(u,j);ρθ
PD(u))duds.
Proposition C.1. Under Assumptions (A1) - (A3), we have that, with probability at least 1−exp(−δ2),
DT(θ,θPD)≤K(γ,T)/parenleftbiggδ+√logn√n/parenrightbigg
, (58)
whereK(γ,T)is a constant depending only on γ,T.
Before proving Proposition C.1, we first prove the following lemma, which characterizes the Lipschitz conti-
nuity of the mean-field ODE.
Lemma C.2. Under Assumptions (A1) - (A3), there exists a universal constant K(γ,T)depending only on
γ,Tsuch that, for any t,τ > 0such thatt,t+τ <T,
∥θ(t+τ)−θ(t)∥2≤K(γ,T)τ,
W2(ρθ(t+τ),ρθ(t))≤K(γ,T)τ.(59)
The same holds for the particle dynamics θPD(t,j),∀j∈[n].
Proof of Lemma C.2. We only prove the results for the mean-field ODE, and the proof for the particle
dynamics follows from the same arguments.
We first try to bound the increments ∥θ(t)−θ(0)∥2. By the definition of the mean-field dynamics, we have
that:
∥θ(t)−θ(0)∥2≤γ/integraldisplayt
0∥θ(s)−θ(0)∥2ds+/integraldisplayt
0/integraldisplays
0∥∇θΨ(θ(u);ρθ(u))∥2duds
≤γ/integraldisplayt
0∥θ(s)−θ(0)∥2ds+K1(γ,T),
where in the last step we use that ∥∇θΨ(θ(u);ρθ(u))∥2≤K1(γ,T), which follows from Lemma A.1.
By Gronwall’s lemma, this implies that, for any t≤T,
∥θ(t)−θ(0)∥2≤K1(γ,T) exp(γT) :=K2(γ,T).
Next, by definition of the mean-field ODE, we have that:
∥θ(t+τ)−θ(t)∥2≤γ/integraldisplayt+τ
t∥θ(s)−θ(0)∥2ds+/integraldisplayt+τ
t/integraldisplays
0∥∇θΨ(θ(u);ρθ(u))∥2duds.
Thus,
∥θ(t+τ)−θ(t)∥2≤K4(γ,T)τ,
where we use that fact that
∥θ(s)−θ(0)∥2≤K3(γ,T),
/integraldisplays
0∥∇θ,Ψ(θ(u);ρθ(u))∥2du≤K3(γ,T).
27Published in Transactions on Machine Learning Research (02/2023)
For the Lipschitz continuity of ρθ, we just note that by definition of the W2distance, we have:
W2(ρθ(t+τ),ρθ(t))≤E/bracketleftbig
∥θ(t+τ)−θ(t)∥2
2/bracketrightbig1/2.
Now we are ready to prove Proposition C.1.
Proof of Proposition C.1. In order to bound the difference, we first define ni.i.d mean-field dynamics:
θ(t,j) =θ(0,j)−γ/integraldisplayt
0(θ(s,j)−θ(0,j))ds−/integraldisplayt
0/integraldisplays
0∇θΨ(θ(u,j);ρθ(u,j))duds,
whereρθ(t,j)is the law of θ(t,j), and we coupled the ni.i.d dynamics with the particle dynamics at
initialization, that is, we let:
θ(0,j) =θPD(0,j),∀j∈[n].
We also define the empirical distribution of θ(t,j), that is:/hatwideρθ(t) =1
n/summationtextn
j=1δθ(t,j). Since the nmean-field
dynamics are i.i.d, we have that ρθ(t,j) =ρθ(t),∀j∈[n], thus we use the notation of ρθ(t)to denote the
the law ofθ(t,j)for eachj∈[n].
By Lemma A.1 and Lemma C.2, we know that:
sup
t∈[T]max
j∈[n]∥w2(t,j)∥2≤K(γ,T),
sup
t∈[T]max
j∈[n]∥θ(t+τ,j)−θ(t,j)∥2≤K(γ,T)τ.
We have that
∥θPD(t,j)−θ(t,j)∥2≤(1 +γt)∥θPD(0,j)−θ(0,j)∥2+γ/integraldisplayt
0∥θPD(s,j)−θ(s,j)∥2ds
+/integraldisplayt
0/integraldisplays
0∥∇θΨ(θPD(u,j);ρθ
PD(u))−∇θΨ(θ(u,j);ρθ(u))∥2duds,
and our goal is to bound:
sup
t∈[0,T]max
j∈[n]∥θPD(t,j)−θ(t,j)∥2.
Now we aim to bound the quantity
sup
t∈[0,T]max
j∈[n]∥∇θΨ(θPD(u,j);ρθ
PD(u,j))−∇θΨ(θ(u,j);ρθ(u))∥2.
An application of the triangle inequality gives
∥∇θΨ(θ(u,j);ρθ(u))−∇θΨ(θPD(u,j);ρθ
PD(u,j))∥2≤∥∇θΨ(θ(u,j);/hatwideρθ(u))−∇θΨ(θ(u,j);ρθ(u))∥2(60)
+∥∇θΨ(θ(u,j);/hatwideρθ(u))−∇θΨ(θPD(u,j);ρθ
PD(u))∥2.
(61)
Recall by definition that
∇w1Ψ(θ(u,j);ρθ(u)) =Ez/bracketleftbig
∂2R(y,f(x;ρθ(u)))w2(u,j)σ′(w1(u,j)Tx)x/bracketrightbig
,
∇w2Ψ(θ(u,j);ρθ(u)) =Ez/bracketleftbig
∂2R(y,f(x;ρθ(u)))σ(w1(u,j)Tx)/bracketrightbig
.
28Published in Transactions on Machine Learning Research (02/2023)
Similarly,
∇w1Ψ(θ(u,j);/hatwideρθ(u)) =Ez/bracketleftbig
∂2R(y,f(x;/hatwideρθ(u)))w2(u,j)σ′(w1(u,j)Tx)x/bracketrightbig
,
∇w2Ψ(θ(u,j);/hatwideρθ(u)) =Ez/bracketleftbig
∂2R(y,f(x;/hatwideρθ(u)))σ(w1(u,j)Tx)/bracketrightbig
.
For the term in (60) , we use concentration inequalities to give an upper bound. By the Lipschitz continuity
of∂2Rin Assumption 3.1, we have
∥∇θΨ(θ(u,j);/hatwideρθ(u))−∇θΨ(θ(u,j);ρθ(u))∥2
≤K/vextenddouble/vextenddouble/vextenddouble/vextenddoubleEz/parenleftbiggw2(u,j)σ′(w1(u,j)Tx)x
σ(w1(u,j)Tx)/parenrightbigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2|f(x;ρθ(u))−f(x;/hatwideρθ(u))|
≤K1(γ,T)|f(x;ρθ(u))−f(x;/hatwideρθ(u))|.
For the term|f(x;ρ(u))−f(x;/hatwideρθ(u))|, we have
|f(x;ρθ(u))−f(x;/hatwideρθ(u))|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
j=1w2(u,j)σ(w1(u,j)Tx)−Eρ(u)w2(u)σ(w1(u)Tx)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle.
Note that, by Lemma A.1, we know that
/vextendsingle/vextendsinglew2(u,j)σ(w1(u,j)Tx)−Eρ(u)w2(u)σ(w1(u)Tx)/vextendsingle/vextendsingle≤K2(γ,T).
By Lemma F.1, we have that, with probability at least 1−exp(−n(δ′)2),
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
i=1w2(u,j)σ(w1(u,j)Tx)−Eρ(u)w2(u)σ(w1(u)Tx)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤K2(γ,T)/parenleftbigg1√n+δ′/parenrightbigg
.
By Lemma C.2, we know that/vextendsingle/vextendsingle1
n/summationtextn
i=1w2(u,j)σ(w1(u,j)Tx)−Eρ(u)w2(u)σ(w1(u)Tx)/vextendsingle/vextendsingleisK(γ,T)-Lipschitz
continuous in u. Thus, by taking a union bound over j∈[n]andt∈/braceleftig
0,η,...,⌊T
η⌋η/bracerightig
, we have that, with
probability at least 1−nT
ηexp(−n(δ′)2),
max
j∈[n]sup
t∈[0,T]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
i=1w2(u,j)σ(w1(u,j)Tx)−Eρ(u)w2(u)σ(w1(u)Tx)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤K3(γ,T)/parenleftbigg1√n+δ′+η/parenrightbigg
.
Takeη=1√n,δ′=/radicaligg
δ2+log/parenleftig
n3
2T/parenrightig
n. Then, with probability at least 1−exp(−δ2),
max
j∈[n]sup
t∈[0,T]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
i=1Eρ(u)w2(u)σ(w1(u)Tx)−w2(u,j)σ(w1(u,j)Tx)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤K4(γ,T)δ+√logn√n,
which implies that, for term (60),
max
j∈[n]sup
t∈[0,T]∥∇θΨ(θ(u,j);/hatwideρθ(u))−∇θΨ(θ(u,j);ρθ(u))∥2≤K5(γ,T))δ+√logn√n,
with probability 1−exp(−δ2).
For the term in (61), we use the Lipschitz continuity of ∇θΨ. By Lemma A.1, we have that, for each j∈[n],
∥∇θΨ(θ(t,j);/hatwideρθ(t))−∇θΨ(θPD(t,j);ρθ
PD(t))∥2≤K6(γ,T)(Dt(θ,θPD) +W2(/hatwideρθ(t),ρθ
PD(t))).
29Published in Transactions on Machine Learning Research (02/2023)
Note that/hatwideρθ(t),ρθ
PD(t)are discrete measures, thus we have:
W2(/hatwideρθ(t),ρθ
PD(t))≤
1
nn/summationdisplay
j=1∥θ(t,j)−θPD(t,j)∥2
2
1/2
≤Dt(θ,θPD).
Hence,
∥∇θΨ(θ(t,j);/hatwideρθ(t))−∇θΨ(θPD(t,j);ρθ
PD(t))∥2≤K7(γ,T)Dt(θ,θPD).
Combining the above results, we have that, with probability 1−exp(−δ2),
Dt(θ,θPD)≤K8(γ,T)δ+√logn√n+γ/integraldisplayt
0Ds(θ,θPD)ds+K8(γ,T)/integraldisplayt
0/integraldisplays
0Du(θ,θPD)duds.
An application of Corollary F.4 concludes the proof.
C.2 Bound between particle dynamics and heavy ball dynamics
In this section, we bound the difference between the particle dynamics defined in (53) and the heavy ball
dynamics defined in (54). We recall that the distance we aim to bound is defined in (56). Note that the
heavy ball dynamics is a discretization of the particle dynamics. Thus we aim to bound the difference at
time point kε.
Proposition C.3. Under Assumptions (A1) - (A3), there exist a universal constant K(γ,T)depending only
onγ,T, such that
DT(θPD,θHB)≤K(γ,T)ε. (62)
Proof of Proposition C.3. By the Taylor expansion, we have the following approximation for the particle
dynamics:
θPD((k+ 1)ε,j) =θPD(kε,j) +rPD(kε,j)ε+1
2∂trPD(kε,j)ε2+O(ε3). (63)
Also by Taylor expansion we have:
rPD(kε,j)ε=θPD(kε,j)−θPD((k−1)ε,j) +1
2∂trPD(kε,j)ε2+O(ε3). (64)
By plugging (61) into (63), we have that
θPD((k+ 1)ε,j) =θPD(kε,j) +θPD(kε,j)−θPD((k−1)ε,j) +∂trPD(kε,j)ε2+O(ε3)
=θPD(kε,j) +θPD(kε,j)−θPD((k−1)ε,j) +/parenleftbig
−γr(kε,j)−∇θΨ(θPD(kε,j);ρθ
PD(kε))/parenrightbig
ε2+O(ε3)
=θPD(kε,j) + (1−γε)(θPD(kε,j)−θPD((k−1)ε,j))−∇θΨ(θPD(kε,j);ρθ
PD(kε))ε2+O(ε3).
Now we get a discrete iteration equation for the particle dynamics, with an approximation error of at most
O(ε3). By accumulating the ∇θΨ(θPD(lε,j);ρθ
PD(lε))term froml= 1,...,k, we have
θPD(kε,j) =θPD(0,j)−k−1/summationdisplay
l=0c(k)
l(∇θΨ(θPD(lε,j);ρθ
PD(lε)) +O(ε)), (65)
wherec(k)
l=ε2/summationtextk−1−l
i=0(1−γε)i=ε21−(1−γε)k
γε≤ε
γ.
30Published in Transactions on Machine Learning Research (02/2023)
The heavy ball dynamics can be written in a similar fashion:
θHB(kε,j) =θHB(0,j)−k−1/summationdisplay
l=0c(k)
l∇θΨ(θHB(lε,j);ρθ
HB(lε)). (66)
Thus, we have that
∥θPD(kε,j)−θHB(kε,j)∥2≤k−1/summationdisplay
l=0c(k)
l/parenleftbig
∥∇θΨ(θPD(lε,j);ρθ
PD(lε))−∇θΨ(θHB(lε,j);ρθ
HB(lε))∥2+O(ε)/parenrightbig
.
(67)
By Lemma A.1, we have that
∥∇θΨ(θPD(lε,j);ρθ
PD(lε))−∇θΨ(θHB(lε,j);ρθ
HB(lε))∥2
≤K1(γ,T)(∥θPD(lε,j)−θHB(lε,j)∥2+W2(ρθ
PD(lε),ρθ
HB(lε))).
Sinceρθ
PD(lε),ρθ
HB(lε))are discrete distributions, we have that
W2(ρθ
PD(lε),ρθ
HB(lε)))≤
1
nn/summationdisplay
j=1∥θPD(lε,j)−θHB(lε,j)∥2
2
1/2
≤Dlε(θPD,θHB),
which implies that
∥∇θΨ(θPD(lε,j);ρθ
PD(lε))−∇θΨ(θHB(lε,j);ρθ
HB(lε))∥2≤K2(γ,T)Dlε(θPD,θHB).
As a result, we have
Dkε(θPD,θHB)≤K2(γ,T)ε
γk−1/summationdisplay
l=1/parenleftbig
Dlε(θPD,θHB) +O(ε)/parenrightbig
.
Finally, an application of the discrete Gronwall’s lemma concludes the proof.
C.3 Bound between heavy ball dynamics and stochastic heavy ball dynamics
In this section, we bound the difference between the heavy ball dynamics defined in (54) and the stochastic
heavy ball dynamics defined in (52). We recall that the distance we aim to bound is defined in (57). The
manipulations of the previous section imply that the heavy ball dynamics can be written as
θHB(k,j) =θHB(0,j)−k−1/summationdisplay
l=1c(k)
l∇θΨ(θHB(l,j);ρθ
HB(l)). (68)
Similarly, the stochastic heavy ball dynamics can be written as
θSHB(k,j) =θSHB(0,j)−k−1/summationdisplay
l=0c(k)
l∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l)). (69)
Proposition C.4. Under Assumptions (A1) - (A3), there exists a universal constant K(γ,T)depending
only onγ,T, such that, with probability 1−exp(−δ2),
DT,ε(θHB,θSHB)≤K(γ,T)√ε(/radicalbig
D+ logn+δ). (70)
31Published in Transactions on Machine Learning Research (02/2023)
Proof.By using (68) and (69), we have
/vextenddouble/vextenddoubleθHB(k,j)−θSHB(k,j)/vextenddouble/vextenddouble
2≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l(∇θΨ(θHB(l,j);ρθ
HB(l))−∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l)))/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2.
By triangle inequality, we have that
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l(∇θΨ(θHB(l,j);ρθ
HB(l))−∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l)))/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
≤k−1/summationdisplay
l=0c(k)
l∥∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l))−∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))∥2 (71)
+/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l(∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))−∇θΨ(θHB(l,j);ρθ
HB(l)))/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2.(72)
For the term in (71), by the Lipschitz continuity of ∇θ/hatwideΨ, we obtain
∥∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l))−∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))∥2
≤K1(γ,T)(Dlε,ε(θHB,θSHB) +W2(ρθ
HB(l),ρθ
SHB(l))).
Sinceρθ
HB,ρθ
SHBare discrete distributions, we have that W2(ρθ
HB(l),ρθ
SHB(l))≤Dlε,ε(θHB,θSHB). Thus,
∥∇θ/hatwideΨ(z(l),θSHB(l,j);ρθ
SHB(l))−∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))∥2≤K2(γ,T)Dlε,ε(θHB,θSHB).
For the term in (72), note that, since the z(l)’s are sampled i.i.d. at each step by definition, we have
Ez(l)/bracketleftig
∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))/bracketrightig
=∇θΨ(θHB(l,j);ρθ
HB(l)).
Thus,
∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))−∇θΨ(θHB(l,j);ρθ
HB(l))
is a martingale difference. By Lemma A.1, we have that, for all l∈{1,...,⌊T/ε⌋},
∥∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))−∇θΨ(θHB(l,j);ρθ
HB(l))∥2≤K3(γ,T).
Thus, an application of Lemma F.2 gives that, with probability at least 1−exp(−δ2),
max
l∈{1,...,⌊T/ε⌋}∥∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))−∇θΨ(θHB(l,j);ρθ
HB(l))∥2≤K4(γ,T)√ε(√
D+δ).
By taking a union bounds on j∈[n], we have that, with probability at least 1−exp(−δ2),
max
j∈[n]max
l∈{1,...,⌊T/ε⌋}∥∇θ/hatwideΨ(z(l),θHB(l,j);ρθ
HB(l))−∇θΨ(θHB(l,j);ρθ
HB(l))∥2≤K4(γ,T)√ε(/radicalbig
D+ logn+δ).
By combining the above result, we conclude that
DT,ε(θHB,θSHB)≤K4(γ,T)√ε(/radicalbig
D+ logn+δ) +K2(γ,T)
γε⌊T
ε⌋/summationdisplay
l=0Dlε,ε(θHB,θSHB).(73)
Finally, an application of the discrete Gronwall’s lemma concludes the proof.
32Published in Transactions on Machine Learning Research (02/2023)
C.4 Proof of Theorem 5.1
Proof of Theorem 5.1. The proof follows from combining Proposition C.1, C.3, C.4, and the fact that:
DT(θ,θSHB)≤DT(θ,θPD) +DT(θPD,θHB) +DT,ε(θHB,θSHB).
D Convergence to the mean-field limit – Three-layer networks
In this section, we prove the convergence of the training dynamics to the mean-field limit for a three-layer
neural network. Our proof’s structure is inspired from Pham & Nguyen (2021a).
Before going into the proofs, let’s first recall the definition of the mean-field ODE and the SHB dynamics,
and then define two auxiliary dynamics, namely the HB dynamics and the particle dynamics. For the
convenience of further computation, we define these continuous dynamics in integral form. We define the
random variable corresponding to the stochastic heavy ball dynamics, the heavy ball dynamics, the particle
dynamics, and the mean-field ODE as WSHB,WHB,WPD,Wrespectively.
The mean-field ODE (13) in integral form is the following:
w3(t,c2) =w3(0,c2)−γ/integraldisplayt
0(w3(s,c2)−w3(0,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(z,c2;W(u))duds,
w2(t,c1,c2) =w2(0,c1,c2)−γ/integraldisplayt
0(w2(s,c1,c2)−w2(0,c1,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
2(z,c1,c2;W(u))duds,
w1(t,c1) =w1(0,c1)−γ/integraldisplayt
0(w1(s,c1)−w1(0,c1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(z,c1;W(u))duds.
(74)
The SHB dynamics is as follows:
wSHB
3(k+ 1,j2) =wSHB
3(k,j2) + (1−γε)(wSHB
3(k,j2)−wSHB
3(k−1,j2))−ε2∆W
3(z(k),j2;WSHB(k)),
wSHB
2(k+ 1,j1,j2) =wSHB
2(k,j1,j2) + (1−γε)(wSHB
2(k,j1,j2)−wSHB
2(k−1,j1,j2)),
−ε2∆W
2(z(k),j1,j2;WSHB(k))
wSHB
1(k+ 1,j1) =wSHB
1(k,j1) + (1−γε)(wSHB
1(k,j1)−wSHB
1(k−1,j1))−ε2∆W
1(z(k),j1;WSHB(k)),
(75)
wherez(k)is the data point sampled at time step k.
We define the particle dynamics as a continuous dynamics without mean-field interaction:
wPD
3(t,j2) =wPD
3(0,j2)−γ/integraldisplayt
0(wPD
3(s,j2)−wPD
3(0,j2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(z,j2;WPD(u))duds,
wPD
2(t,j1,j2) =wPD
2(0,j1,j2)−γ/integraldisplayt
0(wPD
2(s,j1,j2)−wPD
2(0,j1,j2))ds
−/integraldisplayt
0/integraldisplays
0Ez∆W
2(z,j1,j2;WPD(u))duds,
wPD
1(t,j1) =wPD
1(0,j1)−γ/integraldisplayt
0(wPD
1(s,j1)−wPD
1(0,j1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(z,j1;WPD(u))duds.
(76)
33Published in Transactions on Machine Learning Research (02/2023)
We define the HB dynamics by replacing the stochastic gradient in the SHB dynamics by the true gradient.
That is:
wHB
3(k+ 1,j2) =wHB
3(k,j2) + (1−γε)(wHB
3(k,j2)−wHB
3(k−1,j2))−ε2Ez∆W
3(z,j2;WHB(k)),
wHB
2(k+ 1,j1,j2) =wHB
2(k,j1,j2) + (1−γε)(wHB
2(k,j1,j2)−wHB
2(k−1,j1,j2))
−ε2Ez∆W
2(z,j1,j2;WHB(k)),
wHB
1(k+ 1,j1) =wHB
1(k,j1) + (1−γε)(wHB
1(k,j1)−wHB
1(k−1,j1))−ε2Ez∆W
1(z,j1;WHB(k)).(77)
Note that the HB dynamics can be viewed as the discrete version of the PD dynamics.
In order to present our main theoretical results in this section, we first define a distance metric to quantify
the level of correspondence of these dynamics. We define the following distance metrics:
DT(W,WPD) = max sup
t∈[0,T]{/vextenddouble/vextenddoublewPD
1(t,j1)−w1(t,C1(j1))/vextenddouble/vextenddouble
2,
/vextendsingle/vextendsinglewPD
2(t,j1,j2)−w2(t,C1(j1),C2(j2))/vextendsingle/vextendsingle,
/vextendsingle/vextendsinglewPD
3(t,j2)−w3(t,C2(j2))/vextendsingle/vextendsingle:j1∈[n1],j2∈[n2]}(78)
DT(WPD,WHB) = max sup
t∈[0,T]{/vextenddouble/vextenddoublewHB
1(⌊t/ε⌋,j1)−wPD
1(t,j1)/vextenddouble/vextenddouble
2,
/vextendsingle/vextendsinglewHB
2(⌊t/ε⌋,j1,j2)−wPD
2(t,j1,j2)/vextendsingle/vextendsingle,
/vextendsingle/vextendsinglewHB
3(⌊t/ε⌋,j2)−wPD
3(t,j2)/vextendsingle/vextendsingle:j1∈[n1],j2∈[n2]}(79)
DT,ε(WHB,WSHB) = max max
k∈⌊T/ε⌋{∥wHB
1(k,j1)−wSHB
1(k,j1)∥2,
|wHB
2(k,j1,j2)−wSHB
2(k,j1,j2)|,
|wHB
3(k,j2)−wSHB
3(k,j2)|:j1∈[n1],j2∈[n2]}(80)
We acknowledge the abuse in notation from reusing DTfor multiple metrics, which is done to avoid prolif-
eration of notation. It is clear that:
DT(W,WSHB)≤DT(W,WPD) +DT(WPD,WHB) +DT,ε(WHB,WSHB), (81)
whereDT(W,WSHB)is defined in (17).
In the following subsections, we bound the terms DT(W,WPD),DT(WPD,WHB)andDT,ε(WHB,WSHB).
D.1 Bound between mean-field ODE and particle dynamics
Inthissection, weboundthedifferencebetweenthemean-fieldODEdefinedin(74)andtheparticledynamics
defined in (76). We recall that the distance we aim to bound is defined in (78).
Proposition D.1. Under Assumptions (B1)-(B3), we have that, with probability at least 1−exp(−δ2),
DT(W,WPD)≤K(γ,T)√nmin/parenleftig/radicalbig
lognmax+δ/parenrightig
, (82)
whereK(γ,T)is a universal constant depending only on γ,T,nmin= min{n1,n2}andnmax= max{n1,n2}.
In order to prove Proposition D.1, we need the following auxiliary lemma, which characterizes the Lipschitz
continuity of the mean-field ODE and of the particle dynamics.
34Published in Transactions on Machine Learning Research (02/2023)
Lemma D.2. Under Assumptions (B1)-(B3), there exists a universal constant K(γ,T)depending only on
γ,Tsuch that, for any t,τ > 0witht,t+τ≤T,
ess sup
c2|w3(t+τ,c2)−w3(t,c2)|≤K(γ,T)τ,
ess sup
c1,c2|w2(t+τ,c1,c2)−w2(t,c1,c2)|≤K(γ,T)τ,
ess sup
c1∥w1(t+τ,c1)−w1(t,c1)∥2≤K(γ,T)τ.(83)
The same holds for the particle dynamics wPD
1(t,j1),wPD
2(t,j1,j2),wPD
3(t,j2).
Proof of Lemma D.2. We do the proof for w1(t,c1), and the same argument applies to w2(t,c1,c2),w3(t,c2).
First, we derive a bound on the increments up to time t,∥w1(t,c1)−w1(0,c1)∥2. By the definition of the
mean-field ODE (74), we have that
w1(t,c1)−w1(0,c1) =−γ/integraldisplayt
0(w1(s,c1)−w1(0,c1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(z,c1;W(u))duds,
which implies that
∥w1(t,c1)−w1(0,c1)∥2=γ/integraldisplayt
0∥w1(s,c1)−w1(0,c1)∥2ds+/integraldisplayt
0/integraldisplays
0∥Ez∆W
1(z,c1;W(u))∥2duds
≤γ/integraldisplayt
0∥w1(s,c1)−w1(0,c1)∥2ds+T2K1(γ,T),
where in the last step we use that, for some constant K1(γ,T)depending only on γ,T,
∥Ezess supc1supu∈[0,T]∆W
1(z,c1;W(u))∥2≤K1(γ,T)by Lemma A.2. Thus, by Gronwall’s lemma, we
have that
sup
t∈[0,T]∥w1(t,c1)−w1(0,c1)∥2≤eγTT2K1(γ,T) :=K2(γ,T). (84)
Now, by using again the definition of the mean-field ODE (74), we have that:
∥w1(t+τ,c1)−w1(t,c1)∥2=/vextenddouble/vextenddouble/vextenddouble/vextenddouble−γ/integraldisplayt+τ
t(w1(s,c1)−w1(0,c1))ds−/integraldisplayt+τ
t/integraldisplays
0Ez∆W
1(z,c1;W(u))duds/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
≤γsup
t∈[0,T]∥w1(t,c1)−w1(0,c1)∥2τ+K1(γ,T)Tτ
≤K2(γ,T)τ+K1(γ,T)Tτ,
where in the second line we use that ∥Ezess supc1supu∈[0,T]∆W
1(z,c1;W(u))∥2≤K1(γ,T)by Lemma A.2,
and in the last passage we use (84). By setting K(γ,T) =K2(γ,T) +K1(γ,T)T, we obtain the desired
result and the proof is complete.
By the above Lemma D.2 and Lemma A.2, we immediately get the following corollary.
Corollary D.3. Under Assumptions (B1)-(B3), there exists a universal constant K(γ,T)depending only
onγ,Tsuch that, for any t,τ > 0witht,t+τ≤T, the following functions
f(x;W(t)), H 2(x,c2;W(t)),EC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
areK(γ,T)-Lipschitz continuous in t. The same holds for the particle dynamics, i.e., the functions
f(x;W(t)), H 2(x,j2;W(t)),1
n2n2/summationdisplay
j2=1∆H
2(z,j2;W(t))w2(t,j1,j2)
areK(γ,T)-Lipschitz continuous in t.
35Published in Transactions on Machine Learning Research (02/2023)
Proof of Corollary D.3. We do the proof for f(x;W(t)), and the same argument applies to the other cases.
By Lemma A.2, we have that
|f(x;W(t+τ))−f(x;W(t))|≤Kess sup
c1,c2(|w3(t+τ,c2)|·|w2(t+τ,c1,c2)|·∥w1(t+τ,c1)−w1(t,c1)∥2
+|w3(t+τ,c2)|·|w2(t+τ,c1,c2)−w2(t,c1,c2)|+|w3(t+τ,c2)−w3(t,c2)|).
By Lemma D.2, we have that
max(∥w1(t+τ,c1)−w1(t,c1)∥2,|w2(t+τ,c1,c2)−w2(t,c1,c2)|,|w3(t+τ,c2)−w3(t,c2)|)≤K(γ,T)τ.
Furthermore, by Lemma A.2, we have that:
ess sup
c2|w3(t+τ,c2)|≤ sup
t∈[0,T]ess sup
c2|w3(t,c2)|≤K3,3(γ,T),
ess sup
c1,c2|w2(t+τ,c1,c2)|≤ sup
t∈[0,T]ess sup
c1,c2|w2(t,c1,c2)|≤K3,2(γ,T).
Thus, we conclude
|f(x;W(t+τ))−f(x;W(t))|≤K(γ,T)τ,
which gives the desired result.
Now we are ready to prove Proposition D.1.
Proof of Proposition D.1. Let us recall that the quantity ∆W
3is defined in (15). We start with computing
the difference in the term ∆W
3:
|Ez∆W
3(z,C2(j2);W(t))−Ez∆W
3(z,j2;WPD(t))|
≤Ez|∆W
3(z,C2(j2);W(t))−∆W
3(z,j2;WPD(t))|
=Ez|∂2R(y,f(x;W(t)))σ2(H2(x,C2(j2);W(t)))−∂2R(y,f(x;WPD(t)))σ2(H2(x,j2;WPD(t)))|
≤KEz|f(x;W(t))−f(x;WPD(t))|+K|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|,(85)
where in the last inequality we use the boundedness and Lipschitz continuity of ∂2Randσ2obtained from
Lemma A.2.
Similarly, for ∆W
1,∆W
2, we have that
|Ez∆W
2(z,C1(j1),C2(j2);W(t))−Ez∆W
2(z,j1,j2;WPD(t))|
≤Ez|∆W
2(z,C1(j1),C2(j2);W(t))−∆W
2(z,j1,j2;WPD(t))|
≤EzK|w3(t,C2(j2))|·/parenleftbig
|f(x;W(t))−f(x;WPD(t))|+|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|/parenrightbig
+|w3(t,C2(j2))|·∥w1(t,C1(j1))−wPD
1(t,j1)∥2+K|w3(t,C2(j2))−wPD
3(t,j2)|
≤EzK3,3(γ,T)/parenleftbig
|f(x;W(t))−f(x;WPD(t))|+|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|/parenrightbig
+K3,3(γ,T)∥w1(t,C1(j1))−wPD
1(t,j1)∥2+K|w3(t,C2(j2))−wPD
3(t,j2)|,(86)
and that
|Ez∆W
1(z,C1(j1);W(t))−Ez∆W
1(z,j1;WPD(t))|
≤K·Ez
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle

+K·Ez/bracketleftbig
|EC2∆H
2(z,C2;W(t))w2(t,C1(j1),C2)|/bracketrightbig
·∥w1(t,C1(j1))−wPD
1(t,j1)∥2
≤K·Ez
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle

+K(T,γ)·∥w1(t,C1(j1))−wPD
1(t,j1)∥2.(87)
36Published in Transactions on Machine Learning Research (02/2023)
Here, we remark that the expectation EC2[∆H
2(·,C2;·)w2(·,·,C2)]for the mean-field ODE corresponds to the
average1
n2/summationtextn2
j2=1∆H
2(·,j2;·)w2(·,·,j2)for the particle dynamics.
Now, our goal is to upper bound the following quantities:
|f(x;W(t))−f(x;WPD(t))|,
|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|,/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
To do so, we follow (Pham & Nguyen, 2021a, Appendix C.2, Proof of Theorem 14, Claim 2). Then, we have
that, for any δ1,δ2,δ3>0,
max/braceleftigg
|f(x;W(t))−f(x;WPD(t))|,
max
j2|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|,
max
j1/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/bracerightigg
≤K1(γ,T)/parenleftbig
DT(W,WPD) +δ1+δ2+δ3/parenrightbig
,
with probability at least
1−/parenleftbiggn2
δ1exp/braceleftbigg
−n1δ2
1
K1(γ,T)/bracerightbigg
+1
δ2exp/braceleftbigg
−n2δ2
2
K1(γ,T)/bracerightbigg
+n1
δ3exp/braceleftbigg
−n2δ2
3
K1(γ,T)/bracerightbigg/parenrightbigg
.
By Corollary D.3, we know that f(x;W(t)),H2(x,c2;W(t)),EC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,c1,C2)/bracketrightbig
are
K(γ,T)-Lipschitz continuous, and the corresponding quantities for the particle dynamics are also K(γ,T)-
Lipschitz continuous. Thus, by taking a union bound on t∈{0,η,...,⌊T/η⌋}, we have
max sup
t∈[0,T]/braceleftigg
|f(x;W(t))−f(x;WPD(t))|,
max
j2|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|,
max
j1/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/bracerightigg
≤K2(γ,T)/parenleftbig
DT(W,WPD) +δ1+δ2+δ3+η/parenrightbig
,
with probability at least
1−T
η/parenleftbiggn2
δ1exp/braceleftbigg
−n1δ2
1
K2(γ,T)/bracerightbigg
+1
δ2exp/braceleftbigg
−n2δ2
2
K2(γ,T)/bracerightbigg
+n1
δ3exp/braceleftbigg
−n2δ2
3
K2(γ,T)/bracerightbigg/parenrightbigg
.
In particular, we pick
η=1√nmax, δ 1=K3(γ,T)√n1/parenleftig/radicalbig
lognmax+δ/parenrightig
, δ 2=δ3=K3(γ,T)√n2/parenleftig/radicalbig
lognmax+δ/parenrightig
.
37Published in Transactions on Machine Learning Research (02/2023)
Then,
max sup
t∈[0,T]/braceleftigg
|f(x;W(t))−f(x;WPD(t))|,
max
j2|H2(x,C2(j2);W(t))−H2(x,j2;WPD(t))|,
max
j1/vextendsingle/vextendsingle/vextendsingle/vextendsingleEC2/bracketleftbig
∆H
2(z,C2;W(t))w2(t,C1(j1),C2)/bracketrightbig
−1
n2n2/summationdisplay
j2=1∆H
2(z,j2;WPD(t))wPD
2(t,j1,j2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/bracerightigg
≤K4(γ,T)/parenleftbigg
DT(W,WPD) +K4(γ,T)√nmin/parenleftig/radicalbig
lognmax+δ/parenrightig/parenrightbigg
(88)
with probability at least 1−exp(−δ2).
Next, we combine (88) with (85), (86) and (87) to provide high-probability bounds on ∆W
3,∆W
2,∆W
1. By
recalling the definition of the mean-field ODE (74) and the analogous definition of the particle dynamics
(76), we finally obtain that, for all t≤T, with probability at least 1−exp(−δ2),
Dt(W,WPD)≤K(γ,T)√nmin/parenleftig/radicalbig
lognmaxT+δ/parenrightig
+γ/integraldisplayt
0Ds(W,WPD)ds+/integraldisplayt
0/integraldisplays
0Du(W,WPD)duds.
An application of Corollary F.4 gives the desired result (82) and concludes the proof.
D.2 Bound between particle dynamics and heavy ball dynamics
In this part we bound the difference between the particle dynamics defined in (76) and the heavy ball
dynamics defined in (77). We recall that the distance we aim to bound is defined in (79).
Proposition D.4. Under Assumptions (B1)-(B3), there exists a universal constant K(γ,T)depending only
onγ,Tsuch that
DT(WPD,WHB)≤K(γ,T)ε. (89)
Proof of Proposition D.4. Note that the heavy ball dynamics is just a discretization of the particle dynamics,
so we first bound the difference at each time point kε. By a second order Taylor expansion, we have the
following approximation for the particle dynamics. We do the computation for w3as a representative, and
the proofs for w1,w2are the same.
We have that
wPD
3((k+ 1)ε,j2) =wPD
3(kε,j 2) +∂twPD
3(kε,j 2)ε+1
2∂2
twPD
3(kε,j 2)ε2+O(ε3). (90)
Also by Taylor expansion, we have that
∂twPD
3(kε,j 2)ε=wPD
3(kε,j 2)−wPD
3((k−1)ε,j2) +1
2∂2
twPD
3(kε,j 2)ε2+O(ε3). (91)
By plugging (91) into (90), we obtain
wPD
3((k+ 1)ε,j2) =wPD
3(kε,j 2) +wPD
3(kε,j 2)−wPD
3((k−1)ε,j2) +∂2
twPD
3kε,j 2)ε2+O(ε3)
=wPD
3(kε,j 2) +wPD
3(kε,j 2)−wPD
3((k−1)ε,j2) + (−γ∂twPD
3(ε,j2)−Ez∆W
3(z,j2;WPD(kε)))ε2+O(ε3)
=wPD
3(kε,j 2) + (1−γε)(wPD
3(kε,j 2)−wPD
3((k−1)ε,j2))−Ez∆W
3(z,j2;WPD(kε))ε2+O(ε3),
where in the last step we use again (91).
38Published in Transactions on Machine Learning Research (02/2023)
By unrolling the recursion, we can write the particle dynamics in the following form:
wPD
3(kε,j 2) =wPD
3(0,j2)−k−1/summationdisplay
l=0c(k)
lEz∆W
3(z,j2;WPD(lε)) +O(ε),
where
c(k)
l=ε2k−1−l/summationdisplay
i=0(1−γε)i=1−(1−γε)k−l
γεε2≤ε
γ.
Similarly for w2,w1, we have:
wPD
2(kε,j 1,j2) =wPD
2(0,j1,j2)−k−1/summationdisplay
l=0c(k)
lEz∆W
2(z,j1,j2;WPD(lε)) +O(ε),
wPD
1(kε,j 1) =wPD
1(0,j1)−k−1/summationdisplay
l=0c(k)
lEz∆W
1(z,j1;WPD(lε)) +O(ε).
We can write analogous expressions for the heavy ball dynamics:
wHB
3(k,j2) =wHB
3(0,j2)−k−1/summationdisplay
l=0c(k)
lEz∆W
3(z,j2;WHB(l)),
wHB
2(k,j1,j2) =wHB
2(0,j1,j2)−k−1/summationdisplay
l=0c(k)
lEz∆W
2(z,j1,j2;WHB(l)),
wHB
1(k,j1) =wHB
1(0,j1)−k−1/summationdisplay
l=0c(k)
lEz∆W
1(z,j1;WHB(l)).(92)
Let us define the following notation, for k∈/braceleftbig
1,...,⌊T
ε⌋/bracerightbig
,
DT(WPD,WHB;k) = max{∥wHB
1(k,j1)−wPD
1(kε,j 1)∥2,
|wHB
2(k,j1,j2)−wPD
2(kε,j 1,j2)|,
|wHB
3(k,j2)−wPD
3(kε,j 2)|:j1∈[n1],j2∈[n2]}}.
Recall that, by construction, wPD
3(0,j2) =wHB
3(0,j2),wPD
2(0,j1,j2) =wHB
2(0,j1,j2)andwPD
1(0,j1) =
wHB
1(0,j1)for allj1,j2. Thus, by computing the difference between wPD
1,wPD
2,wPD
3andwHB
1,wHB
2,wHB
3,
we have thatDT(WPD,WHB;k)satisfies the following induction inequality:
DT(WPD,WHB;k)≤k−1/summationdisplay
l=0c(k)
lK1(γ,T)DT(WPD,WHB;l) +O(ε), (93)
where we have used the Lipschitz continuity of ∆W
3,∆W
2and∆W
1obtained via Lemma A.2. Thus, by the
discrete Gronwall’s lemma, we obtain that, for any k∈/braceleftbig
1,...,⌊T
ε⌋/bracerightbig
,
DT(WPD,WHB;k)≤K2(γ,T)ε
Finally, an application of Lemma D.2 gives that wPD
1,wPD
2,wPD
3areK3(γ,T)-Lipschitz continuous in time.
Thus, for any t≤T,
|wPD
3(t,j2)−wHB
3(⌊t/ε⌋,j2)|≤|wPD
3(t,j2)−wPD
3(⌊t/ε⌋ε,j2)|+|wPD
3(⌊t/ε⌋ε,j2)−wHB
3(⌊t/ε⌋,j2)|
≤|wPD
3(⌊t/ε⌋ε,j2)−wHB
3(⌊t/ε⌋,j2)|+K3(γ,T)ε.
Similar results hold also for |wPD
2(t,j1,j2)−wHB
2(⌊t/ε⌋,j1,j2)|and|wPD
1(t,j1)−wHB
1(⌊t/ε⌋,j1)|. As a result,
we conclude that
DT(WPD,WHB)≤ max
k∈{1,...,⌊T
ε⌋}DT(WPD,WHB;k) +K3(γ,T)ε≤K(γ,T)ε,
which gives the desired result.
39Published in Transactions on Machine Learning Research (02/2023)
D.3 Bound between heavy ball dynamics and stochastic heavy ball dynamics
In this part we bound the difference between the heavy ball dynamics defined in (77) and the stochastic
heavy ball dynamics defined in (75). We recall that the distance we aim to bound is defined in (80).
Proposition D.5. Under Assumptions (B1)-(B3), we have that, with probability at least 1−exp(−δ2),
DT,ϵ(WHB,WSHB)≤K(γ,T)√ε(/radicalbig
D+ log(n1n2) +δ), (94)
whereK(γ,T)is a universal constant depending only on γ,T.
BeforeprovingPropositionD.5,westateandprovearesultconcerningtheboundednessoftheSHBdynamics.
Lemma D.6 (Boundedness of the SHB dynamics) .Under Assumptions (B1)-(B3), we have that, for any
k∈⌊T
ε⌋,
|wSHB
3(k,j2)|≤K/parenleftbigg
1 +1
γ/parenrightbigg
T,
|wSHB
2(k,j1,j2)|≤K/parenleftbigg
1 +1
γ/parenrightbigg/parenleftbigg
1 +T2
γ/parenrightbigg
,
whereKis a universal constant.
Proof.By following passages analogous to those leading to (92), we have that the SHB dynamics can be
written as
wSHB
3(k,j2) =wSHB
3(0,j2)−k−1/summationdisplay
l=0c(k)
l∆W
3(z(l),j2;WSHB(l)),
wSHB
2(k,j1,j2) =wSHB
2(0,j1,j2)−k−1/summationdisplay
l=0c(k)
l∆W
2(z(l),j1,j2;WSHB(l)).(95)
Recall that
∆W
3(z(l),j2;WSHB(l)) =∂2R(y(l),f(x(l);WSHB(l)))·σ2(H2(x(l),j2;WSHB(l))),
which implies that
|∆W
3(z(l),j2;WSHB(l))|=|∂2R(y(l),f(x(l);WSHB(l)))·σ2(H2(x(l),j2;WSHB(l)))|≤K.
Thus, we have
|wSHB
3(k,j2)|≤|wSHB
3(0,j2)|+k−1/summationdisplay
l=0c(k)
lK≤K+kε
γK≤K/parenleftbigg
1 +1
γ/parenrightbigg
T,
where in the last step we use that kε≤T.
For|wSHB
2(k,j1,j2)|, we recall that
|∆W
2(z(l),j1,j2;WSHB(l))|
=|∂2R(y(l),f(x(l);WSHB(l)))·wSHB
3(l,j2)·σ′
2(H2(x(l),j2;WSHB(l)))σ1((wSHB
1(l,j1))Tx(l))|
≤K|wSHB
3(l,j2)|.
Thus, we have
|wSHB
2(k,j1,j2)|≤|wSHB
2(0,j1,j2)|+k−1/summationdisplay
l=0c(k)
l|wSHB
3(l,j2)|
≤K+K/parenleftbigg
1 +1
γ/parenrightbigg
Tkε
γ
≤K/parenleftbigg
1 +1
γ/parenrightbigg/parenleftbigg
1 +T2
γ/parenrightbigg
,
which gives the desired result.
40Published in Transactions on Machine Learning Research (02/2023)
Proof of Proposition D.5. Throughout this argument, we fix εand consider k∈⌊T
ε⌋. Recall that the HB
and SHB dynamics can be written as in (92) and (95), respectively. Furthermore,
wSHB
1(k,j1) =wSHB
1(0,j1)−k−1/summationdisplay
l=0c(k)
l∆W
1(z(l),j1;WSHB(l)). (96)
Recall that, by construction, wHB
3(0,j2) =wSHB
3(0,j2),wHB
2(0,j1,j2) =wSHB
2(0,j1,j2)andwHB
1(0,j1) =
wSHB
1(0,j1)for allj1,j2. Thus, by computing the difference between the expressions in (92) and (95)-(96),
we have
|wHB
3(k,j2)−wSHB
3(k,j2)|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
3(z,j2;WHB(l))]−∆W
3(z(l),j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
3(z,j2;WHB(l))]−Ez[∆W
3(z,j2;WSHB(l))]/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle(97)
+/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
3(z,j2;WSHB(l))]−∆W
3(z(l),j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle,(98)
|wHB
2(k,j1,j2)−wSHB
2(k,j1,j2)|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
2(z,j1,j2;WHB(l))]−∆W
2(z(l),j1,j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
2(z,j1,j2;WHB(l))]−Ez[∆W
2(z,j1,j2;WSHB(l))]/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
(99)
+/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
2(z,j1,j2;WSHB(l))]−∆W
2(z(l),j1,j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle,
(100)
∥wHB
1(k,j1)−wSHB
1(k,j1)∥2=/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
1(z,j1;WHB(l))]−∆W
1(z(l),j1;WSHB(l))/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2
≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
1(z,j1;WHB(l))]−Ez[∆W
1(z,j1;WSHB(l))]/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2(101)
+/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
1(z,j1;WSHB(l))]−∆W
1(z(l),j1;WSHB(l))/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2.(102)
To bound (97), (99) and (101), we use the Lipschitz continuity of ∆W
3,∆W
2and∆W
1, together with the fact
thatc(k)
l≤ε/γ. In particular,
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
3(z,j2;WHB(l))−Ez∆W
3(z,j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤ε
γk−1/summationdisplay
l=0/vextendsingle/vextendsingle/parenleftbig
Ez[∆W
3(z,j2;WHB(l))]−Ez[∆W
3(z,j2;WSHB(l))]/parenrightbig/vextendsingle/vextendsingle
≤K(γ,T)ε
γk−1/summationdisplay
l=0Dlε,ε(WHB,WSHB).(103)
41Published in Transactions on Machine Learning Research (02/2023)
Similarly, we have
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez[∆W
2(z,j1,j2;WHB(l))]−Ez[∆W
2(z,j1,j2;WSHB(l))]/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤K(γ,T)ε
γk−1/summationdisplay
l=0Dlε,ε(WHB,WSHB),
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
1(z,j1;WHB(l))−Ez∆W
1(z,j1;WSHB(l))/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≤K(γ,T)ε
γk−1/summationdisplay
l=0Dlε,ε(WHB,WSHB).
(104)
To bound (102),(100) and (98), we first define the filtration F3(k)as the sigma-algebra generated by
({w3(0,j2)}j2∈[n2],z(0),...,z(k)). We define the filtration F2(k),F1(k)in the same way. Let us recall that,
in a one-pass algorithm, we take i.i.d. samples at each step and, hence, we can write, for all l∈/braceleftbig
1,...,⌊T
ε⌋/bracerightbig
,
Ez(l)/bracketleftbig
∆W
3(z(l),j2;WSHB(l))/vextendsingle/vextendsingleF3(l−1)/bracketrightbig
=Ez∆W
3(z,j2;WSHB(l)),
Ez(l)/bracketleftbig
∆W
2(z(l),j1,j2;WSHB(l))/vextendsingle/vextendsingleF2(l−1)/bracketrightbig
=Ez∆W
2(z,j1,j2;WSHB(l)),
Ez(l)/bracketleftbig
∆W
1(z(l),j1;WSHB(l))/vextendsingle/vextendsingleF1(l−1)/bracketrightbig
=Ez∆W
1(z,j1;WSHB(l)).
Clearly, we have that/braceleftbig
∆W
3(z(l),j2;WSHB(l)),l∈/braceleftbig
1,...,⌊T
ε⌋/bracerightbig/bracerightbig
are mutually independent, which implies
that
∆W
3(z(l),j2;WSHB(l))−Ez∆W
3(z,j2;WSHB(l))
is a martingale difference with respect to the filtration F3(l). Thus,{/summationtextk−1
l=0c(k)
l∆W
3(z(l),j2;WSHB(l))−
Ez∆W
3(z,j2;WSHB(l))|k∈⌊T
ε⌋}is a martingale (same for ∆W
2and∆W
1). Next, we show that the martingale
differences are bounded, so that we can use martingale convergence results to bound these terms.
Combining Lemma D.6 with the same strategy of the a-priori estimations of Lemma A.2, we have the
following upper bounds:
|Ez∆W
3(z,j2;WSHB(k))−∆W
3(z(k),j2;WSHB(k))|≤K1,
|Ez∆W
2(z,j1,j2;WSHB(k)−∆W
2(z(k),j1,j2;WSHB(k)|≤K1(γ,T),
|Ez∆W
1(z,j1;WSHB(k))−∆W
1(z(k),j1;WSHB(k))|≤K1(γ,T).
Thus, an application of Lemma F.2 gives
Pr/bracketleftigg
max
k∈⌊T/ε⌋/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
3(z,j2;WSHB(l))−∆W
3(z(l),j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≥K√
Tϵ(1 +δ3)/bracketrightigg
≤exp(−δ2
3),
Pr/bracketleftigg
max
k∈⌊T/ε⌋/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
2(z,j1,j2;WSHB(l))−∆W
2(z(l),j1,j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≥K(γ,T)√
Tϵ(1 +δ2)/bracketrightigg
≤exp(−δ2
2),
Pr/bracketleftigg
max
k∈⌊T/ε⌋/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
1(z,j1;WSHB(l))−∆W
1(z(l),j1;WSHB(l))/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥K(γ,T)√
Tϵ(√
D+δ1)/bracketrightigg
≤exp(−δ2
1).
42Published in Transactions on Machine Learning Research (02/2023)
By taking a union bound over j1,j2, we have that, with probability at least 1−exp(−δ2),
max
j1,j2max
k∈⌊T/ε⌋/braceleftigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
3(z,j2;WSHB(l))−∆W
3(z(l),j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle,
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
2(z,j1,j2;WSHB(l))−∆W
2(z(l),j1,j2;WSHB(l))/parenrightbig/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle,
/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddoublek−1/summationdisplay
l=0c(k)
l/parenleftbig
Ez∆W
1(z,j1;WSHB(l))−∆W
1(z(l),j1;WSHB(l))/parenrightbig/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2/bracerightigg
≤K(γ,T)√
Tϵ(/radicalbig
Dlog(n1n2) +δ).
Combining the results, we conclude that, with probability at least 1−exp(−δ2),
DT,ε(WHB,WSHB)≤K(γ,T)√
Tϵ(/radicalbig
Dlog(n1n2) +δ) +K(γ,T)ε
γk−1/summationdisplay
l=0Dlε,ε(WHB,WSHB).
An application of the discrete Gronwall’s lemma gives the desired result (94) and concludes the proof.
D.4 Proof of Theorem 5.2
Proof of Theorem 5.2. The proof follows from combining Proposition D.1, D.4, D.5 and the fact that:
DT(W,WSHB)≤DT(W,WPD) +DT(WPD,WHB) +DT,ε(WHB,WSHB).
E Global convergence of the mean-field ODE
In this section, we aim to prove the global convergence result through the recipe below:
1. We show the following degeneracy property for the mean-field ODE: there exist deterministic func-
tionsw∗
1(·,·) :R≥0×RD− →RD,w∗
2(·,·,·,·) :R≥0×RD×R×R− →R,w∗
3(·,·) :R≥0×R− →Rsuch
that
w1(t,C1) =w∗
1(t,w1(0,C1)),
w2(t,C1,C2) =w∗
2(t,w1(0,C1),w2(0,C1,C2),w3(0,C2)),
w3(t,C2) =w∗
3(t,w3(0,C2)).(105)
2. We show that (i)w∗
1(·,·)is continuous in both arguments for any finite t, and that (ii)ifw1(0,C1)
is full support, then w1(t,C1)is full support for any finite t.
3. Combining the argument that w1(t,C1)is full support for all finite tand the mode of convergence
assumption, we show that the mean-field ODE must converge to the global minimum.
We first show the degeneracy property of the mean-field ODE in the following lemma:
Lemma E.1. Under Assumptions (B1) - (B3), there exist deterministic functions w∗
1(·,·) :R≥0×RD− →
RD,w∗
2(·,·,·,·) :R≥0×RD×R×R− →R,w∗
3(·,·) :R≥0×R− →Rsuch that
w1(t,C1) =w∗
1(t,w1(0,C1)),
w2(t,C1,C2) =w∗
2(t,w1(0,C1),w2(0,C1,C2),w3(0,C2)),
w3(t,C2) =w∗
3(t,w3(0,C2)).
43Published in Transactions on Machine Learning Research (02/2023)
Proof of Lemma E.1. We follow the proof in (Pham & Nguyen, 2021a, Appendix D.2). To shorten
the notations, we make the following definition: we define the sigma-algebras generated by
w1(0,C1)),(w1(0,C1),w2(0,C1,C2),w3(0,C2)),w3(0,C2)asS1,S123,S3respectively. The lemma is equiva-
lent to prove that w1(t,C1),w2(t,C1,C2),w3(t,C2)areS1,S123,S3-measurable, respectively.
In order to prove the measurability result, we define a reduced dynamics as follows:
wRD
3(t,c2) =wRD
3(0,c2)−γ/integraldisplayt
0(wRD
3(s,c2)−wRD
3(0,c2))ds−/integraldisplayt
0/integraldisplays
0E/bracketleftbig
∆W
3(z,C2;W(u))|S3/bracketrightbig
duds,
wRD
2(t,c1,c2) =wRD
2(0,c1,c2)−γ/integraldisplayt
0(wRD
2(s,c1,c2)−wRD
2(0,c1,c2))ds
−/integraldisplayt
0/integraldisplays
0E/bracketleftbig
∆W
2(z,C1,C2;W(u))|S123/bracketrightbig
duds,
wRD
1(t,c1) =wRD
1(0,c1)−γ/integraldisplayt
0(wRD
1(s,c1)−wRD
1(0,c1))ds−/integraldisplayt
0/integraldisplays
0E/bracketleftbig
∆W
1(z,C1;W(u))|S1/bracketrightbig
duds.
Note the reduced dynamics wRD
1,wRD
2,wRD
3is clearlyS1,S123,S3-measurable. Furthermore, the re-
duced dynamics is not self-contained, in the sense that the gradient terms E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
,
E/bracketleftbig
∆W
2(z,C1,C2;W(t))|S123/bracketrightbig
andE/bracketleftbig
∆W
1(z,C1;W(t))|S1/bracketrightbig
are induced by the mean-field ODE W(t).
In order to state the next result, we define the following metric:
DT(W,W′) = max/braceleftbig
sup
t∈[0,T]ess sup
c1∥w1(t,c1)−w′
1(t,c1)∥2,
sup
t∈[0,T]ess sup
c1,c2|w2(t,c1,c2)−w′
2(t,c1,c2)|,
sup
t∈[0,T]ess sup
c2|w3(t,c2)−w′
3(t,c2)|/bracerightbig
.
Next, we aim to show that the reduced dynamics is equivalent to the mean-field ODE, i.e., for any T >0,
DT(W,WRD) = 0.
The key step is to prove that
ess sup sup
t∈[0,T]|E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
−Ez∆W
3(z,C2;W(t))|≤K(γ,T)DT(W,WRD),(106)
ess sup sup
t∈[0,T]|E/bracketleftbig
∆W
2(z,C1,C2;W(t))|S123/bracketrightbig
−Ez∆W
2(z,C1,C2;W(t))|≤K(γ,T)DT(W,WRD),(107)
ess sup sup
t∈[0,T]∥E/bracketleftbig
∆W
1(z,C1;W(t))|S1/bracketrightbig
−Ez∆W
1(z,C1;W(t))∥2≤K(γ,T)DT(W,WRD),(108)
whereK(γ,T)is a universal constant depending only on T,γ. Here,|E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
−
Ez∆W
3(z,C2;W(t))|is a random variable, and the ess supin (106) is taken with respect to it. The same
remark applies to the ess supin (107) and in (108), which are intended to be taken with respect to the
corresponding random variables.
We now prove that (106) holds. Note that
|E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
−Ez∆W
3(z,C2;W(t))|≤|E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
−E/bracketleftbig
∆W
3(z,C2;WRD(t))|S3/bracketrightbig
|
+|E/bracketleftbig
∆W
3(z,C2;WRD(t))|S3/bracketrightbig
−Ez∆W
3(z,C2;WRD(t))|
+|Ez∆W
3(z,C2;WRD(t))−Ez∆W
3(z,C2;W(t))|.
(109)
Using the Lipschitz continuous property of ∆W
3, we have that:
|E/bracketleftbig
∆W
3(z,C2;W(t))|S3/bracketrightbig
−E/bracketleftbig
∆W
3(z,C2;WRD(t))|S3/bracketrightbig
|≤K(γ,T)DT(W,WRD),
|∆W
3(z,C2;WRD(t))−∆W
3(z,C2;W(t))|≤K(γ,T)DT(W,WRD).(110)
44Published in Transactions on Machine Learning Research (02/2023)
By following the argument in (Pham & Nguyen, 2021a, Appendix D.2) (which does not depend on the
dynamics, but only on the structure of the gradient), we have that Ez∆W
3(z,C2;WRD(t))isS3-measurable,
i.e.,
|E/bracketleftbig
∆W
3(z,C2;WRD(t))|S3/bracketrightbig
−Ez∆W
3(z,C2;WRD(t))|= 0. (111)
By combining (109), (110) and (111), we obtain that (106) holds. The arguments giving (107) and (108) are
analogous.
From this, we can compute the difference between the reduced dynamics and the mean-field ODE as
DT(W,WRD)≤γ/integraldisplayT
0Ds(W,WRD)ds+K(γ,T)/integraldisplayT
0/integraldisplays
0Du(W,WRD)dvds,
which, after applying Corollary F.4, gives that DT(W,WRD) = 0. This implies that W=WRDand,
hence,w1(t,C1),w2(t,C1,C2),w3(t,C2)areS1,S123,S3-measurable, respectively.
Next, we show the continuity of the function w∗
1(·,·) :R≥0×RD− →RDin both arguments.
Lemma E.2. Under Assumptions (B1) - (B3), we have that, for all t∈[0,T]and for allu1,u′
1∈RD,
∥w∗
1(t,u1)−w∗
1(t′,u1)∥2≤K(γ,T)|t−t′|, (112)
∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2≤K(γ,T)∥u1−u′
1∥2. (113)
Proof.In order to prove the lemma, we first need to derive the dynamics that characterize the evolution of
the functions w∗
1(t,u1),w∗
2(t,u1,u2,u3),w∗
3(t,u3). This dynamics is induced by the mean-field ODE, whose
form we recall below:
w3(t,c2) =w3(0,c2)−γ/integraldisplayt
0(w3(s,c2)−w3(0,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(z,c2;W(v))dvds, (114)
w2(t,c1,c2) =w2(0,c1,c2)−γ/integraldisplayt
0(w2(s,c1,c2)−w2(0,c1,c2))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
2(z,c1,c2;W(v))dvds,
(115)
w1(t,c1) =w1(0,c1)−γ/integraldisplayt
0(w1(s,c1)−w1(0,c1))ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(z,c1;W(v))dvds. (116)
Recall also that w3(t,c2) =w∗
3(t,w3(0,c2)). Thus, in order to get the dynamics of w∗
3(t,u3), we replace
w3(0,c2)byu3,w2(0,c1,c2)byu2, andw1(0,c1)byu1into (114). By doing the same replacements into
(115) and (116) for w2(t,c1,c2)andw1(t,c1), respectively, we obtain
w∗
3(t,u3) =u3−γ/integraldisplayt
0(w∗
3(s,u2)−u3)ds−/integraldisplayt
0/integraldisplays
0Ez∆W
3(v,z,u3)dvds,
w∗
2(t,u1,u2,u3) =u2−γ/integraldisplayt
0(w∗
2(s,u1,u2,u3)−u2)ds−/integraldisplayt
0/integraldisplays
0Ez∆W
2(v,z,u1,u2,u3)dvds,
w∗
1(t,u1) =u1−γ/integraldisplayt
0(w∗
1(s,u1)−u1)ds−/integraldisplayt
0/integraldisplays
0Ez∆W
1(v,z,u1)dvds,
where we have the following modified forward and backward paths:
H1(t,x,u1) = (w∗
1(t,u1))Tx,
H2(t,x,u3) =Eu1∼ρ1
0,u2∼ρ2
0w∗
2(t,u1,u2,u3)σ1(H1(t,x,u1)),
f(x;W(t)) =Eu3∼ρ3
0w3(t,u3)H2(t,x,u3),
∆W
3(t,z,u3) =∂2R(y,f(x;W(t)))σ2(H2(t,x,u3)),
∆W
2(t,z,u1,u2,u3) =∂2R(y,f(x;W(t)))w3(t,u3)σ′
2(H2(t,x,u3))σ1(H1(t,x,u1)),
∆W
1(t,z,u1) =Eu2,u3∂2R(y,f(x;W(t)))w3(t,u3)σ′
2(H2(t,x,u3))w2(t,u1,u2,u3)σ′
1(H1(t,x,u1))x.
45Published in Transactions on Machine Learning Research (02/2023)
Thus, we have that
∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2≤(1 +γt)∥u1−u′
1∥2+γ/integraldisplayt
0∥w∗
1(s,u1)−w∗
1(s,u′
1)∥2ds
+/integraldisplayt
0/integraldisplays
0∥Ez∆W
1(v,z,u1)−Ez∆W
1(v,z,u′
1)∥2dvds. (117)
An application of Lemma A.2 gives that
∥Ez∆W
1(v,z,u1)−Ez∆W
1(v,z,u′
1)∥2≤K1(γ,T)(|w∗
2(v,u1,u2,u3)−w∗
2(v,u′
1,u2,u3)|
+∥w∗
1(v,u1)−w∗
1(v,u′
1)∥2).(118)
Similarly for w∗
2, we have that
|w∗
2(t,u1,u2,u3)−w∗
2(t,u′
1,u2,u3)|≤γ/integraldisplayt
0|w∗
2(s,u1,u2,u3)−w∗
2(s,u′
1,u2,u3)|ds
+/integraldisplayt
0/integraldisplays
0∥Ez∆W
2(v,z,u1,u2,u3)−Ez∆W
2(v,z,u′
1,u2,u3)∥2dvds,
(119)
and another application of Lemma A.2 gives that
∥Ez∆W
2(v,z,u1,u2,u3)−Ez∆W
2(v,z,u′
1,u2,u3)∥2≤K2(γ,T)(|w∗
2(v,u1,u2,u3)−w∗
2(v,u′
1,u2,u3)|
+∥w∗
1(v,u1)−w∗
1(v,u′
1)∥2).(120)
By combining (117), (118), (119) and (120), we obtain
|w∗
2(t,u1,u2,u3)−w∗
2(t,u′
1,u2,u3)|+∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2
≤(1 +γt)∥u1−u′
1∥2+γ/integraldisplayt
0(|w∗
2(s,u1,u2,u3)−w∗
2(s,u′
1,u2,u3)|+∥w∗
1(s,u1)−w∗
1(s,u′
1)∥2)ds
+K3(γ,T)/integraldisplayt
0/integraldisplays
0(|w∗
2(v,u1,u2,u3)−w∗
2(v,u′
1,u2,u3)|+∥w∗
1(v,u1)−w∗
1(v,u′
1)∥2)dvds.
Thus, by Corollary F.4, we have that:
|w∗
2(t,u1,u2,u3)−w∗
2(t,u′
1,u2,u3)|+∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2≤K4(γ,T)∥u1−u′
1∥2,
which implies that ∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2≤K4(γ,T)|u1−u′
1|, and concludes the proof of (113). The
Lipschitz continuity (112) of w∗
1(t,u1)is already proved in Lemma D.2.
At this point, we show that, if w1(0,c1) : Ω− →RDhas full support, then w∗
1(t,u1)has full support.
Lemma E.3. Under Assumptions (B1)-(B3) and Assumption 7.1, we have that w∗
1(t,u1)has full support
for anyt<∞.
Proof.By the continuity argument in Lemma E.2, we have that
∥w∗
1(t,u1)−u1∥2=∥w∗
1(t,u1)−w∗
1(0,u1)∥2≤K(γ,T)t, (121)
∥w∗
1(t,u1)−w∗
1(t,u′
1)∥2≤K(γ,T)∥u1−u′
1∥2. (122)
We want to show that, for any x∈RD, there exist a vsuch thatw∗
1(t,v) =x. For anyx∈RD, define a
mapgx(t,v) =x−(w∗
1(t,v)−v). It is easy to see that if va fixed point of gx(t,·), thenw∗
1(t,v) =xas
gx(t,v) =v⇐⇒x−(w∗
1(t,v)−v) =v⇐⇒w∗
1(t,v) =x.
By (121), we have that gx(t,·) :RD− →B (x,K(γ,T)t), whereB(x,K(γ,T)t)is the closed ball centered
atxwith radius K(γ,T)t. Now, if we restrict gx(t,v)onB(x,K(γ,T)t), we have that it is a map from
B(x,K(γ,T)t), which is a compact set, to itself. Furthermore, gx(t,v)is continuous in v, sincew∗
1(t,v)is
continuous in vby (122). Thus, by the Brouwer fixed point theorem, we have that there exist a fixed point
v∈B(x,K(γ,T)t), which finishes the argument.
46Published in Transactions on Machine Learning Research (02/2023)
Finally, we are ready to prove the main theorem. Our proof follows similar steps as that of (Pham & Nguyen,
2021a, Proof of Theorem 8).
Proof of Theorem 7.2. By Assumption 7.1, we have that
lim
t− →∞ess sup
C1EC2[|Ez∆W
2(z,C1,C2;W(t))|] = 0.
By the definition of ∆W
2(t,z,C1,C2), we have
lim
t− →∞ess sup
C1EC2[|Ez∆H
2(z,C2;W(t))σ1(w1(t,C1)Tx)|] = 0.
Recall from Lemma E.3 that, for all finite t,w1(t,C1)has full support. Hence, we have that, for u1in a
dense subset of RD,
lim
t− →∞EC2[|Ez∆H
2(z,C2;W(t))σ1(uT
1x)|] = 0.
Our aim is to conclude that, for almost all x, we have that Ez[∂2R(y,f(x;W(∞)))|x] = 0. By definition of
the backward path, we have that
EC2[/vextendsingle/vextendsingleEz∆H
2(z,C2;W(t))σ1(uT
1x)/vextendsingle/vextendsingle−/vextendsingle/vextendsingleEz∆H
2(z,C2;W(∞))σ1(uT
1x)/vextendsingle/vextendsingle]
≤EC2[/vextendsingle/vextendsingle/parenleftbig
Ez∆H
2(z,C2;W(t))−Ez∆H
2(z,C2;W(∞))/parenrightbig
σ1(uT
1x)/vextendsingle/vextendsingle]
≤KEC2[Ez/bracketleftbig/vextendsingle/vextendsingle∆H
2(z,C2;W(t))−∆H
2(z,C2;W(∞))/vextendsingle/vextendsingle/bracketrightbig
]
≤KEC1,C2/bracketleftbig
(1 +|w3(∞,C2)|)·/parenleftbig
|w3(∞,C2)−w3(t,C2)|+|w3(∞,C2)|·|w2(∞,C1,C2)−w2(t,C1,C2)|
+|w3(∞,C2)|·|w2(∞,C1,C2)|·∥w1(∞,C1)−w1(t,C1)∥2/parenrightbig/bracketrightbig
.
By Assumption 7.1, the RHS of (123) converges to 0ast→∞. Hence, by taking the limit on both sides,
we have that, for u1in a dense subset of RD,
EC2[|Ez∆H
2(z,C2;W(∞))σ1(uT
1x)|] = lim
t− →∞EC2[|Ez∆H
2(z,C2;W(t))σ1(uT
1x)|] = 0,
which implies that, for almost all c2,
/vextendsingle/vextendsingleEz∆H
2(z,C2;W(∞))σ1(uT
1x)/vextendsingle/vextendsingle= 0.
By definition of ∆H
2(z,C2;W(∞))we have that, for almost all c2,
Ez/bracketleftbig
∂2R(y,f(x;W(∞)))w3(∞,c2)σ′
2(H2(x,c2;W(∞)))σ1(uT
1x)/bracketrightbig
= 0. (123)
Note that Assumption (B1) gives that σ′
2̸= 0, and Assumption 7.1 that w3(∞,c2)̸= 0with probability >0
(where the probability is intended over c2). Hence, we have that, with probability >0(overc2),
Ez/bracketleftbig
∂2R(y,f(x;W(∞)))σ′
2(H2(x,c2;W(∞)))σ1(uT
1x)/bracketrightbig
= 0. (124)
Recall that σ1(uT
1x)is a function of x, but∂2R(y,f(x;W(∞)))depends on both yandx. Thus, we can
re-write (124) as
Ex/bracketleftbig
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))σ1(uT
1x)/bracketrightbig
= 0. (125)
Now, we want to use the universal approximation property of σ1to conclude that, for almost every x,
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞))) = 0. (126)
47Published in Transactions on Machine Learning Research (02/2023)
The idea is that linear combinations of σ1(uT
1x)can approximate any function in L2(Dx). Thus, if
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))is inL2(Dx), we have that there exist a sequence of in-
dex sets{Ik}k∈N, such that:
lim
k− →∞Ex
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEy/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))−/summationdisplay
ik∈Ikaikσ1(uT
ikx)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
= 0.
To simplify the notation, we define:
g(x) =Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞))),
hk(x) =/summationdisplay
ik∈Ikaikσ1(uT
ikx).
From (125) and by linearity of expectation, we have that, for all k,
Ex[g(x)hk(x)] = 0.
Thus we have
0 = lim
k− →∞Ex/bracketleftig
|g(x)−hk(x)|2/bracketrightig
= lim
k− →∞Ex/bracketleftig
|g(x)|2+|hk(x)|2−2g(x)hk(x)/bracketrightig
= lim
k− →∞Ex/bracketleftig
|g(x)|2+|hk(x)|2/bracketrightig
,
which implies that
Ex/bracketleftig
|g(x)|2/bracketrightig
= 0.
Hence, we have that
Ex/bracketleftbig/vextendsingle/vextendsingleEy/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))/vextendsingle/vextendsingle2/bracketrightbig
= 0,
which implies that (126) holds. Furthermore, to see that Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))
is indeed inL2(Dx), it suffices to note that, by Assumption 3.3,
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
σ′
2(H2(x,c2;W(∞)))≤K2.
By Assumption 3.3, we also have that σ′
2(x)̸= 0for allx. Hence, (126) implies that, for almost every x,
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))|x/bracketrightbig
= 0. (127)
Since the loss is convex in f(x;W(∞)), we have
Ez/bracketleftbig
R(y,/tildewidef(x))−R(y,f(x;W(∞)))/bracketrightbig
≥Ex/bracketleftbig
Ey/bracketleftbig
∂2R(y,f(x;W(∞)))/vextendsingle/vextendsinglex/bracketrightbig
(/tildewidef(x)−f(x;W(∞)))/bracketrightbig
= 0,
where the last passage follows from (127). Thus, we conclude that
EzR(y,f(x;W(∞))) = inf
/tildewidefEz/bracketleftbig
R(y,/tildewidef(x))/bracketrightbig
. (128)
Finally, we want to show that
lim
t− →∞EzR(y,f(x;W(t))) =EzR(y,f(x;W(∞))). (129)
48Published in Transactions on Machine Learning Research (02/2023)
To see this, we write
|EzR(y,f(x;W(t)))−EzR(y,f(x;W(∞)))|
≤KEz|f(x;W(t))−f(x;W(∞))|
≤KEC1,C2/bracketleftbig
|w3(∞,C2)−w3(t,C2)|+|w3(∞,C2)|·|w2(∞,C1,C2)−w2(t,C1,C2)|
+|w3(∞,C2)|·|w2(∞,C1,C2)|·∥w1(∞,C1)−w1(t,C1)∥2/bracketrightbig
,
and use again Assumption 7.1. By combining (128) and (129), we obtain the desired result.
F Technical lemmas
Lemma F.1 (Corollary of McDiarmid inequality) .(Mei et al., 2019, Lemma 30)
Let{Xi}i∈[n]∈Rdbe a sequence of i.i.d random variables, with ∥Xi∥2≤KandE[Xi] = 0, then we have:
Pr/parenleftigg/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble1
nn/summationdisplay
i=1Xi/vextenddouble/vextenddouble/vextenddouble/vextenddouble/vextenddouble
2≥K(/radicalbig
1/n+z)/parenrightigg
≤exp (−nz2).
Lemma F.2 (Azuma-Hoeffding bound) .(Mei et al., 2019, Lemma 31) Let (Xk)k≥0be a martingale taking
values in RDwith respect to the filtration (Fk), withX0= 0. Assume that the martingale difference at time
kisLk-subgaussian, which means the following holds almost surely for all λ∈RD:
E[exp{⟨λ,Xk−Xk−1⟩}|Fk−1]≤exp/braceleftbiggL2
k∥λ∥2
2/bracerightbigg
.
Then, we have
Pr
max
k∈[n]∥Xk∥2≥2/radicaltp/radicalvertex/radicalvertex/radicalbtn/summationdisplay
k=1L2
k/parenleftig√
D+δ/parenrightig
≤exp{−δ2}.
Note that, if Lk≤Lfor allk, then
Pr/bracketleftbigg
max
k∈[n]∥Xk∥2≥2√
nL2/parenleftig√
D+δ/parenrightig/bracketrightbigg
≤exp{−δ2}.
Lemma F.3 (Pachpatte’s inequality) .(Ames & Pachpatte, 1997, Chapter 1, Theorem 1.7.1)
Letu,fandgbe non-negative continuous functions defined on [0,T], for which the inequality
u(t)≤u0+/integraldisplayt
0f(s)u(s)ds+/integraldisplayt
0f(s)/parenleftbigg/integraldisplays
0g(r)u(r)dr/parenrightbigg
ds
holds, where u0is a non-negative constant. Then we have:
u(t)≤u0/bracketleftbigg
1 +/integraldisplayt
0f(s) exp/parenleftbigg/integraldisplays
0(g(r) +f(r))dr/parenrightbigg
ds/bracketrightbigg
.
Corollary F.4 (Pachpatte’s inequality for constants) .Letube a non-negative continuous function defined
on[0,T], andγ,Kbe positive real numbers. Assume the following inequality holds:
u(t)≤u0+γ/integraldisplayt
0u(s)ds+K/integraldisplayt
0/integraldisplays
0u(r)drds.
Then, we have
u(t)≤u0/parenleftbigg
1 +γ2
γ2+Kexp/parenleftbiggγ2+K
γt/parenrightbigg/parenrightbigg
≤u0/parenleftbigg
1 + exp/parenleftbiggγ2+K
γt/parenrightbigg/parenrightbigg
.
49