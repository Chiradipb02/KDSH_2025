Communicating with Speakers and Listeners of Different Pragmatic Levels
Kata Naszádi1and Frans A. Oliehoek2and Christof Monz1
1Language Technology Lab, University of Amsterdam
2Delft University of Technology
k.naszadi@uva.nl
Abstract
This paper explores the impact of variable prag-
matic competence on communicative success
through simulating language learning and con-
versing between speakers and listeners with
different levels of reasoning abilities. Through
studying this interaction, we hypothesize that
matching levels of reasoning between commu-
nication partners would create a more benefi-
cial environment for communicative success
and language learning. Our research findings
indicate that learning from more explicit, literal
language is advantageous, irrespective of the
learner’s level of pragmatic competence. Fur-
thermore, we find that integrating pragmatic
reasoning during language learning, not just
during evaluation, significantly enhances over-
all communication performance. This paper
provides key insights into the importance of
aligning reasoning levels and incorporating
pragmatic reasoning in optimizing communica-
tive interactions.
1 Introduction
In everyday conversations there is a trade-off be-
tween clarity and conciseness. Efficient messages
might appear under-specified or ambiguous un-
der a literal interpretation but can be success-
fully resolved using pragmatic reasoning about the
speaker’s intentions and the context of the commu-
nication (Grice, 1975; Horn, 1984; Fox and Katzir,
2011; Davies et al., 2022). If the speaker trusts
the listener to make the right inferences, they can
choose to be more concise. Being able to infer the
intended meaning of an utterance beyond its literal
content allows us to communicate efficiently.
The process of how people attain pragmatic inter-
pretations using a model of the speaker’s intentions
has long been studied. There is also plenty of evi-
dence from psycho-linguistic studies that individu-
als have different levels of pragmatic competence
(Franke and Degen, 2016; Mayn et al., 2023). More
importantly, people have been shown to keep track
Figure 1: The speaker is asking for the red object. For a
literal listener, this is ambiguous. A reasoning listener
considers alternative messages about shape and color
features and concludes that the speaker is asking for
the red circle, as ”square" would have been a more
informative message for the other red object.
of the communicative partner’s pragmatic compe-
tence and adjust their interpretations and messag-
ing accordingly. This has been demonstrated both
with human (Horton and Gerrig, 2002; Mayn et al.,
2024) and artificial partners (Loy and Demberg,
2023; Branigan et al., 2011).
The pragmatic reasoning modeled in this work
involves counterfactual reasoning about alternative
sentences that the speaker could have uttered . The
interaction in Figure 1 depicts an instance of such
pragmatic reasoning about alternatives within our
simple environment. According to pragmatic the-
ory (Grice, 1975) the same process accounts for the
interpretation "They are in the office for the rest of
the week", when we hear the sentence "We are not
in the office on Mondays".
In this work, we investigate the impact of varying
pragmatic competence on communicative success.
We pair literal and pragmatic listeners with speak-
ers of different levels of pragmatic competence.
We study the interaction between such speakers
and listeners not only during inference, where botharXiv:2410.05851v1  [cs.CL]  8 Oct 2024partners have an already learned lexicon, but also
during language learning. This way we gain in-
sight into optimal levels of pragmatic inference for
teachers and language learners. We hypothesise
that matching levels of reasoning between part-
ners benefits communicative success and language
learning.
Our simulations reveal that with a lexicon that
doesn’t perfectly match that of the speaker’s, so-
phisticated pragmatic listeners still significantly
benefit from explicit literal language use. We also
show that language learners that do not model prag-
matic inference, struggle when learning from a
speaker who uses pragmatic communication, while
language learners that integrate a model of the
speaker are significantly more successful.
2 Background
We situate our listener in an image-based version
of Lewis’s signaling game (Lewis, 1969). Image-
referential games are commonly used to study the
benefit of speakers and listeners reasoning about
each other in context (Lee et al., 2018; White et al.,
2020; Andreas and Klein, 2016).
At each turn a collection of N images is pro-
vided as context C=(o1, ..., o N), with the speaker
having knowledge of a specific target image ot,
where 1≤t≤N. The listener’s objective is to
correctly identify the target image index tgiven the
speaker’s message w. The messages may contain
multiple words by combining words from a fixed
vocabulary.
2.1 Literal meanings and the Rational Speech
Act model
Frank and Goodman (2012) provide a concise
model for how speakers and listeners reason about
each-other when sharing referential content. As a
starting point, the model assumes an underlying
literal interpretation. This is a function D(w, o)of
an utterance wand an observation o, in our case an
image. In the original formulation the base inter-
pretation function is a 0-1 valued indicator of the
set of messages that are true of the image o. In line
with other work, we replace this binary function
with a real-valued similarity between the observed
image-embedding and text-embedding.
D(oi, w)=CNN θ(oi)TRNN θ(w) (1)
Each image oiis individually embedded with a
CNN following the ResNet architecture (He et al.,2016). The embedding if the message wis com-
puted by an RNN with Gated Recurrent Units (Cho
et al., 2014).
The listener models the distribution over the in-
dices in an ordered set of images. The simplest
listener distribution is produced by normalizing
the score assigned by literal interpretation function
over all the images in a given context C.
L0(i∣w, C )=eD(oi,w)
∑∣C∣
j=1eD(oj,w)(2)
The speaker produces a message that maximizes
the probability that the listener chooses the right
image and also considers the cost of each message
w. This means that the speaker has an internal
model of the listener.
Sn(w∣C, i)=eλ(log(Ln−1(i∣C,w))−cost(w))
∑w′∈Veλ(log(Ln−1(i∣C,w′))−cost(w′))
(3)
In this work, we use a cost function that assigns
a constant weight to each word and we only con-
sider fully rational speakers with λ=1. In the
case of the speaker, the normalization happens over
all possible messages w∈V. This is the most
expensive step in the hierarchical reasoning pro-
cess. In many natural language applications it is
even prohibited by the fact that the set of all pos-
sible utterances is infinite. While exact inference
is intractable, there are many papers discussing ap-
proximations (Cohn-Gordon et al., 2018; Liu et al.,
2023; Lazaridou et al., 2020; White et al., 2020). In
our communication-game, messages may contain
one or two words: naming either the shape or the
color of the target or both.
Building on 3, higher level listeners have an in-
ternal model of a speaker:
Ln(i∣C, w )∝Sn−1(w∣C, i)P(C, i) (4)
By applying Equations 3 and 4 in an alternating
fashion, we can produce higher level speakers and
listeners.
The most studied levels in the case of human
communication are L0literal and L2pragmatic
listeners paired with S1andS3speakers. This is
motivated by evidence that humans can interpret
messages from a S3speaker consistent with a L2
listener (Goodman and Frank, 2016) and multiple
pragmatic phenomona have been derived using the
RSA framing and these levels (Franke and Degen,
2016; Hawkins et al., 2023).2.2 Reasoning while learning
In the previous subsection 2.1 we saw how to per-
form recursive reasoning on top of given literal
representations D(o, w). These literal interpreta-
tions are most commonly initialized by functions
learned outside of the context of a referential game
and the reasoning is added only during inference
(Fried et al., 2018; Lazaridou et al., 2020; Andreas
and Klein, 2016; Liu et al., 2023).
However, the optimal literal representations are
likely influenced by the reasoning itself. Following
the work of Monroe and Potts (2015) and McDow-
ell and Goodman (2019), we would like to inte-
grate the knowledge that the received messages are
the result of pragmatic reasoning already during
learning. Therefore, we apply recursive reasoning
during model training.
Pragmatic listeners seek to update the weights
of the literal interpretation D(o, w)but they need
to do so by considering the repeated application
of Equations 3 and 4. Similarly to McDowell
and Goodman (2019), we derive the gradients of
the reasoning process with respect to the lexicon
weights. By repeated application of the chain rule
through the hierarchical reasoning, pragmatic lis-
teners backpropagate through the hierarchical rea-
soning and update the weights of the image- and
utterance-embedding models.
3 Data
To investigate the impact of the pragmatic compe-
tence of speakers and listeners on communicative
success, it is necessary to establish a controlled set-
ting that allows for manipulation of the reasoning
abilities of participants. We create a new environ-
ment based on the ShapeWorld dataset (Kuhnle and
Copestake, 2017). Instead of the rule based method
of Kuhnle and Copestake (2017), we use an exact
implementation of the rational speaker defined in
Equation 3. This way we can create speakers with
different depth of recursive reasoning. Our speak-
ers are not learned, they are knowledgeable users
of the language: they have access to the underlying
true lexicon which indicates the mapping between
color and shape words and image properties.
Each game consists of a target image and a vari-
able number of N−1distractor images. Images
are described by one out of six different colors and
a shape that can take five different values. The loca-
tion, size and rotation of the objects is randomized
on a 64x64 grid which creates a large variation ofcandidate pictures.
We parameterize the process that generates the
image tuples for each game by four probability
distributions: the priors over the shapes P(S)and
colors P(C), the probability that controls the corre-
lations between colors P(C∣C)and the conditional
defining the co-occurrence of shapes P(S∣S). We
sample these distributions from different Dirichlet-
distributions. We create two sets of concentration
parameters: in the first version of the game, all sam-
pled distributions are close to uniform ( Corr=0),
while in the second version introduces correlations
in the shape and color conditionals ( Corr=1).
This way the sampled image tuples share more
features, creating higher likelihood for pragmatic
messaging that differentiates S1andS3.
For training, we sample only one instance of
each distribution. At test time, we sample different
P(S),P(C),P(S∣S)andP(C∣C)instances 10
times. From each of these constellations we sample
3200 games.
The random seed is fixed across all experiments
and is reset for the learning and evaluation of each
learner. This ensures that each listener sees the
exact same examples in all environments.
4 Experiments
The fact that we have full control over the speaker’s
messaging strategy and the data generating process
allows us to alter the level of the speakers that the
listeners learn from and create image tuples that
highlight the contrast between higher level prag-
matic and lower level literal messaging strategies.
We train train L0literal listeners and L2prag-
matic listeners. We create two different levels of
speakers to pair them with our learning listeners:
S1has an internal model of a competent L0, while
S3anticipates L2-behavior.
Implementation for training and eval-
uating all models can be found at
https://github.com/naszka/rsa_backward/.
4.1 Results
In this section, we present the insights gained from
simulating language learning and communication
between listeners and speakers with pragmatic or
literal preferences. First we look at altering speaker
and listener levels only during evaluation using
an already trained lexicon. Then we turn to the
learning dynamics between our four pairs: L0-S1,
L0-S3,L2-S1andL2-S3.Distractors S1 S3
2 1.07 1.01
3 1.14 1.02
4 1.24 1.09
Table 1: Average message length in words over 5000
samples for different number of distractors and speaker
levels, Corr=1. Higher level speakers send shorter
messages and more distractors result in longer mes-
sages.
Listener eval Speaker eval Accuracy
a) 0 3 80.5
b) 2 3 81.2**
c) 0 1 85.5
d) 2 1 85.6
Table 2: A listener trained as L0upgraded to different
listener levels and paired with S1orS3at evaluation.
Both L0andL2perform significantly better with the
more verbose S1. When receiving messages from an S3,
the higher level L2is significantly better. Evaluation
setup: cost=0.6,N=5,Corr=1.
Listening to speakers with different depth First
we take the L0listener which learned in the easi-
est environment ( S1,Corr=0,N=3) hence has
the highest in-domain performance of 91.2%accu-
racy. During evaluation, we upgrade this listener
to different levels: this means that during inference
we apply recursive reasoning on top of the already
learned L0lexicon. We pair these listeners with
S1andS3. Table 2 shows that pragmatic L2is
significantly1better than literal L0when paired
withS3. At the same time, L2still achieves the
best performance with the more verbose S1, this
is due to the fact that the listener did not learn the
word-feature mapping with perfect accuracy and
they still benefit from the more descriptive input.
We picked the evaluation parameters shown in
Table 2 to maximize the speaker-type effect. The
same trends hold for different number of distrac-
tors.
Learning from speakers with different depth
Now we turn to how listeners of different levels are
impacted by learning from different speakers.
Table 3 shows that reasoning learners that
learned from lower level speakers always achieve
higher accuracy at evaluation. This can be ex-
1We perform Fisher’s exact test for significance testing.
We note p<0.05with one asterisk * and for p<0.01we put
** next to the results.Listener Speaker train Accuracy
a)01 80.7**
b) 3 79.1
c)21 84.8**
d) 3 83.2
Table 3: For each level of listener, learning from lower
levelS1results in significantly better accuracy. Listener
levels are kept the same during evaluation and train-
ing. Training and evaluation setup: cost=0.6,N=5,
Corr=1. Evaluation: S1.
plained by the fact that lower level speakers send
longer messages on average, see Table 1, because
their internal model is of a simpler listener who
needs longer descriptions for success.
Figure 2: During training, listeners are paired with
speakers of different pragmatic competence. The listen-
ers are trained in environments of increasing difficulty.
L0learners paired with S1speakers have the same per-
formance as L2paired with S3.
Despite the fact that a L2can disambiguate S3
messages, learning from a S1speaker is easier as
it provides more data on both image features. This
behaviour nicely aligns with the intuition that lan-
guage learners benefit from simple, verbose com-
munication and teachers should not assume chal-
lenging patterns of communicative competence
early on in the learning process (Nguyen, 2022).
Comparing all possible pairings in Figure 2 how-
ever, we can clearly see the benefit of listeners
having the appropriate level for the speaker during
learning. A L0listener learning from a S1matches
the performance of a L2listener learning from a
S3speaker. We evaluate listeners that were paired
with higher or lower level speakers during training.
The evaluation environment is kept the same, all
listeners are upgraded to L2and deployed with S1.
Pragmatic L2listener can compensate for the dif-ficulty of learning from the concise S3through all
training environments.
5 Conclusions
Humans exploit pragmatic reasoning in order to re-
duce the effort of speaking. For artificial agents to
understand humans, it is critical to correctly resolve
ambiguities. By recursively modeling the conversa-
tional partner, pragmatic listeners can arrive at the
interpretations intended by pragmatic speakers.
In this work, we introduced speaker-listener
pairs with matching or misaligned levels of prag-
matic competence. We examined the benefits of
integrating pragmatics not only during evaluation
but already during language learning. Our results
show that learning from more explicit, literal lan-
guage is always beneficial, regardless of the prag-
matic capacity of the learner. At the same time,
we conclude that language learners need to apply
reasoning about the context and the speaker when
learning from data that was generated pragmati-
cally.
6 Limitations
While the conversational phenomena we model in
this paper have been widely attested to in linguistic
theory and psycho-linguistic research, our experi-
ments are limited to an artificial sandbox scenario
with a small vocabulary and simple observations.
The reasoning about all possible utterances used in
this paper is intractable with larger vocabularies.
Real world conversations contain a wide range
pragmatic inferences, not all of which can be ac-
counted for by the recursive reasoning presented in
this paper.
7 Acknowledgements
This research was funded in part by the Nether-
lands Organization for Scientific Research (NWO)
under project number VI.C.192.080. We also re-
ceived funding from the Hybrid Intelligence Center,
a 10-year programme funded by the Dutch Min-
istry of Education, Culture and Science through the
Netherlands Organisation for Scientific Research
with grant number 024.004.022.
References
Jacob Andreas and Dan Klein. 2016. Reasoning about
pragmatics with neural listeners and speakers. In Pro-
ceedings of the 2016 Conference on Empirical Meth-ods in Natural Language Processing , pages 1173–
1182, Austin, Texas. Association for Computational
Linguistics.
Holly P Branigan, Martin J Pickering, Jamie Pearson,
Janet F McLean, and Ash Brown. 2011. The role of
beliefs in lexical alignment: Evidence from dialogs
with humans and computers. Cognition , 121(1):41–
57.
Kyunghyun Cho, Bart van Merriënboer, Caglar Gul-
cehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. 2014. Learning
phrase representations using RNN encoder–decoder
for statistical machine translation. In Proceedings
of the 2014 Conference on Empirical Methods in
Natural Language Processing (EMNLP) , pages 1724–
1734, Doha, Qatar. Association for Computational
Linguistics.
Reuben Cohn-Gordon, Noah D. Goodman, and Christo-
pher Potts. 2018. Pragmatically informative image
captioning with character-level inference. In Pro-
ceedings of the 2018 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAACL-
HLT, New Orleans, Louisiana, USA, June 1-6, 2018,
Volume 2 (Short Papers) , pages 439–443. Association
for Computational Linguistics.
Catherine Davies, Vincent Porretta, Kremena Koleva,
and Ekaterini Klepousniotou. 2022. Speaker-specific
cues influence semantic disambiguation. Journal of
Psycholinguistic Research , 51(5):933–955.
Danny Fox and Roni Katzir. 2011. On the characteri-
zation of alternatives. Natural language semantics ,
19:87–107.
Michael C. Frank and Noah D. Goodman. 2012. Predict-
ing pragmatic reasoning in language games. Science ,
336(6084):998–998.
Michael Franke and Judith Degen. 2016. Reasoning
in reference games: Individual-vs. population-level
probabilistic modeling. PloS one , 11(5):e0154854.
Daniel Fried, Jacob Andreas, and Dan Klein. 2018. Uni-
fied pragmatic models for generating and following
instructions. In Proceedings of the 2018 Conference
of the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long Papers) , pages 1951–1963,
New Orleans, Louisiana. Association for Computa-
tional Linguistics.
Noah D Goodman and Michael C Frank. 2016. Prag-
matic language interpretation as probabilistic infer-
ence. Trends in cognitive sciences , 20(11):818–829.
Herbert P Grice. 1975. Logic and conversation. In
Speech acts , pages 41–58. Brill.
Robert D Hawkins, Michael Franke, Michael C Frank,
Adele E Goldberg, Kenny Smith, Thomas L Grif-
fiths, and Noah D Goodman. 2023. From partnersto populations: A hierarchical bayesian account of
coordination and convention. Psychological Review ,
130(4):977.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian
Sun. 2016. Deep residual learning for image recog-
nition. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR) .
Laurence Horn. 1984. Toward a new taxonomy for prag-
matic inference: Q-based and r-based implicature. In
Meaning, form, and use in context: Linguistic appli-
cations , pages 11–42. Georgetown University Press.
William S Horton and Richard J Gerrig. 2002. Speakers’
experiences and audience design: Knowing when
and knowing how to adjust utterances to addressees.
Journal of Memory and Language , 47(4):589–606.
Alexander Kuhnle and Ann A. Copestake. 2017. Shape-
world - a new test methodology for multimodal lan-
guage understanding. ArXiv , abs/1704.04517.
Angeliki Lazaridou, Anna Potapenko, and Olivier Tiele-
man. 2020. Multi-agent communication meets natu-
ral language: Synergies between functional and struc-
tural language learning. In Proceedings of the 58th
Annual Meeting of the Association for Computational
Linguistics , pages 7663–7674, Online. Association
for Computational Linguistics.
Sang-Woo Lee, Yu-Jung Heo, and Byoung-Tak Zhang.
2018. Answerer in questioner’s mind: Information
theoretic approach to goal-oriented visual dialog. Ad-
vances in neural information processing systems , 31.
David Kellogg Lewis. 1969. Convention: A Philosophi-
cal Study . Cambridge, MA, USA: Wiley-Blackwell.
Andy Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, and
Graham Neubig. 2023. Computational language ac-
quisition with theory of mind. In The Eleventh Inter-
national Conference on Learning Representations .
Ilya Loshchilov and Frank Hutter. 2017. Decoupled
weight decay regularization. In International Confer-
ence on Learning Representations .
Jia E Loy and Vera Demberg. 2023. Perspective taking
reflects beliefs about partner sophistication: Modern
computer partners versus basic computer and human
partners. Cognitive Science , 47(12):e13385.
Alexandra Mayn, JE Loy, and Vera Demberg. 2023.
Individual differences in overspecification: reasoning
and verbal fluency.
Alexandra Mayn, Jia E Loy, and Vera Demberg. 2024.
Beliefs about the speaker’s reasoning ability influ-
ence pragmatic interpretation: Children and adults as
speakers.
Bill McDowell and Noah Goodman. 2019. Learning
from omission. In Proceedings of the 57th Annual
Meeting of the Association for Computational Lin-
guistics , pages 619–628, Florence, Italy. Association
for Computational Linguistics.Will Monroe and Christopher Potts. 2015. Learn-
ing in the rational speech acts model. CoRR ,
abs/1510.06807.
Minh Thi Thuy Nguyen. 2022. Interlanguage pragmat-
ics as communicative competence. chapter 8, pages
135–151. Taylor & Francis.
Julia White, Jesse Mu, and Noah D. Goodman. 2020.
Learning to refer informatively by amortizing prag-
matic reasoning. In Proceedings of the 42th Annual
Meeting of the Cognitive Science Society - Devel-
oping a Mind: Learning in Humans, Animals, and
Machines, CogSci 2020, virtual, July 29 - August 1,
2020 . cognitivesciencesociety.org.
A Model training and implementation
All 261838 model-parameters are trained from
scratch. The weights are updated with the AdamW
optimizer (Loshchilov and Hutter, 2017) which we
initialize with a learning rate of 1e−5.
For each training step, we use a batch of 32
games and the listeners are trained for 25920 train-
ing steps. Each instance of a listener training took
1.5 GPU hours on a single NVIDIA RTX A6000
GPU.
BConcentration parameters of the image
generators
We sample P(S),P(C),P(C∣C)andP(S∣S)
from Dirichlet distributions. In the case of no cor-
relation between the images ( Corr=0), we set all
concentration parameters to 1. For the correlated
case ( Corr=1), we introduce correlation between
the same shapes and a randomly chosen shape from
all five shapes. We achieve this by setting the con-
centration parameter αto5at the index that corre-
sponds to the i’th shape and a randomly generated
other index. P(S∣S=shape i)∼Dir(α1, ..., α 5),
where all α’s are 1except for αi=5andαj=5for
a randomly generated j. We apply the same process
for generating all the P(C∣C)distributions.
CBenefits of pragmatic reasoning during
learning
C.1 Pragmatic listeners learn faster
Figure 3 shows that when we keep all parameters
of the learning environment constant, and only vary
the listener’s depth, we observe that listeners with
higher levels, learn to perform the task with good
accuracy faster. The gap in performance is espe-
cially large in the initial learning stages. This result
is in line with McDowell and Goodman (2019),Figure 3: Higher level listeners learn quicker. In this
comparison all other parameters such as speaker level,
number of distractors, correlation between shapes are
left constant.
where they discuss the benefits of pragmatic train-
ing.