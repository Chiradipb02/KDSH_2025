Model-Agnostic Random Weighting for Out-of-Distribution
Generalization
Yue He∗
Tsinghua University
Beijing, China
hy865865@gmail.comPengfei Tian∗
Tsinghua University
Beijing, China
e9tian@gmail.comRenzhe Xu
Tsinghua University
Beijing, China
xrz@199721gmail.com
Xinwei Shen
ETH Zürich
Zürich, Switzerland
xinwei.shen@stat.math.ethz.chXingxuan Zhang
Tsinghua University
Beijing, China
xingxuanzhang@hotmail.comPeng Cui†
Tsinghua University
Beijing, China
cuip@tsinghua.edu.cn
Abstract
Despite the encouraging successes in numerous applications, ma-
chine learning methods grounded on the i.i.d. assumption often
experience performance deterioration when confronted with the
distribution shift between training and test data. This challenge has
instigated recent research endeavors focusing on out-of-distribution
(OOD) generalization. A particularly pervasive and intricate OOD
problem is to enhance the model’s generalization ability by training
it on samples drawn from a single environment. In response to
the problem, we propose a simple model-agnostic method tailored
for a practical OOD scenario in this paper. Our approach centers
on pursuing robust weighted empirical risks, utilizing randomly
shifted training distributions derived through a specific sample-
based weighting strategy. Furthermore, we theoretically establish
that the expected risk of the shifted training distribution can bound
the expected risk of the test distribution. This theoretical foundation
ensures the improved prediction performance of our method when
employed in uncertain test distributions. Extensive experiments
conducted on diverse real-world datasets affirm the effectiveness
of our method, highlighting its potential to address the distribution
shifts in machine learning applications.
CCS Concepts
•Computing methodologies →Machine learning.
Keywords
Out-of-Distribution Generalization, Distribution shift, Sample Weight-
ing
∗Both authors contributed equally to this research.
†Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671762ACM Reference Format:
Yue He, Pengfei Tian, Renzhe Xu, Xinwei Shen, Xingxuan Zhang, and Peng
Cui. 2024. Model-Agnostic Random Weighting for Out-of-Distribution Gen-
eralization. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge
Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain.
ACM, New York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671762
1 Introduction
In past years, the field of machine learning has experienced un-
precedented growth, attributed to advanced data-driven modeling
techniques and powerful computational capabilities. Traditional
machine learning methods often rely on the assumption that train-
ing and test data are independent and identically distributed (i.i.d.).
The model, that achieves empirical risk minimization (ERM) on
training samples, is expected to approximately attain the minimal
expected risk on test samples under the i.i.d. assumption. However,
real-world applications often involve distribution shifts between
training and test data due to the heterogeneity and uncertainty of
real data. This results in the test risk of models based on the i.i.d. as-
sumption being unguaranteed, and prone to deterioration, which is
very detrimental for high-stake scenarios [ 8,39,48]. To address the
challenge of generalizing a model to data drawn out-of-distribution
(OOD) [ 23], researchers have intensively studied the problem of
OOD generalization recently.
To solve the OOD problem, various approaches from differ-
ent paradigms have been investigated. Dai et al . [9], Ganin et al .
[16], Sun and Saenko [45] are designed to transition the model
from a source domain to a target domain by leveraging test data
information. However, having access to such test information prior
is often not feasible. To enhance the non-targeted generalization
ability, a strand of methods proposes to utilize the labels of multi-
ple heterogeneous data environments that training samples come
from. They aim to learn the invariant representation [ 3,6,24,36]
or domain-agnostic model [ 17,27,28] that is irrelevant to the envi-
ronment labels, so that the model can be deployed in the unknown
environment well in virtue of invariance [ 38]; or directly learn
a model that can generalize to the combinations of these envi-
ronments [ 25], enabling the model with improved precision and
reliability across environments. Nonetheless, the performances of
these methods heavily depend on the availability and heterogeneity
of multi-environments [2], which are difficult to guarantee in real
applications, limiting their practical deployment.
 
1050
KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
In contrast, another strand focuses on a more general setting of
the OOD problem, that is to enhance the generalization ability of
the model upon a single training environment. The distribution-
ally robust optimization (DRO) [ 12,35,44] minimizes the worst
expected risk of the distributions in a pre-defined uncertainty set
of test distributions. Creager et al . [7], Liu et al . [32] assume the
training data is a mixture of multi-source data, iteratively mine the
heterogeneity inside data for environment partition and learn an
invariant model from them. Recently, some model-agnostic meth-
ods are proposed to deal with the distribution shift in common
tasks. JTT [ 31] and LfF [ 37] up-weight the samples that are falsely
identified by a biased classifier to train another unbiased classifier.
RWY [ 22] adjusts the imbalanced ratio of positive and negative
samples. Focal loss [ 29] and CVaR [ 47] concentrate on the training
samples of high risks. Despite the advantages in simplicity and
universality, these methods are either designed for a special type
of data bias or lack the theoretical guarantee, resulting in their
unstable efficacy.
Considering both impacts of the changed population of samples
and the distinct system biases1[34,49] in data environments, we
propose a novel model-agnostic model towards better OOD gener-
alization in this paper. Suppose 𝑋and𝑌denote the observational
covariates and outcome variable, respectively. Our method MARW
(Model- Agnostic Random Weighting) randomly shifts the training
distribution through reweighting the training samples according
to the function 𝑤(𝑋,𝑌)from a specific functional space W, and
pursues the robust weighted empirical risks of the shifted distribu-
tions. We further theoretically prove that the expected risk of test
distribution can be upper bounded by the expected risk of train-
ing distribution shifted by 𝑤(𝑋,𝑌). As a result, our method can
facilitate better performance of the prediction model in potential
test distributions, then shows its consistent advantages on OOD
generalization in a range of actual tasks empirically.
In summary, our contributions are highlighted as follows:
•We propose a novel model-agnostic method called MARW
for the out-of-distribution (OOD) generalization problem,
which pursues the robust weighted empirical risks of the ran-
domly shifted training distributions derived from a specific
sample-based weighting, to achieve the better predictions in
the uncertain test distributions.
•We theoretically demonstrate that the expected risk of the
shifted training distribution can bound the expected risk of
the non-i.i.d. test distribution, which proves the rationality
of our method for OOD generalization.
•We conduct extensive experiments on various real-world
datasets to validate the effectiveness of MARW in withstand-
ing the distribution shifts in common tasks.
The rest of this paper is organized as follows. Section 2 gives the
formulation of the OOD problem that we study. Section 3 introduces
our proposed Model-Agnostic Random Weighting method. Section 4
provides the theoretical analysis of our approach. Section 5 reviews
the related work. Section 6 presents the experimental results. Finally,
Section 7 concludes the paper.
1The system bias is widely seen in real applications. The batch effect often appears
in the results of the same biomedical experiment conducted by different experts. It is
also prone to introduce the individual prior biases when labeling the images.2 Preliminary
2.1 Problem Setup
2.1.1 Notations. We define𝑋∈ X ⊆ R𝑑and𝑌∈ Y ⊆ Ras
random variables representing the covariates with dimension 𝑑and
the outcome, respectively. XandYare the space of the covariates
and outcome, respectively. The focus of our paper is on the Out-of-
Distribution (OOD) problem, with E𝑎𝑙𝑙denoting the set of potential
environments. The distribution of data within each environment
𝑒∈E𝑎𝑙𝑙is expressed as 𝑃𝑒(𝑋,𝑌). The predictive model is denoted
asˆ𝑓𝜃:X→Y with parameters 𝜃∈Θ, and the loss function, given
model parameters 𝜃and a sample with covariates and outcome
(𝑥,𝑦), is represented as ℓ(𝑥,𝑦;𝜃).
Given𝑁training samples{(𝑥𝑖,𝑦𝑖)}𝑁
𝑖=1from a specific training
environment 𝑒𝑡𝑟∈E𝑎𝑙𝑙, distributed according to 𝑃𝑒𝑡𝑟(𝑋,𝑌), our
task is to ensure the good performance in an unseen test envi-
ronment𝑒𝑡𝑒∈E𝑎𝑙𝑙, characterized by the distribution 𝑃𝑒𝑡𝑒(𝑋,𝑌).
In other words, we aim to minimize the expected loss in the test
environment, E𝑃𝑒𝑡𝑒[ℓ(𝑋,𝑌;𝜃)]. To simplify the notations, we use
𝑃𝑡𝑟(𝑋,𝑌)and𝑃𝑡𝑒(𝑋,𝑌)to denote the training distribution and test
distribution, respectively.
2.1.2 OOD setting setup. Since the general OOD problem is in-
tractable without further assumptions on the set of all possible
environmentsE𝑎𝑙𝑙[30], we consider a practical setting in this pa-
per, which assumes the distribution 𝑃𝑒(𝑋,𝑌)for each environment
satisfies the following generation function: ∀𝑒∈E𝑎𝑙𝑙,
𝑋∼𝑃𝑒(𝑋), 𝑌 =𝑓(𝑋+𝜂𝑒)+𝜇𝑒+𝜖, 𝜖∼N( 0,𝜎2
𝑒).(1)
Here𝑃𝑒(𝑋)is the marginal distribution on 𝑋and𝜂𝑒∈R𝑑,𝜇𝑒∈
R,𝜎𝑒∈R+are parameters for each environment 𝑒∈E𝑎𝑙𝑙.𝑓:R𝑑→
Ris an invariant labeling function across all environments.
In this setting, we employ the parameters 𝜂𝑒and𝜇𝑒to repre-
sent the system biases affecting the observed values of covariates
and outcomes, respectively, for each environment 𝑒. System biases
often change across different data batches due to distinct mea-
surement conditions [ 15,49]. Additionally, we characterize the
diverse populations denoted by 𝑃𝑒(𝑋)[42] and the varying signal-
to-noise ratios represented by N(0,𝜎2𝑒)[1] across environments,
that are frequently encountered in reality. The goal of this paper is
to achieve out-of-distribution generalization for environments spec-
ified by Equation (1), where the data distribution 𝑃𝑒(𝑋,𝑌)shifts
with changes in 𝑃𝑒(𝑋),𝜎𝑒,𝜂𝑒, and𝜇𝑒.
2.2 Weighted Empirical Risk Minimization
Our method is based on weighted empirical risk minimization.
In i.i.d. settings, the empirical loss is given by E𝑃𝑡𝑟[ℓ(𝑋,𝑌;𝜃)]≈
1/𝑁Í𝑁
𝑖=1ℓ(𝑥𝑖,𝑦𝑖;𝜃). However, for a non-i.i.d. test distribution where
𝑃𝑡𝑒(𝑋,𝑌)≠𝑃𝑡𝑟(𝑋,𝑌), we employ the weighted empirical loss to
approximate the population-level test loss as follows:
E𝑃𝑡𝑒[L(𝑋,𝑌;𝜃)]=∫𝑃𝑡𝑒(𝑥,𝑦)
𝑃𝑡𝑟(𝑥,𝑦)ℓ(𝑥,𝑦;𝜃)𝑃𝑡𝑟(𝑥,𝑦)𝑑𝑥𝑑𝑦
≈1
𝑁𝑁∑︁
𝑖=1𝑤(𝑥𝑖,𝑦𝑖)ℓ(𝑥𝑖,𝑦𝑖;𝜃),(2)
 
1051Model-Agnostic Random Weighting for Out-of-Distribution Generalization KDD ’24, August 25–29, 2024, Barcelona, Spain
where𝑤(𝑥,𝑦)=𝑃𝑡𝑒(𝑥,𝑦)/𝑃𝑡𝑟(𝑥,𝑦)is the importance sampling
weight [ 14,19]. Notably, we can also leverage a suitable weight-
ing function 𝑤(𝑥,𝑦)to simulate test environments [ 46], provided
that the weighting function satisfies the normalization constraint
E𝑃𝑡𝑟[𝑤(𝑋,𝑌)]=1.
3 Model-Agnostic Random Weighting
In this section, we present our proposed method, Model-Agnostic
Random Weighting, abbreviated as MARW. The MARW methodol-
ogy comprises two primary components: random weighting and
variance-based optimization. These components are discussed in
the following two subsections.
3.1 Characterizing the Weighting Function
Class
In this subsection, we provide a proper way to parametrize the
space of feasible weighting functions to simulate unknown test
environments.
All possible weighting functions. We first formulate the ground-
truth weighting function class for all environments in E𝑎𝑙𝑙. Let
𝑃𝑡𝑟(𝑋),𝜂𝑡𝑟,𝜇𝑡𝑟,𝜎𝑡𝑟be the parameters in the training distribution
𝑃𝑡𝑟as shown in Equation (1). Then the probability density ratio
between the distribution 𝑃𝑒(𝑥,𝑦)of any environment 𝑒∈E𝑎𝑙𝑙and
the training distribution 𝑃𝑡𝑟(𝑥,𝑦)can be formulated as ∀𝑥∈X,𝑦∈
Y,
𝑤𝑒(𝑥,𝑦)≜𝑃𝑒(𝑥,𝑦)
𝑃𝑡𝑟(𝑥,𝑦)=exp
𝐴𝑒𝑦2+𝐵𝑒𝑦
ℎ𝑒(𝑥)𝑔𝑒(𝑥,𝑦),(3)
where
𝐴𝑒=1
2𝜎2
𝑡𝑟−1
2𝜎2𝑒, 𝐵𝑒=𝜇𝑒
𝜎2𝑒−𝜇𝑡𝑟
𝜎2
𝑡𝑟,
𝑔𝑒(𝑥,𝑦)=exph 𝑓(𝑥+𝜂𝑒)
𝜎2𝑒−𝑓(𝑥+𝜂𝑡𝑟)
𝜎2
𝑡𝑟𝑦i
,
ℎ𝑒(𝑥)=𝜎𝑡𝑟
𝜎𝑒·𝑃𝑒(𝑥)
𝑃𝑡𝑟(𝑥)
·exph(𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟)2
2𝜎2
𝑡𝑟−(𝑓(𝑥+𝜂𝑒)+𝜇𝑒)2
2𝜎2𝑒i
.(4)
The detailed derivation is available in Appendix, where we addi-
tionally illustrate that the density ratios adhere to the formulation
described in Equation 3 when considering a broader assumption of
exponential distribution noise.
Let the space of all possible weighting functions for all environ-
ments inE𝑎𝑙𝑙beW∗, i.e.,W∗={𝑤𝑒(𝑥,𝑦):𝑒∈E𝑎𝑙𝑙}. We note
that the density ratio 𝑤𝑒(𝑥,𝑦)in Equation (3)can be expressed as
the product of three terms, corresponding to functions on 𝑦,𝑥, and
(𝑥,𝑦)respectively.
Parametrized weighting function class. Our goal is to establish a
parametrized weighting function class derived from Equation (3).
At first glance, one might consider parametrizing all three terms
in Equation (3)and formulating the function class in the following
manner:
W′=
𝑤(𝑥,𝑦)=exp(𝐴𝑦2+𝐵𝑦)𝑔(𝑥,𝑦;𝜉)ℎ(𝑥;𝜙):
𝐴,𝐵∈R,𝜉∈Ξ,𝜙∈Φ,E𝑃𝑡𝑟[𝑤(𝑋,𝑌)]=1	
,(5)
<𝜟
MinDistance𝑃!"𝑃!"!𝑃!"!𝑃!"!Risk!"Risk!"!Risk!"!Risk!"!Risk!#Risk!#Risk!#!!(#,%)!!(#,%)
!!(#,%)Figure 1: The diagram of how our model works. At each op-
timization step, MARW first randomly samples weighting
functions from a specific space to approximate the excepted
risk in the potential test distributions using weighted empir-
ical risk. Then it minimizes the variance of weighted empir-
ical risks to learn a prediction model that performs stably
(having bounded test risk) in different distributions.
where𝑔(𝑥,𝑦;𝜉)andℎ(𝑥;𝜙)are parametrized functions with param-
eters𝜉∈Ξand𝜙∈Φrespectively. The constraint E𝑃𝑡𝑟[𝑤(𝑋,𝑌)]=
1is the normalization requirement to guarantee that the weighting
function is feasible to model the probability density ratio of two
distributions. However, we argue that parametrizing the space of
𝑔𝑒(𝑥,𝑦)in Equation (3)as{𝑔(𝑥,𝑦;𝜉):𝜉∈Ξ}is inherently prob-
lematic for a couple of key reasons.
Firstly, the ground-truth weighting function space of 𝑔𝑒(𝑥,𝑦)
in Equation (3)is intrinsically dependent on only two parameters,
𝜂𝑒and𝜎𝑒, as all other parameters 𝑓,𝜂𝑡𝑟, and𝜎𝑡𝑟remain consis-
tent across different environments. By contrast, the function space
of𝑔(𝑥,𝑦;𝜉)often spans a much larger domain, given that typi-
cally parametrized functions (e.g., linear functions or multi-layer
perceptrons) carry parameters with dimension at least 𝑑(i.e., the
dimension of 𝑥), which tends to be large in practical scenarios (e.g.,
images and texts). Secondly, the function space of 𝑔𝑒(𝑥,𝑦)is heav-
ily influenced by the labeling function 𝑓in Equation (1). Given
the usual lack of prior knowledge about 𝑓, modeling the space for
𝑔𝑒(𝑥,𝑦)with{𝑔(𝑥,𝑦;𝜉):𝜉∈Ξ}is a significant challenge, espe-
cially considering the dimensional constraints that require the size
of the space Ξto be small.
Considering these constraints, we propose an alternate weight-
ing function class by excluding the 𝑔(𝑥,𝑦;𝜉)term from Equation
(5), i.e.,
W=
𝑤(𝑥,𝑦)=exp(𝐴𝑦2+𝐵𝑦)ℎ(𝑥;𝜙):
𝐴,𝐵∈R,𝜙∈Φ,E𝑃𝑡𝑟[𝑤(𝑋,𝑌)]=1	
.(6)
It is noteworthy that while the ℎ𝑒(𝑥)term in Equation (1)incor-
porates the ground-truth labeling function 𝑓, the existence of the
covariate-shift term 𝑃𝑒(𝑥)/𝑃𝑡𝑟(𝑥)expands the function space for
ℎ𝑒(𝑥)considerably in real-world scenarios, making it viable to
model it with a parametrized function space {ℎ(𝑥;𝜙):𝜙∈Φ}.
Furthermore, we prove that the exclusion of the 𝑔𝑒(𝑥,𝑦)term has a
 
1052KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
Algorithm 1 Out-of-Distribution Generalization via Model Agnos-
tic Random Weighting (MARW)
Input: the training dataset {(𝑥𝑖,𝑦𝑖)}𝑁
𝑖=1, the number of sample
weighting𝐸, the randomness 𝑃𝜙of weighting function ℎ(𝑥;𝜙),
and the randomness 𝑃(𝐴,𝐵)of weighting parameters (𝑎,𝑏).
Initialize the parameter set 𝜃of prediction model ˆ𝑓(𝑥;𝜃).
repeat
Sample{𝜙1,···,𝜙𝐸}∼𝑃𝜙,{(𝑎1,𝑏1),···,(𝑎𝐸,𝑏𝐸)}∼𝑃(𝐴,𝐵).
ComputeL0=Í𝑁
𝑖=1ℓ(𝑥𝑖,𝑦𝑖;𝜃)
for𝑒=1to𝐸do
ComputeL𝐸=Í𝑁
𝑖=1exp(𝑎𝑒𝑦2
𝑖+𝑏𝑒𝑦𝑖)·ℎ(𝑥𝑖;𝜙𝑒)·ℓ(𝑥𝑖,𝑦𝑖;𝜃)
end for
ComputeL=1/(𝐸+1)Í𝐸
𝑒=0L𝐸+𝜆·𝑉𝑎𝑟({L 0,···,L𝐸}).
Optimize𝜃←𝜃−𝜂·▽L .
until convergence
return: the prediction model ˆ𝑓(𝑥;𝜃).
moderate impact on the weighting function space to be acceptable,
as detailed in Section 4.1.
3.2 OOD Optimization with Random Sample
Weights
Building upon the preceding subsection, we propose the use of
randomly sampled weighting functions from the class Wto simu-
late novel environments, and we incorporate a variance regularizer
to constrain the model performance within these synthetic envi-
ronments. The generation of environments is independent of the
model optimization, making MARW both simple and stable.
In detail, we first design distributions 𝑃𝐴,𝑃𝐵,𝑃𝜙for all three
parameters 𝐴,𝐵,𝜙 in the weighting function class W. At each
training iteration, we sample 𝐸environments 𝑒1,𝑒2,...,𝑒𝐸, where
each environment 𝑒𝑗is characterized by the weighting function
𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)=exp(𝐴𝑗𝑦2+𝐵𝑗𝑦)ℎ(𝑥;𝜙𝑗)with𝐴𝑗∼𝑃𝐴,𝐵𝑗∼
𝑃𝐵, and𝜙𝑗∼𝑃𝜙. Employing these weighting functions, we generate
𝐸environments and apply variance regularization to minimize the
variance of the weighted empirical risks, thereby mitigating risk
ascent in non-i.i.d. test distributions. This strategy is illustrated
to provide more stable and effective optimization in practice [ 25].
Formally, we optimize 𝜃MARWas the value to minimize following
formula:
1
𝐸+1𝐸∑︁
𝑗=0L𝑗(𝜃)+𝜆·Var(L0(𝜃),L1(𝜃),...,L𝐸(𝜃)),(7)
whereL0(𝜃)=Í𝑁
𝑖=1ℓ(𝑥𝑖,𝑦𝑖;𝜃), and∀𝑗∈{1,2,...,𝐸},
L𝑗(𝜃)=𝑁∑︁
𝑖=1𝑤 𝑥𝑖,𝑦𝑖;𝐴𝑗,𝐵𝑗,𝜙𝑗ℓ(𝑥𝑖,𝑦𝑖;𝜃). (8)
In essence,L0(𝜃)corresponds to the empirical loss in the training
distribution andL𝑗(𝜃)represents the weighted empirical loss in
the distribution constituted by 𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗). Here,𝜆is a hyper-
parameter that controls the intensity of the variance penalty.
The pseudo-code of MARW can be found in Algorithm 1. In
practice, we ensure the sum of weights equals 1by normalizing
each weight 𝑤(𝑥𝑖,𝑦𝑖;𝐴𝑗,𝐵𝑗,𝜙𝑗)through division by the total sumÍ𝑛
𝑖=1𝑤(𝑥𝑖,𝑦𝑖;𝐴𝑗,𝐵𝑗,𝜙𝑗). When adopting our models for deep learn-
ing tasks, we can utilize the representation of the data instead of the
original input sample to compute the sample weights, that benefits
from the dense and separable representation space [20].
4 Theoretical Analysis
In this section, we first examine the distance between the ground-
truth weighting function for a specific environment 𝑒and the
weighting functions within our proposed class W, considering
both the best-case and worst-case scenarios (Section 4.1). Leverag-
ing these results, we investigate the effects of our method on the
OOD performance in Section 4.2. It is worth noting that when we
consider scenarios where the training and test distributions have
identical noise variance (i.e., 𝜎2𝑒=𝜎2
𝑡𝑟), we can obtain a tighter
bound (Section 4.3).
Further assumptions. If the test distribution is entirely unknown,
the prediction tasks become intractable [ 30]. Therefore, we assume
that the test distribution lies within the vicinity of the training
distribution. More specifically, we consider test sets to be in the
following set controlled by 𝑟and𝛿,∀𝑟≥1,𝛿≥0:
E(𝑟,𝛿)=
𝑒∈E𝑎𝑙𝑙:∀𝑥∈X,|𝜂𝑒−𝜂𝑡𝑟|≤𝛿,
1
𝑟≤𝜎𝑒
𝜎𝑡𝑟,𝜇𝑒
𝜇𝑡𝑟,𝑃𝑒(𝑥)
𝑃𝑡𝑟(𝑥)≤𝑟	
.(9)
The parameters 𝑟and𝛿regulate the potential range of the distri-
bution. As these values increase, the probability of the test distri-
bution being significantly divergent from the training distribution
also rises. Particularly, when considering E(1,0), it solely encom-
passes the training distribution, thereby reducing the task to the i.i.d.
scenario. Furthermore, we give an assumption on our generating
function to bound the range and smoothness of the ground-truth
labeling function.
Assumption 4.1.|𝑓(𝑥)|≤𝑀,𝑥∈Xand|𝑓(𝑥1)−𝑓(𝑥2)|≤𝐿|𝑥1−
𝑥2|,∀𝑥1,𝑥2∈X.
4.1 Justification of the Chosen Weighting
Function Class
Based on the weighting function class in Equation (6), we addition-
ally add constraints on the range of the parameters as follows.
W(𝜅𝐴,𝜅𝐵,𝜅𝜙)=
exp(𝐴𝑦2+𝐵𝑦)ℎ(𝑥;𝜙):
|𝐴|≤𝜅𝐴,|𝐵|≤𝜅𝐵,∀𝑥∈X,|lnℎ(𝑥;𝜙)|≤𝜅𝜙	
.(10)
For any environment 𝑒inE(𝑟,𝛿), we could develop upper bounds
on the distance between the ground-truth weighting function and
the worst (Theorem 4.1) and best (Theorem 4.2) weighting function
inW(𝜅𝐴,𝜅𝐵,𝜅𝜙).
 
1053Model-Agnostic Random Weighting for Out-of-Distribution Generalization KDD ’24, August 25–29, 2024, Barcelona, Spain
Theorem 4.1. Under Assumption 4.1, we have ∀𝑒∈E(𝑟,𝛿),∀𝑦∈Y,
sup
𝑤∈W(𝜅𝐴,𝜅𝐵,𝜅𝜙)sup
𝑥∈X|ln𝑤(𝑥,𝑦)−ln𝑤𝑒(𝑥,𝑦)|
≤
𝜅𝐴+𝑟2−1
2𝜎2
𝑡𝑟
𝑦2+
𝜅𝐵+1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟2𝐿𝛿)
+|𝜇𝑡𝑟|(𝑟3−1)
𝜎2
𝑡𝑟
|𝑦|+𝜅𝜙+2 ln𝑟
+(𝑟+1)𝑀+(𝑟2+1)|𝜇𝑡𝑟|
2𝜎2
𝑡𝑟
(𝑟−1)𝑀+𝑟𝐿𝛿+|𝜇𝑡𝑟|(𝑟2−1)
.(11)
Remark. This theorem provides an upper bound on the worst-case
distance between the ground-truth weighting function 𝑤𝑒(𝑥,𝑦)
and any function within W(𝜅𝐴,𝜅𝐵,𝜅𝜙). Since the weight function
is complex, we choose to fix 𝑦and measure the maximum distance
over all𝑥to quantify the gap between weights. In addition, we note
that when𝑟=1and𝛿=0, the scenario reduces to i.i.d. tasks. In
such instances, the right-hand side retains only the worst sample
error,𝜅𝐴𝑦2+𝜅𝐵|𝑦|+𝜅𝜙.
Furthermore, if we have additional information about the range
of the test environment characterized by 𝑟,𝛿, we can obtain the
best-case distance as follows.
Theorem 4.2. Under Assumption 4.1, by setting
𝜅𝐴≥𝑟2−1
2𝜎2
𝑡𝑟,𝜅𝐵≥|𝜇𝑡𝑟|(𝑟3−1)
𝜎2
𝑡𝑟,
𝜅𝜙≥2 ln𝑟+(𝑟+1)𝑀+(𝑟2+1)|𝜇𝑡𝑟|
2𝜎2
𝑡𝑟
·[(𝑟−1)𝑀+𝑟𝐿𝛿+|𝜇𝑡𝑟|(𝑟2−1)],(12)
we have∀𝑒∈E(𝑟,𝛿),∀𝑦∈Y,
inf
𝑤∈W(𝜅𝐴,𝜅𝐵,𝜅𝜙)sup
𝑥∈X|ln𝑤(𝑥,𝑦)−ln𝑤𝑒(𝑥,𝑦)|
≤|𝑦|1
𝜎2
𝑡𝑟
(𝑟2−1)𝑀+𝑟2𝐿𝛿
.(13)
Remark. Similar to the remark of Theorem 4.1, when 𝑟=1and
𝛿=0, the scenario reduces to i.i.d. tasks. In such instances, the
right-hand side of Equation (13)becomes zero since W(𝜅𝐴,𝜅𝐵,𝜅𝜙)
contains the function 𝑤(𝑥,𝑦)≡1. We note that there can be nu-
merous weighting functions that satisfy Equation (13), given that
it merely establishes an upper limit for the distance.
Theorems 4.1 and 4.2 highlight a trade-off in choosing small
or large values for the parameters 𝜅𝐴,𝜅𝐵, and𝜅𝜙. Small values
hinder accurate ground-truth weighting function approximation,
while large values increase the worst-case distance, as shown in
Theorem 4.1.
4.2 Analysis of Model Performance on Test
Distribution
In this subsection, we further analyze how randomly generated
weighting functions and our optimization target in Equation (7)
can help improve performances on unknown test distributions.Consider a specific test environment 𝑒𝑡𝑒∈E𝑎𝑙𝑙. The probability
density ratio between the test environment and training environ-
ment,𝑤𝑒𝑡𝑒(𝑥,𝑦), can be obtained using Equation (3). We show that if
we can randomly generate a weighting function 𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)
that is sufficiently close to the true function 𝑤𝑒𝑡𝑒(𝑥,𝑦), then the test
performance can be bounded by the weighted training performance
with respect to the function 𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗).
Theorem 4.3. Under Assumption 4.1, if there exists sampled envi-
ronment𝑗such that the weighting function 𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)sat-
isfies Equation (13) (i.e.,∀𝑦∈Y,sup𝑥∈X|ln𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)−
ln𝑤𝑒𝑡𝑒(𝑥,𝑦)|≤|𝑦|((𝑟2−1)𝑀+𝑟2𝐿𝛿)/𝜎2
𝑡𝑟), then for any 𝛼>0, there
exist𝐶𝛼=exp[((𝑟2−1)𝑀+𝑟2𝐿𝛿)(𝑀+|𝜇𝑡𝑟|+𝑧1−𝑞(𝛼,𝑟,𝛿)/2𝜎𝑡𝑟)/𝜎2
𝑡𝑟]
such that∀𝜃∈Θ,
E𝑡𝑒h𝑌−ˆ𝑓𝜃(𝑋)i
≤𝐶𝛼E𝑡𝑟h
𝑤(𝑋,𝑌;𝐴𝑗,𝐵𝑗,𝜙𝑗)𝑌−ˆ𝑓𝜃(𝑋)i
+𝛼,(14)
where𝑧1−𝑞(𝛼,𝑟,𝛿)/2represents 1−𝑞(𝛼,𝑟,𝛿)/2quantile of Gaussian
distribution and 𝑞(𝛼,𝑟,𝛿)is increasing about 𝛼and decreasing about
𝑟,𝛿.
Remark. Note that𝐶𝛼≥1. When𝑟=1,𝛿=0,𝐶𝛼=1, the task
degenerates to i.i.d. tasks. If potential test distribution range is small
(i.e.,𝑟,𝛿is small), the coefficient of the training risk 𝐶𝛼is small, and
then the performance guarantee on test distribution is sufficient.
Although we do not have prior knowledge about the true func-
tion𝑤𝑒𝑡𝑒(𝑥,𝑦), there hopefully exists a function 𝑤𝑗(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)∈
W(𝜅𝐴,𝜅𝐵,𝜅𝜙)that satisfies Equation (13)to approximate the op-
timal weight relative to the test distribution well. In addition, as
demonstrated by [ 25], the optimization target in Equation (7)can ef-
fectively guarantee the performances on each environment 𝑒1,𝑒2,...,𝑒𝐸,
i.e., make E𝑡𝑟[𝑤(𝑋,𝑌;𝐴𝑗,𝐵𝑗,𝜙𝑗)|𝑌−ˆ𝑓𝜃(𝑋)|]small. Hence, Theo-
rem 4.3 can demonstrate that our method can effectively optimize
the performances in unknown test distribution. Moreover, under the
same-variance-noise assumption, by employing techniques such
as covering numbers, we can establish that when a sufficient num-
ber of weight functions are sampled, there is a high probability of
ensuring the model’s performance in test domain.
4.3 Case Analysis: when all the distributions
share the same noise variance
In addition to the general situation, a sound assumption that all
the potential data environments share the same noise variance
𝜎𝑒=𝜎is also widely considered. In this section, we discuss the
situation under the equal variance assumption, where we can see
the favorable property of our method in terms of out-of-distribution
generalization.
All Possible Weighting Functions. Here we formulate the ground-
truth weighting function class for the same noise variance (SNV)
environments inE𝑠𝑛𝑣. Then the probability density ratio between
the distribution 𝑃𝑒(𝑥,𝑦)of any environment 𝑒∈ E𝑠𝑛𝑣and the
training distribution 𝑃𝑡𝑟(𝑥,𝑦)can be formulated as
∀𝑥∈X,𝑦∈Y, 𝑤𝑒(𝑥,𝑦)≜𝑃𝑒(𝑥,𝑦)
𝑃𝑡𝑟(𝑥,𝑦)=exp(𝐵𝑒𝑦)ℎ𝑒(𝑥)𝑔𝑒(𝑥,𝑦),
 
1054KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
Table 1: Empirical results in US-Wide PUMS Data in a sub-population generalization setting. We report the precision accuracy
on test data (higher value is better). The bold and underline denote the best and the second best results, respectively. MARW
shows a consistent advantage in all tasks compared to other baselines.
Metho
dA
CSPublicCoverage A
CSEmployment A
CSTravelTime A
CSIncome A
CSMobility
Mean
Worst Mean
Worst Mean
Worst Mean
Worst Mean
Worst
ERM 75.25%
64.00% 77.25%
74.90% 60.03%
50.20% 78.24%
73.10% 70.88%
58.62%
DRO 75.54%
62.68% 77.13%
75.00% 60.14%
50.62% 77.80%
72.70% 71.05%
58.62%
RWY 64.97%
47.20% 77.16%
74.60% 52.33%
48.40% 77.21% 74.50% 55.70%
41.10%
Focal 75.19%
63.50% 77.16%
74.60% 60.01%
50.40% 78.09%
73.00% 70.90%
58.62%
CVaR 75.44%
62.90% 77.51%
75.60% 60.90% 52.90% 78.07%
73.03% 71.77%
62.07%
LfF 74.27%
61.90% 73.24%
69.40% 59.94%
51.70% 77.42%
72.40% 70.99%
58.62%
JTT 74.53%
64.06% 77.34%
75.40% 56.71%
51.24% 78.14%
73.30% 69.00%
62.07%
MARW 75.85% 64.50% 77.96% 76.14% 60.22%
51.52% 78.11%
73.94% 71.53% 63.45%
Table 2: Empirical results in CelebA and Civilcomments
dataset. We report the precision accuracy on test data. MARW
and JTT show the superior performances in these two
datasets.
Metho
dCeleb
A (Image Dataset) Civilcomments
(Text Dataset)
Mean
Worst Mean
Worst
ERM 95.60%
47.20% 92.60%
57.40%
DRO 94.68%
53.89% 92.44%
55.08%
RWY 93.63%
72.23% 90.39%
68.99%
Focal 95.45%
49.45% 92.39%
55.23%
CVaR 94.72%
56.11% 92.22%
55.00%
LfF 85.10%
77.20% 92.50%
58.80%
JTT 88.00% 81.10% 91.10%
69.30%
MARW 92.47%
78.33% 91.11% 70.87%
where
𝐵𝑒=𝜇𝑒−𝜇𝑡𝑟
𝜎2, 𝑔𝑒(𝑥,𝑦)=exp𝑓(𝑥+𝜂𝑒)−𝑓(𝑥+𝜂𝑡𝑟)
𝜎2
𝑦
,
ℎ𝑒(𝑥)=·𝑃𝑒(𝑥)
𝑃𝑡𝑟(𝑥)·exp(𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟)2−(𝑓(𝑥+𝜂𝑒)+𝜇𝑒)2
2𝜎2
.
Then we introduce the covering number to measure the space
W(0,𝜅𝐵,𝜅𝜙)size.
Distance on Weight Function Space. We can define a distance on
W(0,𝜅𝐵,𝜅𝜙), for any𝑤1,𝑤2∈W( 0,𝜅𝐵,𝜅𝜙), we can define
𝑑Ω(𝑤1,𝑤2)=sup
𝑥sup
|𝑦|≥Ω|ln𝑤1(𝑥,𝑦)−ln𝑤2(𝑥,𝑦)|
|𝑦|,∀Ω>0.
Following proposition guarantees the definition is reasonable.
Proposition 4.4. 𝑑Ω(·,·)is a well-defined distance, and W(0,𝜅𝐵,𝜅𝜙)
is a bounded set based on 𝑑Ω.
Then we introduce the covering number to measure the space
W(0,𝜅𝐵,𝜅𝜙)size.
Covering Number [4]. We denoteN(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)as the
minimal number of 𝜉-radius𝑑Ω-ball to cover the W(0,𝜅𝐵,𝜅𝜙).When there are no confusing notations, we use Nto represent
N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω).
Assumption 4.2. Our sampling methods are uniform distribution
on theW(0,𝜅𝐵,𝜅𝜙)based on𝑑Ω.
Remark. That uniform distribution on the W(0,𝜅𝐵,𝜅𝜙)based on
𝑑Ωmeans for any ball 𝐵(𝑂1,𝑅,𝑑Ω),𝐵(𝑂2,𝑅,𝑑Ω)⊂W( 0,𝜅𝐵,𝜅𝜙)
based on𝑑Ω, we have𝑃(𝐵(𝑂1,𝑅,𝑑Ω))=𝑃(𝐵(𝑂2,𝑅,𝑑Ω)). To satisfy
Assumption 4.2, we can uniformly sample 𝐵∈ [−𝜅𝐵,𝜅𝐵], and
choose𝜙∈𝑃𝜙, such that lnℎ(𝑥;𝜙) ∈ [−𝜅𝜙,𝜅𝜙]. For example,
ℎ(𝑥,𝜙)=𝜙andln𝜙uniformly sampled from [−𝜅𝜙,𝜅𝜙].
Theorem 4.5. Under Assumption 4.2, if we independently sample 𝑆
weight functions and our sampling method satisfies Assumption 4.2,
and
𝜅𝐵≥|𝜇𝑡𝑟|(𝑟−1)
𝜎2,𝜅𝜙≥ln𝑟+2𝑀+(𝑟+1)|𝜇𝑡𝑟|
2𝜎2[𝐿𝛿+|𝜇𝑡𝑟|(𝑟−1)],
then with probability 1−(1−N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)−1)𝑆, there
exists a weight function 𝑤(𝑥,𝑦)∈W( 0,𝜅𝐵,𝜅𝜙), such that for any
𝛼>0, there exist 𝐶𝛼=exp[(2𝜉+𝐿𝛿/𝜎2)(𝑀+|𝜇𝑡𝑟|+𝑧1−𝑞(𝛼)/2𝜎)]+
exp(6𝜉𝐾+𝐿𝛿/𝜎2)such that
∀𝜃∈Θ,E𝑡𝑒h𝑌−ˆ𝑓𝜃(𝑋)i
≤𝐶𝛼E𝑡𝑟h
𝑤(𝑋,𝑌;𝐵,𝜙)𝑌−ˆ𝑓𝜃(𝑋)i
+𝛼,
where𝑧1−𝑞(𝛼)/2represents 1−𝑞(𝛼)/2quantile of Gaussian distribu-
tion and𝑞(𝛼)is increasing about 𝛼.
Remark. Compared to Theorem 4.3, Theorem 4.5 states a more clear
version in the description for explaining the probability of taking
enough good weight. Actually, there is no need for our weight
to take the projection of the 𝑤𝑒(𝑥,𝑦), here, we extend the limits
to a broad range, and the range is controlled by 𝜉. The larger 𝜉
implies the larger range. Then it results in the smaller the covering
number and exists the weighting function with higher probability.
But the performance guarantee on test distribution turns weaker.
The difficulty of extending this theorem to the general situation is
on the choice of 𝑑Ω, since in a general situation, W(𝜅𝐴,𝜅𝐵,𝜅𝜙)is
unbounded set based on defined 𝑑Ωhere. Choosing 𝑑Ω(𝑤1,𝑤2)=
sup|𝑦|≥𝐾sup𝑥∈X|ln𝑤1−ln𝑤2|/|𝑦|2can similarly gain the similar
but complicated result, (since quadratic term existence).
 
1055Model-Agnostic Random Weighting for Out-of-Distribution Generalization KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 3: Empirical results in US-Wide PUMS Data in a domain generalization setting. We report the precision accuracy on test
data. The bold and underline denote the best and the second best results, respectively. MARW shows a consistent advantage.
Metho
dA
CSPublicCoverage A
CSEmployment A
CSTravelTime A
CSIncome A
CSMobility
Mean
Worst Mean
Worst Mean
Worst Mean
Worst Mean
Worst
ERM 64.55%
48.80% 76.25%
71.60% 56.31%
39.10% 76.83%
70.70% 62.44%
46.93%
DRO 65.04% 48.74% 76.41%
71.64% 56.09%
41.50% 76.98%
70.84% 62.08%
48.04%
RWY 61.54%
38.82% 76.19%
71.40% 53.92%
41.20% 75.79%
70.60% 60.56%
50.00%
Fo
cal 64.36%
48.30% 76.23%
71.20% 56.19%
39.10% 77.17% 70.80% 62.37%
47.49%
CVaR 64.98%
49.33% 76.52% 71.83% 57.88% 41.70% 77.28% 70.70% 62.53%
48.23%
LfF 63.90%
47.20% 75.09%
71.40% 55.87%
39.50% 76.38%
70.52% 62.68% 48.04%
JT
T 63.93%
47.28% 76.10%
71.00% 52.88%
40.30% 76.91%
70.50% 62.47%
48.78%
MARW 67.36%
55.63% 76.70%
73.18% 58.25%
43.76% 76.83% 71.76% 63.16%
52.28%
5 Related Works
In this section, we review and compare the works related to our
proposal. According to the difference in assumptions of OOD gen-
eralization from single training environment, the methods fall into
three main categories we discuss below.
5.1 Heterogeneity Identification
This type of methods [ 7,32] put forward to find the environments
with heterogeneity a mixture of multi-source data. Then they learn
an invariant model across the heterogeneous environments. How-
ever, the invariant constraints [ 3] on model parameters limits their
deployment in over-parameterized models. In constrast, MARW is
a model-agnostic method.
5.2 Distributionary Robust Optimization
Distributionary Robust Optimization (DRO) supposes that all the
test distributions come from an uncertainty set of distributions Q,
each of which has a limited distance to the training distribution
[26,40]. Thereby, it aims to minimize the worst excepted risk in Q
to improve the OOD performance. To characterize the distribution
setQ, Duchi and Namkoong [12], Michel et al . [35] consider the
𝜙-divergence metric as a distance measure, Sinha et al . [43] , Staib
and Jegelka [44] concern about the Wasserstein ball or MMD ball
around the training distribution, Delage and Ye [10] utilizes the
moments of distribution to constrain the choice of uncertainty set,
and etc. However, these methods often suffer from hard implemen-
tation of distributed distance calculation, and are easily affected
by the noise of sample. And the uncertainty set is usually overpes-
simistic, leading to the prediction model stuck in the unreasonable
distributions. In contrast, MARW directly approximates the test dis-
tributions utilizing an alternative shifted training distributions, that
promotes the generalization ability upon much sound distributions.
5.3 Debias by Simple Weighting
Recently, some model-agnostic methods are proposed to solve dis-
tribution shift by sample weighting, typically including:
•RWY [ 22] balances the ratio of positive and negative samples
by adding weights to minority class.
•Focal loss [29] up-weights the harder samples based on the
prediction confidence during training.•CVaR [ 47] minimizes the empirical risks on the most at-risk
portion of training samples.
•LfF [ 37] optimizes a pair of models synchronously, making
the training of unbiased model focus on the samples go
against the prejudice of biased model.
•JTT [ 31] first trains a prediction model using ERM, then up-
weights the samples that the first model misclassifies when
training the second unbiased model.
Despite the competitive results in special cases, these methods
perform unstable in different OOD scenarios. In constrast, MARW
can address more general OOD problems with a theoretical support.
6 Experiments
To evaluate the effectiveness of our proposed method, we conduct
extensive experiments in two popular out-of-distribution settings,
namely sub-population generalization and domain generalization,
on various types of real datasets.
6.1 Baselines
In this paper, we compare the generalization performance of MARW
with other model-agnostic methods that can deal with the distri-
bution shift between the training and test data, including ERM,
DRO, RWY, Focal loss, CVaR, LfFandJTT. For a fair compari-
son, we adopt the same backbone model for all the methods in each
experiment.
6.2 Datasets
In experiments, we utilize various types of real datasets for the full
validation of methods, including:
•US-Wide ACS PUMS Data [11]: This large tabular dataset2
based on US Census sources contains individual records.
Each sample provides the profile features, outcome label, as
well as an extra sub-group label. Five prediction tasks are
pre-defined in this dataset, each of which aims to determine
a personal event outcome. For example, the outcome of AC-
SPublicCoverage task is whether an individual is covered by
public health insurance.
2https://github.com/zykls/folktables
 
1056KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
Table 4: Empirical results in VLCS and OGB dataset. 1) In VLCS, we report the precision accuracy on test data. Ours achieves
the best average performance. 2) In OGB, we report the ROC metric on test data (higher value is better) in classification tasks
(molhiv, moltoxcast, molbace), and RMSE metric (lower value is better) in regression tasks (molfreesolv, mollipo). Ours shows
its advantage in both types of tasks.
Metho
dVLCS
(Image Dataset) OGB
(Graph Dataset)
P
ASCAL Lab
elMe Calte
ch Sun A
verage molhiv molto
xcast molbace molfr
eesolv mollip
o
ERM 74.6% 64.3% 97.7% 73.4% 77.5% 76.06% 63.54% 79.15% 2.640 0.797
DRO 75.4% 64.6% 99.1% 70.8% 77.5% 77.56% 63.41% 79.86% 2.709 0.840
RW
Y 75.2% 61.7% 97.9% 70.3% 76.3% 76.80% 63.57% 80.72% - -
Fo
cal 77.0% 63.6% 98.6% 68.2% 76.9% 76.54% 63.77% 80.88% - -
CV
aR 77.0% 63.4% 98.6% 69.3% 77.1% 76.78% 63.35% 81.01% 2.663 0.795
LfF 43.8% 46.5% 61.6% 38.4% 47.6% 72.67% 60.59% 78.38% - -
JT
T 75.5% 62.4% 98.6% 69.1% 76.4% 76.93% 63.35% 80.85% - -
MARW 76.7% 63.5% 99.0% 73.1% 78.1% 77.16% 64.23% 81.44% 2.529 0.785
•CelebA [33]: This dataset3contains the face images of celebri-
ties with attribute annotations. We consider the task of pre-
dicting if hair color of a celebrity is blond [ 41], which is
spuriously related to gender attribute.
•CivilComments [5]: This dataset4collects the user-generated
public comments online. We consider the task of predicting
whether a comment is toxic [ 23], which is spuriously related
to 8 demographic identities.
•VLCS [13]: This dataset5gathers the images from 4 separate
datasets (PASCAL VOC, LabelMe, Caltech, and Sun). Distri-
bution shift comes from the heterogeneity between these
data sources.
•OGB [21]: The Open Graph Benchmark (OGB)6is a collec-
tion of realistic graph datasets with pre-defined tasks. In our
experiments, we consider 5 graph-level tasks, which aim to
predict some properties of molecules. The molecules are split
based on their scaffolds, causing the data distribution shift.
6.3 Sub-population Generalization
6.3.1 Experimental Setting. In this section, we first validate the
methods in the sub-population generalization setting, where the
training data composes of a group of sub-populations, but the por-
tion of each sub-population in training data is different. As a result,
the prediction model is prone to overlook the minor groups, while
falsely learns the spurious correlations in the major groups. In test
stage, the model is evaluated in each sub-population separately
to verify if it is trapped by the imbalance training data. Referring
to [31], we take the worst-case result among all the sub-populations
as the main evaluation metric.
In this setting, we conduct experiments in 3 datasets. For all 5
tasks in US-Wide ACS PUMS Data, we partition out 8 sub-populations
according to the hybird of group and state, and collect training sam-
ples in different data size from each sub-population. For CelebA and
CivilComments dataset, we keep the same configuration with [ 31].
3https://drive.google.com/drive/folders/0B7EVK8r0v71pWEZsZE9oNnFzTm8?resourcekey=0-
5BR16BdXnb8hVj6CNHKzLg&usp=sharing
4https://github.com/p-lambda/wilds/
5http://www.mediafire.com/file/7yv132lgn1v267r/vlcs.tar.gz/file
6https://github.com/snap-stanford/ogb6.3.2 Experimental Result. From the results in ACS PUMS Data in
Table 1, we see that:
(1)ERM is sensitive to distribution shift. Its performance sharply
descends in the minor sub-population due to the substantial
imbalance in training data.
(2)DRO achieves the similar performances with ERM. The sam-
ple noise is easy to interfere the correct finding of minor
sub-populations in this dataset.
(3)RWY, Focal loss, CVaR and LfF perform unstably in differ-
ent tasks relying on if their assumptions of model failure’s
reasons hold in the corresponding task.
(4)JTT presents competitive results against sub-population shift.
(5)Compared to baselines, MARW shows superior performance
in all tasks. It reaches the best two results of worst accu-
racy in most cases, that verifies its effectiveness for sub-
population generalization.
The results in CelebA and Civilcomments dataset are reported in
Table 2. Besides ERM, each of the methods can promote the OOD
performance from different perspective. Among them, MARW and
JTT gain the best two results in both two datasets, suggesting their
advances in the sub-population generalization problem.
6.4 Domain Generalization
6.4.1 Experimental Setting. In this section, we validate the meth-
ods in the domain generalization setting. Different from the sub-
population generalization, domain generalization considers that
the test samples come from distinct data environments that are
unseen during training, instead of a sub-population of training data.
The core of domain generalization is whether the model can learn
a prediction function from the limited training environment that
can generalize to more data environments. Hence, we also concern
about the model’s average performance in all test environments, in
addition to the worst-case result.
In this setting, we also conduct experiments in 3 datasets. For
US-Wide ACS PUMS Data, we simulate different environments
according to the group label and state, select training samples of
group 1 from partial states, and test samples of other groups from
whole states. For VLCS dataset, we choose one data domain for test
 
1057Model-Agnostic Random Weighting for Out-of-Distribution Generalization KDD ’24, August 25–29, 2024, Barcelona, Spain
(a) The curve from the number of weighting functions to
model’s OOD performance.
（×10 ）5(b) The curve from the intensity of variance penalty to
model’s OOD performance.
Figure 2: Empirical model analysis unfolded in ACSMobility task. Green and red lines denote mean accuracy and the worst
accuracy, respectively. We see that: 1) as more shifted training distributions appear, MARW’s generalization ability is gradually
enhanced until convergence (a); 2) although the reduction of risk variance benefits the OOD performance, it will hurt model
optimization if the intensity is too large (b).
and the others for training in turn. For OGB dataset, the training
and test data is divided depending on the scaffolds [21].
6.4.2 Experimental Result. From the results in ACS PUMS Data in
Table 3, we observe that:
(1)The unseen test environments in domain generalization usually
imply the heightened distribution shifts, leading to a larger drop
in the performance of traditional ERM.
(2)The performance of DRO is not stable, depending on the mag-
nitude of distribution shift. It performs better upon small shift.
(3)RWY, Focal loss, LfF, and JTT can improve the OOD perfor-
mance in some cases, but still suffer from the unstable problem.
(4) CVaR presents competitive results in this setting.
(5)MARW achieves the best results on both average and worst
accuracy in almost all the tasks. And its advantage is more
significant in domain generalization than that in sub-population
generalization, demonstrating the superiority of our method to
address distribution shift.
Table 4 shows the results in VLCS dataset. Although ERM has
shown farily strong performance [ 18], MARW can still outperforms
the baselines with a higher average performance. The results in
OGB dataset are reported in Table 4 as well. This dataset contains
both classification tasks and regression tasks. Because RWY, Fo-
cal loss, LfF, and JTT are designed for classification, we compare
MARW with DRO, CVaR and ERM in regression tasks (molfreesolv
and mollipo). Compared to the baselines, MARW works well in
both types of tasks thanks to its way of shifting distribution that is
free to the prediction model.
6.5 Model Analysis
Further, we investigate how our method works empirically by the
experiments in US-Wide PUMS Data.
6.5.1 Impact of the Number of Weighting Functions. Firstly, we
change the number of random weighting at each optimization step,
and observe the performances of MARW. The results (Figure 2(a))
points that as the number increases, the model’s generalizationability rises up owing to more potential distributions being ac-
cessed. However, the performance convergences after the number
exceeds a threshold (5 in Figure 2(a)), that says the finite weighting
functions can cover the representative test distributions for OOD
generalization.
6.5.2 Role of Variance Penalty. Secondly, we change the coeffi-
cient of variance penalty to see how it drives the prediction model
towards better generalization. From Figure 2(b), we find that the
stronger variance penalty will force the model to be more stable
in different distributions, thus eliminating the biased correlations.
However, the high-intensity penalty would affect the learning abil-
ity of the model, because the variance of noise term is distinct in
different environments.
7 Conclusion
In this paper, we present a novel model-agnostic approach, the
Model-Agnostic Random Weighting (MARW) method, designed
for out-of-distribution (OOD) generalization from single training
environment. MARW leverages sample-based weighting within a
designated function space to stochastically generate shifted training
environments. This method enables the subsequent training of a
prediction model with emphasis on robust weighted empirical risks.
We provide theoretical evidence supporting the approximation of
test distributions by the shifted training data, ensuring the model’s
guaranteed OOD performance in uncertain test distributions. Fi-
nally, we conduct comprehensive experiments to demonstrate the
advanced capabilities of our model, particularly its effectiveness in
various OOD generalization tasks.
Acknowledgments
This work was supported in part by National Natural Science Foun-
dation of China (No. 62141607), China National Postdoctoral Pro-
gram for Innovative Talents (BX20230195), Beijing Natural Science
Foundation (QY23081). All opinions in this paper are those of the
authors and do not necessarily reflect the views of the funding
agencies. We would like to all the anonymous reviewers for the
helpful feedback.
 
1058KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
References
[1]Alekh Agarwal and Tong Zhang. 2022. Minimax regret optimization for robust
machine learning under distribution shift. In Conference on Learning Theory.
PMLR, 2704–2729.
[2]Kartik Ahuja, Jun Wang, Amit Dhurandhar, Karthikeyan Shanmugam, and Kush R
Varshney. 2020. Empirical or invariant risk minimization? a sample complexity
perspective. arXiv preprint arXiv:2010.16412 (2020).
[3]Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. 2019.
Invariant risk minimization. arXiv preprint arXiv:1907.02893 (2019).
[4]Ben Babcock and Adam Van Tuyl. 2011. Revisiting the spreading and covering
numbers. arXiv preprint arXiv:1109.5847 (2011).
[5]Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasser-
man. 2019. Nuanced metrics for measuring unintended bias with real data for text
classification. In Companion proceedings of the 2019 world wide web conference.
491–500.
[6]Fabio M Carlucci, Antonio D’Innocente, Silvia Bucci, Barbara Caputo, and Tatiana
Tommasi. 2019. Domain generalization by solving jigsaw puzzles. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2229–
2238.
[7]Elliot Creager, Jörn-Henrik Jacobsen, and Richard Zemel. 2021. Environment
inference for invariant learning. In International Conference on Machine Learning.
PMLR, 2189–2200.
[8]Brandon Da Silva and Sylvie Shang Shi. 1906. Towards improved generalization
in financial markets with synthetic data generation. arXiv preprint arXiv (1906).
[9]Wenyuan Dai, Qiang Yang, Gui-Rong Xue, and Yong Yu. 2007. Boosting for
transfer learning. In Proceedings of the 24th international conference on Machine
learning. 193–200.
[10] Erick Delage and Yinyu Ye. 2010. Distributionally robust optimization under mo-
ment uncertainty with application to data-driven problems. Operations research
58, 3 (2010), 595–612.
[11] Frances Ding, Moritz Hardt, John Miller, and Ludwig Schmidt. 2021. Retiring
adult: New datasets for fair machine learning. Advances in neural information
processing systems 34 (2021), 6478–6490.
[12] John Duchi and Hongseok Namkoong. 2019. Variance-based regularization with
convex objectives. Journal of Machine Learning Research 20, 68 (2019), 1–55.
[13] Chen Fang, Ye Xu, and Daniel N Rockmore. 2013. Unbiased metric learning:
On the utilization of multiple datasets and web images for softening bias. In
Proceedings of the IEEE International Conference on Computer Vision. 1657–1664.
[14] Abolfazl Farahani, Sahar Voghoei, Khaled Rasheed, and Hamid R Arabnia. 2021.
A brief review of domain adaptation. Advances in data science and information
engineering: proceedings from ICDATA 2020 and IKE 2020 (2021), 877–894.
[15] Dailin Gan and Jun Li. 2023. SCIBER: a simple method for removing batch effects
from single-cell RNA-sequencing data. Bioinformatics 39, 1 (2023), btac819.
[16] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, François Laviolette, Mario March, and Victor Lempitsky. 2016.
Domain-adversarial training of neural networks. Journal of machine learning
research 17, 59 (2016), 1–35.
[17] Muhammad Ghifary, W Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi.
2015. Domain generalization for object recognition with multi-task autoencoders.
InProceedings of the IEEE international conference on computer vision. 2551–2559.
[18] Ishaan Gulrajani and David Lopez-Paz. 2020. In search of lost domain generaliza-
tion. arXiv preprint arXiv:2007.01434 (2020).
[19] Negar Hassanpour and Russell Greiner. 2019. CounterFactual Regression with
Importance Sampling Weights.. In IJCAI. 5880–5887.
[20] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual
learning for image recognition. In Proceedings of the IEEE conference on computer
vision and pattern recognition. 770–778.
[21] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu,
Michele Catasta, and Jure Leskovec. 2020. Open graph benchmark: Datasets for
machine learning on graphs. Advances in neural information processing systems
33 (2020), 22118–22133.
[22] Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-
Paz. 2022. Simple data balancing achieves competitive worst-group-accuracy. In
Conference on Causal Learning and Reasoning. PMLR, 336–351.
[23] Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin
Zhang, Akshay Balsubramani, Weihua Hu, Michihiro Yasunaga, Richard Lanas
Phillips, Irena Gao, et al .2021. Wilds: A benchmark of in-the-wild distribution
shifts. In International conference on machine learning. PMLR, 5637–5664.
[24] Masanori Koyama and Shoichiro Yamaguchi. 2020. Out-of-distribution general-
ization with maximal invariant predictor. (2020).
[25] David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan
Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. 2021. Out-of-
distribution generalization via risk extrapolation (rex). In International Conference
on Machine Learning. PMLR, 5815–5826.[26] Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh
Shafieezadeh-Abadeh. 2019. Wasserstein distributionally robust optimization:
Theory and applications in machine learning. In Operations research & manage-
ment science in the age of analytics. Informs, 130–166.
[27] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales. 2018. Learning to
generalize: Meta-learning for domain generalization. In Proceedings of the AAAI
conference on artificial intelligence, Vol. 32.
[28] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. 2017. Deeper,
broader and artier domain generalization. In Proceedings of the IEEE international
conference on computer vision. 5542–5550.
[29] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. 2017.
Focal loss for dense object detection. In Proceedings of the IEEE international
conference on computer vision. 2980–2988.
[30] Yong Lin, Shengyu Zhu, Lu Tan, and Peng Cui. 2022. Zin: When and how to
learn invariance without environment partition? Advances in Neural Information
Processing Systems 35 (2022), 24529–24542.
[31] Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh,
Shiori Sagawa, Percy Liang, and Chelsea Finn. 2021. Just train twice: Improving
group robustness without training group information. In International Conference
on Machine Learning. PMLR, 6781–6792.
[32] Jiashuo Liu, Zheyuan Hu, Peng Cui, Bo Li, and Zheyan Shen. 2021. Heterogeneous
risk minimization. In International Conference on Machine Learning. PMLR, 6804–
6814.
[33] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep learning
face attributes in the wild. In Proceedings of the IEEE international conference on
computer vision. 3730–3738.
[34] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram
Galstyan. 2021. A survey on bias and fairness in machine learning. ACM com-
puting surveys (CSUR) 54, 6 (2021), 1–35.
[35] Paul Michel, Tatsunori Hashimoto, and Graham Neubig. 2021. Modeling the sec-
ond player in distributionally robust optimization. arXiv preprint arXiv:2103.10282
(2021).
[36] Krikamol Muandet, David Balduzzi, and Bernhard Schölkopf. 2013. Domain
generalization via invariant feature representation. In International conference on
machine learning. PMLR, 10–18.
[37] Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. 2020.
Learning from failure: De-biasing classifier from biased classifier. Advances in
Neural Information Processing Systems 33 (2020), 20673–20684.
[38] Jonas Peters, Peter Bühlmann, and Nicolai Meinshausen. 2016. Causal inference
by using invariant prediction: identification and confidence intervals. Journal of
the Royal Statistical Society Series B: Statistical Methodology 78, 5 (2016), 947–1012.
[39] Andrea Piazzoni, Jim Cherian, Martin Slavik, and Justin Dauwels. 2020. Modeling
perception errors towards robust decision making in autonomous vehicles. arXiv
preprint arXiv:2001.11695 (2020).
[40] Hamed Rahimian and Sanjay Mehrotra. 2019. Distributionally robust optimiza-
tion: A review. arXiv preprint arXiv:1908.05659 (2019).
[41] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. 2019.
Distributionally robust neural networks for group shifts: On the importance
of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731
(2019).
[42] Hidetoshi Shimodaira. 2000. Improving predictive inference under covariate
shift by weighting the log-likelihood function. Journal of statistical planning and
inference 90, 2 (2000), 227–244.
[43] Aman Sinha, Hongseok Namkoong, Riccardo Volpi, and John Duchi. 2017. Certi-
fying some distributional robustness with principled adversarial training. arXiv
preprint arXiv:1710.10571 (2017).
[44] Matthew Staib and Stefanie Jegelka. 2019. Distributionally robust optimization
and generalization in kernel methods. Advances in Neural Information Processing
Systems 32 (2019).
[45] Baochen Sun and Kate Saenko. 2016. Deep coral: Correlation alignment for
deep domain adaptation. In Computer Vision–ECCV 2016 Workshops: Amsterdam,
The Netherlands, October 8-10 and 15-16, 2016, Proceedings, Part III 14. Springer,
443–450.
[46] Renzhe Xu, Xingxuan Zhang, Zheyan Shen, Tong Zhang, and Peng Cui. 2022.
A Theoretical Analysis on Independence-driven Importance Weighting for
Covariate-shift Generalization. In International Conference on Machine Learning.
PMLR, 24803–24829.
[47] Ziyu Xu, Chen Dan, Justin Khim, and Pradeep Ravikumar. 2020. Class-weighted
classification: Trade-offs and robust approaches. In International conference on
machine learning. PMLR, 10544–10554.
[48] Chaoqi Yang, M Brandon Westover, and Jimeng Sun. 2023. ManyDG: many-
domain generalization for healthcare applications. arXiv preprint arXiv:2301.08834
(2023).
[49] Xu Zhang, Zhiqiang Ye, Jing Chen, and Feng Qiao. 2022. AMDBNorm: an ap-
proach based on distribution adjustment to eliminate batch effects of gene ex-
pression data. Briefings in Bioinformatics 23, 1 (2022), bbab528.
 
1059Model-Agnostic Random Weighting for Out-of-Distribution Generalization KDD ’24, August 25–29, 2024, Barcelona, Spain
Appendix
A Proof of Equation 3 and 4
Proof. We denote Γ𝑒=𝜇𝑒+𝜀for any environment 𝑒∈E𝑎𝑙𝑙and
consider the map Ψ:(𝑋,Γ)→(𝑋,𝑌).Denote𝑥,𝑦,𝛾 as the value
of the correspondingly random variables. Then the Jacobi matrix
of the map Ψis
𝜕(𝑥,𝑦)
𝜕(𝑥,𝛾)=1 0
𝑓′(𝑥+𝜂𝑒)1
.
Therefore𝜕(𝑥,𝑦)
𝜕(𝑥,𝛾)=1.Note that𝑋andΓare independent,
𝑃𝑒(𝑥)𝑃𝑒(𝛾)=𝑃𝑒(𝑥,𝛾)=𝑃𝑒(𝑥,𝑦)𝜕(𝑥,𝑦)
𝜕(𝑥,𝛾)=𝑃𝑒(𝑥,𝑦),
for all𝑒∈E𝑎𝑙𝑙. Then
𝑃𝑒(𝑥,𝑦)
𝑃𝑡𝑟(𝑥,𝑦)=𝑃𝑒(𝑥)𝑃𝑒(𝛾)
𝑃𝑡𝑟(𝑥)𝑃𝑡𝑟(𝛾)=𝑃𝑒(𝑥)
𝑃𝑡𝑟(𝑥)1√
2𝜋𝜎2𝑒exp(−1
2𝜎2𝑒(𝛾−𝜇𝑒)2)
1√︃
2𝜋𝜎2
𝑡𝑟exp(−1
2𝜎2
𝑡𝑟(𝛾−𝜇𝑡𝑟)2)
=𝑃𝑒(𝑥)𝜎𝑡𝑟
𝑃𝑡𝑟(𝑥)𝜎𝑒exp[1
2𝜎2
𝑡𝑟(𝑦−𝑓(𝑥+𝜂𝑡𝑟)−𝜇𝑡𝑟)2−1
2𝜎2𝑒(𝑦−𝑓(𝑥+𝜂𝑒)−𝜇𝑒)2]
=exp[(1
2𝜎2
𝑡𝑟−1
2𝜎2𝑒)𝑦2+(𝜇𝑒
𝜎2𝑒−𝜇𝑡𝑟
𝜎2
𝑡𝑟)𝑦]
·exp[(1
𝜎2𝑒𝑓(𝑥+𝜂𝑒)−1
𝜎2
𝑡𝑟𝑓(𝑥+𝜂𝑡𝑟))𝑦].
We can obtain Equation 3 and 4. □
B Proof of Theorem 4.1
Proof. Actually,
|𝐴𝑒|=1
2𝜎2
𝑡𝑟|𝜎2
𝑡𝑟
𝜎2𝑒−1|≤𝑟2−1
2𝜎2
𝑡𝑟,|𝐵𝑒|=|𝜇𝑡𝑟|
𝜎2
𝑡𝑟|𝜇𝑒
𝜇𝑡𝑟𝜎2
𝑡𝑟
𝜎2𝑒−1|≤|𝜇𝑡𝑟|
𝜎2
𝑡𝑟(𝑟3−1)
|lnℎ𝑒|=|ln𝜎𝑡𝑟
𝜎𝑒+ln𝑃𝑒(𝑥)
𝑃𝑡𝑟(𝑥)+[(𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟)2
2𝜎2
𝑡𝑟−(𝑓(𝑥+𝜂𝑒)+𝜇𝑒)2
2𝜎2𝑒]|
≤2 ln𝑟+1
2|𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟
𝜎𝑡𝑟−𝑓(𝑥+𝜂𝑒)+𝜇𝑒
𝜎𝑒|
·|𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟
𝜎𝑡𝑟+𝑓(𝑥+𝜂𝑒)+𝜇𝑒
𝜎𝑒|
Since
|𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟
𝜎𝑡𝑟+𝑓(𝑥+𝜂𝑒)+𝜇𝑒
𝜎𝑒|
≤|𝑀+𝜇𝑡𝑟
𝜎𝑡𝑟+𝑀+𝑟𝜇𝑡𝑟
𝜎𝑡𝑟/𝑟|
=(𝑟+1)𝑀+(𝑟2+1)|𝜇𝑡𝑟|
𝜎𝑡𝑟,
and
|𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟
𝜎𝑡𝑟−𝑓(𝑥+𝜂𝑒)+𝜇𝑒
𝜎𝑒|
≤|𝑓(𝑥+𝜂𝑡𝑟)
𝜎𝑡𝑟−𝑓(𝑥+𝜂𝑒)
𝜎𝑒|+|𝜇𝑡𝑟
𝜎𝑡𝑟−𝜇𝑒
𝜎𝑒|
≤|𝑓(𝑥+𝜂𝑡𝑟)|
𝜎𝑡𝑟|𝜎𝑡𝑟
𝜎𝑒𝑓(𝑥+𝜂𝑒)
𝑓(𝑥+𝜂𝑡𝑟)−1|+|𝜇𝑡𝑟|
𝜎𝑡𝑟|𝜇𝑒
𝜇𝑡𝑟𝜎𝑡𝑟
𝜎𝑒−1|
≤𝑀
𝜎𝑡𝑟(𝑟𝑀+𝐿𝛿
𝑀−1)+|𝜇𝑡𝑟|
𝜎𝑡𝑟(𝑟2−1)
=1
𝜎𝑡𝑟((𝑟−1)𝑀+𝑟𝐿𝛿+|𝜇𝑡𝑟|(𝑟2−1)).Hence
|lnℎ𝑒|≤2 ln𝑟+(𝑟+1)𝑀+(𝑟2+1)|𝜇𝑡𝑟|
2𝜎2
𝑡𝑟((𝑟−1)𝑀+𝑟𝐿𝛿+|𝜇𝑡𝑟|(𝑟2−1)).
|ln𝑔𝑒|≤|𝑓(𝑥+𝜂𝑒)
𝜎2𝑒−𝑓(𝑥+𝜂𝑡𝑟)
𝜎2
𝑡𝑟||𝑦|
=|𝑓(𝑥+𝜂𝑡𝑟)|
𝜎2
𝑡𝑟(𝑟2|𝑓(𝑥+𝜂𝑡𝑟)|+𝐿𝛿
|𝑓(𝑥+𝜂𝑡𝑟)|−1)|𝑦|
=1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟𝐿𝛿)|𝑦|.
Then since𝑤∈W(𝜅𝐴,𝜅𝐵,𝜅𝜙), then by definition, we have
|ln𝑤(𝑥,𝑦)|≤𝜅𝐴𝑦2+𝜅𝐵|𝑦|+𝜅𝜙.
Then we can obtain the conclusion. □
C Proof of Theorem 4.2
Proof. Since we have acquired the concrete upper bound in
Proof of Theorem 4.1, then as long as
𝜅𝐴≥𝑟2−1
2𝜎2
𝑡𝑟, 𝜅𝐵≥|𝜇𝑡𝑟|(𝑟3−1)
𝜎2
𝑡𝑟,
and
𝜅𝜙≥2 ln𝑟+(𝑟+1)𝑀+(𝑟2+1)|𝜇𝑡𝑟|
2𝜎2
𝑡𝑟[(𝑟−1)𝑀+𝑟𝐿𝛿+|𝜇𝑡𝑟|(𝑟2−1)].
For any environment 𝑒∈E(𝑟,𝛿), there exist 𝑤(𝑥,𝑦)=exp(𝐴𝑦2+
𝐵𝑦)ℎ(𝑥;𝜙)∈W(𝜅𝐴,𝜅𝐵,𝜅𝜙), such that
𝐴=𝐴𝑒, 𝐵=𝐵𝑒, ℎ(𝑥;𝜙)=ℎ𝑒(𝑥).
Then for this 𝑤(𝑥,𝑦)and for∀𝑦∈Y, we have
sup
𝑥∈X|ln𝑤(𝑥,𝑦)−ln𝑤𝑒(𝑥,𝑦)|=sup
𝑥∈X|ln𝑔𝑒(𝑥,𝑦)|≤|𝑦|1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟𝐿𝛿).
□
D Proof of Theorem 4.3
Proof. First, we can find that ∀𝜃∈Θ,
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|
=E𝑡𝑒E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|≥𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
+E𝑡𝑒E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|<𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
.
Since
lim
𝑁→∞E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|≥𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
=0.
Then by E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|≥𝜎𝑡𝑟𝑧1−𝑞/2)
≤E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|
<
∞and Lebesgue Dominated Convergence theorem, we have
lim
𝑞→0E𝑡𝑒E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|≥𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
=0.
Hence for small positive 𝛼>0, there exist 𝑞, such that
E𝑡𝑒E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|≥𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
=𝛼.
We can observe that the large 𝑞=𝑞(𝛼)is, the large 𝛼is. From the
conclusion of the inverse function, 𝑞(𝛼)is an increasing function.
 
1060KDD ’24, August 25–29, 2024, Barcelona, Spain Yue He et al.
We next consider the second term, for any 𝑥∈X and small
𝛼∈R+,∀|𝜀|<𝜎𝑡𝑟𝑧1−𝑞(𝛼)/2, since we collect data from training
distribution, hence
|𝑦|=|𝑓(𝑥+𝜂𝑡𝑟)+𝜇𝑡𝑟+𝜖|≤𝑀+|𝜇𝑡𝑟|+𝜎𝑡𝑟𝑧1−𝑞(𝛼)/2,
and
exp{|𝑦|1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟𝐿𝛿)}
≤exp{(𝑀+|𝜇𝑡𝑟|+𝜎𝑡𝑟𝑧1−𝑞(𝛼)/2)1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟𝐿𝛿)}.
We consider
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|<𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
=∫
𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)|𝑦−ˆ𝑓𝜃(𝑥)|
𝑤𝑒(𝑥,𝑦)
𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)𝑃𝑡𝑟(𝑦|𝑥)𝐼(|𝜀|<𝜎𝑡𝑟𝑧1−𝑞/2)𝑑𝑦
≤𝐶𝛼E𝑡𝑒
𝑤(𝑥,𝑦;𝐴𝑗,𝐵𝑗,𝜙𝑗)|𝑌−ˆ𝑓𝜃(𝑋)|𝑋
,
where
𝐶𝛼=exp{(𝑀+|𝜇𝑡𝑟|+𝜎𝑡𝑟𝑧1−𝑞(𝛼)/2)1
𝜎2
𝑡𝑟((𝑟2−1)𝑀+𝑟𝐿𝛿)}.
Hence
E𝑡𝑒E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝜀|<𝜎𝑡𝑟𝑧1−𝑞/2)𝑋
≤𝐶𝛼E𝑡𝑟
𝑤(𝑋,𝑌;𝐴𝑗,𝐵𝑗,𝜙𝑗)𝑌−ˆ𝑓𝜃(𝑋)
Then we obtain the result.
□
E Proof of THEOREM 4.5
Proof. We have
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|
=E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌≥𝐾|)
+E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌<𝐾|)
Then
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌<𝐾|)
=∫
|𝑦−ˆ𝑓𝜃(𝑥)|𝑤(𝑥,𝑦;𝐵,𝜙)𝜋(𝑤𝑒(𝑥,𝑦))
𝑤(𝑥,𝑦;𝐵,𝜙)𝑤𝑒(𝑥,𝑦)
𝜋(𝑤𝑒(𝑥,𝑦))𝐼(|𝑦|<𝐾)𝑃𝑡𝑟(𝑥,𝑦)𝑑𝑥𝑑𝑦.
Denote𝜋(𝑤𝑒)=arg inf𝑤∈W( 0,𝜅𝐵,𝜅𝜙)𝑑Ω(𝑤,𝑤𝑒)as the projection
of𝑤𝑒, for|𝑦|≤𝐾,
𝑤𝑒(𝑥,𝑦)
𝜋(𝑤𝑒(𝑥,𝑦))≤exp(𝐿𝛿
𝜎2|𝑦|)≤exp(𝐿𝛿
𝜎2𝐾),
then from definition of covering number, we can know that with
probability 1−(1−N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)−1)𝑆,
𝑑Ω(𝑤(𝑥,𝑦;𝐵,𝜙),𝜋(𝑤𝑒(𝑥,𝑦)))≤ 2𝜉,
i.e.,
∀|𝑦|≥𝐾, sup
𝑥∈X|ln𝑤−ln𝜋(𝑤𝑒)
𝑦|≤2𝜉,We take𝑤=exp(𝐵𝑦)ℎ(𝑥,𝜙)and𝜋(𝑤𝑒)=exp(𝐵𝜋𝑦)ℎ(𝑥,𝜙𝜋)do
simple computation,
sup
𝑥∈X|(𝐵−𝐵𝜋)𝑦+lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|≤ 2𝜉|𝑦|,∀|𝑦|≥𝐾,
hence|𝐵−𝐵𝜋|≤2𝜉, and take𝑦=𝐾, we have
2𝜉𝐾≥sup
𝑥∈X|(𝐵−𝐵𝜋)𝐾+lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|
≥sup
𝑥∈X|lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|−|(𝐵−𝐵𝜋)𝐾|
≥sup
𝑥∈X|lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|−2𝜉𝐾.
So
sup
𝑥∈X|lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|≤ 4𝜉𝐾.
Then we know that for |𝑦|≤𝐾,
𝜋(𝑤𝑒)
𝑤≤exp(|(𝐵−𝐵𝜋)𝑦+lnℎ(𝑥,𝜙)−lnℎ(𝑥,𝜙𝜋)|)≤ exp(6𝜉𝐾).
So
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌<𝐾|)
≤exp(𝐿𝛿
𝜎2+6𝜉𝐾)E𝑡𝑟
𝑤(𝑥,𝑦;𝐵,𝜙)|𝑌−ˆ𝑓𝜃(𝑋)|
Then consider another term E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌≥𝐾|)
, since
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌≥𝐾|)
=∫
|𝑦−ˆ𝑓𝜃(𝑥)|𝑤(𝑥,𝑦;𝐵,𝜙)𝑤𝑒(𝑥,𝑦)
𝑤(𝑥,𝑦;𝐵,𝜙)𝐼(|𝑦|≥𝐾)𝑃𝑡𝑟(𝑥,𝑦)𝑑𝑥𝑑𝑦
From definition of covering number, with probability 1−(1−
N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)−1)𝑆,
𝑑Ω(𝑤,𝑤𝑒)≤𝐿𝛿
𝜎2+2𝜉,
hence for|𝑦|≥𝐾,
𝑤𝑒(𝑥,𝑦)
𝑤(𝑥,𝑦;𝐵,𝜙)≤exp((𝐿𝛿
𝜎2+2𝜉)|𝑦|),
we have
E𝑡𝑒
|𝑌−ˆ𝑓𝜃(𝑋)|𝐼(|𝑌≥𝐾|)
≤∫
|𝑦−ˆ𝑓𝜃(𝑥)|𝑤(𝑥,𝑦;𝐵,𝜙)exp((𝐿𝛿
𝜎2+2𝜉)|𝑦|)𝐼(|𝑦|≥𝐾)𝑃𝑡𝑟(𝑥,𝑦)𝑑𝑥𝑑𝑦.
Then repeat the similar proof of Theorem 4.3, and with probability
1−(1−N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)−1)𝑆,
E𝑡𝑒h𝑌−ˆ𝑓𝜃(𝑋)i
≤exp((𝐿𝛿
𝜎2+2𝜉)(𝑀+|𝜇𝑡𝑟|+𝜎𝑧1−𝑞(𝛼)/2))
·E𝑡𝑟h
𝑤(𝑋,𝑌;𝐵,𝜙)𝑌−ˆ𝑓𝜃(𝑋)i
+𝛼.
Above all, with probability 1−(1−N(W( 0,𝜅𝐵,𝜅𝜙),𝜉,𝑑Ω)−1)𝑆,
there exist 𝐶𝛼=exp[(2𝜉+𝐿𝛿/𝜎2)(𝑀+|𝜇𝑡𝑟|+𝑧1−𝑞(𝛼)/2𝜎)]+
exp(6𝜉𝐾+𝐿𝛿/𝜎2)such that
∀𝜃∈Θ,E𝑡𝑒h𝑌−ˆ𝑓𝜃(𝑋)i
≤𝐶𝛼E𝑡𝑟h
𝑤(𝑋,𝑌;𝐵,𝜙)𝑌−ˆ𝑓𝜃(𝑋)i
+𝛼,
where𝑧1−𝑞(𝛼)/2represents 1−𝑞(𝛼)/2quantile of Gaussian distri-
bution and𝑞(𝛼)is increasing about 𝛼. □
 
1061