Unveiling Global Interactive Patterns across Graphs: Towards
Interpretable Graph Neural Networks
Yuwen Wang
School of Software Technology, Zhejiang University
State Key Laboratory of Blockchain and Security, Zhejiang
University
Hangzhou High-Tech Zone (Binjiang) Institute of
Blockchain and Data Security
Hangzhou, China
yuwenwang@zju.edu.cnShunyu Liu∗
State Key Laboratory of Blockchain and Security, Zhejiang
University
Hangzhou High-Tech Zone (Binjiang) Institute of
Blockchain and Data Security
Hangzhou, China
liushunyu@zju.edu.cn
Tongya Zheng
Big Graph Center, School of Computer and Computing
Science, Hangzhou City University
College of Computer Science and Technology, Zhejiang
University
Hangzhou, China
tyzheng@zju.edu.cnKaixuan Chen
Mingli Song
State Key Laboratory of Blockchain and Security, Zhejiang
University
Hangzhou High-Tech Zone (Binjiang) Institute of
Blockchain and Data Security
Hangzhou, China
{chenkx,brooksong}@zju.edu.cn
ABSTRACT
Graph Neural Networks (GNNs) have emerged as a prominent
framework for graph mining, leading to significant advances across
various domains. Stemmed from the node-wise representations of
GNNs, existing explanation studies have embraced the subgraph-
specific viewpoint that attributes the decision results to the salient
features and local structures of nodes. However, graph-level tasks
necessitate long-range dependencies and global interactions for
advanced GNNs, deviating significantly from subgraph-specific
explanations. To bridge this gap, this paper proposes a novel in-
trinsically interpretable scheme for graph classification, termed as
Global Interactive Pattern (GIP) learning, which introduces learn-
able global interactive patterns to explicitly interpret decisions. GIP
first tackles the complexity of interpretation by clustering numer-
ous nodes using a constrained graph clustering module. Then, it
matches the coarsened global interactive instance with a batch of
self-interpretable graph prototypes, thereby facilitating a trans-
parent graph-level reasoning process. Extensive experiments con-
ducted on both synthetic and real-world benchmarks demonstrate
that the proposed GIP yields significantly superior interpretability
and competitive performance to the state-of-the-art counterparts.
Our code will be made publicly available1.
∗Shunyu Liu is the corresponding Author.
1The code is available at https://github.com/Wangyuwen0627/GIP-Framework.git.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671838CCS CONCEPTS
•Information systems →Data mining; •Computing method-
ologies→Learning latent representations.
KEYWORDS
Graph Neural Network, Interpretability, Graph Mining
ACM Reference Format:
Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, and Mingli Song.
2024. Unveiling Global Interactive Patterns across Graphs: Towards Inter-
pretable Graph Neural Networks. In Proceedings of the 30th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining (KDD ’24), August
25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. https:
//doi.org/10.1145/3637528.3671838
1 INTRODUCTION
Graphs, serving as data structures capable of naturally modeling
intricate relationships between entities, have pervasive applications
in real-world scenarios, such as transportation networks [ 6,71],
social networks [ 36,65], power system [ 9,11,34], and biologi-
cal molecules [ 24,44]. In recent years, to effectively uncover po-
tential information in graphs for applications, graph neural net-
works (GNNs) [ 10,23,29,52] have emerged as a prominent para-
digm and made remarkable achievements. Following a message-
passing mechanism, GNNs aggregate the information from the local
neighbors of each node to obtain node-wise representations, bolster-
ing the development in various downstream tasks including node
classification [ 10,35,56,73] and graph classification [ 12,23,29,52].
Despite the remarkable effectiveness of GNNs, their lack of ex-
plainability hinders human trust and thus limits their application
in safety-critical domains. To mitigate this issue, recent efforts have
explored identifying informative subgraphs that serve as either
post-hoc or intrinsic explanations for the decisions made by GNNs.
3277
KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
Specifically, a line of post-hoc studies [ 37,54,66] work on a pre-
trained model and propose different combinatorial search methods
for identifying the most influential subgraphs based on model pre-
dictions. However, since these methods train another explanatory
model to provide explanations, they may be disloyal to the original
model, resulting in distorted attribution analysis. In contrast to the
post-hoc methods, the intrinsically interpretable ones endeavour
to identify subgraphs during training and make reliable predictions
guided by these subgraphs [ 39,64,68]. The pioneering works, e.g.
GIB [ 39] and GSAT [ 68], adopt the information bottleneck prin-
ciple [ 59] to constraint the information flow from input graph to
prediction, ensuring the label-relevant graph components will be
kept while the label-irrelevant ones are reduced. Additionally, Prot-
GNN [ 72] learns representative subgraphs (i.e., prototypes) from
inputs by prototype learning [ 30] and makes predictions based
on the similarity between new instances and prototypes. Unfortu-
nately, the explanation graph is generated by an extra projection
process based on the prototype embedding, which can introduce
explanatory biases.
Graph-level tasks often necessitate global-level explanations to
depict long-range dependencies and global interactions considering
the whole graph [ 4,16,32,63]. For example, in the case of protein
molecules, enzymes are distinguished from other non-enzyme pro-
teins by having fewer helices, more and longer loops, and tighter
packing between secondary structures [ 50]. Identifying such global
structural patterns often requires the collective participation of
dozens or even hundreds of amino acids. It is time-consuming to
entail expert examination over the subgraph explanations of each
node provided by previous subgraph-specific methods. Beyond the
node-wise representations of early GNNs, recent state-of-the-art
GNNs [ 8,31,42,60] have shifted the focus towards considering
global interactions for graph-level tasks, enhancing the expressive
power of GNNs by a large margin. Hence, there exists a significant
gap between local subgraph-specific explanations and global-level
explanations, which are required by both graph-level tasks and
advanced GNNs.
In this paper, we propose the Global Interactive Pattern (GIP)
learning, a new interpretable graph classification task that ap-
proaches the problem from a global perspective. This task poses
two key challenges for existing techniques, namely, high computa-
tional complexity and diverse global patterns. Firstly, the presence
of a large number of nodes, along with their intricate connectivity,
presents a significant challenge in modeling long-range dependen-
cies and accurately extracting global interactions. Simply extending
subgraph-specific methods to identify global interactive patterns
would result in exponentially increasing computational complexity.
This is particularly true in real-world graphs where these patterns
typically involve dozens or even hundreds of nodes. Secondly, there
exist multiple interactive patterns for graphs belonging to the same
class. Existing techniques either provide instance-level explanations
or entail high costs for extracting graph patterns. Hence, it becomes
crucial to identify representative and diverse patterns within an
acceptable computational overhead for more comprehensive and
accurate explanations.
To tackle these challenges, we explore an innovative framework
for sloving GIP, by first performing compression of the graph and
then identifying inter-cluster interactions in the coarsened graphinstances, which we call interactive patterns, to determine the in-
trinsic explanations. Specifically, the framework consists of two
key modules: clustering assignment module and interactive pattern
matching module. First, in the clustering assignment module, we
iteratively aggregate components with similar features or tight
connections to form a cluster-level representation, and then extract
global structure information based on the interactions between lo-
cal structures, thus realizing the modeling of the global interactions
while aggregating the information of local substructures. Then, in
the interactive pattern matching module, different from prior re-
searches [ 15,72] in graph pattern recognition that target at learning
representative embeddings in hidden space, we define learnable
interactive patterns in the form of graph structure to directly reveal
the vital patterns in the graph level. Additionally, we introduce
graph kernels as a measure of similarity between the coarsened
graph and the interactive patterns, thereby propelling the learning
and matching of interactive patterns based on the similarity. Finally,
with the similarity scores, a fully connected layer with softmax is
applied to compute the output probabilities for each class.
In summary, the main contributions of our work are as follows:
•We explore a novel interpretable graph classification task termed
as Global Interactive Pattern (GIP) learning, taking a step further
from local subgraph explanation to global interactive patterns.
•We propose a holistic framework for solving GIP, which achieves
a double-win of high computational efficiency and accurate pat-
tern discovery. By integrating learnable cluster constraints and
graph prototypes, we can adaptively provide the decisions with
reliable graph-level explanations.
•Extensive experiments on both real-world and synthetic datasets
demonstrate the effectiveness of our framework in achieving ac-
curate prediction and valid explanation. In addition, visualization
of the explanations further demonstrates the superior capability
of our framework in identifying global interactive patterns.
2 RELATED WORK
2.1 Graph Neural Networks
Driven by the momentous success of deep learning, recently, a
mass of efforts have been devoted to developing deep neural net-
works for graph-structured data [ 5]. As one of the pioneer works,
graph neural networks (GNNs) [ 23,26,29,67] have demonstrated
effectiveness in various real-world scenarios [ 25,27,58,74] such
as traffic analysis [ 6,71], drug generation [ 1] and recommendation
systems [ 65]. Generally, classic GNN variants adopt the message-
passing mechanism [ 22] to update the embeddings of each node
based on the calculated message set between the node and each
of its neighbors. Then, these node-wise representations are ma-
nipulated through concatenation or pooling operations to form
graph-level representations for graph-level tasks. Although this
unique message-passing mechanism enables GNNs to fully leverage
the relationships between nodes in graph structure, such GNNs
may suffer from over-smoothing due to repeated local aggregation
and over-squashing due to the exponential growth of computa-
tional cost with increasing model depth. Recent years have wit-
nessed many successful architectures that shift the focus towards
considering global interactions for graph-level tasks. These ap-
proaches [ 8,31,42,60] model long-range dependencies and global
3278Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
Input Graph
(1) Clustering Assignment Module
Cluster-level Interactions
(2) Interactive Patterns Matching Module (3) Similarity-based Prediction
Softmax
Linear
Interactive PatternsSimilarityPrediction
Instance-level ExplanationCompression Blocks
Random Walk Graph KernelSim1
Sim2
SimT
K(             ,            )
Logits1Log
2Log
CLog
Interactive Patterns with Highest
SimilarityK(             ,            )
K(             ,            )X
AX
AZ
MLP
SEncoder
Cluster-level Interactions
CE CA IPM-th Block
Figure 1: The architecture of our proposed two-stage framework for GIP.
structures to facilitate a more comprehensive acquisition of the
global information in graphs, thus enhancing the expressive power
of the model. Owing to the powerful representation capability, these
GNNs have achieved state-of-the-art performance.
2.2 Explainability of Graph Neural Networks
Despite the great success of GNNs, their black-box nature under-
mines human trust, thereby hindering their application in high-
stake domains. To bolster understanding of GNNs and provide more
credible evidence for decision-making, plenty of researches focus
on the explainability of GNNs is emerging. Such studies concen-
trate on identifying vital subgraphs, offering intrinsic or post-hoc
explanations for GNNs. The post-hoc explainable methods focus
on designing different combinatorial search method to explore im-
portant subgraphs based on model outputs [ 37,41,66,70]. As an
initial endeavour, GNNExplainer [ 66] learns soft masks from edge
and node features to identify pivotal subgraphs for explaining the
prediction result. Furthermore, PGExplainer [ 37] employs a repa-
rameterization trick to obtain approximated discrete masks instead
of soft masks. In addition, XGNN [ 69] generates representative
subgraphs for different classes as model-level explanations.
Since these methods focus on providing post-hoc explanations
for a trained GNN, they might fail to fit the original model precisely
and generate biased explanation. Though it would be preferable
to design interpretable GNNs [ 7,39], there are still limited efforts
in this regard [ 14,15,72]. The goal of these methods is to identifysubgraphs during training and make reliable predictions guided by
subgraphs [ 39,64,68]. GIB [ 39] and GSAT [ 68] adopt the informa-
tion bottleneck principle [ 59] to constraint the information flow
from the input graph to the prediction, ensuring the label-relevant
components will be kept while the label-irrelevant ones are reduced.
In addition, some existing works attempt to apply prototype learn-
ing for exploring important subgraphs from instances and make
predictions based on the similarity between new instances and
prototypes [ 15,72]. For example, ProtGNN [ 72] applies the Monte
Carlo tree search [ 49] to identify subgraphs in the original graphs
as prototypes, while PxGNN [ 15] obtains prototypes from learnable
prototype embeddings by a pre-trained prototype generator.
However, the aforementioned methods only provide one-side
attribution analysis from a localized viewpoint, which may lead to
under-representative explanations when higher-order node inter-
actions or global graph structure play a pivotal role. To address this
issue, in this paper, we propose an interpretable scheme for graph
classification called GIP, that explicitly extracts global interactive
patterns to deliver graph-level explanations.
3 METHOD
In this section, we elaborate the details of the proposed framework
for GIP. First, in the clustering assignment module, we extract
inter-cluster interactions from coarsened graph as global structural
information. Then, in the interactive pattern matching module, we
match the coarsened graph with a batch of learnable interactive
3279KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
patterns based on the similarity calculated by the graph kernel.
Finally, with the similarity scores, the fully connected layer with
softmax computes the probability distributions for each class. The
architecture of the proposed framework is shown in Figure 1.
3.1 Preliminaries
3.1.1 Notations. We denote an attributed graph with 𝑁nodes by
𝐺=(V,X,A), where V={𝑣1,...,𝑣𝑁}is the set of nodes in graph,
X∈R𝑁×𝑑is the matrix consisting of the 𝑑-dimensional feature
vector of each node, A∈{0,1}𝑁×𝑁is the adjacency matrix. A𝑖𝑗=1
if nodes𝑣𝑖and𝑣𝑗are connected; otherwise A𝑖𝑗=0.
In this paper, we take graph classification as the target task.
Given a set of 𝑀graphsG={𝐺1,𝐺2,...,𝐺𝑀}, and each graph 𝐺𝑚
is associated with a ground-truth class label 𝑦𝑚∈C, whereC=
{1,2,...,𝐶}is the set of candidate labels. The graph classification
task aims to learn a graph classifier that predicts the estimated label
ˆ𝑦𝑚for an input graph 𝐺𝑚.
3.1.2 Graph Normalized Cut. Graph normalized cut is an effective
approach for realizing graph clustering. The goal is to construct a
partition of the graph into 𝐾sets, such that the sets are sparsely
connected to each other while the internal structure of the sets
exhibits high cohesion [ 43]. We formalize the objective of the 𝐾-
way normalized cut as follows:
min
V1,...,V𝐾1
𝐾𝐾∑︁
𝑘=1cut(V𝑘,V𝑘)
vol(V𝑘), (1)
where V𝑘represents the nodes belonging to cluster 𝑘,vol(V𝑘)
=Í
𝑖,𝑗∈V𝑘A𝑖𝑗counts the number of edges within cluster 𝑘, and
cut(V𝑘,V𝑘)=Í
𝑖∈V𝑘,𝑗∈V\V𝑘A𝑖𝑗counts the edges between the nodes
in cluster𝑘and the rest of the graph [ 48]. Let P∈{0,1}𝑁×𝐾be the
cluster assignment matrix, where 𝐾denotes the number of target
clusters and P𝑖𝑗=1when node𝑖belongs to cluster 𝑗. The objective
function of the normalized cut can be further defined according to
the derivation in [13, 18]:
min
P∈{0,1}𝑁×𝐾1
𝐾𝐾∑︁
𝑘=1P𝑇
𝑘LP𝑘
P𝑇
𝑘DP𝑘(2)
= min
P∈{0,1}𝑁×𝐾1
𝐾·Tr(P𝑇LP
P𝑇DP), (3)
where P𝑘represents the 𝑘-th column in P,Dis the corresponding
degree matrix, and L=D−Ais the graph Laplacian matrix.
The optimization problem is NP-hard because the clustering
assignment matrix Ptakes discrete values [ 47]. Therefore, following
the traditional approach of solving the probabilistic approximation
of the𝐾-way normalized cut [ 13,18], we perform a continuous
relaxation for Psuch that it satisfies P𝑖𝑗∈[0,1]and∀𝑖,Í
𝑗P𝑖𝑗=1.
3.1.3 Random Walk Graph Kernel. Random walk graph kernel is a
kind of kernel function for graph similarity evaluation, whose core
idea is to compute the similarity of two input graphs by counting the
number of common paths in the two graphs. 𝑅-step random walk
means that the length of paths formed by the random walk does not
exceed𝑅. To efficiently compute the random walk kernel, we follow
the generalized framework of computing walk-based kernel [ 53],
and use the direct product graph for equivalence calculation.Given two graphs 𝐺=(V,X,A)with𝑁nodes and𝐺′=(V′,X′,A′)
with𝑁′nodes, the direct product graph 𝐺×=(V×,X×,A×)is a
graph with 𝑁𝑁′nodes, each representing a pair of nodes from 𝐺
and𝐺′. The adjacency matrix A×is equal to the Kronecker product
of the adjacency matrices of 𝐺and𝐺′, that is A×=A⊗A′[2].
The attribute of node (𝑣,𝑣′)in𝐺×is calculated based on the at-
tribute of node 𝑣in𝐺and node𝑣′in𝐺′, i.e. X×(𝑣,𝑣′)=X𝑣X′𝑇
𝑣′.
Performing a random walk on the direct product graph 𝐺×is equiv-
alent to performing the simultaneous random walks on graphs 𝐺
and𝐺′. Therefore, The 𝑅-step random walk kernel for attributed
graphs [19] can be calculated as:
𝐾(𝐺,𝐺′)=𝑅∑︁
𝑟=0𝐾𝑟(𝐺,𝐺′) (4)
𝐾𝑟(𝐺,𝐺′)=|V×|∑︁
𝑖,𝑗=1X×𝑖X×𝑗[A𝑟
×]𝑖𝑗 (5)
where X×𝑖denotes the feature of 𝑖-th nodes in 𝐺×and the(𝑖,𝑗)-th
element of A𝑟
×represents the number of common walks of length
𝑟between the 𝑖-th and𝑗-th node in𝐺×.
3.2 Clustering Assignment Module
In this module, the underlying idea of our approach stems from
related work on graph pooling [ 67], which progressively creates
coarser versions to represent cluster-level interactions by applying
a series of compression blocks to the input graph. In each com-
pression block, we first obtain the embedding vector Z∈R𝑁×𝑑′of
nodes by encoder, which can be any model, and we apply GCN [ 29]
as encoder for implementation.
eA=ˆD−1
2ˆAˆD−1
2, (6)
Z=𝑓({X,eA};ΘGCN), (7)
where ˆA=A+I𝑁is the adjacency matrix with added self-loop, ˆD
is the degree matrix of ˆA, andΘGCN are parameters of the encoder.
Then, we divide the original input graph into the cluster-level
representation based on the generated node embeddings in a train-
able manner. Specifically, we define a trainable cluster assignment
matrix Sto map each node to a corresponding cluster, and each
entry S𝑖𝑗represents the probability of node 𝑖belonging to clus-
ter𝑗. Considering that the similarity of node features can affect
clustering assignment to some extent, node feature embedding is
incorporated into the learning process of S. We take Zas input and
use a multi-layer perceptron (MLP) with softmax on the output
layer to compute S:
S=Softmax
MLP Z;ΘMLP 1
, (8)
where Ssatisfies S𝑖𝑗∈[0,1]and∀𝑖Í
𝑗S𝑖𝑗=1,ΘMLP 1denotes the
learnable parameters in the MLP.
Unlike the unconstrained learning process in [ 67], we aim to
impose constraints on Sin order to obtain clustering assignment
results that better reflect the clustering characteristics of nodes
in the real-world graphs. First, we optimize the learning of Sby
3280Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
minimizing an unsupervised loss term L𝑐𝑙𝑢, which defined on a
relaxation formula that approximates the 𝐾-way normalized cut (3):
L𝑐𝑙𝑢=1
𝐾·Tr(S𝑇LS
S𝑇DS), (9)
where Dis the corresponding degree matrix, and L=D−Ais the
graph Laplacian matrix. However, without additional constraints
on the assignment matrix S, cluster assignment may fall into a local
optimal solution: assigning all nodes to the same cluster. Hence, we
introduce an balanced loss term L𝑏𝑎𝑙to encourage more balanced
and discrete clusters:
L𝑏𝑎𝑙=√
𝐾
𝑁||𝑁∑︁
𝑖=1S𝑖||𝐹−1, (10)
where||·||𝐹indicates the Frobenius norm, 𝑁is the number of
nodes and𝐾is the number of target clusters.
In summary, the optimization objective of this module can be
expressed as:
L𝐶𝐴=𝛼1L𝑐𝑙𝑢+𝛼2L𝑏𝑎𝑙, (11)
where𝛼1and𝛼2control the ratio of the loss terms.
Assuming the input adjacency matrix in the ℓ-th compression
block is Aℓ−1, the input node embedding matrix is Zℓ−1, and the
computed clustering assignment matrix is Sℓ, we can generate a
new coarsened adjacency matrix Aℓand a new embedding matrix
Xℓfor next compression block. Specifically, we apply the following
two equations:
Xℓ=Sℓ𝑇Zℓ−1∈R𝑁ℓ×𝑑, (12)
Aℓ=Sℓ𝑇Aℓ−1Sℓ∈R𝑁ℓ×𝑁ℓ, (13)
where𝑁ℓdenotes the number of target clusters in ℓ-th block
and𝑑denotes dimension of node features. By stacking compres-
sion blocks, we can obtain A𝐿andX𝐿for cluster-level represen-
tation𝐶𝐺, where𝐿is the number of compression blocks. Consid-
ering the impact of the enormous edges in the coarsened graph,
we propose to filter the edges. Specifically, we define the matrix
Mask∈{0,1}𝑁𝐿×𝑁𝐿to filter the edges in the coarsened graph,
where𝑁𝐿is the number of nodes in the coarsened graph. If A𝐿
𝑖𝑗
exceeds threshold 𝛿1, the element at the corresponding position in
Mask is set to 1, otherwise it is set to 0:
Mask𝑖𝑗=(
1,ifA𝐿
𝑖𝑗>𝛿1;
0,else,(14)
Thus, we obtain the filtered adjacency matrix A𝐿′=A𝐿⊙Mask for
cluster-level representation, where ⊙is the element-wise product.
3.3 Interactive Patterns Matching Module
In this module, we aim to learn representative inter-cluster struc-
tures and interactions for each class, which we call interactive
patterns, to give accurate predictions and reliable explanations.
First, we define a total of 𝑇learnable interactive patterns, i.e.
P={𝑃1,𝑃2,...,𝑃𝑇}, and allocate them evenly to 𝐶classes. In order
to provide a more understandable explanation, we define each
interactive pattern 𝑃𝑡as a combination of the following two parts:
(i) randomly initialized feature matrix X𝑃𝑡with pre-defined size;(ii) the topology A𝑃𝑡generated from the feature matrix, and the
generation process of A𝑃𝑡is defined as follows:
A𝑃𝑖
𝑖𝑗=𝜎
MLP [X𝑃𝑡
𝑖;X𝑃𝑡
𝑗];ΘMLP 2
(15)
where𝜎(·)is the Sigmoid function, ΘMLP 2is trainable parameters
of MLP,[·;·]is concatenation operation, X𝑃𝑡
𝑖andX𝑃𝑡
𝑗are features
of nodes in interactive pattern. Therefore, the generated interactive
patterns can be directly used for explanation without the need for
additional graph projection or graph generation processes [ 15,72].
Then, for the coarsened graph 𝐶𝐺and interactive pattern 𝑃𝑡, we
propose to calculate their similarity through graph kernels [ 3,28].
The choice of graph kernels can be changed according to the actual
application scenario. Here, we choose the 𝑅-step random walk
graph kernel [ 21,53] which compares random walks up to length
𝑅in two graphs. Then, the similarity between the coarsened graph
𝐶𝐺and the interactive pattern 𝑃𝑡can be expressed as:
sim(𝐶𝐺,𝑃𝑡)=𝐾(𝐶𝐺,𝑃𝑡), (16)
where𝐾(𝐶𝐺,𝑃𝑡)is calculated by equations (4) and (5).
Considering the desired representativeness of the interactive
patterns for their corresponding classes, we suppose that the learn-
ing objective of interactive patterns is to encourage each coarsened
graph to approach the interactive patterns belonging to the same
class, while moving away from the interactive patterns belonging
to other classes. To achieve this, we introduce the multi-similarity
loss [55] to constrain learning of patterns:
L𝑚𝑢𝑙=1
𝑀𝑀∑︁
𝑚=11
𝛾1log 1+∑︁
𝑃𝑖∈Pos𝑚𝑒𝛾1(𝑑𝑚𝑖−𝜆)
+1
𝛾2log 1+∑︁
𝑃𝑖∈Neg𝑚𝑒−𝛾2(𝑑𝑚𝑖−𝜆)(17)
where Pos𝑚denotes the set of interactive patterns belonging to
the same class as the coarsened graph 𝐶𝐺𝑚,Neg𝑚denotes the set
of interactive patterns apart from these, 𝑑𝑚𝑖denotes the distance
between coarsened graph 𝐶𝐺𝑚and interactive pattern 𝑃𝑖,𝛾1and
𝛾2control the contributions of different items, and 𝜆represents the
margin which controls the distribution range of interactive patterns
belonging to the certain class. For the computation of 𝑑𝑚𝑖, we apply
the distance in kernel space [46]:
𝑑𝑚𝑖=√︂
1
2
𝐾 𝐶𝐺𝑚,𝐶𝐺𝑚+𝐾 𝑃𝑖,𝑃𝑖
−𝐾 𝐶𝐺𝑚,𝑃𝑖(18)
Additionally, we encourage diversity in interactive patterns by
adding the diversity loss, which penalizes interactive patterns that
are too close to each other:
L𝑑𝑖𝑣=𝐶∑︁
𝑐=1∑︁
𝑃𝑖,𝑃𝑗∈P𝑐max
0,𝑠𝑖𝑚 𝑃𝑖,𝑃𝑗−𝛿2
(19)
whereP𝑐denotes the interactive patterns belonging to class 𝑐and
𝛿2is the threshold for similarity measurement.
L𝐼𝑃𝑀=𝛼3L𝑚𝑢𝑙+𝛼4L𝑑𝑖𝑣 (20)
where𝛼3and𝛼4control the ratio of the loss terms.
3281KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
Table 1: Comparison of different methods in terms of classification accuracy (%) and F1 score (%). Baselines include widely used
GNNs, interpretable GNNs and post-hoc explainable GNNs. The datasets include real-world datasets and synthetic datasets.
Bold and underline denote the best and the second-best results, respectively.
Datasets
Metrics GCN DGCNN Diffpool RWNN GraphSAGE ProtGNN KerGNN 𝜋-GNN GIB GSAT CAL Ours
ENZYMESA
cc. 57.81±0.73 58.68±2.74 59.99±2.35 56.94±0.87 56.33±0.88 55.00±2.36
57.68±3.79 57.85±0.66 46.17±5.11 60.55±1.87 60.03±5.40 60.76±2.61
F1 49.00±0.54
52.77±2.46 58.89±2.64 49.91±8.19 42.64±1.46 45.17±1.46
49.90±1.47 48.74±0.74 30.84±1.16 53.34±0.56 57.17±7.41 58.45±3.41
A
cc. 75.92±3.63 77.53±1.33 80.03±1.02 77.42±2.16 79.61±4.60 78.34±0.61 74.66±1.39 78.63±1.12 76.49±2.54 73.60±1.07 77.25±3.62 79.52±0.50D&DF1 72.08±0.33 68.54±0.86 73.88±5.27 76.14±1.87 78.62±8.86 73.29±2.87 66.29±2.47 71.14±2.13 68.26±0.98 66.16±4.82 66.65±5.13 73.67±1.71
PRO
TEINSAcc. 79.05±1.17 76.85±2.74 79.73±0.64 74.43±1.20
79.04±1.03 78.22±0.61
78.15±2.21 73.34±0.64 74.90±5.10 77.67±1.59 75.20±3.59 79.84±0.81
F1 70.97±2.89
73.19±4.74 77.95±0.77 72.34±1.28 67.76±2.84 73.79±2.87
72.13±1.40 66.17±4.64 71.11±0.18 72.86±0.96 66.02±3.67 74.50±2.84
A
cc. 74.32±8.10 56.34±0.77 83.90±9.70 86.47±0.39 72.10±4.30 81.67±2.36 72.66±0.94 91.18±0.28 91.04±6.40 94.42±0.92 88.92±8.37 92.13±3.26MU
TAGF1 65.33±4.60 47.35±0.67 69.99±1.10 84.69±0.18 69.81±2.20 62.69±3.81 61.39±1.89 77.51±1.95 80.64±1.13 81.75±0.21 84.36±7.22 87.27±2.27
COLLABA
cc. 72.35±1.57 73.27±1.39 73.53±1.48 72.37±1.32 72.63±1.48 69.26±0.86
75.39±1.78 74.11±1.23 73.17±1.60 76.89±2.83 79.08±1.94 77.72±2.31
F1 63.66±4.91
69.51±0.84 69.29±0.44
67.42±2.04 62.84±2.31 68.92±1.14 70.21±2.09 65.98±3.27
60.54±2.52 64.15±3.26 61.52±6.80 67.34±1.73
A
cc. 81.21±1.08 79.33±2.42 79.17±3.53 80.50±1.65 79.77±1.12 78.11±1.05 79.29±0.77 80.53±1.49 79.87±0.78 81.17±0.86 81.94±1.07 82.51±1.18GraphCy
cleF1 72.95±1.03 74.23±3.24 69.77±4.86 78.52±2.76 71.16±2.56 70.82±2.25 71.82±0.61 75.98±4.87 73.43±2.17 74.12±0.38 75.83±3.24 77.91±5.73
GraphFiv
eAcc. 58.96±2.28 57.38±3.50 54.93±2.27 58.79±1.51 59.49±0.46 56.57±3.38
57.94±0.54 59.39±0.19 59.71±0.65 58.77±0.54
57.35±0.52 60.40±1.75
F1 53.83±0.91
53.31±4.85 52.36±1.32 53.65±1.01 51.02±0.48 54.25±3.51
49.74±0.04 52.29±0.78 58.72±0.63 54.54±2.39 51.63±1.41 55.89±2.52
3.4 Interpretable Classification with interactive
patterns
3.4.1 Classification and Learning Objective. Finally, the𝑇similarity
scores between the coarsened graph and each interactive pattern
are fed into the fully connected layer to obtain the output logits.
Then, the logits processed with softmax to yield the probability
distribution ℎ𝑖for a given graph 𝐺𝑖. To ensure the accuracy of the
proposed framework, we apply a cross-entropy loss to leverage the
supervision from the labeled set:
L𝐶𝐸=1
𝑀𝑀∑︁
𝑖=1CrsEnt(ℎ𝑖,𝑦𝑖) (21)
where𝑦𝑖is the true label of input graph. To sum up, the objective
function we aim to minimize is:
L=L𝐶𝐸+𝛽1L𝐶𝐴+𝛽2L𝐼𝑃𝑀 (22)
whereL𝐶𝐴andL𝐼𝑃𝑀 are loss terms of the clustering assignment
module and interactive patterns matching module, 𝛽1and𝛽2control
the contribution of these loss terms.
3.4.2 Explainability. From the class perspective, the learned inter-
active patternsPreveal the cluster-level interaction characteristics
of the graphs in each class. From the instance perspective, for the
test graph𝐺𝑡, we can identify the most similar interactive pattern
in class ˆ𝑦𝑡with𝐺𝑡as the instance-level explanation:
ˆ𝐺∗
𝑡=arg max
𝑃𝑖∈Pˆ𝑦𝑡sim(𝐺𝑡,𝑃𝑖) (23)
wherePˆ𝑦𝑡is the set of interactive patterns belonging to class ˆ𝑦𝑡.
Since the prediction of 𝐺𝑡is based on several patterns, the instance-
level explanation can be several similar patterns in class ˆ𝑦𝑡, thereby
bringing deeper insights into the graph itself.
4 EXPERIMENTS
4.1 Experimental Settings
4.1.1 Datasets. In the experiment, we use five real-world datasets
with different characteristics (e.g., size, density, etc.) for graph clas-
sification. Additionally, to better demonstrate the explainability
provided by our framework, we design two synthetic datasets. The
specific information of the datasets is as follows:•Real-world Datasets: To probe the effectiveness of our framework
in diffrent domains, we use protein datasets including ENZYMES,
PROTEINS [ 20], D&D [ 17], molecular dataset MUTAG [ 61] and
scientific collaboration dataset COLLAB [ 62]. The statistics of
the datasets are presented in Appendix A.1.
•Synthetic Datasets: To better demonstrate the interpretability of
our framework, we design two synthetic datasets: GraphCycle
and GraphFive. Their labels are based on the interactive patterns
between local structures. GraphCycle consists of two classes:
Cycle and Non-Cycle, while GraphFive consists of five classes:
Wheel, Grid, Tree, Ladder, and Star. The specific implementation
details are presented in Appendix A.1.
4.1.2 Baselines. We extensively compare our framework with the
following three types of baselines:
•Widely Used GNNs: We compare the prediction performance
with the powerful GNN models including GCN [ 29], DGCNN [ 57],
Diffpool [67], RWNN [40] and GraphSAGE [23].
•Post-hoc Explainable GNNs: We compare the explanation perfor-
mance with the post-hoc explainable methods including GNNEx-
plainer [66], SubgraphX [70] and XGNN [69].
•Interpretable GNNs: We compare the prediction and explanation
performance with interpretable models including ProtGNN [ 72],
KerGNN [19], 𝜋-GNN [64], GIB [68], GSAT [38] and CAL [51].
More experimental settings will be presented in Appendix A.2
4.2 Quantitative Analysis
To validate the effectiveness of our framework, we first compare it
with the baselines in terms of prediction and explanation perfor-
mance on several graph classification datasets.
4.2.1 Prediction Performance. To demonstrate the effectiveness of
our approach in providing accurate predictions, we choose classifi-
cation accuracy and F1 scores as evaluation metrics, and compare
them with widely used GNNs and interpretable GNNs on both real-
world and synthetic datasets. We apply three independent runs and
report the average results along with the standard deviations in
Table 1. From the Table 1, we can observe that:
•Our framework achieves superior prediction performance
compared to most of widely used GNNs. Specifically, in terms
of classification accuracy, our framework outperforms widely
3282Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
(a) Our framework (b) ProtGNN
Interative Patterns of the CLass ‘’Non-Cycle‘’
Interative Patterns of the CLass ‘’Cycle‘’Prototypes of the CLass ‘’Non-Cycle‘’
Prototypes of the CLass ‘’Cycle‘’
Figure 2: Explanations generated by our framework and ProtGNN on the GraphCycle dataset.
used GNNs on six of the seven datasets. Particularly on MUTAG,
our framework outperforms widely used models by 5.66%~35.79%.
Furthermore, for the dataset in which our framework lagged
behind (D&D), our framework only falls behind by 0.5%compared
to the best-performing widely used model. For the F1 score metric,
our framework surpasses all widely used baselines in two of the
seven datasets. Additionally, it achieves second-best performance
in three datasets. In the remaining two datasets, it also performs
comparably to most of widely used baselines.
•Our framework significantly outperforms the leading in-
terpretable GNNs in prediction performance. On four of the
seven datasets, our framework exceeds previous interpretable
methods in terms of both accuracy and F1 score. On the remain-
ing three datasets, although its accuracy/F1 score is slightly lower
than the best-performing interpretable method, it still maintains
the best performance in another metric. This demonstrates that
our framework can consistently learn high-quality patterns for
accurate predictions on different datasets; while simply selecting
subgraphs might result in sub-optimal results.
4.2.2 Explanation Performance. We further compare the explana-
tion performance of our method with that of interpretable methods
and post-hoc explainable methods with three evaluation metrics,
including explanation accuracy, consistency and silhouette score.
We perform three independent runs and report the average results.
•Explanation Accuracy. We use trained GNNs to predict the ex-
planations produced by different methods and take the confidence
score of the prediction as the accuracy of the explanation [ 15,33].
We compare our framework with interpretable methods and post-
hoc explainable methods, the results are shown in Figure 2. Com-
pared to previous interpretable methods, our method exhibits the
highest explanation accuracy in five out of seven datasets, and
achieves the second-best performance in the remaining dataset.
Compared to post-hoc explainable methods, our method also
achieves the highest explanation accuracy on most datasets.
•Consistency. In the two synthetic datasets, we calculate the sim-
ilarity between the explanations produced by different methods
and the ground-truth. Here, we use the normalized results of ran-
dom walk graph kernel as the measure of similarity. The resultsTable 2: Comparison of different methods in terms of expla-
nation accuracy.
Metho
d ENZYMES D&D PROTEINS MUTAG COLLAB GraphCycle GraphFive
Pr
otGNN 86.52±2.2678.27±2.59 67.34±3.89 69.74±2.98 78.53±3.41 80.52±1.82 71.48±1.69
KerGNN 62.95±2.82 59.52±2.34 78.32±1.11 86.93±0.7384.62±0.98 87.45±0.36
73.54±0.87
𝜋-GNN 74.94±1.32 79.49±0.5663.82±2.19
79.62±4.52 75.53±0.65 82.86±1.66 63.06±0.60
GIB 73.60±2.17 74.73±2.22 83.80±1.68 82.41±2.83 79.52±3.24 84.94±1.22 78.29±0.87
GSAT 80.45±2.51 74.38±0.53 57.72±1.50 73.68±3.73 74.95±2.74 89.86±3.02 57.83±1.64
CAL 78.42±1.82
73.14±3.62 62.68±2.14 74.73±1.42 83.46±1.42 83.42±2.2480.12±0.52
GNNExplainer 78.26±0.19
77.52±2.1386.27±2.0679.46±2.68 73.89±3.57 86.77±3.70 69.95±3.08
SubgraphX 79.53±2.61 69.59±1.31 73.41±2.37 85.27±3.31 75.38±3.68 90.16±2.98 68.53±3.55
XGNN 85.47±2.92 73.43±2.81 72.39±2.43 79.38±5.52 82.89±0.69 83.75±0.51 74.16±1.06
Ours 86.41±2.1082.59±2.6085.83±2.1791.16±1.45
85.33±3.58 93.47±1.6479.08±1.99
are presented in Table 3. Our framework outperforms other base-
lines by a significant margin across all datasets. This indicates
that our framework can provide more accurate explanations.
•Silhouette Score. High-quality interactive patterns can tightly
cluster instances in dataset. Therefore, we use generated inter-
active patterns as centers to assign each graph to the nearest
interactive pattern and then calculate the silhouette scores [ 45]
to evaluate the compactness and separability of the clusters. We
compare our method with another prototype-based approach
ProtGNN, and the results are shown in Table 4. Our method
consistently achieves better performance on all datasets, which
further demonstrates that our framework can obtain more repre-
sentative patterns.
4.3 Qualitative Analysis
To qualitatively evaluate the performance, we visualize the obtained
interative patterns of our framework.
From class perspective, we present the explanations on the syn-
thetic dataset GraphCycle by visualizing part of the interactive
patterns of different classes. The results is shown in Figure 2(a). We
can find that our framework manages to learn patterns that are
consistent with the ground-truth of “Cycle” and “Non-Cycle”. For
comparison, we also show the identified explaintions of another
methods (ProtGNN) that can provide class-level explanations, the
results are shown in Figure 2(b). It can be observed that the ex-
planations identified by ProtGNN do not exhibit distinctiveness
across different classes. The reason may lie in the fact that the
3283KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
Table 3: Comparison of different methods in terms of consistency.
Datasets
ProtGNN KerGNN 𝜋-GNN GIB GSAT CAL GNNExplainer SubgraphX XGNN Ours
GraphCy
cle0.636±0.023 0.679±0.102 0.473±0.078
0.558±0.124 0.631±0.172 0.647±0.058 0.582±0.064 0.489±0.031 0.573±0.071 0.893±0.121
GraphFive 0.484±0.011 0.592±0.092 0.394±0.023 0.429±0.063 0.751±0.125 0.363±0.029
0.713±0.052 0.380±0.026 0.461±0.078 0.802±0.133
Table 4: Comparison of different methods in terms of silhou-
ette score.
Metho
ds ENZYMES D&D PROTEINS MUTAG COLLAB GraphCycle GraphFive
Pr
otGNN 0.301±0.014 0.178±0.021 0.614±0.047 0.216±0.023 0.348±0.045 0.237±0.021 0.133±0.030
Ours 0.580±0.042 0.284±0.033 0.791±0.104 0.298±0.033 0.739±0.092 0.480±0.083 0.341±0.025
GraphCycle dataset does not exhibit distinctive properties in local
structures, and the method based on subgraph exploration fail to
capture the interactions between local substructures, thus resulting
in weaker explanations. Therefore, we believe that our framework
is able to unveil representative global patterns. More results of the
explanation from class perspective will be presented in Appendix B.
From instance perspective, we identify one or more interaction
patterns similar to the input graph in the decision-making process
of the model to serve as instance-level explanations.
4.4 Efficiency Study
In this section, we compare the efficiency of our proposed frame-
work with several interpretable baselines. In Table 5, we show the
time required to finish training for each interpretable model. It can
be observed that the efficiency of our method is only slightly infe-
rior to KerGNN and 𝜋-GNN. According to the analysis above, our
method outperforms both KerGNN and 𝜋-GNN in terms of both
prediction performance and explanation performance. Therefore,
we believe that the slight additional time cost is worthwhile.
Table 5: Time consumption of different methods. “*” indi-
cates the method requires additional pre-training process
which takes nearly 72 hours.
Metho
dsENZYMES D&D COLLAB MUTAG GraphCycle GraphFive
Pr
otGNN 9590.86s 19864.35s 34794.25s 8920.72s 11781.47s 4706.38s
KerGNN 397.89s 1357.90s 1874.97s 400.94s 197.01s 418.67s
𝜋-GNN*386.06s 956.98s 1827.25s 458.23s 256.33s 445.37s
GIB 704.94s 2934.93s 4210.99s 2977.94s 1088.13s 1145.76s
GSAT 452.90s 1176.47s 2842.64s 817.94s 599.36s 795.29s
Ours 434.12s
1021.77s 2012.55s 469.98s 260.99s 455.47s
4.5 Ablation Studies
In this section, we perform ablation studies of our framework to
explore the impact of different experimental setups on the effective-
ness of the framework and explore the role of different modules.
Due to space limitations, we only present a portion of results here.
More results will be shown in Appendix C.
4.5.1 Influence of the Number of Compression Blocks. First, we
investigate the effect of the number of compression blocks 𝐿and
the compression ratio 𝑞, where𝑞represents the ratio of the numberof nodes after compression to the number of nodes before compres-
sion. We alter the values of 𝐿and𝑞as {1, 2} and {0.1, 0.2, 0.3, 0.5}.
We conduct experiments on GraphCycle dataset, and the results of
classification accuracy and explanation accuracy are presented in
Figure 3. We can find that when the compression ratio is too high
or too low, there is a degradation in both classification accuracy
and explanation accuracy. This may be due to the fact that when
the compression ratio is too low, the presence of noisy structures
may interfere with the extraction of global information, while a
high compression ratio may result in the loss of some information.
Additionally, we also find that the effect of the number of compres-
sion blocks on the results varies with different compression ratios.
Therefore, it is crucial to select appropriate number of compression
blocks and compression ratios for optimal model performance.
4.5.2 Influence of the Number of interactive patterns. Then, we
vary the number of interactive patterns per class 𝑇/𝐶as {2, 4, 6,
8, 10} to investigate its impact to our framework. We report the
results on four datasets in Figure 4. We find that with an increase in
the number of interactive patterns, both the classification accuracy
and explanation accuracy will initially increase and then decrease.
When the number of interactive patterns is too small, they cannot
represent all instances in the dataset, resulting in poor prediction
performance. When the number of the interactive patterns is too
large, we may obtain excessively similar interactive patterns. In
such cases, the prediction performance may be worse. The above
observations also pave a way for selecting optimal number of inter-
active patterns in our framework.
4.5.3 Influence of Different Modules. We adopt clustering assign-
ment module and interactive patterns matching module in our
framework. In order to explore the contribution of these two mod-
ules, we implement two variants: (i) without interactive patterns
matching module and (ii) without clustering assignment module.
0.1 0.2 0.3 0.5
Compression Ratio q657075808590Accuracy(%)(a) Classification Accuracy
L = 1
L = 2
0.1 0.2 0.3 0.5
Compression Ratio q707580859095Accuracy(%)(b) Explanation Accuracy
L = 1
L = 2
Figure 3: The influence of different number of compression
blocks and compression ratio on the model’s effectiveness.
3284Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
2 4 6 8 10
Number of Interactive Patterns Per Class65707580859095Accuracy(%)
(a) Classification Accuracy
MUTAG
D&D
PROTEINS
GraphCycle
2 4 6 8 10
Number of Interactive Patterns Per Class65707580859095Accuracy(%)
(b) Explanation Accuracy
MUTAG
D&D
PROTEINS
GraphCycle
Figure 4: The influence of different numbers of interactive
patterns on the model’s effectiveness.
D&D PROTEINS MUTAG GraphCycle
Datasets707580859095Accuracy(%)(a) Classification Accuracy
w/o IPM
w/o CA
Ours
D&D PROTEINS MUTAG GraphCycle
Datasets707580859095Accuracy(%)(b) Explanation Accuracy
w/o IPM
w/o CA
Ours
Figure 5: The influence of different modules on the model’s
effectiveness.
As shown in Figure 5, we can find that the performance is slightly
inferior when the two modules are used individually, while the com-
bination of these two modules achieve the best performance. Such
merits stem from the fact that the combination of these two modules
can help to identify the common characteristics in the graphs from
the perspective of the global structure interactions, thus effectively
enhancing the depth of information mining in graphs.
5 CONCLUSION
In this article, we explore a novel intrinsically explainable graph
classification task, called Global Interactive Pattern (GIP) learning.
In contrast to previous methods which focus on exploring local
subgraphs for explanation, we propose to analyze cluster-level in-
teraction patterns from a global perspective for attribution analysis.
To this end, we construct a two-stage framework for implementing
GIP, by first performing compression of the graph and then iden-
tifying interactive patterns of the coarsened graphs to determine
the intrinsic explanations. Extensive experiments on real-world
datasets and synthetic datasets demonstrate the effectiveness of
our framework in terms of prediction and explanation performance.
This also signifies the value of mining interactive patterns from
a global perspective to some extent. Therefore, our work paves a
novel path for interpretable graph classification. In the future, we
will further explore this task and endeavor to extend our method
to more practical scenarios.ACKNOWLEDGMENTS
This work was supported in part by the Joint Funds of the Zhe-
jiang Provincial Natural Science Foundation of China under Grant
LHZSD24F020001, in part by the Zhejiang Province “LingYan" Re-
search and Development Plan Project under Grant 2024C01114,
and in part by the Zhejiang Province High-Level Talents Special
Support Program “Leading Talent of Technological Innovation of
Ten-Thousands Talents Program" under Grant 2022R52046.
REFERENCES
[1]Pietro Bongini, Monica Bianchini, and Franco Scarselli. 2021. Molecular gen-
erative graph neural networks for drug discovery. Neurocomputing 450 (2021),
242–252.
[2]Karsten Borgwardt, Nicol Schraudolph, and SVN Vishwanathan. 2006. Fast com-
putation of graph kernels. In Annual Conference on Neural Information Processing
Systems.
[3]Karsten M Borgwardt and Hans-Peter Kriegel. 2005. Shortest-path kernels on
graphs. In IEEE International Conference on Data Mining.
[4]Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2015. Grarep: Learning graph repre-
sentations with global structural information. In ACM International Conference
on Information and Knowledge Management.
[5]Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2016. Deep neural networks for
learning graph representations. In AAAI Conference on Artificial Intelligence.
[6]Cen Chen, Kenli Li, Sin G Teo, Xiaofeng Zou, Kang Wang, Jie Wang, and Zeng
Zeng. 2019. Gated residual recurrent graph neural networks for traffic prediction.
InAAAI Conference on Artificial Intelligence.
[7]Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and Jonathan K
Su. 2019. This looks like that: deep learning for interpretable image recognition.
[8]Dexiong Chen, Leslie O’Bray, and Karsten Borgwardt. 2022. Structure-aware
transformer for graph representation learning. In International Conference on
Machine Learning.
[9]Kaixuan Chen, Shunyu Liu, Na Yu, Rong Yan, Quan Zhang, Jie Song, Zunlei Feng,
and Mingli Song. 2022. Distribution-aware graph representation learning for
transient stability assessment of power system. In International Joint Conference
on Neural Networks.
[10] Kaixuan Chen, Shunyu Liu, Tongtian Zhu, Ji Qiao, Yun Su, Yingjie Tian, Tongya
Zheng, Haofei Zhang, Zunlei Feng, Jingwen Ye, et al .2023. Improving Expressiv-
ity of GNNs with Subgraph-specific Factor Embedded Normalization. In ACM
Knowledge Discovery and Data Mining.
[11] Kaixuan Chen, Wei Luo, Shunyu Liu, Yaoquan Wei, Yihe Zhou, Yunpeng Qing,
Quan Zhang, Jie Song, and Mingli Song. 2024. Powerformer: A Section-adaptive
Transformer for Power Flow Adjustment. arXiv preprint arXiv:2401.02771 (2024).
[12] Kaixuan Chen, Jie Song, Shunyu Liu, Na Yu, Zunlei Feng, Gengshi Han, and
Mingli Song. 2022. Distribution knowledge embedding for graph pooling. IEEE
Transactions on Knowledge and Data Engineering (2022).
[13] Xiaojun Chen, Zhicong Xiao, Feiping Nie, and Joshua Zhexue Huang. 2022. FINC:
An Efficient and Effective Optimization Method for Normalized Cut. IEEE Trans
on Pattern Analysis and Machine Intelligence (2022).
[14] Enyan Dai and Suhang Wang. 2021. Towards self-explainable graph neural
network. In ACM International Conference on Information and Knowledge Man-
agement.
[15] Enyan Dai and Suhang Wang. 2022. Towards prototype-based self-explainable
graph neural network. arXiv preprint arXiv:2210.01974 (2022).
[16] Kaize Ding, Yancheng Wang, Yingzhen Yang, and Huan Liu. 2023. Eliciting
structural and semantic global knowledge in unsupervised graph contrastive
learning. In AAAI Conference on Artificial Intelligence.
[17] Paul D Dobson and Andrew J Doig. 2003. Distinguishing enzyme structures from
non-enzymes without alignments. Journal of molecular biology 330, 4 (2003),
771–783.
[18] Chi Thang Duong, Thanh Tam Nguyen, Trung-Dung Hoang, Hongzhi Yin,
Matthias Weidlich, and Quoc Viet Hung Nguyen. 2023. Deep MinCut: Learning
Node Embeddings by Detecting Communities. Pattern Recognition 134 (2023),
109126.
[19] Aosong Feng, Chenyu You, Shiqiang Wang, and Leandros Tassiulas. 2022.
Kergnns: Interpretable graph neural networks with graph kernels. In Proceedings
of the AAAI Conference on Artificial Intelligence.
[20] Aasa Feragen, Niklas Kasenburg, Jens Petersen, Marleen de Bruijne, and Karsten
Borgwardt. 2013. Scalable kernels for graphs with continuous attributes. In
Annual Conference on Neural Information Processing Systems.
[21] Thomas Gärtner, Peter Flach, and Stefan Wrobel. 2003. On graph kernels: Hard-
ness results and efficient alternatives. In Learning Theory and Kernel Machines:
16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT/Kernel
2003, Washington, DC, USA, August 24-27, 2003. Proceedings. 129–143.
3285KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
[22] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E
Dahl. 2017. Neural message passing for quantum chemistry. In International
Conference on Machine Learning.
[23] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation
Learning on Large Graphs. Annual Conference on Neural Information Processing
Systems.
[24] Zhongkai Hao, Chengqiang Lu, Zhenya Huang, Hao Wang, Zheyuan Hu, Qi Liu,
Enhong Chen, and Cheekong Lee. 2020. ASGN: An active semi-supervised graph
neural network for molecular property prediction. In ACM Knowledge Discovery
and Data Mining.
[25] Yongcheng Jing, Yining Mao, Yiding Yang, Yibing Zhan, Mingli Song, Xinchao
Wang, and Dacheng Tao. 2022. Learning graph neural networks for image style
transfer. In ECCV.
[26] Yongcheng Jing, Yiding Yang, Xinchao Wang, Mingli Song, and Dacheng Tao.
2021. Amalgamating knowledge from heterogeneous graph neural networks. In
CVPR.
[27] Yongcheng Jing, Chongbin Yuan, Li Ju, Yiding Yang, Xinchao Wang, and Dacheng
Tao. 2023. Deep Graph Reprogramming. In CVPR.
[28] Hisashi Kashima, Koji Tsuda, and Akihiro Inokuchi. 2003. Marginalized kernels
between labeled graphs. In International Conference on Machine Learning.
[29] Thomas N Kipf and Max Welling. 2016. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations.
[30] Janet L Kolodner. 1992. An introduction to case-based reasoning. Artificial
intelligence review 6, 1 (1992), 3–34.
[31] Kezhi Kong, Jiuhai Chen, John Kirchenbauer, Renkun Ni, C Bayan Bruss, and
Tom Goldstein. 2023. GOAT: A global transformer on large-scale graphs. In
International Conference on Machine Learning.
[32] Dongha Lee, Su Kim, Seonghyeon Lee, Chanyoung Park, and Hwanjo Yu. 2021.
Learnable structural semantic readout for graph classification. In IEEE Interna-
tional Conference on Data Mining.
[33] Yiqiao Li, Jianlong Zhou, Sunny Verma, and Fang Chen. 2022. A survey of
explainable graph neural networks: Taxonomy and evaluation metrics. arXiv
preprint arXiv:2207.12599 (2022).
[34] Shunyu Liu, Wei Luo, Yanzhen Zhou, Kaixuan Chen, Quan Zhang, Huating Xu,
Qinglai Guo, and Mingli Song. 2023. Transmission interface power flow adjust-
ment: A deep reinforcement learning approach based on multi-task attribution
map. IEEE Transactions on Power Systems (2023).
[35] Tong Liu, Yushan Liu, Marcel Hildebrandt, Mitchell Joblin, Hang Li, and Volker
Tresp. 2022. On Calibration of Graph Neural Networks for Node Classification.
InInternational Joint Conference on Neural Networks.
[36] Zhiwei Liu, Liangwei Yang, Ziwei Fan, Hao Peng, and Philip S Yu. 2022. Feder-
ated social recommendation with graph neural network. ACM Transactions on
Intelligent Systems and Technology 13, 4 (2022), 1–24.
[37] Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng
Chen, and Xiang Zhang. 2020. Parameterized explainer for graph neural network.
InAnnual Conference on Neural Information Processing Systems.
[38] Siqi Miao, Mia Liu, and Pan Li. 2022. Interpretable and generalizable graph learn-
ing via stochastic attention mechanism. In International Conference on Machine
Learning.
[39] Yao Ming, Panpan Xu, Huamin Qu, and Liu Ren. 2019. Interpretable and steerable
sequence learning via prototypes. In ACM Knowledge Discovery and Data Mining.
[40] Giannis Nikolentzos and Michalis Vazirgiannis. 2020. Random walk graph neural
networks. In Annual Conference on Neural Information Processing Systems.
[41] Phillip E Pope, Soheil Kolouri, Mohammad Rostami, Charles E Martin, and Heiko
Hoffmann. 2019. Explainability methods for graph convolutional neural networks.
InIEEE Conference on Computer Vision and Pattern Recognition.
[42] Ladislav Rampášek, Michael Galkin, Vijay Prakash Dwivedi, Anh Tuan Luu, Guy
Wolf, and Dominique Beaini. 2022. Recipe for a general, powerful, scalable graph
transformer. In Annual Conference on Neural Information Processing Systems.
[43] Syama Sundar Rangapuram, Pramod Kaushik Mudrakarta, and Matthias Hein.
2014. Tight continuous relaxation of the balanced k-cut problem. In Annual
Conference on Neural Information Processing Systems.
[44] Yu Rong, Yatao Bian, Tingyang Xu, Weiyang Xie, Ying Wei, Wenbing Huang,
and Junzhou Huang. 2020. Self-supervised graph transformer on large-scale
molecular data. In Annual Conference on Neural Information Processing Systems.
[45] Peter J Rousseeuw. 1987. Silhouettes: a graphical aid to the interpretation and
validation of cluster analysis. Journal of computational and applied mathematics
20 (1987), 53–65.
[46] Bernhard Schölkopf. 2000. The kernel trick for distances. In Annual Conference
on Neural Information Processing Systems.
[47] Shi. 2003. Multiclass spectral clustering. In International Conference on Computer
Vision.
[48] Jianbo Shi and Jitendra Malik. 2000. Normalized cuts and image segmentation.
IEEE Trans on Pattern Analysis and Machine Intelligence 22, 8 (2000), 888–905.
[49] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja
Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
et al.2017. Mastering the game of go without human knowledge. nature 550,7676 (2017), 354–359.
[50] Eric W Stawiski, Albion E Baucom, Scott C Lohr, and Lydia M Gregoret. 2000.
Predicting protein function from structure: unique structural features of proteases.
Proceedings of the National Academy of Sciences 97, 8 (2000), 3954–3958.
[51] Yongduo Sui, Xiang Wang, Jiancan Wu, Min Lin, Xiangnan He, and Tat-Seng Chua.
2022. Causal attention for interpretable and generalizable graph classification. In
ACM Knowledge Discovery and Data Mining.
[52] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro
Liò, and Yoshua Bengio. 2018. Graph Attention Networks. In International Con-
ference on Learning Representations.
[53] SVN Vishwanathan, Karsten M Borgwardt, Nicol N Schraudolph, et al .2006.
Fast computation of graph kernels. In Annual Conference on Neural Information
Processing Systems.
[54] Minh Vu and My T Thai. 2020. Pgm-explainer: Probabilistic graphical model ex-
planations for graph neural networks. In Annual Conference on Neural Information
Processing Systems.
[55] Xun Wang, Xintong Han, Weilin Huang, Dengke Dong, and Matthew R Scott.
2019. Multi-similarity loss with general pair weighting for deep metric learning.
InIEEE Conference on Computer Vision and Pattern Recognition.
[56] Yuwen Wang, Shunyu Liu, Kaixuan Chen, Tongtian Zhu, Ji Qiao, Mengjie Shi,
Yuanyu Wan, and Mingli Song. 2023. Adversarial erasing with pruned elements:
Towards better graph lottery ticket. In European Conference on Artificial Intelli-
gence.
[57] Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and
Justin M Solomon. 2019. Dynamic graph cnn for learning on point clouds. ACM
Transactions on Graphics (2019).
[58] Yu Wang, Tongya Zheng, Shunyu Liu, Zunlei Feng, Kaixuan Chen, Yunzhi Hao,
and Mingli Song. 2024. Spatiotemporal-Augmented Graph Neural Networks
for Human Mobility Simulation. IEEE Transactions on Knowledge and Data
Engineering (2024).
[59] Tailin Wu, Hongyu Ren, Pan Li, and Jure Leskovec. 2020. Graph information
bottleneck. In Annual Conference on Neural Information Processing Systems.
[60] Zhanghao Wu, Paras Jain, Matthew Wright, Azalia Mirhoseini, Joseph E Gonzalez,
and Ion Stoica. 2021. Representing long-range context for graph neural networks
with global attention. In Annual Conference on Neural Information Processing
Systems.
[61] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Ge-
niesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. 2018. MoleculeNet: a
benchmark for molecular machine learning. Chemical science 9, 2 (2018), 513–530.
[62] Pinar Yanardag and SVN Vishwanathan. 2015. Deep graph kernels. In ACM
Knowledge Discovery and Data Mining.
[63] Di Yao, Haonan Hu, Lun Du, Gao Cong, Shi Han, and Jingping Bi. 2022. Trajgat: A
graph-based long-term dependency modeling approach for trajectory similarity
computation. In ACM Knowledge Discovery and Data Mining.
[64] Jun Yin, Chaozhuo Li, Hao Yan, Jianxun Lian, and Senzhang Wang. 2023. Train
Once and Explain Everywhere: Pre-training Interpretable Graph Neural Net-
works. In Annual Conference on Neural Information Processing Systems.
[65] Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton,
and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale
recommender systems. In ACM Knowledge Discovery and Data Mining.
[66] Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec.
2019. Gnnexplainer: Generating explanations for graph neural networks. In
Annual Conference on Neural Information Processing Systems.
[67] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure
Leskovec. 2018. Hierarchical graph representation learning with differentiable
pooling. In Annual Conference on Neural Information Processing Systems.
[68] Junchi Yu, Tingyang Xu, Yu Rong, Yatao Bian, Junzhou Huang, and Ran He.
2020. Graph Information Bottleneck for Subgraph Recognition. In International
Conference on Learning Representations.
[69] Hao Yuan, Jiliang Tang, Xia Hu, and Shuiwang Ji. 2020. Xgnn: Towards model-
level explanations of graph neural networks. In ACM Knowledge Discovery and
Data Mining.
[70] Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, and Shuiwang Ji. 2021. On explain-
ability of graph neural networks via subgraph explorations. In International
Conference on Machine Learning.
[71] Xiyue Zhang, Chao Huang, Yong Xu, Lianghao Xia, Peng Dai, Liefeng Bo, Junbo
Zhang, and Yu Zheng. 2021. Traffic flow forecasting with spatial-temporal graph
diffusion network. In AAAI Conference on Artificial Intelligence.
[72] Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, and Cheekong Lee. 2022. Protgnn:
Towards self-explaining graph neural networks. In AAAI Conference on Artificial
Intelligence.
[73] Tianxiang Zhao, Xiang Zhang, and Suhang Wang. 2021. Graphsmote: Imbalanced
node classification on graphs with graph neural networks. In ACM International
Conference on Web Search And Data Mining.
[74] Tongya Zheng, Zunlei Feng, Tianli Zhang, Yunzhi Hao, Mingli Song, Xingen
Wang, Xinyu Wang, Ji Zhao, and Chun Chen. 2022. Transition propagation graph
neural networks for temporal networks. IEEE Transactions on Neural Networks
and Learning Systems (2022).
3286Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
A MORE IMPLEMENTATION DETAILS
A.1 Datasets
ENZYMES is a proteins dataset from the BRENDA database [ 20].
It comes with the task of classifying the enzymes to one out of six
EC top-level classes. Specific statistics of the dataset are shown in
Table A1.
PROTEINS is a dataset of proteins from Dobson and Doig dataset [ 20].
It comes with the task of classifying proteins into enzymes and non-
enzymes. Specific statistics of the dataset are shown in Table A1.
D&D [17] is a dataset containing high-resolution proteins extracted
from a non-redundant subset of the Protein Data Bank. Nodes are
amino acids, and two nodes are connected by an edge if the distance
between them is less than 6 angstroms. Specific statistics of the
dataset are shown in Table A1.
MUTAG [61] is a molecular property prediction dataset, where
nodes are atoms and edges are chemical bonds. Each graph is as-
sociated with a binary label based on its mutagenic effect. Specific
statistics of the dataset are shown in Table A1.
COLLAB [62] is a scientific collaboration dataset. A graph corre-
sponds to a researcher’s ego network, i.e., the researcher and its
collaborators are nodes and an edge indicates collaboration between
two researchers. A researcher’s ego network has three possible la-
bels, i.e., High Energy Physics, Condensed Matter Physics, and
Astro Physics, which are the fields that the researcher belongs to.
Specific statistics of the dataset are shown in Table A1.
GraphCycle is a self-designed synthetic dataset. Specifically, we
first generate 8~15 Barabási-Albert graphs as communities, each
containing 10~200 nodes. Then, we connect the generated BA
graphs in pre-defined two shapes: Cycle and Non-Cycle. To connect
nodes in different clusters, we randomly add edges with a probabil-
ity ranging from 0.05 to 0.15. Specific statistics of the dataset are
shown in Table A1.
GraphFive is a self-designed synthetic dataset. Specifically, we first
generate 8~15 Barabási-Albert graphs as communities, each con-
taining 10~200 nodes. Then, we connect the generated BA graphs
in pre-defined five shapes: Wheel, Grid, Tree, Ladder, and Star. To
connect nodes in different clusters, we randomly add edges with
a probability ranging from 0.05 to 0.15. Specific statistics of the
dataset are shown in Table A1.
Table A1: The statistics of real-world datasets.
#A
vg.Nodes #Avg.Edges #Classes #Graphs
ENZYMES 32.63
62.14 6 600
D&D 284.32 715.66 2 1178
PROTEINS 39.06 72.82 2 1113
MUTAG 17.93 19.79 2 188
COLLAB 74.49 2457.78 3 5000
GraphCycle 297.70 697.18 2 2000
GraphFive 375.98 1561.77 5 5000
A.2 Hyper-parameter Settings
The hyper-parameters used in our framework include batch size,
optimizer, learning rate, epoch, the 𝛼1and𝛼2for controlling loss
terms in clustering assignment module, the 𝛼3and𝛼4for controllingloss terms in interactive patterns matching module, the 𝛽1and𝛽2
for controlling the contribution of the two modules, etc. The specific
settings are presented in Table A2.
Table A2: The statistics of hyper-parameters setting.
ENZYMES
PROTEINS D&D MUTAG COLLAB GraphCycle GraphFive
Batch
Size 64 64 128 64 64 128 128
Optimizer Adam Adam Adam Adam Adam Adam Adam
Learning Rate 0.001 0.003 0.001 0.001 0.003 0.01 0.01
Epoch 500 500 500 500 500 500 500
𝛼1/𝛼2 0.3/0.2 0.2/0.4 0.4/0.3 0.2/0.4 0.3/0.2 0.1/0.4 0.1/0.1
𝛼3/𝛼4 0.2/0.2 0.4/0.1 0.4/0.2 0.3/0.1 0.1/0.2 0.3/0.1 0.1/0.1
𝛽1/𝛽2 0.5/0.4 0.5/0.3 0.3/0.4 0.4/0.5 0.4/0.4 0.5/0.3 0.3/0.4
B MORE CLASS-LEVEL EXPLANATIONS
In this section, We will provide more visualization results of class-
level explanations on different datasets. We visualize the global
interactive patterns identified in the PROTEINS, D&D, and Graph-
Five datasets as explanations from class perspective. The results
are shown in Figure A1, Figure A2, and Figure A3. It can be easily
observed that the interaction patterns exhibit commonalities within
the same class, while also displaying a certain degree of differen-
tiation between different classes. For example, in the PROTEINS
dataset, the interaction patterns in enzymes exhibit more numerous
and longer loops, as well as tighter connections, compared to the
interaction patterns in non-enzyme. This observation provides us
with new insights to distinguish graphs with different property
in the absence of expertise. In the future, we will cooperate with
domain experts to conduct more comprehensive analysis. Simi-
larly, in the GraphFive dataset, the identified interaction patterns in
different classes exhibit shapes similar to our pre-defined ground-
truth. Therefore, our framework is capable of mining representative
interaction patterns in graphs of different classes.
Enzymes
Non-
Enzymes
Figure A1: The identified interactive patterns of PROTEINS.
Enzymes
Non-
Enzymes
Figure A2: The identified interactive patterns of D&D.
3287KDD ’24, August 25–29, 2024, Barcelona, Spain Yuwen Wang, Shunyu Liu, Tongya Zheng, Kaixuan Chen, & Mingli Song
Wheel
Grid
Tree
Ladder
Star
Figure A3: The identified interactive patterns of GraphFive.
C MORE ABLATION STUDIES
C.1 Influence of the Compression Blocks
In this section, we continue the discussion in Section 4.5.1, and
analyze the influence of the number of compression blocks and
compression ratios on the model performance with D&D and Graph-
Five datasets. We present the results in Figure A4. It can be seen
that for different datasets, the appropriate number of compression
layers and compression ratios vary, further confirming the discus-
sion in Section 4.5.1. However, in most cases, fewer compression
layers and moderate compression ratios will yield better results.
C.2 Influence of the Number of Interactive
Patterns
In this section, we supplement the work in Section 4.5.2 and demon-
strate the variations in model performance with changes in the
number of interactive patterns per class on the ENZYMES, COL-
LAB, and GraphFive datasets. The results are shown in Figure A5.
We further note that changes in the number of interaction pat-
terns have different effects on prediction performance and explana-
tion performance, which requires us to further consider the balance
between prediction performance and explanation performance to
determine the appropriate number of interaction patterns.
C.3 Influence of Different Modules
In this section, we present more results about the influence of differ-
ent modules on the model performance. The results on ENZYMES,
COLLAB, and GraphFive datasets are shown in Figure A6. These
results show the same trend as in Section 4.5.3, i.e., the combinationof the two modules achieves better results, which can indicate that
our two-stage framework is effective.
0.1 0.2 0.3 0.5
Compression Ratio q65.067.570.072.575.077.580.082.585.0Accuracy(%)Classification Accuracy
L = 1
L = 2
0.1 0.2 0.3 0.5
Compression Ratio q657075808590Accuracy(%)Explanation Accuracy
L = 1
L = 2
0.1 0.2 0.3 0.5
Compression Ratio q40455055606570Accuracy(%)Classification Accuracy
L = 1
L = 2
0.1 0.2 0.3 0.5
Compression Ratio q55606570758085Accuracy(%)Explanation Accuracy
L = 1
L = 2
Figure A4: The influence of different numbers of compres-
sion blocks and compression ratios on the effectiveness of
the model.
2 4 6 8 10
Number of Interactive Patterns Per Class455055606570758085Accuracy(%)
(a) Classification Accuracy
ENZYMES
COLLAB
GraphFive
2 4 6 8 10
Number of Interactive Patterns Per Class65707580859095Accuracy(%)
(b) Explanation Accuracy
ENZYMES
COLLAB
GraphFive
Figure A5: The influence of different numbers of interactive
patterns on the model’s effectiveness. The experiments are
conducted on ENZYMES, COLLAB and GraphFive.
ENZYMES COLLAB GraphFive
Datasets4550556065707580Accuracy(%)(a) Classification Accuracy
w/o IPM
w/o CA
Ours
ENZYMES COLLAB GraphFive
Datasets707580859095Accuracy(%)(b) Explanation Accuracy
w/o IPM
w/o CA
Ours
Figure A6: The influence of different modules on the model’s
effectiveness.
3288