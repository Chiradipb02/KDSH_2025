Explicit
and Implicit Modeling via Dual-Path Transformer for
Behavior Set-informed Sequential Recommendation
Ming Chen
College of Computer Science and
Software Engineering, Shenzhen
University
Shenzhen, China
2252271001@email.szu.edu.cnWeike Pan∗
College of Computer Science and
Software Engineering, Shenzhen
University
Shenzhen, China
panweike@szu.edu.cnZhong Ming∗
Shenzhen University
Shenzhen, China
Shenzhen Technology University
Shenzhen, China
mingz@szu.edu.cn
ABSTRACT
Sequentialrecommendation(SR)andmulti-behaviorsequentialrec-
ommendation (MBSR) both come from real-world scenarios. Com-
pared with SR, MBSR takes into account the dependencies of dif-
ferent behaviors. We find that most existing works on MBSR are
studiedinthecontextofe-commercescenarios.Intermsofthedata
format of the behavior types, we observe that the conventional
label-formatted data carries limited information and is inadequate
for scenarios like social media. With this observation, we intro-
duce behavior set and extend MBSR to behavior set-informed se-
quentialrecommendation(BSSR).InBSSR,behaviordependencies
become more complex and personalized, and user interest arousal
maylackexplicitcontextualassociations.Todelveintothedynam-
ics inhered within a behavior set and adaptively tailor recommen-
dation lists upon its variability, we propose a novel solution called
Explicit and Implicit modeling via Dual-Path Transformer (EIDP)
for BSSR. Our EIDP adopts a dual-path architecture, distinguish-
ing between explicit modeling path (EMP) and implicit modeling
path (IMP) based on whether to directly incorporate the behavior
representations. EMP features the personalized behavior set-wise
transition pattern extractor (PBS-TPE) as its core component. It
couples behavioral representations with both the items and posi-
tionstoexploreintra-behaviordynamicswithinabehaviorsetata
finegranularity.IMPutilizeslightmulti-headself-attentionblocks
(L-MSAB) as encoders under specific behavior types. The obtained
multi-view representations are then aggregated by cross-behavior
attention fusion (CBAF), using the behavior set of the next time
step as a guidance to extract collaborative semantics at the be-
havioral level. Extensive experiments on two real-world datasets
demonstrate the effectiveness of our EIDP. We release the imple-
mentation code at: https://github.com/OshiNoCSMA/EIDP.
CCS CONCEPTS
•Information systems →Recommender systems.
∗co-corr
esponding authors
Permission
to make digital or hard copies of all or part of this work for personal or
classroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed
for profit or commercial advantage and that copies bear this notice and the full cita-
tion on the first page. Copyrights for components of this work owned by others than
the author(s) must be honored. Abstracting with credit is permitted. To copy other-
wise, or republish, to post on servers or to redistribute to lists, requires prior specific
permission and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
© 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671755KEYWORDS
Behavior Set; Sequential Recommendation
ACM Reference Format:
Ming Chen, Weike Pan, and Zhong Ming. 2024. Explicit and Implicit Mod-
elingviaDual-PathTransformerforBehaviorSet-informedSequentialRec-
ommendation.In Proceedings of the 30th ACM SIGKDD Conference on Knowl-
edge Discovery and Data Mining (KDD ’24), August 25–29, 2024, Barcelona,
Spain.ACM,NewYork,NY,USA,12pages.https://doi.org/10.1145/3637528.
3671755
1 INTRODUCTION
Online recommender systems have wide applications [1] in sce-
narios such as e-commerce [48], social media [31] and news [35].
The evolution of recommendation problems is gradually aligning
with the settings in real-world scenarios: users’ interactions with
items naturally unfold in a chronological manner, leading to the
SR problem. Traditional SR algorithms model only a single-type
behavioral sequence (e.g., a purchase sequence). They are often
unable to adapt to real-world scenarios where users may engage
in various types of interactions, which further leads to the emer-
gence of MBSR. MBSR aims to leverage auxiliary behavioral data
(e.g., click) to alleviate the sparsity in target behavioral data (e.g.,
purchase), thereby enhancing performance on the target behavior.
Some pioneering studies [ 7, 26, 29, 34, 41, 42], stemming from
different modeling perspectives and backbone network architec-
tures, have achieved performance surpassing the state-of-the-art
models in SR, confirming the validity of the MBSR problem set-
ting. However, we find that these works focus on MBSR in the
e-commerce scenario. Apparently, there exist some differences in
interaction patterns for MBSR across different business scenarios.
For example, the interaction data in a social media scenario may
exhibit short-duration and high-frequency characteristics. Tradi-
tionallabel-formattedbehaviorrepresentationsinMBSRmightnot
be adequately competent due to their limited capacity.
Someoperationsthatchangetheorderoftheitemsinasequence,
like reordering, are widely applied in data augmentation for con-
trastive learning [25, 33, 38]. This indicates the temporal order in
the original sequence does not necessarily need to be strictly pre-
served.Additionally,somestudies[9]haveindicatedthatuniformly
orderedsequencesleadtoasignificantenhancementinmodelper-
formance compared to non-uniform sequences. Inspired by these
findings,werealizethatitispossibletofurtherextendtheconven-
tional label-formatted behavior types to a multi-hot vector format.
We name it as behavior set . This aims at enriching the information
encapsulated within an interaction term from a setperspective.
 
329
KDD
’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
(,)
( )
(,), ,
 (,), ,
 ( )
 (,)
(,)E-commerce 
Scenario 
(MBSR) 
Social Media 
Scenario 
(BSSR) ܊௨௅ିହ={1,1,0,0} ܊௨௅ିସ={1,0,0,0} ܊௨௅ିଷ={1,1,1,1} ܊௨௅ିଶ={1,0,0,0} ܊௨௅ିଵ={1,1,1,1} ܊௨௅={1,0,1,0} ܊௨୲ୟ୰୥ୣ୲ ={1,1,0,0}
Click 
Cart 
Favorite 
Purchase 
Click 
Like 
Share 
Follow א࢛ ट
Ch1. Complexity in Personalized Behavioral Dependen cies 
((,,,,,,,,,,,,,,,,,,))
 ,,,=
 ={1
,
Ch2. Uncertainty in User Interests ArousalSeeking satisfaction for 
the next interest … Interest is aroused 
and satisfied… 
Ch3. Dynamics Inhered within Behavior Sets User Interest-evolving Curve (Hypothetical) (/),
,
Ch4. Variability in Target Behavior Sets A complete user interest-evolving path 
Timeline 
ܾ௨௅ି଺=1 ܾ௨௅ିହ=2 ܾ௨௅ିସ=1 ܾ௨௅ିଷ=2 ܾ௨௅ିଶ=3 ܾ௨௅ିଵ=3 ܾ௨௅=4 ܾ௨୲ୟ୰୥ୣ୲ =4
////////////////////////////////////////////////////////////////////////////
(
//,ڮ
Figur
e 1: Illustration of traditional e-commerce recommendation (top) and social media recommendation (bottom).
Specifically, we represent the set of all behavior types occurring
within a short time span using a multi-hot vector. By aggregating
local interests in this way, we achieve a more even distribution of
behavioral interaction data, assisting the model in better learning
representations. The configuration of interaction sequences with
behavior sets is adaptable to both social media and e-commerce
scenarios. We generalize MBSR and define a new problem called
behavior set-informed sequential recommendation (BSSR).
In this paper, we propose a novel solution, i.e., Explicit and Im-
plicit modeling via Dual-Path Transformer (EIDP), addressing the
BSSR problem. The main contributions of this work are summa-
rized as follows.
•We define and study a new and important problem i.e., BSSR,
which can be reduced to MBSR and SR.
•Wedesignanewencodingschemeforpersonalizedbehaviorset
representation.
•Weproposeanovelsolutionwithadual-pathstructure,i.e.,EIDP,
in which two paths inject the behavior set information from ex-
plicit and implicit perspectivesto capturethe heterogeneous de-
pendencies at both intra-behavior and inter-behavior levels.
•We conduct extensive experiments on two real-world datasets,
wheretheresultsdemonstratetheeffectivenessofourEIDPover
ten state-of-the-art SR and MBSR methods. The ablation studies
show the synergistic effect of the dual-path structure.
2 BEHAVIOR SET-INFORMED SEQUENTIAL
RECOMMENDATION
In this section, we first formally present the problem definition
of BSSR. Subsequently, we enumerate some unique challenges. Fi-
nally, we provide an overview of our proposed solution.2.1 Problem Definition
We useU={𝑢},V={𝑣}andBto denote a set of users, a set of
itemsandasetofuserbehaviors,respectively. |U|,|V|and|B|are
the numbers of users, items and behavior types, respectively. The
interaction sequence with behavior sets of a specific user 𝑢∈U
can be represented as: S𝑢={(𝑣1𝑢,b1𝑢), ...,(𝑣ℓ𝑢,bℓ𝑢), ...,(𝑣𝐿𝑢,b𝐿𝑢)}. We
represent the general form of a behavior set as a multi-hot vector,
bℓ𝑢=(𝑏ℓ
𝑢,1, ..., 𝑏ℓ
𝑢,𝑘, ..., 𝑏ℓ
𝑢,|B|)∈R|B|, where 𝑏ℓ
𝑢,𝑘=1if user 𝑢has
interactedwithitem 𝑣ℓ𝑢withthe 𝑘-thbehavioratthe ℓ-thtimestep,
and𝑏ℓ
𝑢,𝑘=0otherwise. 𝐿indicatesthelengthoftheusersequence.
The goal is to predict the next item 𝑣∈V\S𝑢that is likely to
be interacted with under a target behavior set by user 𝑢at the 𝐿+1
time step. We define the target behavior set as a vector containing
the target behaviors according to the semantic meanings.
2.2 Challenges
BSSR inherently encompasses some unique challenges related to
behavior sets and behavior sequences when compared to MBSR.
•Ch.1 Complexity in Personalized Behavioral Dependen-
cies.Users often exhibit different behavior patterns due to per-
sonalized characteristics as shown in Figure 1. Different from
e-commerce scenarios, in a social media scenario, temporal de-
pendencies can shift to individual interactions completed in a
short period. This also implies that each interaction term serves
as a relatively independent interest event, rendering the encap-
sulated information more high-ordered and complex. Moreover,
thetransitiondependencieswithinorbetweenbehaviorsetsare
also personalized.
•Ch.2 Uncertainty in User Interests Arousal. The user pref-
erence intensity reflected in different combinations of behav-
iors within the behavior set varies with both users and behav-
ior types. Hence, we can roughly visualize a hypothetical user
 
330Explicitand Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation KDD ’24, August 25–29, 2024, Barcelona, Spain
interest-evolving curve, as shown in the lower part of Figure 1.
Unlikethetraceablecontextualinformationonbehaviorseman-
tics in MBSR (e.g., an add-to-cart behavior often increases the
probability of a subsequent purchase behavior), we can see that
the intra-behavior context on behavior sets between the peaks
andvalleysof the curveis highly uncertain.
•Ch.3 Dynamics Inhered within Behavior Sets. The dynam-
ics of behavior transitions in MBSR involve a one-to-one rela-
tionshipamonglabels,whileinBSSR,theintra-behaviordynam-
ics become one-to-many or even many-to-many relationship.
•Ch.4 Variability in Target Behavior Sets. DifferingfromMBSR
that focuses on purchase-oriented prediction, the target behav-
ior setsin BSSR encompass non-single predicting targets. This
requires the model to be sensitive to variations in user prefer-
ence intensity with different target behavior sets and to adap-
tively provide tailored recommendation lists.
2.3 Overview of Our Solution
In this paper, to tackle the aforementioned challenges, we differ-
entiate our modeling perspectives based on whether to directly in-
corporate behavioral representations. As shown in Figure 2, our
EIDP features a dual-path architecture, with each path designed
for different modeling objectives.
•Explicit Modeling Path (EMP): EMP extracts intra-behavior
transition relationships via explicit injection of behavioral in-
formation, mainly in two steps: a) Explicitly encoded Embedding
Layer(EEL) injects the behavior set embeddings into the item
and position sides. b) Personalized Behavior Set-wise Transition
Pattern Extractor (PBS-TPE) tightly couples the behavior infor-
mation from both the item and position aspects.
•Implicit Modeling Path (IMP): Correspondingly,IMPextracts
theinter-behaviorcollaborationacrossmultiplebehavior-specific
views, which mainly consists of three components: a) User Be-
havioral Preference Factor Enhanced Embedding Layer (UB-FEEL)
scalesthesequentialrepresentationsbasedontheenhancement
mask. b) Light Multi-head Self-Attention Block (L-MSAB) serves
as an encoder under various behavior-specific views to obtain
behavior-specificrepresentations.c) Cross Behavior Attention Fu-
sion(CBAF) facilitates the fusion process via cross-attention.
•Dual-Path Next-Item Prediction: OurEIDPcombinestherep-
resentations from the two paths for next-item prediction.
3 PROPOSED METHODOLOGY
In this section, we delve into the technical details of our EIDP. We
list some notations and their explanations in Appendix A.1.
3.1 Entity Encoding
Forallentities,weinitializeanitemembeddingmatrix 𝑰∈R|V|×𝑑
and a position embedding matrix 𝑷∈R𝐿×𝑑to inject chronologi-
cal information, where 𝑑is the dimension of the representations.
Through the look-up operations, we can obtain the item represen-
tation e𝑣ℓ𝑢and the position embedding pℓfor a given item 𝑣ℓ𝑢.
Personalized Behavior Set Encoding. Firstly, considering the
inherent semantics of different behaviors, we initialize a global be-
havior embedding matrix 𝑮∈R|B|×𝑑. Secondly, since the prefer-
ence intensity expressed in a specific behavior may vary amongdifferent users, we introduce a user behavioral preference factor
matrix F∈R|U|×|B|. For a given specific behavior set bℓ𝑢, we can
obtain the personalized behavior set embedding:
𝜷ℓ
𝑢=softmax(f𝑢⊙bℓ
𝑢)·𝑮 (1)
where⊙istheelement-wiseproduct, f𝑢∈R|B|denotesthebehav-
ioralpreferencefactorofuser 𝑢,and𝜷ℓ
𝑢∈R𝑑canbeviewedasthe
embedding of the behavior set corresponding to bℓ𝑢. Note that, we
will use the uppercase symbols 𝑬,𝑩and𝔅to represent the matrix
forms of e𝑣,𝜷andb, respectively. Through this personalized en-
coding of behavior sets, we lay the foundation for addressing the
personalized issue mentioned in Ch.1.
3.2 Explicit Modeling Path
In our EMP, we explicitly capture personalized intra-behavior dy-
namicsby directly incorporating behaviorset embeddings and uti-
lizing fine-grained information within behavior sets.
3.2.1 Explicitly encoded Embedding Layer. In EEL, we explicitly
introduce behavior set embeddings to inject behavioral informa-
tion into interaction terms. For an interaction term (𝑣ℓ𝑢,bℓ𝑢)at the
ℓ-th time step of the user sequence S𝑢, we obtain its latent repre-
sentations from two aspects:
x(𝑖𝑏)
𝑣ℓ𝑢=e𝑣ℓ𝑢⊕𝜷ℓ
𝑢,x(𝑝𝑏)
𝑣ℓ𝑢=pℓ⊕𝜷ℓ
𝑢 (2)
where⊕denoteselement-wiseaddition.Weuse 𝑿★𝑢∈R𝐿×𝑑torep-
resenttheembeddingmatricesobtainedfromtwosides,wherethe
superscript ★∈{(𝑖𝑏),(𝑝𝑏)}is used to distinguish representations
from different aspects, and the subscript 𝑢will be omitted when it
is not necessary.
3.2.2 Personalized Behavior Set-wise Transition Pattern Extractor.
Behavioral information not only varies in its impact on different
items under the influence of users, but also exhibits a clear tempo-
ralorderintriggeringofdifferentbehaviors.Inspiredbythedecou-
pling idea from [39], we propose a personalized behavior set-wise
transitionpatternextractor(PBS-TPE)withdual-coupledbehavior
set-aware attention (DCBA) mechanism.
Dual-Coupled Behavior set-aware Attention (DCBA). The in-
tention of DCBA is designed to thoroughly couple personalized
behavior representations from both the item and position aspects.
Specifically,DCBAconsistsoftwomechanisms:self-attention(SA)
and Hamming distance attention (HDA):
e𝑿★
𝑢=DCBA(𝑿★
𝑢,𝔅𝑢)= SA(𝑿★
𝑢)+HDA(𝔅𝑢)𝑽★
𝑢(3)
SA(𝑿★
𝑢)=softmax(𝑸★𝑢𝑲★𝑢⊤
√
𝑑)
⊙𝚫 (4)
HDA(𝔅𝑢)=softmax(𝑯𝑢√
𝑑)
⊙𝚫 (5)
𝑯𝑢=©­­­
«𝑔𝑢 HD(b1𝑢,b1𝑢)··· 𝑔𝑢 HD(b1𝑢,b𝐿𝑢)
.........
𝑔𝑢 HD(b𝐿𝑢,b1𝑢)··· 𝑔𝑢 HD(b𝐿𝑢,b𝐿𝑢)ª®®®
¬(6)
 
331KDD’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
EEL EEL 
UB-FEEL … …
ࡹۨ௞௘DCBA 
DCBA FFNPBS-TPE 
ࢄ୉୑୔ 
PSA FFNPSA FFNL-MSAB 
PSA FFNPSA FFNL-MSAB 
…
…
…PSA FFN
PSA FFN
Stack ( ࡯ )blocks CBA ࢄ୍୑୔ 
CBAF 
ࢽκାଵCandidate Items ො ݕ௅ାଵ,௩Dual-Path 
Next-Item 
Prediction 
FFN܍௩Prediction ࢞௅
ࡹۨଵ௘
ࡹۨ|ࣜ|௘1 0 0 0
1 1 1 1
1 0 1 0
Implicit Modeling Path (IMP) Explicit Modeling Path (EMP) 
item seq. behavior set seq. position 
࡮ࡼࡱ &জࡱ
࡮
࡮
ࡼজ
ࡱ
ࡼজ
PSA ଵ(ڄ)
Split heads (1) 
(݄)
(ܪ)ࢃொ(௛)
ࢃ௄(௛)
ࢃ௏(௛)ࡽ(௛)
௛௛)
ࡽࡽ(
ࡷ(௛)
ࢂ(௛)Sample 
(randomly) 
Samp Samp 
ࢃ
ഥܯ(ܙ௜,ࡷ)Sort 
Top-ݑ
Top 
ഥࡽ(௛)
softmax(·) 
·ࡹࢤ
………
concat 
ࢃ௅
Output 
ProbSparsemulti-head Attention (PSA) …
mean( ࢂ(௛))
 mean 
ഥࢄ(௛)PSA ௛(ڄ)
PSA ு(ڄ)
at 
PSA ௛
PSA 
{ഥࢄ௛,mean( ࢂ(௛))}ࢄ(௜௣ )…
…
ads 
ࢄڅ
জ
ࢃொڅ
ࢃ௄څ
ࢃ௏څࡽڅ
ࡷڅ
ࢂڅsoftmax(·) 
1 0 0 0
1 1 1 1
1 0 1 0
HD( জ)
·
݃(ڄ)
ࡴ ઢઢ
෩ࢄڅ
Dual Couple Behavior 
Attention (DCBA) ·෡ࢄଵ
෡ࢄ௞෡ࢄ|ࣜ|
ܮ െ11 0 0 0
1 1 1 1
1 0 1 0ܮࡳڄࢽ௅… …[ොܠଵ௅ିଵ;…;ොܠ௞௅ିଵ;…;ොܠ|ࣜ|௅ିଵ]জ
ࢃ෱ொ
ࢃ෱௄
ࢃ෱௏
෱ࡽ௅
෱ࡷ௅
෱ࢂ௅Output 
Cross-Behavior Attention 
(CBA) -0.1 0.3 0.4 0.6 
-0.1 0.3 0.4 0.6 0.4 0.6 0.6 1 0 0 0
1 1 1 1
1 0 1 0
…
broadcast(·) ·জ ࡲ
softmax 
|ऌ|1 1 1
|ऌ| |ऌ| |ऌ| |ऌ|
|ऌ|1|ऌ|1ࡹ௦0.93 0.26 0.26 0.26 
0.65 0.97 1.07 1.30 
0.82 0.23 1.36 0.23 
ࡹ௘=[ܕଵ௘,…,ܕ௞௘,…,ܕ|ࣜ|௘]
broadcast(·) 
dcas t(·) ·ࢄ(௜௣ ) ࡹ௞௘
ࢄ௞(௜௣ )User Behavioral preference Factor Enhanced Embedding  Layer 
(UB-FEEL) 
Figur
e 2: Illustration of our EIDP with a dual-path architecture containing explicit modeling path (EMP) and implicit modeling
path (IMP). EMP takes the representations from the item-behavior side ( 𝑖𝑏) and the position-behavior side ( 𝑝𝑏) as input, with
PBS-TPE as the core component. IMP takes the representations from the item-position side ( 𝑖𝑝) as input and employs L-MSAB
as the encoder for each behavior-specific view, with CBAF for representation fusion. Note that we use black dashed lines to
outline the main components of our EIDP in the middle and gray solid lines to highlight the details within the corresponding
core modules.|B|, 𝐿and 𝑑are assumed to be 4, 3 and 6, respectively, for easy illustration.
where 𝑸★𝑢=𝑿★𝑢𝑾★
𝑄,𝑲★𝑢=𝑿★𝑢𝑾★
𝐾,𝑽★𝑢=𝑿★𝑢𝑾★
𝑉, and𝑾★
𝑄,𝑾★
𝐾,
𝑾★
𝑉∈R𝑑×𝑑are learnable query, key and value projection trans-
formation matrices, respectively. 𝚫is the lower triangular matrix-
form of causality mask to prevent the usage of future information.
HD(bℓ1𝑢,bℓ2𝑢)denotes the Hamming distance between two multi-
hot vectors, i.e., HD(bℓ1,bℓ2)=Í
𝑘𝑏ℓ1
𝑘XOR 𝑏ℓ2
𝑘, where XORdenotes
the exclusive or operation. Let ΩHDrepresent the range of values
forHD(bℓ1,bℓ2), and it is evident that ΩHD={𝑥|𝑥∈[0,|B|]∩ Z},
and𝑔𝑢(·):ΩHD→Risauser-specificmappingfunctionthatcon-
verts the integer of Hamming distance to a real value. 𝑯𝑢∈R𝐿×𝐿
isthesymmetricattentionweightmatrixobtainedbymappingthe
Hamming distances between pairwise behavior sets in the user se-
quenceS𝑢.
Remarks. In Eq.(6), we design the HDA weight matrix specifically
forbehaviorsets.Theintuitionbehinditistwofold:ononehand,in
order to capture the behavior set-wise transition relations for dif-
ferent users, we use the edit distance to model high-dimensional
dependencies; on the other hand, the contextual dependencies men-
tioned in [18] show that focusing on the edit distance of pairwise
behavior sets is pivotal for countering the uncertainty issue in
Ch.2. For Ch.3, we conduct a fine-grained mining of the intra-
behaviorheterogeneousdynamicswithinthebehaviorsetsinDCBA.Finally, through coupling with positional information, this tackles
the issue of HDA weight matrix 𝑯𝑢being unable to differentiate
long-range and short-range behavior set-wise transition patterns.
Feed-forward Network (FFN). In the PBS-TPE module of our
EMP, we follow [19], incorporating a point-wise feed-forward net-
work (FFN) after the DCBA layer to inject non-linearity. The FFN
layer is formally represented as:
FFN(e𝑿★)=ReLU(e𝑿★𝑾1+b1)𝑾2+b2 (7)
where 𝑾1,𝑾2∈R𝑑×𝑑andb1,b2∈R1×𝑑are learnable weights
and biases, respectively. In the subsequent modules, we will also
apply FFN multiple times.
Personalized Behavior Set-wise Transition Pattern Extrac-
tor (PBS-TPE). Our PBS-TPE explicitly incorporates the behavior
set information to capture personalized behavior set-wise transi-
tion patterns. In the end, it derives the output representations for
EMP by combining the representations from two aspects:
𝑿EMP=PBS-TPE(𝑿★)=FFN Õ{(𝑖𝑏),(𝑝𝑏)}
★DCBA(𝑿★,𝔅)(8)
where 𝑿EMP∈R𝐿×𝑑denotes the matrix form of the output repre-
sentations along EMP.
 
332Explicitand Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation KDD ’24, August 25–29, 2024, Barcelona, Spain
3.3 Implicit Modeling Path
From the implicit modeling perspective, in our IMP, we enhance
theembeddingsbasedonbehaviortypessolelyusingbehaviorpref-
erence factors. After feeding into the encoder, we obtain repre-
sentations under multiple behavior-specific views. By extracting
contextual collaboration in behavior semantics, we can attain the
inter-behavior level heterogeneous dependencies.
3.3.1 User Behavioral Preference Factor Enhanced Embedding Layer.
InourUB-FEEL,foraninteractionterm (𝑣ℓ𝑢,bℓ𝑢),weobtaintheini-
tial latent representations:
x(𝑖𝑝)
𝑣ℓ𝑢=e𝑣ℓ𝑢⊕pℓ (9)
Different from EEL in EMP, we simply sum the item embeddings
with the position embeddings. We use 𝑿(𝑖𝑝)
𝑢∈R𝐿×𝑑to represent
the matrix form of the obtained representations.
Traditional MBSR applies multi-view modeling approaches by
eitherreplacingnon-behavior-specificinteractiontermswithpadding
vectorsorskippingthem,onlyconnectingbehavior-specificterms
asasubsequence[7,13,26].Theyfailtopreservethesequentialse-
mantic coherence of the behavior sets. In UB-FEEL, for sequences
partitioned under a specific behavior type, we design our scaling
mask as follows:
𝑴𝑠
𝑢[ℓ, 𝑘]=(1, 𝑏ℓ
𝑢,𝑘=0
|B|, 𝑏ℓ
𝑢,𝑘=1(10)
wheretheconstructionofthescalingmask 𝑴𝑠𝑢∈R𝐿×|B|isrelated
tothebehaviorsetsequenceofuser 𝑢.Forthe 𝑘-thbehaviorinthe
behaviorsetatthe ℓ-thtimestep,wekeepitscorrespondingweight
unchanged if 𝑏ℓ
𝑢,𝑘=0and multiply its weight by a scaling factor
for embedding enhancement if 𝑏ℓ
𝑢,𝑘=1. We define this scaling
factor as|B|and obtain the embedding enhancement mask:
𝑭𝑢=broadcast(f𝑢) (11)
𝑴𝑒
𝑢=[m𝑒
𝑢,1, ...,m𝑒
𝑢,𝑘, ...,m𝑒
𝑢,|B|]=softmax(𝔅𝑢⊙𝑭𝑢)⊙𝑴𝑠
𝑢(12)
where broadcast(·)is an operation that expands a vector matched
with one dimension of a matrix along rows (or columns), enabling
element-wise product computations between them. 𝑭𝑢∈R𝐿×|B|
isthematrixobtainedbyreplicatingthebehavioralpreferencefac-
torf𝑢∈R1×|B|of user 𝑢for𝐿times. We adopt the user behav-
iorpersonalizedweightspreviouslyusedinEq.(1).Theembedding
enhancement mask 𝑴𝑒𝑢∈R𝐿×|B|is derived through the element-
wise multiplication of weights and the scaling mask. The 𝑘-th col-
umn vector can be regarded as the enhancement factors under the
𝑘-th behavior of user 𝑢. For the 𝑘-th behavior, we obtain its en-
hanced sequential representations:
𝑴𝑒
𝑢,𝑘=broadcast(m𝑒
𝑢,𝑘) (13)
𝑿(𝑖𝑝)
𝑢,𝑘=𝑿(𝑖𝑝)
𝑢⊙𝑴𝑒
𝑢,𝑘(14)
where 𝑴𝑒
𝑢,𝑘∈R𝐿×𝑑is acquired by duplicating the column vec-
torm𝑒
𝑢,𝑘∈R𝐿×1for𝑑times. Thus, we can obtain the sequential
representations for all other types of behaviors. Without loss of
generality, we consistently use 𝑿(𝑖𝑝)
𝑘∈R𝐿×𝑑instead of 𝑿(𝑖𝑝)
𝑢,𝑘for
illustration, where 𝑘∈{1, ...,|B|}.3.3.2 Light Multi-head Self-Attention Blocks. In UB-FEEL of IMP,
we selectively enhance representations under different behavior-
specificviews.Next,weintroduceProbSparsemulti-headself-attention
(PSA) [46] to build our light multi-head self-attention blocks (L-
MSAB) as part of the encoder:
𝑀(q𝑖,𝑲)=max
𝑗{q𝑖k⊤
𝑗√
𝑑}
−1
𝐿𝐿Õ
𝑗=1q𝑖k⊤
𝑗√
𝑑(15)
Pr
obSparse multi-head self-Attention (PSA). Basedonthemea-
surement in Eq.(15), PSA assesses the importance of dot-product
pairs, permitting each key to focus exclusively on the 𝑢dominant
queries:
𝑿(ℎ)
𝑘= softmax(𝑸(ℎ)
𝑘𝑲(ℎ)
𝑘⊤
√
𝑑)
⊙𝑴𝚫𝑽(ℎ)
𝑘(16)
where 𝑸(ℎ)
𝑘∈R𝑢×𝑑
𝐻is
the reduced matrix of 𝑸(ℎ)
𝑘for head ℎ,
derived by calculating the top- 𝑢queries under the measurement
𝑀(q𝑖,𝑲).
Notethat 𝑸(ℎ)
𝑘=𝑿(𝑖𝑝)
𝑘𝑾(ℎ)
𝑄𝑘,𝑲(ℎ)
𝑘=𝑿(𝑖𝑝)
𝑘𝑾(ℎ)
𝐾𝑘,𝑽(ℎ)
𝑘=
𝑿(𝑖𝑝)
𝑘𝑾(ℎ)
𝑉𝑘and𝑾(ℎ)
𝑄𝑘,𝑾(ℎ)
𝐾𝑘,𝑾(ℎ)
𝑉𝑘∈R𝑑×𝑑
𝐻ar
e learnable parame-
termatricesspecifictothe 𝑘-thbehaviorandthe ℎ-thhead. 𝐻isthe
total number of heads. 𝑴𝚫∈R𝑢×𝐿is the mask matrix reordered
based on the corresponding indices of top- 𝑢queries from the orig-
inal causality mask 𝚫. We set 𝑢=𝛼ln𝐿and 𝛼is a sampling con-
stant. Finally, for non-dominant queries, PSA replaces the outputs
with the mean of values 𝑽(ℎ)
𝑘:
PSA(ℎ)(𝑿(𝑖𝑝)
𝑘)=[{𝑿(ℎ)
𝑘,mean(𝑽(ℎ)
𝑘)
}] (17)
Wesettheoutputfrom {𝑿(ℎ)
𝑘,mean(𝑽(ℎ)
𝑘)
}basedonwhethertheir
original row indices come from dominant queries since they are
indeterminate. Thus, we obtain the output after randomly sam-
plingthedot-productpairs.Wefollowtheoriginalmulti-headself-
attention mechanism, and perform the process in Eq.(16) across
different latent dimensions 𝐻times in parallel:
PSA(𝑿(𝑖𝑝)
𝑘)=concat PSA(1)(𝑿(𝑖𝑝)
𝑘), ...,
PSA(ℎ)(𝑿(𝑖𝑝)
𝑘), ...,PSA(𝐻)(𝑿(𝑖𝑝)
𝑘)𝑾𝐿(18)
Finally, we concatenate the output from each head and obtain the
final output though a linear projection layer.
Remarks. For the motivations of introducing PSA, one goal is to di-
versifythelearnedrepresentationsunderdifferentbehavior-specific
views. Another consideration is that the view encoder should be
lightweight since the computational time will increase with the
numberofbehaviortypes.Focusingprimarilyondominantqueries
in PSA also equips the model with the ability to counteract the un-
certainty mentioned in Ch.2in user interest stimulation.
Light Multi-head Self-Attention Blocks (L-MSAB). We design
our L-MSAB as a stacked structure similar to [19]. Specifically, ig-
noringthesuperscriptnotation (𝑖𝑝),westackL-MSABwithaPSA
layer and an FFN layer, and the 𝑐-th(𝑐≥1)block is formulated as
follows:
𝑿(𝑐)
𝑘=L-MSAB(𝑐)(𝑿(𝑐−1)
𝑘)=FFN PSA(𝑿(𝑐−1)
𝑘)(19)
b𝑿𝑘=𝑿(𝐶)
𝑘=L-MSAB(𝐶)(𝑿(𝐶−1)
𝑘) (20)
 
333KDD’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
where 𝑐∈{1,2, ..., 𝐶}with 𝐶as the number of stacked blocks in L-
MSAB. We set 𝑿(0)
𝑘=𝑿(𝑖𝑝)
𝑘. Consequently, we obtain the output
representation b𝑿𝑘∈R𝐿×𝑑under each behavior-specific view.
3.3.3 Cross-Behavior Attention Fusion. We design a fusion mod-
ule for multiple behavior-specific views, i.e., cross-behavior atten-
tionfusion(CBAF).TheCBAFmoduleiscomposedofacross-behavior
attention (CBA) layer followed by an FFN layer.
Cross-Behavior Attention (CBA). Motivated by [14, 26], we uti-
lize the behavior set-weighted, but non-user-personalized, behav-
iorsetembeddingatthenexttimestepasaguidanceforthefusion
ofdifferentbehaviorviews.Specifically,weuseitasaqueryinthe
cross-attentionmechanismtocalculatetheattentionscoresamong
various behavior views at the current time step (e.g., ℓ), serving as
fusion weights for multi-view integration:
CBA(b𝑿1, ...,b𝑿|B|,𝔅ℓ+1)=softmax(˘𝑸ℓ˘𝑲⊤
ℓ√
𝑑)˘𝑽ℓ(21)
wher
e˘𝑸ℓ=𝜸ℓ+1𝑾˘𝑄∈R1×𝑑,˘𝑲ℓ=[bxℓ
1;...;bxℓ
𝑘;...;bxℓ
|B|]𝑾˘𝐾∈
R|B|×𝑑,˘𝑽ℓ=[bxℓ
1;...;bxℓ
𝑘;...;bxℓ
|B|]𝑾˘𝑉∈R|B|×𝑑and𝑾˘𝑄,𝑾˘𝐾,
𝑾˘𝑉∈R𝑑×𝑑are learnable query, key and value projection trans-
formation matrices, respectively. Note that 𝜸ℓ+1=bℓ+1·𝑮∈R1×𝑑
denotes the non-user-personalized behavior set embedding at the
(ℓ+1)-th time step.
Remarks. The CBA mechanism is designed to extract contextual
collaborationinbehaviorsemanticsandcaptureinter-behaviorde-
pendencies. The introduction of the behavior set at the next time
stepiscrucialforaddressing Ch.4,enablingourEIDPtoadaptively
recommend items based on different target behavior sets.
Cross-Behavior Attention Fusion (CBAF). Overall, the formal
construction of our CBAF module is as follows:
𝑿IMP=CBAF(b𝑿1, ...,b𝑿|B|,𝔅ℓ+1)
=FFN CBA(b𝑿1, ...,b𝑿|B|,𝔅ℓ+1) (22)
where 𝑿IMP∈R𝐿×𝑑denotes the matrix form of the output repre-
sentations along IMP correspondingly.
3.4 Prediction and Model Training
Dual-Path Next-Item Prediction. Therepresentationsoutputfrom
EMPandIMPtakedifferentperspectives,incorporatingbehavioral
information at both intra-behavior and inter-behavior levels. We
combine the output representations from the two paths to predict
the next item that user 𝑢may interact with under the target behav-
ior setat the ( ℓ+1)-th time step:
ˆ𝑦ℓ+1,𝑣=1
2(xEMP
ℓ⊕xIMP
ℓ)e⊤
𝑣 (23)
wher
exEMP
ℓ∈R1×𝑑andxIMP
ℓ∈R1×𝑑represent the output repre-
sentations from the two paths at the ℓ-th time step, respectively.
ˆ𝑦ℓ+1,𝑣is a scalar that signifies the probability score of interacting
with item 𝑣.Training and Optimization. We utilize the commonly used bi-
nary cross-entropy loss in SR to optimize our EIDP for the next-
item prediction task:
L=−1
|𝛿(𝑣)
|Õ
𝑢∈U𝐿Õ
ℓ=1𝛿(𝑣ℓ
𝑢)[log 𝜎(ˆ𝑦ℓ+1,𝑣ℓ𝑢)+log 1−𝜎(ˆ𝑦ℓ+1,𝑗)]
(24)
where the subscript 𝑗∈V\S𝑢denotes a randomly sampled nega-
tive item and 𝜎(·)is the sigmoid function. The indicator function
𝛿(𝑣ℓ𝑢)=0when 𝑣ℓ𝑢isapaddingitemand 𝛿(𝑣ℓ𝑢)=1otherwise.Note
that|𝛿(𝑣)|represents the total amount of ground truth items.
4 EXPERIMENTS
In this section, we conduct experiments on two publicly available
industrialdatasetsrelatedtoBSSRscenarios,aimingtoanswerthe
following research questions: (1) RQ1: How does our EIDP per-
form in comparison with the state-of-the-art SR and MBSR meth-
ods? (2) RQ2: Can our dual-path architecture for explicit and im-
plicit modeling exhibit synergistic effect in different scenarios? (3)
RQ3: How do the modules in our EIDP perform comparing with
some alternative designs? (4) RQ4: Does the incorporation of ad-
ditional behavioral information enhance the recommendation per-
formanceofourEIDP?(5) RQ5:Howtointerpretthepersonalized
intra-behavior dynamics extracted by EMP and the inter-behavior
collaborativecommonalityinbehaviorsemanticscapturedbyIMP
in our EIDP?
4.1 Experimental Settings
4.1.1 Datasets. WeconductourexperimentsonTenrec[43],which
iscollectedfromsomerecommendationplatformsofTencent,com-
prises user feedback from different scenarios. i) QK-Video . The
interacted items are short videos, and includes positive feedback
(with certain user actions) and negative feedback (with exposure
but no user action). We treat click as auxiliary behavior, and like,
share and follow as target behaviors . ii)QK-Article. Similarly, the
interacted items are articles. We take read as auxiliary behavior ,
and like, share, favorite and follow as target behaviors. The details
ofdatapreprocessingandthecorrespondingstatisticsareprovided
in Appendix A.3 for reproducibility.
4.1.2 Evaluation Protocols. We use two widely adopted ranking-
oriented evaluation metrics, i.e., hit ratio (HR@ 𝑘) and normalized
discounted cumulative gain (NDCG@ 𝑘), where 𝑘∈{5,10,20}. We
adopt the full-ranking setting [20] in evaluation.
4.1.3 Baselines. We compare our EIDP with the following two
sets of state-of-the-art baselines: (1) Sequential Recommenda-
tion: SASRec [19], ICLRec [6] and DuoRec [27], and (2) Multi-
Behavior Sequential Recommendation:MGNN-SPred[34],MBHT
[41],MB-STR[42],NextIP[26]andDyMuS[7].Theintroductionof
all the baselines are presented in Appendix A.4. Most MBSR meth-
odsneedsomeadjustmentstobeusedforBSSR.Thedetailsofthese
adjustments are presented in Appendix A.5.
4.1.4 Implementation Details. WeimplementourEIDPinPyTorch
1.13. The more complete reproduction details are reported in Ap-
pendix A.6. For a fair comparison, we fix the embedding dimen-
sion 𝑑to 64 and the sequence length 𝐿to 50 for all models. We
 
334Explicitand Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 1: Performance comparison of two groups of baselines and our EIDP on two datasets. The best results are marked in
bold, and the second best results are underlined. Note that the superscript ∗indicates a significance level of 𝑝≤0.01based on
paired samples t-test between the best baseline and our EIDP.
Dataset QK
-Video QK
-Article
Metrics NDCG@5
HR@5 NDCG@10 HR@10 NDCG@20 HR@20 NDCG@5
HR@5 NDCG@10 HR@10 NDCG@20 HR@20
SASRe
c 0.0077
0.0131 0.0111 0.0236 0.0154 0.0408 0.0202
0.0332 0.0285 0.0592 0.0388 0.1001
ICLRec 0.0081
0.0131 0.0110 0.0223 0.0154 0.0397 0.0223
0.0362 0.0303 0.0615 0.0399 0.0995
DuoRec 0.0060
0.0101 0.0090 0.0195 0.0128 0.0348 0.0236
0.0383 0.0319 0.0639 0.0421 0.1049
MGNN-SPr
ed0.0066
0.0112 0.0096 0.0207 0.0140 0.0381 0.0184
0.0294 0.0262 0.0536 0.0361 0.0931
MGNN-SPred†0.0069
0.0113 0.0100 0.0212 0.0141 0.0372 0.0197
0.0318 0.0272 0.0555 0.0369 0.0941
MBHT 0.0072
0.0120 0.0106 0.0222 0.0142 0.0369 0.0218
0.0358 0.0299 0.0610 0.0406 0.1037
MB-STR 0.0082
0.0137 0.0112
0.0230 0.0153 0.0392 0.0169
0.0278 0.0240 0.0503 0.0334 0.0874
NextIP 0.0083 0.0135
0.0119 0.0247 0.0165 0.0430 0.0249 0.0406 0.0335 0.0677 0.0445 0.1115
D
yMuS 0.0035
0.0058 0.0054 0.0115 0.0075 0.0202 0.0166
0.0272 0.0239 0.0501 0.0326 0.0848
DyMuS+0.0025
0.0041 0.0040 0.0089 0.0061 0.0172 0.0212
0.0343 0.0298 0.0611 0.0399 0.1015
EIDP 0.0119∗0.0194∗0.0162∗0.0328∗0.0217∗0.0551∗0.0255
0.0413 0.0353∗0.0721∗0.0462∗0.1153∗
Improve. 43.37%
43.70% 36.13% 32.79% 31.52% 28.14% 2.41%
1.72% 5.37% 6.50% 3.82% 3.41%
T
able 2: Ablation studies of our EIDP on two datasets.
Dataset QK
-Video
V
ariants w/o(ib)side
w/o(pb)side w/o EMP w/o IMP EIDP
NDCG@10 0.0073 0.0134 0.0145
0.0116 0.0162
HR@10 0.0155 0.0264 0.0285
0.0237 0.0328
NDCG@20 0.0107 0.0186 0.0198
0.0156 0.0217
HR@20 0.0294 0.0473 0.0495
0.0401 0.0551
Dataset QK
-Article
NDCG@10 0.0213 0.0326 0.0314
0.0285 0.0353
HR@10 0.0438 0.0655 0.0655
0.0577 0.0721
NDCG@20 0.0289 0.0431 0.0428
0.0378 0.0462
HR@20 0.0739 0.1074 0.1108
0.0948 0.1153
Figur
e 3: Performance of our EIDP with different fusion
variants.
use the same truncated user sequences to train all the models and
optimize them under a unified evaluation framework. In our EIDP,
we tune the number of stacked blocks 𝐶in L-MSAB in the range
of{2,3}and the head number 𝐻in PSA in the range of {1,2,4}.
The dropout rate for each dropout layer is searched in the range
of{0.3,0.4,0.5,0.6,0.7,0.8}. For QK-Video and QK-Article, we set
𝛼=8and12for the PSA mechanism, respectively.
4.2 Performance Comparison (RQ1)
We evaluate the performance of next-item prediction on the tar-
get behavior sets among all the baselines and our EIDP. The re-
sults on two datasets from different scenarios are reported in Ta-
ble 1. From the results, we summarize the observations as follows:
(1) We observe that most MBSR methods outperform SR methods
primarily due to the optimization process of cross-entropy loss
function, rather than originating from the behavioral information.When keeping the optimization function consistent with SR meth-
ods, most MBSR methods fail to compete with some advanced SR
methods.Thispartlyindicatesthatthemodelingtechniquesofthese
MBSR methods mainly for behavior labels can not be well trans-
ferred to the behavior sets with higher-order heterogeneous de-
pendencies. (2) MBHT and MB-STR do not perform well on the
QK-Video and QK-Article datasets, respectively, which may be at-
tributed to the fact that models designed for the cloze task do not
adapt well to the next-item prediction [8, 39, 47]. (3) Transformer-
basedmodelstendtooutperformGNN-basedmodelsinthecontext
of BSSR. The performance of SASRec, ICLRec and NextIP is supe-
rior to that of MGNN-SPred on both datasets. This reflects that
the self-attention mechanism is more suitable than GNN for the
next-item prediction under the full rank setting [11, 38]. (4) Our
EIDP outperforms all the baselines on all the metrics, with signif-
icant improvements of 35.94% on average on QK-Video and 3.87%
on QK-Article. This reflects the feasibility of incorporating behav-
ioral information into modeling from both explicit and implicit
perspectives for BSSR. (5) The performance of the baselines (e.g.,
DuoRec performs better on QK-Article but poorly on QK-Video,
while ICLRec exhibits the opposite trend, though they are both SR
methods.) exhibits significant variations across the two datasets,
highlighting the variations across different scenarios.
4.3 Ablation Study (RQ2)
To demonstrate the synergistic effect of explicit and implicit mod-
eling, we conduct ablation studies to investigate the contribution
differences of the two modeling perspectives. Specifically, we cre-
ate four architectural variants: EIDP without item side input in
EEL (denoted as w/o (ib)side), EIDP without position side input
in EEL (denoted as w/o (pb)side), EIDP without EMP (denoted as
w/o EMP) and EIDP without IMP (denoted as w/o IMP). We report
the results in Table 2 and have the following observations: (1) The
contributionsofw/oEMPandw/oIMPtotheoverallperformance
varyacrossdifferentdatasets,andbothareinferiortoEIDP,which
demonstrates the synergistic effect of explicit and implicit model-
ing perspectives. w/o EMP performs well on QK-Video, while w/o
IMPbringsmoreimprovementonQK-Article,whichindicatesthat
 
335KDD’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
(
a) TPE vs. PBS-TPE
 (
b) MBSR and BSSR
Figure 4: Performance comparison between TPE and PBS-
TPE (left), and our EIDP for MBSR and BSSR (right). Note
that the best-performing baseline on each dataset is also in-
cluded for reference in the right figure.
(
a)𝑯𝑢of𝑢2014
 (
b)𝑯𝑢of𝑢2900
Figure 5: Visualization of the attention scores 𝑯𝑢. The blue
bar charts show the preference intensity of the behavior set,
calculated via softmax(f𝑢⊙bℓ𝑢)·bℓ𝑢⊤adapted from Eq.(1).
different scenarios require different approaches to model behav-
ioral information effectively. Implicitly introducing behavioral in-
formation seems more suitable for QK-Video, where signals are
less indicative in next-item prediction, exhibiting a higher level
of uncertainty. Conversely, QK-Article benefits more from explicit
incorporation of behavioral information due to longer-range user
behavioral preferences. (2) w/o (pb)side consistently outperforms
w/o (ib)side on both datasets. This indicates that feeding atten-
tion layers with input devoid of item information often does not
help improve performance and may even be detrimental. (3) EIDP
consistently outperforms w/o (pb)side, indicating that coupling
positional information with behavioral information is beneficial.
(4) EIDP consistently outperforms w/o EMP and w/o IMP, reflect-
ingthesuperiorityofintegratingexplicitandimplicitperspectives.
This allows EIDP to adapt to BSSR in different scenarios.
4.4 Exploratory Study (RQ3 & RQ4)
Inthissection,weproposealternativedesignsforvariousmodules
of our EIDP to conduct exploratory experiments. We place some
supplementary experiments in Appendix A.7.
4.4.1 Fusion Module (CBAF). We provide the following four fu-
sion variants by modifying the CBA mechanism: (a) average fu-
sion (AF): AF(∗)=Í|B|
𝑘bxℓ
𝑘/|B|; (b) cross-attention with sequence
representations as queries (IP_CA): ˘𝑸ℓ=x(𝑖𝑝)
ℓ𝑾˘𝑄; (c) user fac-
tor weighted (UFW): UFW(∗)=softmax(f𝑢)·[bxℓ
1;...;bxℓ
𝑘;...;bxℓ
|B|];
(
a) Behavior set sequence and attention matrix in CBA w.r.t. 𝑢458
(
b) Behavior set sequence and attention matrix in CBA w.r.t. 𝑢260
Figure 6: Visualization of the arousal status of behaviors
within the behavior-set sequence, and the attention matrix
in CBA obtained via Eq.(21).
(d) cross-attention with personalized behavior set embeddings as
queries (PBS_CA): ˘𝑸ℓ=𝜷ℓ+1𝑾˘𝑄. From Figure 3, we can see that
CBA outperforms all the other variants on both datasets, demon-
strating the effectiveness of CBA. IP_CA fusion method performs
poorly on both datasets, while weighted average-based methods
excel on QK-Article, indicating that different scenarios require dif-
ferentadaptivefusionmechanisms.CBAoutperformsPBS_CA,which
showsthat,duetothelackofexplicitinjectionforbehaviorsetem-
beddings,using user-specific representationsas aguidance in IMP
may not be suitable. Extracting collaboration from multiple views
might be a more appropriate approach.
4.4.2 Pattern Extractor (PBS-TPE). Toinvestigatewhetherthecore
component PBS-TPE of EMP effectively utilizes behavior set em-
beddings to extract personalized behavioral patterns and improve
performance,weremovetheinputofthemfromEELandalsoelim-
inateHDAinDCBA,makingPBS-TPEreducetoatrivialTPEcom-
ponent. The comparison between PBS-TPE and TPE in Figure 4
(left) shows that PBS-TPE can effectively leverage the explicitly in-
jected behavioral information and intra-behavior dynamics.
4.4.3 BSSR Reduces to MBSR. To further validate whether EIDP
sufficiently explores the auxiliary behavioral information within
the behavior set, we also reduce BSSR to MBSR by keeping only
the behavior with the highest preference intensity in the behavior
set,thustransformingthemulti-hotvector bℓintoaone-hotvector.
The results in Figure 4 (right) show that EIDP benefits from the
inherentdynamicswithinthebehaviorset.Themulti-hotbehavior
set vectors, on one hand, can better complement user factors to
obtain personalized behavioral embeddings. On the other hand, it
can enrich the value range of the Hamming distance matrix 𝑯.
4.5 Case Study (RQ5)
We conduct case studies with some sampled users for the inter-
pretability of our EIDP. Firstly, we take two users ( 𝑢2014from QK-
Video and 𝑢2900from QK-Article) and visualize the 𝑯𝑢attention
weights obtained in HDA, in order to study interpretability for the
 
336Explicitand Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation KDD ’24, August 25–29, 2024, Barcelona, Spain
personalized intra-behavior dynamics learned by EMP. We addi-
tionally present the preference intensities expressed by the behav-
ior sets corresponding to the position indices of attention scores
with bar charts on both the left and top sides. From Figure 5, we
can observe that: (1) The scores learned by 𝑯𝑢are sensitive to the
step change of the behavior set. The changes in attention scores of-
ten correspond to variations in preference intensity. (2) HDA cap-
turesintra-behaviordynamicsbyfocusingontheweightsbetween
intensity peaks.Itiseasytoobservethattheattentionscorescorre-
sponding to points with higher preference intensity are also rela-
tively high. Scenario variability can be reflected by the significant
differences in the ranges of attention scores among users.
Secondly, to investigate the extracted inter-behavior collabora-
tive commonality in IMP, we also take two user cases ( 𝑢458from
QK-Video and 𝑢260from QK-Article). Subsequently, we visualize
theattentionmatricesreflectingthesemanticcorrelationsbetween
behaviors.Inaddition,wealsoprovidetheinformationoftheorig-
inal behavior-set sequence. From Figure 6, by observing how the
next time step’s behavior set influences the attention scores, we
can find that: (1) Behaviors evoked in the behavior sets at the next
time step often receive emphasis on the current attention scores,
whichcanbeobservedinbothusers.(2)Thecollaborationatthese-
mantic level among different behaviors varies significantly across
two datasets. The preference signals inhered in the behavior sets
areprimarilydominatedbythe followbehavioronQK-Video,while
on QK-Article, they exhibit more diverse collaborative patterns.
5 RELATED WORK
Single-Behavior Sequential Recommendation. Earlyworks[15,
28] employ Markov chains to characterize the item-item transi-
tions.Withtheriseofdeepneuralnetwork(DNN)models,aseries
of models based on various network architectures have emerged,
such as RNN-based [16, 17] and CNN-based [32] models. [19] in-
troducestheattentionmechanismintoSRandobtainstableperfor-
mance.Aconsiderableportionofsubsequentworks[10,24,30,36]
have been dedicated to improvement built upon this foundation.
The adaptability of GNN to structured data has also garnered fa-
vor in the field of SR [12]. The success of GNN-based models [2,
3, 21, 45] can be attributed to their ability to effectively capture
higher-order connections [12]. In addition, there have been efforts
to incorporate recent techniques, such as contrastive learning [6,
27, 33, 38, 40] and DNN variants [44, 49], into SR to provide dif-
ferent solutions. However, the above methods often consider only
one type of behavior in user sequences (e.g., click), neglecting the
heterogeneity within user-item interactions. Therefore, they may
not adapt to real-world recommendation scenarios well.
Multi-Behavior Sequential Recommendation. Most existing
studies on MBSR are deep learning-based algorithms, which can
be further categorized into RNN-based models [7, 22, 23], GNN-
based models [4, 34], Transformer-based models [13, 14, 26, 29,
42] and hybrid techniques-based models [37, 41], according to dif-
ferent underlying DNN architectures [5]. As a recently proposed
RNN-based model, DyMuS [7] allocates a separate GRU for each
behavior-specific sequence and integrates the encoded representa-
tions using a dynamic routing algorithm. MGNN-SPred [34] takes
theleadinutilizingGNNtoconstructamulti-relationalitemgraphfromallbehaviorsequences,facilitatingthelearningofglobalitem-
item relations. MB-STR [42] configures the weights in the classic
multi-head self-attention layer to be behavior-specific. It designs a
relative positional encoding function and uses MMoE for integra-
tion.FollowingSTOSA[10],PBAT[29]utilizesdistributionembed-
dings to encode interactive entities and employs Wasserstein dis-
tance for measuring personalized patterns between interactions.
MBHT [41] models users’ short-term and long-term preferences
through multi-scale Transformer and hypergraph.
Furthermore, upon a closer examination of the utilization of be-
havior information in these works, they can be primarily catego-
rized into two main perspectives. One perspective is to treat the
labelsofbehaviortypeasencodingentitiesundertheIDparadigm.
In this approach, models allocate globally shared learnable param-
eters based on the corresponding behavior types [ 22, 23, 29, 42].
Theotherperspectiveinvolvessegmentingsequencesbasedonbe-
haviortypes,feedingmultiplebehavior-specificsubsequencesinto
corresponding encoders to obtain representations under different
behavior views [7, 13, 34]. The modeling perspectives in the re-
maining methods [4, 14, 26, 37, 41] and our EIDP encompass both
of these two aspects.
6 CONCLUSIONS AND FUTURE WORK
In this paper, we define and study a new problem called behav-
iorset-informedsequentialrecommendation(BSSR),forwhichwe
propose a novel solution, i.e., Explicit and Implicit modeling via
Dual-Path Transformer (EIDP), aiming to exploit the information
in behavior set more effectively. Our EIDP is of dual-path archi-
tecture, consisting of explicit modeling path (EMP) and implicit
modeling path (IMP). Specifically, in EMP, in order to extract the
personalized intra-behavior dynamics, we design a personalized
behavior set-wise transition pattern extractor, tightly coupling be-
havioral information with item side and position side. In IMP, we
employ light multi-head self-attention blocks as encoders to ex-
tract representations from different behavior-specific views. We
capturetheinter-behaviorcollaborationinbehaviorsemanticsand
aggregate them via cross-behavior attention fusion. Extensive ex-
periments, including comparison with ten very competitive meth-
ods, ablation study, exploratory study and case study, on two real-
world datasets demonstrate the effectiveness of our EIDP.
For future works, we are interested in generalizing our EIDP to
multi-domain and large-scale recommendation scenarios.
ACKNOWLEDGMENTS
We thank the support of National Natural Science Foundation of
China (Nos. 62172283 and 62272315), Guangdong Basic and Ap-
plied Basic Research Foundation (No. 2024A1515010122), Guang-
dongProvinceKeyLaboratoryofPopularHighPerformanceCom-
puters (No. 2017B030314073), and Guangdong Province Engineer-
ingCenterofChina-madeHighPerformanceDataComputingSys-
tem.
REFERENCES
[1] Jesús Bobadilla, Fernando Ortega, Antonio Hernando, and Abraham Gutiérrez.
2013. Recommender systems survey. KBS46 (2013), 109–132.
[2] Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng
Jin, and Yong Li. 2021. Sequential recommendation with graph neural networks.
 
337KDD’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
InSIGIR. 378–387.
[3] Hong Chen, Bin Huang, Xin Wang, Yuwei Zhou, and Wenwu Zhu. 2023. Global-
local GraphFormer: Towards better understanding of user intentions in sequen-
tial recommendation. In MM Asia . 1–7.
[4] Weixin Chen, Mingkai He, Yongxin Ni, Weike Pan, Li Chen, and Zhong Ming.
2022. Global and personalized graphs for heterogeneous sequential recommen-
dationby learningbehaviortransitions anduser intentions.In RecSys.268–277.
[5] XiaoqingChen,ZhitaoLi,WeikePan,andZhongMing.2023. Asurveyonmulti-
behavior sequential recommendation. arXiv:2308.15701 (2023).
[6] Yongjun Chen, Zhiwei Liu, Jia Li, Julian McAuley, and Caiming Xiong. 2022. In-
tentcontrastivelearningforsequentialrecommendation.In WWW.2172–2182.
[7] JunsuCho,DongminHyun,DongwonLim,HyeonjaeCheon,Hyoung-ielPark,
andHwanjoYu.2023. Dynamicmulti-behaviorsequencemodelingfornextitem
recommendation. In AAAI. 4199–4207.
[8] Alexander Dallmann, Daniel Zoller, and Andreas Hotho. 2021. A case study
on sampling strategies for evaluating neural sequential item recommendation
models. In RecSys. 505–514.
[9] Yizhou Dang, Enneng Yang, Guibing Guo, Linying Jiang, Xingwei Wang, Xiaox-
iao Xu, Qinghui Sun, and Hong Liu. 2023. Uniform sequence better: Time in-
tervalawaredataaugmentationforsequentialrecommendation.In AAAI.4225–
4232.
[10] Ziwei Fan, Zhiwei Liu, Yu Wang, Alice Wang, Zahra Nazari, Lei Zheng, Hao
Peng, and Philip S Yu. 2022. Sequential recommendation via stochastic self-
attention. In WWW. 2036–2047.
[11] Ziwei Fan, Zhiwei Liu, Jiawei Zhang, Yun Xiong, Lei Zheng, and Philip S Yu.
2021. Continuous-time sequential recommendation with temporal graph collab-
orative transformer. In CIKM. 433–442.
[12] Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan
Quan, Jianxin Chang, Depeng Jin, Xiangnan He, et al. 2023. A survey of graph
neuralnetworksforrecommendersystems:Challenges,methods,anddirections.
ACM TORS 1, 1 (2023), 1–51.
[13] Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, and Dawei
Yin. 2020. Deep multifaceted transformers for multi-objective ranking in large-
scale e-commerce recommender systems. In CIKM. 2493–2500.
[14] Mingkai He, Jing Lin, Jinwei Luo, Weike Pan, and Zhong Ming. 2023. FLAG: A
feedback-awarelocalandglobalmodelforheterogeneoussequentialrecommen-
dation. ACM TIST 14, 1 (2023), 1–22.
[15] RuiningHe,Wang-ChengKang,JulianJMcAuley,etal.2018. Translation-based
recommendation: A scalable method for modeling sequential behavior. In IJCAI.
5264–5268.
[16] Balázs Hidasi and Alexandros Karatzoglou. 2018. Recurrent neural networks
with top-k gains for session-based recommendations. In CIKM. 843–852.
[17] Balázs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
2016. Session-based Recommendations with Recurrent Neural Networks. In
ICLR.
[18] Jiarui Jin, Xianyu Chen, Weinan Zhang, Yuanbo Chen, Zaifan Jiang, Zekun Zhu,
Zhewen Su, and Yong Yu. 2022. Multi-scale user behavior network for entire
space multi-task learning. In CIKM. 874–883.
[19] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom-
mendation. In ICDM. 197–206.
[20] Walid Krichene and Steffen Rendle. 2020. On sampled metrics for item recom-
mendation. In KDD. 1748–1757.
[21] Yunyi Li, Yongjing Hao, Pengpeng Zhao, Guanfeng Liu, Yanchi Liu, Victor S
Sheng,andXiaofangZhou.2023. Edge-enhancedglobaldisentangledgraphneu-
ral network for sequential recommendation. ACM TKDD 17, 6 (2023), 1–22.
[22] Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, and Enhong Chen. 2018.
Learning from history and present: Next-item recommendation via discrimina-
tively exploiting user behaviors. In KDD. 1734–1743.
[23] Qiang Liu, Shu Wu, and Liang Wang. 2017. Multi-behavioral sequential predic-
tion with recurrent log-bilinear model. IEEE TKDE 29, 6 (2017), 1254–1267.
[24] Qiao Liu, Yifu Zeng, Refuoe Mokhosi, and Haibin Zhang. 2018. STAMP: short-
term attention/memory priority model for session-based recommendation. In
KDD. 1831–1839.
[25] Zhiwei Liu, Yongjun Chen, Jia Li, Philip S Yu, Julian McAuley, and Caiming
Xiong. 2021. Contrastive self-supervised sequential recommendation with ro-
bust augmentation. arXiv:2108.06479 (2021).
[26] Jinwei Luo, Mingkai He, Xiaolin Lin, Weike Pan, and Zhong Ming. 2022. Dual-
task learning for multi-behavior sequential recommendation. In CIKM. 1379–
1388.
[27] RuihongQiu,ZiHuang,HongzhiYin,andZijianWang.2022. Contrastivelearn-
ing for representation degeneration problem in sequential recommendation. In
WSDM. 813–823.
[28] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Fac-
torizingpersonalizedMarkovchainsfornext-basketrecommendation.In WWW.
811–820.
[29] Jiajie Su, Chaochao Chen, Zibin Lin, Xi Li, Weiming Liu, and Xiaolin Zheng.
2023. Personalized behavior-aware Transformer for multi-behavior sequentialrecommendation. In MM. 6321–6331.
[30] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.
2019. BERT4Rec: Sequential recommendation with bidirectional encoder repre-
sentations from transformer. In CIKM. 1441–1450.
[31] Jiliang Tang, Jie Tang, and Huan Liu. 2014. Recommendation in social media:
recent advances and new frontiers. In KDD. 1977–1977.
[32] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommendation
via convolutional sequence embedding. In WSDM. 565–573.
[33] Lei Wang, Ee-Peng Lim, Zhiwei Liu, and Tianxiang Zhao. 2022. Explanation
guided contrastive learning for sequential recommendation. In CIKM. 2017–
2027.
[34] Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan
Zha. 2020. Beyond clicks: Modeling multi-relational item graph for session-
based target behavior prediction. In WWW. 3056–3062.
[35] Chuhan Wu, Fangzhao Wu, Yongfeng Huang, and Xing Xie. 2023. Personalized
news recommendation: Methods and challenges. ACM TOIS 41, 1 (2023), 1–50.
[36] Liwei Wu, Shuqing Li, Cho-Jui Hsieh, and James Sharpnack. 2020. SSE-PT: Se-
quential recommendation via personalized transformer. In RecSys. 328–337.
[37] LianghaoXia,ChaoHuang,YongXu,andJianPei.2023. Multi-behaviorsequen-
tialrecommendationwithtemporalgraphTransformer. IEEE TKDE 35,6(2023).
[38] XuXie,FeiSun,ZhaoyangLiu,ShiwenWu,JinyangGao,JiandongZhang,Bolin
Ding, and Bin Cui. 2022. Contrastive learning for sequential recommendation.
InICDE. 1259–1273.
[39] Yueqi Xie, Peilin Zhou, and Sunghun Kim. 2022. Decoupled side information
fusion for sequential recommendation. In SIGIR. 1611–1621.
[40] YuhaoYang,ChaoHuang,LianghaoXia,ChunzhenHuang,DaLuo,andKangyi
Lin. 2023. Debiased contrastive learning for sequential recommendation. In
WWW. 1063–1073.
[41] Yuhao Yang, Chao Huang, Lianghao Xia, Yuxuan Liang, Yanwei Yu, and Chen-
liang Li. 2022. Multi-behavior hypergraph-enhanced transformer for sequential
recommendation. In KDD. 2263–2274.
[42] Enming Yuan, Wei Guo, Zhicheng He, Huifeng Guo, Chengkai Liu, and Ruim-
ing Tang. 2022. Multi-behavior sequential transformer recommender. In SIGIR.
1642–1652.
[43] Guanghu Yuan, Fajie Yuan, Yudong Li, Beibei Kong, Shujie Li, Lei Chen, Min
Yang, Chenyun Yu, Bo Hu, Zang Li, et al. 2022. Tenrec: A large-scale multi-
purpose benchmark dataset for recommender systems. NeurIPS (2022), 11480–
11493.
[44] Zhenrui Yue, Yueqi Wang, Zhankui He, Huimin Zeng, and Julian J. McAuley
andDongWang.2024. Linearrecurrentunitsforsequentialrecommendation.In
WSDM. 930–938.
[45] Mengqi Zhang, Shu Wu, Xueli Yu, Qiang Liu, and Liang Wang. 2023. Dynamic
graph neural networks for sequential recommendation. IEEE TKDE 35, 5 (2023),
4741–4753.
[46] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,
and Wancai Zhang. 2021. Informer: Beyond efficient Transformer for long se-
quence time-series forecasting. In AAAI. 11106–11115.
[47] KunZhou,HuiWang,WayneXinZhao,YutaoZhu,SiruiWang,FuzhengZhang,
Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for
sequential recommendation with mutual information maximization. In CIKM.
1893–1902.
[48] Meizi Zhou, Zhuoye Ding, Jiliang Tang, and Dawei Yin. 2018. Micro behaviors:
A new perspective in e-commerce recommender systems. In WSDM. 727–735.
[49] Tianyu Zhu, Yansong Shi, Yuan Zhang, Yihong Wu, Fengran Mo, and Jian-Yun
Nie. 2024. Collaboration and transition: Distilling item transitions into multi-
query self-attention for sequential recommendation. WSDM, 1003–1011.
A SUPPLEMENTARY MATERIAL
A.1 Notations
We provide a notation table1which summarize the symbols and
their corresponding explanations introduced in Section 3.
A.2 The learning process of EIDP
In this section, we first present the algorithmic pseudo-code2for
ProbSparse multi-head self-attention mechanism [46] introduced
in our behavior-specific encoder L-MSAB. Subsequently, we sum-
marize the learning process of our EIDP model in Alg.1.
1https://github.com/OshiNoCSMA/EIDP/blob/main/A1NotationTable.pdf
2https://github.com/OshiNoCSMA/EIDP/blob/main/A2Algo_PSA.pdf
 
338Explicitand Implicit Modeling via Dual-Path Transformer for Behavior Set-informed Sequential Recommendation KDD ’24, August 25–29, 2024, Barcelona, Spain
Algorithm
1:The forward propagation flow of EIDP
Input
:The interaction sequence with behavior sets of a
specific user 𝑢, i.e.,
S𝑢={(𝑣1𝑢,b1𝑢), ...,(𝑣ℓ𝑢,bℓ𝑢), ...,(𝑣𝐿𝑢,b𝐿𝑢)}
Output : The final sequential representations 𝑿∈R𝐿×𝑑
used for next-item prediction
/* Step 1: Entities Encoding */
1Intialize 𝑰,𝑷,𝑮andFand retrieve 𝑬∈R𝐿×𝑑from𝑰;
2Calculate 𝑩∈R𝐿×𝑑through Eq.(1);
/* Step 2: Explicit Modeling Path Forward */
3𝑿(𝑖𝑏)←𝑬⊕𝑩,𝑿(𝑝𝑏)←𝑷⊕𝑩; // EEL
/* PBS-TPE */
4Perform dual-coupled behavior set-aware attention from
both item and position aspects with 𝑿(𝑖𝑏)and𝑿(𝑝𝑏)
according to Eqs.(3-6) ; // DCBA
5Combine the representations from two aspects and
perform feed-forward network:
𝑿EMP←FFN Í{(𝑖𝑏),(𝑝𝑏)}
★DCBA(𝑿★,𝔅);
/* Step 3: Imlicit Modeling Path Forward */
/* UB-FEEL */
6𝑿(𝑖𝑝)←𝑬⊕𝑷;
7Construct the scaling mask 𝑴𝑠𝑢based on 𝔅according to
Eq.(10);
8Construct the embedding enhancement mask 𝑴𝑒𝑢based on
𝑴𝑠𝑢according to Eqs.(11-12);
9foreach behavior types 𝑘=1to|B|do
10Obtain
the enhanced behavior-specific sequential
representations 𝑿(𝑖𝑝)
𝑘according to Eqs.(13-14);
/* L-MSAB */
11 foreach number of blocks 𝑐=1to𝐶do
12 Perform
ProbSparse multi-head self-attention
mechanism with 𝑿(𝑖𝑝)
𝑘according to Eqs.(15-18) ;
// PSA
13 Perform feed-forward network;
14 end
15Obtain the output representation b𝑿𝑘under 𝑘-th
behavior view: b𝑿𝑘=L-MSAB(𝐶)(𝑿(𝐶−1)
𝑘);
16end
/* CBAF */
17Perform multi-view integration on all the behavior-specific
representations b𝑿1, ...,b𝑿|B|via cross-behavior attention
mechanism according to Eq.(21); // CBA
18Perform feed-forward network and obtain 𝑿IMP:
𝑿IMP←FFN CBA(b𝑿1, ...,b𝑿|B|,𝔅ℓ+1);
/* Step 4: Dual-Path Representation Aggregation */
19𝑿←1
2(𝑿EMP⊕𝑿IMP)
20r
eturn 𝑿
A.3
Dataset Preprocessing
We preprocess the Tenrec datasets3in a manner similar to [26]:
(i) we remove all the interaction records with implicit negative
feedback; (ii) for duplicated (user, item, behavior set) tuples in a
sequence, we only keep the earliest records; (iii) we exclude thecold-start items with less than 5 interactions under target behavior
setsfor both QK-Video and QK-Article; (iv) we delete the user se-
quences with fewer than 5 interactions under target behavior sets ;
(v) for each user, we take the last two interactions under target be-
havior sets for validation and test. The interactions between these
two are kept for test, while those before the penultimate interac-
tion for training; and (vi) we remove the cold-start items in the
validation and test sets that do not appear in the training set. The
statistical details of the processed datasets are shown in Table 3.
A.4 Baselines*
Sequential Recommendation. (1)SASRec [19]servesasastrong
baseline model, introducing self-attention to capture transition re-
lationship between items. (2) ICLRec [6] captures users’ latent in-
tentions by clustering sequential representations. It constructs an
intent-contrasttaskandasequence-augmentedcontrastivetaskin
a self-supervised learning manner for SR. (3) DuoRec [27] pro-
poses model-level and semantic-level contrastive enhancement to
alleviate the degradation issue of representations.
Multi-Behavior Sequential Recommendation. (4)MGNN-SPred
[34]isaGNN-basedMBSRmodelthatconstructsamulti-relational
item graph on auxiliary and target behavior sequences. Finally,
it integrates the representations through a gating mechanism. (5)
MGNN-SPred†is a simplified version for MGNN-SPred in the
aggregationprocess,whereeachspecificbehavioraggregatesonly
withneighborsinvolvedinthesamebehavior-forwardorbehavior-
backward interactions. (6) MBHT [41] is a framework that com-
binesTransformerandGNNtechniques,inwhichmulti-scaleTrans-
formerjointlyencodesbehavior-awaresequentialpatternsatboth
fine-grainedandcoarse-grainedlevels.Theconstructedhypergraph
isprimarilyutilizedforcapturingglobaldependenciesamongmul-
tiple behaviors. (7) MB-STR [42] is a Transformer-based method
that utilizes BERT as its backbone model. It considers behavior-
specific semantics and fine-grained heterogeneous dependencies,
assigning separate weight parameters for each pairwise combina-
tion of behavior types. Meanwhile, it discards the commonly used
positional encoding and designs a heuristic bucketing mechanism
for relative position encoding. Finally, it applies the MMoE mecha-
nismtoitspredictionmodule.(8) NextIP [26]isalsoaTransformer-
basedmodelthatdividestheproblemintotwosubtasks:next-item
prediction and purchase prediction, where the first task extracts
differentcontextinformationfrombehavior-specificsequencesand
behavior-agnostic sequences. The second task focuses on learning
the user’s purchase preferences. (9) DyMuS [7] employs gated re-
current units (GRU) to encode each behavioral sequence, dynami-
callyintegratingtherequiredinformationthroughadynamicrout-
ing algorithm from candidates. (10) DyMuS+is an enhanced ver-
sion of DyMuS , where the dynamic GRU constructs its internal
hiddenstatesascapsulestofurthercaptureitem-levelcorrelations.
3https://drive.google.com/file/d/1R1JhdT9CHzT3qBJODz09pVpHMzShcQ7a/
view?usp=sharing
A.5
Adjustments
Based on the total occurrences of each specific behavior type, we
retain only the behavior with the highest preference intensity in
the behavior set for all the MBSR methods, i.e., (e.g., followon
 
339KDD’24, August 25–29, 2024, Barcelona, Spain Ming Chen, Weike Pan, and Zhong Ming
Figur
e 7: Performance comparison of SAB and L-MSAB on
all metrics across two datasets under the same hyperparam-
eter settings.
Figur
e 8: Performance comparison of EIDP using different
masks (BSBM vs. EEM) in UB-FEEL on two datasets.
Table 3: Statistics of the two processed datasets.
Dataset QK
-Video QK
-Article
#
Users 5,081 5,081
#
Items 20,494 13,788
#
InteractionsClick 104,114 -
Read - 251,033
Like 76,429 81,506
Shar
e 6,628 33,791
Fav
orite - 23,439
Follo
w 4,840 3,405
#
Total 150,396 252,069
A
verage Length 26.27 45.05
Density 0.14% 0.36%
Behavior
Types{
click, like,
share, follow}{r
ead, like, share,
favorite, follow}
QK
-Video) for the least frequent behavior, we consider it to rep-
resent the highest preference intensity. Thus, we transform the
BSSR problem setting into MBSR. Moreover, we have made cor-
responding adjustments for the following certain methods: (1) For
MGNN-SPred [34], we sum the behavior-specific representations
thatusedingatingintegrationbasedon auxiliary andtarget behav-
iorsdefined in Section 4.1.1. (2) For NextIP [26], we also modify
the definition of the contrastive loss function in Eq.(16) from the
original paper, considering the differences in the setting of auxil-
iaryandtarget behaviors defined in Section 4.1.1.A.6 Implementation Details*
We use the codes released by the authors for SASRec4, ICLRec5,
DuoRec6,MGNN-SPred7,MBHT8,MB-STR9,NextIP10andDyMuS11.
For DuoRec, MBHT, MB-STR and DyMuS, we follow the training
sample constructions and training approaches outlined in the au-
thors’ source codes. Particularly, for MBHT, we adjust the multi-
scalesettingparameters (𝐶, 𝑝1, 𝑝2)from([20,4,20],[20,8,40],[40,4,20],
[40,8,40]) to ([10,2,10], [10,5,25], [25,2,10], [25,5,25]), since we set
the sequence length as 50 instead of 200. For the remaining mod-
els, we construct training samples and perform training, follow-
ing the implementation of SASRec4. For most MBSR methods, we
optimize them with binary cross-entropy loss function, except for
MB-STR and DyMuS (as this would result in catastrophic perfor-
mance degradation). We set the training batch size to 1280, except
forICLRec,whereweretainthesourcecodesetting(asweobserve
thepoorerrecommendationperformancewithabatchsizeof1280).
We use the Adam optimizer with a learning rate of 0.001 for opti-
mization. To ensure the reliability of the experimental results, all
the reported results are the mean values obtained from five execu-
tions with different random seeds.
4https://github
.com/pmixer/SASRec.pytorch
5https://github.com/salesforce/ICLRec
6https://github.com/RuihongQiu/DuoRec
7https://github.com/Autumn945/MGNN-SPred
8https://github.com/yuh-yang/MBHT-KDD22
9https://github.com/yuanenming/mb-str
10https://csse.szu.edu.cn/staff/panwk/publications/Code-NextIP.zip
11https://github.com/Junsu-Cho/DyMuS
A.7 Exploratory Study*
Inadditiontothereportedresultsinthemaincontext,wealsocon-
ductvariantstudiesonthefollowingcomponentsasasupplement.
A.7.1 Encoder (L-MSAB). To validate the rationale behind intro-
ducingthePSAmechanism,wecompareitsperformancewithstacked
self-attentionblocksunderthesamehyperparametersettingsacross
twodatasets.Figure7illustratesourexperimentalresults,showing
that L-MSAB outperforms SAB on all the metrics on both datasets.
ThisindicatestheapplicabilityofL-MSABasanencoderindiverse
scenarios. The effectiveness of the PSA mechanism reveals that,
in evolving recommendation scenarios, focusing on dominant dot
products is crucial for obtaining robust representations.
A.7.2 Embedding Enhancement Mask (UB-FEEL). In the UB-FEEL
of IMP, we apply an embedding enhancement mask (i.e., EEM)
for representation scaling, distinguishing from the conventional
approach (behavior-specific binary mask, BSBM) of filling inter-
actions with zero vectors for non-specific behaviors [14, 26]. To
compare the performance differences between these two designs,
wereporttheperformancemetricsunderthesetwosettingsacross
twodatasetsinFigure8.EEMshowssomeimprovementcompared
to the conventional BSBM in both scenarios, with more noticeable
enhancement on QK-Article. This to some extent indicates the im-
portance of preserving the coherence of the original sequential in-
teractions and the intrinsic semantics of the behavior sets in user
preference modeling.
 
340