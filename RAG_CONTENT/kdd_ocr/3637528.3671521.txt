On Finding Bi-objective Pareto-optimal Fraud Prevention Rule
Sets for Fintech Applications
Chengyao Wen
Ant Group
Chengdu, China
wenchengyao.wcy@antgroup.comYin Lou
Ant Group
Sunnyvale, CA, USA
yin.lou@antgroup.com
Abstract
Rules are widely used in Fintech institutions to make fraud preven-
tion decisions, since rules are highly interpretable thanks to their
intuitive if-then structure. In practice, a two-stage framework of
fraud prevention decision rule set mining is usually employed in
large Fintech institutions; Stage 1 generates a potentially large pool
of rules and Stage 2 aims to produce a refined rule subset according
to some criteria (typically based on precision and recall). This paper
focuses on improving the flexibility and efficacy of this two-stage
framework, and is concerned with finding high-quality rule subsets
in a bi-objective space (such as precision and recall). To this end, we
first introduce a novel algorithm called SpectralRules that directly
generates a compact pool of rules in Stage 1 with high diversity. We
empirically find such diversity improves the quality of the final rule
subset. In addition, we introduce an intermediate stage between
Stage 1 and 2 that adopts the concept of Pareto optimality and aims
to find a set of non-dominated rule subsets, which constitutes a
Pareto front. This intermediate stage greatly simplifies the selection
criteria and increases the flexibility of Stage 2. For this intermediate
stage, we propose a heuristic-based framework called PORS and we
identify that the core of PORS is the problem of solution selection
on the front (SSF). We provide a systematic categorization of the
SSF problem and a thorough empirical evaluation of various SSF
methods on both public and proprietary datasets. On two real ap-
plication scenarios within Alipay, we demonstrate the advantages
of our proposed methodology over existing work.
CCS Concepts
‚Ä¢Computing methodologies ‚ÜíRule learning .
Keywords
multi-objective optimization, Pareto front, rule subset selection
ACM Reference Format:
Chengyao Wen and Yin Lou. 2024. On Finding Bi-objective Pareto-optimal
Fraud Prevention Rule Sets for Fintech Applications. In Proceedings of the
30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ‚Äô24), August 25‚Äì29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
10 pages. https://doi.org/10.1145/3637528.3671521
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.36715211 Introduction
Fraud prevention is an important task in Fintech applications. Fraud-
ulent activities usually include identity theft, money laundering,
fraudulent payment transactions, etc. Whenever a fraud is commit-
ted, the loss is not only incurred by the victim who is exploited, but
the reputation of the financial institution involved also takes a hit.
In many Fintech fraud prevention applications, interpretabil-
ity is usually a must-have requirement in addition to predictive
accuracy. Therefore, rule-based models are widely used for such
applications to make fraud prevention decisions [ 16], since rules
can offer intuitive representation of knowledge, thanks to their
simple if-then structure. In practice, decision rule sets (also known
as disjunctive normal form) are often favored over decision rule list
due to their flatter representation [ 13,16]; rule set models make
positive prediction for a transaction whenever any rule in the set
is satisfied. During any stage in a transaction, whenever an alert is
made from the rule set (at least one rule predicts positive on this
transaction), the transaction is interrupted and the user may be
asked to submit additional information to verify the legitimacy for
this transaction.
In practice, a two-stage framework of rule set mining is com-
monly employed in Fintech institutions (e.g., Alipay1) [16]. In Stage
1, a potentially large pool of rules is generated. Stage 2 aims to
produce a refined rule subset according to some criteria (typically
based on precision and recall). Note that in this paper we use rule
set to refer to rules generated by Stage 1 and rule subset to refer to
a refined subset of the initial pool of rules after Stage 1.
The state-of-the-art approach to Fintech fraud prevention appli-
cations employs tree ensemble in Stage 1 [ 16]. We empirically find
such tree-based approach can lead to unnecessarily large pool of
‚Äúhomogeneous‚Äù rules (in terms of precision and recall) in Stage 1
(See Section 5.3.1), which subsequently hurts both the efficiency and
the quality of the refined rule subset for Stage 2. As noted in [ 16],
various filters are needed to reduce the number of rules produced
in this stage for better efficiency and effectiveness. Therefore, in
this paper we first propose a novel algorithm called SpectralRules
that directly generates a compact pool of rules in Stage 1 with high
diversity (of different levels of precision and recall). By design, Spec-
tralRules generates a much smaller rule set (with no post-filtering
needed) in Stage 1 with highly diversified rules, and benefits Stage
2 accordingly with final rule subsets of higher quality.
For finding the rule subset in Stage 2, they are usually evaluated
by precision and recall [ 16]. Precision in our context is negatively
correlated with the frequency that a user experiences an interrup-
tion for a transaction, and recall relates to the amount of fraudulent
activities that can be prevented for a financial institution. Note
1https://www.alipay.com/
5959
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Chengyao Wen and Yin Lou
that these two objectives naturally conflict with each other, and in
practice one either seeks to maximize recall constrained on some
precision threshold [ 16], or combines the two metrics into a single
generalized ùêπscore that can balance the effects of the two objec-
tives.ùêπscore uses a parameter ùõΩto control the contribution of the
two inputs; ùõΩis chosen such that recall is considered ùõΩtimes as
important as precision [ 23]. A largeùõΩweighs recall higher than
precision and a small ùõΩis more biased towards precision. For fraud
prevention problems in Fintech applications, typically a small ùõΩis
used to give more weights on precision, since usually the fraudulent
ratio is low.
In practice, however, rule mining is an explorative and itera-
tiveprocess, and one rarely knows beforehand the best constraint
threshold or ùõΩfor a particular problem. For example, one might
have to experiment multiple precision thresholds and choose a
rule subset according to subjective preferences or domain knowl-
edge [ 16]. In such cases, multiple trials of the rule subset selection
algorithm (Stage 2) are necessary, which is both time consuming
and human labor intensive. Therefore, in this work we aim to find a
set of Pareto-optimal solutions all at once in a bi-objective space of
precision and recall, i.e., rule subsets in which one objective cannot
be improved without worsening the other one. A solution (rule sub-
set) Pareto-dominates another one if both its precision and recall
are no worse and at least one is strictly better. The image of this
non-dominated solution set in the objective space is the so-called
Pareto front.
Finding Pareto-optimal rule subsets can be viewed as an interme-
diate stage between Stage 1 and Stage 2. It takes the initial pool of
rules from Stage 1 and generates a set of non-dominated rule subsets.
Finally, one can easily experiment different precision thresholds
orùõΩon the (already generated) Pareto-optimal solution set and
choose one as the final output for Stage 2. For example, if the goal
is to maximize recall constrained on precision ‚â•0.9, one can simply
filter all Pareto-optimal solutions whose precision is lower than 0.9
and choose the one with the highest recall, and therefore avoids
the need to experiment multiple precision thresholds and greatly
increases the flexibility for Stage 2.
The hypervolume indicator (HV) is one of the most widely used
evaluation metric for the quality of a Pareto front [ 15]. It measures
the ‚Äúsize of the dominated space‚Äù [ 26], and our goal for this paper
is to find Pareto front of large HV. In this work, we mainly focus
on a bi-objective space of precision and recall, and measure the
dominated space referenced by (0, 0) (See Figure 1 for a visual
example). Each solution on a Pareto front forms a rule subset.
This problem can be solved by standard evolutionary multi-
objective optimization (EMO) algorithms, since bi-objective opti-
mization is just a special case [ 14,22]. Popular EMO algorithms
include NSGA-II [ 11], MOEA/D [ 25], etc. However, we empirically
find EMO algorithms are not very efficient on our problem.
In this work, we propose a heuristic-based framework called
PORS of finding Pareto-optimal solutions for rule subset selection
problem. PORS iteratively ‚Äúexpands‚Äù the Pareto front by adding
one rule to a solution (rule subset) on the front to see whether it
expands the front (and thereby improves HV), and it terminates
when no expansion of the current front can move the needle. Due
to the combinatorial nature of this problem, it is computationally
prohibitive to enumerate all rule subsets on the current Pareto front,Sampling Space Method
UniformObjectiveequi-spaced [18]
equi-dist (this paper)
Non-objective equi-jaccard (this paper)
Non-
uniformObjectivehv-ss [8]
igd-ss [8]
igd+-ss [8]
hvc-ss (this paper)
k-medoids-pr [7]
Non-objective k-medoids-jaccard (this paper)
Table 1: Categorization of SSF methods.
and therefore we only select a set of representative solutions on
the current front as candidates for expansion to avoid exponential
growth. We refer to this problem as solution selection on the front
(SSF).
A closely related problem of SSF is the so-called subset selection
of Pareto-optimal solutions, the goal of which is to reduce the num-
ber of solutions on a Pareto front to a user specified number while
achieving some desired properties (e.g., a high HV approximation
of the original Pareto front). Popular methods of Pareto subset se-
lection include HV-SS [ 8], IGD/IGD+-SS [ 8], etc. Our motivation is
different in that we are interested in finding a small set of promising
solutions to expand on the current front so as to achieve a high
HV when PORS terminates. We can, nevertheless, employ existing
algorithms in PORS framework.
Since finding a small set of the most promising solutions to
expand on the current front is at the core of PORS framework, as
one of our contributions, we propose a systematic categorization
of solutions to this problem, map existing methods into different
categories, and conduct a thorough empirical evaluation of methods
in each category for SSF problem to study their effects on the quality
of final Pareto front. If we think of the front as a ‚Äúcurve‚Äù in some
space, we can broadly classify methods into two categories; uniform
or non-uniform sampling on the ‚Äúcurve.‚Äù The space could be the
objective space (such as bi-objective space of precision and recall
considered in this paper) which is usually a coordinate system,
or non-objective space (and therefore potentially non-coordinate
system) where only distance metric of two rule subsets is defined
(e.g., Jaccard distance between two rule subsets). Table 1 summarizes
existing methods and the methods proposed in this paper into each
category.
Although there are benchmark studies on subset selection of
Pareto-optimal solutions in the context of EMO [ 21], there is little
research of finding Pareto-optimal rule subsets; neither EMO-based
methods nor the greedy heuristic-based approaches considered in
this paper. Due to the combinatorial nature of rule set selection,
we believe our work provides a valuable piece of research in this
area. Our empirical study on both public datasets and proprietary
datasets from Alipay reveals that the proposed hvc-ss is the best
SSF method, which achieves highest HV on almost all cases.
Finally, we empirically demonstrate the positive correlation be-
tween HV and the final objective for evaluating the quality of rule
subsets through two case studies and one online experiment, and
5960On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
show that by optimizing HV, the quality of the refined rule subsets
does improve accordingly.
In summary, we make the following contributions in this paper.
‚Ä¢We propose a novel variant of the sequential covering algo-
rithm called SpectralRules that directly generates a compact
pool of rules with high diversity, and demonstrate on both
public and proprietary datasets that SpectralRules improves
HV over existing tree-based approaches [16] for Stage 1.
‚Ä¢We propose a heuristic-based framework called PORS for
finding Pareto-optimal rule subsets in a bi-objective space
as an intermediate stage between Stage 1 and Stage 2. At the
core of this framework is the SSF problem.
‚Ä¢We provide a systematic categorization of the SSF problem
and a thorough empirical evaluation of various SSF methods
on both public and proprietary datasets. We find that the
proposed hvc-ss is the best method for our problem.
‚Ä¢We present two case studies and one online experiment of
using PORS in this paper to produce fraud prevention rule
subsets for applications inside Alipay, and demonstrate the
advantages of our methodology compared to existing work.
‚Ä¢We deploy our method proposed in this paper in our internal
Fanglue system [ 19], and release a repository of code that
can fully reproduce our results on public datasets in this
study to promote research efforts in this area [1].
The rest of this paper is organized as follows. Section 2 presents
related work. We present preliminaries in Section 3. Our approach
is discussed in Section 4. Experimental results are presented in
Section 5 and we conclude the paper in Section 6.
2 Related Work
2.1 Rule Set Mining
There are generally two classes of approaches to generating rule
sets. Tree based approaches, such as decision tree [ 6,20] or random
forests [ 5], extract rules for each path in the tree or tree ensemble.
The other class of approaches focuses on direct rule induction to
form rule sets. Popular methods of this category include sequential
covering [ 17] (e.g., CN2 [ 9] and RIPPER [ 10]) and association rule
mining [ 2]. Recently there is another line of research that focuses
on the diversity of rule sets [13, 24].
In practice, a two-stage framework of rule set mining is used in
Fintech institutions such as Alipay [ 16]. A variant of tree ensemble
is employed to generate an initial rule set (Stage 1), followed by a
rule subset selection procedure that produces a refined rule subset
according to some criteria (Stage 2). Stage 1 in [ 16] initially gener-
ates a large pool of rules, and therefore various filters are needed to
reduce the number of rules for better efficiency and effectiveness.
In addition, since Stage 2 directly produces a refined rule subset,
multiple trials of Stage 2 are necessary as one rarely knows the
selection criteria beforehand, which is both time consuming and
human labor intensive.
2.2 Evolutionary Multi-objective Optimization
The evolutionary multi-objective optimization (EMO) algorithm
is a popular choice for solving multi-objective optimization prob-
lems [ 14,22]. EMO algorithms can be roughly classified into threecategories; dominance-based approach, decomposition-based ap-
proach and indicator-based approach. Dominance based EMO algo-
rithms commonly use Pareto dominance relationship and distance-
based density estimation in the objective space for offspring gener-
ation and environmental selections. NSGA-II [11] and SPEA2 [27]
are well-known and widely used dominance based EMO algo-
rithms, which are believed to be very suitable for problems under
4 objectives [ 22]. Decomposition based approach decomposes a
given multi-objective problem into single-objective sub-problems.
MOEA/D is a representative decomposition based EMO algorithm [ 25].
Indicator based approaches employ a quantity indicator to evaluate
or rank solutions. Popular approaches in this category include SMS-
EMOA [ 4], HypE [ 3], etc. EMO algorithms are, however, typically
inefficient on large problems. This paper employs a heuristic-based
approach that achieves higher efficiency with better Pareto fronts.
2.3 Subset Selection of Pareto-optimal Solutions
Since the number of Pareto-optimal solutions can be very large for
combinatorial optimization problems and infinity for continuous
optimization problems, subset selection of Pareto-optimal solutions
is usually an essential step. It is regarded as one of the most impor-
tant topics in EMO domain, since it is involved in many phases of
EMO algorithms [ 7,8]. It is also studied in the context of discrete
approximation to the Pareto front for continuous optimization prob-
lems [ 18]. Some previous studies favor uniform sampling of the
Pareto front [ 18] while others favor non-uniform sampling [ 7,8,12].
In this work, we employ existing algorithms as SSF methods in
our PORS framework and further extend this categorization into
4 categories as listed in Table 1, which is not revealed in existing
literature. Under this view, we present 4 new methods (one for each
category) and perform a thorough empirical evaluation on both
public and proprietary datasets in the context of fraud prevention
rule set mining for Fintech applications.
3 Preliminaries
LetD={(ùíôùëñ,ùë¶ùëñ)}ùëÅ
ùëñ=1denote a dataset of size ùëÅ, where ùíôùëñ=(ùë•ùëñ1,...,
ùë•ùëñùëù)is a feature vector with ùëùfeatures for a transaction, and ùë¶ùëñ‚àà
{0,1}indicates whether the corresponding transaction is reported
fraud or not. We use P={ùëñ|ùë¶ùëñ=1}to denote the set of points with
positive labels. We use ùõø=|P|/ùëÅto denote the positive ratio of D.
A ruleùëühas two parts; a conjunction of conditions and a pre-
diction. A condition is of the form (feature, operator, value), e.g.,
age > 50. A rule makes a certain prediction when all conditions are
satisfied for a given ùíôùëñ. In this case, we say the rule covers ùíôùëñ. Since
typically the positive ratio ùõøfor fraud in Fintech applications is very
low, we only consider positive-class rules. Hence, ùëü(ùíôùëñ)=1iffùëü
covers ùíôùëñ. A rule setRmakes a positive prediction on ùíôùëñif there ex-
ists a ruleùëü‚ààRsuch thatùëü(ùíôùëñ)=1. We useD(R) ={ùëñ|R(ùíôùëñ)=1}
to denote the set of data points covered by R.
Definition 3.1 (Precision). We define the precision of a rule set R
as the percentage that Rcorrectly finds a fraud,
Prec(R)=|D(R)‚à©P|/|D(R)| . (1)
Definition 3.2 (Recall). We define the recall of a rule set Ras the
ratio of the frauds covered by Ramong all fraudulent transactions,
Rec(R)=|D(R)‚à©P|/|P| . (2)
5961KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Chengyao Wen and Yin Lou
Precision
Recall (0,0)
Figure 1: Illustration of Pareto dominance. A set of 5 non-
dominated solutions (green square) constitutes the Pareto
front (red line). Hypervolume of those 5 solutions is the size
of the light yellow region. The hypervolume contribution of
the solution (red square) to those 5 solutions is the size of
the light grey region.
Definition 3.3 ( ùêπùõΩscore). The general form of ùêπùõΩscore for preci-
sion and recall is defined as,
ùêπùõΩ=(1+ùõΩ2)(precision√órecall)/((ùõΩ2√óprecision)+ recall).(3)
A largeùõΩweighs recall higher than precision, and a small ùõΩ
weighs precision higher than recall. For fraud prevention problems
in Fintech applications, typically a small ùõΩis used to give more
weights on precision, since usually the positive (fraudulent) ratio is
low.
For Stage 2, given an initial rule set R, we mainly aim to find high-
quality rule subsets of Rin this bi-objective space of precision and
recall.2To this end, we introduce the concept of Pareto dominance.
Definition 3.4 (Pareto Dominance). A rule subsetR1is Pareto-
dominated by another rule subset R2ifPrec(R1)‚â§ Prec(R2)‚àß
Rec(R1)‚â§Rec(R2)with at least one objective dimension (preci-
sion or recall) is strictly better. Under the context of Pareto domi-
nance, we use rule subset and solution interchangeably.
Definition 3.5 (Pareto Optimality). A set of solutions (rule subsets)
is called Pareto-optimal if no solution Pareto-dominates another.
Definition 3.6 (Hypervolume Indicator). Given a solution set S
in a bi-objective space, the hypervolume indicator HV (S)is the
measure of region dominated by S, referenced by (0, 0).
Note that Pareto optimality only defines the situation where
no solution can Pareto-dominate another within a solution set.
One can, nevertheless, compare two sets of solutions that are both
Pareto-optimal (via HV).
Definition 3.7 (Hypervolume Contribution). Given two solution
setsSandTin a bi-objective space of precision and recall, the
hypervolume contribution of TtoSreferenced by (0, 0) is,
HVC(T,S)=HV(T‚à™S)‚àí HV(S\T). (4)
Figure 1 illustrates a set of 5 non-dominated solutions (green
square) in a precision-recall space, which constitutes the Pareto
front (red line). Hypervolume of those 5 solutions is the size of
the light yellow region. The HVC of a new solution (red square) to
those 5 solutions is the size of the light grey region.
2Nevertheless, our methodology can be easily extended to metrics other than precision
and recall.Algorithm 1 Sequential Covering
1:procedure SeqentialCovering( D,ùëõ,ùëôùëíùëõ,ùõΩ)
2:R‚Üê‚àÖ
3:D‚Ä≤‚ÜêD
4: forùëñ=1toùëõdo
5:ùëü‚ÜêRuleInduction(ùëôùëíùëõ,ùõΩ,D‚Ä≤)
6:D‚Ä≤‚ÜêD‚Ä≤\{ùíô|ùëücovers ùíô,ùíô‚ààD‚Ä≤}
7:R‚ÜêR‚à™{ùëü}
returnR
Algorithm 2 SpectralRules
1:procedure SpectralRules(D,ùëõ,ùëôùëíùëõ,B)
2:R‚Üê‚àÖ
3: forùõΩ‚ààBdo
4:R‚ÜêR‚à™ SeqentialCovering (D,l
ùëõ
|B|m
,ùëôùëíùëõ,ùõΩ)
returnR
4 Our Approach
In this section, we describe our methodology under the two-stage
framework. We first introduce a novel algorithm called Spectral-
Rules that generates a compact initial pool of rules Rwith high
diversity for Stage 1 in Section 4.1. Given a rule set R, we present a
heuristic-based framework called PORS that iteratively ‚Äúexpands‚Äù
the Pareto front in Section 4.2 for finding high-quality rule subsets.
We identify solution selection on the front (SSF) as the core prob-
lem of this framework, and provide a systematic categorization of
this problem. In Section 4.3, we map existing work into different
categories, and present new methods in each category.
4.1 SpectralRules
The quality of initial rule set from Stage 1 can largely impact the
efficiency and efficacy of the rule subset selection. [ 16] employs
a variant of tree ensemble to extract the initial rule set, which
may generate an unnecessarily large set of ‚Äúhomogeneous‚Äù rules
that look alike each other in terms of precision and recall (See
Section 5.3.1 for details). As noted in [ 16], various filters are needed
to reduce the number of rules produced in this stage for better
efficiency and effectiveness. Therefore, we introduce a novel variant
of sequential covering algorithm called SpectralRules that promotes
the diversity of the initial pool of rules for Stage 1. By design,
SpectralRules directly generates a much smaller rule set (with no
post-filtering needed) in Stage 1 with high diversity, and benefits
Stage 2 accordingly with final rule subsets of higher quality.
We first review the classic sequential covering algorithm (SCA).
SCA is a ‚Äúseparate-and-conquer‚Äù procedure that repeatedly learns
a single rule to form a rule set that covers the entire dataset rule
by rule [ 13]. Algorithm 1 summarizes the sequential covering algo-
rithm. We start with empty rule set Rand whole dataset D(Line
2-3). We iteratively learn a rule ùëüusing standard rule induction
procedure that employs ùêπùõΩas the evaluation metric to grow a rule
up to a pre-specified length ùëôùëíùëõ, and then remove all points covered
byùëüfrom the remaining dataset, until we find ùëõrules (Line 4-7).
A very small ùõΩ(such as 0.1) can be used to focus on mining high
precision rules. However, recall of the rules produced by SCA might
5962On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
be quite limited. As a result, we may end up with many rules of high
precision and low recall, leading to a suboptimal rule set. To this
end, we propose SpectralRules to encourage the diversity among
rules (i.e., rules with different levels of precision and recall). This
is achieved through multiple trials of Algorithm 1 with ùõΩranging
from small number (such as 0.01) to large number (such as 1).
Algorithm 2 summarizes the SpectralRules procedure. We are
given a setBwith multiple ùõΩ‚Äôs. For each ùõΩ‚àà B , we run Al-
gorithm 1 with this specific ùõΩto generate at mostl
ùëõ
|B|m
rules
(Line 3-4). The resulting rule set Ris composed of rules with
different levels of precision and recall. In this paper, we fix B=
{0.01,0.02,0.04,0.06,0.08,0.10,0.20,0.40,0.60,0.80}. As we will see
in our experiments, SpectralRules usually leads to Pareto fronts
with higher HV (Section 5.2), and benefits Stage 2 accordingly with
final rule subsets of higher quality (Section 5.4).
4.2 The PORS Framework
Given an initial rule set Rfrom Stage 1, PORS iteratively ‚Äúexpands‚Äù
the current Pareto front by adding one rule to a solution (rule subset)
on the front to form a new set of solutions. Due to the combinatorial
nature of this problem, na√Øve implementation takes ùëÇ(|R|ùëõ+ùëê)time
for theùëõ-th iteration (where ùëêdenotes the complexity of computing
Pareto front on the newly formed set of solutions), it is computa-
tionally prohibitive to enumerate all rule subsets on the current
Pareto front, and therefore we aim to select a set of representative
solutions on the current front as candidates for expansion. We call
this problem as solution selection on the front (SSF).
Algorithm 3 summarizes the PORS framework. PORS starts with
singleton sets for each rule in R, and then makes them a Pareto front
viamakePF procedure by retaining only non-dominated solutions
(Line 1). PORS applies some SSFmethod to sample ùëòsolutions on the
current front in order to avoid exponential growth (Line 5). Those
ùëòsolutions are then expanded by adding one rule from the initial
pool of rulesRto form new solutions (Line 6-10). The expanded
solutions are then put together with the solutions from last front to
form a new Pareto front by retaining only non-dominated solutions
(Line 11). The framework terminates when the current Pareto front
does not change after expansion (Line 12), otherwise the current
front is ready for the next iteration (Line 13).
The time complexity per iteration of PORS now becomes ùëÇ(ùëò|R|+
ùëê), which is much more computationally affordable compared to
naive implementation. In addition, we empirically found all SSF
methods are very efficient for different values of ùëò(Appendix A).
It is obvious that the performance of PORS is largely affected by
the efficacy of the SSF method, and therefore we discuss different
candidate SSF methods in the next section.
4.3 SSF Methods
We broadly classify SSF methods into two categories; uniform or
non-uniform sampling on the ‚Äúcurve‚Äù of a Pareto front. Under each
category, we identify two sub-categories depending on whether
the ‚Äúdistance measure‚Äù is in the original objective space or not.
4.3.1 Uniform Sampling. We first discuss methods by uniform sam-
pling in the objective space. We consider two methods as follows.Algorithm 3 The Pareto Optimal Rule Subset Selection Framework
1:F‚Üê makePF({{ùëü}|ùëü‚ààR})
2:converged‚Üêfalse
3:while not converged do
4: converged‚Üêtrue
5:F0‚ÜêSSF(F,ùëò)
6:F‚Ä≤‚Üê‚àÖ
7: forùëÜ‚ààF 0do
8: forùëü‚ààRdo
9: ùëÜ‚Ä≤‚ÜêùëÜ‚à™{ùëü}
10:F‚Ä≤‚ÜêF‚Ä≤‚à™{ùëÜ‚Ä≤}
11:F‚Ä≤‚ÜêmakePF(F‚Ä≤‚à™F)
12: converged‚ÜêF‚Ä≤==F
13:F‚ÜêF‚Ä≤
returnF
‚Ä¢equi-spaced [18]. [18] considers uniform sampling of the
Pareto front in the objective space on continuous problems.
In our problem, it is equivalent to uniform sampling of ùëò
solutions by walking along a Pareto front curve with roughly
the same Manhattan distance for two consecutive samples.
‚Ä¢equi-dist . Following the same idea, we propose uniform
sampling of ùëòsolutions on a Pareto front with roughly the
same Euclidean distance for two consecutive samples.
The main difference between these two methods is whether the
distance is measured on curve (Manhattan) or not (Euclidean).
We now describe a method called equi-jaccard that performs
uniform sampling in non-objective space. We employ Jaccard dis-
tance to measure the dissimilarity between the coverage of two
rule subsets. Formally, for two rule subsets R1andR2, their Jaccard
distance is defined as Jaccard(R1,R2)=1‚àí|D(R 1)‚à©D(R 2)|
|D(R 1)‚à™D(R 2)|.
Since this is a non-coordinate system, we think of all solutions
on a Pareto front as a clique where edges between two solutions are
weighed by their Jaccard distance. Now we can generate a traversal
of all solutions on this graph to form a ‚Äúcurve‚Äù in this space, and
then apply the same idea of equi-spaced so that Jaccard distance
is roughly the same for two consecutive samples. There are many
ways to perform a traversal. We can perform depth-first search on
this graph to minimize/maximize the Jaccard distance of the overall
path. We can also search for minimum sum of Jaccard distance
of the traversal using the travelling salesperson (TSP) algorithm.3
During our early investigation, we found that different methods
lead to the final Pareto fronts of similar HV. Therefore, we only
report results of equi-jaccard on a traversal generated by TSP
algorithm.
4.3.2 Non-uniform Sampling. We consider the following methods
of non-uniform sampling in the objective space.
‚Ä¢hv-ss [8].hv-ss aims to select ùëòsolutions so that their
hypervolume is maximized.
‚Ä¢igd/igd+-ss [8].igd/igd+-ss aims to select ùëòsolutions so
that their Inverted Generational Distance (IGD) or Inverted
Generational Distance plus (IGD+) is minimized.
3TSP generates a loop with minimized overall distance. We cut the edge with the
largest Jaccard distance on the loop to form a traversal path.
5963KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Chengyao Wen and Yin Lou
Dataset Size Attributes Pos. Ratio
Default 30,000 24 22.12%
Credit 150,000 11 6.68%
Fraud 284,807 31 0.17%
Bank 45,211 17 11.70%
A1 6,609,266 731 ùõø1
A2 990,798 210 ùõø2
A3 9,837,541 176 ùõø3
Table 2: Datasets.
‚Ä¢hvc-ss . We propose in this work to select ùëòsolutions so
that their HVC to the last Pareto front is maximized. This is
achieved using a greedy forward stepwise approach.
‚Ä¢k-medoids-pr [7] (or k-med.-pr for short). This is the stan-
dardùëò-medoids clustering performed in the objective space,
with distance measured by Euclidean distance.
We also consider ùëò-medoids clustering performed on Jaccard
distance measure, and introduce a non-uniform sampling in non-
objective space method called k-medoids-jaccard (ork-med.-j.
for short).
Some of the aforementioned methods are studied in previous
research in the context of EMO on continuous problems [ 21], but
there is little research of all those 9 methods (covering 4 categories
of the SSF problem) for combinatorial problems of finding Pareto-
optimal rule subsets considered in this paper. To this end, we provide
a thorough evaluation of those 9 methods in Section 5.
5 Experiments
We report our results on both public datasets and proprietary
datasets from Alipay. We mainly compare our approach with [ 16]
under the same two-stage framework for the same application do-
main. Note that [ 16] directly outputs a refined rule subset according
to a given precision threshold (measured using the final objective,
i.e., the recall) while we aim to generate a set of non-dominated solu-
tions (to simplify the rule subset selection in Stage 2) and therefore
an intermediate metric HV is introduced. The experiments in this
section are designed with care to answer the following questions.
Q1 Whether SpectralRules and PORS improve HV?
Q2 Which SSF method achieves the highest HV in PORS?
Q3 Whether large HV suggests high quality (final objective) of
the refined rule subsets?
We release a repository of code that can fully reproduce the re-
sults (including tables and figures) in this section on public datasets [ 1].
5.1 Datasets
Table 2 summarizes the datasets used in our experiments. We use 4
public Fintech-related datasets in this paper. ‚ÄúDefault‚Äù and ‚ÄúBank‚Äù
are from the UCI repository.4‚ÄúCredit‚Äù is a binary classification
problem that predicts the probability that somebody will experi-
ence financial distress in the next two years.5‚ÄúFraud‚Äù is a Kaggle
competition problem that aims to recognize fraudulent credit card
transactions.6
4http://archive.ics.uci.edu/ml/
5https://www.kaggle.com/c/GiveMeSomeCredit/data
6https://www.kaggle.com/mlg-ulb/creditcardfraud‚ÄúA1‚Äù, ‚ÄúA2‚Äù and ‚ÄúA3‚Äù are three proprietary fraud prevention prob-
lems inside Alipay, representing three different fraudulent activities
such as fraudulent payment transactions, identity theft, etc. Those
datasets are large in scale and we do not reveal the positive ratio of
each proprietary dataset by using ùõøto symbolize the actual number.
5.2 Pareto-optimal Rule Subsets (Q1 & Q2)
We first conduct a thorough evaluation of finding Pareto-optimal
rule subsets. We consider the classic EMO algorithm NSGA-II [ 11]
which is believed to perform well for bi-objective optimization prob-
lems [ 22].7Following standard practice [ 8], we equip NSGA-II with
an unbounded external archive (UEA) to store all non-dominated so-
lutions examined during the execution of the algorithm. We found
that NSGA-II with UEA consistently achieves higher performance.
We set the parameter ùëöùë¢ùë°ùëéùë°ùëñùëúùëõ _ùëüùëéùë°ùëí to 0.02 andùëîùëíùëõùëíùëüùëéùë°ùëñùëúùëõùë† to 1000
while using default values for other parameters. We observe this pa-
rameter setup often achieves the best results for NSGA-II. For PORS
framework, we consider all SSF methods listed in Section 4.3 to
implement the framework. We use ùëò=10as the number of samples
for SSF, which is the only parameter to set for SSF methods.
We consider two candidates for generating the initial rule set in
Stage 1. We follow the same approach in [ 16] that uses a variant of
tree ensemble (called TreeEns), and compare that with SpectralRules
for generating the initial set of rules. For both methods, maximum
rule length is fixed to 6 and we generate (up to) 500 rules from each
method to form the initial rule set R(same setting as in [16]).8
We use hypervolume indicator (HV) to measure the quality of
Pareto-optimal rule subsets. For all experiments, we randomly par-
tition the dataset into training (60% of the data), validation (20%
of the data) and test sets (20% of the data). We generate the initial
rule set in Stage 1 using training set. We then apply our 9 PORS
algorithms and NSGA-II on the training set, select the best Pareto
front with highest HV on the validation set and collect its HV on
test set. All experiments are repeated 5 times and we report mean
and standard deviation of the evaluation results on test sets.
Table 3 and 4 shows the HV results on test set for each dataset
when the initial rule set is generated by TreeEns and SpectralRules,
respectively. We first observe that PORS with hvc-ss as its SSF
method consistently achieves the highest HV for both cases. There-
fore, we recommend implementing PORS framework with hvc-ss
as its SSF method, and we now refer to this particular combination
as the PORS algorithm. In addition, we also observe that employing
SpectralRules in Stage 1 leads to higher HV of the final Pareto front
by comparing the best values in Table 3 and 4.
Intuitive explanation of why hvc-ss performs the best.
PORS framework can be viewed as a greedy forward stagewise
algorithm, with maximizing HV as its objective, by iteratively ex-
panding Pareto fronts. Among all SSF methods, hvc-ss achieves the
largest HV increase (by definition) for each iteration (Pareto front
expansion), and therefore it should work well inside PORS frame-
work. Because of the greedy nature of the framework, other SSF
methods might also work well. Our empirical study complements
7We use pyMultiobjective package at https://github.com/Valdecy/pyMultiobjective.
We also experimented HypE [ 3] and MOEA/D [ 25] during our early investigation, but
we found NSGA-II is more efficient and achieves higher HV.
8For TreeEns, we first generate a large pool of rules and then apply the filter provided
in [16] to reduce the size of rule set to pre-specified number as the output of Stage 1.
5964On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Type Method Default Credit Fraud Bank A1 A2 A3
EMO NSGA-II [11] 0.524¬±0.013 0.322¬±0.023 0.786¬±0.027 0.533¬±0.018 0.296¬±0.010 0.169¬±0.006 0.032¬±0.006
unif.obj.equi-spaced [18] 0.515¬±0.008 0.323¬±0.021 0.783¬±0.020 0.517¬±0.020 0.299¬±0.011 0.172¬±0.006 0.033¬±0.006
equi-dist 0.517¬±0.010 0.324¬±0.022 0.786¬±0.021 0.528¬±0.014 0.298¬±0.010 0.173¬±0.006 0.034¬±0.006
non-obj. equi-jaccard 0.509¬±0.007 0.308¬±0.018 0.789¬±0.032 0.516¬±0.019 0.296¬±0.012 0.166¬±0.009 0.033¬±0.006
non-
unif.obj.hv-ss [8] 0.519¬±0.009 0.325¬±0.022 0.783¬±0.037 0.530¬±0.021 0.298¬±0.007 0.165¬±0.007 0.034¬±0.005
igd-ss [8] 0.496¬±0.012 0.297¬±0.023 0.790¬±0.038 0.499¬±0.021 0.297¬±0.012 0.163¬±0.006 0.031¬±0.007
igd+-ss [8] 0.491¬±0.010 0.281¬±0.018 0.789¬±0.031 0.480¬±0.025 0.289¬±0.011 0.147¬±0.008 0.027¬±0.004
hvc-ss 0.524¬±0.011 0.325¬±0.022 0.798¬±0.040 0.533¬±0.015 0.301¬±0.012 0.176¬±0.006 0.036¬±0.006
k-medoids-pr [7] 0.501¬±0.013 0.303¬±0.025 0.785¬±0.027 0.511¬±0.020 0.296¬±0.014 0.170¬±0.005 0.031¬±0.007
non-obj. k-medoids-jaccard 0.472¬±0.016 0.258¬±0.035 0.792¬±0.034 0.479¬±0.026 0.284¬±0.012 0.142¬±0.006 0.024¬±0.010
Table 3: The hypervolume (HV) performance (mean ¬±std) of the Pareto front for different methods on test set of each problem.
Higher HV is better and best method for each dataset is marked in bold. TreeEns [ 16] is employed in Stage 1 to produce the
initial 500 rules.
Type Method Default Credit Fraud Bank A1 A2 A3
EMO NSGA-II [11] 0.526¬±0.013 0.350¬±0.011 0.789¬±0.036 0.585¬±0.011 0.313¬±0.004 0.188¬±0.005 0.033¬±0.004
unif.obj.equi-spaced [18] 0.534¬±0.012 0.350¬±0.014 0.796¬±0.037 0.570¬±0.009 0.313¬±0.006 0.183¬±0.007 0.035¬±0.006
equi-dist 0.535¬±0.011 0.352¬±0.015 0.805¬±0.025 0.575¬±0.009 0.315¬±0.005 0.180¬±0.008 0.034¬±0.006
non-obj. equi-jaccard 0.535¬±0.014 0.357¬±0.014 0.803¬±0.028 0.577¬±0.013 0.314¬±0.009 0.176¬±0.008 0.034¬±0.007
non-
unif.obj.hv-ss [8] 0.534¬±0.011 0.357¬±0.016 0.801¬±0.033 0.582¬±0.008 0.318¬±0.004 0.184¬±0.006 0.035¬±0.005
igd-ss [8] 0.516¬±0.015 0.346¬±0.016 0.798¬±0.045 0.560¬±0.012 0.317¬±0.006 0.185¬±0.006 0.033¬±0.007
igd+-ss [8] 0.515¬±0.016 0.338¬±0.012 0.793¬±0.024 0.553¬±0.017 0.308¬±0.005 0.160¬±0.007 0.029¬±0.004
hvc-ss 0.540¬±0.012 0.359¬±0.013 0.808¬±0.030 0.593¬±0.012 0.319¬±0.006 0.192¬±0.007 0.036¬±0.005
k-medoids-pr [7] 0.515¬±0.013 0.343¬±0.014 0.801¬±0.033 0.563¬±0.009 0.317¬±0.004 0.184¬±0.005 0.033¬±0.006
non-obj. k-medoids-jaccard 0.507¬±0.016 0.333¬±0.011 0.791¬±0.030 0.521¬±0.014 0.301¬±0.011 0.151¬±0.006 0.028¬±0.008
Table 4: The hypervolume (HV) performance (mean ¬±std) of the Pareto front for different methods on test set of each problem.
Higher HV is better and best method for each dataset is marked in bold. SpectralRules is employed in Stage 1 to produce the
initial 500 rules.
100 200 500 1000 2000
Number of Rules0.40.50.60.7HVSpectralRules
TreeEns
Figure 2: HV of PORS algorithm on Bank dataset when using
SpectralRules or TreeEns to produce rule set in Stage 1.
the picture and shows hvc-ss indeed achieves the best results on
most cases.
5.3 Discussion
In this section, we provide more experimental results to shed light
on properties of different combinations of methods.
5.3.1 Comparison of SpectralRules and TreeEns (Stage 1). It is ap-
parent that the quality of the initial rule set Rfrom Stage 1 can
significantly impact the final Pareto front; it is impossible to find
high-quality rule subsets when some key rules are not present in
Rin the first place. Section 5.2 demonstrates that SpectralRules
outperforms TreeEns when the size of Ris set to 500. In this section,we provide further investigation on the effects of SpectralRules and
TreeEns when the size of Rvaries. In this experiment, we use PORS
algorithm as our method to find Pareto-optimal rule subsets.
Figure 2 illustrates the HV performance on Bank dataset when
the size ofRincreases. Results are aggregated over 5 trials of ran-
dom partitioning of the dataset. We observe that SpectralRules
outperforms TreeEns for all |R|‚â§ 500. SpectralRules cannot pro-
duce a rule set large enough to reach at size of 1000 since all positive
points are already covered. We also observe that even if we give
more budget on the number of rules to TreeEns, it cannot catch up
with the level of HV achieved by SpectralRules. Similar patterns
are observed on other datasets.
There exist some key differences between SpectralRules and
TreeEns. TreeEns extracts rules from a tree ensemble, and therefore
we expect that there are many ‚Äúhomogeneous‚Äù rules (in terms
of the distribution of precision and recall) that look alike each
other. This not only hurts the efficiency of the subsequent subset
selection (for there is now a large initial set to select from) but the
efficacy of Stage 2 also takes a hit. As noted in [ 16], various filters
are needed for TreeEns to reduce the number of rules produced
in this stage for better efficiency and effectiveness. On the other
hand, SpectralRules employs direct rule induction and focuses on
promoting the diversity of R, leading to a more compact rule set of
higher quality.
5965KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Chengyao Wen and Yin Lou
100101102103
Time (s)0.30.40.50.6HVPORS Train
PORS Valid
PORS T est
NSGA-II Train
NSGA-II Valid
NSGA-II T est
Figure 3: Efficiency of NSGA-II vs. PORS on Bank dataset.
On Bank dataset, for |R|=500, we observe the mean and stan-
dard deviation for precision (recall) of TreeEns and SpectralRules is
0.5461¬±0.1604 (0.0225¬±0.0330) and 0.6376¬±0.1823 (0.0381¬±0.0699),
respectively. We see that not only the mean of precision (recall)
from SpectralRules is higher, its standard deviation is larger as well;
SpectralRules does generate rule set with high diversity. Combined
with results in Section 5.2, we conclude that high diversity in Stage 1
improves HV. Hence, for the rest of this paper, we use SpectralRules
for Stage 1 by default unless otherwise mentioned.
5.3.2 Efficiency Evaluation for EMO and PORS Algorithm. From
Section 5.2 we observe that NSGA-II as an EMO algorithm is very
competitive to PORS algorithm. In this section, we conduct effi-
ciency evaluation for these two methods. We run both algorithms
on a standard server with 16GB memory using 4 threads.
Figure 3 shows how HV changes on train, validation and test
sets of Bank dataset over wall clock time for NSGA-II and PORS
algorithm. We can see that PORS algorithm quickly converges while
NSGA-II is less efficient. Similar patterns are observed on other
datasets. In particular, on our largest dataset ‚ÄúA3,‚Äù PORS only takes
146 seconds to finish while NSGA-II needs 1610 seconds on the same
server with 16GB using 4 threads. This suggests a heuristic-based
algorithm can be highly efficient.
5.4 Case Study (Q3)
In this section, we provide two case studies within Alipay where the
requirement of the final rule subset of Stage 2 differs, and demon-
strate how finding Pareto-optimal rule sets as an intermediate stage
between Stage 1 and Stage 2 can benefit the eventual result.
To study the relationship of HV (as an intermediate evaluation
metric) and final objective, we consider three implementations of
PORS framework in this section; hvc-ss for high HV, equi-spaced
for medium HV, and k-med.-j. for low HV.
5.4.1 Confidence-Constrained Rule Set Learning. The first case
study focuses on applications that prioritize recall over precision.
We compare PORS with confidence-constrained rule set learning
(CRSL) [ 16]. Note that CRSL only works on TreeEns as it needs a
large candidate set to select from, and we compare it with PORS al-
gorithms (with different SSF implementations) using SpectralRules
for Stage 1 (other settings are the same with Section 5.2).
Table 5 summarizes results on both public and propriety datasets
for CRSL and PORS algorithms. We observe that on both public and
propriety datasets, PORS with hvc-ss outperforms CRSL on most
cases. In addition, we observe that there is a positive correlationDataset Prec CRSL [16]PORS
hvc-ss equi-spaced k-med.-j.
(High HV) (Med. HV) (Low HV)
Default0.3 0.765¬±0.025 0.854¬±0.010 0.853¬±0.013 0.835¬±0.014
0.5 0.519¬±0.012 0.557¬±0.020 0.564¬±0.005 0.543¬±0.017
0.7 0.238¬±0.038 0.260¬±0.040 0.262¬±0.052 0.257¬±0.045
Credit0.3 0.555¬±0.030 0.584¬±0.013 0.581¬±0.015 0.538¬±0.012
0.5 0.269¬±0.059 0.289¬±0.017 0.279¬±0.037 0.273¬±0.030
0.7 0.038¬±0.021 0.041¬±0.013 0.025¬±0.023 0.024¬±0.023
Fraud0.3 0.840¬±0.038 0.851¬±0.045 0.847¬±0.035 0.836¬±0.037
0.5 0.816¬±0.024 0.822¬±0.035 0.822¬±0.038 0.822¬±0.024
0.7 0.812¬±0.032 0.814¬±0.021 0.818¬±0.033 0.808¬±0.034
Bank0.3 0.907¬±0.015 0.951¬±0.007 0.945¬±0.009 0.813¬±0.034
0.5 0.630¬±0.075 0.781¬±0.018 0.764¬±0.034 0.679¬±0.050
0.7 0.337¬±0.044 0.264¬±0.044 0.243¬±0.038 0.253¬±0.055
A15ùõø1 0.789¬±0.023 0.824¬±0.013 0.794¬±0.016 0.775¬±0.021
10ùõø1 0.624¬±0.016 0.657¬±0.011 0.640¬±0.012 0.614¬±0.018
20ùõø1 0.499¬±0.008 0.510¬±0.009 0.501¬±0.006 0.487¬±0.009
A25ùõø2 0.828¬±0.019 0.831¬±0.007 0.767¬±0.012 0.726¬±0.009
10ùõø2 0.483¬±0.072 0.593¬±0.008 0.578¬±0.008 0.545¬±0.009
20ùõø2 0.263¬±0.079 0.324¬±0.017 0.326¬±0.006 0.292¬±0.006
A35ùõø3 0.581¬±0.022 0.563¬±0.019 0.543¬±0.054 0.483¬±0.034
10ùõø3 0.531¬±0.028 0.560¬±0.021 0.526¬±0.037 0.453¬±0.034
20ùõø3 0.387¬±0.033 0.414¬±0.011 0.402¬±0.023 0.381¬±0.021
Table 5: CRSL vs PORS. Each cell represents the recall on test
set (mean¬±std) under a corresponding precision threshold.
For propriety datasets, we use the precision threshold of 5 √ó,
10√ó, 20√óof the positive rate of the dataset. The best method
is marked in bold for each case.
between HV (as an intermediate evaluation metric) and recall (as a
final objective).
Note that CRSL needs to run on each precision threshold to
produce a rule subset, while PORS algorithm only needs to run once
to generate a set of rule subsets that can be readily picked up for
different precision thresholds. Such flexibility is usually appreciated
in real development of rule subsets as rule mining in practice is
typically an explorative and iterative process.
Online Evaluation and Deployment. We perform an online
A/B testing for PORS algorithm and CRSL [ 16] from 12/06/2023 to
12/27/2023. These two algorithms are trained on a same anti-money
laundering dataset with 5,532,623 points and 717 features. The
precision threshold has been set to 0.8 and the goal is to maximize
recall. These two algorithms both produce rule subsets of 22 rules.
We only report the relative increase of recall rather than the
actual number in this paper in accordance with the company‚Äôs
non-disclosure policy. PORS achieved 1.56% increase of recall while
CRSL achieved 1.49% increase of recall; significant with ùëù-value
= 0 from two-tailed paired ùë°-test on 59 million samples. We have
deployed our PORS algorithm in our internal Fanglue system [ 19]
and it has been serving our internal users since May 2023. We have
in total about 23,000 jobs up to March 2024, with an average of
about 2,000 jobs per month.
5.4.2 Rule Set Learning Using ùêπùõΩScore. Our second case study
focuses on applications that prioritize precision over recall and we
useùêπùõΩscore to select the final rule subsets for Stage 2 (which is
also widely used inside Alipay).9We compare PORS with standard
greedy forward stepwise algorithm for subset selection (Greedy),
9Note that for Fintech applications, a small ùõΩis usually favored so that the metric is
more biased towards precision.
5966On Finding Bi-objective Pareto-optimal Fraud Prevention Rule Sets for Fintech Applications KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Dataset ùõΩ GreedyPORS
hvc-ss equi-spaced k-med.-j.
(High HV) (Med. HV) (Low HV)
Default0.1 0.743¬±0.039 0.762¬±0.033 0.747¬±0.022 0.732¬±0.007
0.2 0.685¬±0.015 0.687¬±0.015 0.692¬±0.019 0.685¬±0.012
0.5 0.573¬±0.014 0.578¬±0.008 0.577¬±0.011 0.582¬±0.014
Credit0.1 0.608¬±0.043 0.616¬±0.035 0.608¬±0.039 0.611¬±0.034
0.2 0.523¬±0.020 0.536¬±0.015 0.540¬±0.025 0.534¬±0.025
0.5 0.431¬±0.011 0.433¬±0.009 0.434¬±0.007 0.426¬±0.011
Fraud0.1 0.973¬±0.006 0.968¬±0.013 0.959¬±0.023 0.957¬±0.011
0.2 0.935¬±0.029 0.950¬±0.007 0.941¬±0.016 0.946¬±0.008
0.5 0.838¬±0.032 0.888¬±0.021 0.887¬±0.021 0.873¬±0.019
Bank0.1 0.755¬±0.017 0.763¬±0.020 0.709¬±0.016 0.729¬±0.016
0.2 0.652¬±0.017 0.682¬±0.015 0.666¬±0.018 0.656¬±0.017
0.5 0.596¬±0.009 0.603¬±0.010 0.596¬±0.012 0.586¬±0.010
A10.1 0.689¬±0.011 0.695¬±0.009 0.682¬±0.009 0.674¬±0.010
0.2 0.592¬±0.010 0.599¬±0.006 0.599¬±0.009 0.590¬±0.010
0.5 0.446¬±0.004 0.451¬±0.006 0.443¬±0.003 0.439¬±0.007
A20.1 0.543¬±0.045 0.547¬±0.039 0.543¬±0.044 0.535¬±0.020
0.2 0.443¬±0.018 0.446¬±0.025 0.438¬±0.024 0.429¬±0.017
0.5 0.290¬±0.012 0.290¬±0.012 0.304¬±0.011 0.289¬±0.009
A30.1 0.257¬±0.183 0.250¬±0.114 0.240¬±0.119 0.222¬±0.139
0.2 0.119¬±0.076 0.127¬±0.062 0.126¬±0.060 0.119¬±0.068
0.5 0.067¬±0.029 0.074¬±0.019 0.065¬±0.017 0.063¬±0.009
Table 6: Greedy vs PORS. Each cell represents the ùêπùõΩscore on
test set (mean¬±std) under a particular ùõΩ. The best method is
marked in bold for each case.
0 10 20 30 40 50
Iteration0204060Time (s)PORS
Greedy F0.1
Greedy F0.2
Greedy F0.5
Figure 4: Running time for Greedy and PORS on Bank dataset.
both using SpectralRules to produce the initial 500 rules in Stage 1.
The greedy algorithm iteratively adds one rule from the initial rule
set so as to achieve the highest metric value. To avoid running into
local optima, we equip Greedy with beam search of width 10.
Table 6 summarizes results on both public and propriety datasets
for Greedy and PORS algorithms. We can see that PORS with
hvc-ss outperforms Greedy by finding rule subsets with higher
ùêπùõΩon most cases. We again observe that the positive correlation
between HV (as an intermediate evaluation metric) and ùêπùõΩ(as a
final objective). Note that Greedy needs to run multiple times (one
for eachùõΩ) while PORS only needs to run once and it generates a set
of Pareto-optimal rule subsets. It gives more flexibility for human
to quickly experiment different ùõΩs without additional efforts.
Since both Greedy and PORS adds one rule for each iteration,
we can compare the running time in a relatively fair fashion; we
run both Greedy and PORS (with hvc-ss ) algorithm on a standard
server with 16GB memory using 4 threads, and Figure 4 illustrates
the running time for PORS and Greedy ùêπ0.1,ùêπ0.2, andùêπ0.5on Bank
dataset. As expected, ùõΩhas little impact on the running time for
Greedy. Since PORS aims to generate a set of rule subsets while
Greedy only focuses on one single metric, PORS needs to do more
work for each iteration and we empirically observe PORS takes 2xto 3x more time than single run of Greedy for each iteration. This
is acceptable in practice given the flexibility offered by PORS.
6 Conclusion
The two-stage framework of fraud prevention decision rule set
mining is usually employed in large Fintech institutions. This paper
focuses on improving the flexibility and efficacy of this two-stage
framework and is concerned with finding high-quality rule subsets
in a bi-objective space. We first introduce a novel algorithm called
SpectralRules for Stage 1 that encourages the diversity of rules. We
empirically find such diversity improves the final quality of rule
subset. We also introduce an intermediate stage between Stage 1
and 2 that adopts the concept of Pareto optimality and aims to find a
set of non-dominated rule subsets, which constitutes a Pareto front.
This intermediate stage greatly simplifies the selection criteria and
increases the flexibility for Stage 2. We propose a heuristic-based
framework called PORS and we identify that the core of PORS is
the problem of solution selection on the front (SSF). We provide
a thorough empirical evaluation of various SSF methods on both
public and proprietary datasets. On two real application scenarios
within Alipay, we demonstrate the advantages of our proposed
methodology compared to existing work.
References
[1]2024. Github repo. https://github.com/ChengyaoWen/Pareto-Optimal-Rule-
Subset-Selection
[2]R. Agrawal, T. Imieli≈Ñski, and A. Swami. 1993. Mining association rules between
sets of items in large databases. In SIGMOD.
[3]J. Bader and E. Zitzler. 2011. HypE: An algorithm for fast hypervolume-based
many-objective optimization. Evolutionary Computation 19, 1 (2011), 45‚Äì76.
[4]N. Beume, B. Naujoks, and M. Emmerich. 2007. SMS-EMOA: Multiobjective
selection based on dominated hypervolume. European Journal of Operational
Research 181, 3 (2007), 1653‚Äì1669.
[5] L. Breiman. 2001. Random forests. Machine Learning 45, 1 (2001), 5‚Äì32.
[6]L. Breiman, J.H. Friedman, C.J. Stone, and R.A. Olshen. 1984. Classification and
regression trees. Chapman and Hall/CRC.
[7]W. Chen, H. Ishibuchi, and K. Shang. 2021. Clustering-based subset selection in
evolutionary multiobjective optimization. In SMC.
[8]W. Chen, H. Ishibuchi, and K. Shang. 2021. Fast greedy subset selection from
large candidate solution sets in evolutionary multiobjective optimization. IEEE
Transactions on Evolutionary Computation 26, 4 (2021), 750‚Äì764.
[9]P. Clark and T. Niblett. 1989. The CN2 induction algorithm. Machine Learning 3,
4 (1989), 261‚Äì283.
[10] W.W. Cohen. 1995. Fast effective rule induction. In ICML.
[11] K. Deb, A. Pratap, S. Agarwal, and T Meyarivan. 2002. A fast and elitist multiobjec-
tive genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation
6, 2 (2002), 182‚Äì197.
[12] A.P. Guerreiro, C.M. Fonseca, and L. Paquete. 2020. The hypervolume indicator:
Problems and algorithms. arXiv preprint arXiv:2005.00515 (2020).
[13] H. Lakkaraju, S.H. Bach, and J. Leskovec. 2016. Interpretable decision sets: A
joint framework for description and prediction. In KDD.
[14] B. Li, J. Li, K. Tang, and X. Yao. 2015. Many-objective evolutionary algorithms: A
survey. Comput. Surveys 48, 1 (2015), 1‚Äì35.
[15] M. Li and X. Yao. 2019. Quality evaluation of solution sets in multiobjective
optimisation: A survey. Comput. Surveys 52, 2 (2019), 1‚Äì38.
[16] M. Li, L. Yu, Y.-L. Zhang, X Huang, Q. Shi, Q. Cui, X. Yang, L. Li, W. Zhu, Y. Fang,
and J. Zhou. 2022. An adaptive framework for confidence-constraint rule set
learning algorithm in large dataset. In CIKM.
[17] C. Molnar. 2020. Interpretable machine learning. Lulu. com.
[18] V. Pereyra, M. Saunders, and J. Castillo. 2013. Equispaced Pareto front con-
struction for constrained bi-objective optimization. Mathematical and Computer
Modelling 57, 9-10 (2013), 2122‚Äì2131.
[19] C. Qian, S. Liang, Z. Wang, and Y. Lou. 2023. Fanglue: An interactive system
for decision rule crafting. Proceedings of the VLDB Endowment 16, 12 (2023),
4062‚Äì4065.
[20] J.R. Quinlan. 1993. C4.5: Programs for machine learning. Morgan Kaufmann
Publishers.
[21] K. Shang, T. Shu, H. Ishibuchi, Y. Nan, and L.M. Pang. 2022. Benchmarking
subset selection from large candidate solution sets in evolutionary multi-objective
optimization. arXiv preprint arXiv:2201.06700 (2022).
5967KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Chengyao Wen and Yin Lou
[22] R. Tanabe, H. Ishibuchi, and A. Oyama. 2017. Benchmarking multi-and many-
objective evolutionary algorithms under two optimization scenarios. IEEE Access
5 (2017), 19597‚Äì19619.
[23] C.J. Van Rijsbergen. 1979. Information retrieval. Butterworth-Heinemann.
[24] G. Zhang and A. Gionis. 2020. Diverse rule sets. In KDD.
[25] Q. Zhang and H. Li. 2007. MOEA/D: A multiobjective evolutionary algorithm
based on decomposition. IEEE Transactions on Evolutionary Computation 11, 6
(2007), 712‚Äì731.
[26] E. Zitzler. 1999. Evolutionary algorithms for multiobjective optimization: Methods
and applications. Ph. D. Dissertation. ETH Zurich, Switzerland.
[27] E. Zitzler, M. Laumanns, and L. Thiele. 2001. SPEA2: Improving the strength Pareto
evolutionary algorithm. Technical Report. ETHZ, Z√ºrich, Switzerland.
A Impact of Different Values of ùëò
To further evaluate the impact of different values of ùëòon PORS
with different SSF methods, including running time and HV, we set
ùëòto 5, 10, 15, 20 respectively and apply those 9 PORS algorithms onthe 4 public datasets. According to previous sections, SpectralRules
is employed in Stage 1 and the maximum round running of PORS
is set to 30 to avoid early stopping, i.e., each experiment trial fully
completed 30 iterations. All experiments are repeated 5 times.
Table 7 shows the HV results on test set of different PORS algo-
rithms for each ùëò. Once again, we observe that PORS with hvc-ss
as its SSF method achieves the highest HV on most cases. For all
SSF methods, a larger value of ùëòusually leads to a higher HV as
expected. However, once the ùëòexceeds 10, we observe the standard
diminishing returns phenomenon between ùëòand HV.
The running time of PORS is positively correlated to the value
ofùëòas shown in Table 8. Considering the trade-off between perfor-
mance and efficiency, we recommend using ùëò=10in practice.
Dataset k hvc-ss hv-ss igd-ss igd+-ss k-med.-pr k-med.-j. equi-j. equi-spaced equi-dist
Bank5 0.575¬±0.009 0.583¬±0.011 0.531¬±0.014 0.502¬±0.025 0.549¬±0.012 0.493¬±0.022 0.552¬±0.012 0.555¬±0.009 0.561¬±0.01
10 0.591¬±0.012 0.580¬±0.009 0.546¬±0.017 0.539¬±0.016 0.562¬±0.010 0.512¬±0.013 0.564¬±0.015 0.571¬±0.009 0.571¬±0.010
15 0.596¬±0.011 0.582¬±0.010 0.564¬±0.013 0.553¬±0.014 0.566¬±0.008 0.533¬±0.018 0.567¬±0.012 0.574¬±0.006 0.577¬±0.008
20 0.594¬±0.011 0.583¬±0.010 0.561¬±0.011 0.554¬±0.013 0.571¬±0.011 0.531¬±0.011 0.568¬±0.014 0.574¬±0.006 0.578¬±0.008
Credit5 0.347¬±0.012 0.350¬±0.011 0.333¬±0.010 0.325¬±0.012 0.337¬±0.010 0.316¬±0.008 0.342¬±0.016 0.340¬±0.016 0.341¬±0.012
10 0.357¬±0.012 0.356¬±0.015 0.345¬±0.014 0.336¬±0.011 0.345¬±0.011 0.331¬±0.011 0.355¬±0.013 0.350¬±0.013 0.351¬±0.015
15 0.359¬±0.015 0.358¬±0.014 0.348¬±0.014 0.340¬±0.012 0.349¬±0.013 0.337¬±0.011 0.356¬±0.013 0.353¬±0.013 0.356¬±0.014
20 0.359¬±0.015 0.358¬±0.014 0.352¬±0.014 0.342¬±0.011 0.350¬±0.014 0.341¬±0.012 0.356¬±0.013 0.355¬±0.013 0.357¬±0.013
Default5 0.541¬±0.014 0.532¬±0.013 0.501¬±0.021 0.509¬±0.022 0.512¬±0.014 0.495¬±0.019 0.532¬±0.010 0.529¬±0.012 0.534¬±0.012
10 0.540¬±0.012 0.535¬±0.010 0.517¬±0.015 0.515¬±0.016 0.515¬±0.013 0.504¬±0.021 0.535¬±0.009 0.534¬±0.012 0.535¬±0.011
15 0.536¬±0.012 0.535¬±0.011 0.524¬±0.016 0.525¬±0.018 0.523¬±0.015 0.510¬±0.015 0.535¬±0.010 0.536¬±0.011 0.536¬±0.010
20 0.533¬±0.011 0.537¬±0.010 0.525¬±0.012 0.525¬±0.013 0.527¬±0.014 0.514¬±0.015 0.534¬±0.012 0.536¬±0.011 0.537¬±0.010
Fraud5 0.805¬±0.031 0.794¬±0.034 0.801¬±0.026 0.798¬±0.024 0.802¬±0.030 0.786¬±0.035 0.794¬±0.027 0.793¬±0.039 0.790¬±0.034
10 0.808¬±0.030 0.801¬±0.033 0.798¬±0.045 0.794¬±0.026 0.793¬±0.032 0.800¬±0.029 0.803¬±0.028 0.796¬±0.037 0.805¬±0.025
15 0.806¬±0.032 0.801¬±0.032 0.809¬±0.030 0.806¬±0.032 0.802¬±0.035 0.804¬±0.029 0.808¬±0.025 0.797¬±0.036 0.807¬±0.028
20 0.801¬±0.037 0.797¬±0.045 0.797¬±0.048 0.807¬±0.026 0.808¬±0.033 0.797¬±0.035 0.793¬±0.047 0.806¬±0.033 0.804¬±0.040
Table 7: The hypervolume (HV) performance (mean ¬±std) of the Pareto front for different methods on test set of each problem.
Higher HV is better. SpectralRules is employed in Stage 1 to produce the initial 500 rules. The maximum round running of
PORS is set to 30 to avoid early stopping, i.e., each experiment trial fully completed 30 iterations.
Dataset k hvc-ss hv-ss igd-ss igd+-ss k-med.-pr k-med.-j. equi-j. equi-spaced equi-dist
Bank5 47.36¬±2.00 47.36¬±2.00 46.71¬±0.80 47.09¬±2.13 44.85¬±0.94 59.33¬±3.25 48.10¬±4.76 44.02¬±1.68 44.65¬±1.73
10 64.27¬±4.08 53.61¬±3.08 57.44¬±2.16 58.02¬±2.95 53.62¬±3.05 73.65¬±2.70 65.63¬±2.55 52.64¬±2.19 52.21¬±2.59
15 83.45¬±4.23 57.56¬±1.82 69.57¬±4.38 66.63¬±3.65 60.31¬±3.89 93.31¬±3.93 73.08¬±1.16 55.72¬±1.29 56.26¬±2.15
20 113.47¬±4.22 62.71¬±1.11 80.73¬±4.80 75.91¬±1.23 62.19¬±2.07 110.80¬±4.50 81.95¬±4.08 62.28¬±2.74 61.53¬±2.47
Credit5 57.45¬±6.17 48.92¬±5.83 58.95¬±6.63 49.92¬±2.17 48.03¬±3.61 125.73¬±15.02 68.48¬±5.81 45.31¬±1.19 48.92¬±3.68
10 93.31¬±9.57 63.53¬±4.56 90.76¬±6.50 73.82¬±4.17 61.64¬±4.28 238.02¬±25.20 121.91¬±12.10 57.66¬±3.41 61.02¬±8.11
15 140.18¬±10.64 70.92¬±4.03 121.71¬±12.48 93.68¬±2.77 68.72¬±4.27 350.31¬±22.91 161.11¬±8.78 66.79¬±2.86 71.79¬±11.58
20 185.67¬±8.33 81.91¬±8.87 164.50¬±13.35 119.50¬±8.09 74.65¬±4.09 512.19¬±48.05 196.48¬±18.93 76.58¬±3.32 79.19¬±7.05
Default5 49.19¬±2.19 43.57¬±2.35 49.69¬±2.29 47.44¬±1.78 41.26¬±1.07 53.80¬±3.85 57.73¬±2.32 41.82¬±1.03 43.08¬±1.74
10 71.33¬±4.34 54.12¬±5.40 66.04¬±4.95 63.25¬±3.70 49.20¬±3.36 71.20¬±2.21 79.19¬±3.06 51.53¬±2.41 49.99¬±1.75
15 99.13¬±3.36 60.22¬±4.73 80.24¬±1.89 79.72¬±6.15 54.43¬±2.38 93.06¬±6.31 96.18¬±4.66 56.71¬±2.01 55.31¬±1.72
20 133.09¬±10.86 67.49¬±5.00 101.47¬±2.29 98.13¬±3.53 61.73¬±3.17 116.56¬±4.28 113.25¬±5.85 61.16¬±1.81 61.50¬±1.45
Fraud5 40.42¬±0.16 40.81¬±1.03 41.35¬±1.05 42.23¬±0.81 41.15¬±0.55 61.24¬±1.63 42.40¬±0.52 42.23¬±0.54 42.20¬±0.55
10 45.75¬±1.00 45.62¬±1.14 46.94¬±0.74 47.88¬±1.52 46.68¬±0.81 74.92¬±1.87 48.86¬±1.23 47.35¬±1.36 47.44¬±1.85
15 50.88¬±0.84 50.06¬±0.43 51.90¬±1.41 52.43¬±0.80 50.34¬±0.52 87.41¬±2.18 51.62¬±1.31 50.27¬±0.31 50.49¬±0.91
20 56.71¬±2.46 53.91¬±0.63 55.59¬±1.22 56.99¬±0.99 54.65¬±0.68 100.30¬±1.85 55.06¬±1.58 54.12¬±0.58 53.56¬±0.41
Table 8: The running time in seconds (mean ¬±std) for different methods on test set of each problem. SpectralRules is employed
in Stage 1 to produce the initial 500 rules. The maximum round running of PORS is set to 30 to avoid early stopping, i.e., each
experiment trial fully completed 30 iterations.
5968