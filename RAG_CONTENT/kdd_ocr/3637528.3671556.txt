Metric Decomposition in A/B Tests
Alex Deng∗
Airbnb
Seattle, WA, USA
alex.deng@airbnb.comLuke Hagar
University of Waterloo
Waterloo, ON, Canada
lmhagar@uwaterloo.ca
Nathaniel T. Stevens
University of Waterloo
Waterloo, ON, Canada
nstevens@uwaterloo.caTatiana Xifara
Airbnb
San Francisco, CA, USA
tatiana.xifara@airbnb.comAmit Gandhi†
University of Pennsylvania
Philadelphia, PA, USA
agandhi@upenn.edu
Abstract
Morethanadecadeago,CUPED(ControlledExperimentsUtilizing
Pre-Experiment Data) mainstreamed the idea of variance reduction
leveraging pre-experiment covariates. Since its introduction, it has
been implemented, extended, and modernized by major online ex-
perimentation platforms. Despite the wide adoption, it is known by
practitioners that the variance reduction rate from CUPED utilizing
pre-experimental data varies case by case and has a theoretical limit.
In theory, CUPED can be extended to augment a treatment effect
estimator utilizing in-experiment data, but practical guidance on
how to construct such an augmentation is lacking. In this article, we
fill this gap by proposing a new direction for sensitivity improve-
ment via treatment effect augmentation whereby a target metric of
interest is decomposed into components with high signal-to-noise
disparity. Inference in the context of this decomposition is devel-
oped using both frequentist and Bayesian theory. We provide three
real world applications demonstrating different flavors of metric
decomposition; these applications illustrate the gain in agility metric
decomposition yields relative to an un-decomposed analysis.
CCS Concepts
•Mathematics of computing →Probabilistic inference prob-
lems; Hypothesis testing and confidence interval computa-
tion; Bayesian computation ;•Appliedcomputing →E-commerce
infrastructure.
Keywords
A/B testing, online experimentation, variance reduction, Bayesian
analysis, causal surrogate, counterfactual
ACM Reference Format:
Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit
Gandhi. 2024. Metric Decomposition in A/B Tests. In Proceedings of Proceed-
ings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data
∗Corresponding author.
†Work completed while employed by Airbnb.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671556Mining (KDD ’24). ACM, New York, NY, USA, 11 pages. https://doi.org/10.
1145/3637528.3671556
1 Introduction
Online controlled experiments, also referred to as “A/B tests”, are
an invaluable tool used by companies to test and evaluate changes to
theironlineproducts.Withrespecttosomemetric(s)ofinterest,these
experiments facilitate causal conclusions about the efficacy of such
changes. Large tech companies collectively run tens of thousands
of these experiments each year, engaging millions of users [23].
An A/B test typically compares two versions of a product: a new
treatment version to the existing control version. Interest lies in
understanding the treatment effect 𝛿, which quantifies the poten-
tial improvement (with respect to some metric of interest) induced
by the treatment relative to the control. Denoting the metric of in-
terest𝑀, the treatment effect 𝛿is commonly estimated using the
difference in metric values observed in the treatment and control
groups Δ(𝑀):=𝑀𝑇−𝑀𝐶. Assuming the users are independent of
one another and randomized to the treatment and control groups,
this estimator is unbiased for 𝛿. In some contexts, a treatment ef-
fect defined on the percent scale is preferred for ease of business
communication. This is referred to as lift, and is estimated by
Δ%(𝑀):=𝑀𝑇−𝑀𝐶
𝑀𝐶.
In A/B tests, such metrics are often defined as averages 𝑀:=𝑋of
some measurement 𝑋𝑖observed on each user 𝑖=1,2,...,𝑛 in the
treatment (or control) group. However, ratio and percentile metrics
may also be relevant [ 9,22,23]. In this paper, we focus on average
and ratio metrics as they account for the appreciable majority of
metrics used in practice.
Thus, inference (by way of hypothesis tests and statistical inter-
vals) for𝛿using Δ(𝑀)(orΔ%(𝑀)) is of interest. However, such
inference is complicated by the noisiness of these metrics in practice;
inference quality hinges critically on the sampling variances
Var[Δ(𝑀)]and Var[Δ%(𝑀)].
Although sample sizes in online A/B tests are typically very large—
often at least thousands up to millions—it is widely documented by
practitioners that metrics of interest are highly variable and that
hypothesis tests for 𝛿lack statistical power [ 20]. Consequently, false
negatives—when experimenters cannot detect a non-zero treatment
effect—are prevalent. Moreover, in the face of statistically significant
(abbreviated as stat. sig. henceforth) results, the estimated treatment
effect Δ(𝑀)(orΔ%(𝑀)) often over exaggerates the true treatment
effect𝛿yielding false discoveries [18, 21].
4885
KDD ’24, August 25–29, 2024, Barcelona, Spain Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit Gandhi
Therefore, there is great interest in increasing sensitivity of met-
rics; for a given metric 𝑀, determining how to construct an estimator
of the treatment effect 𝛿with low bias and small variance remains
one of the most critical statistical challenges for A/B testing re-
search [ 3,20,23]. Assuming an unbiased estimator, the method most
widely applied in industry to reduce variability is CUPED (Controlled
experiments Utilizing Pre-Experimental Data) or its variants and
extensions [ 7,12,13]. The general idea with this class of methods
is to use in place of 𝑀an alternative version of the metric that is
augmented by a second metric highly correlated with 𝑀. Another
class of methods recently gaining traction is the use of surrogate
metrics in place of𝑀. Such surrogates are chosen or designed to be
proxies for𝑀with higher sensitivity [15].
In this paper, we propose novel methodology for increasing the
sensitivity of metrics and hence treatment effect estimators that
represents a new direction on this problem. In particular, we propose
decomposing the metric of interest into two or more components in
an attempt to isolate those with high signal and low noise from those
with low signal and high noise. The paper demonstrates both empir-
ically and theoretically the value of this practice in both frequentist
and Bayesian settings.
1.1 Metric Decomposition
Consider an additive decomposition of a metric 𝑀as follows
𝑀=𝑀1+𝑀2. This decomposition implies the following decomposi-
tion of the estimator
Δ(𝑀)=Δ(𝑀1)+Δ(𝑀2), (1)
where the true effect to be estimated also has the decomposition
𝛿=𝛿1+𝛿2. Multiplicative decompositions such as 𝑀=𝑀1×𝑀2
may also be of interest. In a treatment vs. control comparison, if
we observe percent lifts Δ%(𝑀1)andΔ%(𝑀2), by the multiplicative
decomposition, we have
𝑀𝑇=𝑀1,𝑇×𝑀2,𝑇
=[1+Δ%(𝑀1)]𝑀1,𝐶×[1+Δ%(𝑀2)]𝑀2,𝐶
=𝑀𝐶×[1+Δ%(𝑀1)][1+Δ%(𝑀2)].
Dividing both sides by 𝑀𝐶and expanding the right hand side, we see
𝑀𝑇
𝑀𝐶−1=Δ%(𝑀1)+Δ%(𝑀2)+Δ%(𝑀1)·Δ%(𝑀2).
The left hand side is the percent treatment effect Δ%(𝑀), and the last
term on the right hand side is an ignorable second order term. When
bothΔ%(𝑀1)andΔ%(𝑀2)are relatively small, which is often the case
in A/B tests where even a 10% change is commonly deemed extreme,
the following approximate additive decomposition is appropriate
Δ%(𝑀)≈Δ%(𝑀1)+Δ%(𝑀2). (2)
With a unified (though slight abuse of) notation, we let 𝛿≈𝛿1+𝛿2
represent the ground truth multiplicative treatment effect. Thus de-
compositions of Δ(𝑀)andΔ%(𝑀)will both be treated as additive no
matter whether the decomposition of 𝑀is additive or multiplicative.
Note that the above decompositions assume the metric 𝑀decom-
poses into𝑘=2components, but context and/or engineered solutions
may dictate a decomposition into any number of components, e.g.,
𝑀=𝑀1+···+𝑀𝑘or𝑀=𝑀1×···×𝑀𝑘.
We address (and develop theory for) this more general case in this
paper.Where does a decomposition come from?
Context may dictate a natural decomposition. If 𝑀is a simple average
𝑋, an additive decomposition can come from breaking each observa-
tion𝑋𝑖into two (or more) parts. Similarly, when 𝑀is a ratio metric
𝑋/𝑌, an additive decomposition can be constructed from a decompo-
sition of the numerator 𝑋. Multiplicative decompositions such as 𝑋=
𝑋
𝑌×𝑌also occur naturally. For example, multiplicative metric chain-
ing is common in conditional funnels; if a conversion funnel involves
multiple steps, then a conversion rate 𝑌at an intermediate step can
be used to decompose the overall conversion rate 𝑋multiplicatively.
Similarly, common revenue metrics such as revenue per user can be
decomposed into revenue per purchase, and purchases per user.
More generally, both additive and multiplicative decompositions
can be engineered by defining one of the components and then taking
the second component to be the additive or multiplicative comple-
ment. Specifically, let 𝑀1be any arbitrary metric, we can define
𝑀2as𝑀−𝑀1(in the additive case), or 𝑀/𝑀1(in the multiplicative
case). With this construction, we can always get a synthetic metric
decomposition. In Section 3, we illustrate real-world examples of
both contextual and engineered decompositions.
Why is metric decomposition useful?
In Sections 2 and 4 we respectively develop frequentist and Bayesian
theory for how to leverage decompositions to improve the sensitivity
of treatment effect estimators relative to the standard approach with-
out decomposition. Then, in Section 3, we provide three real-world
applications of metric decomposition to illustrate how these meth-
ods can be employed in practice. Here, we motivate at a high-level
the value of metric decomposition from both the frequentist and
Bayesian perspectives.
In the frequentist setting, we propose defining a new treatment
effect estimator as a function of the components. Illustrating the
basic idea with 𝑘=2components, we have
Δ∗(𝜃):=Δ1+𝜃·Δ2 (3)
where Δ1andΔ2are suppressed notation for Δ(𝑀1)andΔ(𝑀2).
Clearly, the original estimator from (1) arises as a special case when
𝜃=1, but the formulation in (3) allows for optimization of different
objectives with respect to 𝜃. Such objectives may include variance
reduction, mean squared error reduction, or power boosting. As we
demonstrate in Section 2.2, the proposed framework is flexible to a
variety of different objectives.
Keen readers familiar with variance reduction and CUPED [ 12]
will recognize this form of regression adjustment. When the compo-
nentΔ2has no treatment effect, i.e., 𝛿2=0, we know𝛿=𝛿1. Instead
of using Δ=Δ1+Δ2, we can directly use Δ1as an estimator if it has
a smaller variance than Δ. Or, more generally, we can find 𝜃that
minimizes variance in the family of (3). However, in general, beyond
using pre-experiment data as suggested by CUPED, it is hard to
construct a component Δ2with theoretically 0treatment effect. Nev-
ertheless, as we demonstrate in this paper, it is commonly possible
to define a decomposition in which the components have drastically
different signal-to-noise ratios (SNRs), with one component captur-
ing the majority of the treatment effect and the other component(s)
capturing much less treatment effect and a large proportion of noise.
With metric decomposition, we can exploit this kind of SNR disparity.
In this way, the estimator in (3)based on metric decomposition can
4886Metric Decomposition in A/B Tests KDD ’24, August 25–29, 2024, Barcelona, Spain
be seen as a generalization of CUPED, where rather than adjusting
by a null-effect term (i.e., mean-zero augmentation) [ 13], we adjust
by an almost null-effect term. We refer to the adjustment made with
estimators in the form of (3)asapproximately null augmentation, or
ANA. This perspective will be formalized in Section 2.
From a Bayesian perspective, inference for 𝛿is carried out via pos-
terior analyses. Of interest here are the two posterior distributions
𝑝(𝛿|Δ)and𝑝(𝛿|Δ1,Δ2),
where the first would be used in a standard analysis and the second
exploits the decomposition. As we formalize in Section 4, we can ex-
pect the posterior distribution 𝑝(𝛿|Δ1,Δ2)to have smaller posterior
variance than 𝑝(𝛿|Δ). Moreover, certain prior information can also
lead to𝑝(𝛿|Δ1,Δ2)being concentrated more closely around 𝛿than
𝑝(𝛿|Δ). Thus, from a Bayesian perspective, sensitivity and hence the
quality of inference can also be improved by metric decomposition.
1.2 Setup and Notation
We assume the target of inference is the treatment effect 𝛿, which
quantifies the additive (or percent) difference between treatment
and control with respect to some metric 𝑀. We further assume 𝑀
decomposes into a sum (or product) of components 𝑀1,...,𝑀𝑘. In
either case, as discussed in Section 1.1, we assume that Δ(𝑀)=
Δ1(𝑀)+···+ Δ𝑘(𝑀)estimates the treatment effect 𝛿which similarly
decomposes: 𝛿=𝛿1+···+𝛿𝑘. Although in this paper we will illus-
trate metric decomposition for the basic 𝑘=2component version,
we develop theory for the general 𝑘>2component case as well.
Throughout we’ll use the vector notation 𝚫=(Δ1,...,Δ𝑘)to repre-
sent observed treatment effects and 𝜹=(𝛿1,...,𝛿𝑘)to represent true
treatment effects. We adopt the following random effect model
𝚫=𝜹+𝜺, (4)
where 𝜹and𝜺are both random vectors which are assumed to be
independent of one another. This model is meant to characterize the
variation in observed treatment effects across a population of A/B
tests (e.g., across all the A/B tests run by a given organization). The
random vector 𝜹reflects variation in true treatment effects across
these experiments and the random vector 𝜺reflects noise in treatment
effect estimation. For large scale A/B tests, it is common to exploit the
central limit theorem and assume that 𝜺¤∼N(0,𝚺). We further follow
industry convention and assume the covariance matrix 𝚺is fixed and
known, where the “known” values are found using sample variances
and covariances based on past experiments. For a given experiment,
this covariance matrix is a function of sample size 𝑛though we
suppress notation and do not notate this dependence explicitly.
We also posit that 𝜹follows a distribution with mean E[𝜹]=0and
covariance matrix Var[𝜹]=𝚲. Note that unlike 𝜺, which follows a nor-
mal distribution due to the central limit theorem, we do not in general
assume 𝜹follows a normal distribution1. The zero-mean assumption
reflects the reality that across an organization’s population of A/B
tests, results will be positive, negative, null, and likely null on average.
We remark that 𝚲can be estimated empirically from data. For exam-
ple, suppose we observe 𝑁equal sample-sized experiment results
each with the observed vector 𝚫𝑠,𝑠=1,...,𝑁 . By the independence of
𝜹and𝜺, the covariance of the observed 𝚫has a trivial decomposition
Var[𝚫]=Var[𝜹]+Var[𝜺]=𝚲+𝚺.
1A normality assumption for 𝜹is however made in Section 4 when we take a Bayesian
view of the problem.This leads to a sample estimate of 𝚲defined as the difference between
the sample covariance matrix of 𝚫and the noise covariance matrix
𝚺. When sample sizes for the set of experiments are different, we
can instead use a sample average of 𝚺𝑠,𝑠=1,...,𝑁 . There exist other
and more robust ways to estimate 𝚲, but this line of research is or-
thogonal to the metric decomposition methods we propose here. In
this paper we’ll simply assume an estimate of 𝚲is already available.
We end this section by emphasizing the symbol 𝛿will be used to de-
scribe the true unknown treatment effect in a single experiment, but
also the random variable representing variation in true treatment ef-
fects across a population of experiments. Though we take care to dis-
tinguish this, context should dictate which version of 𝛿is being used.
1.3 Contributions
This paper makes the following contributions to the online exper-
imentation and measurement science literature:
(1)A new framework for treatment effect estimation that exploits
metric decomposition from both frequentist (see Section 2) and
Bayesian (see Section 4) perspectives. We also share the code to
implement and reproduce our simulation studies2.
(2)Real-world applications of this new methodology in three dif-
ferent flavors: (i) engineered decomposition, (ii) natural funnel
decomposition, and (iii) adjustment of a surrogate metric. These
applications are detailed Section 3.
2 Frequentist View of Metric Decomposition
Here we overview the frequentist motivation for metric decom-
position. See Section 4 for an elaboration of the Bayesian motivation
for decomposition.
2.1 Approximately Null Augmentation
In Section 1.1 we argued that metric decomposition can exploit
disparity in signal-to-noise ratios (SNRs). We define the SNR as
Var[𝛿]
Var[𝜀]. (5)
Given a decomposition with effect variance 𝚲and noise variance 𝚺, if
one component, say the first component (without loss of generality),
has an SNR Λ11/Σ11that is much larger than the other components,
the intuition is that Δ1is the most useful component for estimating
𝛿. And although the other components provide much less signal,
they can still be useful as an (approximately null augmentation)
adjustment to Δ1. This leads us to the following definition.
Definition 2.1 (Approximately Null Augmentation). ANA refers
to the family of estimators Δ∗(𝒄):=𝒄⊺𝚫where 𝒄⊺𝒆1=1for the
standard basis vector 𝒆1∈R𝑘. Note that when 𝑘=2, this reduces to
(3) with 𝒄=(1,𝜃).
The theoretical results developed in this section address the follow-
ing question of theoretical and practical importance. For the purpose
of estimating 𝛿=1⊺
𝑘𝜹in a manner that leverages the SNR disparity
and approximately null augmentation, what vector 𝒄should we use?
In Section 2.2, we define five potential objectives that may be used
to find the optimal augmentation vector 𝒄, and for each we state the
optimal coefficients. In Section 2.3 we explore how the proposed
metric decomposition method is related to and different from exist-
ing variance reduction methods like CUPED and the use of more
sensitive surrogate metrics.
2https://github.com/lmhagar/MetricDecomp
4887KDD ’24, August 25–29, 2024, Barcelona, Spain Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit Gandhi
2.2 ANA Objectives
Note that for brevity and consistency with the examples in Section
3, we consider the 𝑘=2case here, and hence define the optimal 𝜃
for each objective. In Appendix A we provide the corresponding
derivations and also consider the more general 𝑘>2case.
Minimizing Mean Squared Error. We consider minimizing the
MSE of the ANA estimator: E[(𝛿−Δ∗)2]. Doing so balances bias and
variance for better point estimation of effect size at the organiza-
tional level. This is a standard regression objective, except that the
response𝛿is not directly observed. However, because the solution
for the regression coefficients involves only the covariance of 𝛿and
the regressors 𝚫, which can all be estimated, we are still able to
compute the regression coefficients. See also [ 5,26,28]. With respect
to model (4), the value of 𝜃that minimizes E[(𝛿−Δ∗)2]is
𝜃=Λ22−Σ12
Λ22+Σ22. (6)
Maximizing Correlation. Tripuraneni et al . [28] in a slightly
different context suggest maximizing Corr[𝛿,Δ∗], the correlation
between𝛿andΔ∗. This criterion is useful from the perspective of
treating Δ∗as a surrogate metric not just for estimating 𝛿but also
for understanding the direction (i.e., sign) of the effect. With respect
to model (4), the value of 𝜃that maximizes Corr [𝛿,Δ∗]is
𝜃=(Λ12+𝚺12)(Λ11+Λ12)−(Λ12+Λ22)(Λ11+Σ11)
(Λ12+Σ12)(Λ12+Λ22)−(Λ11+Λ12)(Λ22+Σ22). (7)
It is also interesting to point out that the ANA maximizing correlation
is just a rescaled version of the posterior mean E[𝛿|𝚫].
Minimizing Error Variance. Whereas minimizing MSE will
inherently address the bias-variance trade-off associated with ap-
proximately null augmentation, another sensible objective would
be to directly minimize the error variance Var[𝒄⊺𝜺]. This serves as a
lower bound for what variance reduction is possible, as it corresponds
to the optimal adjustment in CUPED. With respect to model (4), the
value of𝜃that minimizes Var[𝒄⊺𝜺]is
𝜃=−Σ12
Σ22. (8)
Maximizing Expected Squared Z-Score. The test statistic as-
sociated with 𝐻0:𝛿=0in an ANA analysis is the following Z-score:
Δ∗/√︁
Var[𝜀1+𝜃𝜀2]. To increase the sensitivity of this test we may
seek to find the augmentation that maximizes the expected magni-
tude of this test statistic. We operationalize this by maximizing the
expected square of this test statistic, which based on model (4)is
Var[Δ∗]/Var[𝜀1+𝜃𝜀2]. The optimal value of 𝜃for this objective is
𝜃=−𝑏−√
𝑏2−4𝑎𝑐
2𝑎(9)
with𝑎=Λ22Σ12−Λ12Σ22,𝑏=Λ22Σ11−Λ11Σ22,𝑐=Λ12Σ11−Λ11Σ12.
Maximizing Power. While maximizing the expected Z-score
seeks to increase sensitivity when testing 𝐻0:𝛿=0, this may be
achieved more directly by maximizing power. Whereas the previous
objective marginalizes over the distribution of possible 𝛿values, we
may seek to maximize the Z-score for a specifically selected (posi-
tive)¤𝛿that reflects (for instance) an anticipated effect size of interest.
Exploiting the decomposition ¤𝛿=¤𝛿1+¤𝛿2, the test statistic for this
anticipated effect is (¤𝛿1+𝜃¤𝛿2)/√︁
Var[𝜀1+𝜃𝜀2]. The value of 𝜃that
maximizes this test statistic (and hence power) is
𝜃=¤𝛿1Σ12−¤𝛿2Σ11
¤𝛿2Σ12−¤𝛿1Σ22. (10)Note that rather than specifying a single effect of interest¤𝛿3, a con-
tinuum of¤𝛿values could be specified and we could maximize an
“integrated” test statistic that aggregates across the plausible ¤𝛿values.
In this case the optimal 𝜃is given by (10)but with¤𝛿1and¤𝛿2replaced
by¯𝛿1and¯𝛿2which denote the average of the ¤𝛿1and¤𝛿2values across
the continuum of interest.
We acknowledge that maximizing power and the expected squared
Z-score will lead to an increase in test rejection, but they may lead
to increasingly biased point estimates of the true effect for the un-
decomposed metric, especially when 𝜃is far away from the region
[0,1]. Therefore, we recommend bounding 𝜃within [0,1] when op-
timizing for power or the expected squared Z-score.
When choosing among objectives, one must recognize that there
is no uniformly superior objective; which is appropriate depends on
a practitioner’s goals. If interest lies in accurately and precisely esti-
mating the treatment effect, minimizing MSE is a sensible objective; a
practitioner primarily interested in determining the sign of the effect
may seek to maximize correlation; and a practitioner interested in
increasing test sensitivity may seek to maximize power. That said,
in practice, if we are able to find decompositions with very high
SNR disparities, ANA with different objectives will not be materially
different. This is illustrated in the first two applications in Section 3.
It’s also important to emphasize that all of these objectives are
defined with respect to model (4). This means that the optimal aug-
mentations are optimal at the organizational level. This does not
necessarily imply that the objectives are satisfied at the individual
experiment level. In future work, we plan to use simulation to in-
vestigate the extent to which the objectives are/ are not satisfied for
individual experiments.
2.3 Relation to Exisiting Work
Metric decomposition follows from existing work aimed at in-
creasing metric sensitivity and statistical power. It is closely related
to CUPED, in that it augments the treatment effect estimator in the
interest of improving sensitivity. Metric decomposition can also be
viewed as a more sensitive surrogate metric of the original metric
of interest. Procedures to find the optimal augmentation 𝒄using a
set of historical experiment results is also a form of meta-analysis,
and is related to an empirical Bayesian analysis of experiments. In
the subsections below, we describe these connections to existing
methodology in more detail.
2.3.1 CUPED The CUPED method [ 12] was inspired by the method
of control variates from stochastic simulation [ 1,25]. CUPED is a
model-free method that relies only on the key observation that any
pre-experiment difference between two randomized groups is pure
noise due to randomization and should be 0in expectation as it esti-
mates a null effect. Deng et al . [13] formulated CUPED as mean-zero
augmentation:
Δ∗=Δ+𝜃·Δ0. (11)
This is similar to the two-component ANA in (3), but it differs in
that the augmentation term Δ0in CUPED is assumed to be ex-
actly zero in expectation. From equation (6)we see that the optimal
ANA that minimizes MSE contains the optimal CUPED adjustment
3In the applications in Section 3, we take ¤𝛿1to be the 95th percentile of N(0,Λ11)
(calibrating to detect reasonably large effects) and ¤𝛿2=Λ12¤𝛿1/Λ11(the mean of the
conditional distribution of 𝛿2|𝛿1=¤𝛿1).
4888Metric Decomposition in A/B Tests KDD ’24, August 25–29, 2024, Barcelona, Spain
(−Cov[𝜀1,𝜀2]/Var[𝜀2]) as a special case when the ANA is in fact an ex-
act mean zero augmentation (i.e., when Λ22=Var[𝛿2]=0). This is the
ANA that minimizes error variance in (8). Importantly, the augmen-
tation term in ANA also need not come from pre-experimental data.
ANAisanontrivialextensionandafundamentallydifferentwayto
construct augmentations, often with a much greater variance reduc-
tion possible. Beyond using pre-experiment period data or relying
on triggering conditions [ 8,13], there aren’t many ways to construct
true mean-zero augmentations. It is documented by various sources
(e.g., [ 4,7]) that the amount of variance reduction elicited by CUPED
varies and in many cases can be as little as 10% or less. Recently, it
has also been shown that CUPED using pre-experiment data has a
variance reduction limit [ 27]. Greater variance reduction can only
be achieved with augmentation terms from in-experiment signals.
Metric decomposition stems from the idea of using in-experiment
observations to directly construct approximately null components
with low SNRs. As we have seen, the theory of ANA gives the optimal
adjustment to suit a variety of objectives.
2.3.2 Surrogate Metrics Instead of restricting attention to unbiased
estimators for a target metric 𝑀, the surrogate metric literature
(e.g., [ 2,5,7,15,28]) aims to use another metric—which may be an
existing metric, a functional combination of a set of metrics, or a
model prediction of the target metric—as a proxy. Surrogate metrics
can often achieve greater variance reduction and greatly improve
experimentation agility when the target metric has low statistical
power. However, one drawback is that surrogate metrics are gener-
ally biased, with the degree of bias varying case by case. Choosing
and evaluating surrogate metrics is an active research area in the
A/B testing community [23].
Metric decomposition shares the similar goal of using a potentially
biased estimator in pursuit of increased sensitivity. ANA differs from
methodologies in the surrogate metric literature, however, because
we define explicitly how these potentially biased estimators arise
by breaking the target metric into components, instead of choosing
from a cohort of existing metrics or linear combinations thereof.
Moreover, the metric decomposition approach leads to further im-
provement for anysurrogate metric, because the target metric can
be decomposed by the surrogate and its residual (additive or mul-
tiplicative). In this way, ANA can be applied to further adjust any
surrogate metric by its residual. We elaborate on this in more detail,
and provide a real example in Section 3.3.
2.3.3 Meta Analysis and Empirical Bayes The way we use a set of
historical experiments to aid metric development is a form of meta-
analysis [11,17,28]. The framework of estimating the parameters of
the distribution of the treatment effect 𝜹is also a form of empirical
Bayes [ 6,10,14,16,24,29] and multilevel (hierarchical) modeling
[19]. But to the authors’ knowledge, we are the first to study the im-
plications of replacing an observed metric value with a decomposed
vector.
3 Real-world Applications
To apply metric decomposition with approximate null augmenta-
tion, we require one or more approximately null components (ANCs)
(i.e.,Δ2in(3)orΔ2,...,Δ𝑘in Definition 2.1). This requires leverag-
ing domain knowledge and additional information to answer the
question what part of the measured outcomes is not attributed to thetreatment intervention? In this section we illustrate three applications
of ANA where bivariate metric decompositions arise by engineering
an ANC (Section 3.1), identifying an ANC that arises naturally in
a funnel decomposition (Section 3.2), and defining an ANC in the
context of a surrogate metric (Section 3.3). In each of these sections
we find that ANA improves sensitivity and increases the number
of stat. sig. results. Through A/A tests and type I error control, in
Section 3.4 we demonstrate that ANA does not arbitrarily increase
sensitivity, it increases sensitivity to non-null effects only.
3.1 Engineering an Approximately Null
Component via Counterfactual Reasoning
We applied approximately null augmentation to 39 early-stage
ranking experiments at Airbnb. The goal of these experiments was to
compare two versions of the ranking algorithm that determines the
order of displayed search results. These early-stage experiments run
for roughly 1 week taking a small percentage of total traffic. The main
target metric of interest is bookings per guest. For each search, a user
is given the ranked results which determines both (i) the list of results
shown in the feed view and on the map view, and (ii) the order of the
results listed in the feed view. See Figure 1 for an example of the feed
view and the map view together in the desktop browser experience.
In the iOS and Android apps, users can switch between the two views.
Figure 1: Example Airbnb Search Results. Feed View (left) and Map View (right).
To construct the ANC, we leverage counterfactual ranking results.
That is, for treated users (those for whom the treatment ranker gen-
erated their ranked feeds and corresponding map view), we also
compute the ranked list that would have been shown to them if they
were assigned to the control group. For control users we similarly
computed the ranked list that would have been shown to them had
they been assigned to the treatment group. We then construct the
approximately null component as described in the following steps:
(1)For each booking conversion, we used attribution logic to at-
tribute the booking to click actions from various search result
pages. The attribution is additive such that the sum of the attrib-
uted values is 1 for every booking. In this way, the attributed
values provide information on the relative importance of var-
ious click actions on the booking. Attribution methods are an
important research area in their own right. See Deng et al . [7]
for more discussion of the attribution logic and the method used
in our application.
(2)We then select a subset of attributed search result clicks leading
to every booking. A click is selected if:
(a)the clicked result is ranked among the top 4 results by both
the treatment and the control ranker, with a ranked position
difference no more than 2, or
4889KDD ’24, August 25–29, 2024, Barcelona, Spain Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit Gandhi
(b)both treatment and control rankers show the clicked result
on the map view, and the click happens only on the map (i.e.,
there was no click on the feed view).
(3)For each booking, define the ANC (Component 2, Δ2) as the
sum of attributed values for all selected clicks from the last step.
The signal component (Component 1, Δ1) is straightforwardly
defined as the complement of the decomposition such that the
two components sum to 1. In other words, Component 1 is the
sum of all attributed values from clicks that were notincluded
in the last step.
(4)Aggregate decomposed bookings to the user level and then to
the treatment/control group level.
The heuristics behind this process can be explained as follows. The
criterion in 2(a) considers cases where the booked listing was highly
ranked by both the factual and the counterfactual rankers. This kind
of booked listing is considered “easy” in the sense that any sensible
ranker would put this listing within the first few results. Moreover,
we require the ranked position difference to be no more than 2 to fur-
ther restrict the proximity of the two rankers on this booked listing’s
position. The intuition is that this type of booking would have hap-
pened regardless of which ranker was used, and thus the treatment
effect should be approximately null. The criterion in 2(b) is based on
the assumption that if search results are clicked on the map (i.e., not
the feed view), and both rankers put this listing on the map, then the
booking would happen regardless of which ranker was used. Thus
the treatment effect for such clicks should be approximately null.
Note that these heuristics ignore second order effects like the possibil-
ity that a user’s booking behavior also depends on the the whole set
of the results, not just the ranked position of the booked listing. How-
ever, we do not aim nor do we need to guarantee zero treatment effect
on Component 2, we only aspire to limit the treatment effect on this
component so it has a much smaller effect compared to Component 1.
The effect covariance 𝚲and the average covariance of the noise
𝜺were estimated to be (after scaling by the same constant)
𝚲=3.479−0.979
−0.979 0.672
and𝚺=0.779 0.162
0.162 4.096
.
We find the approximately null component Δ2displays a noise vari-
ance 5 times larger than the signal component Δ1(4.096vs.0.779),
while the variance of the treatment effects for Δ2is less than 1/5 of
that of Δ1(0.672vs.3.479). This means the SNR of Component 2 is
much smaller than that of Component 1 (see equation (5)).
Table 1 summarizes these results and shows that the SNRs of the
two components differ by almost a factor of 30. Component 1’s SNR
is also more than 10 times greater than the SNR of the original metric
without decomposition. This suggests that if Component 2’s effect is
truly much smaller than Component 1, Δ1alone can be an estimate
for the target metric’s treatment effect, with smaller noise variance
and hence much greater statistical power. Indeed, among the 39 early-
stage experiments, Component 2 was stat. sig. at a 5% level only twice
(i.e., 5.1% of the time). This is very close to the 5% significance level,
indicating that Component 2 is approximately null. Component 1,
on the other hand, was stat. sig. in 13 of the 39 experiments. Without
metric decomposition, the booking metric was only stat. sig. 6 times.
We applied the five versions of ANA adjustment discussed in
Section 2.2 in this example: ANA to maximize correlation (denoted
ANA c), to minimize mean squared error (denoted ANA e), to mini-
mize variance (denoted ANA v), to maximize the expected squaredZ-score (denoted ANA z) and to maximize power (denoted ANA p).
Table 1 demonstrates that all these adjustment methods yield similar
results to analyses using Component 1 alone, though ANA ehas one
less stat. sig. result out of 39 experiments. This is because the adjust-
ment coefficient 𝜃for all objectives tends to be relatively small for
these experiments. Figure 2 plots the optimal 𝜃values. We see these
values range between -0.2 to 0.2. Figure 3 shows the five ANA esti-
mates Δ∗. Despite different objectives, estimates in this application
don’t differ materially, aligning with the similar test results in Table 1.
Finally, Figure 4 compares the variances of these ANA estimators.
We see that minimum variance objective (ANA v) provides the lower
bound of what variance is achievable through augmentation. In gen-
eral, minimizing variance directly could lead to more bias relative
to using the high SNR component ( Δ1) alone, since the second com-
ponent ( Δ2) is only approximately null. However, in this application
Component 2’s SNR is so low (relative to Component 1), it suggests
augmentation by Component 2 is essentially a null augmentation.
Figure 2: Optimal 𝜃for various ANA objectives in Application 1.
Figure 3: Comparison of ANA estimates in Application 1.
Figure 4: Comparison of ANA estimator variances in Application 1.
4890Metric Decomposition in A/B Tests KDD ’24, August 25–29, 2024, Barcelona, Spain
Comp
. 1 (Δ1) Comp. 2 ( Δ2) No Decomposition ( Δ) ANA c(Δ∗𝑐) ANA e(Δ∗𝑒) ANA v(Δ∗𝑣) ANA z(Δ∗𝑧) ANA p(Δ∗𝑝)
Signal: V
ar[𝛿] 3.479 0.672 2.193
Noise: Var[𝜀] 0.779 4.096 5.198
Signal-Noise-Ratio 4.466 0.164 0.422
Proportion of Stat. Sig. 13/39 (33.3%) 2/39 (5.1%) 6/39 (15.4%) 13/39 (33.3%) 12/39 (30.8%) 13/39 (33.3%) 13/39 (33.3%) 13/39 (33.3%)
Table 1: Results of Application 1 (Engineering an ANC via Counterfactual Reasoning).
3.2 A Metric
with Natural Multiplicative Decomposition
In the last section we exploited domain knowledge and context-
specific information to engineer an approximately null component.
Here we consider a context in which an ANC arises naturally in a con-
version funnel where the treatment intervention mainly impacts one
step of the funnel and has close to zero impact on the other steps. To
illustrate this, we study the metric nights per guest which quantifies
the number of nights booked per guest. This metric naturally decom-
poses into nights per booking, and bookings per guest. As explained
in Section 1.1, a multiplicative decomposition of percent treatment
effects can be treated as an additive decomposition when the lifts
are expected to be small. In this study, we use the decomposition
Δ%(Nights/Guest)≈ Δ%(Nights/Booking)+ Δ%(Bookings/Guest)
where Δ%(Nights/Booking) is the approximately null component
(Δ2), and Δ%(Bookings/Guest) is the signal component ( Δ1).
We analyze 116 past A/B tests separately with each of the three
metrics: nights per guest, nights per booking, and bookings per
guest. The results are summarized in Table 2. Generally speaking,
the results are very similar to those from the previous application
in Table 1. First, Component 2 (nights per booking) has close to
5% empirical stat. sig. rate (5 out of 116) with a very low SNR of
0.014. Second, Component 1 (bookings per guest) has a much larger
SNR, and higher empirical stat. sig. rate. (30 out of 116). Analysis
with Component 1 also shows better performance than an analysis
without decomposition (i.e., analyzing with respect to nights per
booking), which has just 11 out of 116 stat. sig. results. Further, anal-
yses with all five ANA adjustments give similar results to analyses
with Component 1 alone. As with the previous application, this is
because the optimal 𝜃values (though not pictured here) are close to 0.
3.3 Adjustment of a Surrogate Metric
As discussed in Section 2.3, an important area of related work
that also seeks to increase metric sensitivity is to build a surrogate
or proxy metric. The goal is to use one or more candidate metrics
to form an index to better track the treatment effect of a metric of
interest, or construct a model-based prediction for the metric of
interest using a set of predictors [2, 7, 15, 28].
Let𝑆be a surrogate metric for a metric 𝑀, then this implies a
decomposition
Δ(𝑀)=Δ(𝑆)+Δ(𝑅),
where𝑅=𝑀−𝑆is the residual. Therefore any surrogate metric is
always associated with a decomposition, and the surrogate metric
framework can therefore be seen as a special case of metric decom-
position. Moreover, if a surrogate metric is unbiased, then
E[Δ(𝑀)]=E[Δ(𝑆)],andE[Δ(𝑅)]=0. This means a surrogate without bias is also a decom-
position with null augmentation!4However, in practice we don’t
expect to achieve an unbiased surrogate and instead aim for small
bias; this of course lends itself well to the benefits of approximately
null augmentation. Thus, we advocate for the general use of the
metric decomposition and ANA framework for two reasons:
(1)Defining surrogate metrics and then verifying their small bias is
often harder than directly constructing a decomposition that has
an approximately null effect. The latter is more straightforward
because we can leverage natural decompositions from conver-
sion funnels or leverage domain knowledge and counterfactual
information, as demonstrated in the previous two applications.
(2)Even when a surrogate metric is available, we can always ap-
ply an ANA adjustment to the decomposition implied by the
surrogate and its residual.
This latter point is illustrated in this application where we took
a surrogate metric for booking-per-guest and studied its decompo-
sition across 133 experiments. This surrogate metric utilizes a set of
upper funnel signals to predict a future conversion. It is known that
this type of surrogate metric is only unbiased under strong surrogacy
assumptions [ 2]. Table 3 summarizes the results. Comparing to the
previous two applications, one distinct difference is that Component
2 (the residual) has a noticeably greater SNR (1.044), and a higher
(12.8%, 17 out of 133) stat. sig. rate than the nominal 5% significance
level. This indicates that Component 2 may still contain some treat-
ment effect not fully captured by the surrogate metric (Component
1). Nevertheless, relative to the original (un-decomposed) metric, the
surrogate component has a greater SNR (6.456 vs. 1.794) and higher
statistical power (55 out of 133 stat. sig. results compared to 34 out
of 133).
ANA in this case would create an adjusted estimate of the form
Δ(𝑆)+𝜃[Δ(𝑀)−Δ(𝑆)], that pulls the surrogate metric closer to the
original metric by the factor of 𝜃. Figure 5 displays the optimal ANA
𝜃across these experiments for each of the 5 objectives discussed in
Section 2.2. We see that maximizing correlation and minimizing er-
ror resulted in larger 𝜃ranging from 0.4 to 0.8, and a smaller number
of stat. sig. results (45 out of 133). On the other hand, minimizing
variance, maximizing expected squared Z-score, and maximizing
power resulted in smaller values of 𝜃(ranging between 0 and 0.3) so
the ANA estimator is closer to using the surrogate metric (Compo-
nent 1, Δ1) directly. Interestingly, these latter 3 objectives resulted
in slightly more stat. sig. results than the surrogate metric alone.
3.4 ANA in A/A Tests
In the previous three subsections, we have celebrated an increase
in the number of stat. sig. results when using ANA versus an unde-
composed analysis. However, it’s important to consider whether this
increase in stat. sig. results coincides with an increase in type I error.
4We can also use multiplicative decomposition with 𝑅=𝑀/𝑆andΔ%(𝑀)=
Δ%(𝑆)+Δ%(𝑅).
4891KDD ’24, August 25–29, 2024, Barcelona, Spain Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit Gandhi
Comp
. 1 (Δ1) Comp. 2 ( Δ2) No Decomposition ( Δ) ANA c(Δ∗𝑐) ANA e(Δ∗𝑒) ANA v(Δ∗𝑣) ANA z(Δ∗𝑧) ANA p(Δ∗𝑝)
Signal: V
ar[𝛿] 6.508 0.074 5.198
Noise: Var[𝜀] 2.810 5.321 8.133
Signal-Noise-Ratio 2.316 0.014 0.639
Proportion of Stat. Sig. 30/116 (25.9%) 5/116 (4.3%) 11/116 (9.5%) 30/116 (25.9%) 30/116 (25.9%) 30/116 (25.9%) 30/116 (25.9%) 30/116 (25.9%)
Table 2: Results of Application 2 (Natural Multiplicative Decomposition).
Comp
. 1 (Δ1) Comp. 2 ( Δ2) No Decomposition ( Δ) ANA c(Δ∗𝑐) ANA e(Δ∗𝑒) ANA v(Δ∗𝑣) ANA z(Δ∗𝑧) ANA p(Δ∗𝑝)
Signal: V
ar[𝛿] 1.011 0.352 0.585
Noise: Var[𝜀] 0.157 0.337 0.326
Signal-Noise-Ratio 6.456 1.044 1.794
Proportion of Stat. Sig. 55/133 (41.4%) 17/133 (12.8%) 34/133 (25.6%) 45/133 (33.8%) 45/133 (33.8%) 57/133 (42.9%) 58/133 (43.6%) 58/133 (43.6%)
Table 3: Results of Application 3 (Adjustment of a Surrogate Metric).
Figure 5: Optimal 𝜃for various ANA objectives in Application 3.
Figure 6: Empirical distribution of p-values of an ANA estimator from 1000
A/A tests.
In this section we emphasize that ANA does not increase sensitivity
in general, it increases sensitivity to non-null effects. To demonstrate
that ANA does not inflate type I error, we simulated 1000 A/A tests
(where the treatment effect is truly null) and performed an ANA-
based analysis on each. In particular, we randomly split one experi-
ment’s data into pseudo treatment and control groups 1000 times and
computed p-values for 𝐻0:𝛿=0when the estimator is taken to be Δ∗𝑐
(i.e., ANA to maximize correlation). Figure 6 shows that the p-values
for these tests were uniformly distributed as expected. The empirical
proportions of p-values less than 5% and 10% were respectively 0.05
and 0.105 and hence close to nominal. Though not shown here, other
augmentations yielded similar behavior. This should provide assur-
ance that ANA is not arbitrarily increasing the number of stat. sig.
results; it is instead increasing sensitivity to truly non-null effects.
4 Bayesian View on Metric Decomposition
Here we elaborate on the Bayesian motivation for metric decom-
position. In Section 4.1 we demonstrate theoretically and through
an example that metric decomposition reduces posterior variance.And in Section 4.2, we use simulation to explore the circumstances
under which the variation reduction elicited by decomposition is
large or small.
4.1 Posterior Variance Reduction
The methodology in Section 2, which is predicated on the random
effects model (4), is closely related to a Bayesian analysis where we
posit a prior distribution for 𝛿and perform inference via posterior
analyses [ 6,10,14,16,24,29]. It is well-known that the Bayesian
posterior mean will shrink the observed frequentist point estimate
towards the global mean of the prior, where the shrinkage factor is re-
lated to the signal-to-noise ratio. Given a metric decomposition with
SNR disparity, the Bayesian posterior mean should shrink each com-
ponent very differently, resulting in a posterior mean that depends
more on high SNR components. Of interest is to investigate whether
this new posterior distribution exhibits reduced posterior variance.
We prove here that when we assume 𝜹has a multivariate normal
prior with covariance matrix 𝚲, at least for the two-component case,
the posterior variance of 𝛿conditioned on the bivariate vector 𝚫
cannot exceed the posterior variance of 𝛿conditioned only on the
univariate Δ. This is also true for the general 𝑘>2case when the
noise covariance matrices 𝚺and𝚲are co-linear. These results are
established in Theorem 1 below.
Theorem 1. Metric decomposition naturally leads to variance re-
duction under the Bayesian framework with a Gaussian prior for 𝜹.
The posterior variances of 𝛿conditioned on 𝚫=(Δ1,Δ2)andΔare
respectively
Var[𝛿|𝚫]=1⊺
𝑘(𝚲−𝚲(𝚲+𝚺)−1𝚲)1𝑘,
Var[𝛿|Δ]=1⊺
𝑘𝚲1𝑘×1⊺
𝑘𝚺1𝑘
1⊺
𝑘(𝚲+𝚺)1𝑘.
When𝑘=2, the posterior variance of 𝛿=𝛿1+𝛿2under bivariate
decomposition cannot exceed the univariate posterior variance, i.e.,
Var[𝛿|𝚫]≤Var[𝛿|Δ]. (12)
When𝑘≥2∈N, the above inequality holds strictly when 𝚺=𝑞𝚲for
some scalar constant 𝑞∈R.
The proof is provided in Appendix B. Even though we have not
provedtheinequalityin (12)forgeneral𝑘(withoutthestrongcollinear-
ity assumption), we conjecture the result holds under much milder
assumptions and leave this investigation for future theoretical de-
velopment.
Next we demonstrate this posterior variance reduction in the con-
text of Application 1 from Section 3.1. The results in that section
4892Metric Decomposition in A/B Tests KDD ’24, August 25–29, 2024, Barcelona, Spain
corresponded to frequentist analyses, but we also analyzed each of
the 39 experiments from the Bayesian perspective, in line with Theo-
rem 1. As the theory suggests, the left panel in Figure 7 demonstrates
that with a Gaussian prior, the posterior variance is greatly reduced
with the bivariate decomposition compared to the univariate analy-
sis without decomposition. Furthermore, the right panel in Figure 7
also illustrates that the Bayesian Z-score (posterior mean divided by
posterior standard deviation) tends to have a larger magnitude un-
der the bivariate decomposition. However, this result does not hold
uniformly; 1 of the 39 experiments has a larger Z-score with the non-
decomposed analysis. Thus, Theorem 1 guarantees a variance reduc-
tion, but it does not guarantee an increase in power; sometimes the
reduction in the size of the posterior mean may be substantial enough
to offset the variance reduction achieved with the decomposition.
Figure 7: Comparison of bivariate decomposed vs. univariate non-decomposed
models with respect to posterior variances (left) and Bayesian Z-scores (right).
4.2 Simulation
Illustrating the Benefit of Decomposition
In Section 4.1 we established that the posterior variance of 𝛿when
conditioned on 𝚫cannot be larger than when conditioned on Δ.
However, we did not explore what variation reduction is achievable
by decomposition, nor did we explore when the variation reduction
is negligible. The numerical study presented in this section provides
insights into this. Here we use a more helpful parameterization of
𝚲and𝚺:
𝚲=𝜆111√
𝐾𝜌𝜆√
𝐾𝜌𝜆𝐾
and𝚺=𝜆11"
1/𝑆1√︁
𝐾/(𝑆1𝑆2)𝜌Σ√︁
𝐾/(𝑆1𝑆2)𝜌Σ𝐾/𝑆2#
,
(13)
where𝜆11=Var[𝛿1],𝐾=Var[𝛿2]/𝜆11,𝜌𝜆=Corr[𝛿1,𝛿2],𝜌Σ=
Corr[𝜀1,𝜀2], and𝑆1=Var[𝛿1]/Var[𝜀1]and𝑆2=Var[𝛿2]/Var[𝜀2]
are signal-to-noise ratios. We can freely vary these parameters and
still satisfy the Cauchy-Schwarz inequality.
Here we compare the posterior variances in the decomposed and
un-decomposed models for each combination of the following pa-
rameter values:
•𝐾,𝑆1,𝑆2={0.01,0.11,...,0.91,1.01,2,3,4,5}
•𝜌𝜆,𝜌Σ={−0.975,−0.925,...,0.975}
Because changing the value for 𝜆11just scales 𝚲and𝚺by the same
constant, we do not consider it in our simulations. For each of these
5.4×106combinations, we computed the ratio of variances in the
posteriors that do and do not account for the bivariate decomposi-
tion. As expected, we found the variances to be equal when 𝜌𝜆=𝜌Σ
and𝑆1=𝑆2. Under these conditions, 𝚺=𝑞𝚲.Across the 5.4×106parameter combinations, we found that vari-
ance reduction is greatest when three conditions are satisfied: the
signal-to-noise ratios 𝑆1and𝑆2differ substantially, |𝜌𝜆|is large, and
|𝜌Σ|is large. To summarize, we visualize the magnitude of the vari-
ancereductionfactorundervariousscenarioswheretheseconditions
are and are not satisfied. Figure 8 plots the density curves of the vari-
ance reduction factor under several scenarios with small and large
|𝜌𝜆|and|𝜌Σ|when|𝑆1−𝑆2|>2. In all such scenarios, the SNRs differ
substantially. As expected, the median reduction factor is largest in
the top left plot, where |𝜌𝜆|and|𝜌Σ|are large. The plots on the off-
diagonals consider scenarios where only one of |𝜌𝜆|or|𝜌Σ|is large.
Figure 8 suggests that strong correlation between 𝛿1and𝛿2is more
beneficial than strong correlation between 𝜀1and𝜀2. The median vari-
ance reduction factor is smallest in the bottom right plot, where |𝜌𝜆|
and|𝜌Σ|are small. Moreover, we find that when SNRs are relatively
similar (i.e.,|𝑆1−𝑆2|<0.1), analogous plots (See Appenix C) indi-
cate minimal variance reduction, no matter the values of |𝜌𝜆|or|𝜌Σ|.
These results suggest that discrepancies (or the lack thereof) between
the SNRs play a greater role than |𝜌𝜆|or|𝜌Σ|in variance reduction.
Figure 8: Density curves of the variance reduction factor for several conditions
when signal-to-noise ratios differ substantially. Median reduction factors are
given by the dashed vertical lines and annotated text.
5 Conclusion & Discussion
In this paper we have proposed metric decomposition as a novel
means to improve metric sensitivity in online A/B tests. The idea
is premised upon the decomposition of a target metric into two or
more components that differ with respect to their signal-to-noise
ratios. We show through theory, simulation, and empirical examples
that if such a decomposition exists (or can be engineered), sensi-
tivity may be increased via approximately null augmentation (in a
frequentist setting) and posterior variance is reduced (in a Bayesian
setting). We provide practical guidance for, and discuss the implica-
tions of, metric decomposition in both settings. We also contrast it
with industry-favorite alternatives like CUPED, and in doing so high-
light its broad utility. An important extension to this work would be
to next consider sample size determination in both the frequentist
or Bayesian contexts; while a boost in sensitivity typically means
less data is required for a given analysis, a methodology that deter-
mines the smallest sample size required to control various operating
characteristics in this context would be of practical value.
4893KDD ’24, August 25–29, 2024, Barcelona, Spain Alex Deng, Luke Hagar, Nathaniel T. Stevens, Tatiana Xifara, and Amit Gandhi
References
[1] Soren Asmussen and Peter Glynn. 2008. Stochastic Simulation. Springer-Verlag.
[2]Susan Athey, Raj Chetty, Guido W Imbens, and Hyunseung Kang. 2019. The surro-
gate index: Combining short-term proxies to estimate long-term treatment effects more
rapidly and precisely. Technical Report. National Bureau of Economic Research.
[3]Iavor Bojinov and Somit Gupta. 2022. Online Experimentation: Benefits,
Operational and Methodological Challenges, and Scaling Guide. Harvard Data
Science Review 4, 3 (jul 28 2022). https://hdsr.mitpress.mit.edu/pub/aj31wj81.
[4]Laura Cosgrove, Jen Townsend, and Jonathan Litz. [n. d.]. Deep Dive Into Variance
Reduction. https://www.microsoft.com/en-us/research/group/experimentation-
platform-exp/articles/deep-dive-into-variance-reduction/.
[5]Tom Cunningham. 2023. Experiment Interpretation and Extrapolation.
https://tecunningham.github.io/posts/2023-04-18-experiment-interpretation-
extrapolation.html
[6]Alex Deng. 2015. Objective Bayesian Two Sample Hypothesis Testing for Online
Controlled Experiments. In Proceedings of the 24th International Conference on
World Wide Web Companion. 923–928.
[7]Alex Deng, Michelle Du, Anna Matlin, and Qing Zhang. 2023. Variance Reduction
Using In-Experiment Data: Efficient and Targeted Online Measurement for Sparse
and Delayed Outcomes. In Proceedings of the 29th ACM SIGKDD Conference on
Knowledge Discovery and Data Mining. 3937–3946.
[8]Alex Deng and Victor Hu. 2015. Diluted treatment effect estimation for trigger
analysis in online controlled experiments. In Proceedings of the Eighth ACM
International Conference on Web Search and Data Mining. 349–358.
[9]Alex Deng, Ulf Knoblich, and Jiannan Lu. 2018. Applying the Delta Method in
Metric Analytics: A Practical Guide with Novel Ideas. In Proceedings of the 24th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
(London, United Kingdom) (KDD ’18). ACM, New York, NY, USA, 233–242.
[10] Alex Deng, Yicheng Li, Jiannan Lu, and Vivek Ramamurthy. 2021. On Post-
selection Inference in A/B Testing. In Proceedings of the 27th ACM SIGKDD
Conference on Knowledge Discovery & Data Mining. 2743–2752.
[11] Alex Deng and Xiaolin Shi. 2016. Data-driven metric development for online
controlled experiments: Seven lessons learned. In Proceedings of the 22nd ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining.
[12] Alex Deng, Ya Xu, Ron Kohavi, and Toby Walker. 2013. Improving the sensitivity
of online controlled experiments by utilizing pre-experiment data. In Proceedings
of the 6th ACM WSDM Conference. 123–132.
[13] Alex Deng, Lo-Hua Yuan, Naoya Kanai, and Alexandre Salama-Manteau. 2023.
Zero to hero: Exploiting null effects to achieve variance reduction in experiments
with one-sided triggering. In Proceedings of the Sixteenth ACM International
Conference on Web Search and Data Mining. 823–831.
[14] Drew Dimmery, Eytan Bakshy, and Jasjeet Sekhon. 2019. Shrinkage Estimators
in Online Experiments. In Proceedings of the 25th ACM SIGKDD International
Conference on Knowledge Discovery & Data Mining. 2914–2922.
[15] Weitao Duan, Shan Ba, and Chunzhe Zhang. 2021. Online Experimentation with
Surrogate Metrics: Guidelines and a Case Study. In Proceedings of the 14th ACM
International Conference on Web Search and Data Mining. 193–201.
[16] Bradley Efron. 2010. Large-scale Inference: Empirical Bayes Methods for Estimation,
Testing and Prediction. Cambridge University Press.
[17] Michael R Elliott, Anna SC Conlon, Yun Li, Nico Kaciroti, and Jeremy MG Taylor.
2015. Surrogacy marker paradox measures in meta-analytic settings. Biostatistics
16, 2 (2015), 400–412.
[18] Andrew Gelman and John Carlin. 2014. Beyond power calculations: Assessing
type S (sign) and type M (magnitude) errors. Perspectives on Psychological Science
9, 6 (2014), 641–651.
[19] Andrew Gelman and Jennifer Hill. 2006. Data analysis using regression and
multilevel/hierarchical models. Cambridge University Press.
[20] Somit Gupta et al .2019. Top Challenges from the First Practical Online Controlled
Experiments Summit. SIGKDD Explor. Newsl. 21, 1 (May 2019), 20–35.
[21] Ron Kohavi, Alex Deng, and Lukas Vermeer. 2022. A/B Testing Intuition Busters:
Common Misunderstandings in Online Controlled Experiments. In Proceedings
of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
3168–3177.
[22] Ron Kohavi, Diane Tang, and Ya Xu. 2020. Trustworthy online controlled
experiments: A practical guide to a/b testing. Cambridge University Press.
[23] Nicholas Larsen, Jonathan Stallrich, Srijan Sengupta, Alex Deng, Ron Kohavi, and
Nathaniel T Stevens. 2023. Statistical challenges in online controlled experiments:
A review of a/b testing methodology. The American Statistician (2023), 1–15.
[24] Sareh Nabi, Houssam Nassif, Joseph Hong, Hamed Mamani, and Guido Imbens.
2022. Bayesian meta-prior learning using Empirical Bayes. Management Science
68, 3 (2022), 1737–1755.
[25] Art B Owen. 2013. Monte Carlo theory, methods and examples. (2013).
[26] Alexander Peysakhovich and Dean Eckles. 2018. Learning causal effects from
many randomized experiments using regularized instrumental variables. In
Proceedings of the 2018 World Wide Web Conference. 699–707.
[27] Daniel Ting and Kenneth Hung. 2023. On the Limits of Regression Adjustment.
arXiv preprint arXiv:2311.17858 (2023).[28] Nilesh Tripuraneni, Lee Richardson, Alexander D’Amour, Jacopo Soriano, and
Steve Yadlowsky. 2023. Choosing a Proxy Metric from Past Experiments. arXiv
preprint arXiv:2309.07893 (2023).
[29] Runzhe Wan, Yu Liu, James McQueen, Doug Hains, and Rui Song. 2023. Exper-
imentation platforms meet reinforcement learning: Bayesian sequential decision-
making for continuous monitoring. arXiv preprint arXiv:2304.00420 (2023).
Appendix
A ANA Derivations
Consider ANA estimators Δ∗:=𝒄⊺𝚫, where 𝒄⊺𝒆1=1for the stan-
dard basis vector 𝒆1. Let𝒄∗be the final𝑘−1components of 𝒄and𝚲∗
be the(𝑘−1)×(𝑘−1)submatrix of 𝚲corresponding to(𝛿2,...,𝛿𝑘).
Let𝚺∗and be the(𝑘−1)×(𝑘−1)submatrix of 𝚺corresponding to
(𝜀2,...,𝜀𝑘). Let𝚺1=(Σ12,...,Σ1𝑘).
Minimizing Mean Squared Error. We have that
E
(𝛿−Δ∗)2
=Eh
(1⊺
𝑘𝜹−𝒄⊺(𝜹+𝜺))2i
=E
((1𝑘−𝒄)⊺𝜹−𝒄⊺𝜺)2
=E[((1𝑘−𝒄)⊺𝜹𝜹⊺(1𝑘−𝒄)−2(1𝑘−𝒄)⊺𝜹𝜺⊺𝒄+𝒄⊺𝜺𝜺⊺𝒄]
=(1𝑘−𝒄)⊺𝚲(1𝑘−𝒄)+𝒄⊺𝚺𝒄
=(1𝑘−1−𝒄∗)⊺𝚲∗(1𝑘−1−𝒄∗)+Σ11+2𝒄⊺
∗𝚺1+𝒄⊺
∗𝚺∗𝒄∗.(A.1)
The penultimate step follows because 𝜹and𝜺are independent, and
the final equality holds because 𝒄⊺𝒆1=1. The derivative of (A.1) with
respect to 𝒄∗is
𝜕
𝜕𝒄∗E
(𝛿−Δ∗)2
=−2𝚲∗(1𝑘−1−𝒄∗)+2𝚺1+2𝚺∗𝒄∗. (A.2)
The value for 𝒄∗that equates the expression in (A.2) to 0and hence
minimizes mean squared error is
𝒄∗=
𝚲∗+𝚺∗−1
𝚲∗1𝑘−1−𝚺1
. (A.3)
The value of 𝜃given in (6)is obtained as a special case when 𝑘=2
and𝒄=(1,𝜃)⊺. □
Maximizing Correlation. We have that
Corr 𝛿,Δ∗=Cov(1⊺
𝑘𝜹,𝒄⊺𝚫)
√︃
Var(1⊺
𝑘𝜹)√︁
Var(𝒄⊺𝚫)
=1⊺
𝑘𝚲𝒄
√︃
1⊺
𝑘𝚲1𝑘√︁
𝒄⊺(𝚲+𝚺)𝒄.(A.4)
To maximize (A.4), we take the partial derivative
𝜕
𝜕𝒄(1⊺
𝑘𝚲𝒄)2
𝒄⊺(𝚲+𝚺)𝒄=2(1⊺
𝑘𝚲𝒄)𝚲1𝑘𝒄⊺(𝚲+𝚺)𝒄−2(𝚲+𝚺)𝒄(1⊺
𝑘𝚲𝒄)2
(𝒄⊺(𝚲+𝚺)𝒄)2.
(A.5)
Equating the numerator of (A.5) to 0prompts the following result:
(𝚲+𝚺)−1𝚲1𝑘=1⊺
𝑘𝚲𝒄
𝒄⊺(𝚲+𝚺)𝒄×𝒄. (A.6)
Since the scaling constant to the left of the ×sign in (A.6) is ap-
plied to each component of 𝒄, we have that 𝑺⊺1𝑘∝𝒄. To enforce the
constraint that 𝒄⊺𝒆1=1, we require
𝒄=1
𝒆⊺
1𝑺⊺1𝑘𝑺⊺1𝑘. (A.7)
This is the augmentation that maximizes correlation. The value of 𝜃
given in (7)is obtained as a special case when 𝑘=2and𝒄=(1,𝜃)⊺.□
Minimizing Error Variance. We have that
Var[𝒄⊺𝜺]=𝒄⊺𝚺𝒄
=Σ11+2𝒄⊺
∗𝚺1+𝒄⊺
∗𝚺∗𝒄∗(A.8)
4894Metric Decomposition in A/B Tests KDD ’24, August 25–29, 2024, Barcelona, Spain
The final equality holds because 𝒄⊺𝒆1=1. The derivative of (A.8)
with respect to 𝒄∗is
𝜕
𝜕𝒄∗Var[𝒄⊺𝜺]=2(𝚺1+𝚺∗𝒄∗). (A.9)
The value for 𝒄∗that equates the expression in (A.9) to 0and hence
minimizes the error variance is
𝒄∗=−𝚺−1
∗𝚺1. (A.10)
The value of 𝜃given in (8)is obtained as a special case when 𝑘=2
and𝒄=(1,𝜃)⊺. □
Maximizing Expected Squared Z-Score. The expected squared
Z-score has the form:
Var[Δ∗]
Var[𝒄⊺𝜺]=𝒄⊺(𝚲+𝚺)𝒄
𝒄⊺𝚺𝒄
=[𝚺1/2𝒄]⊺[𝚺−1/2(𝚲+𝚺)𝚺−1/2][𝚺1/2𝒄]
[𝚺1/2𝒄]⊺[𝚺1/2𝒄].(A.11)
Let𝒙=𝚺1/2𝒄, and (A.11) is a Rayleigh quotient maximized when 𝒙is
any multiple of the first eigenvector of the matrix 𝚺−1/2(𝚲+𝚺)𝚺−1/2.
Let𝒙∗be this eigenvector. Then it is easy to see
𝒄=1
𝒆⊺
1𝚺−1/2𝒙∗𝚺−1/2𝒙∗. (A.12)
The value of 𝜃given in (9)is obtained as a special case when 𝑘=2
and𝒄=(1,𝜃)⊺. □
Maximizing Power. For a specific value ¤𝜹=(¤𝛿1,...,¤𝛿⊺
𝑘)from the
𝜹distribution specified by model (4), the test statistic for testing
𝐻0:𝛿=0is given by
𝒄⊺¤𝜹√
𝒄⊺𝚺𝒄=¤𝛿1+𝒄⊺
∗¤𝜹∗√︁
Σ11+2𝒄⊺
∗𝚺1+𝒄⊺
∗𝚺∗𝒄∗(A.13)
where¤𝜹∗is the final𝑘−1components of¤𝜹. This equality holds
because 𝒄⊺𝒆1=1. The derivative of (A.13) with respect to 𝒄∗is
¤𝜹⊺
∗(Σ11+2𝒄⊺
∗𝚺1+𝒄⊺
∗𝚺∗𝒄∗)−(¤𝛿1+𝒄⊺
∗¤𝜹∗)(𝚺⊺
1+𝒄⊺
∗𝚺∗)
(Σ11+2𝒄⊺
∗𝚺1+𝒄⊺
∗𝚺∗𝒄∗)3/2(A.14)
The value for 𝒄∗that equates the expression in (A.14) to 0and hence
maximizes power is
𝒄∗=−
𝚺1¤𝜹⊺
∗−¤𝛿1𝚺∗−1
Σ11¤𝜹∗−¤𝛿1𝚺1
. (A.15)
The value of 𝜃given in (10)is obtained as a special case when 𝑘=2
and𝒄=(1,𝜃)⊺. □
B Proof of Theorem 1
For this proof, we use the following parameterization for 𝚲and𝚺:
𝚲=𝐿2𝐿√𝜆22𝜌𝜆
𝐿√𝜆22𝜌𝜆𝜆22
and𝚺=Σ11Σ12
Σ12Σ22
.
That is,𝐿=√𝜆11. This parameterization allows us to freely vary 𝐿
across R+while satisfying the Cauchy-Schwarz inequality. We now
show that each side of the inequality in (12) can be expressed as the
ratio of two quadratic functions of 𝐿.
For the left side of (12), we show that 1⊺
2(𝚲−𝚲(𝚲+𝚺)−1𝚲)12takes
the form
𝑏1𝐿2+𝑏2𝐿+𝑏3
𝑏4𝐿2+𝑏5𝐿+𝑏6. (B.1)
Through simple algebra, we can show that 𝑏1=𝜆22(1−𝜌2
𝜆)(Σ11+
2Σ12+Σ22)+Σ11Σ22−Σ2
12,𝑏2=2√𝜆22𝜌𝜆(Σ11Σ22−Σ2
12), and𝑏3=
𝜆22(Σ11Σ22−Σ2
12). The denominator of (B.1) is the determinant of
𝚲+𝚺; it takes the form 𝑏4𝐿2+𝑏5𝐿+𝑏6, where𝑏4=𝜆22(1−𝜌2
𝜆)+Σ22,
𝑏5=−2√𝜆22𝜌𝜆Σ12, and𝑏6=Σ11𝜆22+Σ11Σ22−Σ2
12.The algebra is simpler to show the right side of (12) takes the form
𝑏7𝐿2+𝑏8𝐿+𝑏9
𝑏10𝐿2+𝑏11𝐿+𝑏12. (B.2)
That numerator 1⊺
2𝚲12×1⊺
2𝚺12is such that 𝑏7=Σ11+2Σ12+Σ22,
𝑏8=2√𝜆22𝜌𝜆(Σ11+2Σ12+Σ22), and𝑏9=𝜆22(Σ11+2Σ12+Σ22). That
denominator 1⊺
2(𝚲+𝚺)12can be expressed as 𝑏10𝐿2+𝑏11𝐿+𝑏12,
where𝑏10=1,𝑏11=2√𝜆22𝜌𝜆, and𝑏12=𝜆22+Σ11+2Σ12+Σ22. The de-
nominator of (B.1) must be non-negative due to the Cauchy Schwarz
inequality:𝑏4𝐿2+𝑏5𝐿+𝑏6≥0for all𝐿≥0. Moreover, the denominator
of (B.2) is a variance, so 𝑏10𝐿2+𝑏11𝐿+𝑏12≥0for all𝐿≥0.
We can therefore cross multiply the fractions in (B.1) and (B.2) to
obtain an equivalent inequality to (12) that is a quartic equation of 𝐿:
𝑎𝐿4+𝑏𝐿3+𝑐𝐿2+𝑑𝐿+𝑒≥0, (B.3)
where𝑎=(Σ12+Σ22)2≥0,𝑏=2√𝜆22𝜌𝜆(Σ22−Σ11)(Σ12+Σ22),
𝑐=𝜆22(𝜌2
𝜆(Σ11−Σ22)2−2(Σ11+Σ12)(Σ12+Σ22)),𝑑=2𝜆3/2
22𝜌𝜆(Σ11−
Σ22)(Σ11+Σ12),and𝑒=𝜆2
22(Σ11+Σ12)2.If(B.3)holdstrueforall 𝐿≥0,
then the bivariate variance of 𝛿cannot exceed the univariate variance
(i.e., the inequality in (12) also holds true). It can be shown via algebra
that the coefficients in (B.3) satisfy 𝐷=64𝑎3𝑒−16𝑎2𝑐2+16𝑎𝑏2𝑐−
16𝑎2𝑏𝑑−3𝑏4=0. This result implies that (B.3) has two double roots.
Because the leading coefficient 𝑎≥0, the quartic equation in (B.3) is
non-negative for all 𝐿≥0. Theorem 1 follows directly from this result.
□
C Additional Simulation Plot
Figure 9: Density curves of the variance reduction factor for several conditions
when signal-to-noise ratios do not differ substantially. Median reduction
factors are given by the dashed vertical lines and annotated text.
4895