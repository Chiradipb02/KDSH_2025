Explainable Artificial Intelligence on Biosignals
for Clinical Decision Support
Miriam Cindy Maurer‚àó
Department of Medical Informatics
University Medical Center
Campus Institut Data Science
G√∂ttingen, GermanyJacqueline Michelle Metsch
Department of Medical Informatics
University Medical Center
G√∂ttingen, GermanyPhilip Hempel
Department of Medical Informatics
University Medical Center
G√∂ttingen, Germany
Theresa Bender
Department of Medical Informatics
University Medical Center
German Centre for Cardiovascular
Research
G√∂ttingen, GermanyNicolai Spicher
Department of Medical Informatics
University Medical Center
German Centre for Cardiovascular
Research
Campus Institute Data Science
G√∂ttingen, GermanyAnne-Christin Hauschild
Department of Medical Informatics
University Medical Center G√∂ttingen
Campus Institut Data Science
G√∂ttingen, Germany
Abstract
Deep learning has proven effective in several areas, including com-
puter vision, natural language processing, and disease prediction,
which can support clinicians in making decisions along the clin-
ical pathway. However, in order to successfully integrate these
algorithms into clinical practice, it is important that their decision-
making processes are transparent, explainable, and interpretable.
Firstly, this tutorial will introduce targeted eXplainable Artificial
Intelligence (XAI) methods to address the urgent need for explain-
ability of deep learning in healthcare applications. In particular,
it focuses on algorithms for raw biosignals without prior feature
extraction that enable medical diagnoses, specifically electrocardio-
grams (ECG) ‚Äì stemming from the heart ‚Äì and electroencephalo-
grams (EEG) representing the electrical activity of the brain. Sec-
ondly, participants are provided with a comprehensive workflow
that includes both data processing and an introduction to relevant
network architectures. Subsequently, various XAI methods are de-
scribed and it is shown, how the resulting relevance attributions
can be visualized on biosignals. Finally, two compelling real-world
use cases are presented that demonstrate the effectiveness of XAI
in analyzing ECG and EEG signals for disease prediction and sleep
classification, respectively. In summary, the tutorial will provide
the skills required for gaining insight into the decision process of
deep neural networks processing authentic clinical biosignal data.
Keywords
Explainable AI, Pytorch, Biosignals, Electrocardiogram, Electroen-
cephalogram
‚àóCorresponding Author: Miriam Cindy Maurer, miriamcindy.maurer@med.uni-
goettingen.de
This work is licensed under a Creative Commons Attribution
International 4.0 License.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s).
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671459ACM Reference Format:
Miriam Cindy Maurer, Jacqueline Michelle Metsch, Philip Hempel, Theresa
Bender, Nicolai Spicher, and Anne-Christin Hauschild. 2024. Explainable
Artificial Intelligence on Biosignals for Clinical Decision Support. In Pro-
ceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and
Data Mining (KDD ‚Äô24), August 25‚Äì29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 8 pages. https://doi.org/10.1145/3637528.3671459
1 Introduction
The increasing availability of large-scale biomedical datasets of-
fered by initiatives such as PhysioNet [ 12] or the UK Biobank [ 43]
led to a surge of artificial intelligence (AI) methods in recent years.
Applications range from classification ‚Äì in most cases the diagnosis
of a disease [ 22] ‚Äì to more complex tasks, e.g. the prediction of clin-
ical lab measurements or patient risk assessment [ 19,30]. However,
there are multiple challenges currently in the way of a widespread
translation of these methods to clinical practice. On the one hand,
there are legislative and regulatory hurdles that are currently being
shaped in frameworks such as the EU AI Act [ 27]. On the other
hand, trustworthiness is a major road block for the usage of AI
methods in clinical practice. As these methods are assumed to be
‚Äùblack boxes‚Äù w.r.t. diagnosis and treatment, they are hardly used
as clinicians need to be able to comprehend their reasoning. In
particular, when wrong decisions would have direct negative con-
sequences for patients, a transparent explanation of the reasoning
process is required, which is still lacking in many applications.
Specifically, this work is organised as follows: In sections 1.1
and 1.2, we introduce and discuss relevant considerations when
working with biomedical data. In particular, we focus on biosignals
‚Äì which are non-invasive signals measured by electrodes ‚Äì that
are distinct from other types of medical data, such as electronic
health records or medical images. We also give a state of the art
overview of XAI methods commonly used in this area of research.
In section 2, we provide a schematic workflow of the whole process
of applying XAI to biosignal data, starting with the selection of
a deep learning model and ending with the interpretation of the
computed relevances. In section 3, this schematic workflow is ap-
plied in two practical use cases: electrocardiography (ECG) and
6597
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Miriam Cindy Maurer et al.
Figure 1: Electrocardiogram acquired over 2.5s from a healthy
volunteer. The six limb leads (I,II,III,aVR,aVL,aVF) and six
chest leads (V1-V6) were acquired in parallel, i.e. three heart
beats are depicted. The three most visually obvious parts of
the signals are the so-called QRS complexes that correspond
to the depolarization of the ventricles.
0.0 5.0 10.0 15.0 20.0 25.0
secondsC3_M2
C4_M1
F3_F4
F3_M2
F4_O2
F3_O1
O1_M2
O2_M1
EMG
EOG1
EOG2
Figure 2: Example of a polysomnogram segment of 30seconds
from [ 14] showing deep sleep (sleep stage N3). The first eight
channels show EEG data, the EMG is measured with a chin
electrode.
electroencephalography (EEG) processing. The former focuses on
the detection of cardiac diseases, while the latter focuses on the
classification of sleep segments. This work is concluded in section
4 where we also give some recent trends in the field.
1.1 Introduction to Biosignals
Physiological time series ‚Äì often entitled "biosignals" ‚Äì refer to
signals measured from humans over time. Examples include ECG,
which is a measurement of the electrical activity of the human heart
from the voltages on the skin or EEG, which measures the electrical
activity of the brain from electrodes attached to the head. Typically,
these measurements are done in a clinical context, e.g. for diagnosis
of a disease, monitoring of patients in critical or acute care in urgent
cases such as suspected heart attack. Other physiological entities
that can be measured are muscle activity, skin resistance, blood
volume changes, blood pressure, and many more.
1.1.1 Sensor Technology. ECG is a standard method for assessment
of the heart‚Äôs activity as it is cheap, has minimal risks and is easyto acquire. In the clinical context, it is used in most cases for a 10s
long measurement from ten different electrodes which are attached
to the chest, legs, and arms. As can be seen in Figure 1, voltages
reach values up to 2.5mV and depending on the combination of
electrodes ‚Äì called leads ‚Äì the signals have a different shape. For
intermittent health problems, such as irregular heart beats, long-
term measurements over several days with a reduced number of
electrodes are used. Recently, unobtrusive, cable-free applications
have become popular; e.g. the Apple Watch provides a single-lead
measurement and there are patches that can be attached to the
patient‚Äôs chest available for measurements over several days.
Similar to the ECG, the EEG measures electrical activity, but
from the human skull to assess brain activity. However, the voltages
involved are much lower and in the order of 50ùúáV. In a standard
clinical setting using the ‚Äù10-20 system‚Äù, 21electrodes are placed on
the scalp for a duration of 20‚àí30minutes. To account for artefacts
in measurements from eye movement and the activity of the heart,
ECG and electrooculography (EOG) are often measured in parallel
to remove these signals from the EEG.
As depicted in Figure 2, polysomnographies measure all of these
biosignals simultaneously throughout the night to assess sleep
quality and diagnose sleep disorders. Since many of these disorders
affect breathing, additional biosignals such as muscle activities from
the chin are included, measured as electromyograms (EMGs).
Recently, there has been a trend towards long-term monitoring
outside the clinic which is especially important for diagnosing rare
but serious medical problems such as epileptic seizures.
1.1.2 Interpretation of Biosignals. Biosignals are different to many
other types of biomedical data (e.g. electronic healthcare records,
lab results, medical imaging) due to their i) temporal ordering, ii)
high sampling frequencies, and iii) multiple measurements of the
same organ (e.g. heart, brain) but with multiple sensors. In addition,
iv) many biosignals interfere with each other, e.g. ECG curves are
also influenced by the breathing of the patient. These issues make
the interpretation of biosignals by humans as well as AI a challenge.
As an example, Figure 1 shows all 12 leads of the ECG signals of
a healthy volunteer. The interpretation of the EEG is even more
challenging as they are purely stochastic signals, i.e. they do not
have clear features such as the well visible QRS complex in the
ECG. EEG signals can therefore only be characterized by statistical
means.
1.2 Introduction to XAI
Explainable Artificial Intelligence (XAI) is a field of artificial intel-
ligence research that aims to make AI systems more transparent,
understandable, and trustworthy to humans. The ‚Äôblack box‚Äô na-
ture of AI models, especially those based on deep learning, has
raised concerns as they become more complex and essential to
decision-making in various sectors, including healthcare, finance,
autonomous vehicles, and personalized education. These concerns
relate to the challenge of comprehending how AI models arrive at
their conclusions, the possibility of bias in their decisions, and the
difficulty of validating their reliability and safety. XAI methods aim
to enhance transparency by making the internal workings of AI
models visible and understandable to humans. They also aim to
improve comprehensibility by ensuring that the reasoning behind
6598Explainable Artificial Intelligence on Biosignals
for Clinical Decision Support KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
AI decisions is clear and interpretable to users, regardless of their
technical expertise. To use AI systems in the medical field, it is
essential to demonstrate their fairness, reliability, and compliance
with ethical standards to increase trust in these models.
Although XAI methods aim to clarify AI decisions, several chal-
lenges still exist. These include balancing the trade-off between
model complexity and interpretability, ensuring that explanations
are not only technically accurate but also meaningful to end-users,
and developing standard metrics for evaluating explainability.
1.2.1 XAI Taxonomy (Ante-hoc vs. Post-hoc). XAI methods can
be broadly categorized into ante-hoc and post-hoc methods, as
shown in Figure 3. These refer to the timing of the explanation
process relative to the model‚Äôs decision-making process. Ante-hoc
or transparent methods are interpretable by design and provide
explanations as part of their training process, ensuring that the
model itself can generate explanations for its decision. "Glass-box"
models such as regression, naive Bayes, or decision trees are ante-
hoc interpretable. However, their usefulness is often limited by
the fact that they cannot match the performance of deep neural
networks (DNN), leading to a trade-off between performance and
explainability.
This limitation necessitates the use of post-hoc methods that
attempt to explain predictions made by "black box" models without
explaining the exact internal mechanism of the model. Due to the
complexity of DNNs, post-hoc methods are the only way to interpret
these types of models.
Moreover, post-hoc explanation methods can be further distin-
guished into local and global explanations, which refer to individual
predictions or the overall behavior of the model. For global explana-
tions, these methods provide aggregated, ranked contributions of
input variables for the entire model. They provide a better overview
of the whole prediction space of the model, but suffer from lower
accuracy due to aggregation, e.g. by using averages. In contrast,
local explanations focus on the interpretability of individual pre-
dictions or small parts of the model‚Äôs prediction space. Although
they provide greater precision in understanding model behavior,
they are often less retrievable. Examples of local explanation meth-
ods include perturbation-based methods and layer-wise relevance
propagation[6] methods.
Furthermore, the distinction between model agnostic and model
specific methods is critical to understanding the scope of explana-
tory methods. Model agnostic methods can be applied to any model,
including "black box" models, without worrying about the internal
structure of the model. These methods tend to be less precise, but
only because they explain the behaviour of the model in terms of
inputs and outputs. On the other hand, model-specific methods
are associated with a particular type of model. The type is loosely
defined and can refer to the whole domain, such as DNNs [39].
1.2.2 Need for XAI in Biosignal Processing. The importance of XAI
in biosignal processing is particularly crucial due to the high stakes
involved in healthcare decisions and the complex nature of biosig-
nals such as EEGs, ECGs, and EMGs. Biosignal processing entails
interpreting physiological signals to diagnose diseases, monitor
health status, and guide treatment decisions. Misdiagnosis and in-
correct treatment are an integral part of the medical system and
must be constantly monitored. The reason for such errors lies in
Figure 3: XAI Taxonomy, created with BioRender
both human and technical error [ 13]. If healthcare professionals
want to rely on AI-based diagnoses or treatment recommendations,
they need to trust the underlying technology and factor in the po-
tential for failure. Examples of such failures are when AI systems
learn shortcuts that are not based on disease-related characteristics
of the biosignals but on other peculiarities in the data structures [ 8].
XAI can bridge this gap by providing clear explanations for AI
decisions, thus fostering trust among clinicians and facilitating
wider adoption in clinical practice. More importantly, it can assist
in identifying and correcting model biases or errors, ensuring the
safety and reliability of AI-assisted diagnoses and treatments.
Furthermore, regulatory bodies are increasingly demanding trans-
parency in medical devices, including software algorithms [ 1]. XAI
can play a crucial role in meeting these regulatory requirements by
making AI models more interpretable and their decisions traceable.
Finally, since biosignals are complex and high-dimensional, XAI
can help clarify the way AI models process such data. This pro-
vides insights into the significance of various signal features and
their relation to health outcomes. Therefore, XAI techniques can
uncover new insights and patterns in biosignal data that may not
be noticeable to human experts, which can potentially lead to the
discovery of novel biomarkers for diseases [52].
2 XAI Workflow
In the following, we show the XAI workflow on raw biosignals
without prior feature extraction, including DNN characteristics,
different XAI methods, and their evaluation.
2.1 AI Models suited for Biosignals
DNNs are widely used for biosignal analysis, particularly for signals
that can be represented in a time-frequency domain, allowing the
network to capture spatial and temporal features [ 24]. DNNs can
identify important patterns and characteristics (such as specific
waveforms, shapes, and temporal dynamics) directly from raw sig-
nals without the need for manual feature engineering. Biosignals
6599KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Miriam Cindy Maurer et al.
often contain significant spatial and temporal structures. DNNs can
process data while preserving these structures, making them par-
ticularly suitable for biosignals like EEG or ECG, where the spatial
arrangement of electrodes and the temporal progression of sig-
nals carry important information for tasks like anomaly detection,
patient monitoring, and diagnosis.
Recurrent Neural Network (RNNs) and Long Short-Term Memory
Network (LSTMs) architectures are suitable for sequential data like
biosignals, capturing dependencies in time-series data effectively
[9]. One of the primary strengths of LSTMs is their ability to re-
member information for long periods. This is crucial for biosignal
data, where the relevance of a particular feature or pattern may
depend on data points that occurred far back in the sequence. Tra-
ditional RNNs struggle with long-term dependencies due to the
vanishing gradient problem, but LSTMs overcome this with their
gating mechanisms. Biosignals often contain critical information in
their temporal dynamics, such as the rhythm in an ECG signal or
the temporal evolution of brain activity in an EEG recording. LSTMs
are adept at capturing these dynamics, enabling the analysis and
prediction of physiological states, disorders, or patient responses
over time.
Attention Mechanisms andTransformers [51] have recently been
applied to biosignal processing, providing the ability to focus on
specific parts of the signal that are more informative for the task
[49]. Unlike traditional RNNs and even LSTMs that process data
sequentially, transformers can handle entire sequences at once.
This allows them to capture long-range dependencies in biosignals
more effectively, as they can process and relate distant points in the
sequence directly without step-wise propagation, which is particu-
larly beneficial for understanding the full context of physiological
signals.
Graph Neural Networks (GNNs) offer a powerful framework to
model the complex relationships and structures within data, that
can be naturally represented as graphs (e.g., brain connectivity
networks from EEG) [ 54]. GNNs excel at capturing complex rela-
tionships and interactions between nodes in a graph. For biosig-
nal analysis, this means they can effectively model the intricate
physiological networks underlying the data, such as the functional
connectivity between different regions of the brain or the interac-
tion between different muscles in EMG data. GNNs can incorporate
spatial information about the nodes, which is particularly useful
for biosignals recorded from spatially distributed sensors. For in-
stance, in EEG analysis, the spatial arrangement of electrodes over
the scalp can be critical for interpreting the signals. GNNs can
use this spatial information to better understand the underlying
physiological processes.
2.2 Generating XAI Attributions
XAI methods are increasingly applied to biosignal data analysis to
understand how machine learning models, especially deep learning
models, make decisions based on physiological signals [ 7,47,50].
Biosignal data, such as EEG, ECG, EMG, and others, are complex
and high-dimensional, making interpretability crucial for clinical
decision-making, understanding physiological phenomena, and
ensuring trust in automated systems. Libraries such as Captum [ 26]provide an implementation of multiple post-hoc XAI methods and
compatibility with Pytorch models [32].
Captum provides backpropagation-based post-hoc XAI methods,
such as Input√óGradient [ 38], Integrated Gradients [ 44], LRP [ 6],
GradCAM [ 36], Deconvolution [ 53], Guided Backpropagation [ 40],
and DeepLIFT [ 37]. Backpropagation in the context of XAI involves
tracking the gradients of the output (e.g., classification scores) with
respect to the input features through the network layers. By analyz-
ing these gradients, one can determine how much each input feature
contributes to the final decision. This is based on the intuition that
if a small change in an input feature significantly affects the output,
that feature must be important for the decision-making process.
Integrated Gradients: Calculates the importance of each feature by
integrating gradients with respect to the input along the path from
a baseline to the actual input. It highlights features contributing
most to model predictions. While powerful, backpropagation-based
methods have limitations. They can sometimes produce misleading
or difficult-to-interpret explanations, especially in highly complex
networks. Furthermore, the choice of baseline in methods like In-
tegrated Gradients or the specific rules in LRP can significantly
affect the explanations, requiring careful consideration and domain
knowledge.
Additionally, Captum provides perturbation-based post-hoc XAI
methods, such as Occlusion, Feature Ablation, Feature Permutation,
and Shapley Values [ 42]. Perturbation-based XAI methods interpret
the decisions of machine learning models by systematically altering
(perturbing) the input data and observing the impact on the model‚Äôs
output. This approach helps to uncover which features or parts
of the input data are most important for the model‚Äôs predictions.
Perturbation methods are versatile and can be applied to a wide
range of models, because they are not dependent on underlying
model parameters, such as the gradient. But perturbing the input
and evaluating the model repeatedly can be computationally inten-
sive, especially for large datasets or complex models. Furthermore,
the impact of perturbations can sometimes be difficult to interpret,
especially for interactions between features.
Lastly, Captum provides surrogate XAI methods, such as LIME
[34]. The core principle of surrogate XAI methods is to use a simpler
model to emulate the predictions of a complex model across a
specific input space or dataset. By training the surrogate model to
approximate the outputs of the original model, one can analyze
the surrogate model to gain insights into how the original model
makes decisions. The interpretability of the surrogate model allows
for the extraction of human-understandable explanations, such as
feature importance, decision rules, or visualizations.
2.3 Visualizing Relevance Attributions
Recently, XAI methods have been applied to different biosignals
like EEG [ 17,18,23,29,31], and ECG [ 5,21,22,35,46] to gain in-
sight into the AI‚Äôs decision-making process. However, interpreting
the XAI results themselves, i.e., the relevance attributions, can be
challenging, and there are no standards. By considering the XAI
technique together in the context of the biosignal to be analysed
and the clinical workflow, first steps can be taken to initiate this
standardization process. As a result of the XAI workflow, we gen-
erated a relevance matrix, which has the same shape as our input
6600Explainable Artificial Intelligence on Biosignals
for Clinical Decision Support KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Figure 4: Example of an XAI visualization technique: A neu-
ral network trained to detect a right bundle branch block
(RBBB) in a standard 12-lead ECG has correctly classified
a healthy patient as "no RBBB". The blue-green color high-
lights negative relevances that contradict the presence of
RBBB on the leads, medically referred to as "narrow QRS
complexes". This indicates that the decision-making process
of the neural network is focused on the same regions of the
ECG described in the medical guideline [45].
matrix. This matrix indicates for every data point of the input how
important this particular data point was for the resulting outcome.
For instance, a standard 10s12-lead ECG recording with a 100Hz
sampling frequency results in both relevance and input matrix of
shape (12 ,1000).
One approach to combine the relevance matrix with the input
matrix is to plot the whole ECG recording and highlight the back-
ground of the signals in regions that are most relevant for the
model‚Äôs decision-making process (see Figure 4). Doing so, medical
staff can manually interpret the ECG in the established manner
while the suggested AI‚Äôs diagnosis is shown and the highlighted
regions of the ECG indicate the AI‚Äôs diagnostic findings. If the re-
gion of interest (ROI) of the AI is identical to the perception of
the human user, the trust in the AI‚Äôs diagnosis is backed up by
the known medical textbook knowledge and established scientific
evidence. In this setting the predicted output, i.e. the AI‚Äôs diagnosis,
can be additionally sub-grouped in confidence levels to provide the
information to the user how confident the output is. For instance,
if a neural network is trained to predict the presence of a disease
by providing an output of 1.0while 0.0means absence of the dis-
ease the output can be sub-grouped into the confidence levels low
confidence (output <0.5) and high confidence (output >0.75).2.4 Evaluating Relevance Attributions
The next step is to systematically analyze the relevance matrix
to gain insights into the AI‚Äôs decision making process and link
it to medical guidelines and textbook knowledge. The qualitative
evaluation refers only to the processing of individual subjects or
regions of the signals, while the quantitative evaluation includes
the evaluation across many different subjects, disease states and
together with characteristics known from medical guidelines. For
both, the inherent characteristic of the input signal can be used
and transferred to the relevance matrix. For example, the ECG is
a pseudo-periodic signal with repeating similar patterns for every
single heart beat and can be averaged by overlaying all heart beats
using the characteristic R-peak, which has the highest amplitude
in the recording. When the same transformation is applied to the
relevance matrix, the ROI can be analyzed within a single virtual
heartbeat. Analogically, if standard ECG interpretation algorithms
are transferred to the relevance matrix, not only individual heart-
beats or patients but also entire patient cohorts can be analyzed.
Our source code for different evaluation techniques of relevance
attributions on ECGs is freely available1.
3 Use Cases
In the domain of biosignals, AI models have already been suc-
cessfully applied to many medical classification problems, such as
automated diagnosis [ 33]. In the following, we present two example
use cases where XAI can be used successfully to analyze in how far
the reasoning process aligns with clinical guidelines [7].
3.1 ECG ‚Äì Detection of RBBB
3.1.1 Medical Background. The focus of this use case is on the
analysis of Right Bundle Branch Block (RBBB), characterized by
morphological changes in the shape of every QRS complex on the
ECG, rather than rhythmic alterations. Therefore, both, heartbeats
and relevances can be averaged within an ECG recording to facili-
tate the analysis. RBBB causes the heartbeat signal to be delayed
and out of sync, particularly observable in leads V1-V3 as two dis-
tinct R-peaks, referred to as "bunny ears" (see Figure 5). We aim
to evaluate a range of XAI methods to discern their suitability for
RBBB detection.
3.1.2 Dataset. A subset of the PhysioNet-Computing in Cardiol-
ogy Challenge 2020[ 2] known as the CPSC subset[ 28] is used for
the detection of RBBB, consisting of 6877 ECGs annotated for nine
cardiovascular diseases. The dataset comprises 5020 cases without
RBBB and 1857 cases with RBBB. ECG signals were denoised using
various techniques as outlined in Turb√© et al.[ 47], and R-peaks were
extracted to obtain average beats for each lead. For the classifi-
cation task, the pre-trained DNN proposed by Turb√© et al.[ 48] is
utilized. We use 15XAI methods from CaptumAI [ 26] to generate
the relevance attributions for all samples in the dataset.
3.1.3 XAI Workflow. To obtain a wide variety of XAI methods,
encompassing backpropagation-based, pertubation-based and sur-
rogate methods, Input √óGradient, Deconvolution, Guided Backprop-
agation, Integrated Gradients, LRP, LRP- ùúñ, LRP- ùõº-1-ùõΩ-0, LRP- ùõæ,
1https://gitlab.gwdg.de/medinfpub/biosignal-processing-group/xai-ecg
6601KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Miriam Cindy Maurer et al.
Figure 5: Depiction of characteristic ECG abnormality for
the detection of RBBB, namely RSR‚àópattern or w.r.t. its
characteristic shape denoted as "bunny ears"[ 11]. Adapted
from: https://commons.wikimedia.org/w/index.php?curid=
80427911 (CC0 license)
DeepLIFT, Occlusion, Shapley value sampling, GradientSHAP, Ker-
nelSHAP, DeepSHAP and LIME were used. These relevance attri-
butions are then visualized directly on the leads using averaged
heartbeats, with color-coded representation based on a scale of
[‚àí1,1]. This approach enables the analysis of all heartbeats of a
single patient within one virtual heartbeat.
3.1.4 Results. The qualitative evaluation of the various XAI meth-
ods for RBBB detection yield divergent outcomes. Some methods
yield high positive attributions, indicating importance towards
RBBB, while others provide negative or noisy relevance attribu-
tions. This emphasizes the variability in outcomes when employing
different XAI methods on the same DNN and samples for RBBB
detection. The challenge lies in determining, whether the model has
effectively learned the characteristic "bunny ears" as a significant
ECG abnormality. This variability in performance highlights the
necessity for cautions to identify a suitable XAI methods for ECG
data, acknowledging their sensitivity to dataset characteristics and
model structures.
3.2 EEG ‚Äì Sleep Stage Classification
3.2.1 Medical Background. Sleep disorders such as insomnia or
sleep apnea interfere with the amount and quality of sleep, thus
affecting mental and physical health. The investigation of such
disorders usually includes the measurement of polysomnographies,
resulting in several hours of data. In clinical practice, these mea-
surements are processed by visual inspection of 30-second intervals.
Each interval is labeled with one of five sleep stages according to
AASM criteria [ 4]: Wake (W), Rapid-Eye-Movement (REM) (R), or
Non-REM (N1, N2, N3). The resulting hypnogram, a list of all sleep
stages during a measurement period, is then analyzed further along
with other features to make a diagnosis.
0.0 5.0 10.0 15.0 20.0 25.0
secondsC3_M2
C4_M1
F3_F4
F3_M2
F4_O2
F3_O1
O1_M2
O2_M1
EMG
EOG1
EOG2Figure 6: Example of Integrated Gradients relevance attribu-
tions on a correctly classified polysomnogram segment of 30
seconds from [ 14] showing deep sleep (sleep stage N3). The
red color highlights positive relevance attributions towards
sleep stage N3, while the blue color highlights negative rele-
vance attributions.
For this manual classification of sleep stages over large amounts
of data, many approaches to automating this task have been pro-
posed, such as clustering [ 16], k-nearest neighbours [ 25], support
vector machines [3], or random forests [10].
Furthermore, several DNNs have been developed [ 20,41]. We
analyze RobustSleepNet [ 15], a model based on transfer learning
that was trained on several public datasets with polysomnographies
of healthy subjects and subjects diagnosed with sleep disorders.
3.2.2 Dataset. We analyze the DOD-O dataset [ 14] of55patients
with obstructive sleep apnea. The dataset contains eight EEG deriva-
tions (C3/M2, C4/M1, F3/F4, F3/M2, F4/O2, F3/O1, O1/M2, O2/M1),
one EMG derivation, left and right EOG signals and one ECG chan-
nel, with an average sleep duration of 387minutes.
3.2.3 XAI Workflow. We visualize Integrated Gradients attribu-
tions similar to [ 7] as can be seen in Fig. 6, examining important
channels for the different sleep stages. Furthermore, we analyze
the data in the frequency domain since the dominance of specific
frequency bands is the main feature used for manual classification.
Finally, we compare these features to the official AASM criteria [ 4].
4 Conclusion
This survey paper provides an overview of the application of XAI
methods in the context of biosignal processing. A comprehensive
XAI workflow tailored to biosignal data analysis was presented,
including a selection of appropriate AI models, generation and
visualization of XAI relevance attributions, and evaluation of these
attributions in line with medical guidelines and clinical expertise.
We highlighted the diversity of AI models suitable for biosignal
analysis, each offering unique advantages in capturing temporal,
spatial, and structural dependencies within biosignals. We empha-
sized the importance of selecting appropriate XAI methods based on
the characteristics of the data and the task at hand, considering fac-
tors such as model complexity, interpretability, and computational
efficiency. By outlining a systematic workflow, we have provided a
structured framework for practitioners to follow.
6602Explainable Artificial Intelligence on Biosignals
for Clinical Decision Support KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Through two illustrative use cases focusing on RBBB detection
in ECG signals and sleep stage classification in EEG data, we demon-
strated the practical application of the XAI workflow in analysing
AI decision-making processes and evaluating their alignment with
medical guidelines and expert knowledge. These examples high-
lighted the importance of XAI in providing insight into the reason-
ing processes of AI models, improving interpretability and facilitat-
ing trust between clinicians and end users.
In summary, XAI holds great promise for advancing the field
of biosignal processing by enabling transparent, interpretable and
trustworthy AI systems. By integrating XAI techniques into clin-
ical workflows, we can unlock the full potential of AI models to
diagnose disease, monitor patient health and guide treatment de-
cisions, ultimately improving patient outcomes and transforming
healthcare. Advances in XAI should not only improve the inter-
pretability of AI models but also ensure that the explanations are
actionable, ethical, and aligned with human values. As AI continues
to evolve and integrate into society, XAI will play a crucial role in
fostering a transparent, accountable, and trustworthy relationship
between AI systems and their human users. Continued research
and development of XAI methods tailored to biosignal analysis
will further enhance our understanding of physiological processes
and contribute to the development of innovative diagnostic and
therapeutic solutions.
References
[1]Regulation (eu) 2017/745 of the european parliament and of the council of 5
april 2017 on medical devices, amending directive 2001/83/ec, regulation (ec)
no 178/2002 and regulation (ec) no 1223/2009 and repealing council directives
90/385/eec and 93/42/eec.
[2]Erick A Perez Alday, Annie Gu, Amit J Shah, Chad Robichaux, An-Kwok Ian
Wong, Chengyu Liu, Feifei Liu, Ali Bahrami Rad, Andoni Elola, Salman Seyedi,
Qiao Li, Ashish Sharma, Gari D Clifford, and Matthew A Reyna. Classification of
12-lead ecgs: the physionet/computing in cardiology challenge 2020. Physiological
Measurement, 41(12):124003, dec 2020.
[3]Emina Alickovic and Abdulhamit Subasi. Ensemble svm method for automatic
sleep stage classification. IEEE Transactions on Instrumentation and Measurement,
67(6):1258‚Äì1265, 2018.
[4]American Academy of Sleep Medicine and others. The AASM manual for the
scoring of sleep and associated events: rules, terminology and technical specifications,
volume 23 of Westchester, IL: American Academy of Sleep Medicine. 2007.
[5]Atul Anand, Tushar Kadian, Manu Kumar Shetty, and Anubha Gupta. Explainable
ai decision model for ecg data of cardiac disorders. Biomedical Signal Processing
and Control, 75:103584, 2022.
[6]Sebastian Bach, Alexander Binder, Gr√©goire Montavon, Frederick Klauschen,
Klaus-Robert M√ºller, and Wojciech Samek. On pixel-wise explanations for non-
linear classifier decisions by layer-wise relevance propagation. PLOS ONE, 10(7):1‚Äì
46, 07 2015.
[7]Theresa Bender, Jacqueline Beinecke, Dagmar Krefting, Carolin Muller, Henning
Dathe, Tim Seidler, Nicolai Spicher, and Anne-Christin Hauschild. Analysis of a
deep learning model for 12-lead ecg classification reveals learned features similar
to diagnostic criteria. IEEE journal of biomedical and health informatics, PP, 05
2023.
[8]Alexander Brown, Nenad Tomasev, Jan Freyberg, Yuan Liu, Alan Karthike-
salingam, and Jessica Schrouff. Detecting shortcut learning for fair medical
ai using shortcut testing. Nature Communications, 14(1):4314, 2023.
[9]Maowei Cheng, Worku J. Sori, Feng Jiang, Adil Khan, and Shaohui Liu. Recurrent
neural network based classification of ecg signal features for obstruction of
sleep apnea detection. In 2017 IEEE International Conference on Computational
Science and Engineering (CSE) and IEEE International Conference on Embedded
and Ubiquitous Computing (EUC), volume 2, pages 199‚Äì202, 2017.
[10] Luay Fraiwan, Khaldon Lweesy, Natheer Khasawneh, Heinrich Wenz, and Hart-
mut Dickhaus. Automated sleep stage identification system based on time‚Äì
frequency analysis of a single eeg channel and random forest classifier. Computer
Methods and Programs in Biomedicine, 108(1):10‚Äì19, 2012.
[11] T.B. Garcia and N.E. Holtz. Introduction to 12-lead ECG: The Art of Interpretation.
Emergency Medical Services Series. Jones and Bartlett, 2003.
[12] A. L. Goldberger, L. A. N. Amaral, L. Glass, J. M. Hausdorff, P. Ch. Ivanov, R. G.
Mark, J. E. Mietus, G. B. Moody, C.-K. Peng, and H. E. Stanley. PhysioBank,PhysioToolkit, and PhysioNet: Components of a new research resource for com-
plex physiologic signals. Circulation, 101(23):e215‚Äìe220, 2000 (June 13). Cir-
culation Electronic Pages: http://circ.ahajournals.org/content/101/23/e215.full
PMID:1085218; doi: 10.1161/01.CIR.101.23.e215.
[13] Mark L Graber, Nancy Franklin, and Ruthanna Gordon. Diagnostic error in
internal medicine. Archives of internal medicine, 165(13):1493‚Äì1499, 2005.
[14] Antoine Guillot, Fabien Sauvet, Emmanuel H. During, and Valentin Thorey.
Dreem open datasets: Multi-scored sleep datasets to compare human and au-
tomated sleep staging. IEEE Transactions on Neural Systems and Rehabilitation
Engineering, 28(9):1955‚Äì1965, 2020.
[15] Antoine Guillot and Valentin Thorey. Robustsleepnet: Transfer learning for
automated sleep staging at scale. IEEE Transactions on Neural Systems and
Rehabilitation Engineering, 29:1441‚Äì1451, 2021.
[16] Salih G√ºne≈ü, Kemal Polat, and ≈ûebnem Yosunkaya. Efficient sleep stage recogni-
tion system based on eeg signal using k-means clustering based feature weighting.
Expert Systems with Applications, 37(12):7922‚Äì7928, 2010.
[17] Iqram Hussain, Rafsan Jany, Richard Boyer, AKM Azad, Salem A Alyami, Se Jin
Park, Md Mehedi Hasan, and Md Azam Hossain. An explainable eeg-based
human activity recognition model using machine-learning approach and lime.
Sensors, 23(17):7452, 2023.
[18] Mohammed Saidul Islam, Iqram Hussain, Md Mezbaur Rahman, Se Jin Park, and
Md Azam Hossain. Explainable artificial intelligence model for stroke prediction
using eeg signal. Sensors, 22(24):9859, 2022.
[19] Jacob C Jentzer, Anthony H Kashou, Francisco Lopez-Jimenez, Zachi I Attia, Suraj
Kapa, Paul A Friedman, and Peter A Noseworthy. Mortality risk stratification
using artificial intelligence-augmented electrocardiogram in cardiac intensive
care unit patients. European Heart Journal Acute Cardiovascular Care, 10(5):532‚Äì
541, 2021.
[20] Xiaopeng Ji, Yan Li, and Peng Wen. Jumping knowledge based spatial-temporal
graph convolutional networks for automatic sleep stage classification. IEEE
Transactions on Neural Systems and Rehabilitation Engineering, 30:1464‚Äì1472,
2022.
[21] Yong-Yeon Jo, Younghoon Cho, Soo Youn Lee, Joon-myoung Kwon, Kyung-Hee
Kim, Ki-Hyun Jeon, Soohyun Cho, Jinsik Park, and Byung-Hee Oh. Explain-
able artificial intelligence to detect atrial fibrillation using electrocardiogram.
International journal of cardiology, 328:104‚Äì110, 2021.
[22] Susumu Katsushika, Satoshi Kodera, Shinnosuke Sawano, Hiroki Shinohara,
Naoto Setoguchi, Kengo Tanabe, Yasutomi Higashikuni, Norifumi Takeda, Kat-
suhito Fujiu, Masao Daimon, et al. An explainable artificial intelligence-enabled
electrocardiogram analysis model for the classification of reduced left ventricular
function. European Heart Journal-Digital Health, 4(3):254‚Äì264, 2023.
[23] Mehrin Kiani, Javier Andreu-Perez, Hani Hagras, Silvia Rigato, and Maria Laura
Filippetti. Towards understanding human functional brain development with ex-
plainable artificial intelligence: Challenges and perspectives. IEEE Computational
Intelligence Magazine, 17(1):16‚Äì33, 2022.
[24] Serkan Kiranyaz, Turker Ince, and Moncef Gabbouj. Real-time patient-specific
ecg classification by 1-d convolutional neural networks. IEEE Transactions on
Biomedical Engineering, 63(3):664‚Äì675, 2016.
[25] Tam√°s Kiss, Stephen Morairty, Michael Schwartz, Thomas Kilduff, Derek Buhl,
and Dmitri Volfson. Automated sleep stage scoring using k-nearest neighbors
classifier. Journal of Open Source Software, 5(53):2377, 2020.
[26] Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsal-
lakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya,
Siqi Yan, and Orion Reblitz-Richardson. Captum: A unified and generic model
interpretability library for pytorch, 2020.
[27] Johann Laux, Sandra Wachter, and Brent Mittelstadt. Trustworthy artificial
intelligence and the european union ai act: On the conflation of trustworthiness
and acceptability of risk. Regulation & Governance, 18(1):3‚Äì32, 2024.
[28] Feifei Liu, Chengyu Liu, Lina Zhao, Xiangyu Zhang, Xiaoling Wu, Xiaoyan Xu,
Yulin Liu, Caiyun Ma, Shoushui Wei, Zhiqiang He, Jianqing Li, and Eddie Ng. An
open access database for evaluating the algorithms of electrocardiogram rhythm
and morphology abnormality detection. Journal of Medical Imaging and Health
Informatics, 8:1368‚Äì1373, 09 2018.
[29] Francesco Carlo Morabito, Cosimo Ieracitano, and Nadia Mammone. An explain-
able artificial intelligence approach to study mci to ad conversion via hd-eeg
processing. Clinical EEG and Neuroscience, 54(1):51‚Äì60, 2023.
[30] Meraj Neyazi, Jan P Bremer, Marius S Knorr, Stefan Gross, Jan Brederecke, Nils
Schweingruber, Dora Csengeri, Benedikt Schrage, Martin Bahls, Nele Friedrich,
et al. Deep learning-based nt-probnp prediction from the ecg for risk assessment
in the community. Clinical Chemistry and Laboratory Medicine (CCLM), (0), 2023.
[31] Hmayag Partamian, Fouad Khnaisser, Mohamad Mansour, Reem Mahmoud, and
Hazem Hajjand Fadi Karameh. A deep model for eeg seizure detection with ex-
plainable ai using connectivity features. In International Conference on Biomedical
Engineering and Science (BIOEN 2021) doi, volume 10, 2021.
[32] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory
Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Des-
maison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan
6603KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Miriam Cindy Maurer et al.
Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith
Chintala. Pytorch: An imperative style, high-performance deep learning library.
InAdvances in Neural Information Processing Systems 32, pages 8024‚Äì8035. Curran
Associates, Inc., 2019.
[33] Ant√¥nio H Ribeiro, Manoel Horta Ribeiro, Gabriela MM Paix√£o, Derick M Oliveira,
Paulo R Gomes, J√©ssica A Canazart, Milton PS Ferreira, Carl R Andersson, Peter W
Macfarlane, Wagner Meira Jr, et al. Automatic diagnosis of the 12-lead ecg using
a deep neural network. Nature communications, 11(1):1760, 2020.
[34] Marco Ribeiro, Sameer Singh, and Carlos Guestrin. ‚Äúwhy should I trust you?‚Äù:
Explaining the predictions of any classifier. In Proceedings of the 2016 Conference
of the North American Chapter of the Association for Computational Linguistics:
Demonstrations, pages 97‚Äì101, San Diego, California, June 2016. Association for
Computational Linguistics.
[35] Khaled Rjoob, Raymond Bond, Dewar Finlay, Victoria McGilligan, Stephen J
Leslie, Ali Rababah, Aleeha Iftikhar, Daniel Guldenring, Charles Knoery, Anne
McShane, et al. Towards explainable artificial intelligence and explanation user
interfaces to open the ‚Äòblack box‚Äôof automated ecg interpretation. In Advanced
Visual Interfaces. Supporting Artificial Intelligence and Big Data Applications: AVI
2020 Workshops, AVI-BDA and ITAVIS, Ischia, Italy, June 9, 2020 and September 29,
2020, Revised Selected Papers, pages 96‚Äì108. Springer, 2021.
[36] Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedan-
tam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep
networks via gradient-based localization. In 2017 IEEE International Conference
on Computer Vision (ICCV), pages 618‚Äì626, 2017.
[37] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. Learning impor-
tant features through propagating activation differences. In Proceedings of the
34th International Conference on Machine Learning - Volume 70, ICML‚Äô17, page
3145‚Äì3153. JMLR.org, 2017.
[38] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convo-
lutional networks: Visualising image classification models and saliency maps,
2014.
[39] Timo Speith. A Review of Taxonomies of Explainable Artificial Intelligence (XAI)
Methods. In 2022 ACM Conference on Fairness, Accountability, and Transparency,
pages 2239‚Äì2250, Seoul Republic of Korea, June 2022. ACM.
[40] J.T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. Striving for sim-
plicity: The all convolutional net. In ICLR (workshop track), 2015.
[41] Jens B. Stephansen, Alexander N. Olesen, Mads Olsen, Aditya Ambati, Eileen B.
Leary, Hyatt E. Moore, Oscar Carrillo, Ling Lin, Fang Han, Han Yan, Yun L.
Sun, Yves Dauvilliers, Sabine Scholz, Lucie Barateau, Birgit Hogl, Ambra Stefani,
Seung Chul Hong, Tae Won Kim, Fabio Pizza, Giuseppe Plazzi, Stefano Vandi,
Elena Antelmi, Dimitri Perrin, Samuel T. Kuna, Paula K. Schweitzer, Clete Kushida,
Paul E. Peppard, Helge B. D. Sorensen, Poul Jennum, and Emmanuel Mignot.
Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy.
Nature communications, 9(1):5229, 2018.
[42] Erik Strumbelj and Igor Kononenko. An efficient explanation of individual
classifications using game theory. J. Mach. Learn. Res., 11:1‚Äì18, 2010.
[43] Cathie Sudlow, John Gallacher, Naomi Allen, Valerie Beral, Paul Burton, John
Danesh, Paul Downey, Paul Elliott, Jane Green, Martin Landray, et al. Uk biobank:an open access resource for identifying the causes of a wide range of complex
diseases of middle and old age. PLoS medicine, 12(3):e1001779, 2015.
[44] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep
networks, 2017.
[45] Borys Surawicz, Rory Childers, Barbara J Deal, and Leonard S Gettes.
Aha/accf/hrs recommendations for the standardization and interpretation of
the electrocardiogram: part iii: intraventricular conduction disturbances: a sci-
entific statement from the american heart association electrocardiography and
arrhythmias committee, council on clinical cardiology; the american college of
cardiology foundation; and the heart rhythm society: endorsed by the interna-
tional society for computerized electrocardiology. Circulation, 119(10):e235‚Äìe240,
2009.
[46] Hirohisa Taniguchi, Tomohiro Takata, Mineki Takechi, Asuka Furukawa, Jin
Iwasawa, Akio Kawamura, Tadahiro Taniguchi, and Yuichi Tamura. Explain-
able artificial intelligence model for diagnosis of atrial fibrillation using holter
electrocardiogram waveforms. International heart journal, 62(3):534‚Äì539, 2021.
[47] Hugues Turb√©, Mina Bjelogrlic, Christian Lovis, and Gianmarco Mengaldo.
Dataset: Evaluation of post-hoc interpretability methods in time-series clas-
sification, January 2023.
[48] Hugues Turb√©, Mina Bjelogrlic, Christian Lovis, and Gianmarco Mengaldo. Eval-
uation of post-hoc interpretability methods in time-series classification. Nat.
Mach. Intell., 5(3):250‚Äì260, March 2023.
[49] Akhil Vaid, Joy Jiang, Ashwin Sawant, Stamatios Lerakis, Edgar Argulian, Yuri
Ahuja, Joshua Lampert, Alexander Charney, Heather Greenspan, Jagat Narula,
Benjamin Glicksberg, and Girish Nadkarni. A foundational vision transformer
improves diagnostic performance for electrocardiograms. npj Digital Medicine, 6,
06 2023.
[50] Rutger R van de Leur, Max N Bos, Karim Taha, Arjan Sammani, Ming Wai Yeung,
Stefan van Duijvenboden, Pier D Lambiase, Rutger J Hassink, Pim van der Harst,
Pieter A Doevendans, Deepak K Gupta, and Ren√© van Es. Improving explainability
of deep neural network-based electrocardiogram interpretation using variational
auto-encoders. European Heart Journal - Digital Health, 07 2022. ztac038.
[51] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Å ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In
I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and
R. Garnett, editors, Advances in Neural Information Processing Systems, volume 30.
Curran Associates, Inc., 2017.
[52] Dukyong Yoon, Jong-Hwan Jang, Byung Jin Choi, Tae Young Kim, and Chang Ho
Han. Discovering hidden information in biosignals from patients using artificial
intelligence. Korean journal of anesthesiology, 73(4):275‚Äì284, 2020.
[53] Matthew D. Zeiler and Rob Fergus. Visualizing and understanding convolutional
networks. In David Fleet, Tomas Pajdla, Bernt Schiele, and Tinne Tuytelaars,
editors, Computer Vision ‚Äì ECCV 2014, pages 818‚Äì833, Cham, 2014. Springer
International Publishing.
[54] Kamyar Zeinalipour and Marco Gori. Graph Neural Networks for Topological
Feature Extraction in ECG Classification, pages 17‚Äì27. Springer Nature Singapore,
Singapore, 2023.
6604