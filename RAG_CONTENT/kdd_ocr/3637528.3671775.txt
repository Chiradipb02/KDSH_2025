EAGER: Two-Stream Generative Recommender with
Behavior-Semantic Collaboration
Ye Wang‚àó
Zhejiang University
Hangzhou, China
yewzz@zju.edu.cnJiahao Xun‚àó
Zhejiang University
Hangzhou, China
jhxun@zju.edu.cnMinjie Hong
Zhejiang University
Hangzhou, China
6381735@gmail.com
Jieming Zhu‚Ä†
Huawei Noah‚Äôs Ark Lab
Shenzhen, China
jiemingzhu@ieee.orgTao Jin
Zhejiang University
Hangzhou, China
jint_zju@zju.edu.cnWang Lin
Zhejiang University
Hangzhou, China
linwanglw@zju.edu.cn
Haoyuan Li
Zhejiang University
Hangzhou, China
lihaoyuan@zju.edu.cnLinjun Li
Zhejiang University
Hangzhou, China
lilinjun21@zju.edu.cnYan Xia
Zhejiang University
Hangzhou, China
xiayan.zju@gmail.com
Zhou Zhao‚Ä†
Zhejiang University
Hangzhou, China
zhaozhou@zju.edu.cnZhenhua Dong
Huawei Noah‚Äôs Ark Lab
Shenzhen, China
dongzhenhua@huawei.com
ABSTRACT
Generative retrieval has recently emerged as a promising approach
to sequential recommendation, framing candidate item retrieval as
an autoregressive sequence generation problem. However, existing
generative methods typically focus solely on either behavioral or
semantic aspects of item information, neglecting their complemen-
tary nature and thus resulting in limited effectiveness. To address
this limitation, we introduce EAGER, a novel generative recommen-
dation framework that seamlessly integrates both behavioral and
semantic information. Specifically, we identify three key challenges
in combining these two types of information: a unified generative
architecture capable of handling two feature types, ensuring suffi-
cient and independent learning for each type, and fostering subtle
interactions that enhance collaborative information utilization. To
achieve these goals, we propose (1) a two-stream generation archi-
tecture leveraging a shared encoder and two separate decoders to
decode behavior tokens and semantic tokens with a confidence-
based ranking strategy; (2) a global contrastive task with summary
tokens to achieve discriminative decoding for each type of informa-
tion; and (3) a semantic-guided transfer task designed to implicitly
‚àóEqual contribution.
‚Ä†Corresponding authors.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
¬©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671775promote cross-interactions through reconstruction and estimation
objectives. We validate the effectiveness of EAGER on four public
benchmarks, demonstrating its superior performance compared
to existing methods. Our source code will be publicly available on
PapersWithCode.com.
CCS CONCEPTS
‚Ä¢Information systems ‚ÜíRecommender systems.
KEYWORDS
Generative Recommendation, Autoregressive Generation, Semantic
Tokenization, Behavior-Semantic Collaboration
ACM Reference Format:
Ye Wang, Jiahao Xun, Minjie Hong, Jieming Zhu, Tao Jin, Wang Lin, Haoyuan
Li, Linjun Li, Yan Xia, Zhou Zhao, and Zhenhua Dong. 2024. EAGER: Two-
Stream Generative Recommender with Behavior-Semantic Collaboration.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ‚Äô24), August 25‚Äì29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 10 pages. https://doi.org/10.1145/3637528.3671775
1 INTRODUCTION
Recommender systems are widely adopted solutions for manag-
ing information overload, designed to identify items of interest
to users from a large item corpus. Modern recommender systems
typically integrate representation learning and search index con-
struction to refine the matching process. Initially, users and items
are encoded into latent representations within a shared latent space
using models like two-tower architectures [ 31,33] and sequential
recommendation models [ 14,27]. Subsequently, to efficiently re-
trieve top-k items for users, approximate nearest neighbor (ANN)
search indexes are constructed using tools such as Faiss [ 13] and
3245
KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Ye Wang et al.
Figure 1: A framework of generative recommendation.
SCANN [ 8]. Despite notable progress, the separate phases of repre-
sentation learning and index construction often operate indepen-
dently, presenting challenges for achieving end-to-end optimization
and consequently limiting the overall effectiveness of recommender
systems [29].
To address this limitation, many research efforts have been made.
One prominent direction involves constructing tree-based matching
indexes [ 7,41,42], which optimize both a matching model and a tree
structure index for items. However, these methods often face chal-
lenges such as low inference efficiency due to the tree structure and
limited utilization of item semantic information [ 7,26]. Recently,
generative retrieval [ 16] has emerged as a promising new para-
digm for information retrieval, which has been recently applied for
generative recommendation [ 23]. Unlike traditional representation-
based user-item matching approaches, this paradigm employs an
end-to-end generative model that predicts candidate item identifiers
directly in an autoregressive manner. Specifically, Specifically, these
methods begin by tokenizing each item ùë•into a set of discrete se-
mantic codes1ùê∂={ùëê1,ùëê2,...}, and then utilize an encoder-decoder
model (e.g. Transformer [ 30]) to serve as an end-to-end index for
retrieval. In this setup, the encoder encodes the interaction history
{ùë•1,ùë•2,...,ùë•ùë°‚àí1}between users and item, while the decoder predicts
the code sequence ùê∂ùë°of the next item ùë•ùë°. The overall framework is
illustrated in Fig. 1.
However, existing generative recommendation approaches suffer
from a significant drawback in how they utilize item information,
often focusing narrowly on either behavioral or semantic aspects.
Behavioral information is derived from user-item interaction his-
tories, while semantic information encompasses textual or visual
descriptions of items. For instance, RecForest [ 7] utilizes a pre-
trained DIN model [ 38] to extract behavior-based item embeddings
for constructing semantic codes, while TIGER utilizes the Sentence-
T5 model [ 21] to derive semantic-based item embeddings from
textual descriptions. However, these approaches often focus exclu-
sively on one aspect, overlooking the complementary relationship
between behavior and semantics. On one hand, advances in pre-
trained modality encoders such as BERT [ 4] and ViT [ 6] facilitate
the integration of multimodal features, enhancing prior knowledge
and finding wide applications in multimodal recommendation mod-
els [18]. On the other hand, behavioral data captures user-specific
preferences through interaction sequences, making it particularly
effective in recommendation contexts. Conversely, semantic infor-
mation offers broader, unbiased insights into item characteristics,
fostering better generalization across different domains.
1Note that we use "code" and "token" interchangeably.In this paper, we propose EAGER, a novel two-strEAm GEnerati-
veRecommender with behavior-semantic collaboration. We ana-
lyze the challenges of modeling behavior and semantics within a
unified generative framework and address them from the following
three aspects:
Firstly, a unified generative architecture for handling two
distinct types of information is crucial. Given the inherent differ-
ences in feature spaces between behavior and semantics, directly
integrating them through feature fusion at the encoder side poses
challenges, as demonstrated in previous two-tower models [ 25,34].
Therefore, our approach constructs separate codes for behavior
and semantics, employing a two-stream generation architecture
where each serves as a distinct supervision signal at the decoder
side. This architecture includes a shared encoder for encoding user
interaction history and two separate decoders for predicting behav-
ior and semantic codes respectively, thereby avoiding premature
feature interaction. During inference, we enhance the merging of
results from both streams by utilizing the prediction entropy of
each stream as a confidence measure for item ranking, ensuring
effective predictions.
Secondly, ensuring sufficient and independent learning is
crucial to fully leverage the potential value of each type of informa-
tion. Previous works [ 23] have typically employed autoregressive
approaches to learn each token one by one, focusing on discrete and
local information rather than capturing global insights. In EAGER,
we introduce a global contrastive task with a summary token. This
module draws inspiration from two main sources: (1) traditional
dual-tower models use contrastive learning to acquire discrimina-
tive item features. Similarly, we aim for our decoder model to grasp
global discriminatory capabilities alongside its autoregressive gen-
eration capability, thereby enhancing the extraction of item features
within a contrastive paradigm; (2) Transformer models [ 4,6] utilize
special tokens to encapsulate global information, prompting us to
append a summary token at the end of the token sequence. This
token summarizes the accumulated knowledge in a unidirectional
manner, serving as the focal point for distillation.
Thirdly, while separate decoding and prediction reranking have
shown effectiveness, integrating subtle interaction can enhance
sharing of both knowledge flows. As mentioned earlier, direct
feature-level interactions often yield sub-optimal outcomes [ 34].
Therefore, we introduce a carefully crafted semantic-guided transfer
task to promote implicit knowledge exchange. Specifically, we pro-
pose that semantic information can guide behavioral aspects, and
we design an auxiliary transformer with dual objectives: reconstruc-
tion and recognition. The reconstruction objective involves predict-
ing masked behavior tokens using global semantic features, while
the recognition objective aims to differentiate whether a behavior
token aligns with a specified global semantic feature. Through these
objectives, this module indirectly optimizes interaction between
behavioral and semantic features using the transformer model.
In summary, our main contributions are as follows:
‚Ä¢We introduce EAGER, a novel generative recommendation frame-
work that integrates behavior and semantic information collabo-
ratively.
‚Ä¢We propose a unified two-stream generative architecture, design
a global contrastive module with a summary token to ensure
3246EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
sufficient and independent learning, and introduce a semantic-
guided transfer module for subtle interaction.
‚Ä¢Extensive experiments on four public recommendation bench-
marks demonstrate EAGER‚Äôs superiority over existing methods,
encompassing both generative and traditional paradigms.
2 RELATED WORK
Sequential Recommendation. Using deep sequential models to
capture user-item patterns in recommender systems has developed
into a rich literature. GRU4REC [ 10] was the first to use GRU-based
RNNs for sequential recommendations. SASRec [ 14] adopts self-
attention which is similar to decoder-only transformer models.
Inspired by the success of masked language modeling in language
tasks, BERT4Rec [ 27] utilizes transformer models with masking
strategies for sequential recommendation tasks. ùëÜ3-Rec [ 39] not
only relies on masking but also pre-trains embeddings through
four self-supervised tasks to enhance the quality of item and user
embeddings. The above mentioned methods mainly depend on an
approximate nearest neighbor (ANN) search index (e.g., Faiss [ 13])
to retrieve the next item. Besides, tree-based methods [ 7,41,42]
have shown promising performance in recommender systems. For
example, RecForest [ 7] constructs a forest by creating multiple trees
and integrates a transformer-based structure for routing operations.
Recently, TIGER [ 23] introduced the idea of semantic id, where
each item is represented as a set of tokens derived from its side in-
formation, and then predicts the next item tokens in a seq2seq way.
In this work, we aim to further explore a two-stream generation
architecture to act as an end-to-end index for top-k item retrieval.
Generative Retrieval. Generative retrieval [ 16] has been recently
proposed as a new retrieval paradigm, which consists of two main
phases: discrete semantic tokenization [ 11,12,17] and autoregres-
sive sequence generation [ 23,29,32]. In the domain of document
retrieval, researchers have explored the use of pre-trained language
models to generate diverse types of document identifiers. Notably,
DSI [ 29] and NCI [ 32] leverage the T5 [ 22] model to produce hi-
erarchical document IDs. Conversely, SEAL [ 1] (with BART [ 15]
backbone) and ULTRON [ 40] (using T5) utilize titles or substrings
as identifiers. Another approach, AutoTSG [ 35], adopts term-sets
for identification purposes. Generative document retrieval has also
extended to various domains. For instance, IRGen [ 37] employs a
ViT-based model for image search, while TIGER [ 23] utilizes T5
for recommender systems. However, these studies often face chal-
lenges in large-scale item retrieval within recommender systems
due to the resource-intensive nature of pre-trained language mod-
els. In contrast, our paper delves into integrating both behavior and
semantics for generative retrieval in such systems.
3 METHOD
3.1 Problem Formulation
Given the entire set of items Xand interacted items history X=
{x1,x2,¬∑¬∑¬∑,xùë°‚àí1}‚ààX of a user, the sequence recommendation
system returns a list of item candidates for the next item xùë°.
In generative recommendation, the identifier of each item xis
represented as a serialized code Y=[y1,y2,¬∑¬∑¬∑,yùëô]‚ààY , where
ùëôis the length of the code. The goal of the generative model islearning a mapping ùëì:X‚ÜíY , which takes a user‚Äôs interacted item
sequence as input and generates item codes (candidate identifiers).
For training, the model first feeds the user‚Äôs behavior Xinto the
encoder, then leverages the auto-regressive decoder to generate
the item code Ystep by step. The probability of interaction can be
calculated by:
ùëù(Y|X)=√ñùëô
ùëñ=1ùëù(yùëñ|X,y1,y2,..., yi‚àí1) (1)
During inference, the decoder performs beam search over the se-
quential codes when selecting top-n candidates.
3.2 Overall Pipeline
We present our overall EAGER framework in Fig. 2. EAGER con-
sists of (1) a two-stream generation architecture to unify item rec-
ommendation for both behavior and semantic information, (2) a
global contrastive task with a summary token to capture global
knowledge for better auto-regressive generation quality, and (3) a
semantic-guided transfer task to achieve the cross-information and
cross-decoder interaction.
First, in our two-stream generation architecture, we model user
interactions history and obtain interaction features via the encoder.
Then we extract both behavior and semantic features to construct
two codes, and leverage two decoders to separately predict them in
an auto-regressive way. Meanwhile, we optimize a summary token
in our global contrastive task and leverage it to improve cross-
decoder interaction in our semantic-guided transfer task. After
training, we adopt a confidence-based ranking strategy to merge
the results from two different predictions.
3.3 Two-stream Generation Architecture
To handle two different information, i.e. behavior and semantic, we
leverage the powerful modeling capabilities of transformer models
and design a two-stream generation architecture. This framework
consists of a shared encoder for modeling user interaction, two
separate codes and decoders for two-stream generation.
Shared Encoder. The sequence modeling of user interaction his-
tory X={x1,x2,¬∑¬∑¬∑} is based on the stacked multi-head self-
attention layers and feed-forward layers, as proposed in Trans-
former. It is worth nothing that we only adopt a shared encoder
instead of two encoders, which is enough to generate rich repre-
sentation for the subsequent separate decoding. We denote the
encoded historical interaction features as H=Encoder(X).
Dual Codes. We first extract the behavior and semantic item em-
beddings EùëèandEùë†using two pre-trained models, where the behav-
ior encoder is a two-tower model (e.g. DIN [ 38]) that only uses ID
sequence for recommendation and the semantic encoder is a gen-
eral modality representation model (e.g. Sentence-T5). With the two
extracted embeddings, we separately apply the widely-used hierar-
chical k-means algorithm to each one, where each cluster is evenly
divided into K child clusters until each child cluster merely contains
one single item. As shown in Fig. 3, we can obtain two codes Yùëè
andYùë†, corresponding to behavior and semantic, respectively.
Dual Decoders. To accommodate two different codes, we employ
two separate decoders to decode and generate the prediction for
each of them, allowing each decoder to specialize in one single code.
Compared to one shared decoder that generates two identifiers
3247KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Ye Wang et al.
Figure 2: An overview of EAGER. EAGER consists of three major components: Two-Stream Generation Architecture (TSG),
Global Contrastive Task (GCT), and Semantic-guided Transfer Task (STT).
Pretrained
Semantic Encoder
Pretrained
Behavior Encoder
Candidate  Items
Image
Text
IDs
EmbeddingsItem2token
168
268
379
479
584
243
253
337
437
858
Hierarchical
K-Means
Semantic Tokens
Behavior TokensHierarchical
K-Means
Figure 3: The illustration of dual codes.
in an auto-regressive way, such design mitigates the supervision
difference and offers higher efficiency with parallel generation. For
training, we add a start token ySOSat the beginning of codes Yto
construct the decoder inputs ¬ØY={ySOS,y1,y2,¬∑¬∑¬∑,yùëô}and utilize
cross-entropy loss for prediction. The overall loss Lgenis the sum
of two generations losses LùëègenandLùë†gen, where each is given by:
Lùë°
gen=‚àëÔ∏Åùëô
ùëñ=1logùëù(yùë°
ùëñ|xùë°,yùë°
SOS,yùë°
1,..., yùë°
ùëñ‚àí1), ùë°‚àà{ùëè,ùë†}(2)
3.4 Global Contrastive Task
To endow each generative decoder with a sufficient discriminative
capability, we design a global contrastive task with a summary
token to distill the global knowledge.
Summary Token. For the input ¬ØYof each decoder, we consider the
left-to-right order of auto-regressive generation and insert a learn-
able token y[EOS]at the end of the sequence to construct modified
inputs ÀúY={ySOS,y1,y2,¬∑¬∑¬∑,yùëô,y[EOS]}. This design encourages
the preceding tokens in the codes to learn more comprehensive
and discriminative knowledge, enabling the final token to make asummary. During updates, the gradient on the summary token can
be backpropagated to the preceding tokens.
Contrastive Distillation. To make the summary token capture
global information, we adopt contrastive learning paradigm to dis-
till the item embedding EùëèandEùë†from the pre-trained encoder.
Here we adopt the positive-only contrastive metric [ 3] instead of
commonly used Info-NCE [ 2] to achieve this objective. The full loss
Lconis given by summing two losses LùëèconandLùë†con, where each
is given by:
Lùë°
con=F(ùë¶ùë°
[EOS],Eùë°), ùë°‚àà{ùëè,ùë†} (3)
whereùë¶ùë°
[EOS]corresponds to the embedding of the summary token
yùë°
[EOS]andF(¬∑,¬∑)is the metric function, e.g. Smooth ‚Ñì1.
3.5 Semantic-guided Transfer Task
Through the aforementioned components, our model can effectively
utilize two types of information for prediction. However, we do
not stop at this point. Instead of completely independent decoding,
we further propose a semantic-guided transfer task to utilize the
semantic knowledge to guide the behavior learning.
To enable the knowledge flow between two sides while avoiding
direct interaction, we build an independent bidirectional Trans-
former decoder as an auxiliary module. We first add a token y[cls]at
the beginning of behavior codes to obtain the sequence {yùëè
[cls],yùëè
1,yùëè
2,
¬∑¬∑¬∑,yùëè
ùëô}as the input to the decoder. Then the embedding ùë¶ùë†
EOSof
the semantic summary token yùë†
[EOS]is input to the cross atten-
tion, allowing each behavior token in the decoder to attend over
global feature of the semantic. We denote the output features as
3248EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
Table 1: Statistics of the Datasets.
Dataset
#Users #Items #Interactions #Density
Beauty
22,363 12,101 198,360 0.00073
Sports and Outdoors 35,598 18,357 296,175 0.00045
Toys and Games 19,412 11,924 167,526 0.00073
Yelp 30,431 20,033 316,354 0.00051
{r[cls],r1,r2,¬∑¬∑¬∑,rùëô}. To conduct our transfer training, we design
two following objectives: reconstruction and recognition.
Reconstruction. We reconstruct the masked behavior codes via
the semantic global feature, aiming to enable the each behavior
token benefit from the semantic. For reconstruction training, we
randomly mask m% of tokens in the behavior code to obtain the
masked code{yùëè
[cls],yùëè
1,yùëè
[mask],¬∑¬∑¬∑,yùëè
ùëô}, where yùëè
[mask]means the
masked token. Then, we obtain the corresponding output features
{r[cls],r1,r[mask],¬∑¬∑¬∑,rùëô}and apply the contrastive loss to develop
the reconstruction by:
Lùëñ=logexp(rùëè+
[ùëöùëñ]¬∑yùëñ)
exp(rùëè+
[ùëöùëñ]¬∑yùëñ)+√çùêΩ
ùëó=1exp(rùëè+
[ùëöùëñ]¬∑yùëó),
Lrecon=‚àí2
ùëÅùëÅ/2‚àëÔ∏Å
ùëñ=1Lùëè
ùëñ(4)
where yùëñis the feature of ground truth of the ùëñ-th masked token,
yùëóis the feature of sampled tokens.
Recognition. Besides, we also build a binary classifier to judge
whether the behavior codes is relevant or irrelevant to the seman-
tic global feature. For recognition training, we construct negative
samples by randomly replacing the m% of tokens in the behavior
code with the sampled irrelevant token, e.g. [23, 123, 32] ‚Üí[23,
145, 32]. We add a linear layer on the corresponding output of the
token [CLS] and utilize a linear layer with sigmoid activation to
calculate the score ùë†+/ùë†‚àífor positive/negative samples. The binary
cross-entropy loss is utilized for recognition, given by:
Lrecog=‚àílog(ùë†+)+log(1‚àíùë†‚àí) (5)
3.6 Training and Inference
Training. We combine the generation, contrastive, reconstruction
and recognition losses to train our model, given by:
LEAGER =Lgen+ùúÜ1Lcon+ùúÜ2(Lrecon+L recog) (6)
whereùúÜ1andùúÜ2are loss coefficients.
Inference with Confidence-based Ranking. Since we have two
results derived from the behavior and the semantic streams, we
first obtain top- ùëòpredictions via beam search from each stream.
With the 2* ùëòprediction codes, we calculate the log probabilities
over the codes as the confidence score of each prediction, which is
similar to the perplexity used in the language model and the lower
value indicates more confidence. Finally, we rank these predictions
by their confidence scores and obtain the top- ùëòpredictions, which
corresponds to ùëòitems.4 EXPERIMENTS
We analyze the proposed EAGER method and demonstrate its ef-
fectiveness by answering the following research questions:
‚Ä¢RQ1: How does EAGER perform compared with existing best-
performing sequential recommendation methods among different
datasets?
‚Ä¢RQ2: Do two-stream generation architecture, global contrastive
task module, and semantic-guided transfer task module all con-
tribute to the effectiveness of EAGER?
‚Ä¢RQ3: How do different ablation variants and hyper-parameter
settings affect the performance of EAGER?
4.1 Experimental Setting
Dataset. We conduct experiments on four open-source datasets
commonly used in the sequential recommendation task. For all
datasets, we group the interaction records by users and sort them
by the interaction timestamps ascendingly. Following [ 24,36], we
only keep the 5-core dataset, which filters unpopular items and
inactive users with fewer than five interaction records. Statistics of
these datasets are shown in Table 1.
‚Ä¢Amazon: Amazon Product Reviews dataset [ 20], containing user
reviews and item metadata from May 1996 to July 2018. Here we
use three categories (Beauty, Sports and Outdoors, and Toys and
Games) for evaluations.
‚Ä¢Yelp 20192: Yelp Challenge releases the review data for small
businesses (e.g., restaurants). Following the previous setting [ 39],
we only use the transaction records from January 1st, 2019 to
December 31st, 2019. We view these businesses as items.
Evaluation Metrics. We employ two broadly used criteria for the
matching phase, i.e., Recall and Normalized Discounted Cumula-
tive Gain (NDCG). We report metrics computed on the top 5/10/20
recommended candidates. Following the standard evaluation proto-
col [14], we use the leave-one-out strategy for evaluation. For each
item sequence, the last item is used for testing, the item before the
last is used for validation, and the rest is used for training. During
training, we limit the number of items in a user‚Äôs history to 20.
Implementation Details. For two-stream generation architec-
ture, we set the number of encoder layers to 1, and the number of
decoder layers to 4. Following previous works [ 7,23], we adopt
pre-trained DIN as our behavior encoder and Sentence-T5 as our
semantic encoder, and set the hidden size to 128 as reported in [ 23].
The cluster number ùëòin hierarchical k-means is set to 256. For
global contrastive task, we adopt Smooth ‚Ñì1distance to serve as
the distilling loss. For semantic-guided transfer task, we randomly
mask 50% behavior codes for reconstruction, and randomly replace
50% behavior codes with the sampled code to construct negative
pairs for recognition. To train our model, we adopt Adam optimizer
with the learning rate 0.001, and employ the warmup strategy for
stable training. EAGER is not sensitive to the hyper-parameters for
the GCT and STT tasks because these tasks converge quickly. So
the loss coefficients ùúÜ1,ùúÜ2are both set to 1.
2https://www.yelp.com/dataset
3249KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Ye Wang et al.
Table 2: Performance comparison of different methods. The best performance is highlighted in bold while the second best
performance is underlined. The last column indicates the improvements over the best baseline models and all the results of
Eager are statistically significant with p < 0.05 compared to the best baseline models.
Dataset MetricTraditional Transformer-based Tree-based GenerativeImprov.
GRU4REC Caser HGN SASRec Bert4Rec S^3-Rec TDM Recforest TIGER EAGER
BeautyRecall@5 0.0164 0.0205 0.0325 0.0387 0.0203 0.0387 0.0442 0.0470‚àó0.0454 0.0618 31.49%
Recall@10 0.0283 0.0347 0.0512 0.0605 0.0347 0.0647 0.0638 0.0664‚àó0.0648 0.0836 25.90%
Recall@20 0.0479 0.0556 0.0773 0.0902 0.0599 0.0994 0.0876 0.0915‚àó- 0.1124 13.08%
NDCG@5 0.0099 0.0131 0.0206 0.0249 0.0124 0.0244 0.0323 0.0341‚àó0.0321 0.0451 32.26%
NDCG@10 0.0137 0.0176 0.0266 0.0318 0.0170 0.0327 0.0376 0.0400‚àó0.0384 0.0525 31.25%
NDCG@20 0.0187 0.0229 0.0332 0.0394 0.0233 0.0414 0.0438 0.0464‚àó- 0.0599 29.09%
SportsRecall@5 0.0129 0.0116 0.0189 0.0233 0.0115 0.0251 0.0127 0.0149‚àó0.0264 0.0281 6.44%
Recall@10 0.0204 0.0194 0.0313 0.0350 0.0191 0.0385 0.0221 0.0247‚àó0.0400 0.0441 10.25%
Recall@20 0.0333 0.0314 0.0477 0.0507 0.0315 0.0607 0.0349 0.0375‚àó- 0.0659 8.57%
NDCG@5 0.0086 0.0072 0.0120 0.0154 0.0075 0.0161 0.0096 0.0101‚àó0.0181 0.0184 1.66%
NDCG@10 0.0110 0.0097 0.0159 0.0192 0.0099 0.0204 0.0110 0.0133‚àó0.0225 0.0236 4.89%
NDCG@20 0.0142 0.0126 0.0201 0.0231 0.0130 0.0260 0.0141 0.0164‚àó- 0.0291 11.92%
ToysRecall@5 0.0097 0.0166 0.0321 0.0463 0.0116 0.0443 0.0305 0.0313‚àó0.0521 0.0584 12.09%
Recall@10 0.0176 0.0270 0.0497 0.0675 0.0203 0.0700 0.0359 0.0383‚àó0.0712 0.0714 0.28%
Recall@20 0.0301 0.0420 0.0716 0.0941 0.0358 0.1065 0.0442 0.0483‚àó- 0.1024 -3.85%
NDCG@5 0.0059 0.0107 0.0221 0.0306 0.0071 0.0294 0.0214 0.0260‚àó0.0371 0.0464 25.07%
NDCG@10 0.0084 0.0141 0.0277 0.0374 0.0099 0.0376 0.0230 0.0285‚àó0.0432 0.0505 16.90%
NDCG@20 0.0116 0.0179 0.0332 0.0441 0.0138 0.0468 0.0284 0.0310‚àó- 0.0538 14.96%
YelpRecall@5 0.0152 0.0151 0.0186 0.0162 0.0051 0.0201 0.0181 0.0220‚àó0.0212‚àó0.0265 20.45%
Recall@10 0.0263 0.0253 0.0326 0.0274 0.0090 0.0341 0.0287 0.0302‚àó0.0367‚àó0.0453 12.69%
Recall@20 0.0439 0.0422 0.0535 0.0457 0.0161 0.0573 0.0422 0.0449‚àó0.0552‚àó0.0724 11.56%
NDCG@5 0.0099 0.0096 0.0115 0.0100 0.0033 0.0123 0.0121 0.0119‚àó0.0146‚àó0.0177 3.51%
NDCG@10 0.0134 0.0129 0.0159 0.0136 0.0045 0.0168 0.0154 0.0163‚àó0.0194‚àó0.0242 18.63%
NDCG@20 0.0178 0.0171 0.0212 0.0182 0.0063 0.0226 0.0208 0.0210‚àó0.0230‚àó0.0311 19.62%
Table 3: Ablation studies by selectively discarding the Two-stream Generation Architecture (TSG), Global Contrastive Task
(GCT), and semantic-guided Transfer Task (STT). We study EAGER on different datasets to reveal the model-agnostic capability
of the proposed modules.
Variants Beauty Toys and Games
TSG GCT STT R@5 NDCG@5 R@10 NDCG@10 R@20 NDCG@20 R@5 NDCG@5 R@10 NDCG@10 R@20 NDCG@20
0.0512 0.0370 0.0699 0.0430 0.0943 0.0491 0.0436 0.0344 0.0545 0.0379 0.0657 0.0407
‚úì 0.0582 0.0425 0.0795 0.0496 0.1034 0.0567 0.0526 0.0428 0.0646 0.0469 0.0879 0.0510
‚úì‚úì 0.0604 0.0439 0.0815 0.0514 0.1091 0.0587 0.0563 0.0454 0.0699 0.0497 0.0974 0.0525
‚úì‚úì‚úì0.0618 0.0451 0.0836 0.0525 0.1124 0.0599 0.0584 0.0464 0.0714 0.0505 0.1024 0.0538
4.2 Performance Comparison (RQ1)
Baselines. The baseline methods chosen for comparison can be
split into the following four categories:
(1) For traditional sequential methods, we have:
‚Ä¢GRU4REC [9]: An early attempt to introduce recurrent neural
networks into recommendation.
‚Ä¢Caser [28]: a CNN-based method capturing high-order Markov
Chains by applying horizontal and vertical convolutional opera-
tions for sequential recommendation.‚Ä¢HGN [19]: it adopts hierarchical gating networks to capture
long-term and short-term user interests.
(2) For transformer-based methods, we have:
‚Ä¢SASRec [14]: SASRec models user‚Äôs behavior with Transformer
encoder, where multi-head attention mechanism is attached to
great importance.
‚Ä¢BERT4Rec [27]: it uses a cloze objective loss for sequential
recommendation by the bidirectional self-attention mechanism.
3250EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
‚Ä¢S^3-Rec [39]: S^3-Rec proposes pre-training a bi-directional
Transformer on self-supervision tasks to improve the sequential
recommendation.
(3) For tree-based methods, we have:
‚Ä¢TDM [42]: TDM uses a tree index to organize items (each leaf
node in the tree corresponds to an item) and designs a maximum
heap-based tree model for retrieval.
‚Ä¢RecForest [7]: RecForest constructs a forest with multiple k-
branch trees and integrates a transformer-based structure for
routing operations.
(4) For generative methods, we have:
‚Ä¢TIGER [23]: TIGER uses pretrained T5 to learn semantic ID for
each item and autoregressively decodes the identifiers of the
target candidates with semantic ID.
Results. Tab. 2 reports the overall performance of four datasets.
The results for all baselines without the superscript‚àóare taken
from the publicly accessible results [ 23,39]. For missing statistics,
we reimplement the baseline and report our experimental results.
From the results, we have the following observations:
‚Ä¢EAGER almost achieves better results than base models
among different datasets. Especially, EAGER performs consid-
erably better on the Beauty benchmark compared to the second-
best baseline with up to 31.49% improvement in Recall@5 and
32.26% improvement in NDCG@5 compared to TIGER. Similarly,
on the larger Yelp dataset, EAGER is 20.45% and 3.51% better in
Recall@5 and NDCG@5, respectively. We attribute the improve-
ments to the fact that EAGER succeeds in integrating behavior
and semantics information under a two-stream unified generative
architecture with dual identifiers.
‚Ä¢EAGER beats the previous generative models on most datasets.
EAGER differs from existing models through its two-stream de-
coder architecture and multi-task training, which facilitate a
deeper understanding of behavior-semantic relationships and
capture crucial global information of inter-codes. These superior
improvements validate the effectiveness of our designs and the
necessity of incorporating both behaviors and semantic informa-
tion.
‚Ä¢Generative models outperform other traditional baselines
in most cases across four datasets. The limitation could po-
tentially arise from the utilization of a simplistic inner product
matching approach, which may restrict their ability to effectively
model intricate user-item interactions. Furthermore, in practical
scenarios, the construction of ANN indexes primarily focuses
on achieving rapid matching, leading to additional performance
degradation due to misaligned optimization objectives. However,
the challenge can be overcome by generative methods that lever-
age beam search strategies to directly predict item codes, thereby
boosting the model‚Äôs resilience and robustness.Table 4: Analysis of two-stream generation architecture.
Dataset Yelp
Information R@5 NDCG@5 R@10 NDCG@10
Behav+Text 0.0265 0.0177 0.0453 0.0242
Behav+Vis 0.0259 0.0171 0.0440 0.0236
Behav+Text+Vis 0.0283 0.0187 0.0484 0.0252
Table 5: Analysis of globel token position in global con-
trastive task on different datasets.
Dataset Beauty
Type R@5 NDCG@5 R@10 NDCG@10
Head 0.0473 0.0337 0.0612 0.0401
Mean 0.0559 0.0431 0.0760 0.0502
Tail 0.0604 0.0439 0.0815 0.0514
Dataset Toys and Games
Type R@5 NDCG@5 R@10 NDCG@10
Head 0.0441 0.0303 0.0513 0.0343
Mean 0.0522 0.0406 0.0617 0.0446
Tail 0.0563 0.0454 0.0699 0.0497
4.3 Ablation Study (RQ2)
We evaluated the performance impact of EAGER‚Äôs components via
an ablation study. Specifically, we gradually discard the semantic-
guided transfer task (STT), global constrastive task (GCT) and two-
stream generation architecture (TSG) from EAGER to obtain ab-
lation architectures. The results are reported in Table 3, we can
observe that:
‚Ä¢Removing any TSG, GCT or STT leads to performance degrada-
tion while removing all modules (i.e., the base model) leads to
the worst performance among different datasets. These results
demonstrate the effectiveness and robustness of the proposed
three modules as well as the benefits of the two-stream generative
paradigm.
‚Ä¢Removing GCT leads to more performance drops than removing
STT, suggesting that global information distillation of the inter-
code is slightly more important than the knowledge flow between
the intra-code. The observation also highlights the crucial role of
both tasks in enabling the model to acquire more powerful dual
item identifiers.
‚Ä¢Removing TSG leads to the most performance decline, which
indicates that the base model can significantly enhance its per-
formance by integrating behavior-semantic information of items.
The results again verify the superiority of the dual decoder ar-
chitecture with confidence-based ranking.
4.4 Model Analysis (RQ3)
Analysis of Two-stream Generation Architecture. To further
explore the role of our dual-stream structure in integrating behav-
ior and semantics, we conduct experiments with visual features
3251KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Ye Wang et al.
Table 6: Analysis of the inference speed (second per sample,
topk=5, beam size=100) on Beauty dataset.
DIN RecForest TIGER EAGER
Speed 0.2349 0.0499 0.0281 0.0325
Parameters 93 51 14 87
introduced on Yelp. We use ViT-B to extract image features of item
covers, and then perform the same operation to get the visual-based
semantic code. As shown in Table, we can see that: (1) The combi-
nation of textual semantic features and behavioral information is
more effective than that of visual semantic features. This may be
because text contains more intuitive and richer information than
visual semantics, which can be too abstract and noisy. (2) More-
over, we construct a three-stream architecture to integrate textual
semantics, visual semantics, and behavioral information at once,
which results in improved performance. This phenomenon further
reflects the effectiveness and generalizability of our architecture
for seamless integration of different types of information.
Analysis of Global Contrastive Task. As analyzed in Section
3.4, we consider the auto-regressive decoder lacks discriminative
capability. To tackle the issue, we design a additional global token to
distill the global knowledge from pretrained behavior/semantic en-
coder. In this study, we focus on investigating the impact of different
token types and contrastive metrics on the model‚Äôs performance.
‚Ä¢Token Type. The design of the summary token plays a crucial
role, as it represents global information while having an impact
on the autoregressive generation of the code. We investigate three
token types: ‚ÄôHead‚Äô places the token at the beginning of the code,
‚ÄôTail‚Äô puts the token at the end of the code, and ‚ÄôMean‚Äô directly
uses the mean of the code features. The results in Table indicate
that ‚ÄôTail‚Äô achieves the best performance, which is consistent
with our previous discussion. Placing the token at the beginning
results in unstable training of autoregressive generation due to
frequent updates, while averaging directly impacts the code fea-
tures, causing conflict with generative training. Instead, placing
the token at the end neither directly affects the generation of the
preceding code, nor indirectly optimizes the code representation
through gradient reversal.
‚Ä¢Contrastive metric. In the experiment, we evaluate the per-
formance of three widely adopted distance metrics, e.g. Cosine,
InfoNCE, and Smooth ‚Ñì1, as loss functions. The results presented
in Tab. 7 demonstrate that the positive-only contrastive metrics,
specifically Cosine and Smooth ‚Ñì1, outperform the commonly
used InfoNCE. This superiority can be attributed to two main
reasons: (1) the positive-only contrastive learning approach, com-
bined with frozen pre-trained features, mitigates the risk of rep-
resentation collapsing, as supported by prior works [ 3]. (2) the
dataset often comprises items belonging to specific categories
with limited semantic diversity, such as Books or Sports, which
introduces noise and confusion for negative samples. These chal-
lenging negatives pose difficulty in effective mining, leading to
suboptimal optimization results.Table 7: Analysis of metric functions in global contrastive
task on different datasets.
Dataset Beauty
Metric R@5 NDCG@5 R@10 NDCG@10
Cosine 0.0620 0.0458 0.0842 0.0535
InfoNCE 0.0611 0.0446 0.0820 0.0525
Smooth‚Ñì10.0618 0.0451 0.0836 0.0525
Dataset Toys and Games
Metric R@5 NDCG@5 R@10 NDCG@10
Cosine 0.0578 0.0448 0.0686 0.0488
InfoNCE 0.0558 0.0440 0.0663 0.0478
Smooth‚Ñì10.0584 0.0464 0.0714 0.0505
(a) Beauty
 (b) Toys and Games
Figure 4: Analysis of semantic-guided transfer task module,
where ‚ÄôBehav.‚Äô means we swap the guidance direction.
Analysis of Semantic-guided Transfer Task. We analyze the
objectives and direction in our semantic-guided transfer task.
‚Ä¢Transfer Objective. We design two transfer objectives, i.e., re-
construction and recognition. As illustrated in Fig. 4, removing
either objective leads to a certain degree of performance degrada-
tion, with recognition playing a more vital role. We hypothesize
this is because the recognition task carries out more high-level
knowledge transfer than the local-level reconstruction.
‚Ä¢Transfer Direction. Besides, we also investigate the behavior-
guided transfer by swapping the guidance direction. It can be
observed that the results is inferior to the semantic guidance,
which is reasonable since the semantic information can provide
more prior knowledge related to the item itself.
4.5 Hyper-Parameter Analysis (RQ3)
Layer Number. In our practice, we found that the number of
encoder layers has a negligible effect on performance, whereas the
number of decoder layers has a more significant influence. It sug-
gests that the decoder plays a more important role in our EAGER.
Therefore, we focus on the decoder layer here. To study the impact
of the number of decoder layers on model performance, we ana-
lyze the changes in Recall@10 and NDCG@10 across two datasets
by varying layer scales. As shown in Fig. 5, there is a continuous
improvement in the model‚Äôs performance in both datasets by in-
creasing the number of layers. This can be attributed to the fact that
larger parameters can enhance the model‚Äôs expressive capability.
However, the deeper the model, the slower the inference speed.
3252EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain
(a) Beauty
 (b) Toys and Games
Figure 5: Analysis of the number of transformer layers in
decoders.
(a) Beauty
 (b) Toys and Games
Figure 6: Impact of branch number ùëò, ranging from 64 to 512,
in terms of Recall@10. The corresponding identifier length ùëô
is also annotated.
Cluster Number. We investigated the impact of employing vary-
ing branch numbers ùëòon model performance. The increase in
branch number ùëòleads to a corresponding decrease in the length ùëô
of the item identifier according to the total number of items. The
experiment is conducted on two datasets, Beauty and Toys. aThe
results are illustrated in Fig. 6. We observe that as ùëòincreases from
64 to 512, the model performance of the base and ours both mono-
tonically increase on the Toys dataset. However, an interesting
trend emerged on the Beauty dataset, where we observed a decline
in performance as ùëòincreased from 256 to 512. The performance
improvement resulting from increasing ùëòcan be attributed to the re-
duction in identifier length ùëô, but an excessively larger ùëòcan lead to
a decline in model performance and increase inference time. More-
over, our methods always show a better performance than the base
one, which suggests the superiority of two-decoder architecture.
5 CONCLUSION AND FUTURE WORK
In this paper, we introduce a novel framework, EAGER, designed
to integrate behavioral and semantic information for unified gener-
ative recommendation. EAGER comprises three key components:
(1) a two-stream generation architecture that combines behavioral
and semantic information to enhance item recommendation, (2)
a global contrastive task with a summary token to capture global
knowledge for improved auto-regressive generation quality, and (3)
a semantic-guided transfer task that facilitates interactions acrosstwo decoders and their features. Extensive comparisons with state-
of-the-art methods and detailed analyses demonstrate the effective-
ness and robustness of EAGER. In future work, we plan to further
enhance generative recommendation models by incorporating large
language models and multimodal AI techniques [5].
ACKNOWLEDGMENTS
We thank MindSpore3for the partial support of this work, which
is a new deep learning computing framework.
REFERENCES
[1]Michele Bevilacqua, Giuseppe Ottaviano, Patrick Lewis, Scott Yih, Sebastian
Riedel, and Fabio Petroni. 2022. Autoregressive search engines: Generating
substrings as document identifiers. Advances in Neural Information Processing
Systems 35 (2022), 31668‚Äì31683.
[2]Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. A
simple framework for contrastive learning of visual representations. In Interna-
tional conference on machine learning. PMLR, 1597‚Äì1607.
[3]Xinlei Chen and Kaiming He. 2021. Exploring simple siamese representation
learning. In Proceedings of the IEEE/CVF conference on computer vision and pattern
recognition. 15750‚Äì15758.
[4]Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:
Pre-training of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:1810.04805 (2018).
[5]Zhenhua Dong, Jieming Zhu, Weiwen Liu, and Ruiming Tang. 2023. Ten Chal-
lenges in Industrial Recommender Systems. CoRR abs/2310.04804 (2023).
[6]Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-
aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, et al .2020. An image is worth 16x16 words: Transformers
for image recognition at scale. arXiv preprint arXiv:2010.11929 (2020).
[7]Chao Feng, Wuchao Li, Defu Lian, Zheng Liu, and Enhong Chen. 2022. Recom-
mender Forest for Efficient Retrieval. Advances in Neural Information Processing
Systems 35 (2022), 38912‚Äì38924.
[8]Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix Chern, and
Sanjiv Kumar. 2020. Accelerating large-scale inference with anisotropic vector
quantization. In International Conference on Machine Learning. PMLR, 3887‚Äì3896.
[9]Bal√°zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.
2015. Session-based recommendations with recurrent neural networks. arXiv
preprint arXiv:1511.06939 (2015).
[10] Dietmar Jannach and Malte Ludewig. 2017. When recurrent neural networks
meet the neighborhood for session-based recommendation. In Proceedings of the
eleventh ACM conference on recommender systems. 306‚Äì310.
[11] Bowen Jin, Hansi Zeng, Guoyin Wang, Xiusi Chen, Tianxin Wei, Ruirui Li,
Zhengyang Wang, Zheng Li, Yang Li, Hanqing Lu, Suhang Wang, Jiawei Han,
and Xianfeng Tang. 2023. Language Models As Semantic Indexers. CoRR
abs/2310.07815 (2023).
[12] Mengqun Jin, Zexuan Qiu, Jieming Zhu, Zhenhua Dong, and Xiu Li. 2024. Con-
trastive Quantization based Semantic Code for Generative Recommendation.
CoRR abs/2404.14774 (2024).
[13] Jeff Johnson, Matthijs Douze, and Herv√© J√©gou. 2019. Billion-scale similarity
search with gpus. IEEE Transactions on Big Data 7, 3 (2019), 535‚Äì547.
[14] Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom-
mendation. In 2018 IEEE international conference on data mining (ICDM). IEEE,
197‚Äì206.
[15] Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman
Mohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. BART:
Denoising Sequence-to-Sequence Pre-training for Natural Language Generation,
Translation, and Comprehension. In Proceedings of the 58th Annual Meeting of
the Association for Computational Linguistics. 7871‚Äì7880.
[16] Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yuyao Zhang, Peitian Zhang, Yutao Zhu, and
Zhicheng Dou. 2024. From Matching to Generation: A Survey on Generative
Information Retrieval. CoRR abs/2404.14851 (2024).
[17] Qijiong Liu, Hengchang Hu, Jiahao Wu, Jieming Zhu, Min-Yen Kan, and Xiao-
Ming Wu. 2024. Discrete Semantic Tokenization for Deep CTR Prediction. In
Companion Proceedings of the ACM on Web Conference (WWW). 919‚Äì922.
[18] Qijiong Liu, Jieming Zhu, Yanting Yang, Quanyu Dai, Zhaocheng Du, Xiao-Ming
Wu, Zhou Zhao, Rui Zhang, and Zhenhua Dong. 2024. Multimodal Pretraining,
Adaptation, and Generation for Recommendation: A Survey. CoRR abs/2404.00621
(2024).
3https://www.mindspore.cn
3253KDD ‚Äô24, August 25‚Äì29, 2024, Barcelona, Spain Ye Wang et al.
[19] Chen Ma, Peng Kang, and Xue Liu. 2019. Hierarchical gating networks for
sequential recommendation. In Proceedings of the 25th ACM SIGKDD international
conference on knowledge discovery & data mining. 825‚Äì833.
[20] Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.
2015. Image-based recommendations on styles and substitutes. In Proceedings
of the 38th international ACM SIGIR conference on research and development in
information retrieval. 43‚Äì52.
[21] Jianmo Ni, Gustavo Hernandez Abrego, Noah Constant, Ji Ma, Keith Hall, Daniel
Cer, and Yinfei Yang. 2022. Sentence-T5: Scalable Sentence Encoders from Pre-
trained Text-to-Text Models. In Findings of the Association for Computational
Linguistics: ACL 2022. 1864‚Äì1874.
[22] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of
transfer learning with a unified text-to-text transformer. The Journal of Machine
Learning Research 21, 1 (2020), 5485‚Äì5551.
[23] Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan H Keshavan, Trung
Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Q Tran, Jonah Samost, et al .2023.
Recommender Systems with Generative Retrieval. arXiv preprint arXiv:2305.05065
(2023).
[24] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor-
izing personalized markov chains for next-basket recommendation. In Proceedings
of the 19th international conference on World wide web. 811‚Äì820.
[25] Hongyu Shan, Qishen Zhang, Zhongyi Liu, Guannan Zhang, and Chenliang
Li. 2023. Beyond Two-Tower: Attribute Guided Representation Learning for
Candidate Retrieval. In Proceedings of the ACM Web Conference 2023. 3173‚Äì3181.
[26] Zihua Si, Zhongxiang Sun, Jiale Chen, Guozhang Chen, Xiaoxue Zang, Kai Zheng,
Yang Song, Xiao Zhang, and Jun Xu. 2023. Generative Retrieval with Seman-
tic Tree-Structured Item Identifiers via Contrastive Learning. arXiv preprint
arXiv:2309.13375 (2023).
[27] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.
2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-
resentations from transformer. In Proceedings of the 28th ACM international
conference on information and knowledge management. 1441‚Äì1450.
[28] Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda-
tion via convolutional sequence embedding. In Proceedings of the eleventh ACM
international conference on web search and data mining. 565‚Äì573.
[29] Yi Tay, Vinh Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta,
Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, et al .2022. Transformer memory as a
differentiable search index. Advances in Neural Information Processing Systems
35 (2022), 21831‚Äì21843.
[30] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[31] Jinpeng Wang, Jieming Zhu, and Xiuqiang He. 2021. Cross-Batch Negative
Sampling for Training Two-Tower Recommenders. In The 44th International ACMSIGIR Conference on Research and Development in Information Retrieval (SIGIR).
1632‚Äì1636.
[32] Yujing Wang, Yingyan Hou, Haonan Wang, Ziming Miao, Shibin Wu, Qi Chen,
Yuqing Xia, Chengmin Chi, Guoshuai Zhao, Zheng Liu, et al .2022. A neural
corpus indexer for document retrieval. Advances in Neural Information Processing
Systems 35 (2022), 25600‚Äì25614.
[33] Ji Yang, Xinyang Yi, Derek Zhiyuan Cheng, Lichan Hong, Yang Li, Simon Xi-
aoming Wang, Taibai Xu, and Ed H. Chi. 2020. Mixed Negative Sampling for
Learning Two-tower Neural Networks in Recommendations. In Companion of
The Web Conference (WWW). 441‚Äì447.
[34] Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu
Pan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs.
modality-based recommender models revisited. arXiv preprint arXiv:2303.13835
(2023).
[35] Peitian Zhang, Zheng Liu, Yujia Zhou, Zhicheng Dou, and Zhao Cao. 2023. Term-
Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines.
arXiv preprint arXiv:2305.13859 (2023).
[36] Tingting Zhang, Pengpeng Zhao, Yanchi Liu, Victor S Sheng, Jiajie Xu, Deqing
Wang, Guanfeng Liu, Xiaofang Zhou, et al .2019. Feature-level Deeper Self-
Attention Network for Sequential Recommendation.. In IJCAI. 4320‚Äì4326.
[37] Yidan Zhang, Ting Zhang, Dong Chen, Yujing Wang, Qi Chen, Xing Xie, Hao
Sun, Weiwei Deng, Qi Zhang, Fan Yang, et al .2023. IRGen: Generative Modeling
for Image Retrieval. arXiv preprint arXiv:2303.10126 (2023).
[38] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui
Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through
rate prediction. In Proceedings of the 24th ACM SIGKDD international conference
on knowledge discovery & data mining. 1059‚Äì1068.
[39] Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang,
Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-rec: Self-supervised learning for se-
quential recommendation with mutual information maximization. In Proceedings
of the 29th ACM international conference on information & knowledge management .
1893‚Äì1902.
[40] Yujia Zhou, Jing Yao, Zhicheng Dou, Ledell Wu, Peitian Zhang, and Ji-Rong Wen.
2022. Ultron: An ultimate retriever on corpus with a model-based indexer. arXiv
preprint arXiv:2208.09257 (2022).
[41] Han Zhu, Daqing Chang, Ziru Xu, Pengye Zhang, Xiang Li, Jie He, Han Li, Jian
Xu, and Kun Gai. 2019. Joint optimization of tree-based index and deep model
for recommender systems. Advances in Neural Information Processing Systems 32
(2019).
[42] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai.
2018. Learning tree-based deep model for recommender systems. In Proceedings
of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. 1079‚Äì1088.
3254