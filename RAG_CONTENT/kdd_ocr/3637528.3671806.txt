Practical Single Domain Generalization via Training-time and
Test-time Learning
Shuai Yang
School of Information and Artificial
Intelligence
Anhui Agricultural University
Hefei, Anhui, China
yangs@ahau.edu.cnZhen Zhang
School of Information and Artificial
Intelligence
Anhui Agricultural University
Hefei, Anhui, China
zhangz@stu.ahau.edu.cnLichuan Gu∗
School of Information and Artificial
Intelligence
Anhui Agricultural University
Hefei, Anhui, China
glc@ahau.edu.cn
ABSTRACT
Single domain generalization aims to learn a model that generalizes
well to unseen target domains by using a related source domain.
However, most existing methods only focus on improving the gen-
eralization performance of the model during training, making it
difficult to achieve satisfactory performance when deployed in the
target domain with large domain shifts. In this paper, we propose a
Practical Single Domain Generalization (PSDG) method, which first
leverages the knowledge in a source domain to establish a model
with good generalization ability in the training phase, and subse-
quently updates the model to adapt to target domain data using
knowledge in the unlabeled target domain during the testing phase.
Specifically, during training, PSDG leverages a newly proposed
style (e.g., background features) generator named StyIN to gener-
ate novel domain data. Moreover, PSDG introduces style-diversity
regularization to constantly synthesize distinct styles to expand the
coverage of training data, and introduces object-consistency regu-
larization to capture consistency between the currently generated
data and the original data, making the model filter style knowl-
edge during training. During testing, PSDG uses a sample-aware
and sharpness-aware minimization method to seek for a flat en-
tropy minimum surface for further model optimization by using the
knowledge in the unlabeled target domain. Using three real-world
datasets the experiments have demonstrated the effectiveness of
PSDG, in comparison with several state-of-the-art methods.
CCS CONCEPTS
•Computing methodologies →Machine learning; Transfer
learning; Learning latent representations.
KEYWORDS
Domain generalization, Data augmentation, Test-time adaptation,
Representation learning
∗Corresponding author
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain.
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671806ACM Reference Format:
Shuai Yang, Zhen Zhang, and Lichuan Gu. 2024. Practical Single Domain
Generalization via Training-time and Test-time Learning. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining
(KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA,
12 pages. https://doi.org/10.1145/3637528.3671806
1 INTRODUCTION
Deep neural networks (DNNs) have achieved dramatic successes
in a wide range of applications [ 9,17,20]. However, these suc-
cesses rely on the assumption that the training (source domain)
data share the same distribution as the test (target domain) data.
In practice, such the assumption is often violated, since the target
domain data inevitably encounter natural variations or corruptions
such as changes in weather, scenes and sensor devices, which are
termed domain shifts. Unfortunately, DNNs often suffer from severe
performance degradation even slight domain shifts [5].
To tackle this issue, one branch of work focuses on multi-source
domain generalization, which uses only data from multiple source
domains to train a model without accessing the target domain data
[31,34,41,44]. Nevertheless, in the wild environments, acquir-
ing sufficient training data from multiple source domains is often
impractical due to data collection budgets [ 38]. As an alternative,
single domain generalization has been presented [ 15,35], with the
aim at using only a single-source domain data to train a robust
model that generalizes well to unseen target domains.
The key idea to address single domain generalization is to miti-
gate the distribution discrepancies between the source domain and
unseen target domains. In practical applications, the style features,
such as background features, are unstable across different domains.
In contrast, the content features, such as the object features, are
stable regardless of how the environment changes [ 40]. Therefore,
the core of single domain generalization is to eliminate spurious
correlations between style features and labels. Recently, numer-
ous methods for single domain generalization have been proposed
[7,15,28,35], which mainly focus on increasing the capacity of the
training data by synthesizing novel domains, and thus weaken the
attention of the model on style features due to the increase of style
diversity of training data. Existing single domain generalization
methods can be generally grouped into two different types. The first
type of method generates diverse samples by using back-propagated
gradients to perturb original samples, such as ADA [ 28], M-ADA
[24], and NCDG [ 26]. However, gradient-based perturbations are
visually imperceptible and thus these methods cannot simulate
real-world domain shifts. To alleviate this problem, the second type
3794
KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
Figure 1: (a), (b), (c), and (d) are examples from the Photo,
Art painting, Cartoon, and Sketch domains from the PACS
dataset, respectively.
of method uses convolutional neural networks to synthesize new
style data, such as PDEN [15], L2D [35], and UDP [7].
Previous methods have made tremendous progress in single
domain generalization, but three limitations are still existed. First,
these methods pay little attention to the inter-domain discrepancies
between the currently generated data and the previously gener-
ated data, and thus cannot well constantly generate new style data,
resulting in a limited range of styles. Second, since the object fea-
tures of the original data and the corresponding generated data are
consistent, learning consistent features between them can enhance
the robustness of feature representations. However, existing meth-
ods either use contrastive learning or directly mix the generated
and original data together to learn feature representations, there
is still room for further capturing consistency in learning feature
representations. Third, these methods only focus on improving
the generalization ability of the model during training. In prac-
tice, the slight content shift is ubiquitous. For instance, the PACS
dataset contains four domains, i.e., Photo, Art painting, Cartoon,
and Sketch, obviously, the shapes of objects in the four domains
are slightly different, as shown in Fig. 1. However, these methods
are difficult to accurately classify target domain data when slight
content shifts occur [ 10,39], and thus relying solely on a model
learned during the training phase is inadequate.
Accordingly, a question naturally arises: can we boost the gen-
eralization performance of model in both the training and testing
phases? That is, in the training phase, can we further improve the
style diversity of training data and feature invariance to enhance
the generalization capability of the model? Whereas in the testing
phase, can we further optimize the model by using knowledge in
the unlabeled target domain?
Motivated by the aforementioned issues, we propose a Practical
Single Domain Generalization (PSDG) method, which performs
both training-time and test-time learning to boost the model’s
performance on the target domain. Specifically, in the training
phase, PSDG incorporates a style diversity module with an innova-
tive StyIN generator for synthesizing new style data. Additionally,
style-diversity regularization is incorporated to encourage newly
generated data to be as far away from existing data as possible in fea-
ture and pixel space. Moreover, PSDG introduces a representation
learning module that employs object-consistency regularization
to capture invariance between the currently generated data and
the original data. PSDG constantly synthesizes multiple fresh do-
mains with distinct styles by iteratively optimizing the two modules
to filter domain-specific knowledge, promoting the generalizationperformance of the model. In the testing phase, PSDG incorpo-
rates sample-aware and sharpness-aware minimization (SAM) [ 6]
method, which combines confidence-based sample reweighting and
sharpness-based optimization to pursue a flat entropy minimum
surface for further model optimization by leveraging the specific
knowledge in the target domain. Our main contributions are sum-
marized as follows:
•We propose a PSDG algorithm that performs both training-
time and test-time learning to improve the performance on
an arbitrary target domain following a different distribution,
which is more practical than conventional single domain
generalization methods of only training-time learning.
•To boost the generalization ability of the model during train-
ing, PSDG uses a style diversity module with a novel style
generator StyIN and a representation learning module with
object-consistency regularization for continuous generation
of new style data to filter style knowledge.
•To make the model learned in the training phase adapt to tar-
get domain data during testing, PSDG combines confidence-
based sample reweighting and sharpness-based optimization
to find a flat entropy minimum surface for model optimiza-
tion by using knowledge in the target domain.
•We perform extensive experiments using three public single
domain generalization datasets, and compare PSDG with
several state-of-the-art methods to validate its effectiveness.
2 RELATED WORK
Single domain generalization. The goal of single domain general-
ization is to learn a model with good generalization performance by
leveraging the knowledge in a single source domain during training.
Previous works mainly focus on expanding and diversifying the
distribution of training data by augmenting source domain data,
and they generally fall into two distinct types. The first type of
method performs adversarial data augmentation. Representatively,
ADA [ 28] disturbs original samples using back-propagated gradi-
ents obtained from the classification loss to generate new samples
with the same semantic information as the original ones. Guided
by this work, M-ADA [ 24] incorporates Wasserstein Auto-encoders
to enlarge the distance between the generated and original data
in the raw feature space, and learns feature representations with
good generalization ability via meta-learning. Along with ADA and
M-ADA, ASR-Norm uses neural networks to learn both standard-
ization and rescaling statistics, adapting them to different domains
of data. ME-ADA [ 42] generates new domains with large domain
shifts by increasing the mutual information of the source and gen-
erated data. Later on, NCDG [ 26] simultaneously maximizes the
neuron coverage of deep neural networks and the gradient sim-
ilarity between the generated and original data to enhance the
generalization performance. AdvST [ 43] augments the source do-
main data through semantic transformation, resulting in semantic
changes and new styles with significant variations.
The second type of method uses convolutional neural networks
as generators to synthesize novel domain data. For instance, PDEN
[15] progressively generates multiple domains to simulate photo-
metric and geometric transforms in unseen domains by using a
progressive domain expansion network. However, PDEN relies on
3795Practical Single Domain Generalization via Training-time and Test-time Learning KDD ’24, August 25–29, 2024, Barcelona, Spain.
two generators to preserve semantic information. L2D [ 35] intro-
duces a style-complement module to generate new style data and
optimizes them by minimizing the mutual information between
the generated and original data. Nevertheless, L2D might generate
data with distorted semantic information. Pro-RandConv [ 4] recur-
sively stacks random convolution layers with a small kernel size
to improve the style diversity while preserving class-specific se-
mantic information. UDP [ 7] minimizes the uncertainty coefficients
between the augmented and original samples from an information-
theoretic perspective.
We argue that existing single domain generalization methods
primarily concentrate on enhancing the model’s generalization
performance during the training phase. In contrast, our approach
engages in both training-time and test-time learning, ensuring the
model adapts to diverse target domains.
Test-time adaptation (TTA). The aim of test-time adaptation
is to mitigate domain shifts by using test data to optimize the
model during testing. Massive efforts have been made for TTA in
recent years, and existing methods can be broadly divided into
two categories, i.e., test-time training (TTT) and Fully TTA. The
basic paradigm of TTT methods is to additionally design a self-
supervised auxiliary task during training, and update them for
model optimization during the testing phase, such as TTT [ 25], MT3
[1], TTT++ [ 18], and OST [ 3]. Recent studies [ 2,30] have shown that
if inappropriate self-supervised tasks that are inconsistent with the
primary task are used, the performance of existing TTT methods
will deteriorate. In contrast, Fully TTA is more practical because
it does not require the addition of any auxiliary self supervised
objectives during training and can adapt to arbitrary models, which
uses entropy minimization to update the model during testing, such
as EATA [ 22], SAR [ 23], and DeYo [ 11]. However, most Fully TTA
methods need to filter out high-entropy samples to reduce the effect
of unreliable samples. In practice, the threshold for filtering samples
with high-entropy is not easy to choose.
It is worth noting that TTT methods rely on self-supervised
auxiliary tasks, and Fully TTA only focuses on test-time adaptation.
However, our method does not require the use of self-supervised
auxiliary tasks, and focuses on both training-time and test-time
learning to make the model adapt to the target domain.
3 PROPOSED METHODS
3.1 Problem Formulation and Overview
Problem Formulation. A labeled source domain 𝐷𝑠={𝑥𝑖,𝑦𝑖}𝑛
𝑖=1
with𝑛samples is available during the training phase, where 𝑥𝑖and
𝑦𝑖represent the 𝑖𝑡ℎsample and the class label of 𝑥𝑖, respectively,
and a modelM𝜃with parameter 𝜃trained on𝐷𝑠and an arbitrary
unlabeled target domain 𝐷𝑡=
𝑥𝑡
𝑖	𝑛𝑡
𝑖=1with𝑛𝑡samples is available
during the testing phase, where 𝑥𝑡
𝑖denotes the 𝑖𝑡ℎsample of𝐷𝑡.
The goal of our method is to first learn a model M𝜃with good
generalization ability by using the knowledge in 𝐷𝑠, and then
use information from 𝐷𝑡to further optimize M𝜃toimprove the
prediction performance on𝐷𝑡.
Overview of PSDG. We propose the PSDG algorithm to tackle
the domain shift issue by performing training-time and test-time
learning. PSDG consists of four components, including: (1) feature
extractor Φ(·;𝜃Φ):X→F , whereXandFare the image space andthe feature space, respectively; (2) classifier head 𝑓(·;𝜃𝑓):F→P ,
wherePis the prediction label space; (3) object projection head
𝑧(·;𝜃𝑧):F →Z , whereZis the low-dimensional space of F;
(4) generator 𝐺(·;𝜃𝐺), which is used to synthesize new data. The
PSDG framework is illustrated in Fig. 2. In the training phase, the
training strategy commences with the pretraining of the represen-
tation learning module using original data, followed by iterative
optimization of the representation learning module and the style
diversity module, allowing the two modules to mutually enhance
each other. To be specific, Φ(·;𝜃Φ),𝑓(·;𝜃𝑓), and𝑧(·;𝜃𝑧)are shared
across both modules. Φ(·;𝜃Φ),𝑓(·;𝜃𝑓), and𝑧(·;𝜃𝑧)are updated,
while𝐺(·;𝜃𝐺)remains fixed when learning feature representations.
Conversely, during the generation of new data, 𝐺(·;𝜃𝐺)is updated,
whereas Φ(·;𝜃Φ),𝑓(·;𝜃𝑓), and𝑧(·;𝜃𝑧)remain fixed. PSDG itera-
tively updates these two modules and generates multiple novel
domains to expand the coverage of training data, filtering style
knowledge. For simplicity, in the training phase, the learned model
is referred asM𝜃. During testing, PSDG employs sample-aware
and sharpness-aware minimization to obtain a flat entropy min-
imum surface using specific knowledge in the target domain for
subsequent model optimization. In the following, we provide the
details of PSDG.
3.2 Training-time Learning
1) Representation learning module. The objective of represen-
tation learning module is to capture invariant representations that
exhibit strong generalization capabilities. Before providing the de-
tails of the proposed representation learning module, we give the
following Theorem 1.
Theorem 1 [ 21].Given a finite number of domains K, with the
number of samples 𝑛in each domain approaching infinity, the set of
representations that fulfill the conditionÍ
Ω(𝑖,𝑗)=1;𝑑≠𝑑′dist Φ(𝑥(𝑑)
𝑖),
Φ(𝑥(𝑑′)
𝑗)=0includes the optimal Φ(𝑥)=𝑥𝑐that minimizes the
domain generalization loss, denoted as arg min𝑓E[ℓ(𝑦,𝑓(Φ(𝑥𝑐)))],
where𝑥𝑐are causal features that are robust across different domains.
Here,Ω:X×X→{ 0,1}is a matching function that equals 1 for
pairs of inputs across domains corresponding to the same object and 0
otherwise. The indexes 𝑑and𝑑′represent different domains.
Motivated by Theorem 1, we leverage the generated data to
capture invariance. Considering that the generated data 𝑥+
𝑖(the
details for generating 𝑥+
𝑖are provided in Style diversity module ) and
the original data 𝑥𝑖have the same object with distinct styles, our
expectation is that the feature representations (i.e., Φ(𝑥𝑖)) of𝑥𝑖
and the feature representations (i.e., Φ(𝑥+
𝑖)) of𝑥+
𝑖should exhibit
similarity, thereby mitigating spurious correlations between style
features and labels. To this end, cross-entropy coupled with object-
consistency regularization is incorporated to capture consistency
between the original data and the currently generated data. First,
the classifier 𝑓(·)should accurately predict both the original and
generated data. To achieve this, we minimize the following cross-
entropy loss.
L𝑟=𝑛∑︁
𝑖=1ℓ 𝑦𝑖,𝑓(Φ(𝑥𝑖))+ℓ 𝑦𝑖,𝑓(Φ(𝑥+
𝑖)), (1)
3796KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
Figure 2: The framework of PSDG, mainly containing training-time learning and test-time learning. During training, PSDG
integrates a representation learning module designed to learn invariant representations with good generalization ability and a
style diversity module dedicated to generating new style data. Initially, PSDG pretrains the representation learning module
using data from a single source domain. Subsequently, PSDG iteratively optimizes these two modules to augment multiple
novel domains. During testing, PSDG first computes the confidence of the predictive results by measuring the two largest
values in the prediction logit of a given target sample, and then integrates them into sharpness-aware minimization to find a
flat entropy minimum surface for further model optimization.
whereℓ(·)is the cross-entropy loss.
Second, object-consistency regularization that consists of object-
level contrastive learning loss and residual uncertainty loss is in-
troduced to capture domain invariance. To be specific, we aim to
maximize the correlation between an original sample in the source
domain and its augmented sample in the feature representation
space. Inspired by [ 13,27], we maximize the lower bound of mutual
information through contrastive learning, introducing object-level
contrastive learning to facilitate PSDG learning invariant represen-
tations. Specifically, we treat the source domain and the augmented
domain as distinct domains, considering 𝑥𝑖and𝑥+
𝑖as a paired
sample. Consequently, the object-level contrastive learning loss is
defined as follows.
L𝑜=2𝑛∑︁
𝑖=1−logexp(𝑧𝑖·𝑧+
𝑖/𝜏)
Í2𝑛
𝑗=1,𝑗≠𝑖exp(𝑧𝑖·𝑧𝑗/𝜏), (2)
where𝑧𝑖=𝑧(Φ(𝑥𝑖)),𝑧+
𝑖=𝑧(Φ(𝑥+
𝑖)).𝜏is a temperature parameter.
Nevertheless, object-level contrastive learning primarily focuses
on entire features, potentially encompassing style features. There-
fore, relying solely on these features might lead the model to align
only partial aspects of the style features. Recent research has re-
vealed that an image’s prediction distribution correlates with class
activation maps, which highlight the content the model is concerned
with [ 16]. Inspired by this, we calculate the residual component,
which is the change in the original representation relative to theaugmented representation. If the original sample and its augmented
sample focus on the same region (i.e., content), then the residual
component should not contain classification information, that is,
the residual component should have the maximum prediction un-
certainty. Therefore, we propose incorporating residual uncertainty
loss to ensure that PSDG consistently focuses on the same region
when predicting labels for both the original and generated data as
follows.
L𝑐=𝑛∑︁
𝑖=1𝐶∑︁
𝑐=1−𝑒𝑐
𝑖·log𝑒𝑐
𝑖−𝑒𝑐
𝑖,★·log𝑒𝑐
𝑖,★, (3)
where𝑒𝑖=𝑓(Φ(𝑥+
𝑖)−Φ(𝑥𝑖)),𝑒𝑖,★=𝑓(Φ(𝑥★
𝑖)−Φ(𝑥𝑖)),𝐶is the num-
ber of categories, 𝑒𝑐
𝑖and𝑒𝑐
𝑖,★are the class 𝑐prediction probabilities
of the residual component Φ(𝑥+
𝑖)−Φ(𝑥𝑖),Φ(𝑥★
𝑖)−Φ(𝑥𝑖), respec-
tively.𝑥★
𝑖is an augmented sample of 𝑥𝑖(the details for generating
𝑥★
𝑖are provided in Style diversity module ).
Based on Eq. (1), Eq. (2), and Eq. (3), we formulate the objective
function of the representation learning module as Eq. (4) as follows.
L𝑅=L𝑟+L𝑜−L𝑐. (4)
2) Style diversity module. The goal of style diversity module
is to yield diverse style data sharing similar semantic information
with the original one. To satisfy this requirement, we design a
generator𝐺composed of encoder 𝐺𝑒𝑛, StyIN, and decoder 𝐺𝑑𝑒to
synthesize new data. Specifically, 𝐺first adopts𝐺𝑒𝑛to encode the
3797Practical Single Domain Generalization via Training-time and Test-time Learning KDD ’24, August 25–29, 2024, Barcelona, Spain.
input image 𝑥𝑖to obtain latent representations 𝑟𝑖=𝐺𝑒𝑛(𝑥𝑖). Then,
𝐺uses StyIN to perturb the style at the latent representation layer.
To generate data with large style shifts, StyIN performs two affine
transformations. StyIN uses two fully connected layers Fc 1(·)and
Fc2(·)to encode a Gaussian noise 𝜀∼N( 0,1)to learn variance shift
parameter Fc 1(𝜀)and mean shift parameter Fc 2(𝜀), respectively,
and then performs the first affine transformation on 𝑟𝑖to obtain
style perturbation data 𝑟′
𝑖=AdaIN(𝑟𝑖,𝜀)as follows.
AdaIN(𝑟𝑖,𝜀)=Fc1(𝜀)r𝑖−𝜇(r𝑖)√︁
𝜎2(r𝑖)+𝜖+Fc2(𝜀), (5)
where𝜇(·)is the mean, 𝜎2(·)is the variance, and 𝜖is a positive
number. However, although Eq. (5) can change the styles of the
original data, we have found from the experimental results that it
only produces data with a single-color background, thereby lim-
iting the range of styles and failing to cover the target domain
with large shifts. To this end, based on AdaIN, we propose StyIN,
which conducts a second affine transformation to further enhance
diversity while ensuring safety as follows.
StyIN(𝑟𝑖,𝜀,𝜂)= 1+Fc3(𝜀)(AdaIN(𝑟𝑖,𝜀)+𝜂)+Fc4(𝜀),(6)
where Fc 3(·)and Fc 4(·)are two fully connected layers. Here, we
introduce additional Gaussian noise 𝜂∼N( 0,1)to directly perturb
the AdaIN to further enlarge style shifts. As 𝜂directly affects AdaIN,
potentially changing the original semantic information, we employ
constant 1 (i.e., 1+Fc3(𝜀)) to ensure the transformation process,
including the original representations, maintaining semantic con-
sistency. Finally, 𝐺adopts𝐺𝑑𝑒to decode StyIN(𝑟𝑖,𝜀,𝜂)to obtain
augmented data 𝑥+
𝑖.
In summary, when the inputs 𝑥𝑖and𝜀are given,𝐺can obtain
the augmented sample 𝑥+
𝑖=𝐺(𝑥𝑖,𝜀,𝜂)as the following Eq. (7).
𝐺(𝑥𝑖,𝜀,𝜂)=𝐺𝑑𝑒(StyIN(𝐺𝑒𝑛(x𝑖),𝜀,𝜂)). (7)
To ensure that the augmented data have a different style from
the original data, we introduce style-diversity regularization that
consists of feature maximization loss and pixel maximization loss
to improve the diversity of newly generated style data from both
feature-level and pixel-level. Specifically, first, the feature repre-
sentations of the augmented data and the original data need to
have slight differences. To meet this requirement, we learn feature
representations of the input image using the feature extractor Φ,
and further map feature representations to low-dimensional space
through the object projection head z, and introduce the following
feature maximization loss L𝑓to enlarge the difference between
a sample in the source domain and its augmented sample (i.e., a
sample pair) inZspace.
L𝑓=1
Í2𝑛
𝑖=1−log
exp(𝑧𝑖·𝑧+
𝑖/𝜏)Í2𝑛
𝑗=1,𝑗≠𝑖exp(𝑧𝑖·𝑧𝑗/𝜏).(8)
L𝑓is the inverse of the L𝑜loss.L𝑜andL𝑓are used in the represen-
tation learning module and the style diversity module, respectively.
We train the two modules in an adversarial manner. Note that we
find that the optimization process becomes difficult if we directly
useL𝑓=−L𝑜instead ofL𝑓=1
L𝑜. Therefore, we use L𝑓=1
L𝑜.
Second,𝐺relies on the input 𝜀to generate new style data. To in-
crease the style diversity of augmented data, given different valuesof𝜀, the input of 𝐺should be different. That is, 𝑥+
𝑖=𝐺(𝑥𝑖,𝜀1,𝜂1)
should be different from 𝑥★
𝑖=𝐺(𝑥𝑖,𝜀2,𝜂2), where𝜀1,𝜂1∼N( 0,1)
and𝜀2,𝜂2∼N( 0,1)are Gaussian noises. Moreover, inspired by
[15], we also progressively generate multiple domains (i.e., progres-
sively learning multiple generators) to expand the style coverage
of training data. Therefore, to improve the effectiveness of the
generated new style data, we expect to constantly generate new
styles, that is, the current generated style of 𝑥𝑖should be different
from previously generated styles. To this end, the following pixel
maximization loss is adopted.
L𝑝=1Í𝑛
𝑖=1𝑥+
𝑖−𝑥★
𝑖
2+1
Í𝐾−1
𝑘=1Í𝑛
𝑖=1𝑥+
𝑖−𝑥+
𝑖,𝑘2,(9)
where𝐾(initially set to 1) represents the number of generators.
𝑥+
𝑖,𝑘denotes an augmented sample derived from 𝑥𝑖and generated
by the𝑘𝑡ℎgenerator. The first term ensures that the generator pro-
duces diverse style data with distinct 𝜀. The subsequent term serves
to increase the inter-domain discrepancies between the presently
generated data and the data generated earlier.
Finally,𝑥+
𝑖is the augmented sample derived from 𝑥𝑖, and as such,
accurate predictions by the classifier 𝑓(·)are expected for them to
retain the semantic information. To achieve this, we minimize the
following cross-entropy loss.
L𝑑=𝑛∑︁
𝑖=1ℓ 𝑦𝑖,𝑓(Φ(𝑥+
𝑖)), (10)
where𝑓(Φ(𝑥+
𝑖))is the predicted labels of 𝑥+
𝑖. Besides, we also in-
corporate residual uncertainty loss L𝑐to ensure the generation of
data devoid of semantic information distortions.
In summary, we formulate the objective function of the style
diversity module as Eq. (11) as follows.
L𝐺=L𝑑−L𝑐+𝜆𝑓L𝑓+𝜆𝑝L𝑝, (11)
where𝜆𝑓and𝜆𝑝are the balancing parameters.
In practical scenarios, the collected data exhibit inherent com-
plexity. Generating data from a single domain poses limitations on
the capacity of training data, potentially leading to the capture of
spurious correlations between style features and class labels. To ad-
dress this issue, we adopt a progressive strategy by learning 𝐾style
generators, denoted as 𝐺(·;𝜃𝐺)=
𝐺1(·;𝜃𝐺1),···,𝐺𝐾(·;𝜃𝐺𝐾)	
.
These generators are employed to generate 𝐾new domain datasets,
each with distinct styles, enabling the learning of domain invari-
ant representations. Here, 𝐺𝑖(·;𝜃𝐺𝑖)(𝑖=1,···,𝐾) represents the
𝑖𝑡ℎgenerator. Nevertheless, real-world applications often involve
subtle variations in the shapes of objects between source and tar-
get domains. As discussed in the Introduction, relying solely on
training-time adaptation is insufficient when faced with slight con-
tent shifts.
3.3 Test-time Learning
The model learned in the training phase has good generalization
performance, but it is still difficult to classify all target domain
samples accurately due to the domain discrepancy. Recent studies
[23,30] have revealed that the domain-specific knowledge in the
target domain may facilitate the learning of model, since class la-
bels for different domains have a correlation with domain-specific
3798KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
knowledge. Motivated by this, we perform test-time adaptation,
that is, we aim to use the specific knowledge in the target domain to
enhance the model, making it adapt to the target domain. However,
there is no prior knowledge of what is domain-specific knowledge
in the unlabeled target domain during testing. Therefore, we di-
rectly use unlabeled target domain data to optimize the model. To
do so, we can use the domain-specific knowledge since these target
domain samples contain all domain-specific knowledge. Note that
in the testing phase, we can access the unlabeled target domain data
and the learned model M𝜃consists of feature extractor Φ(·;𝜃Φ),
and classifier 𝑓(·;𝜃𝑓), without accessing any data from the train-
ing domain, and thus a simple and effective method is to directly
minimize the entropy of the target domain samples as follows.
𝐸(𝑥𝑡
𝑖;𝜃)=−𝑓 Φ(𝑥𝑡
𝑖;𝜃)·log𝑓 Φ(𝑥𝑡
𝑖;𝜃). (12)
However, in practice, it is difficult for a model learned in the
training phase to accurately classify all unlabeled target domain
samples, resulting in obtaining partial incorrect pseudo labels [ 36].
Therefore, directly minimizing the entropy of unreliable samples
(i.e., the corresponding pseudo label is incorrect or the sample
has noise) would limit the performance of the model and even
result in collapsed trivial solutions, i.e., all samples are assigned
the same class label [ 23]. Consequently, it becomes necessary to
confirm the trustworthiness of samples. To alleviate this problem,
several methods [ 22,23] are devoted to selecting samples with low
entropy to identify trustworthy samples for model optimization.
However, a recent study [ 11] highlights that there are still some
unreliable samples with low entropy samples. That is to say, it is
difficult to accurately identify unreliable samples. Therefore, it is
necessary to mitigate the impact of unreliable samples. Inspired
by [37], we leverage the confidence of the predictive results to
amplify the impact of reliable samples and diminish the impact of
unreliable ones when optimizing the model parameters. We define
"pseudo unreliable samples" as samples where the model struggles
to confidently classify the sample, leading to hesitation in assigning
its class. An intuitive reflection of this uncertainty can be observed
in the class activation map through the proximity of the prediction
logits. Hence, we classify a sample as pseudo unreliable if its two
largest prediction values in the logits are very close. For a test
sample𝑥𝑡
𝑖∈𝐷𝑡, we first obtain the two largest values 𝑞(𝑥𝑡
𝑖)and
𝑝(𝑥𝑡
𝑖)in logitM𝜃(𝑥𝑡
𝑖), where𝑞(𝑥𝑡
𝑖)denotes the largest prediction
and𝑝(𝑥𝑡
𝑖)represents the prediction ranked after 𝑞(𝑥𝑡
𝑖). Then, we
compute the confidence of 𝑥𝑡
𝑖using Eq. (13) as follows.
𝑊(𝑥𝑡
𝑖)= 𝑞(𝑥𝑡
𝑖)−𝑝(𝑥𝑡
𝑖)2. (13)
We consider that the samples are far from the decision boundary
if the model has high confidence in predictions. In other words,
the model’s predictions are reliable for these samples. Therefore,
𝑊(·)assigns high weights to these samples to encourage the model
to optimize the parameters of these samples. On the other hand,
𝑊(·)assigns low weights to the samples with low confidence in the
prediction to prevent performance degradation. Note that if 𝑞(𝑥𝑡
𝑖)
and𝑝(𝑥𝑡
𝑖)have similar or identical values, the information from 𝑥𝑡
𝑖
will not be used. To alleviate this problem, we add the constant 1
to Eq. (13) to make full use of each sample as follows.
𝑊(𝑥𝑡
𝑖)=1+ 𝑞(𝑥𝑡
𝑖)−𝑝(𝑥𝑡
𝑖)2. (14)Unfortunately, there still exists a risk that some harmful samples
may be present, where the two largest prediction values in the logits
of the sample differ significantly, yet the predicted label is incorrect,
which would mislead the model’s learning. Since the confidence
of the predictive results cannot identify these samples, we seek to
make the model insensitive to these samples. Study [ 6] reveals that
the sharpness measure has a high correlation with generalization
and a flat minimum has good generalization abilities, and thus
encouraging the model to seek to minimize the sharpness measure
of the entropy loss landscape and go to a flat area of the entropy
loss surface is one most straight forward solution to alleviate this
problem, since a flat minimum is robust to noisy or large gradients,
i.e., at the flat minimum, the model loss would not be significantly
affected by the noisy or large gradients updating [ 23]. Motivated
by this, we encourage model to go to a flat area of the entropy loss
surface for achieving the sharpness minimization by using SAM
[6] as follows.
min
𝜃𝐸𝑆𝐴𝑀 𝑥𝑡
𝑖;𝜃, (15)
𝐸𝑆𝐴𝑀 𝑥𝑡
𝑖;𝜃≜max
𝜖:∥𝜖∥2≤𝜌𝐸 𝑥𝑡
𝑖;𝜃+𝜖, (16)
where𝜌is the radius of the neighbourhood, and 𝜖is the weight per-
turbation. Eq. (16) finds the weight perturbation 𝜖in the Euclidean
ball with radius 𝜌that maximizes the empirical loss [ 32]. According
to [6], we can obtain the approximate solution 𝜖𝑚by invoking the
Taylor expansion of the entropy loss as follows.
𝜖𝑚=max
𝜖:∥𝜖∥2≤𝜌𝐸 𝑥𝑡
𝑖;𝜃+𝜖
≈𝜌·sign ∇𝐸(𝑥𝑡
𝑖;𝜃)·∇𝐸
𝑥𝑡
𝑖;𝜃
∇𝐸(𝑥𝑡
𝑖;𝜃)
2.(17)
As a result, the Eq. (15) can be rewritten as
min
𝜃𝐸𝑆𝐴𝑀(𝑥𝑡
𝑖;𝜃+𝜖𝑚). (18)
Based on Eq. (14) and Eq. (18), we employ a sample-aware and
sharpness-aware minimization method to further optimize the
model as follows.
min
𝜃𝑊(𝑥𝑡
𝑖)·𝐸𝑆𝐴𝑀(𝑥𝑡
𝑖;𝜃+𝜖𝑚), (19)
which integrates the weights learned by Eq. (14) into SAM to opti-
mize the model.
4 EXPERIMENTS
4.1 Experimental Setups
Datasets. We evaluate PSDG on three commonly used single do-
main generalization datasets, including Digits, CIFAR10-C, and
PACS. Digits [28] is used for digit classification, which consists
of 5 domains: MNIST, MNIST-M, USPS, SYN, and SVHN in from
10 categories ranging from 0 to 9. Following [ 7,15,35], we regard
the first 10,000 images from MNIST as the source domain and each
of the remaining four domains as the target domain. CIFAR10-C
[8] is created by applying 19 corruptions with 5 severity levels to
the CIFAR10 [ 12] dataset. In our experiments, CIFAR10 is used for
training and CIFAR10-C is employed for test. PACS [14] contains
9,991 images in 7 categories from four distinct domains, namely
3799Practical Single Domain Generalization via Training-time and Test-time Learning KDD ’24, August 25–29, 2024, Barcelona, Spain.
Sketch, Cartoon, Art painting, and Photo. In the experiments, one
domain is used as the source domain and the other three domains
are regarded as the target domains.
Comparison Methods. PSDG is compared with 11 single do-
main generalization methods including Empirical Risk Minimiza-
tion (ERM), ADA [ 28], M-ADA [ 24], ME-ADA [ 42], L2D [ 35], PDEN
[15], NCDG [ 26], MetaCNN [ 29], Pro-RandConv [ 4], UDP [ 7], and
AdvST [ 43]. Moreover, PSDG is compared with 4 test-time adapta-
tion algorithms including Tent [ 30], CoTTA [ 33], EATA [ 22], and
SAR [ 23].For a fair comparison, we use the same pre-trained
model as [ 7,15,35] for all mentioned-above test-time meth-
ods. To fully evaluate the effectiveness of PSDG, we propose
a variant of PSDG, referred as PSDG‡, which only performs
training-time learning. Similarly, we introduce a variant of
PSDG, denoted as PSDG⨿, which only performs test-time
learning. In addition, we use PSDG‡+(·)to represent the test-
time method(·)utilizing PSDG‡as the pre-trained model. In
the following, * indicates our implementation.
Implementation Details. For Digits, the LeNet [ 28] is used as
the backbone. All images are resized to 32 ×32. The images from
USPS and MNIST are converted to RGB images by duplicating them
from one channel to three channels. The model is trained with batch
size 128 for 50 epochs. For optimization, we adopt Adam optimizer
with a learning rate of 1e-4. We set the parameters 𝐾=50,𝜆𝑓=0.1,
and𝜆𝑝=1. At test-time learning, we set the batchsize to 128. For
CIFAR10-C, the feature extractor is built on the WideResNet with
16 layers and the width 4. We train the network using SDG with a
learning rate of 1e-4 and momentum of 0.9 using cosine annealing
schedule. We set batch size to 128 and epoch to 30, and set the
parameters𝐾=50,𝜆𝑓=0.1, and𝜆𝑝=1. The batchsize on test-time
learning is set to 128. For PACS, we adopt the ResNet-18 network as
the backbone pre-trained on ImageNet. For optimization, we adopt
SGD optimizer with a learning rate of 1e-4 and momentum of 0.9.
We train the network with batch size 64 for 4 epochs, and set the
parameters𝐾=20,𝜆𝑓=0.1, and𝜆𝑝=2. The model is trained with
the batchsize of 32 on test-time learning.
4.2 Experiment Results and Analysis
Results on Digits. The performance on Digits is presented in Ta-
ble 1. The results highlight several important findings. Firstly, we
observe that the generalization performance of PSDG‡significantly
outperforms the gradient-based data augmentation methods, ADA,
M-ADA, ME-ADA, NCDG, and AdvST, across most of the target
domains. AdvST conceptualizes a composition of several standard
data augmentations as a semantics transformation with learnable
parameters to generate augmented data. In contrast, PSDG‡does
not need standard data augmentations as prior knowledge and
adopts style generation to generate data with large distribution
shifts. Secondly, when compared to the style-based data augmenta-
tion methods such as PDEN, L2D, MetaCNN, Pro-RandConv and
UDP, PSDG‡also demonstrates superior performance. We reason
that PSDG‡enhances its ability to capture and utilize invariant rep-
resentations, which enables it to gain strong generalization capabil-
ities. Thirdly, we observe that PSDG⨿obtains the highest average
accuracy than the other TTA methods, but it still achieves poor
performance compared to single domain generalization methods,Table 1: Accuracy (%) of different methods trained on Digits.
Each column title indicates the target domain.
Mehto
ds SVHN
MNIST-M SYN USPS A
vg.
ERM 27.8
52.7 39.7 76.9 49.3
AD
A 35.5
60.4 45.3 77.3 54.6
M-
ADA 42.6
67.9 49.0 78.5 59.5
ME-
ADA 42.6
63.3 50.4 81.0 59.3
PDEN 62.2
82.2 69.4 85.3 74.8
L2D 62.9
87.3 63.7 84.0 74.5
MetaCNN 66.5 88.3 70.7
89.6 78.8
NCDG 59.7
77.4 63.8 92.6 73.4
Pr
o-RandConv 69.7
82.3 79.8 93.7 81.4
UDP 72.4
79.7 81.7 96.3 82.5
A
dvST 67.5
79.8 78.1 95.4 80.1
PSDG‡73.1 86.7 83.4 95.7 84.7
T
ent∗29.7
52.0 41.9 82.7 51.6
Co
TTA∗17.1
28.9 30.3 71.6 37.0
EA
TA∗29.7
52.0 41.9 79.7 50.8
SAR∗29.7
52.0 41.9 83.2 51.7
PSDG⨿31.4
55.1 45.2 83.0 53.7
PSDG‡+T
ent 74.7
88.2 86.9 95.7 86.4
PSDG‡+Co
TTA 57.0
78.1 69.4 95.7 75.1
PSDG‡+EA
TA 73.7
87.4 84.1 96.0 85.3
PSDG‡+SAR 75.9
88.9 88.0 95.7 87.1
PSDG 78.1
89.9 89.2 96.5 88.4
indicating that focusing only on test-time learning is insufficient.
After performing test-time learning, it can be seen that PSDG per-
forms the highest average accuracy and achieves a gain of 1.3%
compared to SAR. This is because PSDG optimizes the model by
giving different weights to the samples with different reliability,
which can help the model adapt to the target domains better than
the other test-time adaptation methods.
Results on CIFAR10-C. Table 2 shows the results on CIFAR10-
C dataset. We see that our method performs similar results to the
other methods at severity level 1. We conjecture the reason is that
CIFAR10-C is similar to CIFAR10 at level 1, which leads to stylized
samples with large distribution shifts that may not improve the gen-
eralization performance well. However, at levels 2 to 5, our method
shows excellent generalization performances. This indicates that
PSDG‡prefers to complete difficult tasks with large distribution
shifts. At level 5, our method outperforms the average accuracy
by0.6%over the best baseline UDP. Besides, PSDG‡also achieves
the highest average classification accuracy, which is 81.1%. More-
over, the test-time methods achieve good performance but still are
inferior to PSDG⨿. At test-time learning, it is striking that PSDG
results in 89.5% performance on average accuracy for CIFAR10-C.
In addition, PSDG has a similar performance to the other test-time
adaptation methods, we conjecture the reason for the similar im-
provement is that the parameters of PSDG‡may be almost enough
to extract necessary domain invariant features. However, it is still
valuable to achieve the best average accuracy on a high-quality
benchmark. The specific results of 19 corruption at severity level
5 are reported in Table 4. PSDG exhibits excellent performances
3800KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
Table 2: Accuracy (%) of different methods on CIFAR10 under
different corruption levels. Each column title indicates the
performance on different corruption levels.
Metho
ds Le
vel 1 Level 2 Level 3 Level 4 Level 5 A
vg.
ERM 87.8
81.5 75.5 68.2 56.1 73.8
AD
A 88.3
83.5 77.6 70.6 58.3 75.7
M-
ADA 90.5
86.8 82.5 76.4 65.6 80.4
ME-
ADA 90.0
87.5 84.6 80.7 72.7 83.1
PDEN 90.6
88.9 87.0 83.7 77.5 85.5
L2D 91.3 88.9
86.8 80.9 69.4 83.5
MetaCNN 91.2
88.9 87.0 83.4 78.2 85.7
NCDG∗91.2
89.0 87.1 84.0 79.2 86.1
UDP∗89.9
88.6 87.2 84.7 80.5 86.2
A
dvST∗91.1
89.0 86.9 83.1 77.5 85.5
PSDG‡90.5 89.1
87.8 85.3 81.1 86.8
T
ent∗86.1
84.9 83.5 81.8 79.4 83.1
Co
TTA∗86.5
85.3 84.1 82.5 80.3 83.7
EA
TA∗86.1
84.9 83.6 81.9 79.5 83.2
SAR∗86.6
85.6 84.4 82.8 80.6 84.0
PSDG⨿86.7
85.9 84.8 83.3 81.3 84.4
PSDG‡+T
ent 91.1
90.3 89.4 88.0 86.2 89.0
PSDG‡+Co
TTA 90.5
89.6 88.7 87.4 85.4 88.3
PSDG‡+EA
TA 91.1
90.3 89.4 88.1 86.2 89.0
PSDG‡+SAR 91.3
90.5 89.8 88.5 86.8 89.4
PSDG 91.3
90.5 89.8 88.7 87.2 89.5
compared to the other lines of methods. By assigning high weights
to reliable samples (specifically, the calibration function of Eq. (14))
to help the model update the parameters, we observe improved
performance on every corruption type compared to PSDG‡, even
improving to 31% on Pixelate.
Results on PACS. Table 3 shows the results on PACS dataset.
PSDG‡achieves superior performance on average accuracy. The
accuracy of PSDG‡is 1.5% higher than the second best model, Pro-
RandConv, by average. We also observe that although AdvST and
Pro-RandConv gain the higher accuracy on Photo and Cartoon
compared to PSDG‡, the average accuracy drops, which means that
PSDG‡has the more stable generalization performance than these
methods. We see that PSDG⨿is superior to the other TTA methods.
Nonetheless, its performance is worse than that of ERM, indicating
the insufficiency of only employing test-time learning. Similar to
the results on Digits dataset, the poor performance of test-time
methods indicates the insufficiency of only employing test-time
learning. At test-time learning, similar to the exhibitions of PSDG‡,
PSDG consistently outperforms the existing baselines across each
scenario. We see that PSDG achieves gains against PSDG‡by: +
0.3% on average. In addition, compared with the other test-time
adaptation methods, PSDG performs the highest average accuracy
since assigning reliable samples with high weights can improve
generalization performance.
4.3 Ablation Study
In this section, we provide ablation studies to exhibit where the
performance improvement of PSDG comes from.
Impact of StyIN. To analyze the impact of the StyIN, we present
a variant of PSDG, which employs the AdaIN as the generator
and does not utilize test-time learning, denoted as PSDG‡-AdaIN.Table 3: Accuracy (%) of different methods on PACS. Each
column title indicates the source domain.
Metho
ds P
hoto Art Cartoon Sketch A
vg.
ERM 42.0
70.9 76.5 53.1 60.7
AD
A∗41.7
68.8 69.3 35.1 53.7
M-
ADA 43.1
68.0 71.9 33.9 54.2
ME-
ADA∗42.1
69.2 70.6 36.8 54.7
PDEN∗58.3
77.9 74.6 57.9 67.2
L2D 52.3
76.9 77.9 53.7 65.2
MetaCNN∗56.7
76.5 74.4 55.7 65.8
NCDG 49.0
76.6 76.4 53.1 63.8
Pr
o-RandConv 62.9
77.0 78.5 57.1 68.9
UDP∗56.7
77.1 77.6 57.5 67.2
A
dvST∗64.1 77.9
76.0 57.1 68.8
PSDG‡62.1 78.2 78.3 63.0 70.4
T
ent∗34.0
68.8 69.8 31.1 50.9
Co
TTA∗18.7
59.4 35.6 17.5 32.8
EA
TA∗34.4
70.8 74.3 31.2 52.6
SAR∗41.7 71.8
70.6 31.7 53.9
PSDG⨿43.2 71.7 70.6
32.9 54.6
PSDG‡+T
ent 62.1
78.2 78.3 63.0 70.4
PSDG‡+Co
TTA 56.7
71.8 62.2 56.2 61.8
PSDG‡+EA
TA 62.1
78.2 78.3 63.0 70.4
PSDG‡+SAR 62.5
78.3 78.3 63.0 70.5
PSDG 63.1
78.5 78.3 63.1 70.7
According to the results in Table 5, we observe that PSDG‡achieves
a higher average accuracy than PSDG‡-AdaIN, i.e., 84.7% 𝑣𝑠.79.5%.
Specifically, PSDG‡achieves an accuracy improvement of 17.1% on
MNIST-M dataset. At test-time adaptation, PSDG also achieves the
best generalization performance.
Impact ofL𝑜,L𝑐,L𝑓andL𝑝.Table 6 shows the validity and
necessity of each loss function. We exhibit the validity of L𝑜,L𝑐,
L𝑓andL𝑝. Turning onL𝑜, the average accuracy of the model
training withoutL𝑜decreased from 84.7% to 83.7%. Similarly, the
average accuracy is reduced by 1.1% when PSDG‡is trained with-
outL𝑐, sinceL𝑜andL𝑐jointly help the model extract the domain
invariant features. Note that reducing any loss function still results
in model performance degradation. Since L𝑓encourages the gen-
erator to generate data with different styles than the original data,
it is hard to generate samples with large distribution shifts when
L𝑓is not used. The experiment results without using L𝑓is 83.7%,
which is lower than the 84.7% obtained by using L𝑓. Furthermore,
the results without adopting L𝑝is 81.1%. This result indicates that
the performance of the model is significantly improved when L𝑝is
employed to ensure the diversity of augmented data. Moreover, we
report the results of PSDG‡and its variants on PACS in Appendix
D, which are similar to the results on Digits.
Analysis of the Parameter Sensitivity. To analyze the sensi-
tivity of PSDG to changes in parameters 𝐾,𝜆𝑓and𝜆𝑝, we conduct
experiments to analyze the parameter sensitivity of PSDG w.r.t the
various of𝐾,𝜆𝑓, and𝜆𝑝. To this end, we consider Digits dataset
here. Fig. 3 shows the sensitivity analysis of PSDG concerning 𝐾,
3801Practical Single Domain Generalization via Training-time and Test-time Learning KDD ’24, August 25–29, 2024, Barcelona, Spain.
Table 4: Target-oriented single domain generalization accuracy (%) trained on CIFAR-10 under the corruption levels of 5 (the
most severe). Each column title indicates the performance on 19 types of corruption. * indicates our implementation.
Metho
ds W
eather Blur Noise Digital
Fog
Snow Frost Zo
om Defocus Glass Gaussian Motion Sp
eckle Shot Impulse Gaussian Jp
eg Pixelate Spatter Elastic Brightness Saturate Contrast A
vg.
ERM 65.9
74.4 61.6 60.0
53.7 49.4 30.7 63.8 41.3
35.4 25.7 29.0 69.9
41.0 75.4 72.4 91.3 89.1 36.9 56.1
AD
A 68.3
76.8 69.9 63.0
56.4 53.5 38.3 63.9 38.5
36.9 22.3 32.4 74.2
53.3 80.3 74.6 89.9 82.9 31.6 58.3
M-
ADA 69.4
80.6 76.7 68.0
61.1 61.6 47.3 64.2 60.9
60.6 45.2 56.9 77.1
52.3 80.6 75.6 90.8 87.6 29.7 65.6
ME-
ADA∗61.9
80.4 79.8 74.4
70.3 68.8 60.2 68.9 76.3
76.0 71.6 74.0 85.6
73.8 82.2 78.7 87.6 83.9 27.5 72.7
PDEN 69.6
81.8 84.5 83.7
82.1 60.1 79.3 76.7 79.3
81.3 66.8 81.1 85.2
70.8 79.4 75.1 91.0 88.4 55.6 77.5
L2D∗70.4
80.3 80.2 74.5
64.0 63.3 47.7 71.5 68.8
70.7 18.5 65.7 84.4
56.0 79.8 78.3 91.6 91.6 60.9 69.4
NCDG 81.1
83.5 82.1 88.1 89.0 68.0
85.0 86.0 74.7
71.7 66.8 66.2 78.7
63.4 88.6 80.2 92.2 89.9 69.1 79.2
MetaCNN∗68.1
81.6 83.0 80.0
78.7 73.1 60.5 73.9 78.7
81.4 72.6 80.5 88.5
80.8 83.4 80.1 92.7 85.8 63.3 78.2
UDP∗77.5
82.3 87.2 86.1
84.8 73.5 83.5 79.4 81.5
81.1 71.6 79.7 83.1
56.4 86.8 75.5 89.8 89.0 80.8 80.5
A
dvST∗80.3
82.2 81.9 88.8 88.6
67.2 69.3 69.0 56.7
79.2 46.1 88.7 92.0
81.2 76.9 91.4 79.2 87.1 65.7 77.5
PSDG‡78.6
82.5 87.3 87.1
86.1 73.0 85.1 80.5 81.4
82.0 71.3 80.5 82.4
56.7 87.4 77.7 91.2 90.5 78.9 81.1
T
ent∗83.5
79.5 80.4 84.2
84.7 67.3 85.3 80.2 74.3
74.7 69.9 73.5 76.3
80.6 82.0 73.4 86.9 86.8 85.4 79.4
Co
TTA∗82.5
79.8 81.9 83.7
82.6 70.2 82.4 80.0 76.7
77.9 74.6 76.8 79.5
81.4 82.5 76.3 86.5 86.8 82.5 80.3
EA
TA∗83.5
79.5 80.4 84.3
84.8 67.6 85.4 80.4 74.5
74.8 70.1 73.7 76.5
80.5 82.0 73.5 86.9 86.8 85.5 79.5
SAR∗84.2
80.5 81.4 84.8
85.1 70.2 85.8 81.5 76.6
76.9 72.4 76.3 78.1
81.3 82.9 74.7 87.1 87.0 85.9 80.7
PSDG⨿84.6
81.0 82.0 85.3
85.3 71.2 85.9 82.2 77.8
78.4 73.7 77.3 78.6
82.0 83.5 75.5 87.4 86.9 86.2 81.3
PSDG‡+T
ent 86.9
86.6 88.7 89.7
89.3 76.3 89.3 86.6 84.1
84.4 79.0 83.6 84.1
86.7 89.0 80.1 91.0 90.9 90.6 86.2
PSDG‡+Co
TTA 84.2
84.3 87.5 88.4
87.1 77.4 86.8 85.2 84.4
84.4 81.3 83.3 85.2
86.5 88.0 80.8 89.3 90.4 88.7 85.4
PSDG‡+EA
TA 87.0
86.6 88.8 89.7
89.3 76.5 89.4 86.5 84.3
84.4 79.1 83.7 84.2
86.8 89.1 80.2 91.0 91.0 90.6 86.2
PSDG‡+SAR 87.8
87.2 89.0 90.2 89.5
78.1 89.5 87.4 84.8
85.0 80.6 84.5 84.8
87.5 89.4 81.0 91.3 91.3 90.8 86.8
PSDG 88.9
87.5 89.0 90.2
89.8 79.1 89.7 88.1 85.2
85.6 81.6 84.9 85.0
87.7 89.4 81.6 91.4 91.4 90.7 87.2
Table 5: Accuracy (%) achieved by different style generators.
Metho
ds SVHN
MNIST-M SYN USPS A
vg.
PSDG‡-A
daIN 70.5
69.6 82.0 96.1 79.5
PSDG‡73.1
86.7 83.4 95.7 84.7
PSDG-A
daIN 77.9
71.6 87.6 96.5 83.4
PSDG 78.1
89.9 89.2 96.5 88.4
Table 6: Loss ablation study on Digits.
L𝑜L𝑐L𝑓L𝑝SVHN
MNIST-M SYN USPS A
vg.
%
" " " 71.6
86.0 82.1 95.2 83.7
"
% " " 71.6
83.8 84.5 94.6 83.6
"
" % " 71.8
86.3 82.0 94.7 83.7
"
" " % 68.7
77.5 81.8 96.6 81.1
"
" " " 73.1
86.7 83.4 95.7 84.7
𝜆𝑓and𝜆𝑝. When sensitivity analysis is performed by varying a
parameter at the time over a given range, the other parameters
we set them to their final values. From Fig. 3 (a), we see that the
generalization performance of PSDG improves rapidly during the
value of𝐾increases. By continuously generating new distribution
domains to increase the number of stylized samples, the gener-
alization performance improves. The more generators, the more
style variation in the generated samples, and the more robust the
model to the distribution shifts. Moreover, as 𝐾increases to a cer-
tain value, the increase in generalization performance becomes flat.
This demonstrates that PSDG is almost sufficient to capture the
variability in the sample distribution by diverse stylized samples.
Moreover, the optimal value ranges of 𝜆𝑓and𝜆𝑝may be [0.1, 0.2]
and [1.0, 2.0], respectively. When the values of 𝜆𝑓and𝜆𝑝are small,
the generator can not synthesize sufficient diverse stylized samples.
In addition, the large values of these two parameters deteriorate
the generalization performance since the generated samples may
distort the original semantic information.
0 10 20 30 40 505060708090Accuracy (%)
MNIST-M
USPS
SYN
SVHN(a) Parameter 𝐾
0.05 0.1 0.2 0.3 0.5 1.0707580859095Accuracy (%)
MNIST-M
USPS
SYN
SVHN (b) Parameter 𝜆𝑓
0.5 1.0 2.0 3.0 5.0 10.0707580859095Accuracy (%)
MNIST-M
USPS
SYN
SVHN (c) Parameter 𝜆𝑝
Figure 3: Parameter sensitivity study on Digits.
5 CONCLUSION
In this paper, we present a novel method called PSDG that performs
both training-time and test-time learning to tackle the domain
shift problem. During the training phase, PSDG utilizes StyIN to
synthesize new diversity data to increase the coverage of training
data and introduces object-consistency regularization to capture
consistency between the augmented and original data for filtering
style knowledge. During the testing phase, we use a simple sample
reweighting strategy that assigns a weight to each sample based on
the prediction difference of different classes to mitigate the impact
of unreliable samples, and employ SAM to improve the generaliza-
tion performance. We evaluate PSDG on three datasets and observe
that it consistently surpasses current methods. The success of the
proposed PSDG algorithm indicates that simultaneously perform-
ing training-time and test-time learning is beneficial for mitigating
domain shift problems.
ACKNOWLEDGMENTS
This work was supported in part by the National Natural Science
Foundation of China under Grant 62306008, the Natural Science
Foundation of Anhui Province under Grant 2308085MF217, and the
University Synergy Innovation Program of Anhui Province under
Grant GXXT-2022-046.
3802KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
REFERENCES
[1]Alexander Bartler, Andre Bühler, Felix Wiewel, Mario Döbler, and Bin Yang.
2022. MT3: Meta Test-Time Training for Self-Supervised Test-Time Adaption.
InInternational Conference on Artificial Intelligence and Statistics, Virtual Event,
March 28-30, Vol. 151. 3080–3090.
[2]Liang Chen, Yong Zhang, Yibing Song, Ying Shan, and Lingqiao Liu. 2023. Im-
proved Test-Time Adaptation for Domain Generalization. In IEEE/CVF Conference
on Computer Vision and Pattern Recognition, Vancouver, BC, Canada, June 17-24.
24172–24182.
[3]Liang Chen, Yong Zhang, Yibing Song, Jue Wang, and Lingqiao Liu. 2022. OST:
Improving Generalization of DeepFake Detection via One-Shot Test-Time Train-
ing. In Advances in Neural Information Processing Systems, New Orleans, LA, USA,
November 28 - December 9. 1–12.
[4]Seokeon Choi, Debasmit Das, Sungha Choi, Seunghan Yang, Hyunsin Park, and
Sungrack Yun. 2023. Progressive Random Convolutions for Single Domain Gen-
eralization. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,
Vancouver, BC, Canada, June 17-24. 10312–10322.
[5]Peng Cui and Susan Athey. 2022. Stable learning establishes some common
ground between causal inference and machine learning. Nature Machine Intelli-
gence 4, 2 (2022), 110–115.
[6]Pierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. 2021.
Sharpness-aware Minimization for Efficiently Improving Generalization. In In-
ternational Conference on Learning Representations, Virtual Event, Austria, May
3-7. 1–13.
[7]Kehua Guo, Rui Ding, Tian Qiu, Xiangyuan Zhu, Zheng Wu, Liwei Wang, and
Hui Fang. 2023. Single Domain Generalization via Unsupervised Diversity Probe.
InACM International Conference on Multimedia, Ottawa, ON, Canada, October
29-November 3. 2101–2111.
[8]Dan Hendrycks and Thomas G. Dietterich. 2019. Benchmarking Neural Net-
work Robustness to Common Corruptions and Perturbations. In International
Conference on Learning Representations, New Orleans, LA, USA, May 6-9. 1–11.
[9]Julia Hirschberg and Christopher D Manning. 2015. Advances in natural language
processing. Science 349, 6245 (2015), 261–266.
[10] Zhuo Huang, Xiaobo Xia, Li Shen, Bo Han, Mingming Gong, Chen Gong, and
Tongliang Liu. 2023. Harnessing Out-Of-Distribution Examples via Augmenting
Content and Style. In International Conference on Learning Representations, Kigali,
Rwanda, May 1-5. 1–14.
[11] Saehyung Lee Junsung Park Juhyeon Shin Uiwon Hwang Sungroh Yoon
Jonghyun Lee, Dahuin Jung. 2024. Entropy is not Enough for Test-time Adap-
tation: From the Perspective of Disentangled Factors. In The 12th International
Conference on Learning Representations, Vienna Austria, May 7-11. 1–26.
[12] Alex Krizhevsky, Geoffrey Hinton, et al .2009. Learning multiple layers of features
from tiny images. (2009).
[13] Juliusvon Kügelgen, Yash Sharma, Luigi Gresele, Wieland Brendel, Bernhard
Schölkopf, Michel Besserve, and Francesco Locatello. 2021. Self-Supervised
Learning with Data Augmentations Provably Isolates Content from Style. In
Conference on Neural Information Processing Systems, virtual, December 6-14.
16451–16467.
[14] Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. 2017. Deeper,
broader and artier domain generalization. In IEEE International Conference on
Computer Vision, Venice, Italy, October 22-29. 5542–5550.
[15] Lei Li, Ke Gao, Juan Cao, Ziyao Huang, Yepeng Weng, Xiaoyue Mi, Zhengze Yu,
Xiaoya Li, and Boyang Xia. 2021. Progressive Domain Expansion Network for
Single Domain Generalization. In Conference on Computer Vision and Pattern
Recognition, virtual, June 19-25. 224–233.
[16] Shuang Li, Mixue Xie, Fangrui Lv, Chi Harold Liu, Jian Liang, Chen Qin, and
Wei Li. 2021. Semantic Concentration for Domain Adaptation. In International
Conference on Computer Vision, Montreal, QC, Canada, October 10-17. 9082–9091.
[17] Jian Liang, Dapeng Hu, and Jiashi Feng. 2020. Do We Really Need to Access the
Source Data? Source Hypothesis Transfer for Unsupervised Domain Adaptation.
InInternational Conference on Machine Learning, Virtual Event, July 13-18, Vol. 119.
6028–6039.
[18] Yuejiang Liu, Parth Kothari, Bastien van Delft, Baptiste Bellot-Gurlet, Taylor
Mordan, and Alexandre Alahi. 2021. TTT++: When Does Self-Supervised Test-
Time Training Fail or Thrive?. In Advances in Neural Information Processing
Systems, virtual, December 6-14. 21808–21820.
[19] Zirui Liu, Haifeng Jin, Ting-Hsiang Wang, Kaixiong Zhou, and Xia Hu. [n. d.].
DivAug: Plug-in Automated Data Augmentation with Explicit Diversity Maxi-
mization. In IEEE/CVF International Conference on Computer Vision, Montreal, QC,
Canada, October 10-17. 4742–4750.
[20] David G. Lowe. 1999. Object Recognition from Local Scale-Invariant Features. In
International Conference on Computer Vision, Kerkyra, Corfu, Greece, September
20-25. 1150–1157.
[21] Divyat Mahajan, Shruti Tople, and Amit Sharma. 2021. Domain Generalization
using Causal Matching. In Proceedings of International Conference on Machine
Learning, virtual, July 18-24, Vol. 139. 7313–7324.
[22] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin
Zhao, and Mingkui Tan. 2022. Efficient Test-Time Model Adaptation withoutForgetting. In International Conference on Machine Learning, Baltimore, Mary-
land,USA, July 17-23, Vol. 162. 16888–16905.
[23] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin
Zhao, and Mingkui Tan. 2023. Towards Stable Test-time Adaptation in Dynamic
Wild World. In International Conference on Machine Learning, Kigali, Rwanda,
May 1-5. 1–14.
[24] Fengchun Qiao, Long Zhao, and Xi Peng. 2020. Learning to Learn Single Domain
Generalization. In Conference on Computer Vision and Pattern Recognition, Seattle,
WA, USA, June 13-19. 12553–12562.
[25] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A. Efros, and Moritz
Hardt. 2020. Test-Time Training with Self-Supervision for Generalization under
Distribution Shifts. In International Conference on Machine Learning, Virtual Event,
July 13-18, Vol. 119. 9229–9248.
[26] Chris Xing Tian, Haoliang Li, Xiaofei Xie, Yang Liu, and Shiqi Wang. 2023. Neuron
coverage-guided domain generalization. IEEE Transactions on Pattern Analysis
and Machine Intelligence 45, 1 (2023), 1302–1311.
[27] Aäron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation Learning
with Contrastive Predictive Coding. CoRR abs/1807.03748 (2018).
[28] Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John C. Duchi, Vittorio Murino,
and Silvio Savarese. 2018. Generalizing to Unseen Domains via Adversarial Data
Augmentation. In Conference on Neural Information Processing Systems, Montréal,
Canada, December 3-8. 5339–5349.
[29] Chaoqun Wan, Xu Shen, Yonggang Zhang, Zhiheng Yin, Xinmei Tian, Feng
Gao, Jianqiang Huang, and Xian-Sheng Hua. 2022. Meta Convolutional Neural
Networks for Single Domain Generalization. In Conference on Computer Vision
and Pattern Recognition, New Orleans, LA, USA, June 18-24. 4672–4681.
[30] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno A. Olshausen, and Trevor
Darrell. 2021. Tent: Fully Test-Time Adaptation by Entropy Minimization. In
International Conference on Learning Representations, Virtual Event, Austria, May
3-7. 1–12.
[31] Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Lu,
Yiqiang Chen, Wenjun Zeng, and Philip S. Yu. 2023. Generalizing to Unseen
Domains: A Survey on Domain Generalization. IEEE Transactions on Knowledge
and Data Engineering 35, 8 (2023), 8052–8072.
[32] Pengfei Wang, Zhaoxiang Zhang, Zhen Lei, and Lei Zhang. 2023. Sharpness-
Aware Gradient Matching for Domain Generalization. In Conference on Computer
Vision and Pattern Recognition, Vancouver, BC, Canada, June 17-24. 3769–3778.
[33] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. 2022. Continual Test-
Time Domain Adaptation. In IEEE Conference on Computer Vision and Pattern
Recognition, New Orleans, LA, USA, June 18-24. 7191–7201.
[34] Xinyi Wang, Michael Saxon, Jiachen Li, Hongyang Zhang, Kun Zhang, and
William Yang Wang. 2023. Causal Balancing for Domain Generalization. In
Causal Balancing for Domain Generalization, Kigali, Rwanda, May 1-5. 1–14.
[35] Zijian Wang, Yadan Luo, Ruihong Qiu, Zi Huang, and Mahsa Baktashmotlagh.
2021. Learning to Diversify for Single Domain Generalization. In International
Conference on Computer Vision, Montreal, QC, Canada, October 10-17. 814–823.
[36] Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena,
Krishnamurthy Dvijotham, and Ali Taylan Cemgil. 2022. A Fine-Grained Analysis
on Distribution Shift. In International Conference on Learning Representations,
Virtual Event, April 25-29. 1–15.
[37] Hao Yang, Min Wang, Zhengfei Yu, Hang Zhang, Jinshen Jiang, and Yun Zhou.
2024. Confidence-based and sample-reweighted test-time adaptation. Knowledge-
Based Systems 283 (2024), 111164.
[38] Shuai Yang, Kui Yu, Fuyuan Cao, Lin Liu, Hao Wang, and Jiuyong Li. 2023. Learn-
ing Causal Representations for Robust Domain Adaptation. IEEE Transactions on
Knowledge and Data Engineering 35, 3 (2023), 2750–2764.
[39] Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou,
Zhenguo Li, and Jun Zhu. 2022. OoD-Bench: Quantifying and Understanding
Two Dimensions of Out-of-Distribution Generalization. In IEEE Conference on
Computer Vision and Pattern Recognition, New Orleans, LA, USA, June 18-24. 7937–
7948.
[40] Kui Yu, Lin Liu, and Jiuyong Li. 2021. A Unified View of Causal and Non-causal
Feature Selection. ACM Transactions on Knowledge Discovery from Data 15, 4
(2021), 63:1–63:46.
[41] Kui Yu, Lin Liu, Jiuyong Li, Wei Ding, and Thuc Duy Le. 2020. Multi-Source
Causal Feature Selection. IEEE Transactions on Pattern Analysis and Machine
Intelligence 42, 9 (2020), 2240–2256.
[42] Long Zhao, Ting Liu, Xi Peng, and Dimitris N. Metaxas. 2020. Maximum-Entropy
Adversarial Data Augmentation for Improved Generalization and Robustness. In
Advances in Neural Information Processing Systems, virtual, December 6-12. 1–13.
[43] Guangtao Zheng, Mengdi Huai, and Aidong Zhang. 2024. AdvST: Revisiting
Data Augmentations for Single Domain Generalization. In Thirty-Eighth AAAI
Conference on Artificial Intelligence, February 20-27. 1–9.
[44] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. 2023.
Domain Generalization: A Survey. IEEE Transactions on Pattern Analysis and
Machine Intelligence 45, 4 (2023), 4396–4415.
3803Practical Single Domain Generalization via Training-time and Test-time Learning KDD ’24, August 25–29, 2024, Barcelona, Spain.
Table 7: Efficiency statistics evaluated on RTX 4090.
Digits|Size:[3,32,32] T
rainingA
CC(%)Metho
ds Memor
y Time
PDEN 1.4GB 17.6min 74.8
L2D 1.1GB 8.3min 74.5
UDP 1.5GB 20.0min 82.5
A
dvST 0.9GB 1.8min 80.1
PSDG‡(𝐾=20) 1.5GB 23.5min 83.0
PSDG‡(𝐾=50) 1.6GB 70.3min 84.7
Metho
ds Time A
CC(%)
T
ent 8.2s 50.9
Co
TTA 90.3s 32.8
EA
TA 9.1s 52.6
SAR 11.8s 53.9
PSDG⨿12.0s 54.6
Table 8: Accuracy (%) on Digits achieved by different compo-
nents.
Metho
ds SVHN
MNIST-M SYN USPS A
vg.
PSDG‡w/o
1 71.5
82.5 82.8 95.7 83.1
PSDG‡-L𝑝 70.8
79.5 82.4 96.1 82.2
PSDG‡-ED 17.5
35.9 32.6 75.6 40.4
PSDG‡73.1
86.7 83.4 95.7 84.7
Table 9: Accuracy (%) on CIFAR10-C achieved by different
components.
Metho
ds Le
vel 1 Level 2 Level 3 Level 4 Level 5 A
vg.
PSDG‡w/o
1 90.4
89.1 87.7 84.8 80.2 86.4
PSDG‡-L𝑝 90.4
89.1 87.8 85.0 80.4 86.6
PSDG‡-ED 84.6
82.5 80.3 76.5 71.2 79.0
PSDG‡90.5
89.1 87.8 85.3 81.1 86.8
Table 10: Accuracy (%) on PACS achieved by different compo-
nents.
Metho
ds P
hoto Art Cartoon Sketch A
vg.
PSDG‡w/o
1 61.3
77.9 77.0 61.2 69.3
PSDG‡-L𝑝 59.9
76.8 75.8 57.4 67.5
PSDG‡-ED 19.2
20.0 24.6 16.6 20.1
PSDG‡62.1
78.2 78.3 63.0 70.4
A COMPUTATIONAL COMPLEXITY AND
COMPUTATIONAL RESOURCES
Then, we show the computational complexity and computational
resources of our method and its main competitors on Digits in Table
7. During training, we use MNIST as the training data. Since our
method needs to learn 50 generators (i.e., 𝐾=50) to generate distinct
styles, PSDG‡(𝐾=50) has the highest computational complexity.However, 70.3 minutes is an acceptable amount of time for the high
accuracy, since it only needs to be trained once and can be deployed
to multiple different target domains. Besides, we observe PSDG‡
(𝐾=20) still achieves the highest accuracy compared to the other
methods, and its computational complexity is close to that of UDP
(23.5min v.s. 20.0min). We also see that although PSDG‡requires
saving𝐾different generators, it attains comparable computational
efficiency to those of PDEN and UDP. During testing, we compute
the total inference time on four target domains, i.e., MNIST-M, USPS,
SYN, and SVHN. We find that the inference time of our method
is shorter than that of COTTA, but longer than Tent and EATA.
We also observe that the accuracy of PSDG⨿is 0.7% higher than
that of SAR with a negligible additional inference time of 0.2s. In
summary, compared with its competitors, our method requires more
computational complexity and computational resources, which is a
limitation of our method.
B MORE ABLATION STUDY
To evaluate the effectiveness of several components in our method,
we propose three variants of PSDG‡, referred as “PSDG‡w/o 1”,
“PSDG‡-L𝑝” and “PSDG‡-ED”, respectively. “PSDG‡w/o 1” re-
moves the constant 1 from Eq. (6) in StyIN. “PSDG‡-L𝑝” directly
maximizes the distance between original and generated images in
L𝑝instead of minimizing their inverse, “PSDG‡-ED” uses Euclidean
distance loss between original and generated features instead of
usingL𝑓in Eq. (8). The results on three datasets are shown in
Tables 8, 9 and 10, respectively. We see that the performance of
PSDG‡is superior to “PSDG‡w/o 1”, as incorporating constant 1
into Eq. (6) can avoid generating new style data with large seman-
tic shifts. We observe that PSDG‡achieves higher accuracy than
PSDG‡-L𝑝. We conjecture the reason is that the inverse is easier to
optimize and encourage the generative model to generate data with
more diversity compared to directly maximizing the distance. We
observe that “PSDG‡-ED” collapses on Digits and PACS datasets.
The reason is that the strict restriction of Euclidean distance would
force the representation between the original and generated data
to be exactly the same, which reduces diversity within a class and
weakens feature discriminability, thus deteriorating generalization.
C ANALYZATION OF GENERATING STYLES
To further evaluate the significance of StyIN, we quantitatively
demonstrate the diversity of the augmented data by using the vari-
ance diversity metric proposed in [ 19]. The high diversity means
a large value of diversity. Table 11 shows the variance diversity
values of different numbers of augmented domains ( 𝐾) on MNIST.
We consider that the values of variance diversity increase with the
increase in the number of augmented domains when 𝐾≤40. We
also see that the diversity of the augmented data plateaus (with
a slight decrease) when 𝐾>40. We conjecture that the possible
reason is that the representation learning module might not be able
to generate samples with large shifts from the original samples
when𝐾reaches a certain value. Moreover, we also provide the vari-
ance diversity of PSDG‡-AdaIN in Table 11. The value of variance
diversity of PSDG‡-AdaIN is smaller than that of PSDG‡, which
confirms the effectiveness of StyIN. In addition, we note that the
variance diversity of PSDG‡-AdaIN decreases when 𝐾≥30and
3804KDD ’24, August 25–29, 2024, Barcelona, Spain. Shuai Yang, Zhen Zhang, & Lichuan Gu
Figure 4: Example visualization PSDG ‡and its variants,
which train on Sketch and test on Photo.
Table 11: Variance Diversity of different generators from
different numbers ( 𝐾) of augmented domains.
𝐾 10
20 30 40 50
PSDG‡-A
daIN 0.0305
0.0334 0.0338 0.0327 0.0318
PSDG‡0.1026
0.1077 0.1124 0.1163 0.1154
Table 12: Additional loss ablation study on PACS, which
trains on Sketch and test on the other three task.
L𝑜L𝑐L𝑓L𝑝P
hoto Art Cartoon A
vg.
%
" " " 55.8
57.9 68.3 60.7
"
% " " 58.0
58.0 66.9 61.0
"
" % " 56.6
59.6 68.2 61.5
"
" " % 53.4
52.8 63.5 56.6
"
" " " 58.9
61.7 68.5 63.0
PSDG‡-A
daIN 46.1
52.3 66.7 55.0
PSDG‡only decreases when 𝐾≥40, which means that StyIN can
continuously generate data with large shifts compared to AdaIN.
D EFFECTIVENESS OF EACH COMPONENT
To further evaluate the contributions of different components of
different PSDG‡, we also present the experimental results of PSDG‡and its variants on PACS in Table 12. We find that the performance
of our method PSDG is significantly influenced by the quality of the
generator StyIN. Pixel maximization loss L𝑝also has an important
effect on the performance of PSDG by preventing the replication of
identical styles across all images within a domain and promoting the
generation of data with distinct styles compared to previously aug-
mented data at the pixel level. Compared to L𝑝, the impact ofL𝑓,
which emphasizes feature differences, on the model has somewhat
diminished. This is because pixel differences intuitively capture
disparities between two images more effectively than feature differ-
ences. Since the generator synthesizes 𝐾new domains, achieving
good performance simply using contrastive learning loss L𝑜or
residual uncertainty loss L𝑐alone is possible. However, combining
L𝑜andL𝑐would lead to performance improvement. Although the
improvement is not significant, the model’s performance is already
excellent. Even a slight enhancement is meaningful. Moreover, we
also provide the class activation maps of PSDG‡and its variants to
visualize the contributions of different components in Fig. 4. We
observe that the absence of any component will change the focus
of the model, decreasing the generalization performance and even
leading to model classification errors. We also see that the class
activation map of PSDG‡is more comprehensive and contains less
style features than that of PSDG‡-AdaIN.
E THE PRACTICAL EFFECTIVENESS AND
POTENTIAL ADVANTAGES OF PSDG
Our proposed method PSDG combines the merits of training-time
learning and test-time learning to enhance the model’s performance
on the target domain, which is more robust to domain shift com-
pared to solely performing single-domain generalization or test-
time adaptation. As a result, PSDG is expected to be deployed in
real-world environments with large domain shifts. Furthermore,
since training-time learning and test-time learning are independent
of each other, PSDG is suitable for both single domain generalization
and test-time adaptation problems. In addition, the proposed gener-
ator StyIN can produce data with diverse styles, rendering it highly
applicable for other data augmentation methods that integrate a
style generator module. Besides, the proposed residual uncertainty
loss can be extended to other methods aimed at learning feature rep-
resentations. The simple yet effective sample reweighting strategy
proposed during the test-time learning phase can also be applied
to other test-time adaptation methods. In summary, our proposed
method has ventured into new explorations in dealing with domain
shift problems, with the hope of inspiring the community.
3805