Multi-Behavior Collaborative Filtering with Partial Order Graph
Convolutional Networks
Yijie Zhang∗
Jinan University
Guangzhou, China
wingszhangyijie@gmail.comYuanchen Bei∗
Zhejiang University
Hangzhou, China
yuanchenbei@zju.edu.cnHao Chen∗
The Hong Kong Polytechnic
University
Hong Kong, China
sundaychenhao@gmail.com
Qijie Shen
Alibaba Group
Hangzhou, China
qijie.sqj@alibaba-inc.comZheng Yuan
The Hong Kong Polytechnic
University
Hong Kong, China
yzheng.yuan@connect.polyu.hkHuan Gong
National University of Defense
Technology
Changsha, China
gongh15@outlook.com
Senzhang Wang
Central South University
Changsha, China
szwang@csu.edu.cnFeiran Huang†
Jinan University
Guangzhou, China
huangfr@jnu.edu.cnXiao Huang
The Hong Kong Polytechnic
University
Hong Kong, China
xiaohuang@comp.polyu.edu.hk
Abstract
Representing information of multiple behaviors in the single graph
collaborative filtering (CF) vector has been a long-standing chal-
lenge. This is because different behaviors naturally form separate
behavior graphs and learn separate CF embeddings. Existing models
merge the separate embeddings by appointing the CF embeddings
for some behaviors as the primary embedding and utilizing other
auxiliaries to enhance the primary embedding. However, this ap-
proach often results in the joint embedding performing well on
the main tasks but poorly on the auxiliary ones. To address the
problem arising from the separate behavior graphs, we propose
the concept of Partial Order Recommendation Graphs (POG).
POG defines the partial order relation of multiple behaviors and
models behavior combinations as weighted edges to merge sepa-
rate behavior graphs into a joint POG. Theoretical proof verifies
that POG can be generalized to any given set of multiple behav-
iors. Based on POG, we propose the tailored Partial Order Graph
Convolutional Networks (POGCN) that convolute neighbors’
information while considering the behavior relations between users
and items. POGCN also introduces a partial-order BPR sampling
strategy for efficient and effective multiple-behavior CF training.
POGCN has been successfully deployed on the homepage of Alibaba
∗All authors contributed equally to this research.
†Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/08
https://doi.org/10.1145/3637528.3671569for two months, providing recommendation services for over one
billion users. Extensive offline experiments conducted on three pub-
lic benchmark datasets demonstrate that POGCN outperforms state-
of-the-art multi-behavior baselines across all types of behaviors.
Furthermore, online A/B tests confirm the superiority of POGCN
in billion-scale recommender systems.
CCS Concepts
•Information systems →Retrieval models and ranking; •
Human-centered computing →Collaborative filtering.
Keywords
recommender systems, multi-behavior recommendation, graph col-
laborative filtering
ACM Reference Format:
Yijie Zhang, Yuanchen Bei, Hao Chen, Qijie Shen, Zheng Yuan, Huan Gong,
Senzhang Wang, Feiran Huang, and Xiao Huang. 2024. Multi-Behavior
Collaborative Filtering with Partial Order Graph Convolutional Networks.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671569
1 Introduction
Graph-based collaborative filtering (CF) models [ 16,45,50] have
emerged as the state-of-the-art in predicting user-item interactions,
particularly for single behaviors like clicks [ 8,18,49,58]. How-
ever, in real-world recommender systems, there are other behaviors
equally crucial as clicks, such as favors and purchases, which greatly
impact user retention and platform revenue [ 24,53]. Nonetheless,
CF models focused on a single behavior may not perform well for
other behaviors. For example, graph embeddings trained on click
data often yield suboptimal results for favor and purchase recom-
mendations, and vice versa. This phenomenon requires modern
6257
KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
Click0.060.070.080.090.10Recall@20LightGCN
GHCF
POGCN
Cart0.1200.1250.1300.1350.1400.1450.1500.1550.160
LightGCN
GHCF
POGCN
Buy0.150.160.170.180.190.200.21
LightGCN
GHCF
POGCN
Figure 1: Illustration of the seesaw problems of current multi-
behavior collaborative filtering models.
recommender systems to train respective CF embeddings for every
behavior, leading to considerable time, cost, and storage burdens.
Hence, it is crucial to design an effective multi-behavior graph-
based CF model that can efficiently recommend multiple behaviors
using a single CF embedding.
Existing multi-behavior CF models usually merge the separate
embeddings by affording certain behaviors higher priority and
serving others as secondary to enhance the primary embedding.
For instance, NMTR [ 14], which extends the neural CF model [ 19],
considers purchasing behavior as the primary behavior and incorpo-
rates other behaviors to enhance purchasing predictions. Similarly,
MB-CGCN [ 12] builds upon NMTR by integrating LightGCN [ 18] to
improve graph embeddings for purchasing by leveraging click and
cart addition embeddings. On the other hand, IMGCF [ 64] adopts
a different approach by learning separate embeddings for each
behavior graph and then averaging these for multi-behavior recom-
mendations. GHCF [ 6] introduces a unique weighting strategy for
combining embeddings from different behavior graphs. Another
line of multi-behavior research, Click Through Rate (CTR) predic-
tion models like ESMM [ 34], MMOE [ 33], and PLE [ 41] relies on
designing complex MLP structures to deal with the multi-behavior
recommendation but they fail to represent users and items with
single embedding vectors.
However, current multi-behavior collaborative filtering (CF) mod-
els still learn the embedding of different behaviors separately, rais-
ing severe seesaw problems. The merged embedding may perform
well on the priority behavior but sacrifice recommendation perfor-
mance on the auxiliaries. As shown in Figure.1, LightGCN performs
well on click recommendations but performs significantly worse
on the other two behaviors. On the other hand, GHCF, which treats
“buy” as the priority, outperforms LightGCN in add-to-cart and pur-
chase recommendations. However, GHCF fails in recommending
clicks. In practical applications, all types of behaviors have signif-
icant implications for user experience and platform revenue. As
stated, predicting clicks affects user intentions such as activation,
while add-to-cart and purchasing impact the platform’s revenue.
Therefore, it is crucial to model the separate multi-behaviors in a
joint structure and thus train single embedding naturally.
However, encoding the separate multiple behaviors into a joint
structure poses the following three challenges:
•Separate Graphs: The current graph concept cannot repre-
sent multiple behaviors within one graph. Defining a suitablejoint graph to simultaneously organize arbitrary multiple
behaviors is challenging.
•Complicated Behavior Relations: Multiple behaviors can
have complex combinations. For instance, users may directly
purchase items without favoriting or adding them to the cart.
Alternatively, they may add several items to carts before mak-
ing a purchase. Thus, modeling the combination of behaviors
is more difficult than modeling individual behaviors.
•Behavior Combination Ordering: Existing models only
provide the order of behaviors. It’s challenging to determine
the order of behavior combinations such as comparing the
order of “buy”, ”click&favor&cart”, and “buy&click”.
In this paper, we tackle the above three challenges by upgrad-
ing the infrastructure of multiple behavior graph collaborative
filtering and introducing the general Partial Order Recommen-
dation Graph (POG) to merge separate multi-behavior graphs
into a unified one. Specifically, POG utilizes a “graded partial or-
der set” to model all the potential behavior combinations between
users and items. Consequently, POG is able to convert any be-
havior combination into a joint weighted graph. With the help of
POG, we propose tailored Partial Order Graph Convolutional
Networks (POGCN) to train a single embedding that can benefit
multi-behavior recommendation simultaneously. Additionally, we
simplify the original multiple-behavior BPR sampling process by
developing a tailored partial order BPR sampling strategy. As de-
picted in Figure.1, POGCN naturally resolves the seesaw problem
and improves the recommendation performance on “click”, “cart”,
and “buy” simultaneously. Our paper’s primary contributions can
be summarized as follows:
•We formally define the partial order recommendation graph
to describe the complicated behavior combinations for the
seesaw phenomenon in multi-behavior recommendation nat-
urally. Moreover, we prove the completeness of the definition
of the POG that can deal with arbitrary multiple behaviors.
•We propose a novel partial order graph convolutional net-
work to learn representative single embedding for multi-
behavior CF tasks. Besides, we propose a simplified partial
order BPR sampling strategy1.
•POGCN has been serving as a core recall model at the home-
page of one of the biggest e-commerce platforms—Alibaba,
offering accurate and suitable recommendations to over one
billion users.
•Extensive experiments on three benchmark datasets present
that POGCN outperforms the state-of-the-art multi-behavior
collaborative filtering methods for above 16.84% Recall, and
19.67% NDCG on average. Online A/B test also demonstrates
that POGCN brings 2.02% UCTR and 2.84% GMV improve-
ment in industrial platforms.
2 PRELIMINARY
In this section, we begin by defining the problem of multi-behavior
collaborative filtering. We then proceed to introduce the definition
of the partial order of behaviors and subsequently define the partial
order for combinations of behaviors. Finally, we provide the defini-
tion of the graph that will be used in subsequent sections, which
1Source codes are available at https://github.com/Wings236/POGCN.
6258Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
includes the “separate behavior graph”, the “behavior combination
graph”, and our “partial order recommendation graph (POG)”.
2.1 Notations and Problem Definition
Notations. We useU,I,B, andCto represent the sets of
users, items, behaviors, and behavior combination set, respectively.
Here,𝑀represents the number of users, 𝑁represents the number
of items,𝐾represents the number of behavior categories, and 𝐻
represents the number of behavior combinations. Given Ras the
set of all interactions of all behaviors, R𝑘denotes the interactions
of the𝑘-th behavior. Then, describing from the behavior aspect, for
each behavior, we have a matrix 𝑹𝑘to describe the interaction of
the𝑘-th behavior. Specifically, 𝑹𝑘𝑢𝑖=1if user𝑢and item𝑖have the
𝑘-th behavior, and 𝑹𝑘𝑢𝑖=0if user𝑢and item𝑖do not have the 𝑘-th
behavior. Describing from the users and item interaction aspect,
𝑩𝑢𝑖={𝑏𝑢𝑖,1,...,𝑏𝑢𝑖,𝐾𝑢𝑖}denotes the set of behaviors between user
𝑢and item𝑖, and𝐾𝑢𝑖denotes the number of behaviors between user
𝑢and item𝑖, where𝑏𝑢𝑖,1,...,𝑏𝑢𝑖,𝐾𝑢𝑖∈B, and 𝑩𝑢𝑖is an element of
the behavior combination set C.
Multi-Behavior Collaborative Filtering. The ultimate objec-
tive of the multi-behavior (embedding-based) collaborative filter-
ing [ 18,19,46] model is to acquire a single representation embed-
ding for each user and item, denoted as 𝑬Uand𝑬I. On a micro level,
we utilize 𝒆𝑢and𝒆𝑖to represent the trained embedding vectors for
user𝑢∈U and item𝑖∈I.
During the inference step, the relationship between a given user
and item pair can be calculated by multiplying their embeddings,
ˆ𝑌𝑢𝑖=𝒆⊤𝑢·𝒆𝑖. Subsequently, for any given user, the online recom-
mender system will rank all the items to filter the most relevant
ones. The filtered items for user 𝑢can be formally defined as,
ˆY𝑢=𝐹𝑖𝑙𝑡𝑒𝑟({ˆ𝑌𝑢𝑖,∀𝑖∈I,𝑁top}), (1)
where𝑁toprepresents the hyperparameter that controls the number
of filtered items. During the evaluation process, the recommender
system assesses the recommendation performance of all behaviors
based on ˆY𝑢.
2.2 Definition of Behavior Relations
Partial order of Behaviors. The purpose of proposing a par-
tial order is to address situations where the recommender system
cannot determine the order of two or more behaviors. For example,
consider the comparison of “favorite”, “share”, and “adding cart”.
Previously, the order of behavior definitions would typically treat
“favorite”, “share”, and “adding cart” as the same behavior, such
as “indirect behavior”, without being able to distinguish between
different behaviors. On the other hand, our proposed partial order
of behaviors can accommodate ambiguous orders.
Definition 1 (Partial Order of Behaviors ).We define a binary rela-
tion≤𝑏on behavior setB, such that for all behaviors 𝑥,𝑦,𝑧∈B,
the following conditions are satisfied:
•Reflexivity: For every𝑥∈B,𝑥≤𝑏𝑥.
•Anti-symmetry: For all𝑥,𝑦∈B, if𝑥≤𝑏𝑦and𝑦≤𝑏𝑥, then
𝑥=𝑦.
•Transitivity: For all𝑥,𝑦,𝑧∈B, if𝑥≤𝑏𝑦and𝑦≤𝑏𝑧, then
𝑥≤𝑏𝑧.After the definition of the partial order of behaviors, the above
example can be expressed as the following relation:
𝑐𝑙𝑖𝑐𝑘≤𝑏𝑠ℎ𝑎𝑟𝑒,𝑓𝑎𝑣𝑜𝑟𝑖𝑡𝑒,𝑎𝑑𝑑𝑖𝑛𝑔𝑐𝑎𝑟𝑡 ≤𝑏𝑏𝑢𝑦,
where “𝑠ℎ𝑎𝑟𝑒,𝑓𝑎𝑣𝑜𝑟𝑖𝑡𝑒,𝑎𝑑𝑑𝑖𝑛𝑔𝑐𝑎𝑟𝑡 ” can be called the incomparable
relationship in the definition of partial order.
Rank Functions of Behaviors .By defining the partial order
of behaviors, we can establish the partial order of behavior com-
binations based on the nature of the partial order set. To facilitate
subsequent numerical computations, we also need to introduce the
concept of graded partial order of behaviors.
Definition 2 (Graded Partial Order of Behavior ).The graded par-
tial order of behavior is defined as a partial order set (B,≤𝑏), aug-
mented with a rank function 𝜌𝑏:B→N+, where N+represents
the set of positive natural numbers. The function 𝜌𝑏satisfies the
following conditions:
•Order-Preserving : For all𝑥,𝑦∈B, if𝑥≤𝑏𝑦, then𝜌𝑏(𝑥)≤
𝜌𝑏(𝑦).
•Covering Condition : For all𝑥,𝑦∈B, if𝑦covers𝑥(i.e., there
is no𝑧∈B such that𝑥≤𝑏𝑧≤𝑏𝑦,and𝑧≠𝑥,𝑧≠𝑦), then
𝜌𝑏(𝑦)=𝜌𝑏(𝑥)+1.
With the definition of a graded partial order of behavior, any
arbitrary partial order of behaviors can be represented by a corre-
sponding positive integer.
In subsection A.1, we provide the proof of completeness for
the grade partial order of behavior combinations to showcase the
generality of our definition.
2.3 Definition of Graphs
In this subsection, we formally define the graphs that will be used in
the proceeding contents, which are also presented in Figure 2. We
begin by discussing the separate behavior graph utilized in related
works. Then, we propose the behavior combination graph to depict
all combinations of behaviors in a single graph. Finally, we present
the partial order graph to assign a rank value to each combination.
Separate Behavior Graphs. Separate behavior graphs utilize 𝐾
different graphs to describe each users’ behavior, namely G𝑠𝑒𝑝=
{G1,···,G𝐾}. For different behaviors 𝑘, we have corresponding
historical interaction information R𝑘between users and items.
Therefore, we can represent the corresponding behavior graph of
behavior𝑘asG𝑘=(U,I,R𝑘). Besides, we utilize 𝑹𝑘to denote
the interaction matrix of 𝑘-th behavior between users and items.
Behavior Combination Graph. The behavior combination
graph’s edges describe the combined behavior situations 𝑩𝑢𝑖, rep-
resenting the set of behaviors occurring between user 𝑢and item𝑖.
For instance, if user 𝑢clicks and buys item 𝑖, then the edge between
user𝑢and item𝑖is𝑩𝑢𝑖={𝑐𝑙𝑖𝑐𝑘,𝑏𝑢𝑦}. In this context, we define
the behavior combination graph as G𝑐𝑜𝑚=(U,I,R).
Partial Order Recommendation Graph. Since the edges in
the behavior combination graph represent discrete set values that
cannot be ordered as continuous values, we utilize the rank function
in Definition 2 to convert these discrete sets into ordered sets.
We refer to this graph as a behavior combination partial order
graph or simply a Partial Order Recommendation Graph (POG) .
6259KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
Partial Order Graph Separate BehaviorGraphs Behavior Combination GraphCFBClick Graph (C)
CB
F
C
CFFB
C5
2
1
3 6
1Favor Graph (F) Buy Graph (B)User Item
Behavior Interaction
Step1 Step2
Figure 2: An illustration of the construction of Partial Order Recommendation Graph (POG). The partial order of behaviors is
given as “Click(C)≤𝑏Favor(F)≤𝑏Buy(B)”. According to Definition 3, the rank function of the partial order recommendation
graph can be given as 𝜌𝑐({C, F, B})=7,𝜌𝑐({F, B})=6,𝜌𝑐({C, B})=5,𝜌𝑐({B})=4,𝜌𝑐({C, F})=3,𝜌𝑐({F})=2,𝜌𝑐({C})=1.
Formally, it is defined as Gpo=(U,I,𝜌𝑐(R)) , where𝜌𝑐(·)denotes
the rank function to convert the behavior combinations to integers.
𝑹denotes the interaction matrix of the partial order graph between
users and items.
3 METHODOLOGY
In this section, we begin by explaining the process of generating
the Partial Order Recommendation Graph (POG) from the original
separate behavior graphs. Subsequently, we delve into the graph
convolution on the POG. Lastly, we provide the formula for the
partial order BPR loss for multi-behavior recommendation.
3.1 Construction of POG
The construction of POG involves one predefinition and one con-
verting step. In the predefinition step, the partial order of behaviors
and the partial order of behavior combinations are defined. As de-
picted in Figure 2, once the orders are defined, separate behavior
graphs can be transformed into a behavior combination graph, and
subsequently into the partial order recommendation graph.
3.1.1 Predefinition. As defined in Definition 1, exports from rec-
ommender systems can first define the partial order of behaviors
in a customized mode. As shown in Figure 2, considering three
behaviorsB={𝑐𝑙𝑖𝑐𝑘,𝑓𝑎𝑣𝑜𝑟,𝑏𝑢𝑦}, their partial order ≤𝑏can be
defined as “𝑐𝑙𝑖𝑐𝑘≤𝑏𝑓𝑎𝑣𝑜𝑟≤𝑏𝑏𝑢𝑦”.
Then, with Definition 2, we can define the rank function 𝜌𝑐to
map any behavior combination C𝑖(subset of the behavior set B) to
an integer. Specifically, the rank of each set can be defined using
the following binary comparison strategy ≤𝑐:
Definition 3 (Behavior Combination Binary Relation ).We define a
new binary relation ≤𝑐betweenC𝑖andC𝑗.C𝑖andC𝑗represent the
behavior combination. For convenience, we define 𝑓(𝑘,C𝑖)as the
function that returns the number of 𝑘-ranked behavior ( 𝜌𝑏(𝑏𝑠)=𝑘)
inC𝑖.𝑓(𝑘,C𝑖)can be formally defined as 𝑓(𝑘,C𝑖)=|{𝑏𝑠|𝜌𝑏(𝑏𝑠)=
𝑘,𝑏𝑠∈C𝑖}|, where|·|denotes the number count function. The
relation between behavior combinations can be computed in the
following recursion formula:(1)Equality Check: IfC𝑖=C𝑗, thenC𝑖≤𝑐C𝑗; otherwise, let 𝑘
be the max value of 𝜌𝑏, and proceed to the next step.
(2)Behavior Intensity Count Comparison: If𝑓(𝑘,C𝑖)<
𝑓(𝑘,C𝑗)(or𝑓(𝑘,C𝑗)<𝑓(𝑘,C𝑖)), thenC𝑖≤𝑐C𝑗(orC𝑗≤𝑐C𝑖
); otherwise, proceed to the next step.
(3)Decrease Intensity: Decrease𝑘by 1 (i.e.,𝑘=𝑘−1) and
repeat from step 2 until 𝑘=1.
(4)Incomparability Determination: If𝑘=1and𝑓(𝑘,C𝑖)=
𝑓(𝑘,C𝑗), thenC𝑖andC𝑗are considered incomparable.
With the above definition of “Behavior Combination Binary
Relation”, we have the following corollary to demonstrate that the
behavior combination set Ccan also have a rank function to map
any given behavior combination to an integer:
Corollary 1. The set(C,≤𝑐), when equipped with a rank function
𝜌𝑐:C→N+, constitutes a graded partial order set.
A detailed proof of Corollary 1, under complex situations, can
be found in Appendix A.1.
Rank function example. Figure 2 presents a specific example
of a rank function. For convenience, we use the abbreviations “B”,
“F”, and “C” to represent “buy”, “favor”, and “click” respectively
in the presentation of the rank function. Given the partial order
set and Definition 3, the rank function of the partial order rec-
ommendation graph can be defined as follows: 𝜌𝑐({C, F, B})=7,
𝜌𝑐({F, B})=6,𝜌𝑐({C, B})=5,𝜌𝑐({B})=4,𝜌𝑐({C, F})=3,
𝜌𝑐({F})=2,𝜌𝑐({C})=1. By examining the rank function, we
can observe that “buy” is the most important behavior, and there-
fore, combinations that include “buy” have a higher rank than those
without it. Furthermore, based on the comparison of the most impor-
tant behavior “buy”, {B, F}has a higher rank than {B, C}because
“favor” is considered more important than “click”.
3.1.2 POG Converting. Figure 2 illustrates the entire process of
converting the graph from separate behavior graphs to the behavior
combination graph and then to the partial order recommendation
graph. In summary, the behavior combination graph combines all
the edges from the separate behavior graphs, where each edge rep-
resents a set of behaviors between a specific user and item pair.
6260Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
Afterward, the partial order recommendation graph assigns an in-
teger weight to the set of behaviors, resulting in a unified weighted
graph. Specifically, given the definition of the behavior combination
between user 𝑢and item𝑖as𝑩𝑢𝑖and the rank function 𝜌𝑐(·), then
the interaction matrix of the partial order recommendation graph
can be defined as:
𝑹𝑢𝑖=(
𝜌𝑐(𝑩𝑢𝑖)𝜏,if𝑩𝑢𝑖≠𝜙;
0,if𝑩𝑢𝑖=𝜙,(2)
where𝜏>0represents the temperature coefficient [ 4,42] used to
adjust the importance weight of various behavior combinations.
When𝜏is increased, the distance between behavior combinations
also increases, while decreasing 𝜏results in a smaller distance be-
tween combinations. If 𝜏=0, the partial order interaction matrix
assigns a value of 1 to all interacting user-item pairs, indicating
that all behavior combinations are considered equally important.
3.2 Partial Order Graph Convolutional
Networks
In contrast to GHCF [ 6], MB-CGCN [ 12], and IMGCF [ 64], POGCN
train a single graph-based CF embedding on the POG. In this section,
we first present POGCN in matrix format and then provide the
message passing formula to enhance its applicability in the industry.
For any given user 𝑢and item𝑖, we first initialized the original
embedding vectors 𝒆(0)
𝑢,𝒆(0)
𝑖∈R𝑑, where𝑑represents the dimen-
sion of the vectors. Then we have an original embedding matrix
for all users and items: 𝑬(0)=[𝒆(0)
𝑢1,...,𝒆(0)
𝑢𝑀,𝒆(0)
𝑖1,...,𝒆(0)
𝑖𝑁]𝑇.
Matrix Form. Given the interaction matrix of partial order rec-
ommendation graph 𝑹, we extend the interaction matrix to define
the partial order adjacent matrix:
𝑨=0𝑹
𝑹𝑇0
, (3)
then we are able to obtain the partial order graph convolution
formula as:
𝑬(𝑙+1)=(𝑫−1
2𝑨𝑫−1
2)𝑬(𝑙), (4)
where 𝑫∈R(𝑀+𝑁)×(𝑀+𝑁)is a degree matrix, and 𝑫𝑖𝑖=Í
𝑗𝑨𝑖𝑗,
which denotes the sum of 𝑖-th row value of the partial order ad-
jacent matrix 𝑨. With the above definition, the final partial order
embedding matrix can be computed as follows:
𝑬=1
𝐿+1𝐿∑︁
𝑙=0𝑬(𝑙). (5)
After the graph convolution, POGCN will naturally get a single CF
embedding to achieve the CF task defined in EQ. (1).
Message Passing Form. The partial order recommendation
graph can also be done in a neighbor-wise message passing form.
Specifically, the 𝑙-th message passing of user 𝑢and item𝑖can be
given as:
𝒆(𝑙+1)
𝑢=∑︁
𝑖∈N𝑢𝑹𝑢𝑖√︁Í
𝑡𝑹𝑢𝑡√︁Í
𝑡𝑹𝑡𝑖𝒆(𝑙)
𝑖,
𝒆(𝑙+1)
𝑖=∑︁
𝑢∈N𝑖𝑹𝑢𝑖√︁Í
𝑡𝑹𝑡𝑖√︁Í
𝑡𝑹𝑢𝑡𝒆(𝑙)
𝑢,(6)whereN𝑢andN𝑖represent the sets of neighboring nodes for user
𝑢and item𝑖, respectively.Í
𝑡𝑹𝑢𝑡andÍ
𝑡𝑹𝑡𝑖are the sums of the
𝑢-th row and the 𝑖-th column in the partial order interaction ma-
trix𝑹, respectively.𝑹𝑢𝑖√Í
𝑡𝑹𝑢𝑡√Í
𝑡𝑹𝑡𝑖is the Laplace normalization
of message passing in order to avoid numerical instabilities and
exploding/vanishing gradients [26].
After performing 𝐿rounds of propagation, we take the average
of the obtained partial order embeddings at each layer to obtain
the final representation:
𝒆𝑢=1
𝐿+1𝐿∑︁
𝑙=0𝒆(𝑙)
𝑢,𝒆𝑖=1
𝐿+1𝐿∑︁
𝑙=0𝒆(𝑙)
𝑖, (7)
where 𝒆𝑢and𝒆𝑖represent the final POGCN embedding of user 𝑢
and item𝑖respectively.
3.3 Partial Order Training Strategy
Bayesian Personalized Ranking (BPR) has been extensively applied
in collaborative filtering. Traditional BPR mainly concentrates on
training with a single behavior. In this subsection, we introduce an
extension called partial order BPR, which aims to achieve efficient
and effective multi-behavior collaborative filtering.
Traditional Multi-behavior BPR. Intuitively, one traditional
way to combine the BPR loss for multiple behaviors is to apply BPR
separately for each behavior and then assign different weights to
each behavior. This can be represented as follows:
L𝑀𝑇𝐿−𝐵𝑃𝑅=𝐾∑︁
𝑘=1∑︁
𝑹𝑘𝑢𝑖=1∑︁
𝑹𝑘𝑢𝑗=0𝛼𝑘·ln(𝜎(ˆ𝑌𝑢𝑖−ˆ𝑌𝑢𝑗)), (8)
where 𝑹𝑘𝑢𝑖=1indicates that user 𝑢and item𝑖have the𝑘-th
behavior, while 𝑹𝑘𝑢𝑗=0indicates that user 𝑢and item𝑗do not
have the𝑘-th behavior. 𝛼𝑘denotes the weight of the 𝑘-th behavior.
However, the traditional multi-behavior BPR solution has the
following limitations: 1. High training cost : Performing BPR train-
ing requires computing the embedding for one user and two items,
and then performing backpropagation. Therefore, performing tra-
ditional multi-behavior BPR will incorporate 𝐾times of compu-
tational cost of single-behavior BPR, thus increasing the compu-
tational complexity. 2. Manual weighting : In traditional solutions,
experts have to manually assign the weight, which cannot automat-
ically adapt according to the importance of behavior combinations.
Our POBPR. To overcome these challenges, we propose lever-
aging a Multinomial Distribution [ 35]𝑃(C)=𝑃(𝑝1,···,𝑝𝐻)for
all𝐻possible behavior combinations, allowing for the sampling of
combinations based on their relevance and frequency. Specifically,
for any given behavior combination Cℎ, the sampling probability is
determined as follows:
𝑝ℎ=𝑃(Cℎ)=𝜌𝑐(Cℎ)𝛾·𝑛𝑢𝑚(Cℎ)
Í𝐻
𝑗=1𝜌𝑐(C𝑗)𝛾·𝑛𝑢𝑚(C𝑗), (9)
where𝑛𝑢𝑚(C𝑗)counts the occurrences of each behavior combina-
tionC𝑗, and𝛾is a temperature coefficient [ 4,42] that moderates
the influence of the rank value of each behavior combination.
6261KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
Table 1: Multi-behavior recommendation performance comparison results. The best and second-best results in each column are
highlighted in bold font and underlined , respectively.
Mo
dels MC-BPR
NMTR GHCF MB-GMN MB-CGCN IMGCF ESMM
MMoE PLE POGCN Impr
ov.(%)Beib
eiClickRe
call 0.0693
0.0325 0.0703 0.0449 0.0495 0.0688 0.0750 0.0685
0.0614 0.0935 24.68%
NDCG 0.0560
0.0262 0.0617 0.0360 0.0416 0.0571 0.0652 0.0588
0.0515 0.0841 28.95%
CartRe
call 0.1140
0.0702 0.1347 0.0833 0.0945 0.1338 0.1358 0.1240
0.1170 0.1542 13.61%
NDCG 0.0624
0.0397 0.0812 0.0443
0.0542 0.0758 0.0806
0.0719 0.0672 0.0948 16.78%
BuyRe
call 0.1428
0.1222 0.1999 0.1220
0.1428 0.1950 0.1680
0.1547 0.1789 0.2029 1.47%
NDCG 0.0690
0.0619 0.1052 0.0581
0.0724 0.0971 0.0866
0.0777 0.0903 0.1083 3.01%
MeanRe
call 0.1087
0.0750 0.1350 0.0834
0.0956 0.1326 0.1262
0.1157 0.1191 0.1502 11.28%
NDCG 0.0624
0.0426 0.0827 0.0461
0.0561 0.0767 0.0775
0.0694 0.0696 0.0957 15.80%T
aobaoClickRe
call 0.0180
0.0016 0.0392 0.0006
0.0018 0.0177 0.0070
0.0014 0.0013 0.0424 8.34%
NDCG 0.0114
0.0009 0.0274 0.0003
0.0012 0.0113 0.0043
0.0008 0.0008 0.0281 2.46%
CartRe
call 0.0276
0.0019 0.0498 0.0012
0.0031 0.0327 0.0141
0.0021 0.0016 0.0555 11.39%
NDCG 0.0116
0.0006 0.0225 0.0004
0.0016 0.0136 0.0059
0.0007 0.0009 0.0244 8.40%
Fav
orRecall 0.0271
0.0015 0.0595 0.0005
0.0013 0.0277 0.0054
0.0026 0.0011 0.0633 6.52%
NDCG 0.0116
0.0004 0.0252 0.0003
0.0004 0.0122 0.0021
0.0009 0.0003 0.0261 3.83%
BuyRe
call 0.0172
0.0027 0.0324 0.0021
0.0008 0.0309 0.0072
0.0005 0.0027 0.0396 22.07%
NDCG 0.0067
0.0008 0.0155 0.0007
0.0002 0.0128 0.0027
0.0002 0.0015 0.0188 21.04%
MeanRe
call 0.0225
0.0019 0.0452 0.0011
0.0017 0.0272 0.0084
0.0017 0.0017 0.0502 11.05%
NDCG 0.0103
0.0007 0.0226 0.0004
0.0009 0.0125 0.0038
0.0006 0.0009 0.0243 7.49%T
enrecClickRe
call 0.1284
0.0066 0.1410 0.0102
0.0744 0.0449 0.0108
0.0224 0.0121 0.1627 15.36%
NDCG 0.0827
0.0038 0.0943 0.0055
0.0511 0.0290 0.0069
0.0137 0.0075 0.1097 16.35%
LikeRe
call 0.1048 0.0105
0.0941 0.0128 0.0756 0.0661 0.0173
0.0222 0.0158 0.1221 16.44%
NDCG 0.0488 0.0038
0.0393 0.0041 0.0316 0.0325 0.0063
0.0091 0.0076 0.0621 27.33%
Shar
eRecall 0.1176 0.0147
0.1029 0.0294 0.0882 0.0772 0.0294
0.0147 0.0404 0.1324 12.50%
NDCG 0.0399
0.0035 0.0453 0.0091
0.0346 0.0400 0.0095
0.0036 0.0145 0.0636 40.25%
Follo
wRecall 0.0289
0.0051 0.0408 0.0090
0.0405 0.0408 0.0357
0.0204 0.0102 0.0697 70.83%
NDCG 0.0279 0.0015
0.0225 0.0021 0.0202 0.0162 0.0129
0.0128 0.0034 0.0380 36.25%
MeanRe
call 0.0949 0.0092
0.0947 0.0154 0.0697 0.0573 0.0233
0.0199 0.0196 0.1217 28.19%
NDCG 0.0498
0.0031 0.0503 0.0052
0.0344 0.0294 0.0089
0.0098 0.0083 0.0683 35.74%
With the above definition of the categorical distribution, we can
provide the complete formula for the POBPR loss as follows:
L𝑃𝑂𝐵𝑃𝑅 =ECℎ∼𝑃(C)∑︁
(𝑢,𝑖)∈D+
ℎ∑︁
𝑗∈D−𝑢ln𝜎(ˆ𝑌𝑢𝑖−ˆ𝑌𝑢𝑗),(10)
where ECℎ∼𝑃(C)represents the expectation over the distribution of
behavior combinations, D+
ℎdenotes the sets of positive user-item
pairs under the behavior combination Cℎ, andD−𝑢denotes the
set of negative items under all interactions of user 𝑢. We further
demonstrate the equivalence between the POBPR and the origi-
nal separate formula of multi-behavior in terms of the maximum
likelihood in Appendix A.2.
4 EXPERIMENTS
In this section, we conduct both offline and online experiments,
aiming to answer the following research questions.•RQ1: Does POGCN outperform current state-of-the-art rec-
ommendation models?
•RQ2: What are the effects of different components in POGCN?
•RQ3: How do key hyper-parameters impact POGCN?
•RQ4: How does POGCN perform on real-world industrial
recommender systems?
4.1 Experimental Setup
4.1.1 Datasets. We conduct comprehensive experiments on three
widely used benchmark datasets Beibei [14],Taobao [69], and
Tenrec [60] including both e-commerce and content recommenda-
tion scenarios for offline evaluation to verify the effectiveness and
universality of POGCN. The statistics of these datasets are shown
in Table 2. In order to avoid the cold start situation of interaction,
following previous works [ 18,46], we filter out at least 10 interac-
tive items and users to conduct the experiments. Dataset statistics
are demonstrated in Table 2. We further describe the details of these
datasets in Appendix B.1.
6262Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
Table 2: Statistics of the experimental datasets.
Datasets Users Items Click Cart/Like Fav
or/Share Buy/Follo
w
Beib
ei 21,716 7,977 2,412,586 642,622 \ 304,576
T
aobao 26,213 64,822 1,341,843 52,289 23,676 20,880
T
enrec 19,035 15,539 1,367,967 11,295 1,503 1,330
4.1.2 Compared Baselines. To comprehensively verify the effec-
tiveness of POGCN. We compare our proposed POGCN with six
multi-behavior CF models, three multi-task recommendation mod-
els, and four single-behavior CF models. (I) Multi-behavior CF
models: MC-BPR [32],NMTR [14],GHCF [6],MB-GMN [53],MB-
CGCN [12], and IMGCF [64]. (II) Multi-task recommendation
models: ESMM [34],MMoE [33], and PLE[41]. (III) Single-behavior
CF models: MF-BPR [36],NCF [19],NGCF [46], and LightGCN [18].
The details of these baseline models are left in Appendix B.2.
4.1.3 Implementation Details. For all models, the embedding size
is fixed to 64 and the embedding parameters are initialized with the
normal distribution. The learning rate of POGCN is searched from
{1×10−3,5×10−4,1×10−4}, the regularization term is searched
from {1×10−4,5×10−5,1×10−5},𝜏is searched from [0.2, 1.0] in
Taobao and Tenrec with a step of 0.2, and searched from [1.0, 5.0]
in Beibei with a step of 1.0, 𝛾is searched from [0.2, 2.0] with a step
of 0.2. The batch size is set to 1024 for all models and the Adam
optimizer [ 25] is used. For multi-behavior CF models, we adopt the
partial order relation “click ≤cart≤buy”, “click≤cart, favor≤buy”,
and “ click≤like≤share, follow ” for Beibei, Taobao, and Tenrec. For
multi-task recommendation models, due to their specific designs
for prediction tasks, we replace their backbone with LightGCN to
enhance their performance in CF tasks.
4.1.4 Evaluation Metrics. Our evaluation adopts a full-ranking
evaluation approach, following the state-of-the-art studies [ 18,28,
46]. To evaluate the effectiveness of top-ranked articles, we employ
Recall@20 and NDCG@20 as our primary metrics for each type
of behavior. In order to facilitate the overall comparison across all
types of behaviors, we further adopt the mean metric performance
of all behaviors for evaluation. Note that we ran all the experiments
five times with different random seeds and reported the average
results to prevent extreme cases.
4.2 Main Results (RQ1)
In this subsection, we compare our proposed POGCN with state-
of-the-art baseline models on the three experimental datasets. The
comparison results with multi-behavior CF and CTR models are
reported in Table 1, and the comparison results with single-behavior
CF models are illustrated in Table 3. From the results, we can have
the following observations:
POGCN can achieve significant improvements across all
types of behaviors over state-of-the-art methods. From Ta-
ble 1, we observe that POGCN achieves the highest Recall and
NDCG performance across all types of behaviors than both current
multi-behavior CF models and multi-behavior recommendation
models, with mean NDCG improvements of 15.80%, 7.49%, and
35.74% on Beibei, Taobao, and Tenrec respectively. Furthermore,
from Table 3, we can find that POGCN can also generally obtain theTable 3: Comparison results with the single behavior recom-
mendation models.
Mo
dels MF-BPR
NCF NGCF LightGCN POGCNBeib
eiClickRe
call 0.0635
0.0837 0.0916 0.0920 0.0935
NDCG 0.0506
0.0749 0.0819 0.0823 0.0841
CartRe
call 0.0808
0.0881 0.1210 0.1233 0.1542
NDCG 0.0435
0.0475 0.0702 0.0729 0.0948
BuyRe
call 0.0870
0.1206 0.1534 0.1646 0.2029
NDCG 0.0415
0.0569 0.0775 0.0841 0.1083
MeanRe
call 0.0771
0.0975 0.1220 0.1266 0.1502
NDCG 0.0452
0.0598 0.0766 0.0798 0.0957T
aobaoClickRe
call 0.0191
0.0202 0.0341 0.0421 0.0424
NDCG 0.0121
0.0120 0.0219 0.0273 0.0281
CartRe
call 0.0012
0.0022 0.0062 0.0069 0.0555
NDCG 0.0004
0.0007 0.0025 0.0033 0.0244
Fav
orRecall 0.0005
0.0032 0.0069 0.0054 0.0633
NDCG 0.0002
0.0015 0.0028 0.0021 0.0261
BuyRe
call 0.0013
0.0066 0.0054
0.0059 0.0396
NDCG 0.0005
0.0030 0.0021
0.0020 0.0188
MeanRe
call 0.0055
0.0081 0.0132 0.0151 0.0502
NDCG 0.0033
0.0043 0.0073 0.0087 0.0243T
enrecClickRe
call 0.1296
0.1258 0.1537 0.1620 0.1627
NDCG 0.0834
0.0814 0.1030 0.1097 0.1097
LikeRe
call 0.0032
0.0541 0.0247
0.0277 0.1221
NDCG 0.0012
0.0289 0.0135
0.0141 0.0621
Shar
eRecall 0.0074
0.1103 0.0074
0.0331 0.1324
NDCG 0.0021
0.0470 0.0018
0.0133 0.0636
Follo
wRecall 0.0153
0.0204 0.0102
0.0204 0.0697
NDCG 0.0048
0.0058 0.0028
0.0047 0.0380
MeanRe
call 0.0389
0.0777 0.0490
0.0608 0.1217
NDCG 0.0229
0.0408 0.0303
0.0355 0.0683
best performance through simultaneous multi-behavior learning
than single-behavior models with separate training for each behav-
ior. The results verify that POGCN can get better multi-behavior
CF recommendation results.
The multi-behavior CF models will negatively affect the
performance on click behavior. Comparing the multi-behavior
CF models in Table 1 and the traditional single-behavior CF mod-
els in Table 3, we can find that the multi-behavior CF models can
obtain relatively better results in multiple behaviors recommen-
dation, while they have a performance drop in the click behavior
recommendation than the traditional single-behavior CF models.
Single-behavior CF models only perform effectively on the click
behavior, yielding suboptimal results on other behaviors because
they lack training on such data.
The multi-behavior CTR recommendation methods are
unsuitable for CF tasks. From the results, we can find that the
state-of-the-art multi-behavior recommendation models in CTR
scenarios have suboptimal performance in CF scenarios, even if
they are equipped with the state-of-the-art LightGCN backbone.
Therefore, it is meaningful to design a multi-behavior CF method
with our proposed POG and POGCN, which can achieve the best
6263KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
Click Cart Buy0.060.090.120.150.180.21Recall@20-Beibei
Click Cart Buy0.060.070.080.090.100.11NDCG@20-Beibei
Click Cart Favor Buy0.020.030.040.050.060.07Recall@20-T aobao
Click Cart Favor Buy0.0100.0160.0220.0280.034NDCG@20-T aobaow/o PO-all w/o POG w/o POBPR POGCN
Figure 3: Ablation study results with three POGCN variants.
performance for multiple behavior recommendations simultane-
ously in the collaborative filtering setting. Therefore, it is crucial to
propose a multi-behavior model in the CF scenario, which is the
motivation of our proposed POGCN.
4.3 Ablation Study (RQ2)
In this section, we investigate the effectiveness of the designed
components in our method with three model variants: (1) w/o PO-
all, which remove all partial order components. We substitute the
POG with the interaction graph and treat all interactions with same
weight. We also substitute POBPR with traditional BPR sampling.
(2)w/o POG, which treats all nodes in the graph with equal weight
during graph convolution. (3) w/o POBPR, which utilize traditional
BPR sampling instead of POBPR.
We perform ablation studies on Beibei and Taobao datasets, and
the outcomes are presented in Figure 3. Based on the figure, we
make the following observations:
Partial order relation is important for multi-behavior CF
recommendation. Substituting the POG and POBPR with the
interaction graph and traditional BPR sampling will significantly
decrease the CF recommendation performance on all behaviors.
This phenomenon verifies that Partial order relation provides a
better description of multiple behaviors.
POG and POBPR are necessary for multi-behavior CF rec-
ommendation. From Figure 3, we observe that both POG and
POBPR have a positive impact on the performance of multiple
behaviors, indicating the importance of constructing customized
convolution and training structures.
4.4 Parameter Study (RQ3)
In this subsection, we aim to study the impact of key hyper-parameters
𝜏and𝑟in POGCN.
4.4.1 Effect of POG Parameter 𝜏.We investigate the effect of the
parameter𝜏of the importance degree between different behaviors
with the range of [1.0, 5.0] with a step size of 1.0 for Beibei, and
with the range of [0.2, 1.0] with a step size of 0.2 for Taobao. As
illustrated in the upper side of Figure 4, the best value of 𝜏for
Beibei is 3.0, while the best 𝜏value for Taobao is 0.2. Therefore, the
1 2 3 4 5
0.0820.0830.0840.0850.0860.0870.088NDCGBeibei
0.2 0.4 0.6 0.8 1.0
0.02370.02380.02390.0240T aobao
0.5 1.0 1.5 2.0
0.0800.0820.0840.0860.0880.090NDCG
0.5 1.0 1.5 2.0
0.02340.02360.02380.02400.0242
Figure 4: Parameter study of 𝜏and𝛾on Beibei and Taobao
over the Mean NDCG metric.
Table 4: Results of online A/B tests in the industrial platform.
A/B
Test PCTR
UCTR CVR GMV StayTime
v
.s. LightGCN +2.83%
+2.02% +1.69% +2.84% +1.62%
selection of parameter 𝜏should be considered carefully for better
POGCN performance.
4.4.2 Effect of Sampling Parameter 𝛾.We also evaluate the im-
pact of different partial order sampling values of 𝛾, with the range
of [0.2, 2.0] with a step size of 0.2. From the second row of Figure
4, we can find that the too-small 𝛾value will lead to too similar
between different behaviors and lead to suboptimal performance.
The selection of the 𝛾value is contingent upon the specific charac-
teristics of each dataset, necessitating a careful choice to optimize
performance. For instance, an 𝛾value of 1.4 is well-suited for the
Beibei dataset, whereas a lower value of 0.6 is preferable for the
Taobao dataset.
4.5 Online Evaluation (RQ4)
We conducted an online A/B test on the homepage of Alibaba. In this
experiment, our model served as a recall model, replacing the ex-
isting online best-performed graph-based recall model—LightGCN.
In addition to clicking behavior, POGCN also considers three other
valuable behaviors: “adding to cart”, “favoring”, and “buying”. Ta-
ble 4 presents the average relative performance variation over a
successive month for about 1 billion users and 0.2 billion items.
From the results, we observe that POGCN shows performance
improvements of+1.69%in CVR,+2.84%in GMV, and+1.62%in
StayTime compared to LightGCN. This indicates that considering
deep behaviors such as “adding to cart”, “favor”, and “buy” can
enhance the interaction depth and recommendation conversion,
thereby increasing the intent of purchasing and viewing more items.
Besides, equipped with POGCN, the recommender system is able
6264Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
to provide more accurate recommendations to users, leading to
a+2.83% increase in PCTR and +2.02% improvement in UCTR.
POGCN achieves this through the simultaneous optimization of
multiple types of behaviors, thereby enhancing user willingness to
click more recommended items.
Therefore, all the A/B testing results validate that 𝑃𝑂𝐺 and the
equipped𝑃𝑂𝐺𝐶𝑁 are more suitable than the state-of-the-art online
graph collaborative filtering models.
5 RELATED WORKS
5.1 Graph Collaborative Filtering
In recent years, graph neural networks (GNNs) have achieved su-
perior performance on a wide range of relation modeling tasks [ 11,
43,44,63], such as link prediction [ 2,40,51,61], node classifica-
tion [9, 17, 26, 37], and anomaly detection [3, 54, 55, 62].
As a mainstream link prediction task, there have been exten-
sive works for graph collaborative filtering based on the power
of GNNs [ 7,15]. Representatively, NGCF [ 46] employs a GNN
propagation mechanism that bridges users to items and users to
users, extracting graph embeddings for each entity. Moreover, Light-
GCN [ 18] simplifies the approach by omitting the non-linear param-
etered operators of NGCF and instead, aggregates the layer-wise
embeddings through a weighted summation. Recent studies have
further incorporated data augmentation and self-supervised learn-
ing techniques to bolster the performance of graph collaborative
filtering models [ 15,59]. Notably, SGL [ 49] pioneers the integration
of self-supervised learning on the user-item graph by generating
diverse node perspectives. It leverages contrastive learning to align
these multiple views of identical nodes, while simultaneously reduc-
ing the alignment with nodes that are distinct. NCL [ 30] further re-
fines the neighbor set by incorporating semantic neighbors, guided
by the principles of contrastive learning. Meanwhile, SimGCL [ 58]
offers a streamlined yet potent graph contrastive learning approach
through the strategic elimination of extraneous augmentations.
However, these models mainly focus on the scenario of a single
type of interaction behavior, without the consideration of how to
use multiple interaction behaviors for the recommendation.
5.2 Multi-Behavior Collaborative Filtering
Collaborative filtering recommendation was originally designed for
single-behavior recommendations [ 22,27,39]. Examples of such
recommendations include sequence-based [ 10,21,56,66] and graph-
based [ 18,29,46,68]. However, in real-world scenarios, users and
items exhibit multiple interaction behaviors [ 20], such as clicks,
purchases, or ratings, instead of focusing solely on a single behavior
like clicks [12, 24, 67].
Recent efforts for multi-behavior collaborative filtering mainly
focus on utilizing information from multiple types of behaviors for
user modeling to enhance recommendation performance for sparse
target behaviors, such as using data from clicks, carts, and purchases
to model interactions in the purchase behavior domain [ 47,48,52].
Representatively, NMTR [ 14] incorporates a multi-task learning
framework that acknowledges the cascading relationship among
different user behaviors, allowing for more accurate modeling of
user preferences based on a comprehensive set of interactions for
target behavior recommendations. Recently, MB-CGCN [ 12] furtheremploys a sequence of GCN blocks that correspond to different user
behaviors to capture the complex dependencies between different
user behaviors like views, clicks, and purchases. It enhances recom-
mendation performance by exploiting the cascading nature of these
behaviors, where each behavior’s embeddings are transformed and
used as input for the next behavior’s embedding learning. Neverthe-
less, these studies mainly focus on utilizing all types of behaviors
to enhance the target behavior performance, while the simultane-
ous optimization of multiple behaviors has been highly neglected,
resulting in poor performance for non-target behaviors.
5.3 Multi-Task Recommendation
Multi-task recommendation aims to effectively model relationships
between different recommendation tasks in a multi-task learning
framework [ 13,31,57,65]. These models have achieved state-of-
the-art performance in the ranking and prediction stage of rec-
ommender systems, such as simultaneously predicting the click-
through rate (CTR) and conversion rate (CVR) [1, 34, 38].
The most common method of multi-task learning is Shared Bot-
tom [ 5], which uses the coupled input to predict each task individ-
ually. ESMM [ 34] utilizes a novel structure that models CVR over
the entire space of impressions by employing auxiliary tasks of
predicting click-through rate and click-through&conversion rate.
MoE [ 23], MMoE [ 33] utilizes a mixture of experts architecture,
where each "expert" is a specialized network in a shared structure,
and multiple gating networks then learn to weigh the contribu-
tion of each expert for a given task. Further, PLE [ 41] separates
shared and task-specific components, employing multi-level ex-
perts and gating networks, and introducing a novel progressive
separation routing mechanism. This allows PLE to extract deeper,
more relevant knowledge for each specific task while mitigating
harmful interference between tasks. However, these models are
mainly designed for the prediction stage of recommendations. As
the previous analyses, they lack the capability to be adopted in the
collaborative filtering stage.
6 CONCLUSION
In this paper, we study the seesaw recommendation problem in cur-
rent multi-behavior CF models. To this end, we introduce the Partial
Order Recommendation Graphs (POG) andPartial Order Graph Con-
volutional Networks (POGCN), which has significantly advanced
the field of multi-behavior collaborative filtering for recommender
systems. POGCN offers an update in the infrastructure of multi-
behavior CF tasks and presents a groundbreaking solution to the
longstanding issue of effectively representing diverse user interac-
tions within a single CF framework. Demonstrating superior per-
formance in both offline experiments on three benchmark datasets
and online A/B tests on the industrial system, and practically serv-
ing over a billion users in a major shopping platform, POGCN not
only elevates the capability of recommendation research but also
paves the way for future research and optimizations in the realm
of large-scale multi-behavior recommender systems.
Acknowledgments
This work was supported in part by the National Natural Science
Foundation of China (Grant No. 62272200, U22A2095, 61932010).
6265KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
References
[1]Yuanchen Bei, Hao Chen, Shengyuan Chen, Xiao Huang, Sheng Zhou, and Feiran
Huang. 2023. Non-Recursive Cluster-Scale Graph Interacted Model for Click-
Through Rate Prediction. In Proceedings of the 32nd ACM International Conference
on Information and Knowledge Management. 3748–3752.
[2]Yuanchen Bei, Hao Xu, Sheng Zhou, Huixuan Chi, Haishuai Wang, Mengdi
Zhang, Zhao Li, and Jiajun Bu. 2024. CPDG: A Contrastive Pre-Training Method
for Dynamic Graph Neural Networks. In ICDE.
[3]Yuanchen Bei, Sheng Zhou, Qiaoyu Tan, Hao Xu, Hao Chen, Zhao Li, and Jia-
jun Bu. 2023. Reinforcement Neighborhood Selection for Unsupervised Graph
Anomaly Detection. In 2023 IEEE International Conference on Data Mining (ICDM).
IEEE, 11–20.
[4]Dimitris Bertsimas and John Tsitsiklis. 1993. Simulated annealing. Statistical
science 8, 1 (1993), 10–15.
[5] Rich Caruana. 1997. Multitask learning. Machine learning 28 (1997), 41–75.
[6]Chong Chen, Weizhi Ma, Min Zhang, Zhaowei Wang, Xiuqiang He, Chenyang
Wang, Yiqun Liu, and Shaoping Ma. 2021. Graph heterogeneous multi-relational
recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence ,
Vol. 35. 3958–3966.
[7]Chaochao Chen, Huiwen Wu, Jiajie Su, Lingjuan Lyu, Xiaolin Zheng, and Li
Wang. 2022. Differential private knowledge transfer for privacy-preserving
cross-domain recommendation. In Proceedings of the ACM Web Conference 2022.
1455–1465.
[8]Hao Chen, Yuanchen Bei, Qijie Shen, Yue Xu, Sheng Zhou, Wenbing Huang,
Feiran Huang, Senzhang Wang, and Xiao Huang. 2024. Macro graph neural
networks for online billion-scale recommender systems. In Proceedings of the
ACM on Web Conference 2024. 3598–3608.
[9]Hao Chen, Zhong Huang, Yue Xu, Zengde Deng, Feiran Huang, Peng He, and
Zhoujun Li. 2022. Neighbor enhanced graph convolutional networks for node
classification and recommendation. Knowledge-Based Systems 246 (2022), 108594.
[10] Hao Chen, Zefan Wang, Feiran Huang, Xiao Huang, Yue Xu, Yishi Lin, Peng
He, and Zhoujun Li. 2022. Generative adversarial framework for cold-start item
recommendation. In Proceedings of the 45th International ACM SIGIR Conference
on Research and Development in Information Retrieval. 2565–2571.
[11] Hao Chen, Yue Xu, Feiran Huang, Zengde Deng, Wenbing Huang, Senzhang
Wang, Peng He, and Zhoujun Li. 2020. Label-Aware Graph Convolutional Net-
works. In Proceedings of the 29th ACM International Conference on Information &
Knowledge Management. 1977–1980.
[12] Zhiyong Cheng, Sai Han, Fan Liu, Lei Zhu, Zan Gao, and Yuxin Peng. 2023.
Multi-Behavior Recommendation with Cascading Graph Convolution Networks.
InProceedings of the ACM Web Conference 2023. 1181–1189.
[13] Michael Crawshaw. 2020. Multi-task learning with deep neural networks: A
survey. arXiv preprint arXiv:2009.09796 (2020).
[14] Chen Gao, Xiangnan He, Dahua Gan, Xiangning Chen, Fuli Feng, Yong Li, Tat-
Seng Chua, and Depeng Jin. 2019. Neural multi-task recommendation from
multi-behavior data. In 2019 IEEE 35th international conference on data engineering
(ICDE). IEEE, 1554–1557.
[15] Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, Yuhan
Quan, Jianxin Chang, Depeng Jin, Xiangnan He, et al .2023. A survey of graph
neural networks for recommender systems: Challenges, methods, and directions.
ACM Transactions on Recommender Systems 1, 1 (2023), 1–51.
[16] Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong,
and Qing He. 2020. A survey on knowledge graph-based recommender systems.
IEEE Transactions on Knowledge and Data Engineering 34, 8 (2020), 3549–3568.
[17] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Representation
Learning on Large Graphs. In Advances in Neural Information Processing Systems,
Vol. 30.
[18] Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng
Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for
recommendation. In Proceedings of the 43rd International ACM SIGIR conference
on research and development in Information Retrieval. 639–648.
[19] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international
conference on world wide web. 173–182.
[20] Chao Huang. 2021. Recent Advances in Heterogeneous Relation Learning for
Recommendation. In Proceedings of the Thirtieth International Joint Conference
on Artificial Intelligence, IJCAI-21. 4442–4449. Survey Track.
[21] Feiran Huang, Zefan Wang, Xiao Huang, Yufeng Qian, Zhetao Li, and Hao Chen.
2023. Aligning Distillation For Cold-Start Item Recommendation. In Proceedings
of the 46th International ACM SIGIR Conference on Research and Development in
Information Retrieval. 1147–1157.
[22] Feiran Huang, Zhenghang Yang, Junyi Jiang, Yuanchen Bei, Yijie Zhang, and Hao
Chen. 2024. Large Language Model Interaction Simulator for Cold-Start Item
Recommendation. arXiv preprint arXiv:2402.09176 (2024).
[23] Robert A Jacobs, Michael I Jordan, Steven J Nowlan, and Geoffrey E Hinton. 1991.
Adaptive mixtures of local experts. Neural computation 3, 1 (1991), 79–87.
[24] Bowen Jin, Chen Gao, Xiangnan He, Depeng Jin, and Yong Li. 2020. Multi-
behavior recommendation with graph convolutional networks. In Proceedingsof the 43rd International ACM SIGIR Conference on Research and Development in
Information Retrieval. 659–668.
[25] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-
mization. arXiv preprint arXiv:1412.6980 (2014).
[26] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with
Graph Convolutional Networks. In International Conference on Learning Repre-
sentations.
[27] Yehuda Koren, Steffen Rendle, and Robert Bell. 2021. Advances in collaborative
filtering. Recommender systems handbook (2021), 91–142.
[28] Walid Krichene and Steffen Rendle. 2020. On sampled metrics for item recom-
mendation. In Proceedings of the 26th ACM SIGKDD international conference on
knowledge discovery & data mining. 1748–1757.
[29] Fake Lin, Ziwei Zhao, Xi Zhu, Da Zhang, Shitian Shen, Xueying Li, Tong Xu,
Suojuan Zhang, and Enhong Chen. 2024. When Box Meets Graph Neural Network
in Tag-aware Recommendation. arXiv preprint arXiv:2406.12020 (2024).
[30] Zihan Lin, Changxin Tian, Yupeng Hou, and Wayne Xin Zhao. 2022. Improving
graph collaborative filtering with neighborhood-enriched contrastive learning.
InProceedings of the ACM web conference 2022. 2320–2329.
[31] Qi Liu, Zhilong Zhou, Gangwei Jiang, Tiezheng Ge, and Defu Lian. 2023. Deep
Task-specific Bottom Representation Network for Multi-Task Recommendation.
InProceedings of the 32nd ACM International Conference on Information and
Knowledge Management. 1637–1646.
[32] Babak Loni, Roberto Pagano, Martha Larson, and Alan Hanjalic. 2016. Bayesian
personalized ranking with multi-channel user feedback. In Proceedings of the
10th ACM conference on recommender systems. 361–364.
[33] Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong, and Ed H Chi. 2018.
Modeling task relationships in multi-task learning with multi-gate mixture-of-
experts. In Proceedings of the 24th ACM SIGKDD international conference on
knowledge discovery & data mining. 1930–1939.
[34] Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and Kun
Gai. 2018. Entire space multi-task model: An effective approach for estimating
post-click conversion rate. In The 41st International ACM SIGIR Conference on
Research & Development in Information Retrieval. 1137–1140.
[35] Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press.
[36] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings
of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. 452–461.
[37] Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2020. DropE-
dge: Towards Deep Graph Convolutional Networks on Node Classification. In
International Conference on Learning Representations.
[38] Liangcai Su, Junwei Pan, Ximei Wang, Xi Xiao, Shijie Quan, Xihua Chen, and
Jie Jiang. 2024. STEM: Unleashing the Power of Embeddings for Multi-task
Recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence,
Vol. 38. 9002–9010.
[39] Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering
techniques. Advances in artificial intelligence 2009 (2009).
[40] Qiaoyu Tan, Xin Zhang, Xiao Huang, Hao Chen, Jundong Li, and Xia Hu. 2023.
Collaborative graph neural networks for attributed network embedding. IEEE
Transactions on Knowledge and Data Engineering (2023).
[41] Hongyan Tang, Junning Liu, Ming Zhao, and Xudong Gong. 2020. Progressive
layered extraction (ple): A novel multi-task learning (mtl) model for personalized
recommendations. In Proceedings of the 14th ACM Conference on Recommender
Systems. 269–278.
[42] Peter JM Van Laarhoven, Emile HL Aarts, Peter JM van Laarhoven, and Emile HL
Aarts. 1987. Simulated annealing. Springer.
[43] Binwu Wang, Pengkun Wang, Yudong Zhang, Xu Wang, Zhengyang Zhou, Lei
Bai, and Yang Wang. 2024. Towards Dynamic Spatial-Temporal Graph Learning:
A Decoupled Perspective. In Proceedings of the AAAI Conference on Artificial
Intelligence, Vol. 38. 9089–9097.
[44] Binwu Wang, Yudong Zhang, Xu Wang, Pengkun Wang, Zhengyang Zhou, Lei
Bai, and Yang Wang. 2023. Pattern expansion and consolidation on evolving
graphs for continual traffic prediction. In Proceedings of the 29th ACM SIGKDD
Conference on Knowledge Discovery and Data Mining. 2223–2232.
[45] Shoujin Wang, Liang Hu, Yan Wang, Xiangnan He, Quan Z. Sheng, Mehmet A.
Orgun, Longbing Cao, Francesco Ricci, and Philip S. Yu. 2021. Graph Learning
based Recommender Systems: A Review. In Proceedings of the Thirtieth Interna-
tional Joint Conference on Artificial Intelligence, IJCAI-21. 4644–4652. Survey
Track.
[46] Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.
Neural graph collaborative filtering. In Proceedings of the 42nd international ACM
SIGIR conference on Research and development in Information Retrieval. 165–174.
[47] Yuhao Wang, Ha Tsz Lam, Yi Wong, Ziru Liu, Xiangyu Zhao, Yichao Wang, Bo
Chen, Huifeng Guo, and Ruiming Tang. 2023. Multi-Task Deep Recommender
Systems: A Survey. arXiv preprint arXiv:2302.03525 (2023).
[48] Wei Wei, Chao Huang, Lianghao Xia, Yong Xu, Jiashu Zhao, and Dawei Yin. 2022.
Contrastive meta learning with behavior multiplicity for recommendation. In
Proceedings of the fifteenth ACM international conference on web search and data
mining. 1120–1128.
6266Multi-Behavior Collaborative Filtering with Partial Order Graph Convolutional Networks KDD ’24, August 25–29, 2024, Barcelona, Spain
[49] Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and
Xing Xie. 2021. Self-supervised graph learning for recommendation. In Proceed-
ings of the 44th international ACM SIGIR conference on research and development
in information retrieval. 726–735.
[50] Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. 2022. Graph neural
networks in recommender systems: a survey. Comput. Surveys 55, 5 (2022), 1–37.
[51] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE
transactions on neural networks and learning systems 32, 1 (2020), 4–24.
[52] Lianghao Xia, Chao Huang, Yong Xu, Peng Dai, Bo Zhang, and Liefeng Bo.
2020. Multiplex behavioral relation learning for recommendation via memory
augmented transformer network. In Proceedings of the 43rd international ACM
SIGIR conference on research and development in information retrieval. 2397–2406.
[53] Lianghao Xia, Yong Xu, Chao Huang, Peng Dai, and Liefeng Bo. 2021. Graph
meta network for multi-behavior recommendation. In Proceedings of the 44th
international ACM SIGIR conference on research and development in information
retrieval. 757–766.
[54] Chunjing Xiao, Zehua Gou, Wenxin Tai, Kunpeng Zhang, and Fan Zhou. 2023.
Imputation-based Time-Series Anomaly Detection with Conditional Weight-
Incremental Diffusion Models. In Proceedings of the 29th ACM SIGKDD Conference
on Knowledge Discovery and Data Mining. 2742–2751.
[55] Chunjing Xiao, Xovee Xu, Yue Lei, Kunpeng Zhang, Siyuan Liu, and Fan Zhou.
2023. Counterfactual graph learning for anomaly detection on attributed net-
works. IEEE Transactions on Knowledge and Data Engineering (2023).
[56] Yue Xu, Hao Chen, Zefan Wang, Jianwen Yin, Qijie Shen, Dimin Wang, Feiran
Huang, Lixiang Lai, Tao Zhuang, Junfeng Ge, and Xia Hu. 2023. Multi-Factor
Sequential Re-Ranking with Perception-Aware Diversification. In Proceedings
of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.
5327–5337.
[57] Mingshi Yan, Zhiyong Cheng, Chen Gao, Jing Sun, Fan Liu, Fuming Sun, and
Haojie Li. 2023. Cascading residual graph convolutional network for multi-
behavior recommendation. ACM Transactions on Information Systems (2023).
[58] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet Hung
Nguyen. 2022. Are graph augmentations necessary? simple graph contrastive
learning for recommendation. In Proceedings of the 45th international ACM SIGIR
conference on research and development in information retrieval. 1294–1303.
[59] Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Jundong Li, and Zi Huang. 2023.
Self-supervised learning for recommender systems: A survey. IEEE Transactions
on Knowledge and Data Engineering (2023).
[60] Guanghu Yuan, Fajie Yuan, Yudong Li, Beibei Kong, Shujie Li, Lei Chen, Min Yang,
Chenyun Yu, Bo Hu, Zang Li, et al .2022. Tenrec: A Large-scale Multipurpose
Benchmark Dataset for Recommender Systems. Advances in Neural Information
Processing Systems 35 (2022), 11480–11493.
[61] Muhan Zhang and Yixin Chen. 2018. Link prediction based on graph neural
networks. Advances in neural information processing systems 31 (2018).
[62] Qinggang Zhang, Junnan Dong, Keyu Duan, Xiao Huang, Yezi Liu, and Linchuan
Xu. 2022. Contrastive knowledge graph error detection. In Proceedings of the
31st ACM International Conference on Information & Knowledge Management.
2590–2599.
[63] Qinggang Zhang, Junnan Dong, Qiaoyu Tan, and Xiao Huang. 2023. Integrating
entity attributes for error-aware knowledge graph embedding. IEEE Transactions
on Knowledge and Data Engineering (2023).
[64] Yijie Zhang, Yuanchen Bei, Shiqi Yang, Hao Chen, Zhiqing Li, Lijia Chen, and
Feiran Huang. 2023. Alleviating Behavior Data Imbalance for Multi-Behavior
Graph Collaborative Filtering. In 2023 IEEE International Conference on Data
Mining Workshops (ICDMW).
[65] Yu Zhang and Qiang Yang. 2021. A survey on multi-task learning. IEEE Transac-
tions on Knowledge and Data Engineering 34, 12 (2021), 5586–5609.
[66] Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui
Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through
rate prediction. In Proceedings of the 24th ACM SIGKDD international conference
on knowledge discovery & data mining. 1059–1068.
[67] Huachi Zhou, Jiaqi Fan, Xiao Huang, Ka Ho Li, Zhenyu Tang, and Dahai Yu.
2022. Multi-interest refinement by collaborative attributes modeling for click-
through rate prediction. In Proceedings of the 31st ACM International Conference
on Information & Knowledge Management. 4732–4736.
[68] Huachi Zhou, Qiaoyu Tan, Xiao Huang, Kaixiong Zhou, and Xiaoling Wang. 2021.
Temporal augmented graph neural networks for session-based recommendations.
InProceedings of the 44th International ACM SIGIR conference on research and
development in information retrieval. 1798–1802.
[69] Han Zhu, Xiang Li, Pengye Zhang, Guozheng Li, Jie He, Han Li, and Kun Gai.
2018. Learning tree-based deep model for recommender systems. In Proceedings
of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data
Mining. 1079–1088.A Theoretical Details
A.1 Completeness Proof of Partial Order of
Behavior Combination
Proof. We aim to construct a rank function that maps the sub-
sets partitioned from the set Cby the binary relation ≤𝑐to a positive
integer, thereby establishing (C,≤𝑐)as a graded partial order set.
DefineC𝑖<𝑐C𝑗ifC𝑖≤𝑐C𝑗andC𝑖≠C𝑗.
Consider an arbitrary element C𝑖fromC. Using the binary rela-
tion, we partitionCinto three subsets:
•𝐿𝑐, containing allC𝑗such thatC𝑗<𝑐C𝑖,
•𝐸𝑐, containing allC𝑗such thatC𝑗=C𝑖orC𝑖andC𝑗are
incomparable,
•𝐺𝑐, containing allC𝑗such thatC𝑖<𝑐C𝑗.
According to Definition 3, for any C𝑗1∈𝐿𝑐,C𝑗2∈𝐸𝑐, and
C𝑗3∈𝐺𝑐, it holds thatC𝑗1<𝑐C𝑗2<𝑐C𝑗3. Elements in 𝐸𝑐are
considered of equal significance.
This partitioning process is then recursively applied to 𝐿𝑐and𝐺𝑐
until these sets are empty. Ultimately, we obtain the final partition:
𝐸𝑐1,𝐸𝑐2,...,𝐸𝑐𝑛, satisfyingC𝑗1<𝑐C𝑗2<𝑐···<𝑐C𝑗𝑛for anyC𝑗1∈
𝐸𝑐1,C𝑗2∈𝐸𝑐2, . . . ,C𝑗𝑛∈𝐸𝑐𝑛.
Define𝜌𝑐(C𝑗𝑘)=𝑘for allC𝑗𝑘∈𝐸𝑐𝑘and𝑘=1,2,...,𝑛 . It is
evident that(C,≤𝑐)equipped with 𝜌𝑐satisfies Definition 2. □
A.2 Equivalence Explanation of POBPR
Here, we will explain that such a distribution change is equivalent
to transforming the coefficients in the case where behavior combi-
nations are treated as multi-tasks. We have the likelihood function,
following BPR [36]:
𝐿(𝜃)=𝐻Ö
ℎ=1Ö
(𝑢,𝑖,𝑗)∈D+
ℎ×I𝑝(𝑖>𝑢𝑗|𝜃),
whereD+
ℎ={(𝑢,𝑖)|𝑩𝑢𝑖=Cℎ}represent the interaction set of
behavior combination Cℎ. For the sake of following discussion, we
let𝑝(𝑖>𝑢𝑗|𝜃):=𝜎(ˆ𝑌𝑢𝑖(𝜃)−ˆ𝑌𝑢𝑗(𝜃)), and can get the partial order
BPR loss function:
LPOBPR =ln𝑝(Θ|>𝑢)
=ln𝑝(>𝑢|Θ)𝑝(Θ)
=ln𝐻Ö
ℎ=1Ö
(𝑢,𝑖,𝑗)∈D+
ℎ×I𝑝(𝑖>𝑢𝑗|𝜃)+ln𝑝(𝜃)
=𝐻∑︁
ℎ=1∑︁
(𝑢,𝑖,𝑗)∈D+
ℎ×Iln𝜎(ˆ𝑌𝑢𝑖(𝜃)−ˆ𝑌𝑢𝑗(𝜃))+ln𝑝(𝜃)
=𝐻∑︁
ℎ=1𝛼ℎLBPR,Cℎ+ln𝑝(𝜃),
where𝛼ℎ∝𝑃(Cℎ)is the coefficient of the behavior combination
Cℎtask. So when we change 𝛾, the coefficients in the multi-task
loss function will also change equivalently.
B Experimental details
B.1 Dataset Details
We adopt three publicly available datasets for offline evaluation.
The detailed description of the datasets is as follows:
6267KDD ’24, August 25–29, 2024, Barcelona, Spain Yijie Zhang, et al.
•Beibei [14] is gathered from Beibei platform, one of China’s
premier e-commerce platforms specializing in baby products.
It encompasses the interactions of 21,716 users and 7,977
items, with three types of user-item behaviors: click, cart,
and buy. Source data of Beibei comes from “https://github.
com/Sunscreen123/Beibei-dataset”.
•Taobao [69] is a widely used multi-behavior dataset pro-
vided by Alibaba, one of the biggest e-commerce platforms
in China. It contains the activities (including clicks, carts, fa-
vors, and buys) of 26,213 users toward 64,822 items between
Nov. 2017 and Dec. 2017. Source data of Taobao comes from
“https://tianchi.aliyun.com/dataset/dataDetail?dataId=649”.
•Tenrec [60] is a content recommendation dataset collected
from two different feed recommendation apps of Tencent. We
utilize the video scenario subset for experiments, with 19,035
users, 15,539 items, and four types of user-item behaviors:
click, like, share, and follow. Source data of Tenrec comes
from “https://static.qblv.qq.com/qblv/h5/algo-frontend/tenrec_
dataset.html”.
B.2 Baseline Details
We compare our proposed POGCN with thirteen representative
state-of-the-art models into three main categories as follows:
(I)Multi-behavior CF models:
•MC-BPR [32] utilizes multi-behavior weight to modulate the
importance of different behaviors in the BPR loss function.
•NMTR [14] is an expansion of NCF [ 19] in multi-behavior
recommendation, adhering to the cascade rule.
•GHCF [6] is a graph-based approach for enhancing target
behavior recommendation through multi-task learning.•MB-GMN [53] is a graph meta-learning based CF model to
improve target behavior recommendations.
•MB-CGCN [12] combines multi-behavior cascade rule to
enhance graph convolution networks for the target behavior
recommendation.
•IMGCF [64] employs a multi-task learning paradigm for
collaborative filtering on multi-behavior graphs, enhancing
sparse behavior learning by leveraging information from
behaviors with ample data.
(II)Multi-task recommendation models:
•ESMM [34] employs a feature representation transfer learn-
ing strategy for multi-task CTR recommendations.
•MMoE [33] adapts the MoE structure to multi-task learning
by sharing the expert submodels across all tasks, while also
having a gating network trained to optimize each task.
•PLE [41] is a progressive layered extraction model with a
novel sharing structure design for multi-task CTR recom-
mendations.
(III)Single-behavior CF models:
•MF-BPR [36] is a widely used matrix factorization strategy
with the assumption that the positive items should score
higher than negative ones.
•NCF [19] is a CF model that leverages a multi-layer percep-
tron to learn the user-item interaction function.
•NGCF [46] explicitly encodes the collaborative signal in the
form of high-order connectivities by performing graph em-
bedding propagation.
•LightGCN [18] is a simplified variant of NGCF by including
only the most essential components.
6268