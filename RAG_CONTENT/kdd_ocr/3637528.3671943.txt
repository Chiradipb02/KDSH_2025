EntropyStop: Unsupervised Deep Outlier Detection with Loss
Entropy
Yihong Huang
East China Normal University
Shanghai, China
hyh957947142@gmail.comYuang Zhang
East China Normal University
Shanghai, China
51255902045@stu.ecnu.edu.cnLiping Wang∗
East China Normal University
Shanghai, China
lipingwang@sei.ecnu.edu.cn
Fan Zhang
Guangzhou University
Guangzhou, China
fanzhang.cs@gmail.comXuemin Lin
Shanghai Jiao Tong University
Shanghai, China
xuemin.lin@gmail.com
Abstract
Unsupervised Outlier Detection (UOD) is an important data min-
ing task. With the advance of deep learning, deep Outlier Detec-
tion (OD) has received broad interest. Most deep UOD models are
trained exclusively on clean datasets to learn the distribution of the
normal data, which requires huge manual efforts to clean the real-
world data if possible. Instead of relying on clean datasets, some
approaches directly train and detect on unlabeled contaminated
datasets, leading to the need for methods that are robust to such
challenging conditions. Ensemble methods emerged as a superior
solution to enhance model robustness against contaminated train-
ing sets. However, the training time is greatly increased by the
ensemble mechanism.
In this study, we investigate the impact of outliers on training,
aiming to halt training on unlabeled contaminated datasets before
performance degradation. Initially, we noted that blending normal
and anomalous data causes AUC fluctuations—a label-dependent
measure of detection accuracy. To circumvent the need for labels,
we propose a zero-label entropy metric named Loss Entropy for
loss distribution, enabling us to infer optimal stopping points for
training without labels. Meanwhile, a negative correlation between
entropy metric and the label-based AUC score is demonstrated
by theoretical proofs. Based on this, an automated early-stopping
algorithm called EntropyStop is designed to halt training when
loss entropy suggests the maximum model detection capability.
We conduct extensive experiments on ADBench (including 47 real
datasets), and the overall results indicate that AutoEncoder (AE)
enhanced by our approach not only achieves better performance
than ensemble AEs but also requires under 2%of training time.
Lastly, loss entropy and EntropyStop are evaluated on other deep
OD models, exhibiting their broad potential applicability.
∗Corresponding author.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
KDD ’24, August 25–29, 2024, Barcelona, Spain
©2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-0490-1/24/ 08. . . $15.00
https://doi.org/10.1145/3637528.3671943CCS Concepts
•Computing methodologies →Anomaly detection; Neural
networks; Machine learning.
Keywords
Anomaly Detection, Outlier Detection, Unsupervised Learning, In-
ternal Evaluation
ACM Reference Format:
Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, and Xuemin Lin.
2024. EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy.
InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery
and Data Mining (KDD ’24), August 25–29, 2024, Barcelona, Spain. ACM, New
York, NY, USA, 12 pages. https://doi.org/10.1145/3637528.3671943
1 Introduction
Outlier Detection (OD) is a fundamental machine learning task,
which aims to detect the instances that significantly deviate from
the majority [ 6]. In some contexts, outliers are also named as anom-
alies, deviants, novelties, or exceptions [ 6]. Due to various applica-
tions of OD in high-impact domains (e.g. financial fraud [ 9]), nu-
merous researchers are devoted to proposing algorithms to tackle
OD [ 10,15]. According to the availability of labels, OD tasks and
solutions can be categorized into Supervised OD, Semi-Supervised
OD, and Unsupervised OD [ 30]. With the rapid development of deep
learning, deep OD algorithms are proposed increasingly [ 5,20,24].
Compared to traditional algorithms, deep ODs can handle various
kinds of complex data and high-dimensional data more effectively.
Unlabeled DataUnlabeled dataUnlabeled Normal Data
Unlabeled Abnormal Data
TrainingInliers
OutliersLabeled Data
Inliers
OutliersModel Model
Training
Training Dataset Training DatasetLabeled Normal Data
(a)  UOD trained on clean dataset (b)  UOD trained on contaminated dataset
Figure 1: Two paradigms of unsupervised OD
 
1143
KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
Unsupervised OD (UOD) aims to identify outliers in a contam-
inated dataset (i.e., a dataset consisting of both normal data and
outliers) without the availability of labeled data [ 30]. While the
study on deep UOD is extensive, it is crucial to distinguish between
two fundamentally different paradigms within this domain. The
first type, as shown in Fig. 1(a), refers to the algorithms that are
trained exclusively on clean datasets, e.g. DeepSVDD [ 25], NeuTraL
AD [ 22], ICL [ 27], AnoGAN [ 26]. These UOD algorithms operate
on the premise that the training set is devoid of outliers, allowing
the trained models to be applied to new test datasets containing po-
tential anomalies. This approach necessitates the manual collection
of large normal data, which imposes a burden before OD.
Conversely, the second type of UOD algorithms, shown in Fig.
1(b), are designed to operate directly on the dataset that contains
outliers, e.g., RandNet [ 7], ROBOD [ 8], RDP [ 29], RDA [ 35], Isola-
tionForest [ 14], GAAL [ 16]. These models are capable of identifying
outliers within the training set itself or, after being trained on a
contaminated dataset, can be deployed to detect anomalies in new
data—provided that the distribution of the new data aligns with
that of the original training set. The focus of our work is on the sec-
ond paradigm where the UOD models are trained on contaminated
datasets, which is more challenging. In this paper, we will discuss
the purely unsupervised scenario where there is no available label
for both training and validation. For the sake of convenience, the
term Unsupervised OD mentioned in the remainder of this article,
unless specifically stated otherwise, will refer to OD in the purely
unsupervised setting.
0 50 100 150 200 250 3000.40.50.6AUC
Best AUC
0 50 100 150 200 250 300
Training iterations2550Train Loss
Val LossDataset:  optdigits (polluted)
0 50 100 150 200 250 3000.60.8
AUC
Best AUC
0 50 100 150 200 250 300
Training iterations2550Train Loss
Val LossDataset:  optdigits (clean)
0 50 100 150 200 250 3000.900.95
AUC
Best AUC
0 50 100 150 200 250 300
Training iterations05Train Loss
Val LossDataset:  shuttle (polluted)
0 50 100 150 200 250 3000.9900.995
AUC
Best AUC
0 50 100 150 200 250 300
Training iterations024Train Loss
Val LossDataset:  shuttle (clean)
Figure 2: UOD training process of AutoEncoder on 2 datasets
Challenge .It is well-known that the model trained on a contami-
nated dataset will result in a much worse performance. Fig. 2 shows
the trend of Area Under Curve (AUC) [ 3] and loss throughout the
unsupervised training process of an AutoEncoder (AE) across two
datasets. The dataset is divided into training and validation sets.
"Polluted" indicates the presence of outliers in the datasets, whereas
"clean" signifies that the datasets contain only normal samples. The
AUC is calculated using the labels by Eq. 2. Note that we assume
labels of the validation set in the "polluted" setting are not available
here for evaluation, adhering to a purely unsupervised paradigm.Fig. 2 shows that when the AE model is trained on a clean dataset,
the AUC increases steadily until convergence. However, on the con-
taminated dataset, the AUC exhibits significant fluctuations, and
no such noteworthy features are observed in the loss curve. Such
fluctuations in AUC can be attributed to the AE model’s objective
of minimizing loss across both normal and anomalous data, leading
to a scenario where a reduction in total loss does not necessarily
equate to enhanced detection capabilities. The compulsory diver-
gence between unsupervised training objective and application
objective leads to the observed volatility in AUC.
To solve the above issue, the SOTA deep UOD models adopt an
ensemble learning approach [ 7,8,16,29] to enhance the model’s
robustness to outliers. Their strategy is to train multiple OD models
(such as AEs) and use the results of voting to enhance the robustness
and improve detection performance. To generate diverse voting
outcomes, models are intentionally overfitted to the dataset through
varying configurations, such as different random seeds or hyper-
parameters (HPs) [ 8], and extended training periods [ 7]. However,
overtraining a large number of models imposes significant time
and computation costs.
Our Solution . The current dilemma: the presence of anomalies
diminishes training effectiveness, while existing ensemble solutions
improve performance at the sacrifice of efficiency. Different from
current methods, we propose a novel approach through data dis-
tribution analysis. This work employs early stopping to mitigate
the negative effects of outliers in the training sets, thus improving
training efficiency and effectiveness. Specifically, this work delves
into the impact of outliers on the model training process. We first
identify the existence of a loss gap (i.e., the expected difference in
training loss between outliers and inliers) and introduce a novel met-
ric, the entropy of loss distribution in different training iterations, to
reflect changes in the detection capability during training. We theo-
retically demonstrate that under certain assumptions, an increase in
AUC is likely to cause a decrease in loss entropy, with the converse
also holding. Notably, unlike AUC, the computation of entropy does
not require labels. In this case, we can utilize the entropy curve to
mirror changes in the AUC curve (examples are given in Fig. 5).
Surprisingly, our experiments reveal a strong correlation between
the two metrics across numerous real-world datasets. Leveraging
this, we propose a label-free early stopping algorithm that uses
entropy minimization as a cue for optimal training cessation.
Our experiments across 47 real datasets [ 10] observed that AE
models often achieve high AUC relatively early in training, and our
entropy-based early stopping algorithm effectively identifies these
moments to automatically halt training. The results demonstrate
that our method significantly enhances the detection performance
of AE, while significantly reducing training time compared to AE
ensemble solutions. Lastly, we discovered that the entropy-based
early stopping algorithm can also be extended to other deep UOD
models, exhibiting their broad potential applicability. The contribu-
tions of this paper are as follows:
•We propose a novel metric (loss entropy) to reflect changes in
modeling AUC with no labels. To the best of our knowledge,
this is the first indicator that can predict changes in model
performance without labels, validated across a multitude of
real datasets.
 
1144EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy KDD ’24, August 25–29, 2024, Barcelona, Spain
•We develop an automated early-stopping algorithm that can
automatically help UOD models avoid fitting on anomalous
data and reduce training time.
•We conduct extensive experiments to demonstrate the ef-
ficacy of our metric and algorithm, validating the superior
performance compared to ensemble solutions while requir-
ing a minor fraction of time.
To foster future research, we open source all codes at URL1and a
more comprehensive version of the paper is shared at URL2.
2 Related Work
2.1 Unsupervised Outlier Detection
Unsupervised outlier detection (UOD) is a vibrant research area,
which aims at detecting outliers in datasets without any label dur-
ing the training [ 6]. Solutions for unsupervised OD can be broadly
categorized into shallow (traditional) [ 4,14,23] and deep (neu-
ral network) methods. Compared to traditional counterparts, deep
methods handles large, high-dimensional and complex data better
[5,20,24]. Most deep UOD models [ 22,25–27] are trained exclu-
sively on clean datasets to learn the distribution of the normal data. A
fundamental premise of this methodology presupposes the availabil-
ity of clean training data to instruct the model on the characteristics
of "normal" instances. However, this assumption frequently encoun-
ters practical challenges, as datasets are often enormous and may
inadvertently include anomalies that the model seeks to identify
[21]. In response to this dilemma, certain studies [ 29,35,36] ven-
ture into developing deep UOD algorithms that operate directly on
contaminated datasets. Model ensemble approaches are proposed
for their outstanding performance and robustness, coupled with a
diminished sensitivity to hyperparameters (HPs) [ 7,8,16]. Addi-
tionally, efforts are made to adapt models originally trained on clean
datasets to contaminated ones through outlier refinement processes
[21,32,34]. Nevertheless, to our best knowledge, the existing UOD
studies do not capture the changes in model performance during
the training to enable effective early stopping.
2.2 Early Stopping Techniques
Early stopping is an effective and broadly used technique in machine
learning. Early stopping algorithms are designed to monitor and
stop the training when it no longer benefits the final performance.
A well-known application of early stopping is to use it as a regular-
ization method to tackle overfitting problems with cross-validation,
which can be traced back to the 1990s [ 18]. Recently, with a deeper
understanding of learning dynamics, early stopping is also found
practical in noisy-labeled scenarios [ 1,2,12,31]. According to these
previous studies, overfitting to the noisy samples in the later stage
of training decreases the model’s performance, and can be mitigated
by early stopping. Previous works show the outstanding ability of
early stopping to deal with noisy learning environments. However,
existing researches focus on supervised or semi-supervised settings,
while early stopping in unsupervised contaminated training set
is significantly more challenging. To our best knowledge, we are
the first to apply a label-free and distribution-based heuristic to
1https://github.com/goldenNormal/EntropyStop-KDD2024
2https://arxiv.org/abs/2405.12502explore the potential of early stopping in Unsupervised OD on
contaminated training sets.
3 Preliminary
Problem Formulation (Unsupervised OD). Considering a data
spaceX, an unlabeled dataset 𝐷={x𝑗}𝑛
𝑗=1consists of an inlier
set𝐷𝑖𝑛and an outlier set 𝐷𝑜𝑢𝑡, which originate from two different
underlying distributions X𝑖𝑛andX𝑜𝑢𝑡, respectively [ 11]. The goal is to
learn an outlier score function 𝑓(·)to calculate the outlier score value
𝑣𝑗=𝑓(x𝑗)for each data point x𝑗∈𝐷. Without loss of generality, a
higher𝑓(x𝑗)indicates more likelihood of x𝑗to be an outlier.
Unsupervised Training Formulation for OD. Given a UOD
model𝑀, at each iteration, a batch of instances 𝐷𝑏={𝑥0,𝑥1,...,𝑥𝑛}
is sampled from the data space X. The lossLfor model𝑀is calcu-
lated over𝐷𝑏as follows:
L(𝑀;𝐷𝑏)=1
|𝐷𝑏|∑︁
𝑥∈𝐷𝑏J𝑀(𝑥)=1
|𝐷𝑏|∑︁
𝑥∈𝐷𝑏𝑓𝑀(𝑥)=1
|𝐷𝑏|∑︁
𝑖𝑣𝑖
whereJ𝑀(·)denotes the unsupervised loss function of 𝑀whileL
denotes the loss based on which the model 𝑀updates its param-
eters by minimizing L, with assumption that the learning rate 𝜂
is sufficiently small. In addition, we assume the unsupervised loss
functionJ𝑀(·)and outlier score function 𝑓𝑀(·)are the same in our
context. If this does not hold, at least the Assumption 3.1 should
be satisfied in our context. Since 𝑓𝑀(𝑥)>0typically holds, we
assume𝑓𝑀(𝑥)>0. Note that throughout the training process, no
labels are available to provide direct training signals, nor are there
validation labels to evaluate the model’s performance.
Assumption 3.1 (Alignment).
∀x𝑖,x𝑗∼𝑋, 𝑓𝑀(x𝑖)<𝑓𝑀(x𝑗) ⇐⇒ J𝑀(x𝑖)<J𝑀(x𝑗)
Objective: The objective is to train the model 𝑀such that it
achieves the best detection performance on X. Specifically, we aim
to maximize the probability that an inlier from X𝑖𝑛has a lower
outlier score than an outlier from X𝑜𝑢𝑡, i.e.,
𝑃(𝑣−<𝑣+)=𝑃(𝑓𝑀(𝑥𝑖𝑛)<𝑓𝑀(𝑥𝑜𝑢𝑡)|𝑥𝑖𝑛∼X𝑖𝑛,𝑥𝑜𝑢𝑡∼X𝑜𝑢𝑡)
(1)
as large as possible, where 𝑓𝑀(·)is the outlier score function learned
by model𝑀. LetO𝑖𝑛andO𝑜𝑢𝑡represent the distributions of 𝑓𝑀(𝑥),
where𝑥is drawn fromX𝑖𝑛andX𝑜𝑢𝑡, respectively. Therefore, 𝑣−∼
O𝑖𝑛and𝑣+∼O𝑜𝑢𝑡denotes the corresponding random variable of
outlier score.
The relationship between 𝑃(𝑣−<𝑣+)and AUC . AUC [ 3] is a
widely-used metric to evaluate the outlier detection performance,
which can be formulated as:
𝐴𝑈𝐶(𝑀,𝐷)=1
|𝐷𝑖𝑛||𝐷𝑜𝑢𝑡|∑︁
x𝑖∈𝐷𝑖𝑛∑︁
x𝑗∈𝐷𝑜𝑢𝑡I(𝑓𝑀(x𝑖)<𝑓𝑀(x𝑗))
(2)
where Iis an indicator function. Note that in practice, AUC is
discretely computed on a real dataset, and the expression 𝑃(𝑣−<
𝑣+)is the continuous form of AUC. 𝑃(𝑣−<𝑣+)signifies the model’s
inherent capability to distinguish between inliers and outliers from
a view of the data distribution instead of a certain dataset.
 
1145KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
4 Methodology
In this section, we elucidate how early stopping can enhance the
training effectiveness of unsupervised OD models on contaminated
datasets. Initially, we introduce the concept of loss gap and explain
the prevalence of inlier priority, which refers to the phenomenon
that the average loss of normal samples invariably remains lower
than that of anomalous samples. Subsequently, we introduce a
novel metric, Loss Entropy ( 𝐻𝐿), which mirrors changes in the
model’s detection capability. Notably, the calculation of 𝐻𝐿does
not involve labels, making it a purely internal evaluation metric.
Finally, leveraging the proposed 𝐻𝐿, we design an early stopping
algorithm𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 that can cease training automatically when
the𝐻𝐿is sufficiently small.
4.1 Loss Gap and Inlier Priority
4.1.1 Loss Gap Firstly, we propose the concept of loss gap, which
can reflect the fitting difference between inliers and outliers. Given
that a batch of dataset 𝐷𝑏can be divided into two parts, 𝐷𝑏
𝑖𝑛and
𝐷𝑏
𝑜𝑢𝑡, the average loss for both the normal and abnormal part can
be calculated asL𝑖𝑛andL𝑜𝑢𝑡, respectively. The term "loss gap"
refers to the gap between the two average loss values. Thus, we
define the loss gap as follows:
L𝑖𝑛=1
|𝐷𝑏
𝑖𝑛|∑︁
𝑓𝑀(x𝑖),x𝑖∈𝐷𝑏
𝑖𝑛(3)
L𝑜𝑢𝑡=1
|𝐷𝑏
𝑜𝑢𝑡|∑︁
𝑓𝑀(x𝑖),x𝑖∈𝐷𝑏
𝑜𝑢𝑡 (4)
𝐿𝑔𝑎𝑝=L𝑜𝑢𝑡−L𝑖𝑛 (5)
4.1.2 The prevalence of the inlier priority Typically,𝐿𝑔𝑎𝑝>0
is usually observed during the training, which is called as inlier
priority in the literature [ 30]. The reason can be attributed as
follows. Outliers refer to points that deviate significantly from the
vast majority, such as noise. A characteristic of outliers is their
scarcity and the significant distinction in their pattern from most
points. In some scenarios, although outliers can be similar to inliers
in attributes, they are still relatively scarce and have patterns and
distributions that are different from the majority of the dataset. This
distinction can be utilized by UOD algorithms, assigning higher
scores to outliers. Therefore, the model tends to generate greater
losses for outlier samples compared to normal ones. Consequently,
it is often observed during training that the loss associated with
outlier samples exceeds that of normal samples, indicating a gap
in loss values. This gap helps outlier detectors identify outliers
with greater loss. Examples are shown in Fig. 3 that there is a gap
betweenL𝑖𝑛andL𝑜𝑢𝑡whileL𝑖𝑛<L𝑜𝑢𝑡holds during the training.
L𝑖𝑛<L𝑜𝑢𝑡can also be explained in following two perspectives
[30, 33]:
From the loss perspective: The overall lossLcan be represented
by the weighted sum of L𝑖𝑛andL𝑜𝑢𝑡:
L=|𝐷𝑏
𝑜𝑢𝑡|
𝑛L𝑜𝑢𝑡+|𝐷𝑏
𝑖𝑛|
𝑛L𝑖𝑛 (6)
Due to the scarcity of outliers (i.e., |𝐷𝑏
𝑖𝑛|≫|𝐷𝑏
𝑜𝑢𝑡|), the weight of
L𝑖𝑛is larger. Thus, the model puts more efforts to minimize L𝑖𝑛.
/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013 /uni00000016/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000048/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000018/uni00000013/uni00000014/uni00000013/uni00000013/uni00000014/uni00000018/uni00000013/uni00000015/uni00000013/uni00000013/uni0000004f/uni00000052/uni00000056/uni00000056/uni00000027/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni0000001d/uni00000003/uni00000050/uni00000051/uni0000004c/uni00000056/uni00000057
/uni0000004c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000052/uni00000058/uni00000057/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013 /uni00000016/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000048/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000018/uni00000014/uni00000013/uni00000014/uni00000018/uni00000015/uni00000013/uni00000015/uni00000018/uni00000016/uni00000013/uni00000016/uni00000018/uni0000004f/uni00000052/uni00000056/uni00000056/uni00000027/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni0000001d/uni00000003/uni0000004f/uni00000048/uni00000057/uni00000057/uni00000048/uni00000055
/uni0000004c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000052/uni00000058/uni00000057/uni0000004f/uni0000004c/uni00000048/uni00000055Figure 3: Loss Gap for inliers and outliers in AE models on
MNIST and Letter datasets
From the gradient perspective: The learnable weights Θof𝑀
are updated by gradient descent:
𝑔=1
𝑛∑︁
𝑔𝑖=1
𝑛∑︁d𝑓𝑀(x𝑖)
dΘ(7)
where𝑔𝑖is the gradient contributed by x𝑖. The normalized reduction
in loss for the 𝑖𝑡ℎsample is as follows:
ΔL𝑖=<𝑔𝑖,𝑔>
|𝑔|=|𝑔𝑖|𝑐
𝑜𝑠𝜃(𝑔𝑖,𝑔) (8)
where𝜃(𝑔𝑖,𝑔)is the angle between two gradient vectors. In most
cases, outliers are arbitrarily scattered throughout the feature space,
resulting in counterbalancing gradient directions; while inliers are
densely distributed, and their gradient directions are relatively more
consistent. Therefore, 𝜃(𝑔𝑖,𝑔)for an inlier is often smaller than that
of an outlier, leading to a larger ΔL𝑖forx𝑖∈𝐷𝑖𝑛.
In this case, we can conclude that if L𝑖𝑛≈L𝑜𝑢𝑡, then ΔL𝑖𝑛>
ΔL𝑜𝑢𝑡, resulting in 𝐿𝑔𝑎𝑝>0(i.e.,inlier priority ). Our subsequent
proposed metric, loss entropy, is based on inlier priority, which
works as a foundational assumption for the theoretical proof and
intuition understanding of our metric.
4.2 Loss Entropy 𝐻𝐿: The Novel Internal
Evaluation Metric
Next, we introduce a metric that can be computed without labels.
Importantly, this metric will be used to gain insights into changes
in the model’s AUC during the training process. In this subsection,
we first define the metric and then look into how it works with
both intuitive understanding and theoretical proofs.
4.2.1 Definition: Loss Entropy, 𝐻𝐿, is the entropy of the loss
distribution output by the model, and it can be defined as follows:
𝑢𝑖=𝑓𝑀(𝑥𝑖)Í
𝑥∈𝐷𝑒
𝑣𝑎𝑙𝑓𝑀(𝑥),𝑥𝑖∈𝐷𝑒𝑣𝑎𝑙 (9)
𝐻𝐿=−∑︁
𝑖(𝑢𝑖log𝑢𝑖), 𝑠.𝑡.∑︁
𝑖𝑢𝑖=1,𝑢𝑖≥0 (10)
Eq. 9 denotes the operation to convert the outlier scores to the
loss distribution while Eq. 10 denotes the operation to compute
the entropy for the loss distribution. Compared with computing on
the entire dataset 𝐷, computing on a subset is significantly more
efficient while maintaining nearly intact performance. Since input
samples in each batch are stochastically selected, fixing another
constant set to calculate 𝐻𝐿eliminates the influence of the stochas-
ticity of the input batch. Therefore, we randomly sample 𝑁𝑒𝑣𝑎𝑙
 
1146EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy KDD ’24, August 25–29, 2024, Barcelona, Spain
/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000013/uni00000013/uni00000011/uni0000001b/uni00000015/uni00000018/uni00000013/uni00000011/uni0000001b/uni00000018/uni00000013/uni00000013/uni00000011/uni0000001b/uni0000001a/uni00000018/uni00000013/uni00000011/uni0000001c/uni00000013/uni00000013/uni00000013/uni00000011/uni0000001c/uni00000015/uni00000018/uni0000000b/uni00000044/uni0000000c/uni00000003/uni00000024/uni00000038/uni00000026/uni00000003/uni00000046/uni00000058/uni00000055/uni00000059/uni00000048
/uni00000024/uni00000038/uni00000026
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000027/uni00000044/uni00000057/uni00000044/uni00000003/uni00000053/uni00000052/uni0000004c/uni00000051/uni00000057/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000013/uni00000015/uni00000013/uni00000011/uni00000013/uni00000013/uni00000017/uni00000013/uni00000011/uni00000013/uni00000013/uni00000019/uni00000013/uni00000011/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000011/uni00000013/uni00000014/uni00000013/uni0000004f/uni00000052/uni00000056/uni00000056
/uni0000000b/uni00000047/uni0000000c/uni00000003/uni00000027/uni0000004c/uni00000056/uni00000057/uni00000055/uni0000004c/uni00000045/uni00000058/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000044/uni00000057/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000013
/uni0000004c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000052/uni00000058/uni00000057/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000027/uni00000044/uni00000057/uni00000044/uni00000003/uni00000053/uni00000052/uni0000004c/uni00000051/uni00000057/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018/uni00000013/uni00000011/uni00000013/uni00000014/uni00000013/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni0000004f/uni00000052/uni00000056/uni00000056
/uni0000000b/uni00000048/uni0000000c/uni00000003/uni00000027/uni0000004c/uni00000056/uni00000057/uni00000055/uni0000004c/uni00000045/uni00000058/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000044/uni00000057/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000017/uni0000001c
/uni0000004c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000052/uni00000058/uni00000057/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000018/uni00000011/uni00000014/uni00000018/uni00000011/uni00000015/uni00000018/uni00000011/uni00000016/uni00000018/uni00000011/uni00000017/uni00000018/uni00000011/uni00000018/uni0000000b/uni00000046/uni0000000c/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c/uni00000003/uni00000046/uni00000058/uni00000055/uni00000059/uni00000048
/uni0000004f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000048/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000014/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000013/uni00000014/uni00000013/uni00000015/uni00000013/uni00000016/uni00000013/uni00000017/uni00000013/uni00000018/uni00000013/uni0000004f/uni00000052/uni00000056/uni00000056/uni0000000b/uni00000045/uni0000000c/uni00000003/uni0000002c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055/uni00000003/uni00000053/uni00000055/uni0000004c/uni00000052/uni00000055/uni0000004c/uni00000057/uni0000005c
/uni0000004c/uni00000051/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000052/uni00000058/uni00000057/uni0000004f/uni0000004c/uni00000048/uni00000055
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
Figure 4: An example of the training process. The AE model is trained on the dataset Ionosphere with 300 iterations. In this
example, the lowest 𝐻𝐿exactly matches the optimal AUC at the 49𝑡ℎiteration. The y-axis of two scatter plot (i.e. the 4𝑡ℎfigure
and the 5𝑡ℎfigure) is normalized data loss value 𝑢𝑖.
instances from 𝐷to create the evaluation dataset 𝐷𝑒𝑣𝑎𝑙, ensuring
both the efficiency and consistency of computing 𝐻𝐿.
To ensure the integrity and consistency, when calculating en-
tropy, we disable randomization techniques such as dropout. These
techniques, however, may remain active during training. This ap-
proach mitigates potential variability in loss entropy estimation,
thereby providing a more stable measurement.
4.2.2 Intuition Understanding First, we will present the intu-
ition behind how entropy works. The basic assumption is that if L𝑖𝑛
decreases much more than L𝑜𝑢𝑡(i.e.ΔL𝑖𝑛≫ΔL𝑜𝑢𝑡) , then the
model learns more useful signals, leading to an increase in model’s
detection performance. Contrarily, the model learns more harmful
signals if ΔL𝑖𝑛≪ΔL𝑜𝑢𝑡.
Due to the intrinsic class imbalance, the shape of loss distribu-
tion can give insights into which part of signals the model learns
more. Specifically, if ΔL𝑖𝑛≫ΔL𝑜𝑢𝑡, then the majority of loss
(i.e.{𝑓𝑀(𝑥𝑖),𝑥𝑖∈𝐷𝑖𝑛}) has a dramatic decline while the minority
of loss (i.e.{𝑓𝑀(𝑥𝑖),𝑥𝑖∈𝐷𝑜𝑢𝑡}) remains relatively large, leading
to a steeper distribution. Conversely, when ΔL𝑖𝑛≪ΔL𝑜𝑢𝑡, the
distribution will become flatter. Thus, the changes in the shape of
the distribution can give some valuable insights into the variation
in the latent detection capability.
Interestingly, entropy itself can be utilized to gauge the shape of a
distribution. When the distribution is more balanced, entropy tends
to be higher, whereas a steeper distribution (i.e., when certain events
have a higher probability of occurring) exhibits lower entropy [ 28].
Thus, entropy inherently captures the variations in the shape of
the loss distribution.
An example is shown in Fig. 4 to exhibit our intuition. The red
dashed vertical line marks the 49𝑡ℎiteration where AUC reaches its
peak. As shown in the figure, (1) The lowest 𝐻𝐿exactly matches the
optimal AUC in this example. (2) The change in the loss distribution
from the 0𝑡ℎiteration to the 49𝑡ℎiteration corroborates our analysis
that the loss of inliers drops intensely while the loss of outliers
remains large.
4.2.3 Theoretical Proof: We will demonstrate that an increase
in the AUC is more likely to result in a decrease in 𝐻𝐿, under the
assumption that inlier priority holds.
Theorem 4.1. WhenL𝑖𝑛<L𝑜𝑢𝑡and the AUC increases, the 𝐻𝐿
is more likely to decrease.
Proof. See Appx. B.2 for the proof. □Similarly, the converses of Theorems 4.1 can also be proven
by analogous reasoning. Thus, 𝐻𝐿is expected to have a negative
correlation with detection capability, which paves the ways for our
early stopping algorithm.
4.3 EntropyStop: Automated Early Stopping
Algorithm
Based on the indicator 𝐻𝐿, we devise an algorithm to automated
early stopping the unsupervised training before the model’s detec-
tion performance is degraded by outlier.
Basically, we opt to stop training as soon as the entropy stops
decreasing. Moreover, it is essential to ascertain that the curve
which the lowest entropy lies on is relatively smooth with minor
fluctuations. Strong fluctuations may reflect analogous variations
in the AUC, implying that the improvement in AUC lacks stability.
We formulate our problem as below.
Problem Formulation. SupposeE={𝑒𝑗}𝐸
𝑗=0denotes the en-
tropy curve of model 𝑀. When𝑀finishs its𝑖𝑡ℎtraining iteration,
only the subcurve{𝑒𝑗}𝑖
𝑗=0is available. The goal is to select a point
𝑒𝑖∈Eas early as possible that (1) ∀𝑗<𝑖,𝑒𝑖<𝑒𝑗; (2) the subcurve
{𝑒𝑗}𝑖
𝑗=0has a smooth downtrend; (3) ∀𝑞∈(𝑖,𝑘+𝑖), the subcurve
{𝑒𝑗}𝑞
𝑗=𝑖has no smooth downtrend.
Algorithm. In above formulation, 𝑘is the patience parameter
of algorithm. As an overview, our algorithm continuously explores
new points within 𝑘iterations of the current lowest entropy point
𝑒𝑖, and tests whether the subcurve between the new point and 𝑒𝑖ex-
hibits a smooth downtrend. Specifically, when encountering a new
point𝑒𝑞, we calculate 𝐺=Í𝑞
𝑗=𝑖+1(|𝑒𝑗−𝑒𝑗−1|)as the total variations
of the subcurve{𝑒𝑗}𝑞
𝑗=𝑖and the downtrend of the subcurve is then
quantified by𝑒𝑖−𝑒𝑞
𝐺. Particularly, if the subcurve is monotonically
decreasing, then𝑒𝑖−𝑒𝑞
𝐺=1. To test for a smooth downtrend, we use
a threshold parameter 𝑅𝑑𝑜𝑤𝑛∈(0,1). Only when𝑒𝑖−𝑒𝑞
𝐺exceeds
𝑅𝑑𝑜𝑤𝑛 will𝑒𝑞be considered as the new lowest entropy point. The
complete process is shown in Algorithm 1. In Fig. 5, we list a few
examples to show the effectiveness of 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 .
Two new parameters are introduced, namely 𝑘and𝑅𝑑𝑜𝑤𝑛 .𝑘
represents the patience for searching the optimal iteration, with
larger value usually improving accuracy at the expense of longer
training time. Then, 𝑅𝑑𝑜𝑤𝑛 sets the requirement for the smooth
of downtrend. Apart from these two parameters, learning rate is
also critical as it can significantly impact the training time. We
 
1147KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000017/uni00000013/uni00000013 /uni00000019/uni00000013/uni00000013 /uni0000001b/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000024/uni00000038/uni00000026/uni0000000b/uni00000044/uni0000000c/uni00000003/uni00000024/uni00000028/uni00000003/uni00000052/uni00000051/uni00000003/uni0000002c/uni00000052/uni00000051/uni00000052/uni00000056/uni00000053/uni0000004b/uni00000048/uni00000055/uni00000048
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000015/uni00000013/uni00000013 /uni00000017/uni00000013/uni00000013 /uni00000019/uni00000013/uni00000013 /uni0000001b/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000018/uni00000011/uni00000013/uni00000013/uni00000018/uni00000011/uni00000015/uni00000018/uni00000018/uni00000011/uni00000018/uni00000013/uni00000018/uni00000011/uni0000001a/uni00000018/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c /uni00000056/uni00000048/uni0000004f/uni00000048/uni00000046/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013 /uni00000016/uni00000018/uni00000013/uni00000013/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001a/uni00000013/uni00000011/uni0000001b/uni0000000b/uni00000045/uni0000000c/uni00000003/uni00000024/uni00000028/uni00000003/uni00000052/uni00000051/uni00000003/uni0000004f/uni00000048/uni00000057/uni00000057/uni00000048/uni00000055
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013 /uni00000016/uni00000018/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000019/uni00000011/uni0000001a/uni00000019/uni00000011/uni0000001b/uni00000019/uni00000011/uni0000001c
/uni00000056/uni00000048/uni0000004f/uni00000048/uni00000046/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni0000000b/uni00000046/uni0000000c/uni00000003/uni00000024/uni00000028/uni00000003/uni00000052/uni00000051/uni00000003/uni00000059/uni00000052/uni0000005a/uni00000048/uni0000004f/uni00000056
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000019/uni00000011/uni00000017/uni00000019/uni00000011/uni00000019/uni00000019/uni00000011/uni0000001b
/uni00000056/uni00000048/uni0000004f/uni00000048/uni00000046/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni0000001b/uni00000013/uni00000011/uni0000001c/uni0000000b/uni00000047/uni0000000c/uni00000003/uni00000035/uni00000027/uni00000033/uni00000003/uni00000052/uni00000051/uni00000003/uni0000002c/uni00000052/uni00000051/uni00000052/uni00000056/uni00000053/uni0000004b/uni00000048/uni00000055/uni00000048
/uni00000045/uni00000048/uni00000056/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
/uni00000013 /uni00000018/uni00000013/uni00000013 /uni00000014/uni00000013/uni00000013/uni00000013 /uni00000014/uni00000018/uni00000013/uni00000013 /uni00000015/uni00000013/uni00000013/uni00000013 /uni00000015/uni00000018/uni00000013/uni00000013 /uni00000016/uni00000013/uni00000013/uni00000013
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000017/uni00000011/uni0000001b/uni00000018/uni00000011/uni00000013
/uni00000056/uni00000048/uni0000004f/uni00000048/uni00000046/uni00000057/uni00000042/uni0000004c/uni00000057/uni00000048/uni00000055
Figure 5: Examples of AUC and loss entropy curves during the training of AE and RDP [ 29] on some datasets. “select_iter”
denotes the iteration selected by EntropyStop.
Algorithm 1: EntropyStop: An automated unsupervised
training stopping algorithm for OD model
Input: Model𝑀with learnable parameters Θ, patience parameter
𝑘, downtrend threshold 𝑅𝑑𝑜𝑤𝑛 , dataset𝐷, iterations T,
evaluation set size 𝑁𝑒𝑣𝑎𝑙
Output: Outlier score list O
1Random sample 𝑁𝑒𝑣𝑎𝑙 instances from 𝐷as evaulation set 𝐷𝑒𝑣𝑎𝑙 ;
2𝐺←0;𝑝𝑎𝑡𝑖𝑒𝑛𝑐𝑒←0;Θ𝑏𝑒𝑠𝑡←Θ;;
3Compute𝐻𝐿on𝐷𝑒𝑣𝑎𝑙. ;
4𝑒0←𝐻𝐿;𝑒𝑚𝑖𝑛←𝑒0; ; /* Model Training */
5for𝑗:=1→𝑇do
6 Random sample a batch of training data 𝐷𝑏;
7 CalculateL𝑡𝑟𝑎𝑖𝑛 on𝐷𝑏;
8 Optimize the parameters Θby minimizingL𝑡𝑟𝑎𝑖𝑛 ;
9 Compute𝐻𝐿on𝐷𝑒𝑣𝑎𝑙 ;
10𝑒𝑗←𝐻𝐿;𝐺←𝐺+|𝑒𝑗−𝑒𝑗−1|;
11 if𝑒𝑗<𝑒𝑚𝑖𝑛and𝑒𝑚𝑖𝑛−𝑒𝑗
𝐺>𝑅𝑑𝑜𝑤𝑛 then
12𝑒𝑚𝑖𝑛←𝑒𝑗;;𝐺←0;𝑝𝑎𝑡𝑖𝑒𝑛𝑐𝑒←0;Θ𝑏𝑒𝑠𝑡←Θ;
13 else
14𝑝𝑎𝑡𝑖𝑒𝑛𝑐𝑒←𝑝𝑎𝑡𝑖𝑒𝑛𝑐𝑒+1;
15 end
16 if𝑝𝑎𝑡𝑖𝑒𝑛𝑐𝑒 =𝑘then
17 break
18 end
19end
20Load the Θ𝑏𝑒𝑠𝑡 to𝑀;
Return:{𝑓𝑀(𝑥),𝑥∈𝐷}
recommend setting 𝑅𝑑𝑜𝑤𝑛 within the range of [0.01,0.1], while the
optimal value of 𝑘and learning rate is associated with the actual
entropy curve. We provide a study on the setting of these HPs in
Appx. D of our comprehensive version of paper.
4.4 Discussion
Evaluation Cost. Our algorithm incurs extra computational over-
head with a time complexity of 𝑂(𝑓𝑀(𝐷𝑒𝑣𝑎𝑙)+|𝐷𝑒𝑣𝑎𝑙|)due to the
additional inference on 𝐷𝑒𝑣𝑎𝑙 for entropy calculation after each
training iteration. However, as we observed in our experiments,
deep UOD models often achieve its optimal AUC performance at an
early stage, allowing training to be halted very soon. Therefore, em-
ploying our early stopping method can significantly reduce training
time compared to arbitrarily setting a lengthy training duration.Pseudo inliers. In dataset analysis, we found the existence of
"Pseudo inliers" - instances labeled as inliers but whose loss values
are significantly larger than the average of outlier losses. The emer-
gence of pseudo inliers can be attributed to multiple factors: (1)
multiple types of outliers exist in the dataset while the labels only
cover one type; (2) As UOD methods make assumptions of outlier
data distribution [ 10], there is a mismatch between the assump-
tions of outlier distribution made by model and the labeled outlier
distribution in the dataset. The effectiveness of our proposed met-
ric,𝐻𝐿, may encounter challenges in such scenarios.The possible
solution for this issue is to utilize a small number of labeled outliers
to identify the alignment of the UOD assumptions and real datasets.
We leave this as our future work.
5 Experiments
In this section, we evaluate the effectiveness of our proposed metric
(𝐻𝐿) and the entropy-based early stopping algorithm ( 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 )
through comprehensive experiments. Our key findings are summa-
rized as follows:
•𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 remarkably improves AE model performance,
surpassing ensemble AE models and significantly reducing
training time. (See Sec. 5.2)
•We observe a strong negative correlation between the 𝐻𝐿
curve and AUC curve across a larger number of real-world
datasets, which verifies our analysis. (see Sec. 5.3)
•Our𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 can be applied to other deep UOD models,
exhibiting their broad potential applicability. (See Sec. 5.4)
5.1 Experiment setting
All experiments adopt a transductive setting, where the training
set equals the test set, which is common in Unsupervised OD [ 7,8].
(1) Dataset: Experiments are carried on 47 widely-used real-world
tabular datasets3collected by [ 10], which cover many application
domains, including healthcare, image processing, finance, etc. De-
tails on dataset description can be found in Appx. C.1.
(2) Evaluation Metrics: We evaluate performance w.r.t. two met-
rics that are based on AUC and Average Precision (AP), which are
calculated by the ranking of outlier score list.
(3) Computing Infrastructures: All experiments are conducted
on Ubuntu 22.02 OS, AMD Ryzen 9 7950X CPU, 64GB memory, and
an RTX 4090 (24GB GPU memory) GPU.
3https://github.com/Minqi824/ADBench/
 
1148EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy KDD ’24, August 25–29, 2024, Barcelona, Spain
5.2 Improvements and Efficiency Study
We first study how much improvement can be achieved by em-
ploying𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 for the AE model. The simplest form of AE
without any additional techniques, is denoted as VanillaAE. We ap-
ply our early stopping method to VanillaAE to gain EntropyAE . We
compare our approach with two ensemble AEs, including the recent
SOTA hyper-ensemble ROBOD [ 8] and the widely-used RandNet
[7]. The experiments of two ensemble models are based on the
open-source code of ROBOD4. The detailed HP configuration of
them can be found in Appx. C.2.
Table 1: Detection performance of models from AE family.
𝑝<0.05means there is a signicant difference between the
baseline and 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝐴𝐸 .
V
anillaAE Entr
opyAE (Ours) RandNet ROBOD
𝐴
𝑈𝐶 0.741±0.001 0.768±0.005 0.728±0.00
0.736±0.00
𝐴𝑃 0.299±0.005 0.364±0.009 0.358±0.00
0.360±0.00
𝑅
𝑎𝑛𝑘𝐴𝑈𝐶 2.70 2.14 2.68
2.42
𝑅
𝑎𝑛𝑘𝐴𝑃 2.85 2.23 2.51
2.36
𝑝𝑎
𝑢𝑐0.006 – 0.013
0.023
𝑝𝑎𝑝0.000 –
0.355 0.402
5.2.1 Detection Performance Result The average result of five
runs is reported in Table 1. We conducted a comparative analy-
sis of four UOD methods across 47 datasets, evaluating average
AUC, average AP, average ranking in AUC, and average ranking
in AP. It is evident that EntropyAE not only significantly outper-
forms VanillaAE but also surpasses ensemble models in AUC and
is marginally superior in AP. P-value from the one-sided paired
Wilcoxon signed-rank test is presented as well, emphasizing the sta-
tistical significance of the improvements achieved by EntropyAE.
It is shown that, compared to VanillaAE, EntropyAE achieves a
substantial enhancement by employing early stopping.
5.2.2 Efficiency Result To quantify the extent to which early
stopping reduces training time, we employ the following metric:
Average Train Time (𝑀)=1
|D|∑︁
𝐷∼Dtraining time(𝑀,𝐷)
training time(𝑉𝑎𝑛𝑖𝑙𝑙𝑎𝐴𝐸,𝐷)
(11)
Total Train Time(𝑀)=Í
𝐷∼Dtraining time(𝑀,𝐷)Í
𝐷∼Dtraining time(𝑉𝑎𝑛𝑖𝑙𝑙𝑎𝐴𝐸,𝐷)(12)
where𝐷represents one of the 47 datasets, Ddenotes the collection
of all 47 datasets, and 𝑀signifies any model among VanillaAE,
EntropyAE, RandNet, and ROBOD. We ensure that all models have
the same batch size of 64 and number of epochs of 250 to guarantee
identical iteration counts. Average Train Time (𝑀)reveals the aver-
age relative training time required compared to VanillaAE while
Total Train Time(𝑀)reveals the total time required compared to
VanillaAE. In Table 2, we observe that, compared to VanillaAE,
ROBOD, and RandNet, EntropyAE only requires under 8%, 2%, and
0.3% of the average training time, respectively. For the total train-
ing time, the advantage of 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝐴𝐸 are more significant. This
demonstrates the effectiveness of early stopping in saving time.
4https://github.com/xyvivian/ROBODTable 2: Comparison of training time for AEs.
VanillaAE EntropyAE RandNet ROBOD
Average Train Time 1 0.077 23.05 3.51
Total Train Time 1 0.01 35.03 4.02
Figure 6 displays the training time required by EntropyAE across
47 datasets. The early stopping mechanism is more effective on
larger datasets, as they contain more batches per epoch, resulting
in more iterations.
102103104105
Dataset Size (Log Scale)0.00.20.40.60.8Relative TimeEntropyAE Time vs. Dataset Size
Figure 6: The relative time (compared to VanillaAE) taken by
EntropyAE across different dataset sizes.
5.3 Negative Correlation Study
In this experiment, our objective is to carefully evaluate the efficacy
of our proposed zero-label metric, loss entropy ( 𝐻𝐿), in accurately
reflecting variations in the label-based AUC. We commence our
analysis by visualizing the AUC and 𝐻𝐿curves for each dataset.
In addition, we utilize the Pearson correlation coefficient to sta-
tistically measure such negative correlation. Specifically, we run
AE model and linear DeepSVDD [ 25]on 47 datasets with a 0.001
learning rate and 500 full batch training iterations.
5.3.1 Result The visualization for the AUC and 𝐻𝐿curves on a
part of 47 datasets are shown in Fig. 7. More visualizations can
be accessed in the Appx. B of paper in URL5.The distribution
of Pearson correlation coefficient values across 47 datasets are
shown in Fig. 8. These results show that while 𝐻𝐿has a strong
negative correlation with AUC on more than half of the 47 datasets,
the remaining datasets show a weak or even positive correlation.
Basically, the reason for invalidity can be attributed to the following
aspects:
•Label misleading: The existence of a large number of pseudo
inliers on these datasets.
•The convergence of AUC: the AUC is nearly stationary
during the whole training process, thereby the entropy could
not reflect the changes of AUC.
In Appx. C of our comprehensive version of paper, we conduct
case-by-case analyses of the invalid reasons of AE on these datasets.
Interestingly, although 𝐻𝐿does not perform well on some datasets,
we view this as an opportunity to highlight the inherent limitations
5https://arxiv.org/abs/2405.12502
 
1149KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
0.560.580.60/uni0000002c/uni00000051/uni00000057/uni00000048/uni00000055/uni00000051/uni00000048/uni00000057/uni00000024/uni00000047/uni00000056/uni0000001d/uni00000003/uni00000055/uni00000003/uni00000020/uni00000003/uni00000010/uni00000013/uni00000011/uni0000001c/uni0000001c
0 100 200 300 400 500
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni000000567.157.207.257.307.35/uni00000024/uni00000038/uni00000026
/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c
0.400.450.500.550.600.65/uni00000052/uni00000053/uni00000057/uni00000047/uni0000004c/uni0000004a/uni0000004c/uni00000057/uni00000056/uni0000001d/uni00000003/uni00000055/uni00000003/uni00000020/uni00000003/uni00000010/uni00000013/uni00000011/uni0000001b/uni00000019
0 100 200 300 400 500
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni000000568.108.158.208.258.308.35/uni00000024/uni00000038/uni00000026
/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c
0.800.850.90/uni0000002c/uni00000052/uni00000051/uni00000052/uni00000056/uni00000053/uni0000004b/uni00000048/uni00000055/uni00000048/uni0000001d/uni00000003/uni00000055/uni00000003/uni00000020/uni00000003/uni00000010/uni00000013/uni00000011/uni00000019/uni0000001c
0 100 200 300 400 500
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni000000565.15.25.35.45.5/uni00000024/uni00000038/uni00000026
/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c
0.8250.8500.8750.9000.925/uni00000056/uni00000050/uni00000057/uni00000053/uni0000001d/uni00000003/uni00000055/uni00000003/uni00000020/uni00000003/uni00000010/uni00000013/uni00000011/uni00000019/uni0000001b
0 100 200 300 400 500
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni000000569.69.810.010.2/uni00000024/uni00000038/uni00000026
/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000003/uni00000028/uni00000051/uni00000057/uni00000055/uni00000052/uni00000053/uni0000005c
Figure 7: AE model: AUC curves vs 𝐻𝐿curves. The red ver-
tical line is the epoch selected by 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 .𝑟denotes the
Pearson correlation coefficient between AUC and 𝐻𝐿.
1
 0 1
Pearson Correlation Coefficient024Dataset CountsAE
1
 0 1
Pearson Correlation Coefficient0.02.55.0DeepSVDD
Figure 8: Analysis of Pearson correlation coefficients between
AUC and𝐻𝐿curves across 47 datasets: lower coefficients in-
dicate stronger negative correlations
of UOD algorithms: The model’s outlier assumption does not align
with the labeled outliers in the dataset, suggesting the need to
explore other UOD models for outlier detection.
5.4 Model Expansion Experiment
In this subsection, we include more deep UOD models for experi-
ments, i.e., AE, DeepSVDD [ 25], RDP [ 29], NTL [ 22] and LOE [ 21].
From another perspective, our early stopping algorithm can also
be regarded as selecting the best model from all models - each at
an arbitrary iteration - during the training process. Therefore, we
can reduce the optimal iteration selection problem to the model se-
lection problem. In this case, we also investigate the improvement
of𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 on some Unsupervised Outlier Model Selection
(UOMS) [17] methods.
UOMS Baselines: UOMS solutions aim at selecting a best pair
{Algorithm, HP } among a pool of options, solely relying on the
outlier scores and the input data (without labels). We compare
𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 with baselines including Xie-Beni index (XB) [ 19],ModelCentrality (MC) [ 13], and HITS [ 17]. In additional, we add
two additional baselines, Random andVanilla, which refer to the
average performance of all iterations and the performance of the
final iteration, respectively. Moreover, Max denotes the maximum
performance among the whole training process (i.e., the upper
bound) is also shown. The detailed experiment setup can be found
at Appx. C.3. The experiments are conducted on 47 datasets and
each item in a table represents the average value over all datasets.
For each dataset 𝐷, the UOMS baselines receive a collection of
outlier score lists among 300 training iterations, S={s𝑖}300
𝑖=0, as
their input. From these, the models produce an output consisting
of a single outlier score list, s𝑖∈R|𝐷|, which represents the outlier
scores from the chosen iteration. This specific score list is then
utilized to calculate the AUC metric for performance evaluation.
5.4.1 Result The AUC and AP results are shown in Table 3 and
Table 4, respectively. The second best score is marked in blue italics.
It is observed that (1) our solution exhibits more effectiveness in
selecting the optimal iteration, especially for AE and DeepSVDD.
It’s important to highlight that our approach is also extendable
to other deep UOD models. (2) In addition, Random baseline and
Vanilla baseline rank second on more than half the rows, which
reveals that none of existing UOMS solutions can help select the
optimal iteration, nor can they fulfill the task of early stopping.
Table 3: AUC for the optimal iteration selection
Max Ours XB MCS HITS Random Vanilla
AE 0.806 0.768 0.720 0.745 0.734 0.742 0.744
RDP [29] 0.798 0.754 0.734 0.737 0.739 0.741 0.735
NeuTraL [22] 0.758 0.701 0.309 0.692 0.658 0.641 0.693
NeuTraL+𝐿𝑂𝐸𝐻[21] 0.748 0.696 0.328 0.679 0.661 0.634 0.693
DeepSVDD [25] 0.747 0.679 0.654 0.652 0.657 0.664 0.637
Table 4: AP for the optimal iteration selection
Max Ours XB MCS HITS Random Vanilla
AE 0.420 0.364 0.287 0.303 0.302 0.309 0.303
RDP 0.412 0.343 0.313 0.351 0.352 0.349 0.350
NeuTraL 0.304 0.251 0.112 0.243 0.240 0.227 0.242
NeuTraL+LOE 0.297 0.234 0.121 0.229 0.226 0.212 0.230
DeepSVDD 0.402 0.331 0.308 0.312 0.312 0.318 0.308
The running time on all datasets are shown in Fig. 9. The training
time of AE is also plotted as Train. It reveals that existing UOMS
solutions are quite inefficient, where MCS is even several orders
of magnitude slower than the training time of AE. Our solution is
much more efficient than UOMS baselines.
6 Conclusion
In this paper, we are dedicated to exploring the issue of training
unsupervised outlier detection models on contaminated datasets.
Different from existing methods, we propose a zero-label evaluation
metric, Loss Entropy, to mirror changes in the model’s detection
 
1150EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy KDD ’24, August 25–29, 2024, Barcelona, Spain
/uni00000014/uni00000013/uni00000015
/uni00000014/uni00000013/uni00000016
/uni00000014/uni00000013/uni00000017
/uni00000014/uni00000013/uni00000018
/uni00000014/uni00000013/uni00000019
/uni00000031/uni00000058/uni00000050/uni00000045/uni00000048/uni00000055/uni00000003/uni00000052/uni00000049/uni00000003/uni00000056/uni00000044/uni00000050/uni00000053/uni0000004f/uni00000048/uni00000056/uni00000003/uni0000004c/uni00000051/uni00000003/uni00000057/uni0000004b/uni00000048/uni00000003/uni00000047/uni00000044/uni00000057/uni00000044/uni00000056/uni00000048/uni00000057/uni00000014/uni00000013/uni00000016
/uni00000014/uni00000013/uni00000015
/uni00000014/uni00000013/uni00000014
/uni00000014/uni00000013/uni00000013/uni00000014/uni00000013/uni00000014/uni00000014/uni00000013/uni00000015/uni00000014/uni00000013/uni00000016/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni00000048/uni00000046/uni00000052/uni00000051/uni00000047/uni00000056/uni0000000c/uni00000032/uni00000058/uni00000055/uni00000056
/uni0000003b/uni00000025
/uni00000030/uni00000026/uni00000036
/uni0000002b/uni0000002c/uni00000037/uni00000036
/uni00000037/uni00000055/uni00000044/uni0000004c/uni00000051
Figure 9: Efficiency of UOMS and our solution.
capability. Based on the metric, an early stopping algorithm (En-
tropyStop) to automatically halt the model’s training is devised.
Meanwhile, theoretical proofs for our proposed metric are provided
in detail. Comprehensive experiments are conducted to validate
the metric and algorithm. The results demonstrate that our method
not only shows effectiveness but also significantly saves training
time. Furthermore, EntropyStop can be integrated with various
deep models, suggesting its potential for extensive application. We
envisage that the proposed metric, loss entropy, could bring new
vitality to the field of anomaly detection.
Acknowledgement
This work is supported by the National Science and Technology
Major Project 2021ZD0114501.
References
[1]Devansh Arpit, Stanisław Jastrzębski, Nicolas Ballas, David Krueger, Emmanuel
Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville,
Yoshua Bengio, et al .2017. A closer look at memorization in deep networks. In
International conference on machine learning. PMLR, 233–242.
[2]Yingbin Bai, Erkun Yang, Bo Han, Yanhua Yang, Jiatong Li, Yinian Mao, Gang
Niu, and Tongliang Liu. 2021. Understanding and Improving Early Stopping
for Learning with Noisy Labels. In Advances in Neural Information Processing
Systems, M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman
Vaughan (Eds.), Vol. 34. Curran Associates, Inc., 24392–24403.
[3]Andrew P Bradley. 1997. The use of the area under the ROC curve in the
evaluation of machine learning algorithms. Pattern recognition 30, 7 (1997),
1145–1159.
[4]Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jörg Sander. 2000.
LOF: identifying density-based local outliers. In Proceedings of the 2000 ACM
SIGMOD international conference on Management of data. 93–104.
[5]Raghavendra Chalapathy and Sanjay Chawla. 2019. Deep learning for anomaly
detection: A survey. arXiv preprint arXiv:1901.03407 (2019).
[6]Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009. Anomaly detection:
A survey. ACM computing surveys (CSUR) 41, 3 (2009), 1–58.
[7]Jinghui Chen, Saket Sathe, Charu Aggarwal, and Deepak Turaga. 2017. Outlier de-
tection with autoencoder ensembles. In Proceedings of the 2017 SIAM international
conference on data mining. SIAM, 90–98.
[8]Xueying Ding, Lingxiao Zhao, and Leman Akoglu. 2022. Hyperparameter sensi-
tivity in deep outlier detection: Analysis and a scalable hyper-ensemble solution.
arXiv preprint arXiv:2206.07647 (2022).
[9]Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. 2020.
Enhancing graph neural network-based fraud detectors against camouflaged
fraudsters. In Proceedings of the 29th ACM International Conference on Information
& Knowledge Management. 315–324.
[10] Songqiao Han, Xiyang Hu, Hailiang Huang, Mingqi Jiang, and Yue Zhao. 2022.
Adbench: Anomaly detection benchmark. arXiv preprint arXiv:2206.09426 (2022).
[11] Douglas M Hawkins. 1980. Identification of outliers. Vol. 11. Springer.
[12] Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. 2020. Gradient descent
with early stopping is provably robust to label noise for overparameterized neural
networks. In International conference on artificial intelligence and statistics. PMLR,
4313–4324.[13] Zinan Lin, Kiran Thekumparampil, Giulia Fanti, and Sewoong Oh. 2020. Infogan-
cr and modelcentrality: Self-supervised model training and selection for disen-
tangling gans. In international conference on machine learning. PMLR, 6127–6139.
[14] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008
eighth ieee international conference on data mining. IEEE, 413–422.
[15] Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang,
Kaize Ding, Canyu Chen, Hao Peng, Kai Shu, et al .2022. BOND: Benchmarking
Unsupervised Outlier Node Detection on Static Attributed Graphs. In Thirty-sixth
Conference on Neural Information Processing Systems Datasets and Benchmarks
Track.
[16] Yezheng Liu, Zhe Li, Chong Zhou, Yuanchun Jiang, Jianshan Sun, Meng Wang,
and Xiangnan He. 2019. Generative adversarial active learning for unsupervised
outlier detection. IEEE Transactions on Knowledge and Data Engineering 32, 8
(2019), 1517–1528.
[17] Martin Q Ma, Yue Zhao, Xiaorong Zhang, and Leman Akoglu. 2023. The need
for unsupervised outlier model selection: A review and evaluation of internal
evaluation strategies. ACM SIGKDD Explorations Newsletter 25, 1 (2023).
[18] N. Morgan and H. Bourlard. 1989. Generalization and Parameter Esti-
mation in Feedforward Nets: Some Experiments. In Advances in Neu-
ral Information Processing Systems, D. Touretzky (Ed.), Vol. 2. Morgan-
Kaufmann. https://proceedings.neurips.cc/paper_files/paper/1989/file/
63923f49e5241343aa7acb6a06a751e7-Paper.pdf
[19] Thanh Trung Nguyen, Uy Quang Nguyen, et al .2016. An evaluation method for
unsupervised anomaly detection algorithms. Journal of Computer Science and
Cybernetics 32, 3 (2016), 259–272.
[20] Guansong Pang, Chunhua Shen, Longbing Cao, and Anton Van Den Hengel. 2021.
Deep learning for anomaly detection: A review. ACM Computing Surveys (CSUR)
54, 2 (2021), 1–38.
[21] Chen Qiu, Aodong Li, Marius Kloft, Maja Rudolph, and Stephan Mandt. 2022.
Latent outlier exposure for anomaly detection with contaminated data. In Inter-
national Conference on Machine Learning. PMLR, 18153–18167.
[22] Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan Mandt, and Maja Rudolph.
2021. Neural transformation learning for deep anomaly detection beyond images.
InInternational Conference on Machine Learning. PMLR, 8703–8714.
[23] Sridhar Ramaswamy, Rajeev Rastogi, and Kyuseok Shim. 2000. Efficient algo-
rithms for mining outliers from large data sets. In Proceedings of the 2000 ACM
SIGMOD international conference on Management of data. 427–438.
[24] Lukas Ruff, Jacob R Kauffmann, Robert A Vandermeulen, Grégoire Montavon,
Wojciech Samek, Marius Kloft, Thomas G Dietterich, and Klaus-Robert Müller.
2021. A unifying review of deep and shallow anomaly detection. Proc. IEEE 109,
5 (2021), 756–795.
[25] Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Shoaib Ahmed
Siddiqui, Alexander Binder, Emmanuel Müller, and Marius Kloft. 2018. Deep
one-class classification. In International conference on machine learning. PMLR,
4393–4402.
[26] Thomas Schlegl, Philipp Seeböck, Sebastian M Waldstein, Ursula Schmidt-Erfurth,
and Georg Langs. 2017. Unsupervised anomaly detection with generative ad-
versarial networks to guide marker discovery. In International conference on
information processing in medical imaging. Springer, 146–157.
[27] Tom Shenkar and Lior Wolf. 2021. Anomaly detection for tabular data with inter-
nal contrastive learning. In International Conference on Learning Representations.
[28] MTCAJ Thomas and A Thomas Joy. 2006. Elements of information theory. Wiley-
Interscience.
[29] Hu Wang, Guansong Pang, Chunhua Shen, and Congbo Ma. 2019. Unsuper-
vised representation learning by predicting random distances. arXiv preprint
arXiv:1912.12186 (2019).
[30] Siqi Wang, Yijie Zeng, Xinwang Liu, En Zhu, Jianping Yin, Chuanfu Xu, and
Marius Kloft. 2019. Effective end-to-end unsupervised outlier detection via inlier
priority of discriminative network. Advances in neural information processing
systems 32 (2019).
[31] Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge,
and Yi Chang. 2020. Robust early-learning: Hindering the memorization of noisy
labels. In International conference on learning representations.
[32] Yan Xia, Xudong Cao, Fang Wen, Gang Hua, and Jian Sun. 2015. Learning
discriminative reconstructions for unsupervised outlier removal. In Proceedings
of the IEEE international conference on computer vision. 1511–1519.
[33] Yan Xia, Xudong Cao, Fang Wen, Gang Hua, and Jian Sun. 2015. Learning
discriminative reconstructions for unsupervised outlier removal. In Proceedings
of the IEEE International Conference on Computer Vision. 1511–1519.
[34] Jinsung Yoon, Kihyuk Sohn, Chun-Liang Li, Sercan O Arik, Chen-Yu Lee, and
Tomas Pfister. 2021. Self-trained one-class classification for unsupervised anomaly
detection. arXiv e-prints (2021), arXiv–2106.
[35] Chong Zhou and Randy C Paffenroth. 2017. Anomaly detection with robust deep
autoencoders. In Proceedings of the 23rd ACM SIGKDD international conference
on knowledge discovery and data mining. 665–674.
[36] Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki
Cho, and Haifeng Chen. 2018. Deep autoencoding gaussian mixture model for
unsupervised anomaly detection. In International conference on learning represen-
tations.
 
1151KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
A Expanded Paper
We publish an expanded version of the paper in https://arxiv.org/
abs/2405.12502, which includes a more comprehensive appendix
containing additional valuable information.
B Theoretical proof
In this section, we aim to provide a theoretical basis for the negative
correlation between loss entropy and AUC. We demonstrate that
when AUC increases, loss entropy is more likely to decrease. The
converse can be proven by analogous reasoning. Therefore, we do
not provide a separate proof for the converse.
B.1 Notations and definitions
We summarize here the notations for the effectiveness proof for
entropy-stop. At any time 𝑡, we denote current training dynamics
as:
•𝑛: the number of samples used to evaluate the model 𝑀’s
detection capability in each iteration, i.e. 𝑁𝑒𝑣𝑎𝑙.
•𝑓𝑀(·): the unsupervised loss function and outlier score func-
tion of model 𝑀.
•X: the distribution of data.
•X𝑖𝑛: the normal data distribution.
•X𝑜𝑢𝑡: the anomalous data distribution.
•O={𝑓𝑀(𝑥)|𝑥∼X} : the loss distribution outputted by 𝑀.
•O𝑖𝑛: the loss distribution from inliers.
•O𝑜𝑢𝑡: the loss distribution from outliers.
•𝑣: the random variable of loss value, i.e., 𝑣∼O.
•𝑣+: the random variable that 𝑣+∼O𝑜𝑢𝑡.
•𝑣−: the random variable that 𝑣−∼O𝑖𝑛.
•V={𝑣1,...,𝑣𝑛}: the set of unsupervised losses calculated
over all samples.∀𝑣𝑖,𝑣𝑖>0.
•V+: the set of unsupervised losses calculated over all abnor-
mal samples.
•V−: the set of unsupervised losses calculated over all normal
samples.
•𝜌(·): the Probability Density Function (PDF) of O
•𝜌(·)+: the Probability Density Function (PDF) of O𝑜𝑢𝑡
•𝜌(·)−: the Probability Density Function (PDF) of O𝑖𝑛
•𝛼: the ratio of outliers in all data samples, 𝛼∈(0,1).
•𝑆=Í𝑛
𝑖=1𝑣𝑖: the sum of all losses in 𝑉.
•𝑢𝑖=𝑣𝑖
𝑆: the normalized loss value.
•𝑈={𝑢𝑖}𝑛
𝑖=0: the set of normalized loss values.
•𝐻𝐿=𝐻(𝑈)=−Í𝑛
𝑖=1𝑢𝑖log𝑢𝑖:Loss entropy.
•N′: Corresponding value of notation Nat time𝑡+1. For
example,𝑣′
𝑖means the𝑖-th loss value in the next iteration.
Then we define ΔN=N′−N.
Then we make following definitions:
(1) AUC: the performance indicator, which is:
1
|V−||V+|∑︁
𝑣−
𝑖∈V−∑︁
𝑣+
𝑗∈V+I(𝑣−
𝑖<𝑣+
𝑗)=𝑃(𝑣−<𝑣+)
(2)loss gap:𝐸(𝑣+)−𝐸(𝑣−)=𝐸(𝑣+−𝑣−), the difference of
average loss value between two classes.
(3)𝛿=𝑣+−𝑣−: the random variable of loss gap.(4)speed gap:𝐸(Δ𝑣+)−𝐸(Δ𝑣−)=𝐸(Δ𝑣+−Δ𝑣−), the difference
of the decreasing speed of averaged loss value between two
classes. Note that Δ𝑣=𝑣′−𝑣.
(5)Δ𝛿=Δ𝑣+−Δ𝑣−: the random variable of speed gap.
B.2 AUC and Entropy
We aim to prove that when AUC increases, 𝐻(𝑉𝑡)also has more
possibility to decrease, which has following mathematical form:
𝑃(𝐻(𝑉𝑡)>𝐻(𝑉𝑡+1)|𝑃(𝛿+Δ𝛿>0)>𝑃(𝛿>0))>0.5
Basically,𝑃(𝛿+Δ𝛿>0)>𝑃(𝛿>0))means that the new AUC
is larger than the original AUC. We divide the proof into 2 steps,
providing them in Section B.2.2 and B.2.3.
B.2.1 Assumptions
Assumption B.1 (inlier priority). 𝐸(𝛿)>0.
First, we assume that the outliers have a larger expectation of av-
eraged loss value, which is the concept of inlier priority mentioned
in Section 4.1.2.
Assumption B.2. Δ𝑆<0.
Second, we assume that the losses continue to be minimized by
the optimizer.
Assumption B.3. 𝑃(𝛿>0)<1.
We also assume AUC <1. Otherwise, there is no room for AUC
to increase anymore.
Assumption B.4. The random variable 𝑣is distributed according
to the probability density function 𝜌(𝑣)=𝛼𝜌+(𝑣)+(1−𝛼)𝜌−(𝑣),𝛼∈
[0,1], in which𝜌+(𝑣)and𝜌−(𝑣)are the PDFs of the distribution of
𝑣+and𝑣−, respectively.
Here,𝛼denotes the outlier ratio of data. Assumption B.4 implies
that the random variable v has a 𝛼probability of being sampled
from𝜌+(𝑣)and a 1-𝛼probability of being sampled from 𝜌−(𝑣).
Assumption B.5.
𝑃(𝛿>0,Δ𝛿>0)=𝑃(𝛿>0)𝑃(Δ𝛿>0)
Since𝛿andΔ𝛿do not strongly correlate, we assume that 𝛿>0
andΔ𝛿>0are unrelated for simplifying our analysis.
Assumption B.6. 𝐴𝑈𝐶≥0.5
We assume that the detector ’s performance is better than ran-
dom guess. In most cases, this assumption can be easily satisfied
due to the effectiveness of UOD algorithms.
Assumption B.7. 𝑢𝑖∈(0,1
𝑒)
Given thatÍ|𝐷|
𝑖=1𝑢𝑖=1,𝑢𝑖>0, and the dataset size |𝐷|usually
satisfies|𝐷|≫𝑒, we assume that 𝑢𝑖<1
𝑒.
Assumption B.8. Δ𝑣𝑖is sufficiently small.
Basically, a small learning rate is set to ensure the convergence
of the learning algorithm, thereby resulting in minimal changes in
loss values.
 
1152EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy KDD ’24, August 25–29, 2024, Barcelona, Spain
Assumption B.9.
𝐸(𝛿)>0,𝑃(𝛿+Δ𝛿>0)>𝑃(𝛿>0)→𝑃(Δ𝛿>0)>0.5
𝐸(𝛿)>0,𝑃(𝛿+Δ𝛿>0)<𝑃(𝛿>0)→𝑃(Δ𝛿>0)<0.5
Here, we assume that if the loss gap exists and the 𝐴𝑈𝐶 increases
(or decreases) after a single gradient update, the decrease in outliers’
losses is more (or less) likely to be smaller than the decrease in
inliers’ losses.
B.2.2 Subproof 1 The first subproof is: if
𝑃(𝛿+Δ𝛿>0)>𝑃(𝛿>0)
then
Δ𝑢𝑖>Δ𝑢𝑗→𝑃(𝑢𝑖>𝑢𝑗)>0.5
Proof. WithΔ𝑆<0andΔ𝑢𝑖>Δ𝑢𝑗, we can deduce Δ𝑣𝑖>Δ𝑣𝑗.
Since both losses 𝑣𝑖and𝑣𝑗can be sampled from either O𝑜𝑢𝑡and
O𝑖𝑛,𝑃(𝑢𝑖>𝑢𝑗|Δ𝑣𝑖>Δ𝑣𝑗)equals to the sum of four conditional
probabilities:
𝑃(𝑢𝑖>𝑢𝑗|Δ𝑣𝑖>Δ𝑣𝑗)=𝑃(𝑣𝑖>𝑣𝑗|Δ𝑣𝑖>Δ𝑣𝑗)
=𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛|Δ𝑣𝑖>Δ𝑣𝑗) (13)
+𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑖𝑛,𝑣𝑗∼O𝑜𝑢𝑡|Δ𝑣𝑖>Δ𝑣𝑗)
+𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑜𝑢𝑡|Δ𝑣𝑖>Δ𝑣𝑗) (14)
+𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑖𝑛,𝑣𝑗∼O𝑖𝑛|Δ𝑣𝑖>Δ𝑣𝑗)
where
𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑜𝑢𝑡|Δ𝑣𝑖>Δ𝑣𝑗)
=𝑃(𝑣𝑖>𝑣𝑗,Δ𝑣𝑖>Δ𝑣𝑗|𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑜𝑢𝑡)𝑃(𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑜𝑢𝑡)
𝑃(Δ𝑣𝑖>Δ𝑣𝑗)
=0.25𝛼2
0.5=0.5𝛼2
and
𝑃(𝑣𝑖>𝑣𝑗,𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛|Δ𝑣𝑖>Δ𝑣𝑗)
=𝑃(𝑣𝑖>𝑣𝑗,Δ𝑣𝑖>Δ𝑣𝑗|𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛)𝑃(𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛)
𝑃(Δ𝑣𝑖>Δ𝑣𝑗)
=(𝑃(Δ𝑣𝑖>Δ𝑣𝑗))−1𝑃(𝑣𝑖>𝑣𝑗|𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛)
𝑃(Δ𝑣𝑖>Δ𝑣𝑗|𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛)𝑃(𝑣𝑖∼O𝑜𝑢𝑡,𝑣𝑗∼O𝑖𝑛)
=𝐴𝑈𝐶·𝑃(Δ𝛿>0)𝛼(1−𝛼)
0.5=2𝛼(1−𝛼)𝐴𝑈𝐶·𝑃(Δ𝛿>0)
Similarly we calculate the other two terms in the equation. Then,
𝑃(𝑢𝑖>𝑢𝑗|Δ𝑣𝑖>Δ𝑣𝑗)
=0.5𝛼2+0.5(1−𝛼)2
+2𝛼(1−𝛼)
𝐴𝑈𝐶·𝑃(Δ𝛿>0)+( 1−𝐴𝑈𝐶)· 1−𝑃(Δ𝛿>0)
With𝐴𝑈𝐶≥0.5,𝑃(Δ𝛿>0)>0.5from Assumption B.6 and B.9,
we can infer 𝑃(𝑢𝑖>𝑢𝑗|Δ𝑣𝑖>Δ𝑣𝑗)>0.5. □
B.2.3 Subproof 2 The second sub-proof is dedicated to demon-
strating that it is more likely for the loss entropy to decrease, i.e.,
𝑃(𝐻𝐿↘)>0.5
From Subproof B.2.2, we have:
Δ𝑢𝑖>Δ𝑢𝑗→𝑃(𝑢𝑖>𝑢𝑗)>0.5 (15)Proof. Loss entropy equals to:
𝐻(𝑈)=−𝑛∑︁
𝑖=1𝑢𝑖log𝑢𝑖
=𝑛∑︁
𝑖=1ℎ(𝑢𝑖)
whereℎ(𝑢𝑖)=−𝑢𝑖𝑙𝑜𝑔(𝑢𝑖). We can derive that
ℎ′(𝑢)=−(𝑙𝑜𝑔(𝑢)+1)
ℎ′′(𝑢)=−1
𝑢
whereℎ′(𝑢)is the first derivative of ℎ(𝑢)andℎ′′(𝑢)is the second
derivative of ℎ(𝑢). This suggests that in the domain 𝑢∈(0,1
𝑒), the
variable𝑢exhibits a monotonic increase, with its impact on ℎ(𝑢)
being inversely proportional to its magnitude; namely,
ℎ′(𝑢)>0,𝑢∈(0,1
𝑒) (16)
𝑢𝑖>𝑢𝑗→ℎ′(𝑢𝑖)<ℎ′(𝑢𝑗) (17)
According to Eq. 15, we can derive that
Δ𝑢𝑖>Δ𝑢𝑗→𝑃(ℎ′(𝑢𝑖)<ℎ′(𝑢𝑗))>0.5 (18)
AsÍ
𝑖𝑢𝑖=Í
𝑖𝑢′
𝑖=1. Therefore,
∑︁
𝑖:Δ𝑢𝑖>0Δ𝑢𝑖=−∑︁
𝑖:Δ𝑢𝑖<0Δ𝑢𝑖 (19)
which means the sum of all positive Δ𝑢𝑖equals the negative of the
sum of all negative Δ𝑢𝑖.
Given that Δ𝑢is sufficiently small (i.e., Assumption B.8), we can
perform a Taylor expansion on 𝐻(𝑈′):
𝐻(𝑈′)=∑︁
𝑖:Δ𝑢𝑖>0ℎ(𝑢𝑖+Δ𝑢𝑖)+∑︁
𝑖:Δ𝑢𝑖<0ℎ(𝑢𝑖+Δ𝑢𝑖) (20)
≈∑︁
𝑖ℎ(𝑢𝑖)+∑︁
𝑖ℎ′(𝑢𝑖)Δ𝑢𝑖 (21)
=𝐻(𝑈)+∑︁
𝑖ℎ′(𝑢𝑖)Δ𝑢𝑖 (22)
Accoring to Eq. 18 and Eq. 19,we can derive:
Δ𝑢𝑖>Δ𝑢𝑗→𝑃(∑︁
𝑖:Δ𝑢𝑖>0ℎ′(𝑢𝑖)Δ𝑢𝑖<−∑︁
𝑖:Δ𝑢𝑖<0ℎ′(𝑢𝑖)Δ𝑢𝑖)>0.5
(23)
→𝑃(∑︁
𝑖ℎ′(𝑢𝑖)Δ𝑢𝑖<0)>0.5 (24)
→𝑃(𝐻(𝑈′)<𝐻(𝑈))>0.5 (25)
→𝑃(𝐻𝐿↘)>0.5 (26)
□
Thus, we prove that if AUC increases, then 𝑃(𝐻𝐿↘)>0.5.
Similarly, the converse of theorem can also be proven by analogous
reasoning. This means during the training, the trend of AUC and
loss entropy have a negative correlation with each other, giving the
theoretical guarantee of the algorithm.
 
1153KDD ’24, August 25–29, 2024, Barcelona, Spain Yihong Huang, Yuang Zhang, Liping Wang, Fan Zhang, & Xuemin Lin
C Experiment Details
C.1 Real-world Outlier Detection Datasets
We construct our experiments using 47 benchmark datasets com-
monly employed in OD research, as shown in Table 5.
Table 5: Real-world dataset pool
Dataset Num Pts Dim % Outlier
1 ALOI 49534 27 3.04
2 annthyroid 7200 6 7.42
3 backdoor 95329 196 2.44
4 breastw 683 9 34.99
5 campaign 41188 62 11.27
6 cardio 1831 21 9.61
7 Cardiotocography 2114 21 22.04
8 celeba 202599 39 2.24
9 census 299285 500 6.20
10 cover 286048 10 0.96
11 donors 619326 10 5.93
12 fault 1941 27 34.67
13 fraud 284807 29 0.17
14 glass 214 7 4.21
15 Hepatitis 80 19 16.25
16 http 567498 3 0.39
17 InternetAds 1966 1555 18.72
18 Ionosphere 351 32 35.90
19 landsat 6435 36 20.71
20 letter 1600 32 6.25
21 Lymphography 148 18 4.05
22 magic 19020 10 35.16
23 mammography 11183 6 2.32
24 mnist 7603 100 9.21
25 musk 3062 166 3.17
26 optdigits 5216 64 2.88
27 PageBlocks 5393 10 9.46
28 pendigits 6870 16 2.27
29 Pima 768 8 34.90
30 satellite 6435 36 31.64
31 satimage-2 5803 36 1.22
32 shuttle 49097 9 7.15
33 skin 245057 3 20.75
34 smtp 95156 3 0.03
35 SpamBase 4207 57 39.91
36 speech 3686 400 1.65
37 Stamps 340 9 9.12
38 thyroid 3772 6 2.47
39 vertebral 240 6 12.50
40 vowels 1456 12 3.43
41 Waveform 3443 21 2.90
42 WBC 223 9 4.48
43 WDBC 367 30 2.72
44 Wilt 4819 5 5.33
45 wine 129 13 7.75
46 WPBC 198 33 23.74
47 yeast 1484 8 34.16C.2 Configuration of Improvement Study
In this segment, we elaborate on the HP configuration settings
utilized for the experiments delineated in Sec. 5.2. For Randnet and
ROBOD, the default HP configurations from ROBOD’s publicly
accessible repository6were adopted, specified as epochs=250, batch
size=1024, and learning rate (lr) of 0.001. The Autoencoder (AE)
architecture defined within the codebase was maintained without
modifications. Concerning ensemble size, Randnet amalgamates
ten models, each initialized with distinct random seeds and sub-
jected to a pre-training phase of 100 epochs, whereas ROBOD ag-
gregates sixteen models, each featuring unique HP configurations.
Our𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 is applied to a simple AE model. The simplest
form of AE, devoid of any supplementary techniques, is denoted
as VanillaAE. VanillaAE’s architecture is designed for simplicity,
with dimensions[𝑑𝑖𝑛,64,𝑑𝑖𝑛], where𝑑𝑖𝑛represents the dimension-
ality of the input vectors. For VanillaAE, we designated epochs=250,
batch size=1024, lr=0.001, and employed Adam as the optimizer. The
𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 technique is integrated for early termination within
VanillaAE’s training process, with the modified model termed as En-
tropyAE. Parameters for 𝐸𝑛𝑡𝑟𝑜𝑝𝑦𝑆𝑡𝑜𝑝 are set to𝑘=100,𝑅𝑑𝑜𝑤𝑛 =0.1,
and𝑁𝑒𝑣𝑎𝑙=1024.
C.3 Configuration of Model Expansion
Experiment
More deep-based OD models are experimented based on their
original open-source code78. Among them, NeuTraL9[22] and
DeepSVDD [ 25] are two OD models that are actually trained on
clean dataset. For these models, we trained them for 300 epochs
using a full batch size approach. Additionally, we adhered to the
default hyperparameter settings as specified in their original code-
bases. For UOMS solutions, Xie-Beni index (XB) [ 19], ModelCen-
trality (MC) [ 13], and HITS [ 17] are the baselines for comparison.
These baselines have been evaluated their effectiveness in selecting
models among a large pool of traditional UOD algorithms in [ 17]
with published open-source code10. We follow [ 17] to use a light-
weight version of MC, called MCS, to reduce its time complexity
and𝑙𝑜𝑔𝑁 models are sampled for computing the Kendall 𝜏coeffi-
cient. For each dataset 𝐷, the input of these baselines is the set of
outlier score listsS(|S|=300) while the output is the outlier score
lists𝑖∈R|𝐷|of the selected epoch. The average result with three
runs is reported.
6https://github.com/xyvivian/ROBOD
7https://github.com/billhhh/RDP
8https://github.com/boschresearch/LatentOE-AD
9https://github.com/boschresearch/NeuTraL-AD
10http://bit.ly/UOMSCODE
 
1154