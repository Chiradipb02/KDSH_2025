Under review as submission to TMLR
Actively Inferring Optimal Measurement Sequences
Anonymous authors
Paper under double-blind review
Abstract
Measurement of a physical quantity such as light intensity is an integral part of many re-
construction and decision scenarios but can be costly in terms of acquisition time, invasion
of or damage to the environment and storage. Data minimisation and compliance with data
protection laws is also an important consideration. Where there are a range of measure-
ments that can be made, some may be more informative and compliant with the overall
measurement objective than others. We develop an active sequential inference algorithm
that uses the low dimensional representational latent space from a variational autoencoder
(VAE) to choose which measurement to make next. Our aim is to recover high dimensional
data by making as few measurements as possible. We adapt the VAE encoder to map par-
tial data measurements on to the latent space of the complete data. The algorithm draws
samples from this latent space and uses the VAE decoder to generate data conditional on
the partial measurements. Estimated measurements are made on the generated data and
fed back through the partial VAE encoder to the latent space where they can be evaluated
prior to making a measurement. Starting from no measurements and a normal prior on
the latent space, we consider alternative strategies for choosing the next measurement and
updating the predictive posterior prior for the next step. The algorithm is illustrated us-
ing the Fashion MNIST dataset and a novel convolutional Hadamard pattern measurement
basis. We see that useful patterns are chosen within 10 steps, leading to the convergence
of the guiding generative images. Compared with using stochastic variational inference to
infer the parameters of the posterior distribution for each generated data point individually,
the partial VAE framework can efficiently process batches of generated data and obtains
superior results with minimal measurements.
1 Introduction and overview
In many circumstances, data collection incurs a cost. This cost may be in terms of acquisition time, invasion
of or damage to the environment and storage. Identifying which, out of a range of data measurements,
to collect next is potentially a valuable cost saving activity. Importantly, it also facilitates fast decision
making (Horvitz & Barry, 1995). Data minimisation is an important consideration for compliance with data
protection laws worldwide1. In defense situations, the requirement for covert human intelligence means that
the act of taking measurements can also pose a security risk.2
Inthiswork, ouroverallaimistoidentifyanoptimalmeasurementsequence. Wedevelopanactivesequential
inference algorithm that uses a low dimensional data representation to infer its high dimensional state
conditional on partial measurement of that state. Reducing dimension allows for more efficient exploration
of the space of state possibilities. The state and types of tasks we are primarily interested in are image/scene
reconstruction and related classification tasks using photon based imaging and sensing technology such as a
single pixel camera (Higham et al., 2018). However, the method is applicable to a broader range of activities.
The overall aim is to customise a generative probabilistic model to provide the agent or user with different
reconstruction scenarios conditional on partial measurements. Given a suitably large dataset of task relevant
1https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/
2https://www.gov.uk/government/publications/covert-human-intelligence-sources-code-of-practice-2022/covert-human-
intelligence-sources-revised-code-of-practice-accessible
1Under review as submission to TMLR
data, an appropriate generative model is the variational autoencoder (VAE) (Kingma & Welling, 2014). A
VAE learns to encode data in the convenient form of a low dimensional multivariate Gaussian and to decode
this representation back to data space. This provides a means to obtain different reconstructions through
manipulation of a low dimensional latent space. This neural network model is trained on relevant data to
learn the underlying distribution of the training data and used to generate new data. A VAE comprises an
encoder (a map from data space to a low dimensional latent representative space) and a decoder (a map
from the low dimensional space back to data space). To achieve this the VAE introduces latent variables
and the objective of a VAE is to understand the true posterior distribution of the latent variables. A VAE
accomplishes this by employing an encoder network to approximate the genuine posterior distribution with
a learned approximation. Once trained, samples from the prior on the latent space can be pushed through
the decoder in order to obtain new generated data. Similarly, samples from the posterior can be pushed
through the decoder in order to obtain data conditional on the input data. Here we adapt the encoder to map
partially measured data to the latent space. This necessitates creating a training set of partially measured
data. Once trained, the partial encoder and the original decoder are used by the algorithm to sequentially
reason about the full state and choose the next measurement. The probabilistic model we are inferring over
is capturing both the (approximate) data-generating process and the noisy measurement model.
The main idea of variational methods is to cast inference as an optimization problem (Blei et al., 2017).
Stochastic variational inference (SVI) (Hoffman et al., 2013) can be used to infer the posterior probability
distribution for specific data and a given set of measurements but requires multiple computation steps and
thus is prohibitively slow when required to estimate many possible measurement sets. We propose a hybrid
approach, in a similar spirit to Kim et al. (2018) but novel in our context, to combine the strengths of VAE
and SVI. We use the partial encoder to choose between patterns and integrate robust SVI when a pattern
has been selected for inferring the posterior distribution parameters based on actual measurements. The
algorithm is developed to actively select the next best measurement. It starts by pushing samples from the
priordistributiononthelatentspacethroughthedecodertoobtaincandidateimages. Possiblemeasurements
on these candidate images are estimated, forming an indexed set. The problem can be thought of as choosing
the next measurement index from a set of possible measurement indexes. The partial encoder or SVI is used
to characterise the posterior distribution and hence provide a score under that distribution for each possible
measurement index for each candidate image. There are different ways to define this score. We consider
two approaches. First, we choose the index with the highest average (over the candidate images) likelihood
score. Second, we choose the index with the least uncertainty score. The aim is to develop a method that is
flexible to the task context and measurement basis.
1.1 Related work
There is a large literature on data driven models for solving inverse problems (Arridge et al., 2019). In partic-
ular, generative variational models have been developed for a range of inverse problems in imaging (Habring
& Holler, 2022). These include inpainting, denoising, deblurring, super resolution and JPEG decompression.
Here, we focus on acquiring data rather than how to utilise data once collected. Quantitative methods for
optimizing data acquisition have been explored in statistics and machine learning literature (Rainforth et al.,
2024). Bayesian experimental design is a powerful model-based framework for choosing designs optimally
using information-theoretic principles. This includes adaptive design Bayesian active learning (MacKay,
1992a), sequential (Foster et al., 2021) and Bayesian optimization (Mockus, 1989; Garnett, 2023). Other
related topics include active feature acquisition (Saar-Tsechansky et al., 2009), active multi-modal acquisition
(Kossen et al., 2023), active perception (Bajcsy et al., 2018), Bayesian active learning (MacKay, 1992b),
active reinforcement learning (Andreopoulos & Tsotsos, 2013) and active vision (Whitehead & Ballard, 1990).
A generative model-based approach to Bayesian inverse problems, such as image reconstruction from noisy
and incomplete images, is developed in Böhm et al. (2019). Their inference framework makes use of a
VAE to provide complex, data-driven priors that comprise all available information about the uncorrupted
data distribution and enables computationally tractable uncertainty quantification in the form of posterior
analysis in latent and data space. Our approach differs in how we extend the VAE to the data. Our focus is
identifying high value data points so we propose a different VAE to provide the prior and facilitate posterior
analysis in latent and data space. Similarly our approach can be adapted to different data systems without
2Under review as submission to TMLR
Figure 1: Active Learning. At step k= 0, for each of Nstarting points, sample zifrom the prior for step
k= 0, push zithrough the decoder to obtain a generated image ˆxiand estimate possible measurements
ˆyifor each pattern not yet measured (e.g. ˆy1,ˆy2and ˆy3illustrated above). Use the partial encoder
to approximate the posterior with probability distributions and estimate probability densities q1(z1|ˆy1),
q2(z1|ˆy2)andq3(z1|ˆy3)(illustrated above). Select the pattern which maximises the chosen expression and
take the measurement associated with this pattern. Update the measurement set and update the predictive
prior for the next step. By repeating these steps, we move towards the target distribution p(z|x).
retraining the core VAE. Our extended VAE can be used repeatedly for the sequence of measurements
whereas the method in Böhm et al. (2019) has as its focus corrupted or missing data and is designed to
tackle recovery of data for a given instance rather than exploring uncertainty in a sequential manner.
A partial variational autoencoder (Partial VAE) is introduced in Ma et al. (2019b) to predict problem specific
missing data entries given a subset of of the observed ones. The model is combined with an acquisition
function that maximises expected information gain on a set of target variables. The VAE based framework
is extended to a Bayesian treatment of the weights in Ma et al. (2019a). Our work overlaps in that we
develop a VAE and use it to identify high value data points. However it differs in that we are concerned
with measurements of data taken with respect to a basis. We adapt our encoder to the measurement basis
rather than the problem and hence extend the active learning application to image reconstruction using
sensing technology. The workshop paper by Saar-Tsechansky et al. (2009) is also relevant to our work and
extends the work (Ma et al., 2019b) by adding transformer components to the partial VAE architecture.
One advantage of our partial encoder, over these works, is that given a full VAE on a domain, the partial
encoder can be trained on different measurement basis.
In Section 2 we describe our method for posterior inference given measurements. The active sequential
measurement algorithm is outlined in Section 3. An overview of the algorithm is provided in Figure 1.
3Under review as submission to TMLR
Figure 2: Graphical representation of the VAE model. An image xis generated by a random variable z
parameterized by a deep neural network with parameters θ, a). A variational distribution parameterized by
a deep neural network with parameters ϕis introduced to infer zgiven x, b). The encoder and decoder are
trained together using Nimages. To train the partial encoder we simulate N×Emeasurements y[b]where
bis a subset of patterns, c). The partial encoder parameterized by ϕpis trained with the original decoder,
d). The SVI method involves inferring the mean µand variance Σfor each image individually, e).
2 Method for posterior inference given measurements
We describe the underlying VAE, Section 2.1, the extension of this framework to sensor measurements,
Section 2.2, and the SVI method, Section 2.3. We then introduce the partial encoder, Section 2.4, and
training of the partial encoder, Section 2.5.
2.1 Underlying VAE model
We assume that an image, x, is generated by a latent random variable, z, in a complex non-linear manner,
parameterized by a deep neural network decoder, Dθ, with parameters θ. The structure of this model is
represented graphically in column (a) of Figure 2. To do inference in this model we introduce a variational
distribution to approximate the posterior distribution of zgiven x. Through training the VAE learns a
functionthatmapseach xtotheparametersofposteriordensities. Typicallythismappingencodesthemean,
µ, and variance, Σ, of a Gaussian distribution, N(µ,Σ), in latent space. This function is also parameterized
by a deep neural network with parameters ϕ(encoder network Eϕ) and the variational distribution, qϕ(z|x),
is represented graphically in column (b) of Figure 2. The goal of training is to find optimal values for θand
ϕso that the model, pθ(x|z), is a good fit to the data (log evidence is large) and the variational distribution
is a good approximation to the posterior, p(z|x).
Having learnt θandϕwe can generate images by sampling zfrom the latent space according to the prior
p(z)and pushing zthrough the decoder map, Dθ(z) :z→x. We can also generate images, ˆx, conditioned
on test x, in three steps. First by using the encoder map, Eϕ(x) :x→µ,Σ, to characterise the posterior,
qϕ(z|x;µ,Σ). Second, by drawing samples from this distribution. And third, by using the decoder map as
before,Dθ(z|x) :z|x→ˆx. The full VAE is trained by maximising an evidence lower bound (ELBO) which
is equivalent to minimizing the KL divergence between p(z|x)andqϕ(z|x)(Kingma & Welling, 2014), given
by
DKL(qϕ(z|x)∥p(z|x)) =Ez∼qϕ(z|x)[logqϕ(z|x)−logp(z|x)]
≤Ez∼qϕ(z|x)[logqϕ(z|x)−logpθ(x|z)−logp(z)]≡L. (1)
2.2 Extension of VAE framework to sensor measurements
We now consider the situation where we wish to determine a new xby taking optimal sequential measure-
ments on xwith respect to a measurement basis with Nindexes. At sequential step kthe measurement
4Under review as submission to TMLR
basis indexes chosen so far are denoted Bk={b1,b2,...,bk}. We obtain y[Bk]by taking a measurement
using these basis indices; for convenience we write
y[Bk]=f(x,Bk). (2)
We model these measurements using isotropic Gaussians with variance σ2.
2.3 SVI method
Marginalising xand applying Bayes’ rule, we have
p(z|y) =p(z)p(y|z)
p(y). (3)
The log of the posterior distribution of the latent variables for a given partial observation y[Bk]is therefore
logp(z|y[Bk]) = logp(z) + logp(y[Bk]|z)−logp(y[Bk]). (4)
This equation, as Equation (2), is intractable motivating the use of SVI. The aim of SVI is to approximate
the posterior with a multivariate Gaussian and infer the mean µkand variance Σkof this distribution. As
the posterior, qk=q(z|y[Bk];µk,Σk), evolves with the number and index of basis measurements, the mean
and variance are indexed by k. SVI is an iterative method. The variational parameters for each data input
are randomly initialized and then optimized to minimise the KL divergence
DKL(qk(z|y[Bk])∥p(z|y[Bk])) =Ez∼qk(z|y[Bk])[logqk(z|y[Bk])−logp(z|y[Bk])]
≤Ez∼qk(z|y[Bk])[logqk(z|y[Bk])−logp(y[Bk]|z)−logp(z)]≡Lk.(5)
2.4 Partial encoder
The aim of the partial encoder is to encode incomplete measurements y[Bk]as defined in Equation (2). We
introduce a partial variational distribution, qϕp, to approximate the posterior distribution and train a partial
encoder,Eϕp, to inferµkandΣkfor specific y[Bk], see Figure 1d). The partial encoder VAE is trained
by minimizing the KL divergence between p(z|x), established by the full VAE, and the partial posterior
distribution, qϕp(z|y[Bk];µk,Σk), parameterised also by a neural network with parameters ϕp.
DKL(qϕp(z|y[Bk])∥p(z|x)) =Ez∼qϕp(z|y[Bk])[logqϕp(z|y[Bk])−logp(z|x)]
≤Ez∼qϕp(z|y[Bk])[logqϕp(z|y[Bk])−logp(x|z)−logp(z)]≡Lpartial.(6)
As with the full VAE, once we have learnt ϕpwe can generate images from a set of measurements by sampling
from the approximate posterior distribution qϕp(z|y[b])and then pushing these samples through the decoder,
Dθ(z|y[Bk]) :z|y[Bk]→ˆxto generate the reconstructed image ˆx.
In summary, we have two approaches to approximate the posterior p(z|y[Bk]). First using a partial encoder,
qϕp(z|y[Bk]), and second using SVI, qk(z|y[Bk]). We compare these approaches in Section 4.2.
2.5 Training the partial encoder
To train the partial encoder we assume that our measurement sensor can provide a series of J=Bk
observations,{y1,y2,...,yJ}, each associated with an action (experiment or basis measurement resulting in
5Under review as submission to TMLR
an observation) for an image x, see Equation (2). We now simulate training data by randomly sampling N
experiments for every image x, simulating observations y[J]for each of them. This is repeated Etimes for
eachxgivingN×Eexperiments in total where the measurement vector, y[J], varies in terms of both the
number of measurements and the measurement index. This is achieved in an efficient manner by introducing
a mask layer into the encoder network that randomly masks a different number and index of measurements
with each training batch. Using this training set we learn a variational autoencoder which generates the
required mapping, Eϕp(y[J],j) :→µJ,ΣJ.
3 Method for active sequential algorithm
3.1 The Active Sequential Measurement Inference Algorithm
We now present our sequential algorithm to actively choose the next best measurement. Our proposed
active inference algorithm is illustrated in Figure 1 and pseudocode provided in Algorithm 1. The aim of the
algorithm is to identify, under some criteria (details in Section 3.2), the next best measurement to take. The
algorithm is designed to leverage the encoding and decoding properties of the VAE. The encoder provides a
means to map incomplete measurements onto a low dimensional space for exploration. The decoder provides
a means to project back to image space to assess future measurements.
At the first step, k= 0,Nsamples are drawn from the prior on the latent space, p0=N(0,1). These
samples, zi, are pushed through the decoder, Dθ(zi) :zi→ˆxi, to obtainNgenerated images, ˆxi. Simulated
measurements, ˆyi=f(ˆxi,j), are made under the chosen measurement basis for each basis element indexed
j. The simulated measurements are pushed through the encoder, Eϕp:ˆyi→:µj,Σj, and the output used to
characterise the conditional posterior, qj
i. The algorithm evaluates each measurement indicator and chooses
the measurement indicator which best satisfies the decision criteria. This indicator is added to the indicator
set,Bk+1. Actual measurements are taken on the test image, y[Bk+1]=f(x,Bk+1). SVI is used to infer the
posterior and predictive prior for the next step, pk+1=qk+1. The algorithm continues for K−1steps.
At stepk+ 1,Nsamples, z={z1,...zN}, are drawn from the predictive prior, pk=N(µBk,ΣBk), where
µBkandΣBkare the mean and variance predicted by the partial encoder conditional on the measurements,
y[Bk], made so far
encϕp(y[Bk]) :y[Bk]→µBk,ΣBk. (7)
These samples are then mapped by the decoder to generate images
decθ(z) :z→ˆx={ˆx1...ˆxN}. (8)
For each remaining pattern indicator, j∈B\Bk, we create a set of pattern indicators J={b1,...bk,bj}
and simulate measurements made on each generated image, {ˆy[J]
1,..., ˆy[J]
N}. We now use the partial encoder
to approximate the posterior distribution conditional on these simulated measurements for each generated
image denoted qJ
i=N(µJ
i,ΣJ
i).
3.2 Criteria for choosing next measurement
We consider three criteria for choosing the next pattern to measure. A good choice of measurement is one
that provides useful information to the agent.
3.2.1 Likelihood (QP)
Here, the criterion for choosing the next pattern, bk+1, corresponds to choosing the pattern, bj, with the
highest log likelihood with respect to qJ
iover allNimages;
bk+1= arg max
jN/summationdisplay
i=1log(qJ
i(zi))−log(pk(zi)). (9)
6Under review as submission to TMLR
By using the likelihood we establish which measurements provide information that is consistent with the
predictive prior for that step. We investigate the ability of the algorithm to move towards the target
distribution.
3.2.2 Mutual Information (MI)
An alternative criterion based on the concept of conditional mutual information Bishop (2006) is to choose
the measurement which most reduces the posterior entropy or uncertainty. The mutual information, MI,
between ziandˆy[J]
iis defined in terms of entropy Heas
MI(zi;ˆy[J]
i) =He(zi)−He(z|ˆy[J]
i). (10)
The entropy of random variable xfrom a multivariate Gaussian of dimension Dand variance Σis
He(x) =D
2(1 + log (2π)) +1
2log|Σ|. (11)
Our criteria for choosing the next pattern is then
bk+1= arg max
jN/summationdisplay
i=11
2(log|ΣJ
i|−log|ΣBk|). (12)
3.2.3 Inference-free Hadamard optimisation (HO)
Some measurement bases, for example the Hadamard transform (Ahmed & Rao, 1975), permit patterns to be
prioritised according to the absolute value of the measurement instead of involving inference. High absolute
values (of the eigenvalues associated with each basis eigenvector) contribute more to the reconstructed image
which motivates the choice
bk+1= arg max
jN/summationdisplay
i=1|{ˆy[J]
i}|. (13)
4 Experimental Results
We illustrate the algorithm on Fashion MNIST (Xiao et al., 2017). The basic VAE is trained using the
60,000 training images from Fashion MNIST Xiao et al. (2017). The encoder/decoder architectures and
training details are provided in Appendix A. The partial encoder is trained on simulated measurements from
a novel 4×4 convolutional Hadamard measurement basis, details given in Section 4.1. The partial encoder
architecture is adapted and fitted with a random measurement layer so that experiments involving different
numbers and types of patterns can be efficiently simulated, in terms of computation and memory, during
training.
4.1 Convolutional Hadamard basis
In the context of single pixel imaging, the measurements, y, are made by projecting a series of spatial
patterns on to a scene and capturing the reflected light with a single pixel detector sensor Higham et al.
(2018). Mathematically, the measurement is the inner product between the patterns and the scene and
defines function ffrom equation (2). Expressing an image in vector form, x, and the pattern basis in matrix
form, H, where H∈RD×D, we have y=Hx. Of particular interest is the Hadamard basis, an orthogonal
binary−1,1basis (Ahmed & Rao, 1975). A Hadamard basis is suitable for experimental realization due to
the binary nature of patterns that can be projected using DMD (Digital Micromirror Device) technology as
spatial light modulator (Edgar et al., 2019). We take Hto be this basis though we emphasise our method
is not specific to the Hadamard basis and the approach could be generalised to another appropriate basis.
For an image with 2n×2npixels where nis a positive integer, the complete Hadamard basis, required for
perfect image reconstruction, comprises N= 22npatterns.
7Under review as submission to TMLR
Algorithm 1 Active Sequential Inference
B0←∅ ▷pattern index set
fork= 0...K−1do ▷for each step
fori= 1...N do ▷for each generated image
ifk= 0then
p0=N(0,1) ▷set prior for step 0
else ifk>0then
pk←qk▷set predictive posterior prior for step k
end if
zi∼pk ▷sample latent vector from current pdf
ˆxi←decθ(zi) ▷A.input to decoder to obtain generated image ˆxi
foreach element j∈B\Bkdo ▷for each remaining pattern
J←{b1,...,bk,j} ▷add pattern index jto measurement set J
ˆyi←f(ˆxi,J) ▷B.estimate possible measurements
qj
i←encϕp(ˆyi) ▷C.use partial encoder to approximate pdf qj
end for
end for
Mij←log(qj
i(zi))−log(pk(zi)) ▷D.store results in matrix M
{bk+1}←{ arg maxj/summationtext
iMij} ▷E.find pattern index which maximises expression
Bk+1←Bk∪{bk+1} ▷add pattern index to pattern index set
y[Bk+1]←f(x,Bk+1) ▷take actual measurement on x
qk+1←SVI(y[Bk+1]) ▷F.set predictive posterior prior for next step
end for
In this work we develop a novel convolutional Hadamard basis inspired by convolutional layers. The convo-
lutional approach provides local spatial and resolution rather than global frequency information.
A Hadamard basis matrix with 24rows and columns is rearranged as a 4×4×16tensor which replaces the
filter of a standard convolutional mapping layer, fconv. The Hadamard basis has the property of being its
own inverse so the tensor can be used with transpose convolutional mapping layer, ftpconv, to recover the
input image from the feature image, fconv:x→yandftconv :y→x.
An advantage of this convolutional Hadamard basis is that the resulting feature f∈RN/4×N/4×16has both
spatial (vertical and horizontal) and frequency or resolution dimension associated to each element fjwhere
j= 1...N2. We exploit this in our illustration to give further insights into the decision making process.
4.2 Comparison of pVAE and SVI
At each step of the algorithm, estimating the parameters of the approximate posterior, qJ, requires one
pass through the partial encoder but several iterations with the SVI method. We compare the performance
of pVAE (1 iteration) with SVI and a variable number of iterations {10,20,30,40,50,60,70}in terms of
reconstruction indexes: mean square error (MSE) and similarity structure (SSIM) Wang et al. (2004).
The performance scores are averaged over 100 samples from ten images (each from a different class) and
the algorithm is run for 100 steps, see Figure 3. The SVI method improves as the number of iterations
increases but only matches the pVAE method after 60 iterations. This makes the SVI method an order of
magnitude slower than pVAE. For our final algorithm, we therefore use pVAE to approximate qJ
ibased on
simulatedmeasurements(CinAlgorithm1)andSVIwith100iterationstoapproximate qk+1basedonactual
measurements (F in Algorithm 1). This way we achieve a balance between performance and computation
time.
4.3 Comparison of choice criteria
The different criteria for choosing the next pattern ( QP,MIandHO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, and Ns={1,10,100,200}latent vector
8Under review as submission to TMLR
Figure 3: Comparison of pVAE and SVI. The performance scores (mse left column and ssim right column )
are averaged over 100 samples from ten images (each from a different class) and the algorithm is run for
100 steps. Here lower is better for mse leftand higher is better for ssim right. The performance of pVAE
(1 iteration) bold line with SVI and a variable number of iterations {10,20,30,40,50,60,70}mixed light
lines.The SVI method improves as the number of iterations increases. At 100 steps the results for pVAE
lie between the results for SVI with 60 (SVI60) and 70 (SVI70) iterations. In terms of timings, the pVAE
takes 9×10−4seconds per step and the SVI method takes 7.2×10−3seconds per iteration. With many
iterations required for SVI, this makes the SVI method at least an order of magnitude slower than pVAE.
Time measurements were taken using a NVIDIA GE Force RTX 3090 GPU.
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
Our method ( QP) outperforms Hadamard optimisation ( HO) for the first 25 steps with 1, 10, 100 and
200 starting images in terms of MSE and SSIM. The methods QPandHOdiffer in both the criteria for
choosing the next pattern and reconstruction whereas the methods QPandMIdiffer only in the criteria for
choosing the next pattern. After these first steps, the performance of both methods plateaus with a slightly
superior performance from the Hadamard reconstruction. Comparing QPwithMI,QPshows superior
performance across all the experiments. Investigation of the patterns chosen suggest that using MIearly
in the process leads to the algorithm getting stuck in the latent space. This method relies on choosing the
next pattern to reduce uncertainty across several generated images whereas QPchooses the next pattern
to increase likelihood. The MIstrategy promotes larger initial steps in the latent space and consequently
a tendency to get stuck and miss patterns that are useful for reconstruction. The QPstrategy encourages
smaller steps in the latent space and moves more steadily to a convergence of generated images. The QP
method is therefore the one that we recommend.
4.4 Visualisation of the active learning algorithm using UMAP
We now illustrate the active learning algorithm by exploring low dimensional image space using a two
dimensional representation of the latent space of 10,000 test images from Fashion MNIST created with
9Under review as submission to TMLR
Figure 4: Comparison of choice criteria in terms of the structural similarity index (SSIM). The different
criteria for choosing the next pattern ( QP,MIandHO), equations (9), (12) and (13) respectively, were
evaluated (mean SSIM) using 10 test images, one from each class, and 1 ( top left), 10 (top right ), 100
(bottom left ), 200 (bottom right ) latent vector samples over 100 steps. Our method ( QP) outperforms
Hadamard optimisation ( HO) for the first 25 steps and both show superior performance to MIacross all
the experiments. In terms of timings, HOtook 0.7778 seconds, QPtook 1.3583 seconds and MItook 1.4219
seconds to complete 50 steps. Time measurements were taken using a NVIDIA GE Force RTX 3090 GPU.
UMAP Meehan et al. (2022). UMAP is applied to the mean of the latent representations. The classes are
colour coded and the UMAP clusters within class and between similar classes (i.e. ankle boot, sneaker and
shoe) indicate that class structure has been retained by the latent representation and further dimension
reduction, see Figure 5.
A number, N, of latent variables are drawn from the prior. These are shown as black crosses projected on
to the two dimensional space along with the projected class colour coded test images. These variables are
then passed to the generator, pθ(xi|zi), to produce the generated images shown on the right. Also shown is
the image reconstruction from actual measurements made so far ( top right box ), none at step 0, 10 at step
10 and 30 at step 30, and the target image ( bottom left box ).
At steps 1 to K, the generated images from the previous step are used to estimate possible measurements
corresponding to the set of pattern indexes not yet taken. These possible measurements are individually
added to the actual measurements and passed to the encoder to obtain the posterior probability distribution.
The measurement index, j, which is considered most informative satisfies the following expression:
arg max
j/summationdisplay
ilog(qij(zi)−log(pk(zi)). (14)
At stepkour certainty, quantified by a probability distribution about our location in latent space, having
takenk−1measurements, is denoted by pk−1(zi). If we were to take another measurement, our certainty
becomesqkij(zi). In the interest of increasing our certainty we choose the value which maximises the above
expression. This simple procedure allows us to move through latent space converging on a reconstruction
close to the target.
10Under review as submission to TMLR
Figure5: UMAPisusedtoreducethemeanofthelatentrepresentationsof10,000testimagesto2dimensions
(left hand column ). The classes are colour coded and the UMAP clusters within class and between similar
classes (i.e. ankle boot, sneaker and shoe) indicate that the class structure has been retained by the latent
representation and further dimension reduction. The mean of 100 samples is similarly projected (black
crosses) on to the map at each step of the algorithm. The measurements made, the samples projected back
into image space and the image to be recovered are shown in the top left corner, centre and bottom right
corner of the ( right hand column ) respectively. We see the diversity of possible images in the right hand
column, and this decreases as uncertainty is reduced by more measurements.11Under review as submission to TMLR
5 Discussion and Conclusion
We have shown that given a large dataset and a measurement basis the encoder of a VAE, trained on this
large dataset, can be adapted to map partial measurements on to a representative latent space. An sequential
measurement algorithm is developed to explore this latent space in order to optimise the next best measure-
ment. The algorithm is illustrated using the Fashion MNIST dataset and a novel convolutional Hadamard
measurement basis. We see that useful patterns are chosen within 10 steps leading to the convergence of the
guiding generative images. In situations where there is a cost attached to measurement, the ability to reduce
the number of measurements is a significant benefit. We believe that this algorithm is the first to address the
task of active sequential inference in this context, and we note that it has the potential to increase efficiency
dramatically in many high profile applications.
References
Nasir Ahmed and Kamisetty Ramamohan Rao. Walsh-Hadamard Transform , pp. 99–152. Springer Berlin
Heidelberg, Berlin, Heidelberg, 1975. ISBN 978-3-642-45450-9. doi: 10.1007/978-3-642-45450-9_6. URL
https://doi.org/10.1007/978-3-642-45450-9_6 .
Alexander Andreopoulos and John K. Tsotsos. A computational learning theory of active object recognition
under uncertainty. Int. J. Comput. Vision , 101(1):95–142, January 2013. ISSN 0920-5691. doi: 10.1007/
s11263-012-0551-6. URL https://doi.org/10.1007/s11263-012-0551-6 .
Simon Arridge, Peter Maass, Ozan Öktem, and Carola-Bibiane Schönlieb. Solving inverse problems using
data-driven models. Acta Numerica , 28:1–174, 2019. doi: 10.1017/S0962492919000059.
R. Bajcsy, Y. Aloimonos, and J.K. Tsotsos. Revisiting active perception. Autonomous Robots , 42:177–196,
2018.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statistics) .
Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
David M. Blei, Alp Kucukelbir, and Jon D. McAuliffe. Variational inference: A review for statisticians.
Journal of the American Statistical Association , 112(518):859–877, April 2017. ISSN 1537-274X. doi:
10.1080/01621459.2017.1285773. URL http://dx.doi.org/10.1080/01621459.2017.1285773 .
Vanessa Böhm, François Lanusse, and Uroš Seljak. Uncertainty Quantification with Generative Models. In
33rd Annual Conference on Neural Information Processing Systems , 10 2019.
M.P. Edgar, G.M. Gibson, and M.J. Padgett. Principles and prospects for single-pixel imaging. Nature
Photon, 13:13–20, 2019.
Adam Foster, Desi R Ivanova, Ilyas Malik, and Tom Rainforth. Deep adaptive design: Amortizing sequential
bayesian experimental design. In Marina Meila and Tong Zhang (eds.), Proceedings of the 38th Interna-
tional Conference on Machine Learning , volume 139 of Proceedings of Machine Learning Research , pp.
3384–3395. PMLR, 18–24 Jul 2021. URL https://proceedings.mlr.press/v139/foster21a.html .
Roman Garnett. Bayesian Optimization . Cambridge University Press, 2023.
Andreas Habring and Martin Holler. A generative variational model for inverse problems in imaging. SIAM
Journal on Mathematics of Data Science , 4(1):306–335, 2022. doi: 10.1137/21M1414978. URL https:
//doi.org/10.1137/21M1414978 .
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mo-
hamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational
framework. In International Conference on Learning Representations , 2017.
C.F. Higham, R. Murray-Smith, M.J. M.J. Padgett, and M.P. Edgar. Deep learning for real-time single-pixel
video.Sci Rep, 8:2018, 2018.
12Under review as submission to TMLR
Matthew D. Hoffman, David M. Blei, Chong Wang, and John Paisley. Stochastic variational inference.
Journal of Machine Learning Research , 14(40):1303–1347, 2013.
Eric Horvitz and Matthew Barry. Display of information for time-critical decision making. In Proceedings
of the Eleventh Conference on Uncertainty in Artificial Intelligence , UAI’95, pp. 296–305, San Francisco,
CA, USA, 1995. Morgan Kaufmann Publishers Inc. ISBN 1558603859.
Yoon Kim, Sam Wiseman, Andrew Miller, David Sontag, and Alexander Rush. Semi-amortized variational
autoencoders. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference
on Machine Learning , volume 80 of Proceedings of Machine Learning Research , pp. 2678–2687. PMLR,
10–15 Jul 2018.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference
on Learning Representations (ICLR) , San Diega, CA, USA, 2015.
Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. In Yoshua Bengio and Yann LeCun
(eds.),2nd International Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April
14-16, 2014, Conference Track Proceedings , 2014.
Jannik Kossen, Cătălina Cangea, Eszter Vértes, Andrew Jaegle, Viorica Patraucean, Ira Ktena, Ne-
nad Tomasev, and Danielle Belgrave. Active acquisition for multimodal temporal data: A challeng-
ing decision-making task. Transactions on Machine Learning Research , 2023. ISSN 2835-8856. URL
https://openreview.net/forum?id=Gbu1bHQhEL .
Chao Ma, Wenbo Gong, Sebastian Tschiatschek, Sebastian Nowozin, José Miguel Hernández-Lobato, and
Cheng Zhang. Bayesian EDDI: Sequential variable selection with Bayesian partial VAE. Workshop on
Real-World Sequential Decision Making: Reinforcement Learning and Beyond at NeurIPS , 2019a.
Chao Ma, Sebastian Tschiatschek, Konstantina Palla, Jose Miguel Hernandez-Lobato, Sebastian Nowozin,
and Cheng Zhang. EDDI: Efficient dynamic discovery of high-value information with partial VAE. In
Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference
on Machine Learning , volume 97 of Proceedings of Machine Learning Research , pp. 4234–4243. PMLR,
09–15 Jun 2019b.
David J. C.MacKay. Information-BasedObjective Functions for Active DataSelection. Neural Computation ,
4(4):590–604, 07 1992a. ISSN 0899-7667. doi: 10.1162/neco.1992.4.4.590. URL https://doi.org/10.
1162/neco.1992.4.4.590 .
David J. C. MacKay. Information-based objective functions for active data selection. Neural Computation ,
4(4):590–604, 1992b. doi: 10.1162/neco.1992.4.4.590.
Connor Meehan, Jonathan Ebrahimian, Wayne Moore, and Stephen Meehan. Uniform manifold approx-
imation and projection (UMAP). https://www.mathworks.com/matlabcentral/fileexchange/71902 ,
2022.
Jonas Mockus. Bayesian Approach to Global Optimization . Springer Dordrecht: Kluwer Academic, 1989.
Tom Rainforth, Adam Foster, Desi R. Ivanova, and Freddie Bickford Smith. Modern Bayesian Experimental
Design.Statistical Science , 39(1):100 – 114, 2024. doi: 10.1214/23-STS915. URL https://doi.org/10.
1214/23-STS915 .
Maytal Saar-Tsechansky, Prem Melville, and Foster Provost. Active feature-value acquisition. Manage. Sci. ,
55(4):664–684, April 2009. ISSN 0025-1909. doi: 10.1287/mnsc.1080.0952. URL https://doi.org/10.
1287/mnsc.1080.0952 .
Zhou Wang, A.C. Bovik, H.R. Sheikh, and E.P. Simoncelli. Image quality assessment: from error visibility
to structural similarity. IEEE Transactions on Image Processing , 13(4):600–612, 2004.
Steven D. Whitehead and Dana H. Ballard. Active perception and reinforcement learning. Neural Compu-
tation, 2(4):409–419, 1990.
13Under review as submission to TMLR
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017. URL http://arxiv.org/abs/1708.07747 .
14Under review as submission to TMLR
A VAE architecture and training
The encoder comprised an image input layer, two encoding blocks and a fully connected layer. Each encoding
block contained a convolutional layer, a batchnorm layer and a ReLU activation layer. The input image
(28×28) was downsized to ( 14×14×32) and ( 7×7×64) by the encoding blocks respectively. The output
of the fully connected layer, [µ,log Σ], is twice the size of the latent space ( 32×1).
The partial encoder was formed by replacing the first encoding block with a convolutional layer, modified
to use the convolutional Hadamard basis as fixed weights, resulting in a feature ( 7×7×64). This block
was followed by a random mask layer that randomly selects a number of patterns and pattern indexes. The
subsequent encoding block was adjusted to downsize to ( 4×4×64).
The decoder comprised an latent sample input layer ( 16×1), a project and reshape layer ( 7×7×64) and three
decoding blocks. The decoding blocks each contained a transposed convolutional layer and an activation
layer RELU for the first two blocks and sigmoid for the last block). The input feature was up sampled to
(14×14×64), (28×28×32) and ( 28×28×1) by the decoding blocks respectively.
The encoder and decoder were trained together using a custom training loop and 60,000 fashion MNIST
images Xiao et al. (2017) in mini-batches of 128 for 100 epochs. The parameters were updated using the
adaptive moment estimation (ADAM) algorithm (Kingma & Ba, 2015) with settings: learning rate = 0.001,
gradient decay = 0.9, squared gradient decay = 0.999 and epsilon = 1e-8) chosen using validation set
performance.
The partial encoder was trained using the previously trained decoder with fixed settings for 200 epochs. The
random mask layer was reset for each mini-batch iteration simulating 200×450different experiments.
We modify the KL divergence term in the loss functions to include an additional scaling factor, β, in front
of the KL divergence term. This βVAEapproach was introduced in Higgins et al. (2017) to encourage a
more flexible latent space representation, while still ensuring that the learned distribution is close to the
prior distribution. The value of βis set to 0.1 for the VAE and the partial VAE.
B More results
The different criteria for choosing the next pattern ( QP,MIandHO), equations (9), (12) and (13) respec-
tively, were evaluated using 10 test images, one from each class, and Ns={1,10,100,200}latent vector
samples over 100 steps. Performance measures, SSIM and MSE, were evaluated at each step and averaged
over the test images, see Figure 4 and, in Appendix B, Figure 6.
C Interpreting results
The patterns belonging to the convolutional Hadamard basis have two spatial and one resolution component.
A log likelihood map for each generated image can be formed by averaging the row Mi,:over the resolution
component
Mi,xy=/summationdisplay
rMi,xyr. (15)
Figure 7 shows resized Mxyoverlaid on the generated image ˆxat step 0. This visualisation highlights regions
of interest. Namely the tops of the sleeves for T-shirt (a), the back and toe of the boot (b) and the waist
and lower legs for the trousers (c).
15Under review as submission to TMLR
Figure 6: Comparison of choice criteria in terms of mean squared error (MSE). The different criteria for
choosing the next pattern ( QP,MIandHO), equations (9), (12) and (13) respectively, were evaluated
(mean MSE) using 10 test images, one from each class, and 1 ( top left), 10 (top right ), 100 (bottom left ),
200 (bottom right ) latent vector samples over 100 steps. ( QP) outperforms Hadamard optimisation ( HO)
for the first 25 steps.
(a)
 (b)
 (c)
Figure 7: After step 0, we overlay Miover ˆxito indicate regions of high information (white) and low
information (black) within the active learning frame at this step. For the long sleeved top, regions of interest
are the tops of the sleeves (a). The back and toe of the boot are regions of interest (b). The waist and lower
legs are regions of interest for the trousers (c). Using expression in equation 14 the next measurement taken
is determined by averaging the information over Nimages.
16