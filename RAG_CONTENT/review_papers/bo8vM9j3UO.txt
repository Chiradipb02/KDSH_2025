Published in Transactions on Machine Learning Research (10/2024)
A Theoretical Framework for Zeroth-Order Budget Convex
Optimization
François Bachoc francois.bachoc@math.univ-toulouse.fr
Institut de Mathématiques de Toulouse
Université Paul Sabatier
Institut universitaire de France (IUF)
Tommaso Cesari tcesari@uottawa.ca
School of Electrical Engineering and Computer Science
University of Ottawa
Roberto Colomboni roberto.colomboni@unimi.it
Università degli Studi di Milano
Politecnico di Milano
Andrea Paudice apaudice@cs.au.dk
Department of Computer Science
Aarhus University (AU)
Reviewed on OpenReview: https: // openreview. net/ forum? id= bo8vM9j3UO
Abstract
This paper studies a natural generalization of the problem of minimizing a convex function f
by querying its values sequentially. At each time-step t, the optimizer selects a query point
Xtand invests a budget bt(chosen by the environment) to obtain a fuzzy evaluation of f
atXtwhose accuracy depends on the amount of budget invested in Xtacross times. This
setting is motivated by the minimization of objectives whose values can only be determined
approximately through lengthy or expensive computations, where it is paramount to recycle
past information. In the univariate case, we design ReSearch, an anytime parameter-free
algorithm for which we prove near-optimal optimization-error guarantees. Then, we present
two applications of our univariate analysis. First, we show how to use ReSearch for stochastic
convex optimization, obtaining theoretical and empirical improvements on state-of-the-art
benchmarks. Second, we handle the d-dimensional budget problem by combining ReSearch
with a coordinate descent method, presenting theoretical guarantees and experiments.
1 Introduction
Consider the following fundamental question: given a convex real-valued function f, how can we efficiently
and sequentially select oracle queries of it in order to recommend a point xsuch thatf(x)is as close as
possible to the infimum of f? This problem is known as zeroth order convex optimization and has been
studied for more than half a century (Rosenbrock, 1960). The field has also recently attracted the interest of
the machine learning and statistical community because computing the gradient of a function that depends
on a large dataset (e.g., the empirical risk) can be very expensive if not unfeasible (see for example Bubeck
et al. 2021 and references therein). Another significant application arises in simulation-based optimization,
where the goal is to optimally tune the parameters of a system by only observing its output (Conn et al.,
2009; Spall, 2005).
1Published in Transactions on Machine Learning Research (10/2024)
There are several different ways to model this problem. In the deterministic setting, the oracle answers
each query xwith the exact value f(x). The classic stochastic setting alleviates the restrictiveness of the
deterministic oracle by assuming that each query xreturns a noisy independent estimation of f(x). This
oracle model is still not flexible enough to cover applications where perturbations are not independent or
where the optimizer can compute the value f(x)at a query point xwith incremental precision. The former is
crucial to include scenarios where errors have long-range dependence (Lahiri, 2003; Beran, 2017). The latter
has several practical applications, e.g., when the values of fare the results of long sums (as in time-series
forecasting via weighted empirical risk minimization; Kuznetsov & Mohri 2015; 2016) or, crucially, when they
can only be computed approximately through lengthy simulations (as it happens ubiquitously in the field of
computer experiments; Santner et al. 2003; Sacks et al. 1989).
Contributions. We make the following contributions:
•We design a novel zeroth-order budgetoptimization setting where the oracle answers each query x
with an interval that is guaranteed to contain f(x)and whose length decreases with the amount of
budget invested on xso far. In addition to generalizing the deterministic and stochastic settings, our
model also captures the aforementioned problems not covered by them. (Section 2.)
•We design ReSearch, an anytime,practicable , andparameter free algorithm for univariate zeroth-order
budget convex optimization that works under a minimal convexity assumption on f. (Section 3.1.)
•We prove a sharp anytime upper bound on the optimization error of ReSearch. Furthermore,
our analysis reveals that the optimal dependence on the Lipschitz constant of fis extremely
mild, asymptotically negligible, and can be entirely lifted by transitioning to a continuous budget
optimization setting. (Section 3.2.)
•We prove a matching (up to constants) lower bound, certifying the optimality of ReSearch. (Sec-
tion 3.3.)
•We apply ReSearch and its analysis to univariate stochastic convex optimization, improving the
state-of-the-art guarantees for this problem. (Section 4.1.)
•We illustrate how to handle the d-dimensional budget setting using ReSearch as a subroutine of a
coordinate-descent algorithm and provide corresponding theoretical guarantees. (Section 4.2.)
•Finally, we present illustrative experiments supporting our theory in the univariate stochastic and
uni/multivariate budget settings. (Section 5.)
Related Work. Zeroth-order convex optimization is a massive field with vast literature. We limit our
discussion to references more closely aligned with the scope of this paper.
The deterministic case is the simplest setting in zeroth-order optimization, where the oracle answers each
queryxwith the exact value of the objective f(x)(see Nesterov et al. 2018 and references therein). Although
not the core of our work, we highlight that in this setting, our one-dimensional algorithm ReSearch achieves
the well-known optimal geometric decay on the optimization error while not requiring the objective to be
globally Lipschitz.
To the best of our knowledge, our flexible budget setting with errors decaying as functions of the budget is
not addressed theoretically in the convex optimization literature. The more specific stochastic setting, where
the oracle answers queries with random independent estimates of the objective, is studied in particular by
Agarwal et al. (2013); Jamieson et al. (2012); Shamir (2013); Belloni et al. (2015). Our budget setting recovers
it as a special case when errors decay as O(1/√budget). In the one-dimensional case, an optimization error of
Ω(1/√
T)is unavoidable in the stochastic setting, even knowing the time-horizon Tin advance and under the
additional assumptions of smoothness and strong-convexity (see Shamir 2013, Theorem 3). This rate is also
achieved by Belloni et al. (2015) and Lattimore (2020), with high-probability and in-expectation respectively,
up to extra log terms; however, these algorithms are quite involved. Agarwal et al. (2013) and Jamieson
et al. (2012) propose simpler and more practical trisection-based algorithms with similar optimization error
guarantees. While these algorithms share some features with ReSearch (e.g., they monitor confidence-interval
separation to discard domain portions), our analysis departs substantially from those of Agarwal et al. (2013)
and Jamieson et al. (2012), leading to additional theoretical benefits (in particular, a negligible dependence
on the Lipschitz constant and an improved logarithmic dependence on the time horizon T). Finally, in
2Published in Transactions on Machine Learning Research (10/2024)
contrast to the works above, we highlight that our reduction from the univariate budget to the univariate
stochastic setting hold without any additional assumption (such as strong convexity, smoothness, or global
Lipschitzness).
2 Setting
Given a bounded convex set I⊂Rd, our goal is to minimize an unknown convexfunctionf∶I→Rpicked
by a possibly adversarial and adaptive environment by only requesting fuzzy evaluations of f. At every
interaction t, the optimizer selects a query point Xtand the environment selects and reveals a budget bt.
This budget is then used to reduce the fuzziness on the value of f(Xt), modeled by an interval Jt∋f(Xt). In
other words, the reader might think of the budget as a perishable (must be spent in full at every interaction)
and non-divisible (all must be spent in a single query point) amount of resources made available by the
environment to reduce the fuzziness of the value of the unknown objective at the current query point.
The interactions between the optimizer and the environment are described in Optimization Protocol 1.
Optimization Protocol 1
input: A non-empty bounded convex set I⊂Rd(the domain of the unknown objective
f)
1:fort=1,2,...do
2:The optimizer selects a query point Xt∈Iwhere to invest the next budget
3:The environment picks and reveals budget bt>0and an interval Jt⊂Rsuch thatf(Xt)∈Jt
4:The optimizer recommends a point Rt∈I
We stress that the environment is adaptive. Indeed, the intervals Jtthat are given as answers to the queries
Xtcan be chosen by the environment as an arbitrary function of the past history, as long as they represent
fuzzy evaluations of the convex objective f(i.e., as long as f(Xt)∈Jtfor allt).
Note that optimization would be impossible without further restrictions on the behavior of the environment,
since an adversarial convex environment could return Jt=Rfor allt∈N, making it impossible to gather any
meaningful information. We limit the power of the environment by relating the amount of budget invested in
a query point Xtwith the length of the corresponding fuzzy representation Jtoff(Xt), as quantified by the
following assumption.
Assumption 2.1. There exist c≥0andα>0such that, for any t∈N, if the optimizer invested the budgets
b1,...,btin the query points X1,...,Xt, then
∣Jt∣≤c/Bα
t,
where∣Jt∣denotes the length of JtandBt∶=∑t
s=1bsI{Xs=Xt}is the total budget invested in Xtup to time
t.
The performance of a recommendation RTis evaluated with the optimization error f(RT)−infx∈If(x).
3 An optimal algorithm for the univariate case
In this section we study the univariate budget convex optimization problem, i.e., the case when the underlying
convex setI⊂Ris a bounded interval. To solve this problem we propose ReSearch, an algorithm exploiting
the1-dimensional nature of the problem by following a query strategy that allows the learner to recycle most
of the past queries (Algorithm 2).
3.1 ReSearch
Before presenting its pseudo-code, we introduce some notation. For any positive integer n∈Nwe denote by
[n]the set {1,...,n}of the first nintegers. Let P∶={∎◻◻◻,◻◻◻∎,∎∎◻◻,◻◻∎∎,∎◻◻∎}. The blackened parts
of the elements of Prepresent which portions of the active interval maintained by ReSearch the algorithm
3Published in Transactions on Machine Learning Research (10/2024)
l crJ+
lJ−
r
JlJc
Jrf
Figure 1: A representation of the deletefunction. Since J+
l≤J−
r, the points right of rare deleted, i.e.,
delete(Jl,Jc,Jr)=◻◻◻∎.
0 1/41/23/41u
0 1/31/22/3 1/u
Figure 2: The uniform ( u) and non-uniform ( /u) partition functions applied to the interval I=[0,1].
will delete. Additionally, we will consider the element ◻◻◻◻representing the case where no parts of the
active interval will be deleted. Let Jbe the set of all intervals, and I⊂Jthat of all bounded intervals.
Furthermore, for any interval J∈J, letJ−∶=inf(J)andJ+∶=sup(J). ReSearch relies on four auxiliary
functions: the deletefunction, the uniform partition function u, the non-uniform partition function /u, and
theupdatefunction. The deletefunction (see Figure 1)
delete∶J3→P∪{◻◻◻◻}
is defined, for all (Jl,Jc,Jr)∈J3, by
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩∎∎◻◻ifJ−
c≥J+
r, else
◻◻∎∎ifJ−
c≥J+
l, else
∎◻◻∎ifJ−
l≥min(J+
c,J+
r)&J−
r≥min(J+
l,J+
c), else
∎◻◻◻ifJ−
l≥min(J+
c,J+
r), else
◻◻◻∎ifJ−
r≥min(J+
l,J+
c), else
◻◻◻◻.
In words, the intervals Jl,Jc,Jrwill represent the fuzzy evaluations of three points l<c<rin the domain of
the unknown objective (left, center, and right). Since we are assuming that the objective is convex, note
that whenever an upper bound on the value of the objective at a point xis lower than the lower bound at
another point ythat is left (resp., right) of x, then, all points that are left (resp., right) of y(yincluded) are
no better than x. Therefore, the function deletereturns which part of an interval containing three distinct
pointsl<c<rshould be deleted given the fuzzy evaluations Jl,Jc,Jr. (E.g.,∎∎◻◻represents the deletion of
all points of the active interval left of c,◻◻◻∎represents the deletion of all points of the active interval right
ofr,◻◻◻◻is returned when the fuzzy evaluations are not sufficient to delete anything, etc.)
The uniform and non-uniform partition functions (see Figure 2) are defined, respectively, by
u∶I→R3, I↦(3
4I−+1
4I+,1
2I−+1
2I+,1
4I−+3
4I+),
/u∶I→R3, I↦(2
3I−+1
3I+,1
2I−+1
2I+,1
3I−+2
3I+).
In words, the uniform (resp., non-uniform) partition function u(resp.,/u) returns the three points that are at
1/4,1/2, and 3/4(resp., 1/3,1/2, and 2/3) of the input interval I.
4Published in Transactions on Machine Learning Research (10/2024)
Theupdatefunction
update∶I×{u,/u}×P→I×{u,/u}
is defined, for all (I,ϑ,del)∈I×{u,/u}×P, by the table:
u /u
∎∎◻◻ ([1
2I−+1
2I+,I+],u) ([1
2I−+1
2I+,I+],/u)
◻◻∎∎ ([I−,1
2I−+1
2I+],u) ([I−,1
2I−+1
2I+],/u)
∎◻◻∎ ([3I−+I+
4,I−+3I+
4],u) ([2I−+I+
3,I−+2I+
3],u)
∎◻◻◻ ([3
4I−+1
4I+,I+],/u) ([2
3I−+1
3I+,I+],u)
◻◻◻∎ ([I−,1
4I−+3
4I+],/u) ([I−,1
3I−+2
3I+],u)
In words, when applied to an interval I, a type of partition ϑ, and a symbol del(representing the subset of I
to be deleted), the updatefunction returns as the first component the interval Ipruned of the subset of I
specified by ϑanddel, and, as the second component, how the new interval will be partitioned. It can be
seen that the types of partitions returned by updateare chosen so that our ReSearch algorithm will only
query points on a (rescaled) dyadic mesh (e.g., if I=[0,1], ReSearch will only query points of the form k/2h,
fork,h∈N).
For allt∈N, if the sequence of budgets picked by the environment up to time tisb1,...,bt, the se-
quence of query points selected by the optimizer is X1,...,Xt, the corresponding feedback is J1,...,Jt(see
Optimization Protocol 1), then, for each x∈R, we define the quantities
Bx,t∶=t
∑
s=1bsI{Xs=x}andJx,t∶=⋂
s∈[t],Xs=xJs
with the understanding that Jx,t=RwheneverXs≠xfor alls∈[t]. Furthermore, define Bx,0=0for all
x∈R. In words, Bx,tis the total budget that has been invested in xby the optimizer up to and including
timet, whileJx,tis the best fuzzy evaluation of the unknown objective at xthat is available at the end of
timet.
The pseudocode of ReSearch is provided in Algorithm 2. ReSearch proceeds in epochs τwhere it maintains
an active interval Iτand three query points lτ,cτ,rτ∈Iτ. During each epoch τ, it repeatedly queries a point
in{lτ,cτ,rτ}where it invested the least amount of budget until the function deletehas gathered enough
information to prune the current active interval. When this happens, first it updates the active interval and
the type of partition using the updatefunction. Then, it computes the three query points lτ+1,cτ+1,rτ+1of
the next epoch τ+1. Notably, among lτ+1,cτ+1,rτ+1there will be the point among lτ,cτ,rτthat has the
smallest value of f(or one of them, if there are more than one). Afterwards, the algorithm recommends a
pointx∈{lτ+1,cτ+1,rτ+1}with the best known upper bound J+
x,ton the value of f(x)available at the present
timet,1and concludes the current epoch. In all rounds in which function deletehas not yet gathered enough
information to prune the current active interval, the algorithm makes different recommendations depending
on whether or not the amount of budget invested in the current epoch is higher than the amount of budget
spent in all past epochs combined. See Figure 3 for an illustration of how ReSearch works.
We stress that ReSearch is any-time (it does not need to know the time horizon Ta priori), any-budget
(it does not need to know the total budget B∶=∑T
t=1bt) and does not require the unknown objective to be
Lipschitz. Nevertheless, we will show in Theorems 3.1 and 3.2 that its performance is guaranteed to be
near-optimal even when compared to algorithms with full knowledge of TandB, and run on convex Lipschitz
functions with knownLipschitz constant.
3.2 Upper bound
We now provide theoretical guarantees for ReSearch.
1Under Assumption 2.1, this corresponds to recommending a point x∈{lτ,cτ,rτ}with the best known upper bound J+
x,ton
the value of f(x)that will “survive” as a query point of the next epoch. Indeed, for x∈{lτ+1,cτ+1,rτ+1}∖{lτ,cτ,rτ}, we have
J+
x,t=+∞, sincexhas never been evaluated. On the other hand, any x∈{lτ,cτ,rτ}has already been evaluated, hence J+
x,t<∞.
5Published in Transactions on Machine Learning Research (10/2024)
Algorithm 2 ReSearch
input:A non-empty bounded interval I⊂R(the domain of the unknown objective)
initialization: I1∶=[I−,I+],ϑ1∶=u,(l1,c1,r1)∶=ϑ1(I1),t0∶=0,B0∶=0,B1,0∶=0
1:forepochsτ=1,2,...do
2:fort=tτ−1+1,tτ−1+2,...do
3:QueryXt∈argminx∈{lτ,cτ,rτ}Bx,t−1
4:Letdelt∶=delete(Jlτ,t,Jcτ,t,Jrτ,t)
5:LetBτ,t∶=Bτ,t−1+btandτt∶=τ
6: ifdelt≠◻◻◻◻ then
7: Lettτ∶=t,Bτ∶=Bτ,t, andBτ+1,t∶=0
8: Let(Iτ+1,ϑτ+1)∶=update(Iτ,ϑτ,delt)
9: Let(lτ+1,cτ+1,rτ+1)∶=ϑτ+1(Iτ+1)
10: Recommend Rt∈argminx∈{lτ+1,cτ+1,rτ+1}J+
x,t
11: break
12: else ifBτ,t≥∑τ−1
τ′=0Bτ′then
13: Recommend Rt∈argminx∈{lτ,cτ,rτ}J+
x,t
14: else
15: Recommend Rt∶=Rtτ−1
f(x)
xτ
Figure 3: A run of ReSearch. Here, the function is piece-wise linear and its graph is in thick black. The
horizontal segments are the active intervals Iτof consecutive epochs τ. The short vertical segments are the
current query points lτ,cτ,rτof epochτ, and the dots (prolonged down vertically) are the recommendations
at the end of each epoch, that converge towards x⋆. Note that, from one epoch to the next, two out of three
points are kept (together with their guarantees), maximizing the recycling of past information.
6Published in Transactions on Machine Learning Research (10/2024)
Theorem 3.1. For any bounded interval I⊂R, if the optimizer is running ReSearch (Algorithm 2) with
inputIin an environment satisfying Assumption 2.1 for some c≥0andα>0, then, there exist c1≤
12⋅(48/(21/α−1))α,c2≤9/8,c3≥(ln2)/48such that, for any time T∈N, every sequence of budgets
b1,...,bT>0, and every convex function f∶I→R, the optimization error f(RT)−infx∈If(x)is upper
bounded by
c1⋅c
(∑T
t=1bt)α+c2⋅L∣I∣exp(−c3⋅∑T
t=1bt
maxt∈[T]bt), (1)
whereLis the local Lipschitz constant of fon[lτT,rτT].
The full proof of this result can be found in Appendix A. Before presenting a sketch of it here, we make a few
remarks. First, note that the bound is non-trivial even when the function is notglobally Lipschitz (as it is
the case, e.g., for the function f(x)=−√
1−x2defined on the interval I=[−1,1]), since it depends on a local
Lipschitz constant L(which is always finite) that, informally, as the epochs go by, captures better and better
how much the function varies around the points that are close to the minimum.2Second, note that (up to
the constants c1,c2,c3) the bound consists of two terms.
The first term c/(∑T
t=1bt)αis a consequence of the fuzziness of the evaluations, that is regulated by Assumption
2.1: when∑T
t=1bt≥1, it decreases when αincreases or cdecreases. Moreover, when c=0andbt=1for
allt∈[T], our problem reduces to deterministic convex optimization. In this case, the first term vanishes
completely, leaving behind only the known optimal exponentially-decaying rate L∣I∣e−Ω(T)for deterministic
convex optimization.
The second term L∣I∣e−Ω(∑T
t=1bt/maxt∈[T]bt)is a consequence of the discrete nature of our setting. Notably, if
the optimizer could choose to invest infinitesimally small budgets bt(i.e., if the discrete optimization protocol
became a continuous one), the term would vanish completely. Strikingly, when this is the case, the bound
becomes completely independent of the Lipschitz constant L. To the best of our knowledge, this is the first
result in convex optimization that shows how the dependence on Lcould be entirelylifted if we transitioned
from a discrete to a continuous setting. In other words, our bound gives a parameterization of the dependence
on the Lipschitz constant in terms of how close our setting is to a continuous one. The high-level reason for
this behavior is that, in a discrete setting, the optimizer might be forced to spend a large amount of budget
bton a pointXtwhere a significantly smaller investment would have been sufficient to determine whether or
not that point was suboptimal. In this case, if the function is varying significantly, the number of queries
could not be sufficient to get close to a minimizer, and this would yield an optimization error that scales with
L. Finally, we note that, naturally, the Lipschitz constant Land the domain length ∣I∣appear as a product.
Indeed, shrinking (resp., dilating) the domain of a function f∶I→Rcorresponds (inversely-proportionally) to
an increase (resp., decrease) of the Lipschitz constant.
Proof sketch. We divide the analysis in the 3cases sketched below, depending on how ReSearch selects RT.
1.delT≠◻◻◻◻. In this case, we partition the number of epochs in several classes and focus our attention
on the class where we invested the highest fraction of the total budget ∑T
t=1bt. Say that this class
containsnepochs. Ifnis small, we show that in the last epoch of this class there exist two query
points that are near-optimal and that the recommendation RTof ReSearch has guarantees that are
close to those of these two near-optimal points. If, on the other hand, nis large, the result follows by
the local Lipschitzness of f.
2.delT=◻◻◻◻and the majority of the budget was invested in the last epoch. In this case, we split
again the analysis in two further cases. If the maximum budget maxt∈[T]btis small, we show that all
three query points of the last epoch are near-optimal, therefore so is the recommendation RT. If, on
the other hand, the maximum budget maxt∈[T]btis large, we fall back again to the local Lipschitzness
of the objective.
3.delT=◻◻◻◻and the majority of the budget was invested before the last epoch. Since in this case the
recommendation RTis the same as the recommendation that ended the previous epoch, the result
follows by Item 1, using half of the total budget.
2For more on the advantages of an adaptive local Lipschitz constant, see Appendix E.
7Published in Transactions on Machine Learning Research (10/2024)
3.3 Lower bound
In this section, we show that ReSearch is worst-case optimal: there exist instances where the upper bound of
Theorem 3.1 is matched (up to possibly different constants c1,c2,c3). The apparent asymmetry between our
upper and lower bounds is due to the fact that, in Theorem 3.2:
•We gave the optimizer the freedom to select the time horizon Tand total budget Bahead of time.
•We restricted the result to convex Lipschitz functions.
Note that both these changes make our results stronger, since ReSearch is able to match the lower bound
despite lacking the freedom to select T,B(in fact, being totally oblivious to a possibly adversarial choice of
both) and Theorem 3.1 holds even for non-Lipschitz functions.
Theorem 3.2. For any nondegenerate bounded interval I⊂R, if the environment satisfies Assumption 2.1
for somec≥0andα>0, then, there exist c1≥1/4,c2≥1/32e,c3≤1such that, for any time T∈N, every total
budgetB>0, every Lipschitz constant L>0, and every deterministic algorithm run by the optimizer, there
exists a sequence of budgets b1,...,bTsuch that∑T
t=1bt=Band there exists a max(c
∣I∣Bα,L)-Lipschitz convex
functionf∶I→R, for which the optimization error f(RT)−infx∈If(x)is lower bounded by
c1⋅c
(∑T
t=1bt)α+c2⋅L∣I∣exp(−c3⋅∑T
t=1bt
maxt∈[T]bt). (2)
We defer the proof of this result to Appendix B.
4 Applications
We present two notable applications of our method. First, we show how to apply ReSearch to the case of
univariate stochastic convex optimization, improving on state-of-art bounds; remarkably and in contrast with
previous works, the algorithm does not require the Lipschitzness of the objective. Second, we illustrate how
to address the multivariate budget case by combining ReSearch with a classic coordinate descent method (see
Tseng 2001 and references therein) when the objective is smooth and strongly convex.
4.1 Univariate Stochastic Convex Optimization
In this section, we show how to apply ReSearch to the related problem of univariate stochastic convex
optimization (SCO). Typically, in this problem, one assumes that querying a point xreturns an i.i.d.
subgaussian (noisy) evaluation of the unknown objective f(x). Instead, we will introduce a more general
setting where the key property is the concentration of the (averages of the) queried evaluations. This way, we
can recover the classic SCO but also obtain results for more general non-i.i.d. settings (see below).
LetIbe a bounded interval and f∶I→Ran unknown convex function.
Assumption 4.1. There exist α>0,c∶(0,1)→(0,∞),m∶⋃t∈NRt→R, and a family of random variables
(Yx,s)x∈I,s∈Nsafisfying, for all x∈Iandt∈N,
P[∣m(Yx,1,...,Yx,t)−f(x)∣≤1
2c(δ)
tα]≥1−δ.
Note that, in classic SCO, where for each x∈I, the sequence (Yx,t)t∈Nis i.i.d. and σ-subgaussian, Assumption
4.1 is implied by Hoeffding’s inequality for α∶=1/2,c(δ)∶=√
8σ2ln(2/δ)(for allδ∈(0,1)) andmas
the empirical average. The case α<1/2in Assumption 4.1 is relevant to model errors with long-range
dependence (Lahiri, 2003; Beran, 2017). To give a simple example, consider that (Yx,t)t∈Nare Gaussian
with Cov(Yx,t,Yx,s)=σ2(1+∣t−s∣)−βfort,s∈Nand for a fixed β∈(0,1). Then, it can be checked that
Assumption 4.1 holds with mas the empirical average, with α∶=β/2and withc(δ)∶=√
16σ2ln(2/δ). This is
obtained by bounding the variance and then the tail of the (Gaussian) average.
LetT∈Nbe the time horizon. The learner interacts with the environment according to Optimization
Protocol 3. As before, the goal is to minimize the optimization error after Ttime stepsf(RT)−infx∈If(x).
8Published in Transactions on Machine Learning Research (10/2024)
Stochastic Optimization Protocol 3
1:fort=1,...,T do
2:The optimizer selects a query point Xt∈I
3:The environment reveals YXt,Nt, where
Nt∶=∑s∈[t]I{Xs=Xt}
4:The optimizer recommends a point RT∈I
By running ReSearch with feedback Jtequal to a suitable confidence interval for f(Xt)(at each time
t), we extend the state-of-the-art for stochastic convex optimization (Agarwal et al., 2013) beyond the
globally-Lipschitz case and, even where the previous guarantees held, we improve them in two ways: we
remove a logarithmic factor from the bound and we only pay the Lipschitz constant in the non-dominating
term, which decreases exponentially with T.
To lighten the notation, let Mt∶=m(YXt,1,...,YXt,Nt)and consider Algorithm 4.
Algorithm 4 ReSearch for SCO
input:Confidence parameter δ∈(0,1)
1:fort=1,...,T do
2:ReSearch selects the next query point Xt
3:The optimizer feeds ReSearch with the feedback
Jt∶=[Mt−1
2c(δ)
Nα
t,Mt+1
2c(δ)
Nα
t]
4:ReSearch recommends a point RT
Note also that Mtis (in general) a biased estimate of f(Xt), even in the case when mis the empirical
average3.
Theorem 4.2. If the optimizer runs ReSearch for SCO (Algorithm 4), its optimization error is upper bounded
by
c1⋅c(δ)
Tα+c2⋅L∣I∣exp(−c3⋅T),
on the complement of an event having probability O(T2δ), wherec1,c2,c3,Lare as in Theorem 3.1.
In particular, in the i.i.d. subgaussian setting, picking δ=Θ(1/T5/2)yields an expected optimization error of
order√
(logT)/T, improving the state-of-the-art in Agarwal et al. (2013) by a logTfactor.
We defer the proof of Theorem 4.2 to Appendix C.
4.2 Multivariate Budget Convex Optimization
We now illustrate how to use ReSearch to address the multivariate budget setting (see Algorithm 5), where
the objective fis defined on a convex bounded subset I⊂Rd. We use an adaptation to the budget setting of
a coordinate descent method in the spirit of Jamieson et al. (2012). Coordinate descent is typically analyzed
assuming that the objective fis strongly convex and smooth, which we also assume until the end of the
section.
Algorithm 5 proceeds by performing sequential line searches. During line search k, it uses ReSearch along a
segment determined by a base point xkand a randomly drawn axis i(k), recommending points based on
the recommendations of ReSearch. A line search is concluded as soon as the length of the active interval of
ReSearch is ≤η. At the end of each line search, the base point xk+1is updated using the best point found by
ReSearch.
3Because ReSearch recycles past observations multiple times, even after they have been used to decide which part of the
current interval to discard. (At a high level, the estimates of the values of the function at the points that we keep have the
tendency to “look better”.) This recycling of information is a feature, not a flaw of the algorithm, as it allows reaching an
approximate minimizer with a smaller number of queries (see Section 5.2).
9Published in Transactions on Machine Learning Research (10/2024)
10210310410510610−510−410−310−210−1100
(a) Univariate budget10210310410510610−210−1
(b) Univariate stochastic10210310410510610−610−410−2100102104
(c) Multivariate budget: error
2040608010000.51
(d) Multivariate budget: runtime
Figure 4: (a) The optimization error of ReSearch (black) is compared with the corresponding upper (red)
and lower (blue) bounds. (b) The median optimization error of ReSearch for SCO (black) is compared with
Jamieson et al. 2012 (green) and Agarwal et al. 2013 (orange); shaded areas are Inter-Quartile Ranges. (c)
The average optimization error of Algorithm 5 tuned as in Theorems 4.3 and D.1 (black) is compared with
its corresponding upper bound (red) and alternative choices of η:1(blue), 0.1(purple), 0.01(orange) —see
Section 5.3. Plots are in log scale. (d) The average runtime of Algorithm 5 is plotted against the dimension
of the problem —see Section 5.3. All, but (d), plots are in log scale.
Algorithm 5 Budget coordinate descent via ReSearch
input:Initial base point x0∈I, threshold length η>0
1:fork=0,1,...do
2:Picki(k)uniformly at random from [d]
3:Run ReSearch for time steps s=1,...,Tk(η)on the interval Ik∶={z∈R∶xk+zei(k)∈I}, recommending
xk+Rsei(k)at time∑k−1
j=0Tj(η)+s, whereTk(η)is the first time step where the length of the active
interval maintained by ReSearch is ≤η
4:Setxk+1=xk+RTk(η)ei(k)
For the sake of simplicity, we present our results in the case where the budgets btare equal to 1, for allt.
Theorem 4.3 (Informal statement) .Under Assumption 2.1, whenever fis strongly convex and smooth, for
anyη>0, the expected optimization error of Algorithm 5 is upper bounded by
(f(x0)−inf
x∈If(x))(1−1/Θ(d))K(T,η)+Θ(dη2),
whereK(T,η)is the total number of line searches performed up to time Tand the expectation is taken with
respect to the random draws of the directions i(0),i(1),....
Moreover, an appropriate tuning of ηyields the bound ˜O(d(d/T)α)on the expected optimization error.
10Published in Transactions on Machine Learning Research (10/2024)
For a formal statement, the proof of the previous theorem, and a more general version holding for arbitrary
budgets see Appendix D.
We now make the following comments.
First, to put things into perspective, when α=1/2, we note that our rate d(d/T)1/2for the budget setting
is in line with state-of-the-art bounds in the related classic field of (i.i.d. subgaussian) stochastic convex
optimization (Jamieson et al., 2012), where confidence intervals shrink at the rate in Assumption 2.1, with
α=1/2.
Second, in convex optimization, strong convexity usually allows for unconstrained optimization (i.e., I∶=Rd);
our method can be extended to this case by adding a pre-processing step before each line search that works
by doubling the search space sequentially on the given line until we can guarantee to contain the minimizer.
For the sake of conciseness, we leave this standard step out of our presentation.
Third, if one sets a target optimization error of ε, it is a consequence of Theorem D.1 that the runtime of
Algorithm 5 is of the order of (d1+α/ε)1/α. This is due to the fact that Line 3 takes constant time for each
function query and that after Titerations of Algorithm 5, the optimization error is of the order of d1+α/Tα
(ignoring logarithmic factors). Furthermore, the algorithm, at each iteration, only needs to store three points
for ReSearch, the d-dimensional vector with the current direction, and finally the dpairs of interval limits
delimiting the box-constraint. Thus, the overall space complexity is of the order of d. We believe that it
is unlikely that in this setting one can obtains bounds that are independent from d. Indeed, in the related
stochastic case, (Shamir, 2013) shows that at least a linear dependence on dis unavoidable.
Finally, we highlight a remarkable benefit of coordinate descent frameworks (in particular, Algorithm 5): they
trade off some generality (by requiring strong convexity and smoothness) to gain an easy implementation and
obtain efficiency on the two separate fronts of query (by featuring state-of-the-art optimization error bounds)
and computational complexity (having low memory requirements and fast execution, irrespectively of the
dimension).
5 Experiments
We present a preliminary experimental evaluation in support of our theoretical findings, illustrating the
following. First, the performance of ReSearch is in line with the theoretical guarantees and, in practice,
closer to the lower (Theorem 3.2) than to the upper bound (Theorem 3.1). Second, Algorithm 4 significantly
outperforms its natural competitors. Third, the role played by the threshold parameter ηin Algorithm 5,
and its performance compared to the upper bound.
5.1 Comparison with upper and lower bounds
This experiment aims at comparing the performance of ReSearch with the corresponding theoretical upper
(Theorem 3.1) and lower (Theorem 3.2) bounds. The oracle is based on the setting described in the first
part of the proof of Theorem 3.2 with parameters c=0.1,α=1/2,bt=1for allt. We test the performance of
ReSearch on a grid of time horizons T∈{102,103,..., 106}against the objective fconstructed in the lower
bound. Figure 4(a) shows that ReSearch performs well, appearing significantly (note the log scale) closer to
the lower than the upper bound.
5.2 Stochastic Case
This experiment (Figure 4(b)) aims at showing the effectiveness of Algorithm 4 when compared to the
uni-dimensional algorithms proposed in Agarwal et al. (2013) and Jamieson et al. (2012), which are state-
of-the-art for this setting. To this end, we optimize the function f(x)=1
2x2overI=[0,1]; notice that
fis1-Lipschitz over Iand its minimum value is 0. The stochastic oracle is implemented according to
Stochastic Optimization Protocol 3 with independent Gaussian noise with mean 0and variance σ2=0.1.
This corresponds to having c(δ)=√
σ2ln(1/δ)andα=1/2in Assumption 4.1. We set all the algorithms with
the parameters indicated by the theory, so that the overall confidence is 1−1/Tin all cases. Consistently
11Published in Transactions on Machine Learning Research (10/2024)
with the previous section, we evaluate the algorithms on a grid of time horizons T∈{102,103,..., 106}. Since
we are comparing high probability bounds, we measure the median optimization error and plot it with the
corresponding Inter-Quartile Range over 10repetitions.
5.3 Multivariate case
These experiments illustrate the performance of Assumption 5 in the multivariate budget case. We minimize
the function f(x)=1
2∥x∥2
2over[−1,3d]dford=10, which has the minimum close to a corner, but not
exactly there. We implemented the oracle according to Optimization Protocol 1 and Assumption 2.1 with
c=1,α=1andbt=1for allt. In addition to using the threshold ηTrecommended by the tuning in
appendix D and the corresponding theoretical upper bound, we also run algorithm 5 using η∈{1,10−1,10−2}
forT∈{102,103,..., 106}. We repeat each run 10times and report the average optimization error and the
standard deviation (note the high concentration: paths have little to no variance). Figure 4(c) shows the
results (in logarithmic scale), highlighting that the tuning of the threshold ηTdictated by the theory can be
a little more conservative in some cases than some ad hocchoices ofη, but it is still far better than the upper
bound (which is on par with state-of-the-art bounds for analogous settings) and a random guess of η.
In a second experiment, we considered the same problem setting and measured the runtime of the algorithm
against the dimension, varying the dimension din the interval [10,100]with a step of 10. We set a target
optimization error 0.1and run the algorithm until it reaches it. In Figure 4(d) we reported the average
runtime across 10repetitions. As predicted by the theory, the runtime follows the predicted d2behavior and
remarkably the execution for d=100takes less than a second.
6 Conclusions
We designed and studied a flexible zeroth-order convex optimization setting, where the accuracy of the queries
improves with the invested budget (Assumption 2.1). This framework grants additional modeling power (see
Section 1) compared to standard stochastic settings. In dimension one, we designed an any-time, any-budget,
parameter-free algorithm, called ReSearch (Algorithm 2), that does not require the a priori knowledge of
the (local) Lipschitz constant of the objective and works even in an adversarial and adaptive environment.
We provided upper and lower bounds on the optimization error that match up to constants. We provided a
natural adaptation of ReSearch to the stochastic setting together with a corresponding upper bound featuring
the same mild dependence on the Lipschitz constant, and further improved the state-of-the-art for this
setting by a logarithmic term. Finally, in the multivariate budget setting, we illustrated the benefits of using
ReSearch as a line search procedure in a coordinate descent method: this results in a numerically efficient
and practicable budget optimizer that can run even in high-dimensional spaces.
References
Alekh Agarwal, Dean P. Foster, Daniel J. Hsu, Sham M. Kakade, and Alexander Rakhlin. Stochastic convex
optimization with bandit feedback. SIAM J. Optim. , 23(1):213–240, 2013.
Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the local
minima via simulated annealing: Optimization of approximately convex functions. In Conference on
Learning Theory , pp. 240–265. PMLR, 2015.
Jan Beran. Statistics for long-memory processes . Routledge, 2017.
Sébastien Bubeck, Ronen Eldan, and Yin Tat Lee. Kernel-based methods for bandit convex optimization.
Journal of the ACM (JACM) , 68(4):1–35, 2021.
Andrew R Conn, Katya Scheinberg, and Luis N Vicente. Introduction to derivative-free optimization . SIAM,
2009.
Kevin G Jamieson, Robert Nowak, and Ben Recht. Query complexity of derivative-free optimization. In
Advances in Neural Information Processing Systems , volume 25, 2012.
12Published in Transactions on Machine Learning Research (10/2024)
Vitaly Kuznetsov and Mehryar Mohri. Learning theory and algorithms for forecasting non-stationary time
series.Advances in neural information processing systems , 28, 2015.
Vitaly Kuznetsov and Mehryar Mohri. Time series prediction and online learning. In Conference on Learning
Theory, pp. 1190–1213. PMLR, 2016.
SN Lahiri. Central limit theorems for weighted sums of a spatial process under a class of stochastic and fixed
designs. Sankhy¯ a: The Indian Journal of Statistics , pp. 356–388, 2003.
Tor Lattimore. Improved regret for zeroth-order adversarial bandit convex optimisation. Mathematical
Statistics and Learning , 2(3):311–334, 2020.
Yurii Nesterov et al. Lectures on convex optimization , volume 137. Springer, 2018.
HoHo Rosenbrock. An automatic method for finding the greatest or least value of a function. The computer
journal, 3(3):175–184, 1960.
Jerome Sacks, William J Welch, Toby J Mitchell, and Henry P Wynn. Design and analysis of computer
experiments. Statistical science , 4(4):409–423, 1989.
Thomas J Santner, Brian J Williams, William I Notz, and Brain J Williams. The design and analysis of
computer experiments , volume 1. Springer, 2003.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algorithms .
Cambridge university press, 2014.
Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In Conference
on Learning Theory , pp. 3–24. PMLR, 2013.
James C Spall. Introduction to stochastic search and optimization: estimation, simulation, and control . John
Wiley & Sons, 2005.
Paul Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization. Journal
of optimization theory and applications , 109(3):475, 2001.
13Published in Transactions on Machine Learning Research (10/2024)
A Full proof of Theorem 3.1
In this section, we give a detailed proof of Theorem 3.1.
Proof of Theorem 3.1. Fix any bounded interval I⊂R, a timeT∈N, and a convex function f∶I→R. Without
loss of generality, we can (and do!) assume that Icontains at least two distinct points.4Moreover, without
loss of generality, we can also (and do!) assume that fattains its minimum in I.5Then, note that the active
intervalIτof any epoch τ∈[τT](defined in the initialization and updated at Line 8) always contains at least
a minimizer, because the first active interval I1is the entire domain Iand, by the unimodality of fand
the definition of the deleteandupdatefunctions, ReSearch deletes a fraction of the active interval (Line 8)
only if it is certain that the value of fat one of the remaining points is no bigger than allof the deleted
points. Thus, there exists (and we fix for the rest of the proof) an x⋆∈Isuch thatx⋆∈IτT⊂...⊂I1and
f(x⋆)=min(f). Recall that, for all t∈N,τtis the epoch of round t(Line 5 of Algorithm 2). Also, for the
sake of convenience, we define t0∶=0and, if the last epoch is not concluded exactly at the end of time T, we
redefinetτT∶=TandBτT∶=BτT,T.
To prove the result, we analyze separately the performance of the recommendation RTof ReSearch in the
three cases of Lines 10, 13 and 15 in Algorithm 2.
Assume at first that delT≠◻◻◻◻(i.e., the condition on Line 6 is true and we recommend RTas in Line
10). We partition the epochs τ∈[τT]into four sets, depending on whether or not the epoch is uniform and
whether or not x⋆≤cτ. More precisely, for any ζ∈{u,/u}and⊢∈{≤,>}, we letAζ,⊢be the set of all epochs
τ∈[τT]such thatϑτ=ζandx⋆⊢cτ. (or, equivalently stated, that there exist at least two distinct elements
x,y∈{lτ,cτ,rτ}such thatx⋆⊢x⊢y). Now fixA∶=Aζ,⊢, where
(ζ,⊢)∈ argmax
(ζ′,⊢′)∈{u,/u}×{≤,>}∑
τ∈Aζ′,⊢′Bτ.
In words,Ais the set of epochs Aζ′,⊢′where ReSearch spent the highest budget. Define, for each τ∈A,
the pointsxτ≠yτas the closest and second-closest points in {lτ,cτ,rτ}tox⋆such thatx⋆⊢xτ⊢yτ(they
always exist by definition of A). More precisely,
xτ∶= argmin
x∈{lτ,cτ,rτ},x⋆⊢x∣x−x⋆∣,
yτ∶= argmin
x∈{lτ,cτ,rτ}∖{xτ},x⋆⊢x∣x−x⋆∣.
Letnbe the number of elements of Aandκ1,...,κnbe the elements of Ain increasing order. Then, for any
i∈N, we have
∣Iκi∣≤∣Iκi−1∣/2 if2≤i≤n, (3)
∣yκi−xκi∣≤∣yκi−1−xκi−1∣/2 if2≤i≤n, (4)
∣xκi−x⋆∣≤∣yκi−xκi∣⋅2 ifi≤n, (5)
∣xκi−x⋆∣≤∣xκi−1−x⋆∣ if2≤i≤n, (6)
∣yκi−x⋆∣≤∣yκi−1−x⋆∣ if2≤i≤n. (7)
Here, equation 3 follows directly by the definition of the updatefunction, noting that there are never two
uniform or two non-uniform epochs in a row, unless half of the current interval is eliminated in one single call
of the updatefunction. Inequality equation 4 follows directly from equation 3. Inequality equation 5 is a
consequence of the definitions of the partition functions uand/u. To prove equation 6, note first that the claim
4Otherwise, the optimization error is trivially zero.
5Indeed, if it does not, then there exists x⋆∈{I−,I+}such that limx→x⋆,x∈If(x)=infx∈If(x)(this can only happen if Iis
not closed or fis discontinuous at x⋆; in the latter case, note that by convexity, f(x⋆)>limx→x⋆,x∈If(x)=infx∈If(x)). Thus,
noting that ReSearch neverqueries nor recommends the endpoints {I−,I+}ofI, one can replace fwith ¯f, where ¯f(x)∶=f(x)
for allx∈Iand ¯f(x⋆)∶=infx∈If(x). This way, up to extending (or redefining) fatx⋆, we are left with a convex function ¯fsuch
that ¯f(X1)∈J1,..., ¯f(XT)∈JT, attains its minimum at x⋆(in its domain), and satisfies f(RT)−infx∈If(x)=¯f(RT)−¯f(x⋆).
14Published in Transactions on Machine Learning Research (10/2024)
holds trivially when xκi−1∈{lκi,cκi,rκi}. When this is not the case, since ReSearch discarded xκi−1at the end
of some previous epoch, it either holds that Iκi⊂(−∞,xκi−1]orIκi⊂[xκi−1,∞). Ifx⋆≤xκi−1(meaning that
⊢=≤), it follows from x⋆∈IκithatIκi⊂(−∞,xκi−1], which implies x⋆≤xκi<xκi−1. Analogously, if x⋆>xκi−1
(meaning that ⊢=>), it follows from x⋆∈IκithatIκi⊂[xκi−1,∞), which implies x⋆>xκi>xκi−1. This proves
equation 6. Moreover, as a direct consequence of equation 4 and equation 6, we obtain equation 7.
By construction, we have that
4∑
τ∈ABτ≥∑
τ∈[τT]Bτ=T
∑
t=1bt. (8)
Now, we show that for any τ∈[τT]andk∈{0,...,tτ}, we have
min
x∈{lτ,cτ,rτ}Bx,tτ−k≥Bτ−(2+k)maxt∈[T]bt
3, (9)
i.e., that the total budget Bx,tτ−kspent on any query point x∈{lτ,cτ,rτ}up to timetτ−kis no smaller (up to
Θ(k)⋅maxt∈[T]bt) than the budget Bτspent (on all query points) only during epoch τ. Indeed, for any τ∈[τT]
andk∈{0,...,tτ}, lettingxmin∈argminx∈{lτ,cτ,rτ}Bx,tτ−kbe a query point where the algorithm spent the
least amount of budget up to time tτ−kandM∶={x∈{lτ,cτ,rτ}∶Bx,tτ−k−Bxmin,tτ−k≤maxt∈[T]bt}be the
set of all query points in which the algorithm spent a budget close to that of xmin, we have
3⋅min
x∈{lτ,cτ,rτ}Bx,tτ−k≥∑
x∈MBx,tτ−k−2 max
t∈[T]bt
≥∑
x∈Mtτ−k
∑
t=tτ−1+1btI{Xt=x}−2 max
t∈[T]bt
(∗)=Bτ−tτ
∑
t=tτ−k+1bt−2 max
t∈[T]bt
≥Bτ−(2+k)max
t∈[T]bt
with the understanding that any sum ∑j
s=izsis equal to zero whenever i>j, and where in (∗)we used the
fact that, if x∈{lτ,cτ,rτ}is such that Bx,tτ−k−Bxmin,tτ−k>maxt∈[T]bt, then ReSearch never queried xin
epochτup to time tτ−k, i.e.,
tτ−k
∑
t=tτ−1+1bt=0.
This proves equation 9.
Thus, for any τ∈A, ifBτ>3maxt∈[T]bt, sinceJ+
xτ,tτ−1>J−
yτ,tτ−1(this follows from the definition of the
deletefunction and can be proved by exhaustion), it holds that
f(yτ)−f(xτ)≤J+
yτ,tτ−1−J−
xτ,tτ−1
<J+
yτ,tτ−1−J−
yτ,tτ−1+J+
xτ,tτ−1−J−
xτ,tτ−1
=∣Jyτ,tτ−1∣+∣Jxτ,tτ−1∣≤c
Bα
yτ,tτ−1+c
Bα
xτ,tτ−1
≤2⋅c
(minx∈{lτ,cτ,rτ}Bx,tτ−1)α
equation 9≤3α⋅2⋅c
(Bτ−3 maxt∈[T]bt)α. (10)
Assume now that f(yκn)−f(xκn)>0. Then, for any τ∈A, by convexity and inequalities equation 6–
equation 7, we have that f(yτ)−f(xτ)>0is also true. By equation 10, it follows that, for any i∈[n],
15Published in Transactions on Machine Learning Research (10/2024)
regardless of the fact that the inequality Bκi>3 maxt∈[T]btholds or not,
Bκi≤3 max
t∈[T]bt+3⋅(2⋅c)1/α
(f(yκi)−f(xκi))1/α. (11)
Summing equation 11 over i∈[a], we obtain
T
∑
t=1btequation 8≤ 4∑
τ∈ABτ=4n
∑
i=1Bκi
equation 11≤ 4n
∑
i=1⎛
⎜
⎝3 max
t∈[T]bt+3⋅(2⋅c)1/α
(f(yκi)−f(xκi))1/α⎞
⎟
⎠
=12⋅max
t∈[T]bt⋅n+n
∑
i=112⋅(2⋅c)1/α
(f(yκi)−f(xκi))1/α. (12)
Now, using equation 6–equation 7 together with the fact that difference quotients of a convex function are
non-decreasing in both variables, and since for each i∈[n]it holds that (yκn−xκn)⋅(yκi−xκi)>0, we have
n
∑
i=1(f(yκn)−f(xκn))1/α
(f(yκi)−f(xκi))1/α=n
∑
i=1(f(yκn)−f(xκn)
f(yκi)−f(xκi))1/α
=n
∑
i=1⎛
⎜⎜
⎝⎛
⎜
⎝f(yκn)−f(xκn)
yκn−xκn
f(yκi)−f(xκi)
yκi−xκi⎞
⎟
⎠1/α
⋅∣yκn−xκn
yκi−xκi∣1/α⎞
⎟⎟
⎠
equation 6+equation 7≤n
∑
i=1∣yκn−xκn
yκi−xκi∣1/αequation 4≤n
∑
i=1(1
2n−i)1/α
≤1
1−2−1/α. (13)
Putting equation 12 and equation 13 together, we obtain the inequality
T
∑
t=1bt≤12⋅max
t∈[T]bt⋅n+12⋅(2⋅c)1/α⋅1
1−2−1/α
(f(yκn)−f(xκn))1/α,
that can be rearranged, whenever ∑T
t=1bt≥24⋅maxt∈[T]bt⋅n, to obtain the inequality
f(yκn)−f(xκn)≤4⋅(24
21/α−1)α
⋅c
(∑T
t=1bt)α. (14)
Then, relying again on the fact that difference quotients of a convex function are non-decreasing in both
variables, and that (ykn−xkn)⋅(xkn−x⋆)≥0, whenever∑T
t=1bt≥24⋅maxt∈[T]bt⋅nandxκn≠x⋆, we have
that
f(xκn)−f(x⋆)=f(xκn)−f(x⋆)
xκn−x⋆⋅(xκn−x⋆)
≤f(yκn)−f(xκn)
yκn−xκn⋅(xκn−x⋆)
equation 14≤ 4⋅(24
21/α−1)α
⋅c
(∑T
t=1bt)α⋅∣xκn−x⋆
yκn−xκn∣
equation 5≤ 8⋅(24
21/α−1)α
⋅c
(∑T
t=1bt)α(15)
16Published in Transactions on Machine Learning Research (10/2024)
(note that equation 15 is trivially true also when xκn=x⋆) and
f(yκn)−f(x⋆)=f(yκn)−f(xκn)+f(xκn)−f(x⋆)
equation 14+equation 15≤ 12⋅(24
21/α−1)α
⋅c
(∑T
t=1bt)α. (16)
Recall that the derivations for equation 15 and equation 16 were carried out under the assumption that
f(yκn)−f(xκn)>0. If this assumption does not hold, by convexity, f(yκn)=f(xκn)=f(x⋆), therefore
equation 15 and equation 16 are still (trivially) true.
Now, we will prove that the recommendation RTis approximately at least as good as xκnandyκn. Since
under the assumption that ∑T
t=1bt≥24⋅n⋅maxt∈[T]btwe showed in equation 15 and equation 16 that xκnand
yκnare both near-minimizers, this will yield under the same assumption that RTis also a near-minimizer.
Recalling that we are currently assuming delT≠◻◻◻◻, we have that RT∈argminx∈{lτT+1,cτT+1,rτT+1}J+
x,T,
which (as can be checked directly) implies in turn that RT∈argminx∈{lτT,cτT,rτT}J+
x,Tand, whenever
∑T
t=1bt≥24⋅n⋅maxt∈[T]bt:
1. IfRT∈{xκn,yκn}, then equation 1 follows by equation 15 and equation 16.
2.IfRT∉{xκn,yκn}, and{xκn,yκn}⊂{lτT,cτT,rτT}, then there exists x∈{lτT,cτT,rτT}∖{RT}=
{xκn,yκn}such thatf(RT)≤J+
RT,T≤J−
x,T≤f(x); therefore, equation 1 follows by equation 15 and
equation 16.
3.IfRT∉{xκn,yκn}, and{xκn,yκn}⊄{lτT,cτT,rτT}, then, since at least one between xκnandyκn
does not belong to the set of active query points {lτT,cτT,rτT}at timeT, there exist a past time
t∈[T]and a past query point x∈{lτt,cτt,rτt}such thatJ+
x,t≤max(J−
xκn,t,J−
yκn,t); therefore, noting
that the sequence s↦minx′∈{lτs,cτs,rτs}J+
x′,sis non-increasing, we have f(RT)≤J+
RT,T≤J+
x,t≤
max(J−
xκn,t,J−
yκn,t)≤max(f(xκn),f(yκn))and equation 1 follows by equation 15 and equation 16.
On the other hand, if ∑T
t=1bt<24⋅n⋅maxt∈[T]bt, then
f(RT)−f(x⋆)≤3
4L∣IτT+1∣≤9
16L∣Iκn∣
equation 3≤9
16L∣I∣(1/2)n−1≤9
16L∣I∣(1/2)∑T
t=1bt
24maxt∈[T]bt−1
=9
8L∣I∣exp(−ln 2
24∑T
t=1bt
maxt∈[T]bt),
whereLis the smallest between the Lipschitz constants of fon[lτT,rτT]and[lτT+1,rτT+1]—indeed, by
convexity,Lis a Lipschitz constant for fon the convex hull of {x⋆,lτT,rτT}(resp., {x⋆,lτT+1,rτT+1}) if
and only if it is a Lipschitz constant on [lτT,rτT](resp.,[lτT+1,rτT+1]). Putting everything together yields
equation 1 when delT≠◻◻◻◻.
Assume now that delT=◻◻◻◻andBτT≥∑τT−1
τ′=0Bτ′(i.e., the condition on Line 12 is true and we recommend
RTas in Line 13). This implies that the three intervals JlτT,T,JcτT,T,JrτT,Thave non-empty intersection,
which in turn implies that
max
x′∈{lτT,cτT,rτT}J+
x′,T− min
x′∈{lτT,cτT,rτT}J−
x′,T≤2 max
x′∈{lτT,cτT,rτT}∣Jx′,T∣. (17)
Now, we define f1,f2,f3,f4as the four functions whose graphs are straight lines such that f1passes through
the points (lτT,J−
lτT,T)and(rτT,J+
rτT,T),f2passes through the points (cτT,J−
cτ,T)and(rτT,J+
rτT,T),f3
passes through the points (lτT,J+
lτT,T)and(cτT,J−
cτT,T), andf4passes through the points (lτT,J+
lτT,T)and
(rτT,J−
rτT,T)(Figure 5).
17Published in Transactions on Machine Learning Research (10/2024)
J−
lτT,TJ+
lτT,T
J−
cτT,TJ+
cτT,T
J−
rτT,TJ+
rτT,T
lτTcτTrτTf1
f2
f3f4f
Figure 5: A representation of the four lines f1,...,f 4. By convexity, fis lower bounded by the blue solid
segments. Note that, since JlτT,T∩JcτT,T∩JrτT,T≠∅, thenf1,f2are nondecreasing and f3,f4nonincreasing.
Therefore, the minimum of the ycoordinates of the red dots is a lower bound on the value of the function,
which in turn implies equation 18.
By the convexity of f, for eachx∈[I−
τT,lτT]we havef(x)≥f1(x), for eachx∈[lτT,cτT]we havef(x)≥f2(x),
for eachx∈[cτT,rτT]we havef(x)≥f3(x), and for each x∈[rτT,I+
τT]we havef(x)≥f4(x). Writing down
explicitly these four inequalities and upper bounding, we conclude that
f(x⋆)≥ min
x′∈{lτT,cτT,rτT}J−
x,T
−2( max
x′∈{lτT,cτT,rτT}J+
x′,T− min
x′∈{lτT,cτT,rτT}J−
x′,T). (18)
Then, ifBτT≥4 maxt∈[T]bt, for allx∈{lτT,cτT,rτT}, we have
f(x)−f(x⋆)≤J+
x,T−f(x⋆)
equation 18≤J+
x,T− min
x′∈{lτT,cτT,rτT}J−
x,T
+2( max
x′∈{lτT,cτT,rτT}J+
x′,T− min
x′∈{lτT,cτT,rτT}J−
x′,T)
equation 17≤ 6 max
x′∈{lτT,cτT,rτT}∣Jx′,T∣≤6 max
x′∈{lτT,cτT,rτT}c
Bα
x′,T
equation 9≤ 6c
(BτT−2 maxt∈[T]bt
3)α≤6⋅3αc
(BτT/2)α
≤6⋅12α⋅c
(∑T
t=1bt)α≤12⋅(48
21/α−1)α
⋅c
(∑T
t=1bt)α.
If, on the other hand, BτT<4 maxt∈[T]bt, sinceBτT≥1
2∑T
t=1bt, then for all x∈{lτT,cτT,rτT}, we have
f(x)−f(x⋆)≤L∣I∣(3/4)≤L∣I∣(1/2)4maxt∈[T]bt
12maxt∈[T]bt
≤L∣I∣(1/2)BτT
12maxt∈[T]bt≤L∣I∣(1/2)∑T
t=1bt
24maxt∈[T]bt
=L∣I∣exp(−ln 2
24∑T
t=1bt
maxt∈[T]bt)
whereLthe Lipschitz constant of fon[lτT,rτT]. Thus, adding together the two bounds for BτT≥4maxt∈[T]bt
andBτT<4 maxt∈[T]btyields equation 1 when delT=◻◻◻◻andBτT≥∑τT−1
τ′=0Bτ′.
Finally, assume that delT=◻◻◻◻andBτT<∑τT−1
τ′=0Bτ′(i.e., the condition on Line 14 is true and we
recommend RTas in Line 15). Then the recommendation RTis the point with the best upper bound at the
18Published in Transactions on Machine Learning Research (10/2024)
end of the second-to-last epoch. Thus, proceeding as in the first part of the proof (case delT≠◻◻◻◻), we get
f(RT)−f(x⋆)=f(RtτT−1)−f(x⋆)
≤12(24
21/α−1)αc
(∑tτT−1
t=1bt)α
+9
8L∣I∣exp⎛
⎝−ln 2
24∑tτT−1
t=1bt
maxt∈[tτT−1]bt⎞
⎠
<12(48
21/α−1)αc
(∑T
t=1bt)α
+9
8L∣I∣exp(−ln 2
48∑T
t=1bt
maxt∈[T]bt)
whereLthe Lipschitz constant of fon[lτT,rτT]. Being the interval I, the timeTand the convex function f
arbitrarily chosen, the proof is complete.
B Full proof of Theorem 3.2
In this section, we give a detailed proof of Theorem 3.2.
Proof.Fix a nondegenerate bounded interval I⊂R. Fix also an horizon T∈N, a total budget B>0, and a
Lipschitz constant L>0. For eacht∈[T], definebt∶=B/T. We divide the proof in two cases, depending on
which of the two addends in equation 2 is the dominant term.
Assume first1
4⋅c
(∑T
t=1bt)α≥1
32e⋅L∣I∣exp(−∑T
t=1bt
maxt∈[T]bt). For allb>0, defineJ(b)∶=[−c/(2bα),c/(2bα)].
Consider the two alternative objective functions f+andf−, defined for all x∈I, by
f±(x)∶=±(1−2(x−I−)
∣I∣)⋅c
2Bα.
At each time t∈[T], if the algorithm chosen by the optimizer queried X1,...,Xt, the environment returns
the fuzzy evaluation Jt∶=J(BXt,t), where we recall that Bx,twas defined, for any x∈I, by∑t
s=1bsI{Xs=x}.
Note that the environment satisfies Assumption 2.1 and that both functions f±arec
∣I∣Bα-Lipschitz. Moreover,
the algorithm provides the same queries and recommendations for both f−andf+, as it receives the same
J1,...,JT. Furthermore, if the algorithm recommends RT≥(I−+I+)/2thenf−(RT)−infx∈If−(x)≥c/(2Bα),
while if the algorithm recommends RT<(I−+I+)/2thenf+(RT)−infx∈If+(x)≥c/(2Bα). Thus, in both
cases there exists ac
∣I∣Bα-Lipschitz convex function f∈{f−,f+}for which:
f(RT)−inf
x∈If(x)≥1
4⋅c
(∑T
t=1bt)α+1
32eL∣I∣e−∑T
t=1bt
maxt∈[T]bt.
Assume now1
4⋅c
(∑T
t=1bt)α<1
32e⋅L∣I∣exp(−∑T
t=1bt
maxt∈[T]bt). In this case, at each time t∈[T], the environment
returnsJt∶={f(Xt)}. Note that, in this instance, our problem reduces to deterministic convex optimization.
By a classic lower bound for deterministic convex optimization (see, e.g., Nesterov et al. 2018, Theorem 3.2.8),
then, there exists an L-Lipschitz convex function f∶I→Rfor which
f(RT)−inf
x∈If(x)>1
16eL∣I∣e−T=1
16eL∣I∣e−∑T
t=1bt
maxt∈[T]bt
≥1
4⋅c
(∑T
t=1bt)α+1
32eL∣I∣e−∑T
t=1bt
maxt∈[T]bt.
Being the interval I, the horizon T, the budget B, and the Lipschitz constant Larbitrarily chosen, the
theorem follows.
19Published in Transactions on Machine Learning Research (10/2024)
C Full proof of Theorem 4.2
In this section, we give a detailed proof of Theorem 4.2.
Proof.For the sake of simplicity, we assume that I∶=[0,1],fis continuous and admits a unique minimizer
x⋆∈[0,1](the other cases can be treated similarly). For each n∈N, letDn∶={k⋅2−n∣k∈Z}, let
D⋆
n∶={xn,1,...,xn,10}⊂Dnsuch that
xn,1<⋅⋅⋅<xn,5≤x⋆≤xn,6<⋅⋅⋅<xn,10
andxn,j+1−xn,j≤2−n, for allj∈[9]. Define D∶=⋃n∈[T]D⋆
n∩(0,1). Consider the “good event”
E∶=⋂
n,t∈[T]
j∈[10]{∣m(Yxn,j,1,...,Yxn,j,t)−f(xn,j)∣≤c(δ)
tα}
and note that ⋂t∈[T]{f(Xt)∈Jt}⊂E. By De Morgan’s laws, a union bound, and Assumption 4.1, we have
P[Ec]≤10T2δ. Now, if we are in the good event E, then Assumption 2.1 holds for all t∈[T], withc=c(δ)
andb1=⋅⋅⋅=bT=1, since ReSearch queries points only in D. To prove the last claim, consider the budget
version of ReSearch. Recall the observation (at the beginning of the proof in Appendix A) that the minimizer
x⋆offbelongs to all active intervals of ReSearch at all epochs. Assume by contradiction that there exists
an epochτ∈[τT]such that {lτ,cτ,rτ}is not included in D. Then, the set of query points {lτ,cτ,rτ}is not
included in D⋆
n∩(0,1)whenn=−log2((rτ−lτ)/2). Consider the case where rτ∉D⋆
n∩(0,1)andrτ>xn,10
(the other cases can be analyzed analogously). Since the leftmost point I−
τof the active interval of epoch τis
always bigger than or equal to rτ−4⋅2−n, then
x⋆≥I−
τ≥rτ−4⋅2−n≥xn,10+2−n−4⋅2−n=xn,7>xn,6≥x⋆
which yields a contradiction. It follows that, in the good event E(hence, with probability at least 1−10T2δ),
we can apply Theorem 3.1, obtaining the result.
D Missing details on Section 4.2
We now consider the minimization of a multivariate objective over a convex bounded subset I⊂Rd, where
Optimization Protocol 1 has bt=1for eachtand Assumption 2.1 holds. In this section, we refer to this
setting as Multivariate Budget Convex Optimization (MBCO) for the sake of emphasis. We assume the
objective to be µstrongly convex and β-smooth with 0<µ≤βi.e.,∀x,x0∈Rd
f(x)≥f(x0)+⟨∇f(x0),x−x0⟩+µ
2∥x−x0∥2
f(x)≤f(x0)+⟨∇f(x0),x−x0⟩+β
2∥x−x0∥2
where the first equation corresponds to the strong convexity and the second to the smoothness. For simplicity,
we further assume the existence of a unique minimizer6x∗∈int(I). As it will be apparent later, it is not
necessary to assume that x∗is in the interior of I: the entire analysis that follows holds if the objective is
Lipschitz, a condition that is implied by the strong convexity and smoothness. This cosmetic choice allows us
to replace the local Lipschitz constant appearing in equation 1 with β.
Before providing the detailed version of Theorem 4.3, let us provide some intuition on the bounds appearing
there. Given some budget ¯Tfor a line search subroutine, the bound of equation 1 scales roughly as 1/¯Tα,
which implies that the point recommended by ReSearch is at distance at most 1/¯Tα/2fromx∗due to strong
convexity. We denote with T(η)=⌈(4c1
µη2)1
α⌉the maximum number of iterations needed by ReSearch to find
6The existence of a unique minimizer is an easy consequence of the strong convexity of f.
20Published in Transactions on Machine Learning Research (10/2024)
anη-minimizer in a given epoch and by ¯K(T,η)∶=⌊T/T(η)⌋the corresponding minimum number of epochs
made by the algorithm with an overall budget of T(we have approximately K(T,η)≥¯K(T,η)with the
notation of Theorem 4.3).
Now, we state the detailed version of Theorem 4.3.
Theorem D.1. Let∆0∶=f(x0)−f(x∗),x∗be the unique minimizer, κ∶=β/µbe the condition number of f,
andΘ∶=max
i∈[d]∣Ik∣. Recallc1,c2,c3from Theorem 3.1. Suppose that α≥ln 2
48and
T≥max⎧⎪⎪⎨⎪⎪⎩(2dκβ)1
α,1
log(1−1
4dκ),2α
c3ln(α
c3),4α
c3ln(2α
c3)+2
c3ln(c2βΘdiam(I)
c1)⎫⎪⎪⎬⎪⎪⎭.
If the optimizer runs ReSearch for MBCO (Algorithm 5), then, its expected optimization error is upper
bounded by
(1−1
4dκ)¯K(T,η)
∆0+2dκβη2. (19)
Thus by setting η=(1
c(α)Tlog(1−1
4dκ)log(2dκβ
Tα))α
2
withc(α)=(µ/(4c1))1/α, the expected optimization error is
upper bounded by
2dκβ
Tα⎛
⎝∆0
(1−1
4dκ)+⎛
⎝1
c(α)log(1−1
4dκ)log(2dκβ
Tα)⎞
⎠α⎞
⎠. (20)
Proof of Theorem D.1. Takeα,µ,β,κ andΘas defined in Theorem D.1. Let gbe a univariate function
obtained by considering fon a segment I′ofI. We can upper bound the Lipschitz constant of the function g
using the global Lipschitz constant Loff, which, given that we are assuming that x⋆∈I○, can be further
upper bounded by β⋅diam(I). We start noticing that, assuming bt=1for alltandc=1, the bound of
equation 1 can be bounded from above by 2c1/Tαwhenever
T≥max{2α
c3ln(α
c3),4α
c3ln(2α
c3)+2
c3ln(c2LΘ
c1)}. (21)
Indeed,
c1
Tα≥c2LΘ exp(−c3T), (22)
is equivalent to
c1
c2LΘ≥Tαexp(−c3T).
Taking logs both sides and re-arranging this is equivalent to
T≥α
c3ln(T)+1
c3ln(c2LΘ
c1).
Now consider the case when c2LΘ≥c1, so that the second term on the right hand side is positive. Notice that
by hypothesis we have that α/c3≥1, so by Lemma A.2 from Appendix A of Shalev-Shwartz & Ben-David
(2014), by taking
T≥4α
c3ln(2α
c3)+2
c3ln(c2LΘ
c1),
21Published in Transactions on Machine Learning Research (10/2024)
equation 22 holds. On the other hand, if c2LΘ<c1, then the second term on the right hand side is negative
and we can solve the stronger inequality
T≥α
c3ln(T),
using Lemma A.1 from Appendix A of Shalev-Shwartz & Ben-David (2014). Thus by taking
T≥2α
c3ln(α
c3),
equation 22 holds.
Now letTany integer satisfying equation 21 and let denote with xTthe output of ReSearch after Titerations.
Notice that for any function gas described above, by the strong convexity of git holds that
∣xT−x∗∣≤√
2
µ(g(xT)−g∗)≤2√c1
µTα.
Let0<η≤Θ, ifT(η)=⌈(4c1
µη2)1
α⌉, then it follows that the point xTfound by ReSearch satisfies ∣xT−x∗∣≤η.
Now letfbe a multi-variate function satisfying the assumption of Theorem D.1. Notice that any restriction
fkoffalong a coordinate line k, will also satisfies the same assumptions over the interval Ik(see line 3 of
Algorithm 5).
The analysis of Jamieson et al. (2012) applies to our case and they show that after kepochs of coordinate
descend, the expected optimization error of the current iterate is bounded above by
(1−1
4dκ)k
∆0+2dκβη2.
Recalling that T(η)is the worst-case number of iterations required by ReSearch to find an η-optimizer, and
if we are given a total budget of T, the number of epochs made by equation 5 is at least ¯K(T,η)=⌊T/T(η)⌋.
From this we get the bound of equation 19. Now we set
η=⎛
⎝2
c(α)Tlog(1−1
4dκ)log(2dκβ
Tα)⎞
⎠α
2
,
whitc(α)=(µ/(4c1))1/α, and notice that if T>max{1/(log(1−1/(4dκ))),(2dκβ)1/α}, thenT(η)≤
2(4c1/(µη2))1/α>1/2. Thus, the following holds
¯K(T,η)=⌊T/T(η)⌋≥T/T(η)−1≥T
2(4c1
µη2)1
α−1=T
2(µ
4c1)1
α
η2
α−1
=⎛
⎝1
log(1−1
4dκ)log(2dκβ
Tα)⎞
⎠−1.
Replacing this into equation 19
(1−1
4dκ)¯K(T,η)
∆0+2dκβη2
≤2dκβ
Tα
(1−1
4dκ)∆0+2dκβ⎛
⎝1
c(α)Tlog(1−1
4dκ)log(2dκβ
Tα)⎞
⎠α
=2dκβ
Tα⎛
⎝∆0
(1−1
4dκ)+⎛
⎝1
c(α)log(1−1
4dκ)log(2dκβ
Tα)⎞
⎠α⎞
⎠,
22Published in Transactions on Machine Learning Research (10/2024)
we obtain equation 20.
In the following we also present a generalization of the above theorem to arbitrary budgets bt,α>0andc.
In the context of the next theorem B(η)(defined in the proof) is meant to be the worst case total budget
required to find an η-optimizer at a given epoch, BTis the total budget and ¯K(T,η)=⌊BT/B(η)⌋.
Theorem D.2. Let∆0∶=f(x0)−f(x∗),x∗be the unique minimizer, κ∶=β/µbe the condition number of f,
andΘ∶=max
i∈[d]∣Ik∣. Recallc1,c2,c3from Theorem 3.1. Let b∗
T=maxt∈[T]btandBT=∑T
t=1bt. Suppose that
BT≥max{(2dκβ)1
α,2αb∗
T
c3ln(αb∗
T
c3),4 max{αb∗
T
c3,1}ln(2 max{αb∗
T
c3,1})+2b∗
T
c3ln(c2βΘdiam(I)
c1c)}.
If the optimizer runs ReSearch for MBCO (Algorithm 5), then, its expected optimization error is upper
bounded by
(1−1
4dκ)¯K(T,η)
∆0+2dκβη2. (23)
Thus by setting
η=⎛
⎜⎜⎜⎜⎜⎜
⎝1
c(α)BTlog⎡⎢⎢⎢⎢⎣(1−1
4dκ)(Bα
T
2κβd)b∗
T
BT⎤⎥⎥⎥⎥⎦log(2dκβ
Bα
T)⎞
⎟⎟⎟⎟⎟⎟
⎠α
2
withc(α)=(µ/(4c1c))1/α, ifη>07, the expected optimization error is upper bounded by
2dκβ
Bα
T⎛
⎜⎜⎜⎜⎜⎜
⎝∆0
(1−1
4dκ)+⎛
⎜⎜⎜⎜⎜⎜
⎝1
c(α)log⎡⎢⎢⎢⎢⎣(1−1
4dκ)(Bα
T
2κβd)b∗
T
BT⎤⎥⎥⎥⎥⎦log(2dκβ
Bα
T)⎞
⎟⎟⎟⎟⎟⎟
⎠α⎞
⎟⎟⎟⎟⎟⎟
⎠. (24)
Proof of Theorem D.2. Takeα,µ,β,κ andΘas defined in Theorem D.2. Let gbe a univariate function
obtained by considering fon a segment I′ofI. We can upper bound the Lipschitz constant of the function g
using the global Lipschitz constant Loff, which, given that we are assuming that x⋆∈I○, can be further
upper bounded by β⋅diam(I). We start noticing that, using b∗
T=maxt∈[T]bt, the bound of equation 1 can
be bounded from above by 2c1c/(∑T
t=1bt)αwhenever
T
∑
t=1bt≥max{2αb∗
T
c3ln(αb∗
T
c3),4 max{αb∗
T
c3,1}ln(2 max{αb∗
T
c3,1})+2b∗
T
c3ln(c2LΘ
c1c)}.(25)
Indeed,
c1c
(∑T
t=1bt)α≥c2LΘ exp(−c3∑T
t=1bt
b∗
T), (26)
is equivalent to
c1c
c2LΘ≥(T
∑
t=1bt)α
exp(−c3∑T
t=1bt
b∗
T).
7At a high level, note that η>0whenever the total budget BTis large compared to b∗
T.
23Published in Transactions on Machine Learning Research (10/2024)
Taking logs both sides and re-arranging this is equivalent to
T
∑
t=1bt≥αb∗
T
c3ln(T
∑
t=1bt)+b∗
T
c3ln(c2LΘ
c1c).
Now consider the case when c2LΘ≥c1c, so that the second term on the right hand side is positive. So by
Lemma A.2 from Appendix A of Shalev-Shwartz & Ben-David (2014), by taking
T
∑
t=1bt≥4 max{αb∗
T
c3,1}ln(2 max{αb∗
T
c3,1})+2b∗
T
c3ln(c2LΘ
c1c),
equation 26 holds. On the other hand, if c2LΘ<c1c, then the second term on the right hand side is negative
and we can solve the stronger inequality
T
∑
t=1bt≥αb∗
T
c3ln(T
∑
t=1bt),
using Lemma A.1 from Appendix A of Shalev-Shwartz & Ben-David (2014). Thus by taking
T
∑
t=1bt≥2αb∗
T
c3ln(αb∗
T
c3),
equation 26 holds.
Now let (bt)T
t=1any sequence satisfying equation 25 and let denote with xTthe output of ReSearch after T
iterations. Notice that for any function gas described above, by the strong convexity of git holds that
∣xT−x∗∣≤√
2
µ(g(xT)−g∗)≤2⌟roo⟪⟪op
⌟roo⟪mo⟨⌟roo⟪mo⟨⌟roo⟪⟨o⟪c1c
µ(∑T
t=1bt)α.
Let0<η≤Θ, and define B(η)=∑T(η)
t=1btwithT(η)the first natural number s.t. ∑T(η)
t=1bt≥(4c1c
µη2)1
α, then it
follows that the point xTfound by ReSearch satisfies ∣xT−x∗∣≤η. Now letfbe a multi-variate function
satisfying the assumption of Theorem D.2. Notice that any restriction fkoffalong a coordinate line k, will
also satisfies the same assumptions over the interval Ik(see line 3 of Algorithm 5).
The analysis of Jamieson et al. (2012) applies to our case and they show that after kepochs of coordinate
descend, the expected optimization error of the current iterate is bounded above by
(1−1
4dκ)k
∆0+2dκβη2.
Recalling that B(η)is the worst-case number budget required by ReSearch to find an η-optimizer, and
if we are given a total budget of BT, the number of epochs made by Line 1 of Algorithm 5 is at least
¯K(T,η)=⌊BT/B(η)⌋. From this we get the bound of equation 23. Now notice that
B(η)∈[(4c1c
µη2)1
α
,(4c1c
µη2)1
α
+b∗
T)
and that
η=⎛
⎜⎜⎜⎜⎜⎜
⎝1
c(α)BTlog⎡⎢⎢⎢⎢⎣(1−1
4dκ)(Bα
T
2κβd)b∗
T
BT⎤⎥⎥⎥⎥⎦log(2dκβ
Bα
T)⎞
⎟⎟⎟⎟⎟⎟
⎠α
2
,
24Published in Transactions on Machine Learning Research (10/2024)
withc(α)=(µ/(4c1c))1/αimplies the following
¯K(T,η)=⌊BT/B(η)⌋≥BT/B(η)−1=BT
(4r∗c1c
µη2)1
α+b∗
T−1
=⎛
⎝1
log(1−1
4dκ)log(2dκβ
Bα
T)⎞
⎠−1.
Replacing this into equation 23
(1−1
4dκ)¯K(T,η)
∆0+2dκβη2
≤2dκβ
Bα
T
(1−1
4dκ)∆0+2dκβ⎛
⎜⎜⎜⎜⎜⎜
⎝1
c(α)BTlog⎡⎢⎢⎢⎢⎣(1−1
4dκ)(Bα
T
2κβd)b∗
T
BT⎤⎥⎥⎥⎥⎦log(2dκβ
Bα
T)⎞
⎟⎟⎟⎟⎟⎟
⎠α
=2dκβ
Bα
T⎛
⎜⎜⎜⎜⎜⎜
⎝∆0
(1−1
4dκ)+⎛
⎜⎜⎜⎜⎜⎜
⎝1
c(α)log⎡⎢⎢⎢⎢⎣(1−1
4dκ)(Bα
T
2κβd)b∗
T
BT⎤⎥⎥⎥⎥⎦log(2dκβ
Bα
T)⎞
⎟⎟⎟⎟⎟⎟
⎠α⎞
⎟⎟⎟⎟⎟⎟
⎠,
we obtain equation 24. Notice finally that to make the above bound valid, it has to be BT≥(2dκβ)1/α.
E Adaptive Lipschitz constants
This experiment aims to show the advantages of featuring the local Lipschitz constant, as given in Theorem
3.1, over a bound that uses the global constant. To this end, we optimize the function f(x)=−√x+1over
the interval (a,1)witha>0. The Lipschitz constant of fgrows roughly as 1/√a. Moreover, f(x∗)=0and
the maximum value is smaller than 1, thus any meaningful upper bound on the optimization error should be
smaller than 1. In the experiment we set a=0.001,c=0.1,α=1(Assumption 2.1), bt=1(for allt), and we
let the intervals Jtto be symmetric around f(x)for a query at xat timet. We run ReSearch for T=1000
iterations.
Figure 6 shows that the upper bound featuring the local Lipschitz constants (local) is much tighter than that
featuring the global constant (global). In particular, as denoted by the vertical lines, the former falls below 1
after 84 iterations, while the latter becomes non-trivial only at iteration 339.
25Published in Transactions on Machine Learning Research (10/2024)
0 100 200 300 400 500 600 700 800 900 1000
t101
100101102upper bound (85,1.0)(85,33.16)
(339,0.18)(339,1.0)local
global
Figure 6: The vertical green line raises at the first point where the local curve falls below 1; the red line
raises at the first point where the global curve falls below 1.
26