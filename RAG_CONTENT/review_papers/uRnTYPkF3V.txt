Sequential Probability Assignment with Contexts:
Minimax Regret, Contextual Shtarkov Sums, and
Contextual Normalized Maximum Likelihood
Ziyi Liu
University of Toronto & Vector Institute
kevind.liu@mail.utoronto.caIdan Attias
Ben-Gurion University & Vector Institute
idanatti@post.bgu.ac.il
Daniel M. Roy
University of Toronto & Vector Institute
daniel.roy@utoronto.ca
Abstract
We study the fundamental problem of sequential probability assignment, also
known as online learning with logarithmic loss, with respect to an arbitrary, pos-
sibly nonparametric hypothesis class. Our goal is to obtain a complexity measure
for the hypothesis class that characterizes the minimax regret and to determine
a general, minimax optimal algorithm. Notably, the sequential ℓ∞entropy, ex-
tensively studied in the literature (Rakhlin and Sridharan, 2015, Bilodeau et al.,
2020, Wu et al., 2023), was shown to not characterize minimax regret in general.
Inspired by the seminal work of Shtarkov (1987) and Rakhlin, Sridharan, and
Tewari (2010), we introduce a novel complexity measure, the contextual Shtarkov
sum, corresponding to the Shtarkov sum after projection onto a multiary context
tree, and show that the worst case log contextual Shtarkov sum equals the mini-
max regret. Using the contextual Shtarkov sum, we derive the minimax optimal
strategy, dubbed contextual Normalized Maximum Likelihood (cNML). Our re-
sults hold for sequential experts, beyond binary labels, which are settings rarely
considered in prior work. To illustrate the utility of this characterization, we pro-
vide a short proof of a new regret upper bound in terms of sequential ℓ∞entropy,
unifying and sharpening state-of-the-art bounds by Bilodeau et al. (2020) and Wu
et al. (2023).
1 Introduction
Sequential probability assignment is a fundamental problem with connections to information theory
[Ris84; MF98; XB00], machine learning [CL06; V ov95; RST15; FKLMS18; Sha20], and portfolio
optimization [Kel56; Cov74; Cov91; CO96; Fed91]. In the original non-contextual setup, the learner
aims to assign probabilities to a series of labels, which are revealed sequentially. The goal is to offer
probabilistic forecasts over the label set such that the probability assigned to any observed sequence
is comparable to that assigned by the best model in any fixed class of models.
The celebrated work of Shtarkov [Sht87] characterized minimax regret for context-free sequential
probability assignment in terms of what is now known as the Shtarkov sum , and subsequently de-
scribed the minimax algorithm, Normalized Maximum Likelihood (NML). NML represents the ideal
probabilistic forecast in the sense of minimax regret, providing a benchmark for universal coding
and prediction strategies. While often not used directly due to its computational complexity, NML
has guided the design of practical algorithms and informed the development of efficient approxima-
38th Conference on Neural Information Processing Systems (NeurIPS 2024).tion methods. The principles underlying NML have inspired advances in both information theory
and online learning, establishing fundamental limits and serving as a critical benchmark.
In this work, we study the problem of sequential probability assignment with contexts, which
has been analyzed in recent works (e.g. [RS15; BFR20; WHGS23]) under the framework of on-
line supervised learning formalized by Rakhlin, Sridharan, and Tewari [RST10]. In this setup,
the problem is modeled as a T-round game between a learner and the nature : On each round
t= 1, . . . , T , the learner observes a context xtfrom nature and predicts a distribution ˆptover some
finite label space Y. Then nature reveals a label yt∈ Y and the learner incurs a logarithmic loss
ℓ(ˆpt, yt) =−log(ˆpt(yt)), where ˆpt(yt)is the probability assigned to label ytbyˆpt. The perfor-
mance of the learner is measured by the regret with respect to a class Fofexperts , defined as the
difference between the total loss of the learner and that of the best expert in F. The value of primary
interest is the minimax regret , that is, the worst-case regret by the best learner over arbitrarily adap-
tive data sequences. The minimax regret serves as a benchmark for all algorithms and as a target for
studies of adaptivity. Our goal is to address several fundamental questions:
Can we find a natural complexity measure of Fthat characterizes the minimax regret, enabling us
to analyze the minimax regret in new ways? And can we identify, in view of this complexity
measure, a general, minimax optimal algorithm?
Notably, the sequential covering number of F, a well studied measure of complexity, has been
shown not to characterize the minimax regret on its own [RS15; BFR20; WHGS23]. This fact
distinguishes sequential probability assignment and log loss: while sequential covering numbers
enable a tight analysis in online learning problems with convex Lipschitz losses, like absolute loss
[RST15] and square loss [RS14a], they do not yield minimax rates for log loss on some classes.
Tackling such classes evidently requires new techniques.
Main contributions.
1. We introduce a new complexity measure, which we call the contextual Shtarkov sum , that serves
as a natural generalization of the Shtarkov sum from the context-free setting. We show that the
minimax regret is characterized by the worst-case contextual Shtarkov sum.
2. We derive the minimax optimal algorithm, dubbed contextual Normalized Maximum Likelihood
(cNML), using a data-dependent variant of the contextual Shtarkov sum, thereby generalizing
NML from the context-free setting.
3. We apply contextual Shtarkov sums to the study of sequential entropy bounds on minimax.
Doing so, we provide a short proof of a new regret upper bound in terms of sequential entropy
that unifies and even improves on state-of-the-arts bounds by [BFR20] and [WHGS23]. Our
results extend beyond the binary label setting studied by recent work to arbitrary finite label sets.
Related work. Sequential probability assignment has been studied extensively. Various aspects
of this problem have been investigated, including sequences with and without side information
(contexts), parametric and nonparametric hypothesis classes, and stochastic or adversarial data-
generating mechanisms. This problem has a long history in the machine learning community, see
[CL06, Ch. 9] and the references therein. In the information theory community, this problem is also
known as universal prediction [MF98], where the regret is also referred to as redundancy with respect
to a set of codes. This has been studied in both stochastic and adversarial settings [Fre96; Ris86;
Ris96; Sht87; XB97; DS04; MF98; OS04; Sha06; Szp98], where the focus was primarily on the
parametric classes of experts. Closely related topics include universal source coding [Kol65; Sol64;
Fit66; Dav73], data compression with arithmetic coding [Ris76; RL81; ZL77; ZL78; FMG92], and
the minimum description length (MDL) principle [Ris78; Ris84; Ris87; BRY98; Grü05; HY01].
Lastly, this topic is intimately tied with sequential gambling and portfolio optimization, as pointed
out by [Kel56; Cov74; Cov91; CO96; Fed91].
A classical result in context-free sequential probability assignment is that the minimax regret is
equal to the log contextual Shtarkov sum [Sht87], and the minimax algorithm is the well-known
Normalized Maximum Likelihood. When the set of contexts is known in advance to the forecaster,
namely, a fixed design setting, the minimax regret is equivalent to the log Shtarkov sum of the
function class when projected onto the known set of contexts [JSS21; WHGS23].
2A long line of work has focused on controlling minimax regret for rich classes in terms of covering
numbers. [CL99; OH99] upper bounded the regret in terms of the (non-sequential) uniform covering
number of the class. However, this complexity measure proved to be insufficient for obtaining
optimal rates. [RS15] improved regret upper bounds by proposing a sequential covering measure.
Thereafter, by utilizing the self-concordance property and the curvature of the log loss, [BFR20]
further improved the upper bound in terms of the sequential covering number for nonparametric
Lipschitz classes, through a non-constructive proof. [WHGS23] proposed a Bayesian algorithmic
approach in order to upper bound the regret using a global notion of sequential covering. Notably,
both the global and local sequential covering numbers do not fully characterize the regret, and the
algorithm in [WHGS23] is not minimax optimal. By relaxing the worst-case analysis, [BHS23]
studied this problem within the smoothed analysis framework, where nature is not fully adversarial
but constrained.
Online learning with respect to arbitrary hypothesis classes and the zero-one loss, in the realizable
case, is known to be characterized by the Littlestone dimension [Lit88]. The agnostic case was ad-
dressed by [BPS09; ABDMNY21]. Understanding sequential complexities in online learning with
Lipschitz losses was extensively studied by [RST10; RS14a; RS14b; RST15]. Note that the logarith-
mic loss is neither Lipschitz nor bounded. Recently, [AHKKV23] characterized online regression
in the realizable case, for any approximate pseudo-metric, such as the ℓploss.
2 Preliminaries
Notation. For a positive integer K, let[K] :={1,2, . . . , K }. For a finite set Kwith|K|=K, we
use∆(K)to denote the set of all distributions on K. We may identify Kwith[K](under arbitrary
enumeration of elements in K) and treat elements of ∆(K)as vectors in RK. For a vector p∈RK
andi∈[K], letp(i)be the i-th coordinate of p. Let ∆+(K) ={p∈∆(K) :p(k)>0,∀k∈ K} .
For a general finite sequence (ai)N
i=1, we will use an:mto denote the sub-sequence (an, . . . , a m)for
anyn≤mand the empty sequence for n > m . For any set A, letA∗=∪k≥0Akbe the set of all
finite length sequences over A.
Sequential probability assignment and minimax regret. LetXbe the context space and Ybe
the finite label space. In each round t∈[T]during the game of sequential probability assignment,
the learner receives a context xt∈ X from nature and assigns a probability distribution ˆpt∈∆(Y)to
the possible labels. Then nature reveals the true label yt∈ Y and the learner incurs a loss ℓ(ˆpt, yt) =
−log(ˆpt(yt)). Throughout, the learner is required to predict nearly as well as the best expert from
an expert class, which is modeled as an arbitrary hypothesis class F ⊆ { (X × Y )∗× X → ∆(Y)}.
More formally, the goal of the learner is make their regret with respect to F,
RT(F; ˆp1:T, x1:T, y1:T) =TX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(f(x1:t, y1:t−1), yt),
as small as possible for all sequences xandygenerated by nature, possibly in an adversarial manner.
Here f(x1:t, y1:t−1)∈∆(Y)can be understood as the prediction made by expert fat round tusing
past observations (x1:t−1, y1:t−1)as well as the fresh context xt. The main focus is to study the
minimax regret RT(F), which can be written as the following extensive form
RT(F) = sup
x1inf
ˆp1sup
y1···sup
xTinf
ˆpTsup
yTRT(F; ˆp1:T, x1:T, y1:T),
where xt∈ X,ˆpt∈∆(Y)andyt∈ Y,∀t∈[T]. In light of this formulation, we can see that the
minimax regret concerns both the learner and the nature to be adaptive , meaning that their actions
can rely on the revealed history so far.
Remark 2.1 (Sequential vs non-sequential experts) Experts fas mappings from (X ×Y )∗×X to
∆(Y)are sometimes called fully sequential experts [WHGS23] due to their ability to predict based
on the past history. However, the literature (e.g. [RS15; BFR20; WHGS23]) often considers the
more limited notion of non-sequential experts, modeled as F ⊆ {X → ∆(Y)}, reflecting the fact
that prediction made by each expert fis simply f(xt)in each round t. In contrast, our results are
more general as our novel techniques can be applied to the more flexible sequential experts.
3Multiary trees. The complexity of online learning problems stems from the sequential and adap-
tive nature of the adversary, which we can capture with multiary trees . Formally, for a general
space Aand a finite set K, anA-valued K-ary tree vof depth dis a sequence of mappings
vt:Kt−1→ A fort∈[d]. A path in a depth- dtree is a sequence ε= (ε1, . . . , ε d)∈ Kd.
We use the notation vt(ε)to denote vt(ε1, . . . , ε t−1)fort∈[d]and the boldface notation v(ε)to
denote (v1(ε), . . . , vd(ε))∈ Ad. Throughout we will only consider Y-ary trees valued in either X
or∆(Y), where the paths are denoted by the boldface y. We refer to X-valued trees as context trees
and∆(Y)-valued trees as probabilistic trees .
Time-varying context sets. So far we consider the context set Xto be constant over time. But
all of our results can be extended easily to allow for time-varying context spaces. Details of this
generalization can be found in Appendix C.
2.1 Prior work: the Shtarkov sum in context-free and fixed designs
Before introducing our complexity measure that characterizes RT(F), we review some prior set-
tings where the minimax regret can be characterized by the well-studied Shtarkov sum . First we
introduce the notion of likelihood of a hypothesis fwith respect to a context and label sequence,
which plays a key role in defining complexity measures and optimal algorithms.
Definition 2.2 (Likelihood) Forf: (X × Y )∗× X → ∆(Y)and length −dsequences x1:d∈
Xd, y1:d∈ Yd, the likelihood Pf(y1:d|x1:d)is defined as
Pf(y1:d|x1:d) =dY
t=1f(x1:t, y1:t−1)(yt),
where we use the compact notation f(x1:t, y1:t−1)forf(x1, y1, . . . , x t−1, yt−1, xt).
In the classical context-free setting where Xcan be thought of as a singleton, any sequential expert
fdegenerates to a joint distribution over label sequences. Indeed, given any label sequence y1:t−1,
f(y1:t−1)∈∆(Y)can be interpreted as the conditional distribution fassigns to the next label yt.
We use Pf(y1:d) =Qd
t=1f(y1:t−1)(yt)to denote this distribution. Similarly, the learner’s strategy
is also specified by a joint distribution that is decomposed to a sequence of conditional distributions
ˆpt= ˆpt(·|y1:t−1)∈∆(Y). In this setup the minimax regret RT(F)is characterized by the Shtarkov
sum [Sht87].
Proposition 2.3 ([Sht87]) In the context-free setting, for any hypothesis class Fand horizon T, the
Shtarkov sum ST(F)is defined as
ST(F) =X
y1:T∈YTsup
f∈FPf(y1:T).
Moreover, the minimax regret is given by RT(F) = log ST(F), and the unique minimax optimal
strategy is the normalized maximum likelihood (NML) distribution given by
pnml(y1:T) =supf∈FPf(y1:T)P
y′
1:T∈YTsupf∈FPf(y′
1:T),∀y1:T∈ YT.
To go beyond this classical context-agnostic setting and incorporate contextual information, prior
work (e.g. [JSS21]) also considered an easier problem than the aforementioned sequential probabil-
ity assignment, by forcing nature to reveal the context sequence x1:Tto the learner at the start of the
game. This is known as the fixed design setting or transductive online learning [WHGS23], where
the goal is to characterize the so-called fixed design maximal minimax regret
RFD
T(F) := sup
x1:T∈XTinf
ˆp1sup
y1···inf
ˆpTsup
yTRT(F; ˆp1:T, x1:T, y1:T).
It is straightforward to see that after projecting on x1:T, the hypothesis class Fagain collapses to a
set of joint distributions over YTspecified by the likelihood function in Definition 2.2. Moreover,
this set of distributions can be accessed by the learner from the start, so the fixed design setting can
4be essentially reduced to the context-free setting. To be more specific, for any f∈ F, it induces an
expert in the context-free setting after being projected on x1:T, which is denoted by f|x1:Tand
f|x1:T(y1:t−1) :=f(x1:t, y1:t−1)∈∆(Y),∀t∈[T], y1:t−1∈ Yt−1,
and let F|x1:T:={f|x1:T:f∈ F} . Then given any predetermined x1:T, the learner is equivalently
competing with F|x1:Tin the context-free setting. With the following natural variant of the Shtarkov
sum, we can easily characterize RFD
T(F).
Definition 2.4 (Conditional Shtarkov sum) Given a context sequence x1:T∈ XT, the Shtarkov
sum of Fconditioned on x1:Tis
ST(F|x1:T) :=X
y1:T∈YTsup
f∈FPf(y1:T|x1:T).
In fact, ST(F|x1:T)is just the Shtarkov sum of the projected class F|x1:Tin the context-free setting.
The following result characterizes the fixed-design setting:
Proposition 2.5 (Minimax regret, fixed design [JSS21]) In the fixed design setting, for any hy-
pothesis class Fand horizon T, the fixed design maximal minimax regret is
RFD
T(F) = sup
x1:T∈XTlogST(F|x1:T),
and, given any context sequence x1:T, the minimax optimal response is NML with respect to F|x1:T.
3 Minimax regret via contextual Shtarkov sum
Now we state one of our main results about the characterization of the minimax regret of sequential
probability assignment. First we introduce the key concept of contextual Shtarkov sum , which is a
natural generalization of Shtarkov sum in the context-free setting.
Definition 3.1 (Contextual Shtarkov sum) Thecontextual Shtarkov sum ST(F|x)of a hypothesis
classFon a given context tree xof depth Tis defined as
ST(F|x) :=X
y∈YTsup
f∈FPf(y|x(y)).
Just like the conditional Shtarkov sum, the contextual Shtarkov sum ST(F|x)can be interpreted as
the Shtarkov sum of the projected class F|x:={f|x:f∈ F} where f|xis the induced context-free
expert specified by
f|x(y1:t−1) :=f(x(y1:t−1), y1:t−1)∈∆(Y),∀t∈[T], y1:t−1∈ Yt−1,
where we have slightly abused the notation to use x(y1:t−1)to denote the length- tcontext sequence
obtained by tracing tree xthrough the (partial) path y1:t−1. Next we show that the minimax regret
RT(F)is characterized by the worst-case contextual Shtarkov sum:
Theorem 3.2 (Main result: minimax regret) For any hypothesis class F ⊆ { (X × Y )∗× X →
∆(Y)}and horizon T,
RT(F) = sup
xlogST(F|x),
where the supremum is taken over all X-valued context trees xof depth T.
Since any context sequence x1:Tcan be thought as a special context tree xthat is constant in
each level t∈[T](i.e.,xt(y) =xt,∀y), we can find that the supremum over context trees in
Theorem 3.2 strictly subsumes the supremum over context sequences in Proposition 2.5. Thus we
can see the separation between RT(F)andRFD
T(F)is clearly exhibited.
The full proof of Theorem 3.2 as well as an overview are provided in Appendix A.
53.1 Applications: an improved regret upper bound in terms of sequential entropy
To illustrate the utility of our characterization in Theorem 3.2, we walk through some examples
where we are able to recover and sharpen existing regret upper bounds with relatively short proofs
via contextual Shtarkov sum. As a start, we provide a short proof in Appendix A.6 of the classical
regret bound for a finite hypothesis class.
Proposition 3.3 (Finite classes) For any F ⊆[0,1]Xand horizon T,RT(F)≤log|F|.
Let us go back to the binary label setting with non-sequential experts, that is, Y={0,1}and
F ⊆ [0,1]X, and f(x)∈[0,1]is interpreted as the probability assigned to label 1by this expert f.
We will show a regret bound that outperforms the state-of-the-art ones in [BFR20; WHGS23] with
a surprisingly simple proof. To proceed, we need the following notation. Given a context tree xof
depth T, letF ◦x={f◦x:f∈ F} , where f◦xis the [0,1]-valued tree such that
(f◦x)t(y) =f(xt(y)),∀y∈ YT.
Next we introduce the definitions of sequential ℓ∞covers and entropy.
Definition 3.4 (Sequential ℓ∞cover and entropy) Given a hypothesis class F ⊆ [0,1]Xand a
context tree xof depth T, we say a collection of R-valued trees Vx,αis a sequential cover of F ◦x
at scale α >0if for any f∈ F,y∈ YT, there exists some v∈Vx,αsuch that
|f(xt(y))−vt(y)| ≤α,∀t∈[T].
Let the sequential ℓ∞covering number N∞(F ◦x, α, T )be the size of the smallest such cover. The
sequential ℓ∞entropy of Fat scale αand depth Tis defined as the logarithm of the worst-case
sequential covering number: H∞(F, α, T ) := supxlogN∞(F ◦x, α, T ).
Definition 3.5 (Global sequential ℓ∞cover and entropy) Given a hypothesis class F ⊆ [0,1]X,
we say a collection of mappings Gα⊆[0,1]X∗is aglobal sequential cover of Fat scale α >0and
depth Tif for any f∈ F, x1:T∈ XT, there exists some g∈ Gαsuch that
|f(xt)−g(x1:t)| ≤α,∀t∈[T].
Let the global sequential ℓ∞covering number NG(F, α, T )be the size of the smallest such cover.
Theglobal sequential ℓ∞entropy of Fat scale αand depth Tis defined as
HG(F, α, T ) := log NG(F, α, T ).
Proposition 3.6 ([BFR20; WHGS23]) For any F ⊆[0,1]Xand horizon T,
RT(F)≤min
inf
α>0
4Tα+cH∞(F, α, T )	
| {z }
[BFR20],inf
α>0
Tlog(1 + 2 α) +HG(F, α, T )	
| {z }
[WHGS23]
,
where c=2−log(2)
log(3)−log(2)∈(3,4).
It is easy to show that H∞(F, α, T )≤ H G(F, α, T ), but, in general, the two bounds in Propo-
sition 3.6 are incomparable due to constants and different dependence on α(more discussions on
these bounds are deferred to Appendix C). Starting from the contextual Shtarkov sum, we are able
to derive a bound that combines the best of these two bounds:
Theorem 3.7 (Main result: sequential entropy bound) For any F ⊆[0,1]Xand horizon T,
RT(F)≤inf
α>0n
Tlog(1 + 2 α) +H∞(F, α, T )o
.
6Proof For any scale α >0and depth- Tcontext tree x, letVx,αbe a sequential cover of F ◦xat
scale αwith size N∞(F ◦x, α, T ). We can always assume Vx,αto be [0,1]-valued without loss of
generality because otherwise we can just truncate it without violating its coverage guarantee. Define
the smoothed covering set ˜Vx,α=n
˜v:∀t∈[T],˜vt(·) =vt(·)+α
1+2α, v∈Vx,αo
, inspired by [BFR23;
WHGS23]. Then for any f∈ F,y∈ YT, there exists some v∈Vx,αsuch that |f(xt(y))−vt(y)| ≤
α,∀t∈[T]and hence ˜vsatisfies
f(xt(y))
˜vt(y)≤1 + 2 α,1−f(xt(y))
1−˜vt(y)≤1 + 2 α.
Hence
Pf(y|x(y)) =TY
t=1f(xt(y))yt(1−f(xt(y)))1−yt≤(1 + 2 α)TTY
t=1˜vt(y)yt(1−˜vt(y))1−yt,
and
X
ysup
f∈FPf(y|x(y))≤(1 + 2 α)TX
ysup
˜v∈˜Vx,αTY
t=1˜vt(y)yt(1−˜vt(y))1−yt
≤(1 + 2 α)TX
˜v∈˜Vx,αX
yTY
t=1˜vt(y)yt(1−˜vt(y))1−yt= (1 + 2 α)T|˜Vx,α|,
where the last equality follows from Lemma D.1, treating ˜vas sequential experts. Finally,
RT(F) = sup
xlog X
ysup
f∈FPf(y|x(y))!
≤sup
xlog
(1 + 2 α)T|˜Vx,α|
=Tlog(1 + 2 α) +H∞(F, α, T ).
Since our choice of αis arbitrary, the result follows. ■
3.2 The inadequacy of sequential ℓ∞covering number
We conclude this section with a discussion on the suboptimality of regret bounds based on sequential
covering numbers as in Proposition 3.6 and Theorem 3.7. Let us consider the binary label setting
and the following hypothesis classes over the unit Hilbert ball X=B2:
FLin:=
x7→⟨w, x⟩+ 1
2:w∈B2
,FAbsLin:={x7→ |⟨w, x⟩|:w∈B2}. (1)
We can see that the sequential ℓ∞covering numbers of FLinandFAbsLinare of the same order
for all scales, thus the aforementioned results will yield the same regret bound for these two classes.
However, we have RT(FLin) =˜O(√
T)whileRT(FAbsLin) =˜Θ(T2/3)[RS15; WHGS23], which
implies that the sequential ℓ∞covering number, in its current form within the regret bound, cannot
characterize the minimax regret.
It is worth mentioning that an ˜Ω(√
T)lower bound on RT(FLin)is achievable, via an ˜Ω(1/α2)
lower bound on the sequential fat-shattering dimension sfatα(FLin)combined with Proposition 2
in [WHGS23]. The same lower bound also holds in the finite-dimensional case, where B2is a unit
d-dimensional Euclidean ball with d≥√
T[WHGS23, Footnote 6]. Our proof (Appendix A.7) of
the next result works in both the infinite and finite dimensional (with d≥T) cases.
Lemma 3.8 ( Ω(√
T)lower bound for the linear class FLin)ForFLindefined as in Eq. (1)with
B2being the unit Hilbert ball or the unit d-dimensional Euclidean ball with d≥T, then
RT(FLin)≥ RFD
T(FLin)≥√
T/4.
The proof of Lemma 3.8 is based on lower bounding the conditional Shtarkov sums (and hence the
contextual Shtarkov sums) of FLin. From Theorem 3.2 we know that the ˜O(√
T)upper bound holds
for the log of contextual Shtarkov sums as well but we do not have a direct proof of this fact so far.
7Algorithm 1 Contextual Normalized Maximum Likelihood (cNML)
Input: Hypothesis class F, horizon T
Fort= 1,2, ..., T do
1. Observe context xt∈ X
2. If supf∈FPf(y1:t−1|x1:t−1)>0, predict ˆpt∈∆(Y)with
ˆpt(y) =supxSx1:t,(y1:t−1,y)
T (F|x)
P
y′∈YsupxSx1:t,(y1:t−1,y′)
T (F|x),∀y∈ Y, (2)
and otherwise set ˆptto be an arbitrary member of ∆+(Y)
3. Receive label yt∈ Y
End for
4 Contextual NML, the minimax optimal algorithm
So far we have settled the minimax regret of sequential probability assignment in a nonconstruc-
tive way. Now we switch to the algorithmic lens to study the optimal strategy that achieves the
minimax regret. Remarkably, we show that the minimax optimal algorithm can be described by a
data-dependent variant of the contextual Shtarkov sum, which is named contextual Shtarkov sum
with prefix .
Definition 4.1 (Contextual Shtarkov sum with prefix) Given sequences x1:t∈ Xt, y1:t∈ Yt, t∈
[T]and a context tree xof depth T−t, the contextual Shtarkov sum Sx1:t,y1:t
T (F|x)ofFonxwith
prefix x1:t, y1:tis defined as
Sx1:t,y1:t
T (F|x) =X
y∈YT−tsup
f∈FPf(y1:t,y|x1:t,x(y)).
Now we present our prediction strategy, contextual normalized maximum likelihood (cNML),
which is summarized in Algorithm 1. In each round t, with x1:t, y1:t−1as past observations,
the learner first checks whether supf∈FPf(y1:t−1|x1:t−1)>0since if that is not the case and
supf∈FPf(y1:t−1|x1:t−1) = 0 , the cumulative losses of all experts in Fhave already blown up to
+∞and the learner only needs to predict any ˆp∈∆+(Y)in all remaining rounds. On the other
hand, if supf∈FPf(y1:t−1|x1:t−1)>0, then
max
y∈Ysup
xSx1:t,(y1:t−1,y)
T (F|x)>0
and the ˆptgiven by Eq. (2) is indeed a valid member of ∆(Y)(shown in Appendix B) and is used as
the learner’s prediction. The following theorem shows that cNML is the minimax optimal algorithm,
with proof deferred to Appendix B.
Theorem 4.2 (Main result: optimal algorithm) The contextual normalized maximum likelihood
strategy (Algorithm 1) is minimax optimal.
To see that cNML is reduced to NML in the context-free setting, it suffices to consider the case
where supf∈FPf(y1:T)>0since otherwise NML will simply assign 0probability on this se-
quence y1:Tand during the actual round-wise implementation of NML, it also predicts an arbitrary
element from ∆+(Y)in those rounds twhere supfPf(y1:t−1) = 0 . Now for any y1:Tsuch that
supf∈FPf(y1:T)>0, the prediction by cNML in each round tis
ˆpt(y) =P
y∈YT−tsupf∈FPf(y1:t−1, y,y)P
y′∈YT−t+1supf∈FPf(y1:t−1,y′),∀y∈ Y
which can be summarized into a joint density over y1:Tby
ˆp(y1:T) =supf∈FPf(y1:T)P
y′
1:T∈YTsupf∈FPf(y′
1:T).
Recall that this is exactly the NML prediction pnml(y1:T).
8Remark 4.3 (Relaxations and efficient algorithms) One may wonder if more efficient algorithms
are available when it is not easy to compute contextual Shtarkov sums with prefix. One solution is
to apply the framework of admissible relaxation in [RSS12], which provides a systematic way of
constructing efficient algorithms at the cost of worse regret guarantees. Notice that the worst-case
log contextual Shtarkov sums with prefix constitute a trivially “admissible relaxation” since they are
the exact conditional game values.
5 Perspectives on contextual Shtarkov sums
In this section, we provide further insight into contextual Shtarkov sums, defined in Sections 3 and 4.
5.1 Contextual Shtarkov sums through martingales
We can relate our characterization of the minimax regret to the more extensively studied sequential
Rademacher complexity , which arises in online learning problems with hypothesis class F ⊆[0,1]X
and bounded convex losses like absolute loss. Specifically, the (conditional) sequential Rademacher
complexity [RST15] is defined by
RT(F;x) :=Eεh
sup
f∈FTX
t=1εtf(xt(ε))i
,
where xis a depth- Tbinary context tree and ε= (ε1, . . . , ε T)∈ {± 1}Tis a sequence of i.i.d.
Rademacher random variables. A notable feature of RT(F;x)is that it is the expected supremum
of the sum of a martingale differences, i.e., for any f,E[εtf(xt(ε))|ε1, . . . , ε t−1] = 0 . Likewise,
ST(F|x)also admits a martingale interpretation. To see this, let F ⊆ { (X × Y )∗× X → ∆(Y)}
and rewrite ST(F|x)for any context tree x:
ST(F|x) =X
y∈YTsup
f∈FPf(y|x(y)) =Eyh
sup
f∈FTY
t=1
|Y| ·f(x1:t(y), y1:t−1)(yt)i
,
where y= (y1, . . . , y T)is a sequence of i.i.d. variables following the uniform distribution over Y.
It is easy to check that E[|Y| ·f(x1:t(y), y1:t−1)(yt)|y1, . . . , y t−1] = 1 , and thus
ntY
s=1
|Y| ·f(x1:s(y), y1:s−1)(ys)o
t∈[T]
is a martingale with respect to filtration Ft=σ(y1, . . . , y t), t∈[T]. It would be of independent
interest to study the contextual Shtarkov sums more quantitatively by developing new tools for such
product-type martingales.
5.2 General Shtarkov sums
We can also interpret contextual Shtarkov sums as an instance of general Shtarkov sums , which are
defined over sub-probability measures.
Definition 5.1 (Sub-probability measure) A setP={p:K → [0,1]}is a class of sub-probability
measures over a finite set Kif X
k∈Kp(k)≤1,∀p∈ P.
Due to Lemma D.1, it is easy to see that for any hypothesis class F ⊆ { (X × Y )∗× X → ∆(Y)}
and depth- Tcontext tree x, they induce a class
PF|x:={Pf(·|x(·)) :f∈ F}
that is a class of sub-probability measures over YT. Moreover, for any F, depth- (T−t)context tree
xand sequences x1:t∈ Xt, y1:t∈ Yt, the induced
PFx1:t,y1:t|x:={Pf(y1:t,·|x1:t,x(·)) :f∈ F}
9is a class of sub-probability measure over YT−tsince
X
y∈YT−tPf(y1:t,y|x1:t,x(y)) =Pf(y1:t|x1:t)≤1.
Next we introduce the notion of general Shtarkov sum over classes of sub-probability measures.
Definition 5.2 (General Shtarkov sum) Given any class Pof sub-probability measures over K,
the general Shtarkov sum of Pis defined as
S(P) =X
k∈Ksup
p∈Pp(k).
With the notion of general Shtarkov sum, it is not hard to verify that the contextual Shtarkov sums
with & without prefix can be interpreted as instances of general Shtarkov sums:
Proposition 5.3 For any horizon T, t∈[T], data sequence x1:t∈ Xt, y1:t∈ Yt, and context trees
x,x′of depth T, T−trespectively, we have
ST(F|x) =S(PF|x), Sx1:t,y1:t
T (F|x′) =S(PFx1:t,y1:t|x′).
It would be interesting to find out other instances of general Shtarkov sums that capture the com-
plexities of other online learning problems with log loss.
6 Discussions
In this paper, we characterize the minimax regret and the optimal prediction strategy for sequen-
tial probability assignment, generalizing the classical results in the context-free setting. Moreover,
our results are general enough to subsume the setting of multiary labels and sequential hypothesis
classes, which has not been sufficiently explored before. Remarkably, our characterization holds
for arbitrary hypothesis classes that may not admit the regularity assumptions implicitly required by
prior works (e.g. [RST15; BFR20]).
For future works, it would be interesting to study the minimax regret of specific classes more quan-
titatively using our contextual Shtarkov sums. It is also intriguing to consider the setting of infinite
labels. Although most of our arguments would go through under sufficient regularity conditions, a
more systematic study is needed. On the practical side, it is important to develop algorithms that are
more computationally efficient than cNML and with provable guarantees.
Acknowledgements
We are grateful to Changlong Wu for telling us about Proposition C.2 and to Zeyu Jia for insights
leading to Lemma 3.8. We would also like to thank Blair Bilodeau and Sasha V oitovych for helpful
discussions and comments on earlier drafts of this work. ZL is supported by the Vector Research
Grant at the Vector Institute. IA is supported by the Vatat Scholarship from the Israeli Council
for Higher Education. DMR is supported by an NSERC Discovery Grant and funding through his
Canada CIFAR AI Chair at the Vector Institute.
References
[ABDMNY21] N. Alon, O. Ben-Eliezer, Y . Dagan, S. Moran, M. Naor, and E. Yogev. “Adver-
sarial laws of large numbers and optimal regret in online classification”. In: Pro-
ceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing .
2021, pp. 447–455 (cit. on p. 3).
[AHKKV23] I. Attias, S. Hanneke, A. Kalavasis, A. Karbasi, and G. Velegkas. “Optimal Learn-
ers for Realizable Regression: PAC Learning and Online Learning”. In: Thirty-
seventh Conference on Neural Information Processing Systems . 2023 (cit. on p. 3).
[BRY98] A. Barron, J. Rissanen, and B. Yu. “The minimum description length principle in
coding and modeling”. In: IEEE transactions on information theory 44.6 (1998),
pp. 2743–2760 (cit. on p. 2).
10[BPS09] S. Ben-David, D. Pál, and S. Shalev-Shwartz. “Agnostic Online Learning.” In:
COLT . V ol. 3. 2009, p. 1 (cit. on p. 3).
[BHS23] A. Bhatt, N. Haghtalab, and A. Shetty. “Smoothed Analysis of Sequential Prob-
ability Assignment”. In: Thirty-seventh Conference on Neural Information Pro-
cessing Systems . 2023 (cit. on p. 3).
[BFR20] B. Bilodeau, D. Foster, and D. Roy. “Tight bounds on minimax regret under
logarithmic loss via self-concordance”. In: International Conference on Machine
Learning . PMLR. 2020, pp. 919–929 (cit. on pp. 2, 3, 6, 10, 14, 15, 25).
[BFR23] B. Bilodeau, D. J. Foster, and D. M. Roy. “Minimax rates for conditional den-
sity estimation via empirical entropy”. In: The Annals of Statistics 51.2 (2023),
pp. 762–790 (cit. on pp. 7, 15).
[CL06] N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games . Cambridge uni-
versity press, 2006 (cit. on pp. 1, 2).
[CL99] N. Cesa-Bianchi and G. Lugosi. “Minimax regret under log loss for general
classes of experts”. In: Proceedings of the Twelfth annual conference on com-
putational learning theory . 1999, pp. 12–18 (cit. on p. 3).
[Cov74] T. M. Cover. “Universal gambling schemes and the complexity measures of Kol-
mogorov and Chaitin”. In: Technical Report, no. 12 (1974) (cit. on pp. 1, 2).
[Cov91] T. M. Cover. “Universal portfolios”. In: Mathematical finance 1.1 (1991), pp. 1–
29 (cit. on pp. 1, 2).
[CO96] T. M. Cover and E. Ordentlich. “Universal portfolios with side information”. In:
IEEE Transactions on Information Theory 42.2 (1996), pp. 348–363 (cit. on pp. 1,
2).
[Dav73] L. D. Davisson. “Universal noiseless coding”. In: IEEE Trans. Inf. Theory 19
(1973), pp. 783–795 (cit. on p. 2).
[DS04] M. Drmota and W. Szpankowski. “Precise minimax redundancy and regret”. In:
IEEE Transactions on Information Theory 50.11 (2004), pp. 2686–2707 (cit. on
p. 2).
[Fed91] M. Feder. “Gambling using a finite state machine”. In: IEEE Transactions on
Information Theory 37.5 (1991), pp. 1459–1465 (cit. on pp. 1, 2).
[FMG92] M. Feder, N. Merhav, and M. Gutman. “Universal prediction of individual se-
quences”. In: IEEE transactions on Information Theory 38.4 (1992), pp. 1258–
1270 (cit. on p. 2).
[Fit66] B. Fitingof. “Optimal encoding with unknown and variable message statistics”.
In:Probl. Inform. Transm. 2 (1966), pp. 3–11 (cit. on p. 2).
[FKLMS18] D. J. Foster, S. Kale, H. Luo, M. Mohri, and K. Sridharan. “Logistic regression:
The importance of being improper”. In: Conference on learning theory . PMLR.
2018, pp. 167–208 (cit. on p. 1).
[Fre96] Y . Freund. “Predicting a binary sequence almost as well as the optimal biased
coin”. In: Proceedings of the ninth annual conference on Computational learning
theory . 1996, pp. 89–98 (cit. on p. 2).
[Grü05] P. Grünwald. “Minimum description length tutorial”. In: (2005) (cit. on p. 2).
[HY01] M. H. Hansen and B. Yu. “Model selection and the principle of minimum descrip-
tion length”. In: Journal of the American Statistical Association 96.454 (2001),
pp. 746–774 (cit. on p. 2).
[JSS21] P. Jacquet, G. Shamir, and W. Szpankowski. “Precise minimax regret for logis-
tic regression with categorical feature values”. In: Algorithmic Learning Theory .
PMLR. 2021, pp. 755–771 (cit. on pp. 2, 4, 5).
[Kel56] J. L. Kelly. “A new interpretation of information rate”. In: the bell system techni-
cal journal 35.4 (1956), pp. 917–926 (cit. on pp. 1, 2).
[Kol65] A. N. Kolmogorov. “Three approaches to the definition of the concept “quantity
of information””. In: Problemy peredachi informatsii 1.1 (1965), pp. 3–11 (cit. on
p. 2).
[Lit88] N. Littlestone. “Learning quickly when irrelevant attributes abound: A new linear-
threshold algorithm”. In: Machine learning 2 (1988), pp. 285–318 (cit. on p. 3).
11[MF98] N. Merhav and M. Feder. “Universal prediction”. In: IEEE Transactions on Infor-
mation Theory 44.6 (1998), pp. 2124–2147 (cit. on pp. 1, 2).
[MG22] J. Mourtada and S. Gaïffas. “An improper estimator with optimal excess risk in
misspecified density estimation and logistic regression”. In: Journal of Machine
Learning Research 23.31 (2022), pp. 1–49 (cit. on p. 22).
[OH99] M. Opper and D. Haussler. “Worst case prediction over sequences under log
loss”. In: The Mathematics of Information Coding, Extraction and Distribution .
Springer, 1999, pp. 81–90 (cit. on p. 3).
[OS04] A. Orlitsky and N. P. Santhanam. “Speaking of infinity [iid strings]”. In: IEEE
Transactions on Information Theory 50.10 (2004), pp. 2215–2230 (cit. on p. 2).
[RS14a] A. Rakhlin and K. Sridharan. “Online non-parametric regression”. In: Conference
on Learning Theory . PMLR. 2014, pp. 1232–1264 (cit. on pp. 2, 3).
[RS14b] A. Rakhlin and K. Sridharan. “Statistical Learning and Sequential Prediction”. In:
2014 (cit. on p. 3).
[RS15] A. Rakhlin and K. Sridharan. “Sequential probability assignment with binary al-
phabets and large classes of experts”. In: arXiv preprint arXiv:1501.07340 (2015)
(cit. on pp. 2, 3, 7, 14, 25).
[RST10] A. Rakhlin, K. Sridharan, and A. Tewari. “Online learning: Random averages,
combinatorial parameters, and learnability”. In: Advances in Neural Information
Processing Systems 23 (2010) (cit. on pp. 2, 3).
[RST15] A. Rakhlin, K. Sridharan, and A. Tewari. “Sequential complexities and uniform
martingale laws of large numbers”. In: Probability theory and related fields 161
(2015), pp. 111–153 (cit. on pp. 1–3, 9, 10, 14).
[RSS12] S. Rakhlin, O. Shamir, and K. Sridharan. “Relax and randomize: From value to
algorithms”. In: Advances in Neural Information Processing Systems 25 (2012)
(cit. on p. 9).
[Ris78] J. Rissanen. “Modeling by shortest data description”. In: Automatica 14.5 (1978),
pp. 465–471 (cit. on p. 2).
[Ris84] J. Rissanen. “Universal coding, information, prediction, and estimation”. In: IEEE
Transactions on Information theory 30.4 (1984), pp. 629–636 (cit. on pp. 1, 2).
[Ris86] J. Rissanen. “Complexity of strings in the class of Markov sources”. In: IEEE
Transactions on Information Theory 32.4 (1986), pp. 526–532 (cit. on p. 2).
[Ris87] J. Rissanen. “Stochastic complexity”. In: Journal of the Royal Statistical Society:
Series B (Methodological) 49.3 (1987), pp. 223–239 (cit. on p. 2).
[RL81] J. Rissanen and G. Langdon. “Universal modeling and coding”. In: IEEE Trans-
actions on Information Theory 27.1 (1981), pp. 12–23 (cit. on p. 2).
[Ris76] J. J. Rissanen. “Generalized Kraft inequality and arithmetic coding”. In: IBM
Journal of research and development 20.3 (1976), pp. 198–203 (cit. on p. 2).
[Ris96] J. J. Rissanen. “Fisher information and stochastic complexity”. In: IEEE transac-
tions on information theory 42.1 (1996), pp. 40–47 (cit. on p. 2).
[Sha06] G. I. Shamir. “On the MDL principle for iid sources with large alphabets”. In:
IEEE transactions on information theory 52.5 (2006), pp. 1939–1955 (cit. on
p. 2).
[Sha20] G. I. Shamir. “Logistic regression regret: What’s the catch?” In: Conference on
Learning Theory . PMLR. 2020, pp. 3296–3319 (cit. on p. 1).
[Sht87] Y . M. Shtarkov. “Universal Sequential Coding of Single Messages”. In: Problems
of Information Transmission 23 (3 1987), pp. 3–17 (cit. on pp. 1, 2, 4).
[Sio58] M. Sion. “On general minimax theorems”. In: Pacific Journal of Mathematics 8
(1958), pp. 171–176 (cit. on p. 15).
[Sol64] R. Solmonoff. “A formal theory of inductive inference. I”. In: II Information and
Control 7 (1964), pp. 224–254 (cit. on p. 2).
[Szp98] W. Szpankowski. “On asymptotics of certain recurrences arising in universal cod-
ing”. In: PROBLEMS OF INFORMATION TRANSMISSION C/C OF PROBLEMY
PEREDACHI INFORMATSII 34 (1998), pp. 142–146 (cit. on p. 2).
12[V ov95] V . G. V ovk. “A game of prediction with expert advice”. In: Proceedings of the
eighth annual conference on Computational learning theory . 1995, pp. 51–60 (cit.
on p. 1).
[WHGS23] C. Wu, M. Heidari, A. Grama, and W. Szpankowski. “Regret Bounds for Log-loss
via Bayesian Algorithms”. In: IEEE Transactions on Information Theory (2023)
(cit. on pp. 2–4, 6, 7, 15, 25, 26).
[XB97] Q. Xie and A. R. Barron. “Minimax redundancy for the class of memoryless
sources”. In: IEEE Transactions on Information Theory 43.2 (1997), pp. 646–
657 (cit. on p. 2).
[XB00] Q. Xie and A. R. Barron. “Asymptotic minimax regret for data compression, gam-
bling, and prediction”. In: IEEE Transactions on Information Theory 46.2 (2000),
pp. 431–445 (cit. on p. 1).
[ZL77] J. Ziv and A. Lempel. “A universal algorithm for sequential data compression”.
In:IEEE Transactions on information theory 23.3 (1977), pp. 337–343 (cit. on
p. 2).
[ZL78] J. Ziv and A. Lempel. “Compression of individual sequences via variable-rate
coding”. In: IEEE transactions on Information Theory 24.5 (1978), pp. 530–536
(cit. on p. 2).
13A Proofs for Section 3
Notations. When the context and label sequences x1:T, y1:Tare clear from the context, we may
useftto denote the probability vector f(x1:t, y1:t−1)∈∆(Y)produced by hypothesis fat time t
for notational convenience. We also adopt the notation for repeated operators in [RST15; BFR20],
denoting Opt1···OptT[···]by⟪Optt⟫T
t=1h
···i
. For any discrete distribution Pand discrete
random variables X, Y , letH(P)be the entropy of PandH(X|Y)be the conditional entropy of
Xgiven Y.
A.1 Proof overview of Theorem 3.2
Before presenting the proof of Theorem 3.2 in full details in Appendices A.2 to A.4, we give a
high-level overview here.
The proof starts from swapping the pairs of inf and sup (after randomizing the labels revealed by the
nature) in the extensive formulation of RT(F)to move to the dual game , where the learner predicts
after seeing the action of the nature. Trivially the value of this swapped game is a lower bound for
RT(F), and after rearranging we get that
the value of the swapped game = sup
x,pEy∼p[RT(F;p(y),x(y),y)]≤ R T(F),
where the supremum is taken over all context trees xand probabilistic trees p, of depth T. Also
Ey∼pmeans the nested conditional expectations Ey1∼p1(y)Ey2∼p2(y)···EyT∼pT(y).
Similar to the proof of Lemma 6 in [BFR20] for the binary label setting, we apply the minimax
theorem with a tweak that we devise to handle multiary labels to derive that
RT(F) = sup
x,pEy∼p[RT(F;p(y),x(y),y)](3)
under some mild regularity condition for F. A key observation is that the supremum over depth- T
probabilistic trees pis equivalent to the supremum over joint distributions PoverYT. Based on
this observation and some algebra, for a fixed context tree x, the supremum over pin Eq. (3) is
sup
P∈∆(YT)H(P) +Ey∼P
sup
f∈FlogPf(y|x(y))
.
The value of this maximization problem can be easily computed to be
log X
ysup
f∈FPf(y|x(y))!
= log ST(F|x).
Thus,
RT(F) = sup
x,pEy∼p[RT(F;p(y),x(y),y)]
= sup
xsup
P∈∆(YT)H(P) +Ey∼P
sup
f∈FlogPf(y|x(y))
= sup
xlogST(F|x).
However, Eq. (3) is not guaranteed when there is no assumed regularity condition for F. To get
away from this, prior works have assumed a particular hypothesis is included in Fsuch that the
enlarged class allows for the minimax swap [RS15; BFR20]. Nevertheless, even adding a mere
hypothesis may lead to suboptimal analysis for some classes F, say when RT(F)is of constant
order. To completely get rid of any regularity assumption and obtain a unified characterization of
the minimax regret for arbitrary class F, we provide a novel argument as follows. For an arbitrary
classF, we study a smooth truncated version of it, denoted by Fδfor any level δ∈(0,1/2), such
thatFδalways validates the use of the minimax theorem and hence RT(Fδ) = supxlogST(Fδ|x).
Then we give a series of refined analysis comparing the minimax regrets and contextual Shtarkov
sums of FandFδthat yields
RT(F)≤ R T(Fδ) +Tlog(1 + |Y|δ) = sup
xlogST(Fδ|x) +Tlog(1 + |Y|δ)
≤log
sup
xST(F|x) +δ·C(T,|Y|)
+Tlog(1 + |Y|δ),
where C(T,|Y|)<∞is a positive constant that only depends on Tand|Y|. Sending δ→0+
will conclude that RT(F)≤supxlogST(F|x), which finishes the whole proof as we already have
RT(F)≥supxlogST(F|x)from the start.
14A.2 Minimax swap
As standard in online learning literature, we will first move to a dual game after applying a minimax
swap at each round of the game. Under mild assumptions, the value of the original game coincides
with the that of the swapped game. More specifically, we have:
Lemma A.1 Whenever Fsatisfies that for every sequence x1:T∈ XT, y1:T∈ YT,
inf
f∈FTX
t=1ℓ(f(x1:t, y1:t−1), yt)<∞, (4)
we have that
RT(F) = sup
x,pEy∼p[RT(F;p(y),x(y),y)],(5)
where the supremum is taken over all X-valued Y-ary trees xand∆(Y)-valued Y-ary trees p, of
depth T. AlsoEy∼pmeans the nested conditional expectations Ey1∼p1(y)Ey2∼p2(y)···EyT∼pT(y).
To deal with the unboundedness of log loss in the proof, we introduce the following truncation
method inspired by [BFR23; WHGS23], generalizing the one in [BFR20] which was specific to
binary labels.
Definition A.2 (Smooth truncation) The general smooth truncation map τδ: ∆(Y)→∆(Y)is
defined such that for all p∈∆(Y)andy∈ Y,
τδ(p)(y) =p(y) +δ
1 +|Y|δ,
given threshold δ∈(0,1/2).
It is easy to check that τδ(p)is indeed a valid member in ∆(Y)andτδ(p)(y)∈[δ/(1 +|Y|δ),(1 +
δ)/(1 +|Y|δ)]. Moreover, it is not hard to verify that τδ(∆(Y)) ={p∈∆(Y) :p(y)∈[δ/(1 +
|Y|δ),(1 +δ)/(1 +|Y|δ)],∀y∈ Y} . We will use ∆δ(Y)to denote this image set τδ(∆(Y)).
Proof of Lemma A.1 Fixδ∈(0,1/2). By restricting the learner’s prediction ˆptto∆δ(Y), we get
an upper bound on RT(F):
RT(F)≤⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T
t=1hTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
=⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T−1
t=1sup
xTinf
ˆpT∈∆δ(Y)sup
pTEyT∼pThTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
.
Now we can apply Sion’s minimax theorem [Sio58] to the function
A(ˆpT, pT) =EyT∼pThTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
to derive that
inf
ˆpT∈∆δ(Y)sup
pT∈∆(Y)A(ˆpT, pT) = sup
pT∈∆(Y)inf
ˆpT∈∆δ(Y)A(ˆpT, pT).
This is because:
1.A(ˆpT, pT)is convex and continuous in ˆpTover the compact ∆δ(Y)and
2.A(ˆpT, pT)is concave and continuous in pTover the compact ∆(Y), which is further due
to that A(ˆpT, pT)is linear in pTand is bounded given Eq. (4).
15Hence
RT(F)≤⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T−1
t=1sup
xTsup
pTinf
ˆpT∈∆δ(Y)EyT∼pThTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
=⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T−2
t=1sup
xT−1inf
ˆpT−1∈∆δ(Y)sup
pT−1EyT−1∼pT−1
hT−1X
t=1ℓ(ˆpt, yt) + sup
xTsup
pT
inf
ˆpT∈∆δ(Y)EyT∼pTℓ(ˆpT, yT)−EyT∼pTinf
f∈FTX
t=1ℓ(ft, yt)i
.
Again the order of infˆpT−1∈∆δ(Y)andsuppT−1∈∆(Y)with respect to
B(ˆpT−1, pT−1) =EyT−1∼pT−1hT−1X
t=1ℓ(ˆpt, yt) + sup
xTsup
pT
inf
ˆpT∈∆δ(Y)EyT∼pTℓ(ˆpT, yT)−EyT∼pTinf
f∈FTX
t=1ℓ(ft, yt)i
can be swapped due to the same reason as above, leading to
RT(F)≤⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T−2
t=1sup
xT−1sup
pT−1inf
ˆpT−1∈∆δ(Y)EyT−1∼pT−1
hT−1X
t=1ℓ(ˆpt, yt) + sup
xTsup
pT
inf
ˆpT∈∆δ(Y)EyT∼pTℓ(ˆpT, yT)−EyT∼pTinf
f∈FTX
t=1ℓ(ft, yt)i
=⟪sup
xtinf
ˆpt∈∆δ(Y)sup
yt⟫T−3
t=1sup
xT−2inf
ˆpT−2∈∆δ(Y)sup
pT−2EyT−2∼pT−2
nT−2X
t=1ℓ(ˆpt, yt) + sup
xT−1sup
pT−1h
inf
ˆpT−1∈∆δ(Y)EyT−1∼pT−1ℓ(ˆpT−1, yT−1)
+EyT−1∼pT−1sup
xTsup
pTh
inf
ˆpT∈∆δ(Y)EyT∼pTℓ(ˆpT, yT)−EyT∼pTinf
f∈FTX
t=1ℓ(ft, yt)iio
.
Repeating this procedure through all Trounds yields
RT(F)≤⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1inf
ˆpt∈∆δ(Y)Eyt∼pt[ℓ(ˆpt, yt)]−ℓ(ft, yt)i
.
By Lemma A.7, we know that we do not lose too much by restricting learner’s prediction to ∆δ(Y):
RT(F)≤⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1inf
ˆptEyt∼pt[ℓ(ˆpt, yt)]−ℓ(ft, yt)i
+|Y|δT.
Sending δ→0+on the RHS of the above inequality, we get
RT(F)≤⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1inf
ˆptEyt∼pt[ℓ(ˆpt, yt)]−ℓ(ft, yt)i
.
It is easy to see that on the RHS of the above inequality, the inner infimum over ˆpt∈∆(Y)is
achieved at ˆpt=ptdue to the nature of log loss. So
RT(F)≤⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1Eyt∼pt[ℓ(pt, yt)]−ℓ(ft, yt)i
= sup
x,pEy∼p[RT(F;p(y),x(y),y)],
where in the last equality we use the compact notation of trees to further simplify our expression
and this concludes the proof. ■
16Lemma A.3 For any hypothesis class Fand horizon T,
sup
x,pEy∼p[RT(F;p(y),x(y),y)] = sup
xlogST(F|x).(6)
It is implied that whenever Fsatisfies Eq. (5), we have
RT(F) = sup
xlogST(F|x).
Proof of Lemma A.3 First we can see that the outcome sequence y1:Tgenerated under any tree
pis the same thing as y1:Tgenerated by its associated joint distribution over YT, and vice versa.
So we can replace the supremum over trees pin the LHS of Eq. (6) by the supremum over joint
distributions PoverYT. Hence,
sup
x,pEy∼p[RT(F;p(y),x(y),y)] = sup
x,PEy∼P[RT(F;p(y),x(y),y)]
= sup
x,PEy∼PhTX
t=1ℓ(Pt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
,
where Ptdenotes the conditional distribution Pt(·|y1:t−1)∈∆(Y)ofytunder Pgiven y1:t−1.
Now fix the context tree xand distribution P. Then we can see that Ey∼P[ℓ(Pt, yt)] =
H(yt|y1:t−1). SoEy∼P[PT
t=1ℓ(Pt, yt)] =PT
t=1H(yt|y1:t−1) =H(P). Further notice that
inf
f∈FTX
t=1ℓ(ft, yt) = inf
f∈F(−logPf(y1:T|x1:T)) =−sup
f∈FlogPf(y1:T|x1:T).
So naturally we define the map Fx:YT→R∪ {−∞} by
Fx(y) = sup
f∈FlogPf(y|x(y)),
and then we see that
Ey∼PhTX
t=1ℓ(Pt, yt)−inf
f∈FTX
t=1ℓ((f(xt(y)), yt)i
=H(P) +Ey∼P[Fx(y)].
For any given tree x, notice that the optimization problem
sup
P∈∆(YT)H(P) +Ey∼P[Fx(y)]
is actually a maximization problem in the form of max P∈∆(YT)H(P) +⟨P, v⟩, where vis some
|Y|T−dimensional vector. According to the conjugacy between negative entropy function and log-
sum-exp function, the optimal P∗is given by
P∗(y) =exp(Fx(y))P
y′exp(Fx(y′))=supf∈FPf(y|x(y))P
y′supf∈FPf(y′|x(y′)),∀y∈ YT.
Note that the above formula for P∗is also valid when Fx(y) =−∞ for some y, since P∗should
be supported on {y∈ YT:Fx(y)>−∞} , and Fx(y)cannot be −∞ for all ydue to Lemma D.1.
The associated value of this maximization problem is
log X
yexp(Fx(y))!
= log X
ysup
f∈FPf(y|x(y))!
.
Therefore,
sup
x,pEy∼p[RT(F;p(y),x(y),y)] = sup
x,PEy∼PhTX
t=1ℓ(Pt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
= sup
xsup
Pn
H(P) +Ey∼P[Fx(y)]o
= sup
xlog X
ysup
f∈FPf(y|x(y))!
= sup
xlogST(F|x).
■
17In the proof of Lemma A.1, if we do not restrict the learner’s prediction and simply swap the order
of inf and sup to produce an inequality at each time t, we will reach the following folklore result.
Lemma A.4 For any hypothesis class Fand horizon T,
RT(F)≥sup
x,pEy∼p[RT(F;p(y),x(y),y)].(7)
Proof of Lemma A.4 To get Eq. (7), we simply need to reverse the order of sup and inf at each time
in the extensive formulation of minimax regret and produce an inequality:
RT(F) = sup
x1inf
ˆp1sup
y1···sup
xTinf
ˆpTsup
yTRT(F; ˆp1:T, x1:T, y1:T)
=⟪sup
xtinf
ˆptsup
yt⟫T
t=1hTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(f(x1:t, y1:t−1), yt)i
=⟪sup
xtinf
ˆptsup
yt⟫T−1
t=1sup
xTinf
ˆpTsup
pTEyT∼pThTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
≥⟪sup
xtinf
ˆptsup
yt⟫T−1
t=1sup
xTsup
pTinf
ˆpTEyT∼pThTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)i
=⟪sup
xtinf
ˆptsup
yt⟫T−1
t=1hT−1X
t=1ℓ(ˆpt, yt) + sup
xTsup
pT
inf
ˆpTEyT∼pTℓ(ˆpT, yT)−EyT∼pTinf
f∈FTX
t=1ℓ(ft, yt)i
.
Iterating the argument and rearranging terms as above, we will get that
RT(F)≥⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1inf
ˆptEyt∼pt[ℓ(ˆpt, yt)]−ℓ(ft, yt)i
=⟪sup
xtsup
ptEyt∼pt⟫T
t=1sup
f∈FhTX
t=1Eyt∼pt[ℓ(pt, yt)]−ℓ(ft, yt)i
= sup
x,pEy∼p[RT(F;p(y),x(y),y)].
■
A.3 Smooth truncated hypothesis class
To remove the reliance on Eq. (4), we introduce a smooth truncated version of Fthat always satisfies
Eq. (4) and study its minimax regret as well as contextual Shtarkov sums, compared to those of the
untruncated class F. To be more specific, we will apply the smooth truncation map to hypotheses:
for any δ∈(0,1/2)andf: (X × Y )∗× X → ∆(Y), we use fδto denote its smooth truncated
counterpart τδ◦f; for any hypothesis class F, we use Fδto denote the corresponding smooth
truncated class τδ◦ F={τδ◦f:f∈ F} . It is easy to verify that any smooth truncated class Fδ
satisfies Eq. (4) and hence
RT(Fδ) = sup
xlogST(Fδ|x).
Next we control the effect of truncation on the minimax regret.
Lemma A.5 For any F, Tandδ∈(0,1/2),
RT(F)≤ R T(Fδ) +T·log(1 + |Y|δ).
18Proof of Lemma A.5 Fix threshold δ∈(0,1/2)and hypothesis f. By Lemma A.7, for any given
sequences x1:T, y1:T, there is
TX
t=1ℓ(fδ(x1:t, y1:t−1), yt)−TX
t=1ℓ(f(x1:t, y1:t−1), yt)≤T·log(1 + |Y|δ). (8)
Then, for any sequence of predictions ˆp1:T,
RT(F; ˆp1:T, x1:T, y1:T) =TX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(ft, yt)
≤TX
t=1ℓ(ˆpt, yt)−inf
fδ∈FδTX
t=1ℓ(fδ
t, yt) +T·log(1 + |Y|δ)
=RT(Fδ; ˆp1:T, x1:T, y1:T) +T·log(1 + |Y|δ),
which concludes the proof. ■
Lemma A.6 There exists a constant M(T)<∞that only depends on Tsuch that for any f, x1:T∈
XT, y1:T∈ YTandδ∈(0,1/2),
Pfδ(y1:T|x1:T)≤Pf(y1:T|x1:T) +δ·M(T).
Proof of Lemma A.6 Fix threshold δ∈(0,1/2), hypothesis fand sequences x1:T, y1:T. Then
Pfδ(y1:T|x1:T) =TY
t=1fδ
t(yt) =Y
tft(yt) +δ
1 +|Y|δ
≤Y
t(ft(yt) +δ)
=Y
tft(yt) +δ·X
tY
t′̸=tft′(yt′) +···+δT
≤Y
tft(yt) +δ·M(T)
=Pf(y1:T|y1:T) +δ·M(T),
where we can set M(T) =T+ T
2
+ T
3
+···+ T
T
since ft(yt)’s are bounded by 1. ■
A.4 Putting together
Now we are fully prepared to finish the proof of Theorem 3.2, our main result in Section 3.
Proof of Theorem 3.2 By Lemma A.6, we have that for any context tree xof depth T,X
y∈YTsup
fδ∈FδPfδ(y|x(y))≤X
y∈YTsup
f∈FPf(y|x(y)) +δ·M(T)· |Y|T.
Thus
RT(Fδ) = sup
xlogST(Fδ|x)
= sup
xlog
X
y∈YTsup
fδ∈FδPfδ(y|x(y))

≤sup
xlog
X
y∈YTsup
f∈FPf(y|x(y)) +δ·M(T)· |Y|T

= log
sup
xX
y∈YTsup
f∈FPf(y|x(y)) +δ·M(T)· |Y|T
.
19Together with Lemma A.5, we get that for any δ∈(0,1/2),
RT(F)≤log
sup
xX
y∈YTsup
f∈FPf(y|x(y)) +δ·M(T)· |Y|T
+T·log(1 + |Y|δ).(9)
After sending δ→0+on the RHS of Eq. (9),
RT(F)≤log
sup
xX
y∈YTsup
f∈FPf(y|x(y))
= sup
xlogST(F|x).
Recall that we have RT(F)≥supxlogST(F|x)from Lemma A.4 and Lemma A.3. So finally,
RT(F) = sup
xlogST(F|x).
■
A.5 Additional proofs
Lemma A.7 For any p∈∆(Y)andδ∈(0,1/2),
ℓ(τδ(p), y)≤ℓ(p, y) + log(1 + |Y|δ)≤ℓ(p, y) +|Y|δ,∀y∈ Y.
Proof of Lemma A.7 By direct computation, for any y∈ Y,
ℓ(τδ(p), y)−ℓ(p, y) = logp(y)
p(y) +δ·(1 +|Y|δ)
≤log(1 + |Y|δ)
≤ |Y| δ.
■
A.6 Proof of Proposition 3.3
Starting from Theorem 3.2 that RT(F) = supxlogST(F|x), we have
RT(F) = sup
xlog X
ysup
f∈FPf(y|x(y))!
≤sup
xlog
X
yX
f∈FPf(y|x(y))

= sup
xlog
X
f∈FX
yPf(y|x(y))
= log|F|,
where the last equality is due to Lemma D.1.
A.7 Proof of Lemma 3.8
It suffices to show that RFD
T(FLin)≥√
T/4. In particular, we only need to find some context
sequence x1:Tsuch that logST(FLin|x1:T)≥√
T/4due to Proposition 2.5. Here we pick x1:T
such that xtare unit vectors and xt⊥xt′whenever t̸=t′. Such sequence exists because the
20dimension of B2is no smaller than T. In this way, for each possible label sequence y1:T∈ {0,1}T,
we can see that the fw∈ FLinthat is indexed by
w=TX
t=12yt−1√
Txt
achieves likelihood Pfw(y1:T|x1:T) = (1+1/√
T
2)T. Therefore,
ST(FLin|x1:T) =X
y1:T∈{0,1}Tsup
f∈FLinPf(y1:T|x1:T)≥X
y1:T∈{0,1}T 
1 + 1 /√
T
2!T
=
1 + 1 /√
TT
,
which implies that RFD
T(FLin) = log ST(FLin|x1:T)≥Tlog(1 + 1 /√
T)≥√
T/4for all T≥1.
B Proofs for Section 4
Notations. Again we may use ftto denote the probability vector f(x1:t, y1:t−1)∈∆(Y)produced
by hypothesis fat time twhen the context and label sequences x1:T, y1:Tare clear from the context.
For a context tree xof depth T−tand a path y∈ YT−t, we re-index x(y)as(xt+1(y), . . . , xT(y))
whenever it takes the last T−tentries of the entire context sequence. And we do the same for the
probabilistic tree pas well. That is, whenever y= (yt+1, . . . , y T)∈ YT−ttakes the last T−t
entries of the whole label sequence and y∼p, then we will denote this label generating process by
yt+1∼pt+1(y), . . . , y T∼pT(y).
B.1 Proof of Theorem 4.2
Recall that the minimax regret is
RT(F) =⟪sup
xtinf
ˆptsup
yt⟫T
t=1hTX
t=1ℓ(ˆpt, yt)−inf
f∈FTX
t=1ℓ(f(x1:t, y1:t−1), yt)i
.
Through this extensive form of the minimax regret, we know that given x1:t, y1:t−1, the minimax
prediction ˆp∗
tat round tis the one that minimizes the following expression over all ˆpt∈∆(Y):
sup
yt⟪sup
xsinf
ˆpssup
ys⟫T
s=t+1hTX
s=tℓ(ˆps, ys)−inf
f∈FTX
s=1ℓ(f(x1:s, y1:s−1), ys)i
. (10)
Define
G(F, x1:t, y1:t) =⟪sup
xsinf
ˆpssup
ys⟫T
s=t+1hTX
s=t+1ℓ(ˆps, ys)−inf
f∈FTX
s=1ℓ(f(x1:s, y1:s−1), ys)i
,
and now
ˆp∗
t= argmin
ˆpt∈∆(Y)sup
ytn
ℓ(ˆpt, yt) +G(F, x1:t, y1:t)o
.
The crux of the proof is to show the following:
Lemma B.1 For any hypothesis class Fand sequences x1:t∈ Xt, y1:t∈ Yt,
G(F, x1:t, y1:t) = sup
xlogSx1:t,y1:t
T (F|x).
The proof of Lemma B.1 is done by essentially following the same strategy in Appendix A since
G(F, x1:t, y1:t)admits a similar extensive form with the minimax regret RT(F). For completeness
we provide its proof in Appendix B.2. Given Lemma B.1, we have
ˆp∗
t= argmin
ˆpt∈∆(Y)sup
ytn
ℓ(ˆpt, yt) + sup
xlogSx1:t,y1:t
T (F|x)o
= argmin
ˆpt∈∆(Y)sup
ytlogsupxSx1:t,y1:t
T (F|x)
ˆpt(yt)
.
We apply the following result to solve the above program:
21Lemma B.2 [MG22, Lemma 15] Let g:Y → [0,+∞]be a measurable function such that R
Yg(y)dµ∈(0,+∞). Then,
inf
psup
y∈Ylogg(y)
p(y)= logZ
Yg(y)µ(dy)
, (11)
where the infimum in Eq. (11) spans over all probability densities p:Y → [0,+∞)with respect to
µ, and the infimum is reached at
p∗=gR
Yg(y)dµ.
Letting g(y) = supxSx1:t,(y1:t−1,y)
T (F|x)∈[0,1]andµbe the counting measure on the finite space
Y, we can apply Lemma B.2 whenever not all g(y)’s are 0. In this case, we solve that
ˆp∗
t(y) =g(y)P
y′∈Yg(y′)=supxSx1:t,(y1:t−1,y)
T (F|x)
P
y′∈YsupxSx1:t,(y1:t−1,y′)
T (F|x),∀y∈ Y.
On the other hand, if g(y) = 0 ,∀y∈ Y, then any ˆptsuch that ˆpt(y)>0,∀y∈ Y, is an minimax
optimal prediction. Moreover, it implies that Pf(y1:t−1|x1:t−1) = 0 ,∀f∈ F. This is because for
arbitrary context tree x,
0 =X
ytX
y∈YT−tPf(y1:t,y|x1:t,x(y))
=X
ytPf(y1:t|x1:t)
=Pf(y1:t−1|x1:t−1).
So the cumulative loss for each expert fup to round t−1already blows up to +∞and
the learner only needs to predict an arbitrary ˆp∈∆+(Y)in all remaining rounds to achieve
RT(F; ˆp1:T, x1:T, y1:T) =−∞.
Overall, we can see that the minimax optimal prediction ˆp∗
t∈∆(Y)at round tgiven x1:t, y1:t−1is
ˆp∗
t(y) =supxSx1:t,(y1:t−1,y)
T (F|x)
P
y′∈YsupxSx1:t,(y1:t−1,y′)
T (F|x),∀y∈ Y,
if there exists y∈ Y such that supxSx1:t,(y1:t−1,y)
T (F|x)>0. Otherwise, select ˆp∗
tto be an arbitrary
element in ∆+(Y)(and so do all remaining rounds).
B.2 Auxiliary lemmas
Recall that for any hypothesis class Fand sequences x1:t∈ Xt, y1:t∈ Yt,
G(F, x1:t, y1:t) =⟪sup
xsinf
ˆpssup
ys⟫T
s=t+1hTX
s=t+1ℓ(ˆps, ys)−inf
f∈FTX
s=1ℓ(f(x1:s, y1:s−1), ys)i
=⟪sup
xsinf
ˆpssup
psEys∼ps⟫T
s=t+1hTX
s=t+1ℓ(ˆps, ys)−inf
f∈FTX
s=1ℓ(f(x1:s, y1:s−1), ys)i
.
To prove Lemma B.1, we need the following lemmas.
Lemma B.3 For any hypothesis class Fand sequences x1:t∈ Xt, y1:t∈ Yt,
G(F, x1:t, y1:t)≥sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
. (12)
And whenever for every xt+1:T∈ XT−t, yt+1:T∈ YT−t, it holds
inf
f∈FTX
s=1ℓ(f(x1:s, y1:s−1), ys)<∞, (13)
22then
G(F, x1:t, y1:t) = sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
. (14)
Proof of Lemma B.3 First we see that similar to the proof of Lemma A.4, we can reverse every pair
of sup over psand inf over ˆpsin the extensive formulation of G(F, x1:t, y1:t)and rearrange terms
to obtain
G(F, x1:t, y1:t)≥⟪sup
xssup
psEys∼ps⟫T
s=t+1hTX
s=t+1inf
ˆpsEys∼ps[ℓ(ˆps, ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
,
and again due to the nature of log loss,
G(F, x1:t, y1:t)≥⟪sup
xssup
psEys∼ps⟫T
s=t+1hTX
s=t+1Eys∼ps[ℓ(ps, ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
,
where in the last step we compress the expression using trees (of depth T−t) and Eq. (12) is proved.
To show that the minimax swap is valid under Eq. (13), we follow the same strategy as in the proof
of Lemma A.1 by restricting the learner’s prediction ˆpsto∆δ(Y)for any threshold δ∈(0,1/2)
which yields
G(F, x1:t, y1:t)≤⟪sup
xssup
psEys∼ps⟫T
s=t+1hTX
s=t+1inf
ˆps∈∆δ(Y)Eys∼ps[ℓ(ˆps, ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
≤⟪sup
xssup
psEys∼ps⟫T
s=t+1hTX
s=t+1inf
ˆpsEys∼ps[ℓ(ˆps, ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
+|Y|δT.
So Eq. (14) is proved by sending δ→0+on the RHS of the last inequality and the established
Eq. (12). ■
Lemma B.4 For any hypothesis class Fand sequences x1:t∈ Xt, y1:t∈ Yt,
sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
xlogSx1:t,y1:t
T (F|x).
Proof of Lemma B.4 The proof follows that of Lemma A.3. By replacing the probabilistic tree p
by the joint distribution P∈∆(YT−t), we get
sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
x,PEy∼PhTX
s=t+1ℓ(Ps, ys)−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
xsup
P∈∆(YT−t)H(P) +Ey∼Ph
sup
f∈FlogPf(y1:t,y|x1:t,x(y))i
.
Similarly, for any fixed x, define the map Fx1:t,y1:tx :YT−t→R∪ {−∞} by
Fx1:t,y1:t
x (y) = sup
f∈FlogPf(y1:t,y|x1:t,x(y)),
23and now we solve
sup
P∈∆(YT−t)H(P) +Ey∼P[Fx1:t,y1:t
x (y)].
If there exists some y∈ YT−tsuch that Fx1:t,y1:tx (y)>−∞, then the optimal P∗is given by
P∗(y) =exp(Fx1:t,y1:tx (y))P
y′exp(Fx1:t,y1:tx (y′))=supf∈FPf(y1:t,y|x1:t,x(y))P
y′supf∈FPf(y1:t,y′|x1:t,x(y′)),∀y∈ YT−t,
and then
sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
xsup
P∈∆(YT−t)H(P) +Ey∼P[Fx1:t,y1:t
x (y)]
= sup
xlogX
ysup
f∈FPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x).
However, if Fx1:t,y1:tx (y) =−∞ for all y, then it implies that for any context tree x, path y, and
f∈ F,Pf(y1:t,y|x1:t,x(y)) = 0 and hence,
sup
x,pEy∼phTX
s=t+1Eys∼ps(y)[ℓ(ps(y), ys)]−inf
f∈FTX
s=1ℓ(fs, ys)i
= sup
xsup
P∈∆(YT−t)H(P) +Ey∼P[Fx1:t,y1:t
x (y)]
=− ∞
= sup
xlogX
ysup
f∈FPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x),
which finishes our proof. ■
Now we are able to prove the key result Lemma B.1.
Proof of Lemma B.1 Fix any hypothesis class Fand sequences x1:t∈ Xt, y1:t∈ Yt. First we
know
G(F, x1:t, y1:t)≥sup
xlogSx1:t,y1:t
T (F|x)
due to Eq. (12) and Lemma B.4. For the other direction, let us fix any threshold value δ∈(0,1/2)
and then
G(F, x1:t, y1:t)≤G(Fδ, x1:t, y1:t) +T·log(1 + |Y|δ)
= sup
xlogSx1:t,y1:t
T (Fδ|x) +T·log(1 + |Y|δ)
= sup
xlogX
y∈YT−tsup
fδ∈FδPfδ(y1:t,y|x1:t,x(y))
+T·log(1 + |Y|δ)
≤sup
xlogX
y∈YT−tsup
f∈FPf(y1:t,y|x1:t,x(y)) +δ·M(T)· |Y|T
+T·log(1 + |Y|δ)
= log
sup
xX
y∈YT−tsup
f∈FPf(y1:t,y|x1:t,x(y)) +δ·M(T)· |Y|T
+T·log(1 + |Y|δ),
where we have applied Lemma A.7, Lemma B.3, Lemma B.4, and Lemma A.6 accordingly. Simi-
larly, we send δ→0+on the RHS of the last inequality and get
G(F, x1:t, y1:t)≤sup
xlogX
y∈YT−tsup
f∈FPf(y1:t,y|x1:t,x(y))
= sup
xlogSx1:t,y1:t
T (F|x),
which concludes the proof. ■
24C Additional discussions
C.1 On the time-variant context space
In this section we generalize our analysis to the setting where the context space can evolve over time.
We model time-varying context sets by a sequence of maps Xt:Xt−1× Yt−1→2X, t∈[T]as in
[RS15; BFR20]. In each round t, instead of picking any context from X, the nature is now required
to only choose xtfromXt(x1:t−1, y1:t−1)⊆ X . Then the minimax regret with respect to (Xt)t∈[T]
is rewritten as
RT(F) =⟪ sup
xt∈Xt(x1:t−1,y1:t−1)inf
ˆptsup
yt⟫T
t=1RT(F; ˆp1:T, x1:T, y1:T).
A context tree xisconsistent with respect to (Xt)t∈[T]if for all t∈[T]andy∈ YT,xt(y)∈
Xt(x1:t−1, y1:t−1). Then our results in Section 3 and Section 4 can be generalized simply by replac-
ing the supremum over all context trees (of depth T) by the supremum over all consistent context
trees. For example, we will have
RT(F) = sup
x:xis consistentlogST(F|x).
C.2 On the global and non-global sequential cover
Now we go back to consider the usual setting of binary label and constant experts, i.e., Y={0,1}
andF ⊆ [0,1]X. As mentioned in Section 3, previous works [BFR20; WHGS23] provided re-
gret upper bounds based on ℓ∞sequential entropy. More specifically, both of their bounds are in
the form of O(infα>0{αT+H(F, α, T )}), with H(F, α, T )being either the non-global entropy
H∞(F, α, T )or the global entropy HG(F, α, T ). It is then natural to ask which one of these two
bounds is tighter. It is straightforward to prove that H∞(F, α, T )is no larger than HG(F, α, T ).
In fact, the gap between them is at most a polylog factor, as we state and prove below.1The proof
ofH∞(F, α, T )≤ H G(F, α, T )is also included for completeness. Before stating the results, we
introduce the definition of sequential fat-shattering dimension.
Definition C.1 We say an X-valued binary tree xof depth disα-shattered by a class F ⊆ [0,1]X
for some α >0, if there exists a [0,1]-valued binary tree sof depth dsuch that
∀y∈ {0,1}d,∃f∈ F,s.t.(2yt−1)·(f(xt(y))−st(y))≥α
2,∀t∈[d].
In this case, sis called the witness of the shattering. The sequential fat-shattering dimension of Fat
scale α, denoted by sfatα(F), is the largest dsuch that some depth- dcontext tree is α-shattered by
F.
Proposition C.2 For any scale α >0, we have
H∞(F, α, T )≥min{T,sup
α′>αsfat2α′(F)} ·log(2) .
Therefore, together with H∞(F, α, T )≤ H G(F, α, T )and the folklore HG(F, α, T )≤
O(sfat α(F) log( T/α)), we conclude that the regret upper bounds O(infα>0{αT+
H(F, α, T )}),H ∈ {H ∞,HG}, differ by at most a polylog factor.
Proof of Proposition C.2 Fix any α′> α > 0and let dα′denote min{T,sfat2α′(F)}. Then there
exists a context tree xand a witness tree s, both of depth dα′, such that for any path y∈ {0,1}dα′,
there exists an f∈ F such that
∀t∈[dα′],(2yt−1)·(f(xt(y))−st(y))≥α′> α. (15)
1This result and its detailed proof sketch were communicated to the first author by Changlong Wu. The
argument here differs only in minor details that we introduced, perhaps unnecessarily, to arrive at a rigorous
proof.
25LetVx,αbe an arbitrary sequential ℓ∞covering of Fonx. Now we select a path yand a sequence
of subsets V(t)
x,α⊆Vx,α, t∈[dα′]in the following recursive way. Define V(0)
x,α=Vx,α. For
each t∈[dα′], choose yt∈ {0,1}such that 2yt−1∈ {− 1,+1}is the minority among all
sgn(vt(y1:t−1)−st(y1:t−1)), v∈V(t−1)
x,α (ignoring those of 0’s). Finally update V(t)
x,α={v∈
V(t−1)
x,α: sgn( vt(y1:t−1)−st(y1:t−1)) = 2 yt−1}.
First we argue that, if there is any time t′∈[dα′]such that V(t′−1)
x,α̸=∅, V(t′)
x,α=∅, then Vx,α
is not a valid cover of Fonx. Otherwise, recall we have selected y1, . . . , y t′−1. Now pick an
arbitrary yt′∈ {0,1}. By Eq. (15) we can find some f∈ F such that (2yt−1)·(f(xt(y1:t−1))−
st(y1:t−1))> α,∀t∈[t′]. Since Vx,αis a covering at scale α, there is v∈Vx,αsuch that |vt(y)−
f(xt(y))| ≤α,∀t∈[t′]. This implies that sgn(f(xt(y))−st(y)) = sgn( vt(y)−st(y)) =
2yt−1,∀t∈[t′]. So we can always find some member of V(t′−1)
x,α to match the minority sign of
vt′(y1:t′−1)−st′(y1:t′−1), v∈V(t′−1)
x,α , which means that V(t′)
x,α̸=∅and yields a contradiction.
Now we know that |V(t)
x,α| ≥1,∀t∈[dα′]. By design |V(t)
x,α| ≤ | V(t−1)
x,α|/2,∀t∈[dα′], so we
must have |Vx,α|=|V(0)
x,α| ≥2dα′. As the choice of covering is arbitrary, the covering number
N∞(F ◦x, α, d α′)is also lower bounded by 2dα′and hence H∞(F, α, d α′)≥dα′·log(2) . If
supα′>αsfat2α′(F)≤T, then we get that
H∞(F, α, T )≥sup
α′>αH∞(F, α,sfat2α′(F))≥sup
α′>αsfat2α′(F)·log(2) .
If there is some α′> α such that sfat2α′(F)≥T, then
H∞(F, α, T ) =H∞(F, α, d α′)≥T·log(2) .
Combining these two cases together, we have
H∞(F, α, T )≥min{T,sup
α′>αsfat2α′(F)} ·log(2) .
■
Proposition C.3 LetGαbe a global sequential α-covering of Fas defined in [WHGS23]. Then for
any context tree x, there exists a sequential cover Vx,αofF ◦xat scale αwith|Vx,α| ≤ |G α|. This
implies that H∞(F, α, T )≤log|Gα|.
Proof of Proposition C.3 Fix arbitrary context tree x. For any g∈ Gα, define the [0,1]-valued tree
vgbyvg
t(y) =g(x1:t(y)),∀t∈[T],y∈ YT. Now let Vx,α={vg:g∈ Gα}and we will show that
Vx,αis indeed a sequential cover of F ◦xat scale α.
For any f∈ F andy∈ YT, tree xyields a length −Tsequence x1:T(y)and by definition of the
global sequential covering, there exists g∈ Gαsuch that
|f(xt(y))−g(x1:t(y))| ≤α,∀t∈[T].
So by our construction of Vx,α,vg∈Vx,αholds
|f(xt(y))−vg
t(y)|=|f(xt(y))−g(x1:t(y))| ≤α,∀t∈[T],
which yields our claim after observing |Vx,α| ≤ |G α|. ■
D Additional proofs
Lemma D.1 For any X-valued Y-ary context tree xof depth T, and f: (X × Y )∗× X → ∆(Y),
we have X
y∈YTPf(y|x(y)) = 1 ,(16)
where we recall that x(y)denotes the context sequence (x1(y), . . . , xT(y)).
26Proof of Lemma D.1 This is done by induction on the depth T. The key observation is that for any
label sequence y,xt(y) =xt(y1, . . . , y t−1)only depends on the first t−1labels. For T= 1, any
context tree xis represented by its root node x1(·) =x1∈ X and hence
X
y1Pf(y1|x1) =X
y1f(x1)(y1) = 1 .
Suppose Eq. (16) holds for all context trees xof depth T≤dand all sequential functions f. Now
given any context tree x= (x1, . . . , xd+1)of depth T=d+ 1, we denote its depth dsubtree
(x1, . . . , xd)byx[d]. Then
X
y∈Yd+1Pf(y|x(y)) =X
y1:dX
yd+1Pf(y1:d+1|x1,x2(y1), . . . , xd+1(y1:d))
=X
y1:dX
yd+1Pf(y1:d|x1, . . . , xd(y1:d−1))·f(x1, . . . , xd+1(y1:d), y1:d)(yd+1)
=X
y1:dPf(y1:d|x1, . . . , xd(y1:d−1))X
yd+1f(x1, . . . , xd+1(y1:d), y1:d)(yd+1)
=X
y1:dPf(y1:d|x1, . . . , xd(y1:d−1))
=X
y∈YdPf(y|x[d](y)) = 1 ,
where the last step is due to induction. We are done. ■
27NeurIPS Paper Checklist
The checklist is designed to encourage best practices for responsible machine learning research, ad-
dressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove
the checklist: The papers not including the checklist will be desk rejected. The checklist should
follow the references and precede the (optional) supplemental material. The checklist does NOT
count towards the page limit.
Please read the checklist guidelines carefully for information on how to answer these questions. For
each question in the checklist:
• You should answer [Yes] , [No] , or [NA]
• [NA] means either that the question is Not Applicable for that particular paper or the
relevant information is Not Available.
• Please provide a short (1–2 sentence) justification right after your answer (even for NA).
The checklist answers are an integral part of your paper submission. They are visible to the
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it
(after eventual revisions) with the final version of your paper, and its final version will be published
with the paper.
The reviewers of your paper will be asked to use the checklist as one of the factors in their evalu-
ation. While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No]
" provided a proper justification is given (e.g., "error bars are not reported because it would be too
computationally expensive" or "we were unable to find the license for the dataset we used"). In
general, answering "[No] " or "[NA] " is not grounds for rejection. While the questions are phrased
in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your
best judgment and write a justification to elaborate. All supporting evidence can appear either in the
main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question,
in the justification please point to the section(s) where related material for the question can be found.
IMPORTANT, please:
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist" ,
•Keep the checklist subsection headings, questions/answers and guidelines below.
•Do not modify the questions and only use the provided macros for your answers .
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Abstract summarizes theorems we have proven.
Guidelines:
• The answer NA means that the abstract and introduction do not include the claims
made in the paper.
• The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
• The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
• It is fine to include aspirational goals as motivation as long as it is clear that these
goals are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
28Justification: We discuss limitations in the Discussion section.
Guidelines:
• The answer NA means that the paper has no limitation while the answer No means
that the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
• The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The au-
thors should reflect on how these assumptions might be violated in practice and what
the implications would be.
• The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
• The authors should reflect on the factors that influence the performance of the ap-
proach. For example, a facial recognition algorithm may perform poorly when image
resolution is low or images are taken in low lighting. Or a speech-to-text system might
not be used reliably to provide closed captions for online lectures because it fails to
handle technical jargon.
• The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
• If applicable, the authors should discuss possible limitations of their approach to ad-
dress problems of privacy and fairness.
• While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We don’t see how to justify this without machine checkable proofs, which we
have not provided.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
• All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theo-
rems.
• The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a
short proof sketch to provide intuition.
• Inversely, any informal proof provided in the core of the paper should be comple-
mented by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main
experimental results of the paper to the extent that it affects the main claims and/or conclu-
sions of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: There are no experiments.
29Guidelines:
• The answer NA means that the paper does not include experiments.
• If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
• If the contribution is a dataset and/or model, the authors should describe the steps
taken to make their results reproducible or verifiable.
• Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture
fully might suffice, or if the contribution is a specific model and empirical evaluation,
it may be necessary to either make it possible for others to replicate the model with
the same dataset, or provide access to the model. In general. releasing code and data
is often one good way to accomplish this, but reproducibility can also be provided via
detailed instructions for how to replicate the results, access to a hosted model (e.g., in
the case of a large language model), releasing of a model checkpoint, or other means
that are appropriate to the research performed.
• While NeurIPS does not require releasing code, the conference does require all sub-
missions to provide some reasonable avenue for reproducibility, which may depend
on the nature of the contribution. For example
(a) If the contribution is primarily a new algorithm, the paper should make it clear
how to reproduce that algorithm.
(b) If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c) If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to re-
produce the model (e.g., with an open-source dataset or instructions for how to
construct the dataset).
(d) We recognize that reproducibility may be tricky in some cases, in which case au-
thors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [NA]
Justification: There is no data or code.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
• Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
• While we encourage the release of code and data, we understand that this might not
be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
• The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
• The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
• The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
30• At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
• Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The experimental setting should be presented in the core of the paper to a level of
detail that is necessary to appreciate the results and make sense of them.
• The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropri-
ate information about the statistical significance of the experiments?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
• The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
• The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
• It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
• It is OK to report 1-sigma error bars, but one should state it. The authors should prefer-
ably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of
Normality of errors is not verified.
• For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
• If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: There are no experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
31• The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
• The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
• The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments
that didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have read the code and do not see any violation. Our work relates to the
mathematical foundations of a basic task in ML.
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
• If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
• The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: The paper presents a mathematical characterization of the limits of probabilis-
tic forecasting, and a (meta)algorithm that achieves these limits. For any class of interest,
there remains significant work to realize that algorithm in an efficient way. As such, our
impact is most directly on the theoretical community, who might then have direct societal
impact by producing an minimax optimal algorithm. As such, our societal impact may be
great, but it will always be quite indirect.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
• If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
• Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact spe-
cific groups), privacy considerations, and security considerations.
• The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
• The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
• If there are negative societal impacts, the authors could also discuss possible mitiga-
tion strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
32Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We are not releasing models or data.
Guidelines:
• The answer NA means that the paper poses no such risks.
• Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by re-
quiring that users adhere to usage guidelines or restrictions to access the model or
implementing safety filters.
• Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
• We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: We use no such assets.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
• The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
• For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
• If assets are released, the license, copyright information, and terms of use in the pack-
age should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the li-
cense of a dataset.
• For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
• If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documenta-
tion provided alongside the assets?
Answer: [NA]
Justification: No new assets are introduced.
Guidelines:
• The answer NA means that the paper does not release new assets.
• Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
• The paper should discuss whether and how consent was obtained from people whose
asset is used.
33• At submission time, remember to anonymize your assets (if applicable). You can
either create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the pa-
per include the full text of instructions given to participants and screenshots, if applicable,
as well as details about compensation (if any)?
Answer: [NA]
Justification: No such experiments were performed.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
• Including this information in the supplemental material is fine, but if the main contri-
bution of the paper involves human subjects, then as much detail as possible should
be included in the main paper.
• According to the NeurIPS Code of Ethics, workers involved in data collection, cura-
tion, or other labor should be paid at least the minimum wage in the country of the
data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: Paper does not involve crowdsourcing or research with human subjects.
Guidelines:
• The answer NA means that the paper does not involve crowdsourcing nor research
with human subjects.
• Depending on the country in which research is conducted, IRB approval (or equiva-
lent) may be required for any human subjects research. If you obtained IRB approval,
you should clearly state this in the paper.
• We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
• For initial submissions, do not include any information that would break anonymity
(if applicable), such as the institution conducting the review.
34