Published in Transactions on Machine Learning Research (10/2023)
Binary Classification under Local Label Differential Privacy
Using Randomized Response Mechanisms
Shirong Xu shirong@stat.ucla.edu
Department of Statistics and Data Science
University of California, Los Angeles
Chendi Wang chendi@wharton.upenn.edu
Department of Statistics and Data Science
University of Pennsylvania
Will Wei Sun sun244@purdue.edu
Daniels School of Business
Purdue University
Guang Cheng guangcheng@ucla.edu
Department of Statistics and Data Science
University of California, Los Angeles
Reviewed on OpenReview: https: // openreview. net/ forum? id= uKCGOw9bGG
Abstract
Label differential privacy is a popular branch of ϵ-differential privacy for protecting labels
in training datasets with non-private features. In this paper, we study the generalization
performance of a binary classifier trained on a dataset privatized under the label differential
privacyachievedbytherandomizedresponsemechanism. Particularly, weestablishminimax
lower bounds for the excess risks of the deep neural network plug-in classifier, theoretically
quantifying how privacy guarantee ϵaffects its generalization performance. Our theoretical
result shows: (1) the randomized response mechanism slows down the convergence of excess
risk by lessening the multiplicative constant term compared with the non-private case (ϵ=
∞); (2) asϵdecreases, the optimal structure of the neural network should be smaller for
better generalization performance; (3) the convergence of its excess risk is guaranteed even if
ϵis adaptive to the size of training sample nat a rate slower than O(n−1/2). Our theoretical
results are validated by extensive simulated examples and two real applications.
1 Introduction
In the past decade, differential privacy (DP; Dwork, 2008) has emerged as a standard statistical framework
to protect sensitive data before releasing it to an external party. The rationale behind DP is to ensure that
information obtained by an external party is robust enough to the change of a single record in a dataset.
Generally, the privacy protection via DP inevitably distorts the raw data and hence reduces data utility for
downstream learning tasks (Alvim et al., 2012; Kairouz et al., 2016; Li et al., 2023a). To achieve better
privacy-utility tradeoff, various research efforts have been devoted to analyzing the effect of DP on learning
algorithms in the machine learning community (Ghazi et al., 2021; Bassily et al., 2022; Esfandiari et al.,
2022). Depending on whether the data receiver is trusted or not, differential privacy can be categorized into
two main classes in the literature, including central differential privacy (central DP; Erlingsson et al. 2019;
Girgis et al. 2021; Wang et al. 2023) and local differential privacy (local DP; Wang et al. 2017; Arachchige
et al. 2019). Central DP relies on a trusted curator to protect all data simultaneously, whereas local DP
perturbs data on the users’ side. Local DP becomes a more popular solution to privacy protection due to its
1Published in Transactions on Machine Learning Research (10/2023)
successful applications, including Google Chrome browser (Erlingsson et al., 2014) and macOS (Tang et al.,
2017).
An important variant of differential privacy is label differential privacy (Label DP; Chaudhuri & Hsu, 2011),
which is a relaxation of DP for some real-life scenarios where input features are assumed to be publicly
available and labels are highly sensitive and should be protected. Label DP has been gaining increasing at-
tention in recent years due to the emerging demands in some real applications. For example, in recommender
systems, users’ ratings are sensitive for revealing users’ preferences that can be utilized for advertising pur-
poses (McSherry & Mironov, 2009; Xin & Jaakkola, 2014). In online advertising, a user click behavior is
usually treated as a sensitive label whereas the product description for the displayed advertisement is pub-
licly available (McMahan et al., 2013; Chapelle et al., 2014). These real scenarios motivate various research
efforts to develop mechanisms for achieving label differential privacy and understanding the fundamental
tradeoff between data utility and privacy protection. In literature, label DP can be divided into two main
classes depending on whether labels are protected in a local or central manner. In central label DP, privacy
protection is guaranteed by ensuring the output of a randomized learning algorithm is robust to the change
of a single label in the dataset (Chaudhuri & Hsu, 2011; Ghazi et al., 2021; Bassily et al., 2022; Ghazi et al.,
2023). In local label DP, labels are altered at the users’ side before they are released to learning algorithms,
ensuring that it is difficult to infer the true labels based on the released labels (Busa-Fekete et al., 2021;
Cunningham et al., 2022).
In the literature, various efforts has been devoted to developing mechanisms to achieve label DP efficiently
and analyze their essential privacy-utility tradeoffs in downstream learning tasks. The original way to
achieve label DP is via randomized response mechanisms (Warner, 1965), which alters observed labels in
a probabilistic manner. For binary labels, the randomized response mechanism flips labels onto the other
side with a pre-determined probability (Nayak & Adeshiyan, 2009; Wang et al., 2016b; Busa-Fekete et al.,
2021). Originally designed to safeguard individuals’ responses in surveys (Warner, 1965; Blair et al., 2015),
the RR mechanism has found extensive data collection applications (Wang et al., 2016b), such as pairwise
comparisons in ranking data (Li et al., 2023b) and edges in graph data (Hehir et al., 2022; Guo et al., 2023).
Ghazi et al. (2021) proposed a multi-stage training algorithm called randomized response with prior, which
flips training labels via a prior distribution learned by the trained model in the previous stage. Such a
multi-stage training algorithm significantly improves the generalization performance of the trained model
under the same privacy guarantee. Malek Esmaeili et al. (2021) proposed to apply Laplace noise addition to
one-hotencodingsoflabelsandutilizedtheiterativeBayesianinferencetode-noisetheoutputsoftheprivacy-
preserving mechanism. Bassily et al. (2022) developed a private learning algorithm under the central label
DP and established a dimension-independent deviation margin bound for the generalization performance
of several differentially private classifiers, showing that the margin guarantees that are independent of the
input dimension. However, their developed learning algorithm relies on the partition of the hypothesis and
is hence computationally inefficient. The current state-of-the-art approach, outlined in Ghazi et al. (2023),
presents a variant of RR that incorporates additional information from the loss function to enhance model
performance. Analyzing this variant can be challenging due to its construction involving the solution of an
optimization problem without a closed-form representation.
Acriticalchallengeindifferentialprivacyistounderstandtheessentialprivacy-utilitytradeoffthatshedslight
on the fundamental utility limit for a specific problem. For example, Wang & Xu (2019) studied the sparse
linear regression problem under local label DP and establish the minimax risk for the estimation error under
label DP. In this paper, we intend to study the generalization performance of binary classifiers satisfying
ϵ-local label DP, aiming to theoretically understand how the generalization performance of differentially
private classifiers are affected by the local label DP under the margin assumption (Tsybakov, 2004). To this
end, we consider the local label DP via the randomized response mechanism due to its remarkable ability to
incurring less utility loss (Wang et al., 2016b). Specifically, Wang et al. (2016b) demonstrated that, while
adhering to the same privacy standard, the RR mechanism exhibits smaller expected mean square errors
between released and actual values compared to the Laplace mechanism. Furthermore, the effectiveness
of the RR mechanism surpasses that of the output perturbation approach, particularly in scenarios where
the sensitivity of output functions is high. This result can be explained from the perspective of statistical
hypothesis testing that the RR mechanism achieves the optimal tradeoff between type I and type II errors
2Published in Transactions on Machine Learning Research (10/2023)
underϵ-label DP (Dong et al., 2022). Additionally, the RR mechanism has a succinct representation, which
allows us to develop certain theories related to deep learning.
In literature, few attempts are made to theoretically quantify the generalization performance of classifiers
under local label DP even though binary classification has already become an indispensable part of the
machine learning community. An important characteristic distinguishing binary classification problem is
that the convergence of the generalization performance depends on the behavior of data in the vicinity of
the decision boundary, which is known as the margin assumption (Tsybakov, 2004). Therefore, our first
contribution is that we theoretically quantify how local label DP alters the margin assumption, which allows
us to bridge the connection between the local label DP and the generalization performance. Additionally,
we mainly consider two scenarios for the function class of classifiers in this paper. First, we consider the
large margin classifier with its hypothesis space being a parametric function class and the deep neural
network plug-in classifier. For these two scenarios, we establish their upper bound and the minimax lower
bound for their excess risks, which theoretically quantifies how ϵaffects the generalization performance.
The implications of our theoretical results are three-fold. First, the Bayes classifier stays invariant to the
randomized response mechanism with any small ϵ, which permits the possibility of learning the optimal
classifier from the privatized dataset. Second, the local label DP achieved via the randomized response
mechanism implicitly reduces the information for estimation. Specifically, we theoretically prove that the
convergence rate of excess risk is slowed down with an additional multiplicative constant depending on ϵ.
Third, basedonourtheoreticalresults, weshowthattheexcessriskfailstoconvergewhenthe ϵisadaptiveto
the training sample size nat the order O(n−1/2), which is independent of the margin assumption. To the best
ofourknowledge, noexistingliteraturerelatedtoclassificationunderDPorcorruptedlabels(Canningsetal.,
2020; van Rooyen & Williamson, 2018) has investigated the effects of noise on neural network structures.
Our theoretical results are supported by extensive simulations and two real applications.
The rest of this paper is organized as follows. After introducing some necessary notations in Section 1.1,
Section 2 introduces the backgrounds of the binary classification problem, neural network, and the local
label differential privacy. In Section 3, we introduce the framework of the differentially private learning
under the label differential privacy and present theoretical results regarding the asymptotic behavior of the
differentially private classifier. Section 4 quantifies how ϵaffects the generalization performance of the deep
neural network plug-in classifier by establishing a minimax lower bound. Section 5 and Section 6 conduct a
series of simulations and real applications to support our theoretical results. All technical proofs are provided
in the Appendix.
1.1 Notation
For a vector x∈Rp, we denote its l1-norm and l2-norm as∥x∥1=/summationtextp
i=1|xi|and∥x∥2=/parenleftbig/summationtextp
i=1|xi|2/parenrightbig1/2,
respectively. For a function f:X→R, we denote its Lp-norm with respect to the probability measure µas
∥f∥Lp(µ)=/parenleftbig/integraltext
X|f(x)|pdµ(x)/parenrightbig1/p. For a real number a, we let⌊a⌋denote the largest integer not larger than
a. For a set S, we defineN(ξ,S,∥·∥)as the minimal number of ξ-balls needed to cover Sunder a generic
metric∥·∥. For two given sequences {An}n∈Nand{Bn}n∈N, we writeAn≳Bnif there exists a constant
C > 0such thatAn≥CBnfor anyn∈N. Additionally, we write An≍BnifAn≳BnandAn≲Bn.
2 Preliminaries
2.1 Binary Classification
The goal in binary classification is to learn a discriminant function f, which well characterizes the functional
relationship between the feature vector X∈Xand its associated label Y∈{− 1,1}. To measure the quality
off, the 0-1 risk is usually employed,
R(f) =E/parenleftig
I/parenleftbig
f(X)Y < 0/parenrightbig/parenrightig
=P/parenleftig
sign(f(X))̸=Y/parenrightig
,
whereI(·)denotes the indicator function and the expectation is taken with respect to the joint distribution
of(X,Y).
3Published in Transactions on Machine Learning Research (10/2023)
In addition to 0-1 loss, the false negative error (FNE) and false positive error (FPE) are frequently used to
assess classifier performance when dealing with highly imbalanced datasets. Specifically, FNE measures the
percentage of positive samples being classified as negative, whereas FPE measures the percentage of negative
samples being classified as positive. For a margin classifier f, the expected false positive error (EFNE) and
false positive error (EFPE) are written as
EFNE (f) =E/parenleftig
I(f(X)<0)/vextendsingle/vextendsingleY= 1/parenrightig
=P/parenleftig
sign(f(X))̸=Y/vextendsingle/vextendsingleY= 1/parenrightig
,
EFPE (f) =E/parenleftig
I(f(X)>0)/vextendsingle/vextendsingleY=−1/parenrightig
=P/parenleftig
sign(f(X))̸=Y/vextendsingle/vextendsingleY=−1/parenrightig
.
Furthermore, the 0-1 risk R(f)can be re-written as a weighted combination of EFNE and EFPE:
R(f) =EFNE (f)P(Y= 1) +EFPE (f)P(Y=−1).
Letf∗= inffR(f)denote the minimizer of R(f), which refers to as the Bayes decision rule. Generally, f∗is
obtained by minimizing R(f)in a point-wise manner and given as f∗(X) = sign/parenleftbig
η(X)−1/2/parenrightbig
withη(X) =
P(Y= 1|X). The minimal risk R(f∗)can be written as R(f∗) =EX/parenleftbig
min{η(X),1−η(X)}/parenrightbig
. In practice,
the underlying joint distribution on (X,Y)is unavailable, but a set of i.i.d. realizations D={(xi,yi)}n
i=1
is given. Therefore, it is a common practice to consider the estimation procedure based on minimizing the
sample average of a surrogate loss, which is given as
/hatwideRϕ(f) =1
nn/summationdisplay
i=1ϕ(f(xi)yi),
whereϕ(·)is the surrogate loss function replacing the 0-1 loss since the 0-1 loss is computationally intractable
(Arora et al., 1997).
LetRϕ(f) =E/parenleftbig
ϕ(f(X)Y)/parenrightbig
denote the ϕ-risk. Given that ϕis classification calibrated, the minimizer
f∗
ϕ= arg minfRϕ(f)isconsistentwiththeBayesdecisionrule(Lin,2004), i.e., sign(f∗
ϕ(x)) = sign(η(x)−1/2)
for anyx∈X. In literature, there are various classification-calibrated loss functions (Zhang, 2004; Bartlett
et al., 2006), such as exponential loss, hinge loss, logistic loss, and ψ-loss (Shen et al., 2003).
2.2 Deep Neural Network and Function Class
Letf(x; Θ)be anL-layer neural network with Rectified Linear Unit (ReLU) activation function, that is,
f(x; Θ) =AL+1/parenleftbig
hL◦hL−1◦···h1(x)/parenrightbig
+bL+1,
where◦denotes function composition, hl(x) =σ(Alx+bl)denotes the l-th layer, and Θ =/braceleftbig
(Al,bl)/bracerightbig
l=1,...,L +1denotes all the parameters. Here Al∈Rpl×pl−1is the weight matrix, bl∈Rplis
the bias term, plis the number of neurons in the l-th layer, and σ(x) = max{0,x}is the ReLU function.
To characterize the network architecture of f, we denote the number of layers in ΘasΥ(Θ), the maximum
number of nodes as ∆(Θ), the number of non-zero parameters as ∥Θ∥0, the largest absolute value in Θas
∥Θ∥∞. For a given n, we denote byFNN
n(Ln,Nn,Pn,Bn,Vn)a class of neural networks, which is defined as
FNN
n(Ln,Nn,Pn,Bn,Vn) =/braceleftbig
f(x; Θ) : Υ(Θ)≤Ln,∆(Θ)≤Nn,
∥Θ∥0≤Pn,∥Θ∥∞≤Bn,∥f∥∞≤Vn,/bracerightbig
.
Letβ >0be a degree of smoothness, then the Hölder space is defined as
H(β,X) ={f∈C⌊β⌋(X) :∥f∥H(β,X)<∞},
whereC⌊β⌋(X)the class of⌊β⌋times continuously differentiable functions on the open set Xand the Hölder
norm∥f∥H(β,X)is given as
∥f∥H(β,X)= max
m:∥m∥1≤⌊β⌋sup
x∈X|∂mf(x)|+ max
m:∥m∥1=⌊β⌋sup
x,y∈X,x̸=y|∂mf(x)−∂mf(y)|
∥x−y∥β−⌊β⌋
2,
4Published in Transactions on Machine Learning Research (10/2023)
where∂mf(x) =∂m1+...+mp
∂xm1
1···∂xmp
pf(x)denotes the partial derivative of order mwith respect to xandm=
(m1,...,mp)∈Np
0is a multi-index with N0=N∪{0}. Further, we let H(β,X,M) ={f∈H(β,X) :
∥f∥H(β,X)≤M}be a closed ball of radius MinH(β,X).
The Hölder assumption serves as a common assumption for studying the generalization capabilities of neural
networks for approximating functions possessing a certain degree of smoothness or regularity (Audibert &
Tsybakov, 2007; Kim et al., 2021). This assumption is useful in developing a tighter generalization bounds.
However, it is essential to acknowledge that the Hölder assumption presupposes a level of smoothness in the
underlying function. In reality, many real-world problems involve functions that deviate from this idealized
smoothness. When the actual smoothness of the function does not align with the assumption, algorithms
reliant on it may fall short of the anticipated generalization performance.
2.3 Local Label Differential Privacy
Label differential privacy (Label DP; Chaudhuri & Hsu, 2011) is proposed as a relaxation of differential
privacy (Dwork, 2008), aiming to protect the privacy of labels in the dataset, whereas training features are
non-sensitive and hence publicly available. An effective approach to label DP is the randomized response
mechanism (Busa-Fekete et al., 2021). As its name suggests, it protects the privacy of labels via some local
randomized response mechanisms under the framework of local differential privacy.
Definition 1. (Label Differential Privacy; Ghazi et al., 2021) A randomized training algorithm Ataking as
input a dataset is said to be (ϵ,δ)-label differentially private if for any two datasets DandD′that differ in
the label of a single example, and for any subset Sof the outputs of A, it is the case that P(A(D)∈S)≤
eϵP(A(D′)∈S) +δ, thenAis said to be ϵ-label differentially private ( ϵ-label DP).
A direct way to achieve ϵ-Label DP in binary classification is to employ the randomized response mechanism
(Warner, 1965; Nayak & Adeshiyan, 2009; Wang et al., 2016b; Karwa et al., 2017). The main idea of
the binary randomized response mechanism is to flip observed labels indepdently with a fixed probability.
Specifically, letAθdenote the randomized response mechanism parametrized by θ. For an input label Y, we
define
Aθ(Y) =/braceleftigg
Y,with probability θ,
−Y,with probability 1−θ,
whereθ >1/2denotes the probability that the value of Ystays unchanged. It is straightforward to verify
that the randomized response mechanism satisfies ϵ-label DP with ϵ= log(θ/(1−θ))(Ghazi et al., 2021;
Busa-Fekete et al., 2021). In this paper, we denote the ϵ-label DP achieved through the randomized response
mechanism as ϵ-local label DP.
3 Differentially Private Learning
3.1 Effect of Locally-Label Differential Privacy
Under the setting of local differential privacy, users do not trust the data curator and hence privatize their
sensitive data via some randomized mechanisms locally before releasing them to central servers. We let
D={(xi,yi)}n
i=1denote the original dataset containing ni.i.d. realizations of the random pair (X,Y). As
illustrated in Figure 1, users’ labels are privatized by a locally differentially private protocol Aθ, and then
the untrusted curator receives a privatized dataset, which we denote as /tildewideD={(xi,/tildewideyi)}n
i=1.
A natural question is what the quantitative relation between ϵ-label DP and the discrepancy between the
distributions ofDand/tildewideDis. This is useful to analyze how privacy parameter ϵdeteriorates the utility of
data for downstream learning tasks.
Notice that/tildewideyi’s are generated locally and independently, therefore the randomized response mechanism only
alters the conditional distribution of YgivenX, whereas the marginal distribution of Xstays unchanged.
Hence, we can assume /tildewideDis a set of i.i.d. realizations of (X,/tildewideY), and it is straightforward to verify that the
5Published in Transactions on Machine Learning Research (10/2023)
Figure 1: The framework of local label differential privacy.
conditional distribution of /tildewideYgivenX=xcan be written as
/tildewideη(x) =P(/tildewideY= 1|X=x) =θη(x) + (1−θ)(1−η(x)).
Clearly,Aθamplifies the uncertainty of the observed labels by shrinking /tildewideη(x)towards 1/2. Particularly,
/tildewideη(X) = 1/2almost surely when θ= 1/2. In this case, the privatized dataset /tildewideDconveys no information for
learning the decision function.
The following Lemma quantifies how the randomized response mechanism alters the conditional distribution
ofYand/tildewideYgiven the feature xvia the Kullback-Leibler divergence (KL) divergence between these two
Bernoulli distributions. Specifically, the inequalities in (1) explicates how the divergence changes with
privacy guarantee ϵ.
Lemma1. Suppose the randomized response mechanism /tildewideY=Aθ(Y)satisfiesϵ-label DP with θ= exp(ϵ)/(1+
exp(ϵ)), then for any x∈Xit holds that
L(ϵ,x)≤DKL/parenleftbig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightbig
≤U(ϵ,x), (1)
whereDKL/parenleftbig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightbig
denotes the Kullback-Leibler divergence (KL) divergence between P/tildewideY|X=xand
PY|X=x,L(ϵ,x) = 2(2η(x)−1)2(1 + exp(ϵ))−2, andU(ϵ,x) = min{U1(ϵ,x),U2(ϵ,x)}withU1(ϵ,x) =
(2η(x)−1)2η−1(x)(1−η(x))−1(1 + exp(ϵ))−2andU2(ϵ,x) = (2η(x)−1)2exp(−ϵ).
In Lemma 1, the lower bound L(ϵ,x)and the upper bound U(ϵ,x)share a factor (1 + exp(−ϵ))2, indicating
thatDKL(PY|X=x|P/tildewideY|X=x)decreases exponentially with respect to ϵ.
3.2 Differentially Private Classifier
On the side of the untrusted curator, inference tasks vary according to the purpose of data collector, such
as estimation of population statistics (Joseph et al., 2018; Yan et al., 2019) and supervised learning (Ghazi
et al., 2021; Esfandiari et al., 2022). In this paper, we suppose that the computation based on /tildewideDimplemented
by the untrusted curator is formulated as the following regularized empirical risk minimization task,
min
f∈FLn(f) = min
f∈F1
nn/summationdisplay
i=1ϕ(f(xi)/tildewideyi) +λnJ(f), (2)
whereϕis a surrogate loss, λnis a tuning parameter, J(·)is a penalty term, and Fis a pre-specified
hypothesis space.
We denote by /tildewideR(f) =E/bracketleftbig
sign(f(X))̸=/tildewideY/bracketrightbig
the risk with expectation taken with respect to the joint distribu-
tion of (X,/tildewideY)and let/tildewidef∗= arg minf/tildewideR(f)denote the Bayes decision rule under the distribution of (X,/tildewideY).
The excess risk of funder the distributions of (X,Y)and(X,/tildewideY)is denoted as D(f,f∗) =R(f)−R(f∗)
and/tildewideD(f,/tildewidef∗) =/tildewideR(f)−/tildewideR(/tildewidef∗), respectively.
Lemma 2. If/tildewideY=Aθ(Y)withθ>1/2, thenf∗(x) =/tildewidef∗(x)for anyx∈Xand/tildewideD(f,/tildewidef∗) = (2θ−1)D(f,f∗)
for anyf.
6Published in Transactions on Machine Learning Research (10/2023)
Lemma 2shows that the Bayes decision rule stays invariant under the randomized response mechanism. It
is clear to see that /tildewideD(f,f∗)diminishes as θgets close to 1/2. Particularly, /tildewideD(f,f∗)is equal to 0 when
θ= 1/2. This is as expected since θ= 1/2implies that/tildewideη(X) = 1/2almost surely, where all classifiers
deteriorates in performance simultaneously. This result demonstrates that the optimal classifiers for the
underlying distributions of Dand/tildewideDare identical. Basically, Lemma 2 reveals an inherent debiasing process
in the development of the generalization performance of the differentially private classifier /tildewidef. To be more
specific, we can deduce the excess risk of /tildewidefby the relation /tildewideR(/tildewidef)−/tildewideR(f∗) =eϵ−1
eϵ+1(R(/tildewidef)−R(f∗))underϵ-local
label DP.
Letf∗
ϕ= arg minfRϕ(f)and/tildewidef∗
ϕ= arg minf/tildewideRϕ(f)be the minimizers of ϕ-risk under the joint distributions
of(X,Y)and(X,/tildewideY), respectively. For illustration, we only consider hinge loss ϕ(x) = max{1−x,0}in
this paper, and similar results can be easily obtained for other loss functions by the comparison theorem
(Bartlettetal.,2006;Bartlett&Wegkamp,2008). With ϕ(·)beingthehingeloss, wehave /tildewidef∗
ϕ=f∗
ϕ=f∗=/tildewidef∗
(Bartlett et al., 2006; Lecué, 2007). With a slight abuse of notation, we use f∗to refer to these four functions
simultaneously in the sequel.
3.3 Consistency under the Randomized Response Mechanism
In this section, we establish the asymptotic behavior of the classifier trained on privatized datasets. Specif-
ically, we theoretically quantify how the randomized response mechanism affects the convergence rate of
excess risk under the low-noise assumption (Lecué, 2007).
We suppose that the randomized response mechanism satisfies the ϵ-label DP, which indicates that ϵ=
log(θ/(1−θ)). Furthermore, we denote that /tildewidefn= arg minf∈FLn(f)andH(f,f∗) =Rϕ(f)−Rϕ(f∗). In
classification problems, H(f,f∗)is an important metric that admits the decomposition into the estimation
error and the approximation error (Bartlett et al., 2006),
H(f,f∗) =H(f,f∗
F) +H(f∗
F,f∗),
wheref∗
F= arg minf∈FRϕ(f). HereH(f,f∗
F)is the estimation error and H(f∗
F,f∗)is the approximation
error. The estimation error depends on the learning algorithm in finding f∗
Fbased on a dataset with finite
samples, where the searching difficulty is unavoidably affected by the complexity of Fas the approximation
error. Generally, the richness of Fcan be measured by VC dimension (Blumer et al., 1989; Vapnik &
Chervonenkis, 2015), Rademacher complexity (Bartlett & Mendelson, 2002; Smale & Zhou, 2003), and
metric entropy methods (Zhou, 2002; Shalev-Shwartz & Ben-David, 2014).
Assumption 1. (Low-noise assumption) There exists a constant c > 0and 0< γ≤+∞such that
P/parenleftig
|2η(X)−1|≤t/parenrightig
≤ctγ,for anyt∈[0,1).
Assumption 1 is known as the low-noise assumption in the binary classification (Lecué, 2007; Shen et al.,
2003; Bartlett et al., 2006), which characterizes the behavior of 2η(x)−1around the decision boundary
η(x) = 1/2. Particularly, the case with γ= +∞andc= 1implies that the labels yi’s are deterministic in
thatη(X)takes values in{0,1}almost surely, resulting in the fastest convergence rate of the estimation
error.
Lemma 3. Denote that κϵ= (eϵ−1)/(eϵ+ 1). Under Assumption 1, for any θ∈(1/2,1], it holds that
(1)P/parenleftig
|2/tildewideη(X)−1|≤t/parenrightig
≤cκ−γ
ϵtγ,for anyt∈[0,1),
(2)/tildewideRϕ(f)−/tildewideRϕ(f∗)≥κϵ(4c)−1/γ/parenleftig
E/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig/parenrightigγ+1
γfor anyf∈F,
Lemma 3 presents some insights regarding the influence of the randomized response mechanism on the low-
noise assumption and the margin relation (Lecué, 2007), showing that the low-noise structure and margin
relation are both invariant to the randomized response mechanism in the sense that only the multiplicative
terms are enlarged by the effect of the privacy guarantee ϵ.
7Published in Transactions on Machine Learning Research (10/2023)
Assumption 2. We assume thatFis properly chosen satisfying that ∥f∥∞≤1for anyf∈Fand
logN(ξ,F,∥·∥L2(µ))≍V1(Θ) log(1 + ξ−1V2(Θ)),and VC (GF)≍V1(Θ)
whereGF={{x: sign(f(x)) = 1}:f∈F},VC(GF)denotes the VC dimension of GF,µdenotes the
marginal distribution of X,Θdenotes the parameters of f, andV1(Θ)andV2(Θ)are some functions de-
pending on Θ.
Assumption 2 characterizes the complexity of function class Fthrough the metric entropy (Zhou, 2002;
Bousquet et al., 2003; Lei et al., 2016), where V1(Θ)andV2(Θ)are quantities increasing with the size of
Θ. Assumption 2 generally holds for function classes of parametric models (Wang et al., 2016a; Xu et al.,
2021), most notably for deep neural networks (Bartlett et al., 2019; Schmidt-Hieber, 2020). Additionally,
Assumption 2 also holds for those VC classes with VC dimensions increasing with the size of Θ(Wellner
et al., 2013; Bartlett et al., 2019; Lee et al., 1994).
Theorem 1. Under Assumptions 1 and 2, for any minimizer /tildewidefnof(2), there exist some positive constants
A1andA2such that
A2/braceleftig/parenleftigV1(Θ)
nκ2ϵ/parenrightigγ+1
γ+2+τn/bracerightig
≤sup
π∈PγE/tildewideD/bracketleftbig
R(/tildewidefn)−R(f∗)/bracketrightbig
≤A1/braceleftig/parenleftigV1(Θ) log(n)
nκ2ϵ/parenrightigγ+1
γ+2+sn/bracerightig
,
wherePγbe a class of distributions of (X,Y)satisfying Assumption 1, sn= supπ∈Pγinff∈FH(f,f∗), and
τn= supπ∈Pγinff∈FD(f,f∗).
Theorem 1 quantifies the asymptotic behavior of /tildewidefnby establishing its upper and lower bounds, which
explicitly demonstrates the quantitative relation between the effect of privacy guarantee ϵand the excess
risk. Theupperboundisproventhroughauniformconcentrationinequalityundertheframeworkofempirical
risk minimization analysis. The estimator /tildewidefnis derived from a pre-specified function class Fthat may not
include the true underlying function f∗. Consequently, snrepresents the approximation error, quantifying
the capability of the optimal function within Fto approximate f∗. The accuracy of estimating the optimal
function inFfor approximating f∗depends on the complexity of F(Assumption 2) and the size of the
training set n. A largerFmay reduce snbut can increase the estimation error. Thus, achieving the best
convergence rate involves striking the right balance between these two sources of error. The proof of the
lower bound is similar to Theorem 2 in Lecué (2007), mainly applying the Assouad’s lemma (Yu, 1997) to
an analytic subset of Pγ. Further details regarding the proof are provided in the Appendix.
It is worth noting that the upper bound matches the lower bound except for a logarithmic factor when the
approximation error term sn≲/parenleftig
V1(Θ)
nκ2ϵ/parenrightigγ+1
γ+2. This shows that the randomized response mechanism slows
down the convergence rate by enlarging the multiplicative constant. Moreover, based on Theorem 1, we
can obtain the optimal convergence rate of the excess risk in classification problem under the low-noise
assumption (Lecué, 2007) by setting ϵ=∞and|F|<∞.
Lemma 4. Denote thatM= max{EFNE (f)−EFNE (f∗),EFPE (f)−EFPE (f∗)}. Under Assumption 1,
for any margin classifier f, it holds that
R(f)−R(f∗)≤M≤1
2 min{P(Y= 1),P(Y=−1)}/parenleftig
2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)/parenrightig
,(3)
wherecandγare as defined in Assumption 1. Particularly, if Assumption 1 holds with γ=∞, for any
margin classifier f, (3) becomes
R(f)−R(f∗)≤M≤3
2 min{P(Y= 1),P(Y=−1)}/parenleftbig
R(f)−R(f∗)/parenrightbig
.
Lemma 4 establishes a crucial relationship between excess risk and the maximum of excess EFNE and EFPE
for any classifier f, which also includes /tildewidefnas a special case. This connection enables us to demonstrate
the convergence of EFNE (/tildewidefn)and EFPE (/tildewidefn)based on that of the excess risk. Remarkably, this finding
8Published in Transactions on Machine Learning Research (10/2023)
implies that the differentially private classifier /tildewidefnwill exhibit similar false negative and false positive rates to
those of the Bayes classifier as the sample size ntends to infinity. In addition, increasing the degree of data
imbalance will enlarge the upper bound in (3), indicating that data imbalance slows down the convergence
rates of EFNE (/tildewidefn)and EFPE (/tildewidefn). Particularly, under the low-noise assumption with γ=∞, which implies
that samples are separable, both excess EFNE and EFPE of /tildewidefnexhibit the same convergence rate as the
excess risk regardless of the degree of class imbalance. Furthermore, this result indicates that the privacy
guaranteeϵhas a similar impact on the excess EFNE and EFPE as it does on the excess risk.
4 Deep Learning with Local Label Differential Privacy
A typical class of models that are popularly considered in the domain of differential privacy is deep neural
network (Ghazi et al., 2021; Yuan et al., 2021) due to its success in various applications in the past decade.
Unlike Section 3.3 considering the estimation and approximation errors separately, we establish theoretical
results regarding the convergence rate of the excess risk of the deep neural network plug-in classifier trained
from/tildewideD, which is obtained by making a tradeoff between the estimation and approximation errors of deep
neural networks (Schmidt-Hieber, 2020). Our theoretical results not only quantify how the optimal structure
of the deep neural network changes with the privacy parameter ϵ, but also derive the optimal privacy
guarantee we can achieve for the deep neural network classifier.
Remind that /tildewideD={(xi,/tildewideyi)}n
i=1is the privatized dataset with /tildewideyi=Aθ(yi)andθ= exp(ϵ)/(1 + exp(ϵ)). The
deep neural network is solved as
/tildewidefnn= arg min
f∈FNNn(Ln,Nn,Pn,Bn,Vn)1
nn/summationdisplay
i=1/parenleftbig
f(xi)−/tildewidezi/parenrightbig2, (4)
where/tildewidezi= (/tildewideyi+1)/2andFNN
n(Ln,Nn,Pn,Bn,Vn)is a class of multilayer perceptrons defined in Section 2.2.
The plug-in classifier based on /tildewidefnncan be obtained as /tildewidesnn= sign(/tildewidefnn−1/2). To quantify the asymptotic
behavior of/tildewidesnn, we further assume that the support of xis[0,1]p, which is a common assumption for deep
neural networks (Yarotsky, 2017; Nakada & Imaizumi, 2020)
Theorem 2. LetPγ,βbe a class of probability measures on X×{− 1,1}satisfying Assumption 1 and
η(X)∈H(β,[0,1]p,M). For any minimizer /tildewidefnnin (4) with Ln≍log(κϵn/log(n)),Nn≍(κϵn/log(n))2p
2β+p,
Bn= 1, andPn≍Nnlog(κϵn/log(n)), we have
/parenleftig1
nκ2ϵ/parenrightigβ(γ+1)
β(γ+2)+p≲sup
π∈Pγ,βE/tildewideD/bracketleftbig
R(/tildewidesnn)−R(f∗)/bracketrightbig
≲/parenleftiglogn
nκ2ϵ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2). (5)
Particularly, supπ∈Pγ,βE/tildewideD/bracketleftbig
R(/tildewidesnn)−R(f∗)/bracketrightbig
=o(1)given thatϵ≳n−1/2+ζfor anyζ >0.
In Theorem 2, we quantify the asymptotic behavior of the excess risk of /tildewidesnnby providing upper and lower
boundsfor supπ∈Pγ,βE/tildewideD/bracketleftbig
R(/tildewidesnn)−R∗/bracketrightbig
. SimilartoTheorem1, theproofofthelowerboundof(5)reliesonthe
Assouad’s lemma. A significant distinction of the upper bound in (5) from that of Theorem 1 is explicating
the approximation error snwith respect to the structure of neural network and making the optimal tradeoff
between estimation and approximation errors to achieve the fastest convergence rate. It should be noted
that ifϵ=∞which refers to the non-private case, the upper and lower bounds in (5) match with existing
theoretical results established in Audibert & Tsybakov (2007). Moreover, Theorem 2 goes a step further by
precisely characterizing the impact of ϵon the convergence of /tildewidesnnto the Bayes decision rule. Additionally,
it specifies how the optimal neural network’s structure contracts as ϵdecreases, crucial for achieving the
fastest convergence rate. Specifically, attaining this rapid convergence necessitates reducing the maximum
number of hidden units at an order of O(ϵ2p/(2β+p))when compared to the non-private case. Furthermore,
we leverage Theorem 2 to derive the fastest adaptive rate of ϵunder the consistency of /tildewidesnn. Specifically, we
find thatϵ≳n−1/2+ζfor anyζ >0to achieve this desired consistency rate. This result represents a crucial
step towards understanding the interplay between privacy and performance in our framework.
9Published in Transactions on Machine Learning Research (10/2023)
5 Simulated Experiments
This section aims to validate our theoretical results through extensive simulated examples. Specifically, we
show that the excess risk of a differentially private classifier converges to 0 for any fixed ϵ, whereas the
convergence is not achievable as long as ϵis adaptive to the size of the training dataset with some properly
chosen orders as shown in Theorems 1 and 2.
5.1 Support Vector Machine
This simulation experimentally analyzes the effect of label DP on the SVM classifier. The generation of
simulated datasets is as follows. First, we set the regression function in classification as η(x) = 1//parenleftbig
1 +
exp(−βT
0x)/parenrightbig
, whereβ0∈Rpandxare bothp-dimensional vectors generated via β0i,xi∼Unif(−1,1)for
i= 1,...,p. For each feature x, its labelyis chosen from{1,−1}with probabilities η(x)and1−η(x),
respectively. Repeatingtheaboveprocess ntimes,weobtainanon-privatetrainingdataset D={(xi,yi)}n
i=1.
Subsequently, we apply the randomized response mechanism to generate /tildewideyias/tildewideyi=Aθ(yi), whereθ=
exp(ϵ)/(1 + exp(ϵ))andϵis the privacy guarantee. Therefore, the obtained privatized training dataset
/tildewideD={(xi,/tildewideyi)}n
i=1satisfiesϵ-Label DP. Based on /tildewideD, we obtain the SVM classifier (Cortes & Vapnik, 1995),
/tildewidefn= arg min
β1
nn/summationdisplay
i=1(1−/tildewideyiβTxi)++λ∥β∥2
2,
where (x)+= max{x,0}. Next, we evaluate the performance of /tildewidefnin terms of the empirical excess risk and
the classification error,
/hatwideE(/tildewidefn) =1
ntestntest/summationdisplay
i=1I/parenleftig
sign(/tildewidefn(x′
i))̸= sign(η(x′
i)−1/2)/parenrightig/vextendsingle/vextendsingle2η(x′
i)−1/vextendsingle/vextendsingle,
CE(/tildewidefn) =1
ntestntest/summationdisplay
i=1I/parenleftig
sign(/tildewidefn(x′
i))̸=sign(η(x′
i)−1/2)/parenrightig
.
wherex′
i’s are testing samples generated in the same way as xi’s.
Scenario I . In the first scenario, we aim to verify that /hatwideE(/tildewidefn)will converge to 0 as sample size nincreases
when the privacy parameter is a fixed constant. To this end, we consider cases (n,ϵ) ={100×2i,i=
0,1,..., 8}×{ 1,2,3,4,∞}.
Scenario II . In the second scenario, we explore the asymptotic behavior of /hatwideE(/tildewidefn)withϵadaptive to
the sample size n. Specifically, we set ϵ= 5n−ζand consider cases (n,ζ) ={100×2i,i= 0,1,..., 8}×
{1/5,1/4,1/3,1/2,2/3,1}. We also include the worst case ϵ= 0as a baseline.
Scenario III . In the third scenario, we intend to verify that ϵ≍n−1/2is the dividing line between whether
or not the excess risk converges. To this end, we consider three kinds of adaptive ϵ, including ϵ≍n−1/2,
ϵ≍log(n)n−1/2, andϵ≍log−1(n)n−1/2. The size ofDis set as{100×3i,i= 0,1,..., 7}. For all cases, we
report the averaged empirical excess risk in 1,000 replications as well as their 95% confidence intervals.
For Scenario I and Scenario II, we report the averaged empirical excess risk and the classification error in
1,000 replications for each setting in Figure 2 and Figure 3, respectively. From the left panel of Figure 2, we
can see that the empirical excess risks and the classification errors with a fixed ϵconverge to 0 regardless
of the value of ϵ, showing that the randomized response mechanism with a fixed ϵfails to prevent the third
party from learning the optimal classifier based on /tildewideD. Moreover, as seen from Figure 3, when ζ <1/2the
estimatedexcessriskspresentadecreasingpatternasthesamplesizeincreases, whereasthatofthecase ζ= 1
deteriorates steadily and the curve finally overlaps with that of the worst case ϵ= 0. It is also interesting
to observe that the curve of ζ= 1/2remains unaffected by the sample size. All these phenomenons are in
accordance with the results of Theorem 1.
As can be seen in Figure 4, the curve of the case ϵ≍n−1/2remains unchanged as sample size increases as
in Scenario II. This is due to the offset of information gain yielded by increasing the sample size and the
10Published in Transactions on Machine Learning Research (10/2023)
Figure 2: The averaged classification errors (Left) and averaged empirical excess risks (Right) of all settings
withntest= 50,000in Scenario I.
Figure 3: The averaged classification errors (Left) and averaged empirical excess risks (Right) of all settings
withntest= 50,000in Scenario II.
Figure 4: The averaged classification errors (Left) and averaged empirical excess risks (Right) of all settings
withntest= 50,000in Scenario III.
information loss in the label-flipping mechanism. As expected, the additional logarithmic term significantly
alters the original curve pattern. Specifically, for the case with ϵ≍log−1(n)n−1/2, the performance of /tildewidefn
deteriorates significantly and approaches the worst case with ϵ= 0. On the contrary, the performance of /tildewidefn
in the case ϵ≍log(n)n−1/2improves significantly with /hatwideE(/tildewidefn)converging to 0. Therefore, ϵ≍n−1/2appears
11Published in Transactions on Machine Learning Research (10/2023)
to be the dividing line that determines whether the excess risk converges, which completely matches our
theoretical results.
5.2 Deep Neural Network Classifier
The simulation in this section aims to verify our theoretical results in Theorem 2, which mainly lies in two
aspects. First, we intend to verify the effect of ϵof Label DP on the optimal structure of deep neural networks
for classification problems. Specifically, as stated in Theorem 2, if label noise yielded by the randomized
response mechanism increases, a smaller deep neural network should be employed to strike a better balance
between the approximation error and the estimation error to achieve a better generalization error. Second,
the consistency in estimating the decision boundary is prohibited provided that ϵis adaptive to the training
sizenat some specific orders. To these ends, we consider generating training datasets /tildewideD={(xi,/tildewideyi)}n
i=1as
follows. First, we set the regression function as ηnn(xi) =/summationtext4
j=1sin(2πxij)/8 + 1/2withxij∼Unif(0,1)for
anyi,j. Then we generate yifrom{1,−1}with probabilities ηnn(xi)and1−ηnn(xi), respectively. As in
the last simulation, we then apply the randomized response mechanism Aθto eachyito generate/tildewideyi=Aθ(yi)
withθ= exp(ϵ)/(1 + exp(ϵ)). Then we set the hypothesis space to be the class of L-layer fully connected
neural network with equal width and the ReLU activation function, where hdenotes the widths in all hidden
layers.
The overall training process of the neural network is implemented in Tensorflow (Abadi et al., 2016) with
the Adam optimizer and learning rate being 0.001. Additionally, we employ the early-stopping technique to
monitor the training error with patience 10 and maintain the parameter with the smallest training error.
Let/tildewidefnndenote the resultant neural network obtained from minimizing (4). We construct the associated
plug-in classifier as /tildewidesnn= sign(/tildewidefnn−1/2)and evaluate its performance by the empirical excess risk and the
classification error as in Section 5.1.
Scenario I . In the first scenario, we consider privacy guarantees ϵ∈{1,2,∞}and neural network structures
withL= 2andh∈{8,12,16,20,24}with . We report the averaged empirical excess risks and the classifi-
cation errors of all cases in 100 replications as well as their 95% confidence intervals in Figure 5. Clearly, if
ϵ= 1, the optimal neural network structure is h= 8, whereas those of the cases ϵ= 2andϵ=∞areh= 20
andh= 24, respectively. Such results show that a smaller neural network is preferred when stronger privacy
protection of labels (smaller ϵ) is considered, which coincides with our theoretical results in Theorem 2 that
the optimal neural network structure to achieve the fastest convergence rate of excess risk should diminish as
ϵdecreases. Moreover, as the training sample size nincreases from 2,000 to 4,000, the optimal structure of
the neural network enlarges for the cases ϵ= 1andϵ= 2due to their new tradeoffs between the estimation
and approximation errors.
Figure 5: The averaged classification errors (Left) and averaged empirical excess risks (Right) of all cases
withntest= 50,000.
Scenario II . In the second scenario, we fix the neural network structure as (L,h) = (2,16)and consider
training sample sizes n∈{2i×103;i= 0,1,2,3,4}. To verify our theoretical results, we compare two privacy
12Published in Transactions on Machine Learning Research (10/2023)
schemesϵ≍n−1/2andϵ≍log(n)n−1/2. We also include the case with invariant privacy scheme ϵ= 4as
a baseline. For comparing their difference in trend patterns, the multiplicative constants of two adaptive
privacy schemes are chosen such that they have the same starting point as ϵ= 4whenn= 1,000. We report
the averaged empirical excess risks, the classification errors of all cases in 100 replications, and their 95%
confidence intervals in Figure 6. Clearly, the performances of the cases ϵ= 4andϵ≍log(n)n−1/2improve
asnincreases. However, the performance of case ϵ≍n−1/2presents a different pattern in generalization
performance as nincreases. Most notably, as nincreases from 8,000 to 16,000, it performance deteriorates
while the other two cases still observe significant improvements, showing that the additional logarithmic
term plays a deterministic role in the convergence of excess risk, which perfectly aligns with our theoretical
findings in Theorem 2.
Figure 6: The averaged classification errors (Left) and averaged empirical excess risks (Right) of all cases
withntest= 50,000.
6 Real Applications - Mnist Dataset
This experiment considers similar settings of the privacy parameter ϵas Section 5.2 in order to verify our
theoretical findings of DNN on the MNIST dataset (LeCun, 1998). The MNIST dataset consists of 60,000
training images and 10,000 testing images, and each sample is a 28 ×28 grey-scale pixel image of one of the 10
digits. In this experiment, we consider a binary classification problem by only including samples of digits 2
and 3 for training and testing due to their similarity in appearance. The resultant training dataset contains
12,089 training samples and 2,042 testing samples.
For the hyperparameters setting, we consider the neural network with three convolution layers with ReLU
activation and two fully-connected layers. For the three convolution layers, we set their kernel sizes and
numbers of channels as 4×4and 4, respectively. Additionally, each convolution layer is followed by a max
pooling layer with size 2×2. The first fully-connected layer has 10 hidden units with ReLU activation,
and the last layer outputs the probability of an image being digit 2. As in Section 5.2, the neural network
is trained with the Adam optimizer and learning rate being 0.001, and the early-stopping technique to
monitor the training error with patience 10 and maintain the parameter with the smallest training error. We
evaluate of the trained model by the testing error on 2,042 testing samples. We consider training sample size
n∈{2×i×103;i= 1,2,3,4,5}. Wemainlyconsidertwoscenarios, includingthefixedprivacyguaranteewith
ϵ∈{1,2,∞}and the adaptive privacy schemes with ϵ≍log(n)√
n−1,ϵ≍n−1/2, andϵ≍log−1(n)n−1/2.
The averaged testing error of each case in 50 replications is reported in Figure 7.
Figure 7 presents similar results as in Section 5.2. First, when ϵis fixed, differentially private classifiers
improve in generalization performance as the training sample size increases and attain competitive perfor-
mance as the non-private classifier ( ϵ=∞) when the training sample size is large enough. This result
accords with our theoretical findings in Theorem 1 that fixed privacy guarantee in the label DP slows down
the convergence to the optimal classifier with a multiplicative constant. In stark contrast, as shown in the
right plot of Figure 7, the convergence to the optimal classifier is prevented if ϵ≍n−1/2, as boosting the
13Published in Transactions on Machine Learning Research (10/2023)
Figure 7: The averaged testing errors with fixed ϵ(Left) and adaptive ϵ(Right) under different training
sample sizes in MNIST dataset
training size from 2,000 to 10,000 fails to significantly improve the testing error. This again aligns with our
Theorem 1
References
Martín Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin,
Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. {TensorFlow}: a system for{Large-Scale}
machine learning. In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI
16), pp. 265–283, 2016.
Mário S Alvim, Miguel E Andrés, Konstantinos Chatzikokolakis, Pierpaolo Degano, and Catuscia
Palamidessi. Differential privacy: on the trade-off between utility and information leakage. In Inter-
national Workshop on Formal Aspects in Security and Trust , pp. 39–54. Springer, 2012.
Pathum Chamikara Mahawaga Arachchige, Peter Bertok, Ibrahim Khalil, Dongxi Liu, Seyit Camtepe, and
Mohammed Atiquzzaman. Local differential privacy for deep learning. IEEE Internet of Things Journal ,
7(7):5827–5842, 2019.
Sanjeev Arora, László Babai, Jacques Stern, and Z Sweedyk. The hardness of approximate optima in lattices,
codes, and systems of linear equations. Journal of Computer and System Sciences , 54(2):317–331, 1997.
Jean-Yves Audibert and Alexandre B Tsybakov. Fast learning rates for plug-in classifiers. The Annals of
statistics , 35(2):608–633, 2007.
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural
results.Journal of Machine Learning Research , 3(Nov):463–482, 2002.
Peter L Bartlett and Marten H Wegkamp. Classification with a reject option using a hinge loss. Journal of
Machine Learning Research , 9(8), 2008.
Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. Journal
of the American Statistical Association , 101(473):138–156, 2006.
Peter L Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight VC-dimension and
pseudodimension bounds for piecewise linear neural networks. The Journal of Machine Learning Research ,
20(1):2285–2301, 2019.
Raef Bassily, Mehryar Mohri, and Ananda Theertha Suresh. Open problem: Better differentially pri-
vate learning algorithms with margin guarantees. In Po-Ling Loh and Maxim Raginsky (eds.), Pro-
ceedings of Thirty Fifth Conference on Learning Theory , volume 178 of Proceedings of Machine Learn-
14Published in Transactions on Machine Learning Research (10/2023)
ing Research , pp. 5638–5643. PMLR, 02–05 Jul 2022. URL https://proceedings.mlr.press/v178/
open-problem-bassily22a.html .
GraemeBlair, KosukeImai, andYang-YangZhou. Designandanalysisoftherandomizedresponsetechnique.
Journal of the American Statistical Association , 110(511):1304–1319, 2015.
Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, and Manfred K Warmuth. Learnability and the
vapnik-chervonenkis dimension. Journal of the ACM (JACM) , 36(4):929–965, 1989.
Olivier Bousquet, Stéphane Boucheron, and Gábor Lugosi. Introduction to statistical learning theory. In
Summer School on Machine Learning , pp. 169–207. Springer, 2003.
Robert Istvan Busa-Fekete, Umar Syed, Sergei Vassilvitskii, et al. Population level privacy leakage in binary
classification wtih label noise. In NeurIPS 2021 Workshop Privacy in Machine Learning , 2021.
Timothy I Cannings, Yingying Fan, and Richard J Samworth. Classification with imperfect training labels.
Biometrika , 107(2):311–330, 04 2020. doi: 10.1093/biomet/asaa011. URL https://doi.org/10.1093/
biomet/asaa011 .
Olivier Chapelle, Eren Manavoglu, and Romer Rosales. Simple and scalable response prediction for display
advertising. ACM Transactions on Intelligent Systems and Technology (TIST) , 5(4):1–34, 2014.
Kamalika Chaudhuri and Daniel Hsu. Sample complexity bounds for differentially private learning. In Pro-
ceedings of the 24th Annual Conference on Learning Theory , pp.155–186.JMLRWorkshopandConference
Proceedings, 2011.
Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine Learning , 20(3):273–297, 1995.
Teddy Cunningham, Konstantin Klemmer, Hongkai Wen, and Hakan Ferhatosmanoglu. Geopointgan: Syn-
thetic spatial data with local label differential privacy. arXiv preprint arXiv:2205.08886 , 2022.
Jinshuo Dong, Aaron Roth, and Weijie J Su. Gaussian differential privacy. Journal of the Royal Statistical
Society Series B: Statistical Methodology , 84(1):3–54, 2022.
Cynthia Dwork. Differential privacy: A survey of results. In International Conference on Theory and
Applications of Models of Computation , pp. 1–19. Springer, 2008.
Úlfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova. Rappor: Randomized aggregatable privacy-
preserving ordinal response. In Proceedings of the 2014 ACM SIGSAC Conference on Computer and
Communications Security , pp. 1054–1067, 2014.
Úlfar Erlingsson, Vitaly Feldman, Ilya Mironov, Ananth Raghunathan, Kunal Talwar, and Abhradeep
Thakurta. Amplification by shuffling: From local to central differential privacy via anonymity. In Pro-
ceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms , pp. 2468–2479. SIAM,
2019.
Hossein Esfandiari, Vahab Mirrokni, Umar Syed, and Sergei Vassilvitskii. Label differential privacy via
clustering. In International Conference on Artificial Intelligence and Statistics , pp. 7055–7075. PMLR,
2022.
Badih Ghazi, Noah Golowich, Ravi Kumar, Pasin Manurangsi, and Chiyuan Zhang. Deep learning with
label differential privacy. Advances in Neural Information Processing Systems , 34:27131–27145, 2021.
Badih Ghazi, Pritish Kamath, Ravi Kumar, Ethan Leeman, Pasin Manurangsi, Avinash Varadarajan, and
Chiyuan Zhang. Regression with label differential privacy. In The Eleventh International Conference on
Learning Representations , 2023. URL https://openreview.net/forum?id=h9O0wsmL-cT .
Antonious Girgis, Deepesh Data, Suhas Diggavi, Peter Kairouz, and Ananda Theertha Suresh. Shuffled
model of differential privacy in federated learning. In International Conference on Artificial Intelligence
and Statistics , pp. 2521–2529. PMLR, 2021.
15Published in Transactions on Machine Learning Research (10/2023)
Xiao Guo, Xiang Li, Xiangyu Chang, and Shujie Ma. Privacy-preserving community detection for locally
distributed multiple networks. arXiv preprint arXiv:2306.15709 , 2023.
Jonathan Hehir, Aleksandra Slavkovic, and Xiaoyue Niu. Consistent spectral clustering of network block
models under local differential privacy. Journal of Privacy and Confidentiality , 12(2), 2022.
Matthew Joseph, Aaron Roth, Jonathan Ullman, and Bo Waggoner. Local differential privacy for evolving
data.Advances in Neural Information Processing Systems , 31, 2018.
Peter Kairouz, Sewoong Oh, and Pramod Viswanath. Extremal mechanisms for local differential privacy.
The Journal of Machine Learning Research , 17(1):492–542, 2016.
Vishesh Karwa, Pavel N Krivitsky, and Aleksandra B Slavković. Sharing social network data: differentially
private estimation of exponential family random-graph models. Journal of the Royal Statistical Society:
Series C (Applied Statistics) , 66(3):481–500, 2017.
YongdaiKim, IlsangOhn, andDonghaKim. Fastconvergenceratesofdeepneuralnetworksforclassification.
Neural Networks , 138:179–197, 2021.
Vladimir Koltchinskii. Oracle inequalities in empirical risk minimization and sparse recovery problems: École
D’Été de Probabilités de Saint-Flour XXXVIII-2008 , volume 2033. Springer Science & Business Media,
2011.
Guillaume Lecué. Optimal rates of aggregation in classification under low noise assumption. Bernoulli , 13
(4):1000–1022, 2007.
Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/ , 1998.
Wee Sun Lee, Peter L Bartlett, and Robert C Williamson. Lower bounds on the VC-dimension of smoothly
parametrized function classes. In Proceedings of the Seventh Annual Conference on Computational Learn-
ing Theory , pp. 362–367, 1994.
Yunwen Lei, Lixin Ding, and Yingzhou Bi. Local rademacher complexity bounds based on covering numbers.
Neurocomputing , 218:320–330, 2016.
Ximing Li, Chendi Wang, and Guang Cheng. Statistical theory of differentially private marginal-based
data synthesis algorithms. In The Eleventh International Conference on Learning Representations, ICLR
2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023a. URL https://openreview.net/pdf?id=
hxUwnEGxW87 .
Zhechen Li, Ao Liu, Lirong Xia, Yongzhi Cao, and Hanpin Wang. Differentially private condorcet voting.
InProceedings of the AAAI Conference on Artificial Intelligence , volume 37, pp. 5755–5763, 2023b.
Yi Lin. A note on margin-based loss functions in classification. Statistics & Probability Letters , 68(1):73–82,
2004.
Mani Malek Esmaeili, Ilya Mironov, Karthik Prasad, Igor Shilov, and Florian Tramer. Antipodes of label
differential privacy: Pate and alibi. Advances in Neural Information Processing Systems , 34:6934–6945,
2021.
H Brendan McMahan, Gary Holt, David Sculley, Michael Young, Dietmar Ebner, Julian Grady, Lan Nie,
Todd Phillips, Eugene Davydov, Daniel Golovin, et al. Ad click prediction: a view from the trenches. In
Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining ,
pp. 1222–1230, 2013.
Frank McSherry and Ilya Mironov. Differentially private recommender systems: Building privacy into the
netflix prize contenders. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining , pp. 627–636, 2009.
16Published in Transactions on Machine Learning Research (10/2023)
Ryumei Nakada and Masaaki Imaizumi. Adaptive approximation and generalization of deep neural network
with intrinsic dimensionality. Journal of Machine Learning Research , 21(174):1–38, 2020.
Tapan K Nayak and Samson A Adeshiyan. A unified framework for analysis and comparison of randomized
response surveys of binarycharacteristics. Journal of Statistical Planning and Inference , 139(8):2757–2766,
2009.
Igal Sason and Sergio Verdú. f-divergence inequalities. IEEE Transactions on Information Theory , 62(11):
5973–6006, 2016.
Johannes Schmidt-Hieber. Nonparametric regression using deep neural networks with relu activation func-
tion.The Annals of Statistics , 48(4):1875–1897, 2020.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algorithms .
Cambridge university press, 2014.
Xiaotong Shen and Wing Hung Wong. Convergence rate of sieve estimates. The Annals of Statistics , pp.
580–615, 1994.
Xiaotong Shen, George C Tseng, Xuegong Zhang, and Wing Hung Wong. On ψ-learning. Journal of the
American Statistical Association , 98(463):724–734, 2003.
Steve Smale and Ding-Xuan Zhou. Estimating the approximation error in learning theory. Analysis and
Applications , 1(01):17–41, 2003.
Jun Tang, Aleksandra Korolova, Xiaolong Bai, Xueqiang Wang, and Xiaofeng Wang. Privacy loss in apple’s
implementation of differential privacy on macos 10.12. arXiv preprint arXiv:1709.02753 , 2017.
Alexander B Tsybakov. Optimal aggregation of classifiers in statistical learning. The Annals of Statistics ,
32(1):135–166, 2004.
Brendan van Rooyen and Robert C. Williamson. A theory of learning with corrupted labels. Journal of
Machine Learning Research , 18(228):1–50, 2018. URL http://jmlr.org/papers/v18/16-315.html .
Vladimir N Vapnik and A Ya Chervonenkis. On the uniform convergence of relative frequencies of events to
their probabilities. In Measures of Complexity , pp. 11–30. Springer, 2015.
Chendi Wang, Buxin Su, Jiayuan Ye, Reza Shokri, and Weijie Su. Unified enhancement of privacy bounds
for mixture mechanisms via f-differential privacy. In NeurIPS , 2023.
Di Wang and Jinhui Xu. On sparse linear regression in the local differential privacy model. In International
Conference on Machine Learning , pp. 6628–6637. PMLR, 2019.
Junhui Wang, Xiaotong Shen, Yiwen Sun, and Annie Qu. Classification with unstructured predictors and
an application to sentiment analysis. Journal of the American Statistical Association , 111(515):1242–1253,
2016a.
Tianhao Wang, Jeremiah Blocki, Ninghui Li, and Somesh Jha. Locally differentially private protocols for
frequency estimation. In 26th USENIX Security Symposium (USENIX Security 17) , pp. 729–745, 2017.
Yue Wang, Xintao Wu, and Donghui Hu. Using randomized response for differential privacy preserving data
collection. In EDBT/ICDT Workshops , volume 1558, pp. 0090–6778, 2016b.
Stanley L Warner. Randomized response: A survey technique for eliminating evasive answer bias. Journal
of the American Statistical Association , 60(309):63–69, 1965.
Jon Wellner et al. Weak convergence and empirical processes: with applications to statistics . Springer Science
& Business Media, 2013.
Yu Xin and Tommi Jaakkola. Controlling privacy in recommender systems. Advances in Neural Information
Processing Systems , 27, 2014.
17Published in Transactions on Machine Learning Research (10/2023)
Shirong Xu, Ben Dai, and Junhui Wang. Sentiment analysis with covariate-assisted word embeddings.
Electronic Journal of Statistics , 15(1):3015–3039, 2021.
Ziqi Yan, Qiong Wu, Meng Ren, Jiqiang Liu, Shaowu Liu, and Shuo Qiu. Locally private jaccard similarity
estimation. Concurrency and Computation: Practice and Experience , 31(24):e4889, 2019.
Dmitry Yarotsky. Error bounds for approximations with deep relu networks. Neural Networks , 94:103–114,
2017.
Bin Yu. Assouad, Fano, and Le Cam. In Festschrift for Lucien Le Cam: Research Papers in Probability and
Statistics , pp. 423–435. Springer, 1997.
Sen Yuan, Milan Shen, Ilya Mironov, and Anderson CA Nascimento. Practical, label private deep learning
training based on secure multiparty computation and differential privacy. Cryptology ePrint Archive , 2021.
TongZhang. Statisticalbehaviorandconsistencyofclassificationmethodsbasedonconvexriskminimization.
The Annals of Statistics , 32(1):56–85, 2004.
Ding-Xuan Zhou. The covering number in learning theory. Journal of Complexity , 18(3):739–767, 2002.
A Appendix
Lemma 1 (Restatement of Lemma 1) .Suppose the randomized response mechanism /tildewideY=Aθ(Y)satisfies
ϵ-Label DP with θ= exp(ϵ)/(1 + exp(ϵ)), then for any x∈Xit holds that
L(ϵ,x)≤DKL/parenleftbig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightbig
≤U(ϵ,x),
whereDKL/parenleftbig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightbig
denotes the Kullback-Leibler divergence (KL) divergence between P/tildewideY|X=xand
PY|X=x,L(ϵ,x) = 2(2η(x)−1)2(1 + exp(ϵ))−2, andU(ϵ,x) = min{U1(ϵ,x),U2(ϵ,x)}withU1(ϵ,x) =
(2η(x)−1)2η−1(x)(1−η(x))−1(1 + exp(ϵ))−2andU2(ϵ,x) = (2η(x)−1)2exp(−ϵ).
Proof of Lemma 1 : We first prove the lower bound of DKL/parenleftig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightig
, which is mainly based
on the Pinsker’s inequality (Sason & Verdú, 2016). Without loss of generality, we assume that η(x)>1/2.
Define
S(p,q) =plogp
q+ (1−p) log1−p
1−q−2(p−q)2,
wherep,q∈[0,1]. LetS(p,q)take the partial derivative with respect to q, we get
∂S(p,q)
∂q=−p
q+1−p
1−q+ 4(p−q) =−(p−q)(1
q(1−q)−4)≤0,forq≤p,
where the last inequality follows from that fact that q(1−q)≤1/4forq∈[0,1]and the equality holds when
p=q. Suppose thatAθsatisfiesϵ-Label DP, which is equivalent to set θ= exp(ϵ)/(1 + exp(ϵ)). Therefore,
it holds that
DKL/parenleftig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightig
≥2(η(x)−/tildewideη(x))2= 2(2η(x)−1)2(1 + exp(ϵ))−2≜L(ϵ,x).
Next, we proceed to prove the upper bound. For any pair of distribution PandQ, we have
DKL(P|Q) =DKL(P|Q) + 1−1≤exp(DKL(P|Q))−1.
18Published in Transactions on Machine Learning Research (10/2023)
Recall that Yand/tildewideYtake values in{−1,1}, we have
DKL/parenleftig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightig
≤exp/parenleftbig
DKL/parenleftbig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightbig/parenrightbig
−1
≤η(x)η(x)
/tildewideη(x)+ (1−η(x))1−η(x)
1−/tildewideη(x)−1 =η(x)/parenleftigη(x)
/tildewideη(x)−1/parenrightig
+ (1−η(x))/parenleftig1−η(x)
1−/tildewideη(x)−1/parenrightig
=η(x)/parenleftigη(x)−/tildewideη(x)
/tildewideη(x)/parenrightig
+ (1−η(x))/parenleftig/tildewideη(x)−η(x)
1−/tildewideη(x)/parenrightig
=/parenleftbig
η(x)−/tildewideη(x)/parenrightbig2
/tildewideη(x)(1−/tildewideη(x)).
Note that
/tildewideη(x)(1−/tildewideη(x)) =/parenleftig
θη(x) + (1−θ)(1−η(x))/parenrightig/parenleftig
(1−θ)η(x) +θ(1−η(x))/parenrightig
=θ(1−θ)η2(x) +η(x)(1−η(x))/parenleftbig
θ2+ (1−θ)2/parenrightbig
+θ(1−θ)(1−η(x))2
≥max{η(x)(1−η(x)),θ(1−θ)}.
It then follows that
DKL/parenleftig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightig
≤/parenleftbig
η(x)−/tildewideη(x)/parenrightbig2
max{η(x)(1−η(x)),θ(1−θ)}. (6)
Pluggingθ= exp(ϵ)/(1 + exp(ϵ))into (6) yields that
DKL/parenleftig
PY|X=x/vextendsingle/vextendsingleP/tildewideY|X=x/parenrightig
≤(2η(x)−1)2
max{η(x)(1−η(x))(1 + exp(ϵ))2,exp(ϵ)}≜U(θ,x).
This completes the proof.
Lemma 2 (Restatement of Lemma 2) .If/tildewideY=Aθ(Y)withθ>1/2, thenf∗(x) =/tildewidef∗(x)for anyx∈Xand
/tildewideD(f,/tildewidef∗) = (2θ−1)D(f,f∗)for anyf.
Proof of Lemma 2: By the definition of /tildewideη(x), we can obtain
2/tildewideη(x)−1 = (2θ−1)(2η(x)−1). (7)
Clearly, 2η(x)>1indicatesthat 2/tildewideη(x)>1providedthat θ>1/2. Bythefactthat f∗(x) = sign(η(x)−1/2),
it holds that f∗(x) =/tildewidef∗(x)for anyx∈X. Recall that the excess risk in terms of 0-1 loss can be written as
R(f)−R(f∗) =E/bracketleftbig
|sign(f(X))̸= sign(f∗(X))||2η(X)−1|/bracketrightbig
.
Combined with (7), it holds that
/tildewideR(f)−/tildewideR(/tildewidef∗) =E/bracketleftbig
|sign(f(X))̸= sign(/tildewidef∗(X))||2/tildewideη(X)−1|/bracketrightbig
=(2θ−1)E/bracketleftbig
|sign(f(X))̸= sign(/tildewidef∗(X))||2η(X)−1|/bracketrightbig
=(2θ−1)/parenleftbig
R(f)−R(f∗)/parenrightbig
.
This completes the proof.
Lemma 3 (Restatement of Lemma 3) .Denote that κϵ= (eϵ−1)/(eϵ+ 1). Under Assumption 1, for any
θ∈(1/2,1], it holds that
(1)P/parenleftig
|2/tildewideη(X)−1|≤t/parenrightig
≤cκ−γ
ϵtγ,for anyt∈[0,1),
(2)/tildewideRϕ(f)−/tildewideRϕ(f∗)≥κϵ(4c)−1/γ/parenleftig
E/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig/parenrightigγ+1
γfor anyf∈F,
19Published in Transactions on Machine Learning Research (10/2023)
Proof of Lemma 3 : By the assumption that ∥f∥∞≤1and the fact that 0-1 loss is upper bounded by
hinge loss, we obtain Rϕ(f)−Rϕ(f∗)≥R(f)−R(f∗). Sinceϕis set as hinge loss, it holds that
Rϕ(f)−Rϕ(f∗) =EX/bracketleftbig
|f(X)−f∗(X)||1−2η(X)|/bracketrightbig
≥tEX/bracketleftbig
|f(X)−f∗(X)|I/parenleftbig
|1−2η(X)|>t/parenrightbig/bracketrightbig
.
By the fact that I/parenleftbig
|1−2η(X)|>t/parenrightbig
= 1−I/parenleftbig
|1−2η(X)|≤t/parenrightbig
, it then follows that
Rϕ(f)−Rϕ(f∗)≥t/parenleftig
EX/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig
−2P/parenleftbig
|1−2η(X)|≤t/parenrightbig/parenrightig
≥t/parenleftig
EX/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig
−2ctγ/parenrightig
=tEX/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig
−2ctγ+1
where the last inequality follows from Assumption 1. Choosing tsuch thattE/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig
= 4ctγ+1,
we get
Rϕ(f)−Rϕ(f∗)≥(4c)−1/γ/parenleftig
E/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig/parenrightigγ+1
γ.
Next, we proceed to establish the relation between /tildewideRϕ(f)−/tildewideRϕ(f∗)andE/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig
. For eachx∈X,
the conditional risk is given as
E/tildewideY/parenleftig
ϕ(f(X)/tildewideY)|X=x/parenrightig
=/tildewideη(x)ϕ(f(x)) + (1−/tildewideη(x))ϕ(−f(x))
=[θη(x) + (1−θ)(1−η(x))]ϕ(f(x)) + [θ(1−η(x)) + (1−θ)η(x)]ϕ(−f(x))
=/parenleftig
θη(x)ϕ(f(x)) +θ(1−η(x))ϕ(−f(x))/parenrightig
+/parenleftig
(1−θ)(1−η(x))ϕ(f(x)) + (1−θ)η(x)ϕ(−f(x))/parenrightig
.
Taking the expectation with respect to Xyields that
/tildewideRϕ(f) =E(X,/tildewideY)/parenleftig
ϕ(f(X)/tildewideY)/parenrightig
=θRϕ(f) + (1−θ)Rϕ(−f) (8)
Notice that ϕis hinge loss, hence
Rϕ(f)−Rϕ(f∗) =Rϕ(−f∗)−Rϕ(−f),
for anyfwith∥f∥∞≤1. It follows that
/tildewideRϕ(f)−/tildewideRϕ(f∗) =θ(Rϕ(f)−Rϕ(f∗)) + (1−θ)(Rϕ(−f)−Rϕ(−f∗))
= (2θ−1)(Rϕ(f)−Rϕ(f∗))
≥(2θ−1)(4c)−1/γ/parenleftig
E/bracketleftbig
|f(X)−f∗(X)|/bracketrightbig/parenrightigγ+1
γ.
This completes the proof.
Lemma 4 (Restatement of Lemma 4) .Denote thatM= max{EFNE (f)−EFNE (f∗),EFPE (f)−
EFPE (f∗)}. Under Assumption 1, for any margin classifier f, it holds that
R(f)−R(f∗)≤M≤1
2 min{P(Y= 1),P(Y=−1)}/parenleftig
2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)/parenrightig
,
wherecandγare as defined in Assumption 1. Particularly, if Assumption 1 holds with γ=∞, for any
margin classifier f, (3) becomes
R(f)−R(f∗)≤M≤3
2 min{P(Y= 1),P(Y=−1)}/parenleftbig
R(f)−R(f∗)/parenrightbig
.
20Published in Transactions on Machine Learning Research (10/2023)
Proof of Lemma 4 : We first prove the left-hand side of (3). By the relation among R(f), EFNE (f), and
EFPE (f), one has
R(f)−R(f∗) =/parenleftbig
EFNE (f)−EFNE (f∗)/parenrightbig
P(Y= 1) +/parenleftbig
EFPE (f)−EFPE (f∗)/parenrightbig
P(Y=−1)
≤max{EFNE (f)−EFNE (f∗),EFPE (f)−EFPE (f∗)}(P(Y= 1) + P(Y=−1))
= max{EFNE (f)−EFNE (f∗),EFPE (f)−EFPE (f∗)}.
Next, we prove the right-hand side of (3). We first define
S1(f) ={x∈X: sign(f(x)) = 1}andS−1(f) ={x∈X: sign(f(x)) =−1}.
Clearly, it can be verified that S1(f∗) ={x:η(x)>1/2}andS−1(f∗) ={x:η(x)<1/2}. With these, we
further get
EFNE (f)−EFNE (f∗) =1
P(Y= 1)/parenleftigg/integraldisplay
S−1(f)η(x)PX(x)dx−/integraldisplay
S−1(f∗)η(x)PX(x)dx/parenrightigg
=1
P(Y= 1)/parenleftigg/integraldisplay
S−1(f)\△S−1η(x)PX(x)dx−/integraldisplay
S−1(f∗)\△S−1η(x)PX(x)dx/parenrightigg
,
EFPE (f)−EFPE (f∗) =1
P(Y=−1)/parenleftigg/integraldisplay
S1(f)(1−η(x))PX(x)dx−/integraldisplay
S1(f∗)(1−η(x))PX(x)dx/parenrightigg
=1
P(Y=−1)/parenleftigg/integraldisplay
S1(f)\△S1(1−η(x))PX(x)dx−/integraldisplay
S1(f∗)\△S1(1−η(x))PX(x)dx/parenrightigg
,
where△S−1=S−1(f∗)∩S−1(f)and△S1=S1(f∗)∩S1(f). We can easily verify that S−1(f)\△S−1=
S1(f∗)\△S1andS1(f)\△S1=S−1(f∗)\△S−1. Therefore, it follows that
R(f)−R(f∗) =/parenleftbigg/integraldisplay
△1η(x)PX(x)dx−/integraldisplay
△2η(x)PX(x)dx/parenrightbigg
+/parenleftbigg/integraldisplay
△2(1−η(x))PX(x)dx−/integraldisplay
△1(1−η(x))PX(x)dx/parenrightbigg
≥2/parenleftbigg/integraldisplay
△1η(x)PX(x)dx−/integraldisplay
△2η(x)PX(x)dx/parenrightbigg
−/integraldisplay
△1∪△2PX(x)dx,
where△1=S−1(f)\△S−1and△2=S1(f)\△S1.
Then
/integraldisplay
△1η(x)PX(x)dx−/integraldisplay
△2η(x)PX(x)dx≤/integraldisplay
△1∪△2PX(x)dx+R(f)−R(f∗)
≤/integraldisplay
△1∪△2I(|2η(x)−1|≤t)PX(x)dx+/integraldisplay
△1∪△2I(|2η(x)−1|>t)PX(x)dx+R(f)−R(f∗)
≤ctγ+/integraldisplay
△1∪△2I(|2η(x)−1|>t)|2η(x)−1|
tPX(x)dx+R(f)−R(f∗)
≤ctγ+t−1(R(f)−R(f∗)) +R(f)−R(f∗)
where the last inequality follows from the low-noise assumption. Choosing t= (R(f)−R(f∗))1
1+γ/c1
1+γ, we
get
/integraldisplay
△1η(x)PX(x)dx−/integraldisplay
△2η(x)PX(x)dx≤2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)
Finally, we have
EFNE (f)−EFNE (f∗)≤1
2P(Y= 1)/parenleftig
2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)/parenrightig
. (9)
21Published in Transactions on Machine Learning Research (10/2023)
Using similar steps, we also have
EFPE (f)−EFPE (f∗)≤1
2P(Y=−1)/parenleftig
2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)/parenrightig
.(10)
Combining (9) and (10) yields that
max{EFNE (f)−EFNE (f∗),EFPE (f)−EFPE (f∗)}
≤1
2 min{P(Y= 1),P(Y=−1)}/parenleftig
2c−1
1+γ(R(f)−R(f∗))γ
1+γ+R(f)−R(f∗)/parenrightig
.
The desired results immediately follows by letting γgo to infinity, which completes the proof.
Theorem 1 (Restatement of Theorem 1) .Under Assumptions 1 and 2, for any minimizer /tildewidefnof(2), there
exist some positive constants A1andA2such that
A2/braceleftig/parenleftigV1(Θ)
nκ2ϵ/parenrightigγ+1
γ+2+τn/bracerightig
≤sup
π∈PγE/tildewideD/bracketleftbig
R(/tildewidefn)−R(f∗)/bracketrightbig
≤A1/braceleftig/parenleftigV1(Θ) log(n)
nκ2ϵ/parenrightigγ+1
γ+2+sn/bracerightig
,
wherePγbe a class of distributions of (X,Y)satisfying Assumption 1, sn= supπ∈Pγinff∈FH(f,f∗), and
τn= supπ∈Pγinff∈FD(f,f∗).
Proof of Theorem 1 :Proof of the upper bound. The proof of the upper bound mainly utilizes a
uniform concentration inequality. We first denote that /tildewideH(f,f∗) =/tildewideRϕ(f)−/tildewideRϕ(f∗). Next, we proceed to
prove that P/parenleftbig/tildewideH(/tildewidefn,f∗)≥δn/parenrightbig
converges to zero as ngoes to infinity for some convergent sequence δn>0.
For anyδn>0, we letFδn={f∈F:/tildewideH(f,f∗)≥δn}. If/tildewidefn∈Fδn, one has
sup
f∈Fδn1
nn/summationdisplay
i=1ϕ(f∗
F(xi)/tildewideyi) +λnJ(f∗
F)−1
nn/summationdisplay
i=1ϕ(f(xi)/tildewideyi)−λnJ(f)≥0.
This follows from the optimality of /tildewidefnfor minimizing (2). Therefore,
P/parenleftig
/tildewideH(/tildewidefn,f∗)≥δn/parenrightig
≤P/parenleftigg
sup
f∈Fδn1
nn/summationdisplay
i=1ϕ(f∗
F(xi)/tildewideyi) +λnJ(f∗
F)−1
nn/summationdisplay
i=1ϕ(f(xi)/tildewideyi)−λnJ(f)≥0/parenrightigg
≡I.
Next, it suffices to prove the convergence of Iwithn. To this end, we proceed to provide an upper bound
forI. Define thatHij={f∈F : 2i−1δn≤/tildewideH(f,f∗)≤2iδn,2j−1J0≤J(f)≤2jJ0}fori≥1andj≥1
andHi0={f∈F : 2i−1δn≤/tildewideH(f,f∗)≤2iδn,J(f)≤J0}. It can be easily verified that Fδnadmits the
decomposition as Fδn=∪∞
i=1∪∞
j=0Hij. With this, Ican be upper bounded as
I=P/parenleftigg
sup
f∈Fδn1
nn/summationdisplay
i=1ϕ(f∗
F(xi)/tildewideyi) +λnJ(f∗
F)−1
nn/summationdisplay
i=1ϕ(f(xi)/tildewideyi)−λnJ(f)≥0/parenrightigg
≤∞/summationdisplay
i=1∞/summationdisplay
j=0P/parenleftigg
sup
f∈Hij1
nn/summationdisplay
i=1ϕ(f∗
F(xi)/tildewideyi) +λnJ(f∗
F)−1
nn/summationdisplay
i=1ϕ(f(xi)/tildewideyi)−λnJ(f)≥0/parenrightigg
≤∞/summationdisplay
i=1∞/summationdisplay
j=0P/parenleftigg
sup
f∈Hij1
nn/summationdisplay
i=1lϕ(f∗
F,zi)−1
nn/summationdisplay
i=1lϕ(f,zi)≥λn/parenleftbig
inf
f∈HijJ(f)−J0/parenrightbig
+ inf
f∈HijE(ϕ(f(Xi)/tildewideYi))−E(ϕ(f∗
F(Xi)/tildewideYi))/parenrightigg
,
wherezi= (xi,/tildewideyi)andlϕ(f,zi) =ϕ(f(xi)/tildewideyi)−E(ϕ(f(Xi)/tildewideYi)). Here it is important to note that
inf
f∈HijE(ϕ(f(Xi)/tildewideYi))−E(ϕ(f∗
F(Xi)/tildewideYi)) = inf
f∈Hij/tildewideRϕ(f)−/tildewideRϕ(f∗)−/tildewideRϕ(f∗
F) +/tildewideRϕ(f∗)
= inf
f∈Hij/tildewideH(f,f∗) +/tildewideH(f∗
F,f∗) = inf
f∈Hij/tildewideH(f,f∗) + (2θ−1)H(f∗
F,f∗).
22Published in Transactions on Machine Learning Research (10/2023)
LetV(i,j) =λn/parenleftbig
inff∈HijJ(f)−J0/parenrightbig
+ inff∈HijE(lϕ(f,Z))−E(lϕ(f∗
F,Z)). By the definition of Hij, we get
V(i,j)≥M(i,j) =λn(2j−1−1)J0+ (2i−1−1/4)δn,fori,j≥1, (11)
where the inequality follows by assuming that (2θ−1)sn≤1/4δn. Next, we suppose that λnJ0≤1/4δn, we
further have
M(i,0)≥(2i−1−1/2)δn≥2i−2δn,fori≥1. (12)
Plugging (11) and (12) into I, it follows that
I≤∞/summationdisplay
i=1∞/summationdisplay
j=0P/parenleftig
sup
f∈Hij1
nn/summationdisplay
i=1lϕ(f∗
F,zi)−1
nn/summationdisplay
i=1lϕ(f,zi)≥M(i,j)/parenrightig
=∞/summationdisplay
i=1∞/summationdisplay
j=0Pij.
Therefore, bounding Ireduces to bounding Pijseparately. Let Qn=1
n/summationtextn
i=1/parenleftbig
lϕ(f∗
F,zi)−lϕ(f,zi)/parenrightbig
, then
Pijcan be written as
Pij=P/parenleftigg
sup
f∈HijQn−E/bracketleftbig
sup
f∈HijQn/bracketrightbig
≥M(i,j)−E/bracketleftbig
sup
f∈HijQn/bracketrightbig/parenrightigg
.
Next, we proceed to bound Pijby the Talagrand’s inequality (see Theorem 2.6 in Koltchinskii, 2011). To
this end, we first establish the relation between E/bracketleftbig
supf∈HijQn/bracketrightbig
andM(i,j). Letq(f,zi) =ϕ(f∗
F(xi)yi)−
ϕ(f(xi)yi)andz′= (z′
1,...,z′
n)be a ghost sample.
E/bracketleftigg
sup
f∈HijQn/bracketrightigg
=E/bracketleftigg
sup
f∈Hij1
nn/summationdisplay
i=1q(f,zi)−E(q(f,Z))/bracketrightigg
=Ez/bracketleftigg
sup
f∈HijEz′/parenleftig1
nn/summationdisplay
i=1q(f,zi)−1
nn/summationdisplay
i=1q(f,z′
i)|z/parenrightig/bracketrightigg
≤Ez,z′/bracketleftigg
sup
f∈Hij/parenleftig1
nn/summationdisplay
i=1q(f,zi)−1
nn/summationdisplay
i=1q(f,z′
i)/parenrightig/bracketrightigg
=Ez,z′,σ/bracketleftigg
sup
f∈Hij/parenleftig1
nn/summationdisplay
i=1σi(q(f,zi)−q(f,z′
i))/parenrightig/bracketrightigg
≤2EzEσ/bracketleftig
sup
f∈Hij/parenleftig1
nn/summationdisplay
i=1σiq(f,zi)/parenrightig/bracketrightig
= 2Rn(Hij).
By Theorem 3.11 in Koltchinskii (2011), it follows that there exists some constant C2such that
Rn(Hij)≤C2√nE/integraldisplayσij
0/radicalig
logN(u,Hij,L2(Pn))du≤C2√nE/integraldisplayσij
0/radicalbig
V1(Θ) log(u−1V2(Θ))du,
whereσij=/radicalig
supf∈Hij1
n/summationtextn
i=1q2(f,zi),∥f∥L2(Pn)=/radicalig
1
n/summationtextn
i=1q2(f,zi), andN(Hij,L2(Pn),u)is the
minimal number of L2(Pn)-balls of radius uto coverHij.
Notice that/integraltextσij
0/radicalbig
V1(Θ) log(u−1V2(Θ))duis concave function with respect to σij, therefore
E/braceleftbigg/integraldisplayσij
0/radicalbig
V1(Θ) log(u−1V2(Θ))du/bracerightbigg
≤/integraldisplayEσij
0/radicalbig
V1(Θ) log(u−1V2(Θ))du≤/integraldisplay√
Eσ2
ij
0/radicalbig
V1(Θ) log(u−1V2(Θ))du.
By the definition of σij, we have E/bracketleftbig
σ2
ij/bracketrightbig
=E/bracketleftig
supf∈Hij1
n/summationtextn
i=1q2(f,zi)/bracketrightig
. Using symmetrization and con-
traction inequalities, we get
E/bracketleftbig
σ2
ij/bracketrightbig
≤sup
f∈HijE[q2(f,Z)] + 8Rn(f,Hij).
23Published in Transactions on Machine Learning Research (10/2023)
Next, we proceed to bound E[q2(f,Z)].
E[q2(f,Z)] =E/bracketleftig
ϕ(f∗
F(X)/tildewideY)−ϕ(f(X)/tildewideY)/bracketrightig2
≤2E/bracketleftig
ϕ(f∗
F(X)/tildewideY)−ϕ(f∗
ϕ(X)/tildewideY)/bracketrightig2
+ 2E/bracketleftig
ϕ(f∗
F(X)/tildewideY)−ϕ(f(X)/tildewideY)/bracketrightig2
≤2E/bracketleftig
ϕ(f∗
F(X)/tildewideY)−ϕ(f∗(X)/tildewideY)/bracketrightig
+ 2E/bracketleftig/vextendsingle/vextendsingleϕ(f(X)/tildewideY)−ϕ(f∗
F(X)/tildewideY)/vextendsingle/vextendsingle/bracketrightig
≤2sn+ 2E/bracketleftbig/vextendsingle/vextendsinglef(X)−f∗
F(X)/vextendsingle/vextendsingle/bracketrightbig
≤2−1δn+ 2E/bracketleftbig/vextendsingle/vextendsinglef(X)−f∗
F(X)/vextendsingle/vextendsingle/bracketrightbig
, (13)
where the second inequality follows from the assumption that ∥f∥∞≤1. Combining this with Lemma 3
yields that
sup
f∈HijE[q2(f,Z)]≤2−1δn+ 2C1/parenleftbig
(2θ−1)−1(/tildewideRϕ(f)−/tildewideRϕ(f∗))/parenrightbigγ
γ+1= 4C1(2θ−1)−γ
γ+1(2iδn)γ
γ+1,
whereC1= (4c)1
γ+1. Consequently, we get
Rn(Hij)≤C2√n/integraldisplayUij(f)
0/radicalbig
V1(Θ) log(u−1V2(Θ))du, (14)
whereUij(f) = min/braceleftbig/radicalig
4C1(2θ−1)−γ
γ+1(2iδn)γ
γ+1+ 8Rn(Hij),1/bracerightbig
due to the fact that |q(f,Z)|≤1. Then,
the right-hand side of (14)can be upper bounded as
C2√n/integraldisplayUij(f)
0/radicalbig
V1(Θ) log(u−1V2(Θ))du=C2V2(Θ)/radicalbig
V1(Θ)√n/integraldisplayUij(f)/V2(Θ)
0/radicalbigg
log/parenleftbig1
u/parenrightbig
du
=C2V2(Θ)/radicalbig
V1(Θ)√n/integraldisplay+∞
V2(Θ)
Uij(f)1
u2/radicalig
log/parenleftbig
u/parenrightbig
du≤2C2/radicalbig
V1(Θ)Uij(f)√n/radicaligg
log/parenleftbigV2(Θ)
Uij(f)/parenrightbig
. (15)
Combining (15) with (14) yields that
/parenleftig
Rn(Hij)/parenrightig2
≤4C2
2V1(Θ)/parenleftig
4C1(2θ−1)−γ
γ+1(2iδn)γ
γ+1+ 8Rn(Hij)/parenrightig
nlog/parenleftbigV2(Θ)
Uij(f)/parenrightbig
. (16)
Solving (16) gives Rn(f,Hij)≲max{V1(Θ)n−1,n−1/2V1(Θ)1/2(2θ−1)−γ
2(γ+1)δγ
2(γ+1)
n}. Therefore, we get
Rn(f,Hij)≤1/4δnprovided that
/parenleftbig
V1(Θ)/n/parenrightbigγ+1
γ+2(2θ−1)−γ
γ+2log(n/V1(Θ))≤Cδn, (17)
for some large constants C. Hence, as ngoes to infinity, it follows that
Rn(f,Hij)≤1/4δn≤1/4M(i,j).
With this, we get
E/bracketleftbig
sup
f∈HijQn/bracketrightbig
≤Rn(f,Hij)≤1/4M(i,j).
Therefore,Pijcan be further bounded as
Pij≤P/parenleftigg
sup
f∈HijQn−E/bracketleftbig
sup
f∈HijQn/bracketrightbig
≥1/2M(i,j)/parenrightigg
. (18)
24Published in Transactions on Machine Learning Research (10/2023)
Applying Talagrand’s inequality to the right-hand side, it follows that there exists some positive constants
C4such that
Pij≤C4exp/parenleftigg
−nM(i,j)
2C4log/parenleftbig
1 +M(i,j)
2E[σ2
ij]/parenrightbig/parenrightigg
.
As proved above, we can verify that there exists some constant C5
E[σ2
ij]≤sup
f∈HijE[q2(f,Z)] + 8Rn(f,Hij)≤C5/parenleftig
(2θ−1)−γ
γ+1(2iδn)γ
γ+1+M(i,j)/parenrightig
.
Notice thatM(i,j)
2E[σ2
ij]converges to 0 as nincreases, therefore there exists some constant 0<C 7<1such that
log(1 +x)≥C7xforx∈[0,1/(2C5)]. It then follows that
Pij≤C4exp/parenleftigg
−C7nM2(i,j)
4C4C5/parenleftbig
(2θ−1)−γ
γ+1(M(i,j))γ
γ+1+M(i,j)/parenrightbig/parenrightigg
.
SinceM(i,j)≪(2θ−1)−γ
γ+1(M(i,j))γ
γ+1whenθ−1/2 =o(1)andM(i,j) =o(1), we have
Pij≤C4exp/parenleftig
−C8n(2θ−1)γ
γ+1Mγ+2
γ+1(i,j)/parenrightig
,
whereC8=C7/(4C4C5). Therefore, we have
n/summationdisplay
i=1n/summationdisplay
j=0Pij≤n/summationdisplay
i=1n/summationdisplay
j=1C4exp/parenleftigg
−C8nMγ+2
γ+1(i,j)
(2θ−1)−γ
γ+1/parenrightigg
+n/summationdisplay
i=1C4exp/parenleftigg
−C8nMγ+2
γ+1(i,0)
(2θ−1)−γ
γ+1/parenrightigg
≡I1+I2.
Note that for any i,j≥1,
Mγ+2
γ+1(i,j)≥/parenleftbig
(2i−1−1/4)δn+λn(2j−1−1)J0/parenrightbigγ+2
γ+1
≥(2i−1−1/4)δγ+2
γ+1n+ (2j−1−1)(λnJ0)γ+2
γ+1
≥i/2δγ+2
γ+1n+ (j−1)(λnJ0)γ+2
γ+1.
HenceI1is upper bounded as
I1≤n/summationdisplay
i=1n/summationdisplay
j=1C4exp
−C8ni/2δγ+2
γ+1n+ (j−1)(λnJ0)γ+2
γ+1
(2θ−1)−γ
γ+1

=C4exp/parenleftigg
−C8nδγ+2
γ+1
n
2(2θ−1)−γ
γ+1/parenrightigg
1−exp/parenleftigg
−C8nδγ+2
γ+1
n
2(2θ−1)−γ
γ+1/parenrightigg·1
1−exp/parenleftbigg
−C8n(λnJ0)γ+2
γ+1
2(2θ−1)−γ
γ+1/parenrightbigg≤4C4exp
−C8nδγ+2
γ+1n
2(2θ−1)−γ
γ+1
,
where the last inequality holds when max/braceleftigg
exp/parenleftigg
−C8nδγ+2
γ+1
n
2(2θ−1)−γ
γ+1/parenrightigg
,exp/parenleftbigg
−C8nδ2−1/γ
n
2(2θ−1)−γ
γ+1/parenrightbigg/bracerightigg
≤1/2, which holds
true whenngoes to infinity. Similarly, for I2, we get
I2≤n/summationdisplay
i=1C4exp
−i/4C8nδγ+2
γ+1n
(2θ−1)−γ
γ+1
≤2C4exp
−C8nδγ+2
γ+1n
4(2θ−1)−γ
γ+1
.
25Published in Transactions on Machine Learning Research (10/2023)
Combining I1andI2, it follows that
I≤6C4exp
−C8nδγ+2
γ+1n
4(2θ−1)−γ
γ+1
=T1exp
−T2nδγ+2
γ+1n
(2θ−1)−γ
γ+1
,
whereT1= 6C4andT2=C8/4. Therefore, we conclude that
P/parenleftig
/tildewideH(/tildewidefn,f∗)≥δn/parenrightig
≤T1exp
−T2nδγ+2
γ+1n
(2θ−1)−γ
γ+1
.
With a choice of δnsuch thatδn≥C9/parenleftbig
(2θ−1)−γ
γ+1|Θ|n−1log(n/|Θ|)/parenrightbigγ+1
γ+2for some positive constants
C9>0, we have/tildewideH(/tildewidefn,f∗) =op(1), which implies that E/parenleftbig/tildewideH(/tildewidefn,f∗)/parenrightbig
=Op(δn). Notice that T1andT2are
both independent of π, therefore we further have
sup
π∈PγP/parenleftig
/tildewideH(/tildewidefn,f∗)≥δn/parenrightig
≤T1exp
−T2nδγ+2
γ+1n
(2θ−1)−γ
γ+1
. (19)
By the relation between excess risk and excess ϕ-riskE/tildewideD/parenleftbig/tildewideD(/tildewidefn,f∗)/parenrightbig
≤E/tildewideD/parenleftbig/tildewideH(/tildewidefn,f∗)/parenrightbig
(Bartlett et al., 2006),
we further have
sup
π∈PγE/tildewideD/parenleftig
/tildewideD(/tildewidefn,f∗)/parenrightig
=O(δn).
Combining this with the Lemma 2 that D(/tildewidefn,f∗) = (2θ−1)−1/tildewideD(/tildewidefn,f∗), we get
sup
π∈PγE/tildewideD/parenleftig
D(/tildewidefn,f∗)/parenrightig
=O(δn(2θ−1)−1).
The fastest rate for δncan be obtained by choosing the fastest rate such that the right-hand side of (19)
converges to zero with nand (17) holds, which yields that
δ≍/parenleftbig
V1(Θ)/n/parenrightbigγ+1
γ+2(2θ−1)−γ
γ+2log(n).
This completes the proof of the upper bound.
Proof of lower bound. We first define the minimax excess risk as
Wn= inf
fsup
π∈PγE/tildewideD/bracketleftbig
R(f)−R(f∗)/bracketrightbig
,
which admits the decomposition as
Wn= inf
fsup
π∈Pγ/braceleftig
E/tildewideD/bracketleftbig
R(f)−inf
f∈FR(f)/bracketrightbig
+ inf
f∈FR(f)−R(f∗)/bracerightig
,
where the second term on the right-hand side denotes the approximation error under the 0-1 risk. In what
follows, we proceed to consider a sub-family of Pγsuch that inff∈FR(f) =R(f∗). For example, let P′⊂Pγ
be such a sub-family, then we have
Wn≥inf
fsup
π∈P′/braceleftig
E/tildewideD/bracketleftbig
R(f)−inf
f∈FR(f)/bracketrightbig/bracerightig
+ sup
π∈Pγ/parenleftig
inf
f∈FR(f)−R(f∗)/parenrightig
= inf
fsup
π∈P′/braceleftig
E/tildewideD/bracketleftbig
R(f)−R(f∗)/bracketrightbig/bracerightig
+ sup
π∈Pγ/parenleftig
inf
f∈FR(f)−R(f∗)/parenrightig
=(2θ−1)−1inf
fsup
/tildewideπ∈/tildewideP′(θ)/braceleftig
E/tildewideD/bracketleftbig/tildewideR(f)−/tildewideR(f∗)/bracketrightbig/bracerightig
+ sup
π∈Pγ/parenleftig
inf
f∈FR(f)−R(f∗)/parenrightig
,
26Published in Transactions on Machine Learning Research (10/2023)
where the last inequality follows from Lemma 2 and /tildewideP′(θ)is a set of probability measures /tildewideπon(X,/tildewideY)such
that any probability distribution /tildewideπ∈/tildewideP′(θ)is associated with an π∈P′with/tildewideπandπhaving the same
marginal distribution on Xand/tildewideY=Aθ(Y).
To provide a lower bound for Wn, it suffices to bound inffsup/tildewideπ∈/tildewideP′(θ)/braceleftig
E/tildewideD/bracketleftbig/tildewideR(f)−/tildewideR(f∗)/bracketrightbig/bracerightig
. For ease of
notation, we denote /tildewidestWn= inffsup/tildewideπ∈/tildewideP′(θ)E/tildewideD/bracketleftbig/tildewideR(f)−/tildewideR(f∗)/bracketrightbig
and/tildewidePγ(θ) ={/tildewideπ(X,/tildewideY) :/tildewideY=Aθ(Y),π∈Pγ}.
Then we proceed to construct /tildewideP′(θ)⊂/tildewidePγ(θ). First, following from Lemma 3, we have for any /tildewideπ∈/tildewidePγ(θ)
P/parenleftig
|2/tildewideη(X)−1|≤t/parenrightig
≤c(2θ−1)−γtγ,
where the probability is measured under /tildewideπ.
By Assumption 2, we know VC(GF)≍V 1(Θ). For anyNsuch thatN≍V 1(Θ), there exist Ndistinct
pointsx1,...,xNsuch that{x1,...,xN}is shattered byGF. Therefore, we consider distribution supported
on{x1,...,xN}. Letw∈(0,1)be a number satisfying (N−1)w≤1. LetQbe the probability measure on
Xsuch that
Q(xi) =/braceleftigg
w, i = 1,...,N−1,
1−(N−1)w, i =N.
In what follows, we consider the hypercube C={−1,1}N−1. For anyσ= (σ1,...,σN−1)∈C, we define the
regression function as
/tildewideησ(xi) =/braceleftigg1+σjh
2, i= 1,...,N−1,
1, i =N.
Next, we let/tildewideπσdenote the associated probability measure on X×{− 1,1}withQbeing marginal distribution
onXand/tildewideησ(x)being the regression function. With this, we obtain
P/parenleftbig
|2/tildewideησ(X)−1|≤t/parenrightbig
= (N−1)wI(h≤t).
By assuming (N−1)w≤c(2θ−1)−γhγ, we have P/parenleftbig
|2ησ(X)−1|≤t/parenrightbig
=c(2θ−1)−γtγfor anyt∈[0,1),
which indicates that /tildewideπσ∈/tildewidePγ(θ). By setting/tildewideP′(θ) ={/tildewideπσ:σ∈C}, we have
/tildewidestWn= inf
fsup
/tildewideπσ∈/tildewideP′(θ)E/bracketleftbig/tildewideR(f)−/tildewideR(f∗
σ)/bracketrightbig
,
wheref∗
σ(xi) =σifori= 1,...,N−1.
Under/tildewideπσ,
/tildewideR(f)−/tildewideR(f∗
σ) =E/tildewideπσ/bracketleftbig
|sign(f(X))̸=f∗
σ(X)||1−2/tildewideη(X)|/bracketrightbig
=1
2E/tildewideπσ/bracketleftbig
|sign(f(X))−f∗
σ(X)||1−2/tildewideη(X)|/bracketrightbig
≥t
2E/tildewideπσ/bracketleftig
|sign(f(X))−f∗
σ(X)|/parenleftig
1−P/parenleftbig
|1−2/tildewideη(X)|≤t/parenrightbig/parenrightig/bracketrightig
≥(2θ−1)(41−γc)−1/γ/parenleftig
E/tildewideπσ/bracketleftbig
|sign(f(X))−f∗
σ(X)|/bracketrightbig/parenrightigγ+1
γ
≥(2θ−1)(41−γc)−1/γ/parenleftig
wN−1/summationdisplay
i=1|sign(f(xi))−f∗
σ(xi)|/bracketrightbig/parenrightigγ+1
γ.
Under the distribution /tildewideπσ, we havef∗(xi) =σifori= 1,...,N−1, which then implies that
/tildewideR(f)−/tildewideR(f∗
σ)≥(2θ−1)(41−γc)−1/γwγ+1
γ/parenleftigN−1/summationdisplay
i=1|sign(f(xi))−σi|/parenrightigγ+1
γ.
27Published in Transactions on Machine Learning Research (10/2023)
Taking the expectation of both sides with respect to /tildewideDyields that
E/tildewideD/parenleftig
/tildewideR(f)−/tildewideR(f∗
σ)/parenrightig
≥(2θ−1)(41−γc)−1/γwγ+1
γE/tildewideD/bracketleftig/parenleftigN−1/summationdisplay
i=1|sign(f(xi))−σi|/parenrightigγ+1
γ/bracketrightig
≥(2θ−1)(41−γc)−1/γwγ+1
γEγ+1
γ
/tildewideD/bracketleftig/parenleftigN−1/summationdisplay
i=1|sign(f(xi))−σi|/parenrightig/bracketrightig
,
where the second inequality follows from Jensen’s inequality.
For ease of notation, we let X(w,γ,θ ) = (2θ−1)(41−γc)−1/γwγ+1
γ.
sup
/tildewideπσ∈/tildewideP′(θ)E/tildewideD/parenleftig
/tildewideR(f)−/tildewideR(f∗
σ)/parenrightig
≥sup
/tildewideπσ∈/tildewideP′(θ)X(w,γ,θ )Eγ+1
γ
/tildewideD/bracketleftig/parenleftigN−1/summationdisplay
i=1|sign(f(xi))−σi|/parenrightig/bracketrightig
,
≥1
2N/summationdisplay
σ∈CX(w,γ,θ )Eγ+1
γ
/tildewideD/bracketleftig/parenleftigN−1/summationdisplay
i=1|sign(f(xi))−σi|/parenrightig/bracketrightig
=1
2N−1/summationdisplay
σ∈CX(w,γ,θ )Eγ+1
γ
/tildewideD/bracketleftigN−1/summationdisplay
i=1I/parenleftbig
sign(f(xi))̸=σi/parenrightbig/bracketrightig
=X(w,γ,θ )/parenleftig1
2N−1/summationdisplay
σ∈CN−1/summationdisplay
i=1E/tildewideD/bracketleftig
I/parenleftbig
sign(f(xi))̸=σi/parenrightbig/bracketrightig/parenrightigγ+1
γ
=X(w,γ,θ )/parenleftigN−1/summationdisplay
i=11
2N−1/summationdisplay
σ∈CP/tildewideπσ/parenleftbig
sign(f(xi))̸=σi/parenrightbig/parenrightigγ+1
γ.
For eachi, we observe that
1
2N−1/summationdisplay
σ∈CP/tildewideπσ/parenleftig
sign(f(xi))̸=σi/parenrightig
=1
2N−1/summationdisplay
σ:σi=1P/tildewideπσ/parenleftig
sign(f(xi))̸=σi/parenrightig
+1
2N−1/summationdisplay
σ:σi=−1P/tildewideπσ/parenleftig
sign(f(xi))̸=σi/parenrightig
=2P+i/parenleftig
sign(f(xi))̸= 1/parenrightig
+ 2P−i/parenleftig
sign(f(xi))̸=−1/parenrightig
≥2−2TV(P⊗n
+i,P⊗n
−i).
where P+i=1
2N−1/summationtext
σ:σi=1P/tildewideπσ,P−i=1
2N−1/summationtext
σ:σi=−1P/tildewideπσ, and TV (Pn
+i,Pn
−i)denotes the total variation
between P⊗n
+iandP⊗n
−i. Notice that for any probability measures PandQ, we have
TV(P,Q) =1
2/integraldisplay
|p(x)−q(x)|dx=1
2/integraldisplay
|/radicalbig
p(x)−/radicalbig
q(x)||/radicalbig
p(x) +/radicalbig
q(x)|dx
≤1
2/parenleftig/integraldisplay/parenleftbig/radicalbig
p(x)−/radicalbig
q(x)/parenrightbig2dx/parenrightig1/2/parenleftig/integraldisplay/parenleftbig/radicalbig
p(x) +/radicalbig
q(x)/parenrightbig2dx/parenrightig1/2
≤/radicalbig
H2(P,Q),
whereH2(P,Q)denotes the Hellienger distance between PandQ. Letσandσ′be two indexes such that
σl=σ′
lforl̸=iandσi=−σ′
i= 1, then we have
TV(P⊗n
+i,P⊗n
−i)≤/summationdisplay
σ,σ′1
2N−2TV/parenleftbig
P⊗n
/tildewideπσ,P⊗n
/tildewideπσ′/parenrightbig
≤max
σ,σ′TV/parenleftbig
P⊗n
/tildewideπσ,P⊗n
/tildewideπσ′/parenrightbig
≤max
σ,σ′H(P⊗n
/tildewideπσ,P⊗n
/tildewideπσ′).
By the definition of /tildewideπσand/tildewideπσ′, we get
H2(P/tildewideπσ,P/tildewideπσ′) =wN−1/summationdisplay
i=1/parenleftig/radicalbig
ησ(xi)−/radicalbig
ησ′(xi)/parenrightig2
+/parenleftig/radicalbig
1−ησ(xi)−/radicalbig
1−ησ′(xi)/parenrightig2
=2w(1−/radicalbig
1−h2)≤2wh2,
28Published in Transactions on Machine Learning Research (10/2023)
for anyh∈[0,1]. By the fact that H2(P⊗n,Q⊗n) = 2−2(1−2−1H2(P,Q))n, we have
H2(P⊗n
/tildewideπσ,P⊗n
/tildewideπσ′) =2−2/bracketleftbig
1−w(1−/radicalbig
1−h2)/bracketrightbign≤2−2/bracketleftbig
1−nw(1−/radicalbig
1−h2)/bracketrightbig
=2nw(1−/radicalbig
1−h2)≤1/16,
where the last inequality holds by choosing wandhsuch thatwh2≤n−1/32, from which it follows that
TV(Pn
+i,Pn
−i)≤1/4. Notice that wandhare chosen to satisfy (N−1)w≤c(2θ−1)−γhγandwh2≤n−1/32.
For simplicity, we obtain the following solution by considering the case equalities hold.
h=(N−1)1
γ+2(2θ−1)γ
γ+2
(32cn)1
γ+2andw=c2
γ+2(N−1)−2
γ+2(2θ−1)−2γ
γ+2
(32n)γ
γ+2.
Therefore, we can conclude that
sup
/tildewideπσ∈/tildewideP′(θ)E/tildewideD/parenleftig
/tildewideR(f)−/tildewideR(f∗
σ)/parenrightig
≥(2θ−1)(41−γ)−1/γc−1
γ+2(N−1)−2γ+2
γ(γ+2)(2θ−1)−2γ+2
γ+2
(32n)γ+1
γ+2/parenleftig3(N−1)
2/parenrightigγ+1
γ
=(2θ−1)(41−γ)−1/γc−1
γ+2(N−1)γ+1
γ+2(2θ−1)−2γ+2
γ+2
(32n)γ+1
γ+2/parenleftig3
2/parenrightigγ+1
γ
=(2θ−1)(41−γ)−1/γc−1
γ+2/parenleftigN−1
32n(2θ−1)2/parenrightigγ+1
γ+2/parenleftig3
2/parenrightigγ+1
γ.
ChoosingN≍V1(Θ)yields that
inf
fsup
/tildewideπσ∈/tildewideP′(θ)E/tildewideD/parenleftig
/tildewideR(f)−/tildewideR(f∗)/parenrightig
≥(2θ−1)A2/parenleftigV1(Θ)
n(2θ−1)2/parenrightigγ+1
γ+2,
whereA2≍(41−γ)−1/γc−1
γ+2(2−1)6γ+6
γ+2(3/2)γ+1
γ.
Following from Lemma 2, it holds that
inf
fsup
π∈PγE/tildewideD/parenleftig
R(f)−R(f∗)/parenrightig
≥A2/parenleftigV1(Θ)
n(2θ−1)2/parenrightigγ+1
γ+2+ sup
π∈Pγ/parenleftig
inf
f∈FR(f)−R(f∗)/parenrightig
.
This completes the proof of the lower bound.
Corollary 1. Suppose thatFis chosen such that sn= 0andϵis adaptive to nsuch thatϵ=o(1). There
exists some constants A3>0such that supπ∈PγE/tildewideD/bracketleftbig
R(/tildewidefn)−R(f∗)/bracketrightbig
≥A3provided that ϵ≲n−1/2.
Proof of Corollary 1 : By Theorem 1, we have
sup
π∈PγE/tildewideD/bracketleftbig
R(/tildewidefn)−R(f∗)/bracketrightbig
≥A2/braceleftig/parenleftigV1(Θ)
nκ2ϵ/parenrightigγ+1
γ+2+τn/bracerightig
.
Sincesn= 0impliesτn= 0, we further have
sup
π∈PγE/tildewideD/bracketleftbig
R(/tildewidefn)−R(f∗)/bracketrightbig
≥A2/braceleftig/parenleftigV1(Θ)
nκ2ϵ/parenrightigγ+1
γ+2/bracerightig
.
Without loss of generality, we assume that ϵ<1sinceϵ=o(1). Then, by the definition of κϵ,κϵ≍ϵwhen
ϵ→0. Therefore, we have
V1(Θ)
nκ2ϵ=V1(Θ)(exp(ϵ) + 1)2
n(exp(ϵ)−1)2≥V1(Θ)
ne2ϵ2, (20)
where the last inequality follows from the fact that ex−1>exfor anyx∈(0,1]. Further, if ϵ=o/parenleftbig
1/√n/parenrightbig
, we
havenϵ2=o(1). Therefore, it follows that V1(Θ)n−1κ−2
ϵ≥CV1(Θ)e−2for some constants C. The desired
result immediately follows by setting A3= (CV1(Θ)e−2)γ+1
γ+2and this completes the proof.
29Published in Transactions on Machine Learning Research (10/2023)
Theorem2 (RestatementofTheorem2) .LetPγ,βbe a class of probability measures on X×{− 1,1}satisfying
Assumption 1 and η(X)∈H(β,[0,1]p,M). For any minimizer /tildewidefnnin (4) with Ln≍log(κϵn/log(n)),
Nn≍(κϵn/log(n))2p
2β+p,Bn= 1, andPn≍Nnlog(κϵn/log(n)), we have
/parenleftig1
nκ2ϵ/parenrightigβ(γ+1)
β(γ+2)+p≲sup
π∈Pγ,βE/tildewideD/bracketleftbig
R(/tildewidesnn)−R(f∗)/bracketrightbig
≲/parenleftiglogn
nκ2ϵ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2).
Particularly, supπ∈Pγ,βE/tildewideD/bracketleftbig
R(/tildewidesnn)−R(f∗)/bracketrightbig
=o(1)given thatϵ≳n−1/2+ζfor anyζ >0.
Proof of Theorem 2 :Proof of the upper bound. Let/tildewideZ= (/tildewideY+ 1)/2. We intend to establish the
connection between the excess risk of /tildewidefnnand∥/tildewidefnn−η∥2
L2(PX). Here the proof is mainly based on Lemma
5.2 in Audibert & Tsybakov (2007).
/tildewideR(/tildewidesnn)−/tildewideR(f∗) =E/bracketleftig/vextendsingle/vextendsingle2/tildewideη(X)−1/vextendsingle/vextendsingle·I/parenleftbig
/tildewidesnn(X)̸=f∗(X)/parenrightbig/bracketrightig
≤2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−1/2/vextendsingle/vextendsingle·I/parenleftbig
/tildewidesnn(X)̸=f∗(X)/parenrightbig
·I/parenleftbig
|/tildewideη(X)−1/2|≤t/parenrightbig/bracketrightig
+ 2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−1/2/vextendsingle/vextendsingle·I/parenleftbig
/tildewidesnn(X)̸=f∗(X)/parenrightbig
·I/parenleftbig
|/tildewideη(X)−1/2|>t/parenrightbig/bracketrightig
≤2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−/tildewidefnn(X)/vextendsingle/vextendsingle·I/parenleftbig
|/tildewideη(X)−1/2|≤t/parenrightbig/bracketrightig
+ 2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−/tildewidefnn(X)/vextendsingle/vextendsingle·I/parenleftbig
|/tildewideη(X)−/tildewidefnn(X)|>t/parenrightbig/bracketrightig
, (21)
where the last inequality follows from the fact that/vextendsingle/vextendsingle/tildewideη(X)−1/2/vextendsingle/vextendsingle≤/vextendsingle/vextendsingle/tildewideη(X)−/tildewidefnn(X)/vextendsingle/vextendsingle, when/tildewidesnn(X)̸=f∗(X).
Next, by Cauchy–Schwarz inequality, (21) can be further bounded as
2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−/tildewidefnn(X)/vextendsingle/vextendsingle·I/parenleftbig
|/tildewideη(X)−1/2|≤t/parenrightbig/bracketrightig
+ 2E/bracketleftig/vextendsingle/vextendsingle/tildewideη(X)−/tildewidefnn(X)/vextendsingle/vextendsingle·I/parenleftbig
|/tildewideη(X)−1/2|>t/parenrightbig/bracketrightig
≤2∥/tildewideη−/tildewidefnn∥L2(PX)/radicalbig
P(|/tildewideη(X)−1/2|≤t) + 2∥/tildewideη−/tildewidefnn∥2
L2(PX)/t
≤21−γ/2∥/tildewideη−/tildewidefnn∥L2(PX)cκ−γ/2
ϵtγ/2+ 2∥/tildewideη−/tildewidefnn∥2
L2(PX)/t.
Choosingt=∥/tildewidefnn−/tildewideη∥2
γ+2
L2(PX)κγ
γ+2ϵ, we get
/tildewideR(/tildewidesnn)−/tildewideR(f∗)≲κ−γ
γ+2ϵ∥/tildewideη−/tildewidefnn∥2γ+2
γ+2
L2(PX).
Subsequently, by Lemma 2, it follows that
R(/tildewidesnn)−R(f∗) =κ−1
ϵ/parenleftig
/tildewideR(/tildewidesnn)−/tildewideR(f∗)/parenrightig
≲/parenleftig
κ−2
ϵ∥/tildewideη−/tildewidefnn∥2
L2(PX)/parenrightigγ+1
γ+2. (22)
Next, we proceed to establish the convergence rate of ∥/tildewideη−/tildewidefnn∥2
L2(PX). LetFNN
n,δn={f∈FNN
n:∥/tildewideη−
f∥2
L2(PX)≥δn}. For anyδn>0,
P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
≤P/parenleftig
inf
f∈FNN
n,δnn−1n/summationdisplay
i=1(f∗
nn(xi)−/tildewidezi)2−n−1n/summationdisplay
i=1(f(xi)−/tildewidezi)2≥δn/parenrightig
,
wheref∗
nn= arg minf∈FNNn∥f−/tildewideη∥2
L2(PX).
For ease of notation, we denote that Un(f) =n−1/summationtextn
i=1(f(xi)−/tildewidezi)2andU(f) =E(f(X)−/tildewideZ)2. Then, we
have
P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
≤P/parenleftig
inf
f∈FNN
n,δnUn(f∗
nn)−Un(f)≥0/parenrightig
.
30Published in Transactions on Machine Learning Research (10/2023)
Notice thatFNN
n,δnadmits the decomposition as FNN
n,δn=∪n
i=1HiwithHi={f∈FNN
n: 2i−1δn≤∥/tildewideη−
f∥2
L2(PX)≤2iδn}. Therefore, we further have
P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
≤n/summationdisplay
i=1P/parenleftig
inf
f∈HiUn(f∗
nn)−Un(f)≥0/parenrightig
.
Clearly, it suffices to bound P/parenleftig
inff∈HiUn(f∗
nn)−Un(f)≥0/parenrightig
for upper bounding P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
.
Fori≥1,
P/parenleftig
inf
f∈HiUn(f∗
nn)−Un(f)≥0/parenrightig
≤P/parenleftig
inf
f∈Hi/bracketleftbig
Un(f∗
nn)−U(f∗
nn)/bracketrightbig
−/bracketleftbig
Un(f)−U(f)/bracketrightbig
≥inf
f∈HiU(f)−U(f∗
nn)/parenrightig
=P/parenleftig
inf
f∈Hi/bracketleftbig
Un(f∗
nn)−U(f∗
nn)/bracketrightbig
−/bracketleftbig
Un(f)−U(f)/bracketrightbig
≥inf
f∈HiU(f)−U(/tildewideη) +U(/tildewideη)−U(f∗
nn)/parenrightig
≤P/parenleftig
inf
f∈Hi/bracketleftbig
Un(f∗
nn)−U(f∗
nn)/bracketrightbig
−/bracketleftbig
Un(f)−U(f)/bracketrightbig
≥2i−1δn−∥f∗
nn−/tildewideη∥2
L2(PX)/parenrightig
.
Assuming∥f∗
nn−/tildewideη∥2
L2(PX)≤δn/2yields that
P/parenleftig
inf
f∈HiUn(f∗
nn)−Un(f)≥0/parenrightig
≤P/parenleftig
inf
f∈Hi/bracketleftbig
Un(f∗
nn)−U(f∗
nn)/bracketrightbig
−/bracketleftbig
Un(f)−U(f)/bracketrightbig
≥2i−2δn/parenrightig
.
Denote that Mi= 2i−2δn. We turn to establish the relation between the variance of/parenleftbig
f∗
nn(X)−/tildewideZ/parenrightbig2−/parenleftbig
f(X)−/tildewideZ/parenrightbig2andMi.
sup
f∈HiVar/bracketleftig/parenleftbig
f∗
nn(X)−/tildewideZ/parenrightbig2−/parenleftbig
f(X)−/tildewideZ/parenrightbig2/bracketrightig
= sup
f∈HiVar/bracketleftig/parenleftbig
f∗
nn(X)−f(X)/parenrightbig/parenleftbig
f∗
nn(X) +f(X)−2/tildewideZ/parenrightbig/bracketrightig
≤sup
f∈HiE/bracketleftig/parenleftbig
f∗
nn(X)−f(X)/parenrightbig2/parenleftbig
f∗
nn(X) +f(X)−2/tildewideZ/parenrightbig2/bracketrightig
≤sup
f∈Hi4V2
n∥f∗
nn−f∥2
L2(PX)
≤sup
f∈Hi8V2
n/parenleftig
∥f∗
nn−/tildewideη∥2
L2(PX)+∥/tildewideη−f∥2
L2(PX)/parenrightig
≤64V2
nMi≡Vi.
In the following, we proceed to verify conditions (4.5)-(4.7) in Shen & Wong (1994). First, the relation
betweenMiandVidirectly implies (4.6) with T= 32V2
nandϵ= 1/2. Second, by Lemma 5 of Schmidt-
Hieber (2020),
logN/parenleftig
ϵ,FNN
n(Ln,Nn,Pn,Bn,Vn),∥·∥L∞(P(X)/parenrightig
≤
2Ln(Pn+ 1) log/parenleftig
ϵ−1(Ln+ 1)(Nn+ 1) max{Bn,1}/parenrightig
.
It then follows that
/integraldisplayV1/2
i
ϵ
32Mi/radicalbigg
logN/parenleftig
ϵ,FNNn(Ln,Nn,Pn,Bn,Vn),∥·∥L∞(P(X)/parenrightig
dϵ/Mi
≤/integraldisplayV1/2
i
ϵ
32Mi/radicalbigg
2Ln(Pn+ 1) log/parenleftig
ϵ−1(Ln+ 1)(Nn+ 1) max{Bn,1}/parenrightig
dϵ/Mi. (23)
Notice that the right-hand side of (23) is non-increasing in iandMi, it then follows that
/integraldisplayV1/2
i
ϵ
32Mi/radicalbigg
2Ln(Pn+ 1) log/parenleftig
ϵ−1(Ln+ 1)(Nn+ 1) max{Bn,1}/parenrightig
dϵ/Mi
≤/integraldisplayV1/2
1
ϵ
32M1/radicalbigg
2Ln(Pn+ 1) log/parenleftig
ϵ−1(Ln+ 1)(Nn+ 1) max{Bn,1}/parenrightig
dϵ/M 1.
31Published in Transactions on Machine Learning Research (10/2023)
With this, condition (4.7) can be satisfied by imposing
/integraldisplayV1/2
1
ϵ
32M1/radicalbigg
2Ln(Pn+ 1) log/parenleftig
ϵ−1(Ln+ 1)(Nn+ 1) max{Bn,1}/parenrightig
dϵ/M 1≲n1/2, (24)
which directly implies the condition (4.5) by appropriate choices of LnandSn. By Theorem 3 in Shen &
Wong (1994), we get
P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
≲∞/summationdisplay
i=1exp/parenleftig
−nM2
i
512V2nMi+ 2Mi/3/parenrightig
≲∞/summationdisplay
i=1exp/parenleftig
−n2i−2δn/parenrightig
.
By the fact 2i−2≥(i−1/2)fori≥1, there exists some constants Csuch that
P/parenleftig
∥/tildewideη−/tildewidefnn∥2
L2(PX)≥δn/parenrightig
≲exp(−Cnδn),
provided that nδ=o(1).
Next, we proceed to consider the approximation error of neural network to meet the assumption that ∥f∗
nn−
η∥2
L∞(PX)≤δn. Notice that η(X)∈H(β,[0,1]p,M). By Theorem 5 of Schmidt-Hieber (2020), there exists
a class of neural networks FNN
n(Ln,Nn,Pn,Bn,Vn)such that for any 0<ψn<1
inf
f∈FNNn(Ln,Nn,Pn,Bn,Vn)∥f−η∥L∞(PX)≤κ−1
ϵψn,
wherePn≍(κ−1
ϵψn)−p/βlog(κϵ/ψn),Nn≍(κ−1
ϵψn)−p/β,Bn= 1,Vn≥M+ 1andLn≍log(κϵ/ψn). Let
η∗
nndenote the optimal function in FNN
n(Ln,Nn,Pn,Bn,∞)to approximate η. Suppose that η∗
nnis aL-layer
neural network and formulated as
η∗
nn(x) =AL+1gL(x) +bL+1,
wheregL(x) =hL◦hL−1◦···◦h1(x). We construct a new neural network that /tildewideηnnas
/tildewideηnn(x) =θη∗
nn(x) + (1−θ)(1−η∗
nn(x))
=θAL+1gL(x) +θbL+1+ (1−θ)(−AL+1gL(x) + (1−bL+1))
=(2θ−1)AL+1gL(x) + (2θ−1)bL+1+ (1−θ)1L+1.
It can be easily verified that /tildewideηnn∈FNN
n(Ln,Nn,Pn,Bn,Vn). This along with the fact that /tildewideη(x) =θη(x) +
(1−θ)(1−η(x))withBn≥1results in
∥/tildewideηnn−/tildewideη∥L∞(PX)=∥θη∗
nn+ (1−θ)(1−η∗
nn)−θη−(1−θ)(1−η)∥L∞(PX)
=(2θ−1)∥η∗
nn−η∥L∞(PX)=κϵ∥η∗
nn−η∥L∞(PX)≤ψn.
Therefore,
∥f∗
nn−/tildewideη∥2
L∞(PX)= inf
f∈FNNn(Ln,Nn,Pn,Bn,Vn)∥f−/tildewideη∥2
L∞(PX)≤∥/tildewideηnn−/tildewideη∥2
L∞(PX)≤ψ2
n.
PluggingPn≍(κ−1
ϵψn)−p/βlog(κϵ/ψn),Nn≍(κ−1
ϵψn)−p/β, andLn≍log(κϵ/ψn)into (24) yields that
κp/(2β)
ϵψ−p/(2β)
n log(ψ−1
n)≲(nδn)1/2. Combining this with the assumption that ψ2
n≲δn, it follows that
δn≍ψ2
n≍κ2p/(2β+p)
ϵ (logn/n)2β/(2β+p). Plugging this into (22) yields that
E/bracketleftig
R(/tildewidesnn)−R(f∗)/bracketrightig
≲/parenleftiglogn
nκ2ϵ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2). (25)
Notice that the proof of (25) is independent of the distribution of X, therefore (25) holds for any distribution
inPγ,β, which implies that
sup
π∈Pγ,βE/bracketleftig
R(/tildewidesnn)−R(f∗)/bracketrightig
≲/parenleftiglogn
nκ2ϵ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2).
32Published in Transactions on Machine Learning Research (10/2023)
Proof of the lower bound. The proof is based on the well-known Assouad’s lemma. The overall proof
for the lower bound is mainly based on the proofs Theorem 3.5 and 4.1 in Audibert & Tsybakov (2007). We
first introduce the partition {Xi}m
i=0of the cube [0,1]pusing the grid Gq⊆[0,1]pdefined by
Gq=/braceleftbigg/parenleftbigg2k1+ 1
2q,···,2kp+ 1
2q/parenrightbigg
:ki∈{0,···,q−1},i∈{1,···,p}/bracerightbigg
,
whereq≥1is an integer. For any x∈Rp, letnq(x)∈Gqbe the unique point which is the closest point to
x∈Rpamong all points in Gq. Without loss of generality, we assume the uniqueness of nq(x)by choosing
the one closest to 0. We define a partition {X′
i}qp
i=1ofRpas follows. For x,y∈Rp,xandyare in the
same cellXiif and only if nq(x) =nq(y). Then, for m≤qp, we defineXiasXi=X′
ifor1≤i≤mand
X0=Rp/∪m
i=1Xi.
Letu:R+→R+be a non-increasing infinitely differentiable function such that u= 1on[0,1/4]andu= 0
on[1/2,∞). Letϕ:=Cϕu(∥x∥), whereCϕ≤1is taken small enough such that ϕ∈H(β,[0,1]p,M). For a
givenσ= (σ1,···,σm)∈{± 1}m, we construct a distribution πσonRp×{− 1,1}as follows. Let µbe the
Lebesgue measure. For 0< ω <1
mandA0⊆X 0withµ(A0)>0, we construct the marginal distribution
PXonRpthat has the density function
PX(x) =

ω
µ(B(0,q−1/4)),x∈B(z,q−1/4)for somez∈Gq,
(1−mω)/µ(A0),x∈A0,
0, otherwise.
The conditional distribution on {−1,1}is defined by
ησ(x) =P(Y= 1|X=x) =/braceleftigg1+σjφ(x)
2,forx∈Xj,j= 1,···,m,
1/2,x∈X0,
whereφ(x) =q−βϕ(q(x−nq(x))). Correspondingly, for any σ,/tildewideησ(x)is given as
/tildewideησ(x) =θ/tildewideησ(x) + (1−θ)(1−/tildewideησ(x)) =/braceleftigg1+(2θ−1)σjφ(x)
2,forx∈Xj,j= 1,···,m,
1/2, x∈X0,
Notice that Dsφ=q|s|−βDs(q(x−nq(x)))for anys∈Nwith|s| ≤β. Thus,ησ(x)belongs to
H(β,[0,1]p,M).
P/parenleftig
|ησ(x)−1/2|≤t/parenrightig
=mP/parenleftig
ϕ(q(x−nq(x)))≤2tqβ/parenrightig
=m/integraldisplay
B(x0,(4q)−1)I/parenleftig
ϕ/parenleftbig
q(x−x0)/parenrightbig
≤2tqβ/parenrightigw
µ(B(0,(4q)−1))dx
=m/integraldisplay
B(0,1/4)I/parenleftig
ϕ/parenleftbig
x/parenrightbig
≤2tqβ/parenrightigw
µ(B(0,1/4))dx=mwI/parenleftig
t≥Cϕ/(2qβ)/parenrightig
,
wherex0=/parenleftbig1
2K,...,1
2K/parenrightbig
. Clearly, the low-noise assumption of ησcan be satisfied by setting mw≤
Cγ
ϕ/(2qβ)γ. LetPγ,βdenote the set of joint distributions of (X,Y)satisfying the low-noise assumption
andη(x)∈H(β,[0,1]p,M). For anyσ, we haveπσ∈Pγ,β, implyingP′={πσ:σ∈{− 1,1}m}⊂Pγ,β.
Therefore,
sup
π∈Pγ,βE/tildewideD/bracketleftig
R(/tildewidesnn)−R(f∗)/bracketrightig
≥sup
πσ∈P′E/tildewideD/bracketleftig
R(/tildewidesnn)−R(f∗)/bracketrightig
.
Let/tildewideP′be a set of probability measures on (X,/tildewideY)satisfying that for each πσ∈P′there exists an /tildewideπσ∈/tildewideP′
such thatπσand/tildewideπσhave the same marginal distribution of Xand/tildewideησ(x) =θησ(x) + (1−θ)(1−ησ(x)).
It follows that
sup
πσ∈P′E/tildewideD/bracketleftig
R(/tildewidesnn)−R(f∗)/bracketrightig
≥(2θ−1)−1sup
/tildewideπσ∈/tildewideP′E/tildewideD/bracketleftig
/tildewideR(/tildewidesnn)−/tildewideR(f∗)/bracketrightig
.
33Published in Transactions on Machine Learning Research (10/2023)
Next, we proceed to bound sup/tildewideπσ∈/tildewideP′E/tildewideD/bracketleftig
/tildewideR(/tildewidesnn)−/tildewideR(f∗)/bracketrightig
. Notice that f∗varies with the value of σ,
therefore we use f∗
σto characterize its dependence on σ.
sup
/tildewideπσ∈/tildewideP′E/tildewideD/bracketleftig
/tildewideR(/tildewidesnn)−/tildewideR(f∗)/bracketrightig
= sup
/tildewideπσ∈/tildewideP′/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
|2/tildewideησ(X)−1|1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightig/bracerightig
= (2θ−1) sup
/tildewideπσ∈/tildewideP′/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightig/bracerightig
,
where 1{x}= 1if the statement xis true.
LetΠbe the distribution of a Rademacher random variable σ, that is, Π(σ= 1) = Π(σ=−1) = 1/2. Then
sup
/tildewideπσ∈/tildewideP′/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=f∗σ(X)}/bracketrightig/bracketrightig/bracerightig
≥EΠm/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=f∗σ(X)}/bracketrightig/bracketrightig/bracerightig
.
Note that for x∈X0,∥x−nq(x)∥≥(2q)−1andφ(x) = 0. Thus, we have
EΠm/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=f∗σ(X)}/bracketrightig/bracketrightig/bracerightig
=m/summationdisplay
j=1EΠm/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightig/bracerightig
.
Letσj,r= (σ1,···,σj−1,r,σj+1,···,σm)forr∈{0,±1}. Hereσj,rdenotes a vector deduced from σby
fixing itsj-th element to r. We have
EΠm/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightig/bracerightig
=EΠm/braceleftigg
E/tildewideπnσj,0/bracketleftigg
d/tildewideπn
σ
d/tildewideπnσj,0EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightigg/bracerightigg
=EΠm−1/braceleftigg
E/tildewideπnσj,0Eσj∼Π/bracketleftigg
d/tildewideπn
σ
d/tildewideπnσj,0EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightigg/bracerightigg
.
where/tildewideπσj,0has the same marginal distribution as PXand/tildewideπσj,0and/tildewideπσdiffer in the conditional distribution
over the points in Xj. Specifically,
/tildewideησj,0(x) =/braceleftigg
1/2,ifx∈Xj,
/tildewideησ(x),otherwise.
It then follows that
EΠm−1/braceleftigg
E/tildewideπnσj,0Eσj∼Π/bracketleftigg
d/tildewideπn
σ
d/tildewideπnσj,0EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightigg/bracerightigg
=EΠm−1/braceleftigg
E/tildewideπnσj,0Eσj∼Π/bracketleftigg
d/tildewideπn
σ
d/tildewideπnσj,0EX∼PX/bracketleftig
φ(X)1{X∈Xj}1{/tildewidesnn(X)̸=σj}/bracketrightig/bracketrightigg/bracerightigg
=EΠm−1/braceleftigg
EX∼PX/bracketleftigg
φ(X)1{X∈Xj}E/tildewideπnσj,0Eσj∼Π/bracketleftigg
d/tildewideπn
σ
d/tildewideπnσj,01{/tildewidesnn(X)̸=σj}/bracketrightigg/bracketrightigg/bracerightigg
≥EΠm−1/braceleftbigg
EX∼PX/bracketleftbigg
φ(X)1{X∈Xj}/parenleftig1
2P/tildewideπnσj,1(/tildewidesnn(X)̸= 1) +1
2P/tildewideπnσj,−1(/tildewidesnn(X)̸=−1)/parenrightig/bracketrightbigg/bracerightbigg
≥1
2EΠm−1/braceleftig
EX∼PX/bracketleftbig
φ(X)1{X∈Xj}/bracketrightbig/parenleftig
1−TV(/tildewideπn
σj,1,/tildewideπn
σj,−1/parenrightig/bracerightig
,
where TVis the total variation distance between two distributions. Since PX(Xj) =ω, we have
EΠm/braceleftig
E/tildewideD/bracketleftig
EX∼PX/bracketleftig
φ(X)1{/tildewidesnn(X)̸=σj;X∈Xj}/bracketrightig/bracketrightig/bracerightig
≥ω
2EX∼PX/parenleftbig
φ(X)/vextendsingle/vextendsingleX∈Xj/parenrightbig/parenleftig
1−TV(/tildewideπn
σj,1,/tildewideπn
σj,−1)/parenrightig
,
34Published in Transactions on Machine Learning Research (10/2023)
Notice that the above inequality holds for any index j∈[m]. In conclusion, we obtain
m/summationdisplay
j=1EΠm/braceleftig
E/tildewideπnσ/bracketleftig
EX∼PX/bracketleftig
φ(X)1[/tildewidesnn(X)̸=σj;X∈Xj]/bracketrightig/bracketrightig/bracerightig
≥mω
2EX∼PX(φ(X)|X∈Xj)/parenleftig
1−TV(/tildewideπn
σ1,1,/tildewideπn
σ1,−1)/parenrightig
.
Now we bound TV(/tildewideπn
σ1,1,/tildewideπn
σ1,−1). First, it holds
TV(/tildewideπn
σ1,1,/tildewideπn
σ1,−1) =n/summationdisplay
l=1/parenleftbiggn
l/parenrightbigg
ωl(1−ω)n−lVl,
whereVl= TV(/tildewideπl
−1,/tildewideπl
1)with/tildewideπr=/tildewideπσ1,r(·|X∈X1). Note that
Vl≤H(/tildewideπl
−1,/tildewideπl
1) =/radicaltp/radicalvertex/radicalvertex/radicalbt2/parenleftigg
1−/bracketleftbigg
1−H2(/tildewideπ−1,/tildewideπ1)
2/bracketrightbiggl/parenrightigg
whereHis the Hellinger distance and
1−H2(/tildewideπ−1,/tildewideπ1)
2=EX∼PX/parenleftig/radicalbig
1−(2θ−1)2φ(X)/vextendsingle/vextendsingle/vextendsingleX∈X1/parenrightig
=:/radicalbig
1−b2
Since 1−(1−x2)l/2≤lx2
2forl≥2andx>0, we haveVl≤b√
land
TV(/tildewideπn
σ1,1,/tildewideπn
σ1,−1)≤bn/summationdisplay
l=1P/parenleftign/summationdisplay
i=1ϵi,ω=l/parenrightig√
l≤b√nω,
whereϵiare i.i.d. random variables such that P(ϵi= 1) =ω= 1−P(ϵi=−1). In conclusion, we have
sup
/tildewideπσ∈/tildewideP′/braceleftig
E/tildewideD/bracketleftig
/tildewideR(/tildewidesnn)/bracketrightig
−/tildewideR∗/bracerightig
≥mωb′(1−b√nω),
where
b=/bracketleftbigg
1−/parenleftig
E/bracketleftig/radicalbig
1−(2θ−1)2φ2(X)/vextendsingle/vextendsingle/vextendsingleX∈Xj/bracketrightig/parenrightig2/bracketrightbigg1/2
≍(2θ−1)q−β,
b′=E/parenleftig
(2θ−1)φ(X)/vextendsingle/vextendsingle/vextendsingleX∈Xj/parenrightig
≍(2θ−1)q−β.
As a result, we have
sup
π∈Pγ,βE/tildewideD/bracketleftig
R(/tildewidesnn)−R∗/bracketrightig
≳mωq−β(1−(2θ−1)q−β√nω).
Takeω=q2β
4n(2θ−1)2andm=qp, we obtain
sup
π∈Pγ,βE/tildewideD/bracketleftig
R(/tildewidesnn)−R∗/bracketrightig
≳qβ+p
nκ2ϵ≍/parenleftbigg1
nκ2ϵ/parenrightbigg(γ+1)β
(γ+2)β+p
by takingq≍/parenleftbig
n(2θ−1)2/parenrightbig 1
(γ+2)β+p. Particularly, when ϵ≍n−1/2+ζ, we have
sup
π∈Pγ,βE/tildewideD/bracketleftig
R(/tildewidesnn)−R∗/bracketrightig
≲/parenleftiglogn
nκ2ϵ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2)≍/parenleftiglog(n)
n2ζ/parenrightig2β(γ+1)
2β(γ+2)+p(γ+2)→0asn→∞.
This completes the proof.
35