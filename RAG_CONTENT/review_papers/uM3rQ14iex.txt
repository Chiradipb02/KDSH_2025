Partial Structure Discovery is Sufficient for
No-regret Learning in Causal Bandits
Muhammad Qasim Elahi
Electrical and Computer Engineering
Purdue University
elahi0@purdue.eduMahsa Ghasemi
Electrical and Computer Engineering
Purdue University
mahsa@purdue.edu
Murat Kocaoglu
Electrical and Computer Engineering
Purdue University
mkocaoglu@purdue.edu
Abstract
Causal knowledge about the relationships among decision variables and a reward
variable in a bandit setting can accelerate the learning of an optimal decision.
Current works often assume the causal graph is known, which may not always
be available a priori . Motivated by this challenge, we focus on the causal bandit
problem in scenarios where the underlying causal graph is unknown and may
include latent confounders. While intervention on the parents of the reward node
is optimal in the absence of latent confounders, this is not necessarily the case in
general. Instead, one must consider a set of possibly optimal arms/interventions,
each being a special subset of the ancestors of the reward node, making causal
discovery beyond the parents of the reward node essential. For regret minimization,
we identify that discovering the full causal structure is unnecessary; however, no
existing work provides the necessary and sufficient components of the causal graph.
We formally characterize the set of necessary and sufficient latent confounders
one needs to detect or learn to ensure that all possibly optimal arms are identified
correctly. We also propose a randomized algorithm for learning the causal graph
with a limited number of samples, providing a sample complexity guarantee for
any desired confidence level. In the causal bandit setup, we propose a two-stage
approach. In the first stage, we learn the induced subgraph on ancestors of the
reward, along with a necessary and sufficient subset of latent confounders, to
construct the set of possibly optimal arms. We show that for our proposed algorithm,
the number of intervention samples required to learn the set of possibly optimal
arms scales polynomially with respect to the number of nodes. The second phase
involves the application of a standard bandit algorithm, such as the UCB algorithm.
We also establish a regret bound for our two-phase approach, which is sublinear in
the number of rounds.
1 Introduction
Causal bandits have been a topic of interest since their inception and have been studied in various
contexts [ 1]. The authors assumed precise knowledge of the causal graph and the impact of in-
terventions or actions on the parents of the reward node. Subsequently, there has been a flurry of
research on causal bandits [ 2,3,4]. The primary limitation of the majority of existing works on causal
bandits is their assumption of full knowledge of the causal graph, which is often impractical for many
38th Conference on Neural Information Processing Systems (NeurIPS 2024).real-world applications [ 1,5,6]. Recently, efforts have been made to overcome this limitation. In [ 7],
the authors propose a sample efficient algorithm for cases where the causal graph can be represented
as a directed tree or a causal forest and later extend the algorithm to encompass a broader class of
general chordal graphs. However, the proposed algorithm is only applicable to scenarios where the
Markov equivalence class (MEC) of the causal graph is known and does not have confounders. In
[8], the authors propose a causal bandit algorithm that does not require any prior knowledge of the
causal structure and leverages separating sets. However, their theoretical result holds only when a
true separating set is known. The paper by Konobeev et al. [ 9] also deals with causal bandits with an
unknown graph and proposes a two-phase approach. The first phase uses a randomized parent search
algorithm to learn the parents of the reward node, and the second phase employs UCB to identify
the optimal intervention over the parents of the reward node. However, similar to [ 7], they assume
causal sufficiency, i.e., no latent confounders are present. In another related paper, [ 10], the authors
initially emphasize the challenge of dealing with exponentially many arms when addressing causal
bandits with an unknown graph. To tackle this issue, the authors assume that the reward is a noisy
additive function of its parents. This assumption enables them to reframe the problem as an additive
combinatorial linear bandit problem.
We also focus on the causal bandit setup where the causal graph is unknown, but we allow the
presence of latent confounders and make no parametric assumptions. The optimal intervention in
this case is not limited to parents of the reward node; instead, we have a candidate set of optimal
interventions, called possibly optimal minimum intervention sets (POMISs), each being a special
subset of the ancestors of the reward node [ 5]. Thus, learning only the parents of the reward, similar
to [9], is insufficient. This implies that causal discovery beyond parents of the reward is imperative.
However, for regret minimization, discovering the full causal structure is not necessary. Instead, we
characterize the set of necessary and sufficient latent confounders one needs to detect/learn to ensure
all the possibly optimal arms are learned correctly.
Causal discovery is a well-studied problem and can be applied to our setup [ 11,12,13]. However,
the majority of the existing causal discovery algorithms rely on the availability of an infinite amount
of interventional data [ 14,15,16]. Some prior work shows that discovery is possible with limited
interventional data, with theoretical guarantees when the underlying causal graph is a tree and
contains no latent confounders [ 17]. Also, the paper [ 18] proposes a sample-efficient active learning
algorithm for causal graphs without latent confounders, given that the MEC for the underlying causal
graph is known. Bayesian causal discovery can also be a valuable tool when interventional data is
limited. However, it faces challenges when tasked with computing posterior probabilities across
the combinatorial space of directed acyclic graphs (DAGs) without specific parametric assumptions
[19,20,21]. All in all, the sample-efficient learning of causal graphs with latent confounders, without
any parametric or graphical assumptions, with theoretical guarantees, remains an open problem.
We propose a randomized algorithm for sample-efficient learning of causal graphs with confounders.
We analyze the algorithm and bound the maximum number of interventional samples required to
learn the causal graph with all the confounders with a given confidence level. For the causal bandit
setup, we propose a two-stage approach where the first step learns a subgraph of the underlying causal
graph to construct a set of POMISs, and the second phase learns the optimal arm among the POMISs.
We show that the requirement of learning only a subgraph leads to significant savings in terms of
interventional samples and consequently, regret. The main contributions of our work are as follows:
•We characterize the necessary and sufficient set of latent confounders in the induced subgraph
on ancestors of the reward node that we need to learn/detect in order to identify all the
POMISs for a causal bandit setup when the underlying causal graph is unknown.
•We propose a randomized algorithm for sample-efficient learning of causal graphs with
confounders, providing theoretical guarantee on the number of interventional samples
required to learn the graph with a given confidence level.
•We propose a two-phase algorithm for causal bandits with unknown causal graphs containing
confounders. The first phase involves learning the induced subgraph on reward’s ancestors
along with a subset of latent confounders to identify all the POMISs. The next phase involves
a standard bandit algorithm, e.g., upper confidence bound (UCB) algorithm. Our theoretical
analysis establishes an upper bound on the cumulative regret of the overall algorithm.
22 Preliminaries and Problem Setup
We start with an overview of the causal bandit problem and other relevant background needed on
causal models. Structural causal model (SCM) is a tuple M=⟨V,U,F, P(U)⟩where V=
{Vi}n
i=1∪ {Y}is the set of observed variables, Uis the set of independent exogenous variables, Fis
the set of deterministic structural equations and P(U)is the distribution for exogenous variables [ 22].
The equations fimap the parents ( Pa(Vi)) and a subset of exogenous variables Ui⊆U, to the value
of variable Vi, i.e., Vi=fi(Pa(Vi),Ui). We consider the causal bandit setup where all the observed
variables Vi∈Vare discrete with the domain Ω(Vi) = [K] :={1,2,3, . . . , K }, and the reward Y
is binary, i.e., Ω(Y) ={0,1}. We can associate a DAG G= (V,E)with every SCM, where the
vertices Vcorrespond to the observed variables and edges Econsist of directed edges Vi→Vjwhen
Vi∈Pa(Vj)and bi-directed edges between ViandVj(Vi← →Vj)when they share some common
unobserved variable, also called latent confounder. We restrict ourselves to semi-Markovian causal
models in which every unobserved variable has no parents and has exactly two children, both of
which are observed [ 10]. An intervention on a set of variables W⊆V, denoted by do(W), induces
a post-interventional DAG ( GW) with incoming edges to vertices Wremoved . We can broadly
classify interventions into deterministic interventions, where variables are set to a fixed realization
denoted by do(W=w), and stochastic interventions, where instead of a fixed realization we have
W∼P(.), where Pis a probability measure over the domain Ω(W). We denote the sub-model
induced under hard intervention by MW=wand the one induced under stochastic intervention by
MW. In the context of causal bandits, an arm or action corresponds to hard intervention on a subset
of variables other than the reward. The goal of the agent is to identify the intervention that maximizes
the expected reward. The performance of an agent is measured in terms of cumulative regret RT.
RT:=Tmax
W⊆Vmax
w∈[K]|W|E[Y|do(W=w)]−TX
t=1E[Y|do(Wt=wt)], (1)
where do(Wt=wt)represents the intervention selected by the agent in round t. We use the notation
∆do(w)to define the sub-optimality gap of the corresponding arm do(W=w). We denote the
descendants, ancestors and children of a vertex VibyDe(Vi),An(Vi)andCh(Vi)respectively. We
use the notation Bi(Vi,G)to denote the set of vertices having bidirected edges to Viexcept the reward
node Y. We refer to the induced graph between observed variables as the observable graph. The
transitive closure of a graph, denoted by Gtc, encodes the ancestral relationship in G. That is, the
directed edge Vi→Vjis included in Gtconly when Vi∈An(Vj). The transitive reduction , denoted
byTr(G) = ( V,Er), is a graph with the minimum number of edges such that the transitive closure
is the same as G. The connected component (c-component) of the DAG G, containing vertex Vi, is
denoted by CC(Vi), which is the maximal set of all vertices in Gthat have a path to Vi, consisting only
of bi-directed edges [ 23]. For a subset of vertices W⊆V, we define CC(W) :=S
Wi∈WCC(Wi).
In a DAG, a subset of nodes Wd-separates two nodes ViandVjwhen it effectively blocks all
paths between them, denoted as Vi⊥ ⊥dVj|W. Blocking is a graphical criterion associated with
d-separation [ 22]. A probability distribution is said to be faithful to a graph if and only if every
conditional independence (CI) statement can be inferred from d-separation statements in the graph.
Faithfulness is a commonly used assumption in the existing work on causal discovery [ 14,24]. We
assume that the following form of the interventional faithfulness assumption holds in our setup.
Assumption 2.1. Consider a set of nodes W⊆Vand the stochastic intervention do(W,U)onW
and any set U⊆V\W. The conditional independence (CI) statement (X⊥ ⊥Y|Z)MW,Uholds in
the induced model if and only if there is a corresponding d-separation statement in post-interventional
graph (X⊥ ⊥dY|Z)GW,U, where X,Y, andZare disjoint subsets of V\W. The CI statements in
the induced model are with respect to the post-interventional joint probability distribution.
3 Possibly Optimal Arms in Causal Bandits with Unknown Causal Graph
The optimal intervention in a causal bandit setup is not restricted to the parent set of the reward
node when the reward node Yis confounded with any node in its ancestors An(Y)[5]. For instance,
consider SCM X1=U1andX2=X1⊕U2and reward Y=X2⊕U2, where U1∼Ber(0.5)and
U2∼Ber(0.5). Note that X2and reward Yare confounded in this SCM. The optimal intervention
in this case is do(X1= 1) sinceE[Y|do(X1= 1)] = 1 . The intervention on the parent of the reward
(Pa(Y) =X2) is suboptimal because E[Y|do(X2= 0)] = E[Y|do(X2= 1)] = 0 .5. The example
3YV1 V2V3
(a)GYV1 V2V3
(b)G1YV1 V2V3
(c)G2YV1 V2V3
(d)G3
Figure 1: True Causal Graph Gwith four other graphs each with one missing bi-directed edge.
shows that it is possible to construct SCMs where optimal intervention is on ancestors of the reward
node instead of parents when reward node is confounded with one of its ancestors. The authors in [ 5]
propose a graphical criterion to enumerate the set of all possibly optimal arms, which they refer to as
POMISs. We revisit some definitions and results from their work.
Definition 3.1. (Unobserved Confounder (UC)-Territory [5]) Consider a causal graph G(V,E)
with a reward node Yand let HbeG[An(Y)]. A set of variables T⊆V(H)containing Yis called
anUC-territory onGwith respect to YifDeH(T) =TandCCH(T) =T.
A UC-territory is minimal if none of its subsets are UC-territories. A minimal UC-territory denoted
byMUCT (G, Y), can be constructed by extending a set of variables, starting from the reward {Y},
alternatively updating the set with the c-component and descendants of the set until there is no change.
Definition 3.2. (Interventional Border)[ 5]LetTbe a minimal UC-territory on Gwith respect to Y.
Then, X=Pa(T)\Tis called an interventional border for Gw.r.t. Ydenoted by IB (G, Y).
Lemma 3.1. [5] For causal graph Gwith reward Y,IB(GW, Y)is a POMIS, for any W⊆V\ {Y}.
Although the graphical characterization in Lemma 3.1 provides a means to enumerate the complete
set of POMISs, it comes with exponential time complexity. The authors also propose an efficient
algorithm for enumerating all POMISs in [ 5]. However, this requires knowing the true causal
graph, and without it, one has to consider interventions on all possible subsets of nodes, which are
exponentially many. One naive approach to tackle the problem is to learn the full causal graph with all
confounders to list all POMISs. However, a question arises: Do we need to learn/detect all possible
confounders since the goal is to find POMISs and not the full graph?
Before answering the above question, we start with an example considering the causal graphs in Figure
1. Using Lemma 3.1, the set of POMISs for the true graph GisIG={ϕ,{V1},{V2},{V3},{V1, V2}}.
However, for G1which has the bidirected edge V2↔Ymissing, the set of POMISs is IG1=
{ϕ,{V2},{V1, V2}}. Also for G2which has the bidirected edge V1↔V2missing, the set of POMISs
isIG2={ϕ,{V1},{V2},{V1, V2}}. In both cases, we miss at least one POMIS, and since it is
possible to construct an SCM compatible with the true causal graph Gwhere any arm in POMIS
is optimal, if this arm is not learned, we can suffer linear regret [ 5]. Although the graph G3has
the bidirected edge V1↔V3missing, it still has the same set of POMISs as the true graph, i.e.,
IG3={ϕ,{V1},{V2},{V3},{V1, V2}}. This example shows that only a subset of latent confounders
affect the POMISs learned from the graph. We formally prove that it is necessary and sufficient to
learn/detect all latent variables between the reward and its ancestors because missing any one of them
will cause us to miss at least one of POMISs leading to linear regret for some bandit instances.
Lemma 3.2. It is necessary to learn/detect the latent confounders between reward node Yand any
nodeX∈An(Y)in causal graph Gto learn all the POMISs correctly and hence avoid linear regret.
Theorem 3.1. Consider a causal graph G(V,E)and another causal graph G′such that they have
the same vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′
being a subset of the bidirected edges in G. The graphs will yield different collections of POMISs if
and only if there exists some Z∈An(Y)such that either (a) or (b) is true:
(a) There is a bi-directed edge between ZandYinGbut not in G′.
(b)Neither of the graphs G′andGhave a bidirected edge between ZandY, and there exists a
bidirected edge in Gbetween some X∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)andZbut not in G′.
We extend Lemma 3.2 to provide necessary and sufficient conditions in Theorem 3.1 characterizing
all the latent variables that need to be learned, ensuring that the POMISs learned from a sparser causal
4graph match all those in the true causal graph. Suppose we have access to the induced observable
subgraph G′on ancestors of the reward node. We can start by testing for latent confounders between
Yand any node in An(Y). Then, we need to test for latent confounders between any pair Z∈An(Y)
such that ZandYdon’t have a bi-directed edge between them, and X∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)
until there are no new pairs to test. Theorem 3.1 can be useful because depending on the underlying
causal graph, it saves us the number of latent confounders we need to test. For instance, consider a
causal graph that has the reward Ywithndifferent parent nodes, i.e., Pa(Y) ={V1, V2, . . . , V n},
with no edges between the parents. In cases where every parent of Yis confounded with Y, or when
none of them is confounded with Y, we only need to test for |An(Y)|latent variables, as implied by
Theorem 3.1. However, in the worst-case scenario, we would need to test |An(Y)|+1
2
latent variables
when the true graph only has the confounders V1← →YandVi← →Vi+1for all i= 1, .., n−1. The
exact number of latents we need to test can range from |An(Y)|to |An(Y)|+1
2
depending on the true
graph. One issue still remains: we need a sample-efficient algorithm to learn the induced observable
graph over An(Y)and to test the presence of confounders, which is addressed in upcoming sections.
4 Finite Sample Causal Discovery Algorithm
In this section, we propose a sample-efficient algorithm to learn causal graphs with latent confounders.
We propose a two-phase approach. In the first phase, the algorithm learns the observable graph
structure, i.e., the induced graph between observed variables. In the second phase, it detects the
latent confounders. In the next section, we use the proposed discovery algorithm to construct the
algorithm for causal bandits with an unknown graph. We begin by proposing two Lemmas to learn
the ancestrality relations and latent confounders using interventions.
Lemma 4.1. Consider a causal graph G(V,E)andW⊆V. Furthermore, let X, T∈V\Wbe
any two variables. Under the faithfulness Assumption 2.1 (X∈An(T))GWif and only if for any
w∈[K]|W|, we have P(t|do(w))̸=P(t|do(w), do(x))for some x, t∈[K].
Lemma 4.2. Consider two variables XiandXjsuch that Xj/∈An(Xi)and a set of variables
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi, Xj/∈W. Under the faithfulness Assumption 2.1 there
is latent confounder between XiandXjif and only if for any w∈[K]|W|, we have P(xj|
do(xi), do(W=w))̸=P(xj|xi, do(W=w))for some realization xi, xj∈[K].
These Lemmas are modified versions of Lemma 1 in [ 14] and Interventional Do-see test in [ 14],
respectively. The difference between Lemma 4.1 and Lemma 1 in [ 14] is that we have an inequality
test that can be used in the sample-efficient discovery instead of a statistical independence test. The
Interventional Do-see test in [ 14] is valid for adjacent nodes only; however, our Lemma 4.2 can be
used to test presence of latent confounder between any pair of nodes. This is because the condition in
Lemma 4.2, Xj/∈An(Xi), can always be satisfied for any pair by flipping the order when one node
is an ancestor of the other. In order to provide theoretical guarantees on sampling complexity, the
inequality conditions are not enough; we need to assume certain gaps similar to [7, 9, 17].
Assumption 4.1. Consider a causal graph G(V,E)andW⊆V. Furthermore, let X, T∈V\W
be any two variables. Then, we have (X∈An(T))GWif and only if for any w∈[K]|W|, we have
|P(t|do(w))−P(t|do(w), do(x))|> ϵfor some x, t∈[K], where ϵ >0is some constant.
Assumption 4.2. Consider two variables XiandXjsuch that Xj/∈An(Xi)and a set of variables
(Pa(Xi)∪Pa(Xj)\{Xi})⊆WandXi, Xj/∈W. There is a latent confounder or a bidirected edge
between XiandXjif and only if for any w∈[K]|W|, we haveP(xj|do(xi), do(W=w))−P(xj|
xi, do(W=w))> γ for some realization xi, xj∈[K]and some constant γ >0.
4.1 Learning the Observable Graph
We propose Algorithm 1 to learn the transitive closure under any arbitrary intervention do(W),
denoted by Gtc
W. We use the Assumption 4.1 to bound the number of samples for ancestrality tests.
We start with an empty graph and add edges by running ancestrality tests for all pairs of nodes in
V\W, resulting in the transitive closure Gtc
W. We recall that the transitive reduction Tr(G) = (V,Er)
of a DAG G= (V,E)is unique, with Er⊆E, and it can be computed in polynomial time [ 25]. Also,
note that Tr(G) =Tr(Gtc). We propose a randomized Algorithm 2 similar to the one proposed in
5Algorithm 1: Learn the Transitive Closure of the Causal Graph under any intervention, i.e., Gtc
W
1Function LearnTransitiveClosure( V,W, δ1, δ2):
2 E=∅, Fix some w∈[K]|W|and A = max(8
ϵ2,8
γ2) log2nK2
δ1andB=8
ϵ2log2nK2
δ2
3 GetBsamples from do(W=w)
4 GetAsamples from every do(Xi=xi,W=w)∀Xi∈V\Wand∀xi∈[K]
5 forevery pair Xi, Xj∈V\Wdo
6 Use the Interventional Data to Test if (Xi∈An(Xj))GW
7 if∃xi, xj∈[K]s.t.|bP(xj|do(w))−bP(xj|do(w), do(xi))|>ϵ
2then
8 E←− E∪(Xi, Xj)
9 return The graph’s transitive closure (V,E)and All Interventional data
10End Function
Algorithm 2: Learn the Observable Graph
1Function LearnObservableGraph( V, α, d max, δ1, δ2):
2 E=∅&IData =∅
3 fori =1 : 8 α dmax log(n)do
4 W=∅
5 forVi∈Vdo
6 W← −W∪Viwith probability 1−1
2dmax
7 Gtc
W,DataW=LearnTransitiveClosure (V,W, δ1, δ2)
8 Compute the transitive reduction Tr(Gtc
W)& add any missing edges from Tr(Gtc
W)toE
9 IData =IData∪DataW(Keep Saving Interventional Data)
10 return The observable graph structure (V,E)and interventional data samples in IData
11End Function
[14] that repeatedly uses Algorithm 1 to learn the observable graph structure. The motivation behind
the randomized Algorithm 2 is Lemma 5 from [ 14], which states that for any edge (Xi, Xj), consider
a set of variables Wsuch that {Wi:π(Wi)> π(Xi) &Wi∈Pa(Xj)} ⊆Wwhere πis any total
order that is consistent with the partial order implied by the DAG, i.e., π(X)< π(Y)iffX∈An(Y).
In this case, the edge (Xi, Xj)will be present in the graph Tr(GW). Algorithm 2 randomly selects
W, computes the transitive reduction of the post-interventional graphs, and finally accumulates all
edges found in the transitive reduction across iterations. Algorithm 2 takes a parameter dmax, which
must be greater than or equal to the highest graph degree for our theoretical guarantees to hold.
Lemma 4.3. Suppose that the Assumption 4.1 holds and we have access to max(8
ϵ2,8
γ2) log2K2
δ1
samples from do(Xi=xi,W=w)∀xi∈[K]and8
ϵ2log2K2
δ2samples from do(W=w)for a fixed
w∈[K]|W|andW⊆V. Then, with probability at least 1−δ1−δ2, we have (Xi∈An(Xj))GWif
and only if ∃xi, xj∈[K]s.t.bP(xj|do(w))−bP(xj|do(w), do(xi))>ϵ
2.
Lemma 4.3 provides the sample complexity for running ancestrality tests. Algorithm 1 selects a
realization w∈[K]|W|, takes Bsamples from the intervention do(W=w), and Asamples from
every do(Xi=xi,W=w)for all Xi∈V\Wandxi∈[K]interventions. Thus, in the worst
case, Algorithm 1 requires KAn +Bsamples to learn the true transitive closure with high probability.
We formally prove this result in the Lemma 4.4.
Lemma 4.4. Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc
W, with
probability at least 1−nδ1−δ2with a maximum KAn +Binterventional samples. If we set
δ1=δ
2nandδ2=δ
2, then Algorithm 1 learns true transitive closure with probability at least 1−δ.
Algorithm 2 repeatedly invokes Algorithm 1 to learn Tr(GW)for randomly sampled W. Through
this iterative process, it accumulates edges across iterations, ultimately constructing the observable
graph structure. To establish the sampling complexity guarantee for Algorithm 2, we leverage the
result from Lemma 4.4. The Theorem 4.1 gives the sampling complexity for learning the true
observable graph with high probability.
6Theorem 4.1. Algorithm 2 learns the true observable graph with probability at least 1−1
nα
2dmax−2−
8αdmaxlog(n)(nδ1+δ2)with8αdmaxlogn(KAn +B)interventional samples. If we set α=
2dmaxlog (2
δ+2)
logn,δ1=δ
32αdmaxnlognandδ2=δ
32αdmaxlogn, then Algorithm 2 learns the true
observable graph with probability at least of 1−δ. (We have A= max
8
ϵ2,8
γ2
log2nK2
δ1&
B=8
ϵ2log2nK2
δ2as in line 2 of Algorithm 1.)
4.2 Learning the Latent Confounders
Assumption 4.2 can be used to test for latents between any pair of observed variables. Note that while
using Algorithm 2, we save and return all the interventional data samples. These samples can be reused
to detect latent confounders in the next phase. For any variables XiandXjsuch that Xj/∈An(Xi),
we need access to interventional samples do(W=w)such that (Pa(Xi)∪Pa(Xj)\ {Xi})⊆W
andXi&Xj/∈W. In the supplementary material, we demonstrate that randomly selecting
the target set Win Algorithm 2 ensures that we have access to all such datasets for all pairs of
observed variables with high probability. In addition to simple causal effects we need to estimate
the conditional causal effect of the form P(xj|xi, do(W=w)). To bound the number of samples
required to ensure accurate estimation of the conditional causal effects, we rely on Assumption 4.3.
Note that Assumption 4.3 does not restrict the applicability of our algorithm; it simply assumes that
under an intervention do(W=w), either the probability of observing a realization Xi=xiis zero
or is lower-bounded by some constant η >0. The role of this assumption is to bound the number of
interventional samples required for accurate estimation of the conditional causal effects.
Assumption 4.3. For any variable Xi∈Vand any intervention do(W=w)where W⊆Vand
w∈[K]|W|, we assume that either P(xi|do(W=w)) = 0 orP(xi|do(W=w))≥η >0.
Algorithm 3: Learn the Causal Graph along-with the Latent Confounders
1Function LearnCausalGraph( α, dmax, δ1, δ2, δ3, δ4):
2G,IData =LearnObservableGraph (α, dmax, δ1, δ2)
3 C=16
ηγ2log(2n2K2
δ3) +1
2η2log(2n2K2
δ4),B=8
ϵ2log2nK2
δ2
4 forevery pair Xi, Xj∈Vdo
5 IfXj∈An(Xi), swap them.
6 Find interventional data sets do(W=w)anddo(Xi=xi,W=w)fromIData s.t.
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W
7 Getmax(0 , C−B)new samples for do(W=w)
8 if∃xi, xj∈[K]s.t.|bP(xj|do(xi), do(w))−bP(xj|xi, do(w))|>γ
2then
9 Add bi-directed edge Xi← →Xjto graph G
10 return The Causal Graph with Latent Confounders G
11End Function
Lemma 4.5. Consider two nodes XiandXjs.t.Xj/∈An(Xi)and suppose that Assumptions
2.1 4.2 hold and we have access to max(8
ϵ2,8
γ2) log2K2
δ1samples from do(Xi=xi,W=w)
∀xi∈[K]and16
ηγ2log(2K2
δ3) +1
2η2log(2K2
δ4)samples from do(W=w)for a fixed w∈[K]|W|
andW⊆Vsuch that (Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W. Then, with
probability at least 1−δ1−δ3−δ4, we have a latent confounder between XiandXjiff∃xi, xj∈
[K]s.t.bP(xj|do(xi), do(w))−bP(xj|xi, do(w))>γ
2.
Lemma 4.5 establishes the sample complexity for detecting the presence of latent confounders for
any pair of nodes in the causal graph. Using results from Theorem 4.1 and Lemma 4.5, we bound
the number of interventions required by the proposed Algorithm 3 to learn the causal graph along
with the latent confounders. Theorem 4.2 provides the sample complexity guarantee for Algorithm 3
to learn the true causal graph, including all latent confounders, with a given confidence level. An
important feature of the sampling complexity result in Theorem 4.2 is that the number of intervention
samples needed to learn the causal graph scales polynomially with the number of nodes n.
7Theorem 4.2. Algorithm 3 learns the true causal graph with latents with probability at least
1−2
nα
2dmax−2−8αdmaxlog(n)(nδ1+ (δ2+δ3+δ4))with a maximum of 8αdmaxlogn(KAn +
max( B, C))interventional samples. If we set α=2dmaxlog (4
δ+2)
logn,δ1=δ
64αdmaxnlognandδ2=
δ3=δ4=δ
64αdmaxlogn, then Algorithm 3 learns the true causal graph with probability at least
1−δ. (AandBare given by line 2 of Algorithm 1 and Cis given by line 3 of Algorithm 3.)
Suppose the constant gaps ϵandγin Assumptions 4.1 and 4.2 are close; then, we have C >1
ηA≥
1
ηB. The value of the constant 0< η < 1is usually small in practical scenarios, so the quantity Cis
much greater than both BorA. This implies that the number of samples required to test the presence
of latent variables is greater than that required to learn ancestral relations. This is because we need to
accurately estimate conditional causal effects to detect latent variables, which requires a large number
of samples compared to simple causal effects. Theorem 3.1 is useful here because it shows that we
do not need to test for confounders between all pairs of nodes among ancestors of the reward node to
learn the POMIS set.
5 Algorithm for Causal Bandits with Unknown Graph Structure
Algorithm 4 is the sketch of our algorithm for causal bandits with unknown graph structure. The
detailed algorithm with all steps explained is given in the supplementary material (Algorithm 6).
Algorithm 4 first learns the transitive closure of the graph Gtcto find ancestors of the reward node
Y. This is because POMISs are only subsets of An(Y). The next step is to learn the observed graph
structure among the reward Yand nodes in An(Y). Instead of detecting the presence of confounders
between all pairs of nodes in An(Y)as in Algorithm 3, we focus on identifying the necessary and
sufficient ones, as characterized by Theorem 3.1. This approach is more sample-efficient since it
tests for fewer latent confounders. The exact saving in terms of samples depends on the underlying
causal graph and is hard to characterize in general. The last step of Algorithm 4 is to run a simple
bandit algorithm, e.g., UCB algorithm [ 26], to identify the optimal arm from the POMISs. Given that
Assumptions 4.1, 4.2, and 4.3 hold, and the reward is binary (Y∈ {0,1}), using the results from
Lemma 4.4 and Theorem 4.2, we provide a worst-case regret bound for Algorithm 4 in Theorem 5.1.
Algorithm 4: Sketch of Algorithm for causal bandits with unknown graph structure
1Calculate α, δ 1, δ2, δ3, δ4as in Theorem 5.1
2Gtc=LearnTransitiveClosure (W=ϕ,δ
2n,δ
n)
3G,IData =LearnObservableGraph (An(Y)Gtc, α, d max, δ1, δ2)
4# Learn the bi-directed edges between reward Yand all nodes Xi∈An(Y)and update G.
5forevery Xi∈An(Y)Gtcdo
6G=DetectLatentConfounder (G, Xi, Xj, δ2, δ3, δ4,IData )(Algorithm 5)
7while There is a new pair that is tested do
8 Find a new pair (Z, X)s.t.Z∈An(Y)such that ZandYdon’t have a bi-directed edge between them
inGandX∈MUCT (GPa(Z),Bi(Z,G), Y)and test for the latent and update G.
9G=DetectLatentConfounder (G, Z, X, δ 2, δ3, δ4,IData )
10Learn the set of POMISs IGfrom the graph G(Using Algorithm 1 from [5]).
11Run UCB algorithm over the arm set A={Ω(I)| ∀I∈ IG}.
Theorem 5.1. Algorithm 4 learns the true set of POMISs with probability at least 1−2δ. Under the
event that it learns POMISs correctly, the cumulative regret is bounded as follows:
RT≤Knmax8
ϵ2,8
γ2
log4n2K2
δ+8
ϵ2log4nK2
δ+
8αdmax
KAAn(Y)+ max( B, C)
log An(Y)
+X
s∈{Ω(I)|∀I∈IG}∆do(s)
1 +logT
∆2
do(s)
,
where AandBare given by line 2 of Algorithm 1, and Cis given by line 3 of Algorithm 3 by setting
α=2dmaxlog (4
δ+2)
logAn(Y),δ1=δ
64αdmaxAn(Y)logAn(Y)andδ2=δ3=δ4=δ
64αdmaxlogAn(Y).
8The first three terms in the regret bound correspond to the interventional samples required to learn
the ancestors of the reward node, and then the set of POMISs ( IG). The last term corresponds to the
regret incurred by running the UCB algorithm over the POMIS set. The number of interventional
samples used to learn the true set of POMISs, with high probability, has polynomial scaling with
respect to the number of nodes nin the graph. However, the total number of arms in the POMIS
set, in the worst case, can exhibit exponential scaling with respect to the number of ancestors of
the reward node |An(Y)|. The advantage of sample-efficient discovery is that it helps us reduce the
action space before applying the UCB algorithm. If the graph is not densely confounded, the total
number of arms in the POMIS set would be small, and running causal discovery before the bandit
algorithm is advantageous. Without discovery, one would always have to run the UCB or a standard
MAB solver with exponentially many arms. For instance, if the causal graph has nnodes, there will
bePn
i=1 n
i
Ki= (K+ 1)ndifferent possible arms/interventions.
6 Experiments
Theorem 5.1 establishes the worst-case upper bound for cumulative regret when we need to test latent
confounders between all pairs of nodes within An(Y). However, Algorithm 4 selectively examines
only a subset of latent confounders sufficient to infer the true POMIS set, as outlined in Theorem
3.1. Although the advantage is hard to quantify in general, we demonstrate it using simulations on
randomly generated graphs. We sample a random ordering σamong the vertices. Then, for each nth
node, we determine its in-degree as Xn= max(1 ,Bin(n−1, ρ)), followed by selecting its parents
through uniform sampling from the preceding nodes in the ordering. Finally, we chordalize the graph
using the elimination algorithm [ 27], employing an elimination ordering that is the reverse of σ.
Additionally, we introduce a confounder between every pair of nodes with a probability of ρL. For
all the simulations, we randomly sample 50causal graphs with different values of densities ρand
ρLand assume that all variables are binary for simplicity, i.e., K= 2. We set the value of δto 0.99,
and the gaps γ=ϵ= 0.01andη= 0.05. We plot interventional samples used to learn the induced
observable graph on An(Y)with and without latent confounders, as well as the samples required to
learn the POMIS set by Algorithm 4. The width of confidence interval is set to 2standard deviations.
Figure 2: Simulations to demonstrate the advantage of Algorithm 4 over full graph discovery
(Learning all possible latents)
The simulation results in Figure 2 demonstrate that Algorithm 4 requires fewer samples than learning
the induced graph on An(Y), which includes all confounders. However, as ρLincreases for a fixed
ρ, this advantage diminishes, as illustrated in Figure 2. The trend remains consistent as the density
parameters ρandρLare varied from 0.2,0.4, and0.6. The plots in Figure 3 compare the exponentially
9growing arms in causal bandits with intervention samples used by our algorithm to learn the reduced
action set in the form of POMISs. This demonstrates the major advantage of our algorithm, which,
instead of exploring an exponentially large action set as in naive UCB algorithms, uses interventions
to reduce the action space to the POMIS set before applying the UCB algorithm. Additionally, the
number of intervention samples required in the first phase of identifying the true POMIS set grows
polynomially with respect to the number of nodes in the graph. However, the number of arms in the
POMIS set can still exhibit exponential scaling with respect to the number of ancestors of the reward
node in the worst case.
(a)ρ= 0.4, ρL= 0.2
 (b)ρ= 0.4, ρL= 0.4
 (c)ρ= 0.4, ρL= 0.6
Figure 3: Simulations to demonstrate advantage of discovery for causal bandits.
(a) Nodes n= 10
 (b) Nodes n= 15
 (c) Nodes n= 20
Figure 4: Cumulative regret for Algorithm 4 versus learning all possible latents (ρ=ρL= 0.3).
We also run the UCB algorithm on the learned POMIS set and plot the cumulative regret in Figure 4.
Since the number of time steps Tis on the order of 108, it is not feasible to store and plot cumulative
regret for every time step over multiple randomly sampled graphs; therefore, we downsample the
cumulative regret to show the overall trend. The downsampling, along with the large scale of the
y-axis, makes the regret in the discovery phase appear linear with a fixed slope, although it is piece-
wise linear if we zoom in. Also, the UCB phase converges very fast compared to the discovery phase
because the number of POMISs for randomly sampled graphs is small. We plot the results for graphs
with 10, 15, and 20 nodes, and in all cases, we can see the advantage of partial discovery compared to
full discovery, since Algorithm 4 finds the POMIS set with fewer samples. The code to reproduce
our experimental results is available at https://github.com/CausalML-Lab/CausalBandits_
with_UnknownGraph .
7 Conclusion
We show that partial discovery is sufficient to achieve sublinear regret for causal bandits with an
unknown causal graph containing latent confounders. Without relying on causal discovery, one must
consider interventions on all possible subsets of nodes, which is infeasible. Therefore, we propose a
two-phase approach: the first phase learns the induced subgraph of the ancestors of the reward node,
along with a subset of confounders, to construct a set of possibly optimal arms. We demonstrate that
the number of interventional samples in the first phase required to identify the POMIS set scales
polynomially with respect to the number of nodes in the causal graph. In the next phase, we apply
the Upper Confidence Bound (UCB) algorithm to the reduced action space to find the optimal arm.
8 Acknowledgment
Murat Kocaoglu acknowledges the support of NSF CAREER 2239375, IIS 2348717, Amazon
Research Award and Adobe Research.
10References
[1]Finnian Lattimore, Tor Lattimore, and Mark D Reid. Causal bandits: Learning good interven-
tions via causal inference. Advances in Neural Information Processing Systems , 29, 2016.
[2]Rajat Sen, Karthikeyan Shanmugam, Alexandros G Dimakis, and Sanjay Shakkottai. Identifying
best interventions through online importance sampling. In International Conference on Machine
Learning , pages 3057–3066. PMLR, 2017.
[3]Yangyi Lu, Amirhossein Meisami, Ambuj Tewari, and William Yan. Regret analysis of bandit
problems with causal background knowledge. In Conference on Uncertainty in Artificial
Intelligence , pages 141–150. PMLR, 2020.
[4]Vineet Nair, Vishakha Patil, and Gaurav Sinha. Budgeted and non-budgeted causal bandits. In
International Conference on Artificial Intelligence and Statistics , pages 2017–2025. PMLR,
2021.
[5]Sanghack Lee and Elias Bareinboim. Structural causal bandits: Where to intervene? Advances
in neural information processing systems , 31, 2018.
[6]Lai Wei, Muhammad Qasim Elahi, Mahsa Ghasemi, and Murat Kocaoglu. Approximate
allocation matching for structural causal bandits with unobserved confounders. Advances in
Neural Information Processing Systems , 36, 2024.
[7]Yangyi Lu, Amirhossein Meisami, and Ambuj Tewari. Causal bandits with unknown graph
structure. Advances in Neural Information Processing Systems , 34:24817–24828, 2021.
[8]Arnoud De Kroon, Joris Mooij, and Danielle Belgrave. Causal bandits without prior knowledge
using separating sets. In Conference on Causal Learning and Reasoning , pages 407–427.
PMLR, 2022.
[9]Mikhail Konobeev, Jalal Etesami, and Negar Kiyavash. Causal bandits without graph learning.
arXiv preprint arXiv:2301.11401 , 2023.
[10] Alan Malek, Virginia Aglietti, and Silvia Chiappa. Additive causal bandits with unknown graph.
arXiv preprint arXiv:2306.07858 , 2023.
[11] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: founda-
tions and learning algorithms . The MIT Press, 2017.
[12] Xinpeng Shen, Sisi Ma, Prashanthi Vemuri, and Gyorgy Simon. Challenges and opportunities
with causal discovery algorithms: application to alzheimer’s pathophysiology. Scientific reports ,
10(1):2975, 2020.
[13] Alessio Zanga, Elif Ozkirimli, and Fabio Stella. A survey on causal discovery: Theory and
practice. International Journal of Approximate Reasoning , 151:101–129, 2022.
[14] Murat Kocaoglu, Karthikeyan Shanmugam, and Elias Bareinboim. Experimental design for
learning causal graphs with latent variables. Advances in Neural Information Processing
Systems , 30, 2017.
[15] Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Schölkopf. Causal discov-
ery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination.
InIJCAI: Proceedings of the Conference , volume 2017, page 1347. NIH Public Access, 2017.
[16] Karthikeyan Shanmugam, Murat Kocaoglu, Alexandros G Dimakis, and Sriram Vishwanath.
Learning causal graphs with small interventions. Advances in Neural Information Processing
Systems , 28, 2015.
[17] Kristjan Greenewald, Dmitriy Katz, Karthikeyan Shanmugam, Sara Magliacane, Murat Ko-
caoglu, Enric Boix Adsera, and Guy Bresler. Sample efficient active learning of causal trees.
Advances in Neural Information Processing Systems , 32, 2019.
[18] Muhammad Qasim Elahi, Lai Wei, Murat Kocaoglu, and Mahsa Ghasemi. Adaptive online
experimental design for causal discovery, 2024.
11[19] David Heckerman, Christopher Meek, and Gregory Cooper. A bayesian approach to causal
discovery. Technical report, Technical report msr-tr-97-05, Microsoft Research, 1997.
[20] Yashas Annadani, Nick Pawlowski, Joel Jennings, Stefan Bauer, Cheng Zhang, and Wenbo
Gong. Bayesdag: Gradient-based posterior sampling for causal discovery. arXiv preprint
arXiv:2307.13917 , 2023.
[21] Christian Toth, Lars Lorch, Christian Knoll, Andreas Krause, Franz Pernkopf, Robert Peharz,
and Julius V on Kügelgen. Active bayesian causal inference. Advances in Neural Information
Processing Systems , 35:16261–16275, 2022.
[22] Judea Pearl. Causality . Cambridge university press, 2009.
[23] Jin Tian and Judea Pearl. A general identification condition for causal effects. In Aaai/iaai ,
pages 567–573, 2002.
[24] Alain Hauser and Peter Bühlmann. Two optimal strategies for active learning of causal models
from interventional data. International Journal of Approximate Reasoning , 55(4):926–939,
2014.
[25] Alfred V . Aho, Michael R Garey, and Jeffrey D. Ullman. The transitive reduction of a directed
graph. SIAM Journal on Computing , 1(2):131–137, 1972.
[26] Tor Lattimore and Csaba Szepesvári. Bandit algorithms . Cambridge University Press, 2020.
[27] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques .
MIT press, 2009.
12A Supplemental Material
A.1 Review of d-separation:
Consider three disjoint sets of nodes X,Y, andZin the causal graph G= (V,E). The sets of nodes
XandYared-separated given Z, denoted by (X⊥ ⊥dY|Z)G, if and only if there exists no path,
directed or undirected, between any node in set Xand any node in set Ysuch that for every collider
on the path, either the collider itself or one of its descendants is included in the set Z, and no other
non-collider nodes on the path are included in the set Z. (A collider on a path is a node with both
arrows converging, e.g., Bis a collider on the path ABC inA→B←C).
A.2 Pearl’s Rules of do-Calculus ([22]):
LetGrepresent the causal DAG, and let Pdenote the probability distribution induced by the
corresponding causal model. For any disjoint subsets of variables X,Y,Z, and W, the following rules
apply:
Rule 1: (Insertion/deletion of observations):
P(y|do(x),z,w) =P(y|do(x),w)if(Y⊥ ⊥dZ|X,W)GX. (2)
Rule 2: (Action/observation exchange):
P(y|do(x), do(z),w) =P(y|do(x),z,w)if(Y⊥ ⊥dZ|X,W)GXZ. (3)
Rule 3: (Insertion/deletion of actions):
P(y|do(x), do(z),w) =P(y|do(x),w)if(Y⊥ ⊥dZ|X,W)GX,Z(W), (4)
where Z(W)is the set of nodes in Zthat are not ancestors of any of the nodes in Win the graph GX.
A.3 Function to Detect Presence of Latent Confounder:
Algorithm 5: Function to Detect Presence of Latent Confounder
1Function DetectLatentConfounder( G, Xi, Xj, δ2, δ3, δ4,IData ):
2 C=16
ηγ2log(2n2K2
δ3) +1
2η2log(2n2K2
δ4),B=8
ϵ2log2nK2
δ2
3 ifXj∈An(Xi)swap them.
4 Find interventional data sets do(W=w)anddo(Xi=xi,W=w)fromIData s.t.
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W
5 Getmax(0 , B−C)new samples for do(W=w)
6 if∃xi, xj∈[K]s.t.|bP(xj|do(xi), do(w))−bP(xj|xi, do(w))|>γ
2then
7 Add bi-dirceted edge Xi← →Xjto graph G
8 return Updated Causal Graph G
9End Function
A.4 Proof of Lemma 3.2:
Lemma. 3.2: It is necessary to learn/detect the latent confounders between reward node Yand any
nodeX∈An(Y)in causal graph Gto learn all the POMISs correctly and hence avoid linear regret.
Before proceeding to the proof, we recall an important result from [ 5]: For a causal graph Gwith
reward variable Y, IB(GW, Y)is a POMIS for any W⊆V\Y.
Proof: Consider a causal graph G(V,E)with a node X∈An(Y)such that there exists a latent
confounder between Xand the reward Y. Suppose we do not detect the presence of the confounder
and have access to another causal graph G′with everything the same as Gexcept that there is no
confounder between XandY. We show that there exists one such POMIS that we cannot learn
fromG′, which actually exists in the true causal graph G. To prove this, consider a set of nodes
13W=Pa(X)∪Ch(Pa(X))∪CC(X)\ {X, Y}. For the graph G′, note that X /∈MUCT (G′
W, Y),
and also there ∄Z∈Ch(Pa(X))\ {X}s.t.Z∈MUCT (G′
W, Y). This implies that ∄Z∈Pa(X)
s.t.Z∈IB(G′
W, Y). However, for the true graph G, we have a different IB(GW, Y)for the same
definition of Wbecause it contains the bi-directed edge between XandY, which implies that
X∈MUCT (GW, Y), and as a result, Pa(X)⊆IB(GW, Y). Also, in the case Pa(X) =∅, we have
a different POMIS. On this side, note that X /∈MUCT (G′
W, Y), which implies that along the causal
path from XtoY, there must be one node Zsuch that Z∈MUCT (G′
W, Y), which implies either
Xor one of its descendants on the path from XtoYis in IB(G′
W, Y), which is not the case for G
since X∈MUCT (GW, Y). Thus, we have different interventional boundary or POMIS for the two
causal graphs GandG′given the above choice of W, even if Xhas no parents.
The next step is to show that the particular POMIS IB(GW, Y)cannot be learned from the DAG G′,
i.e.,IB(GW, Y)̸=IB(G′
W′, Y)for any W′⊆V. We need to show this because of the graphical
characterization of POMISs in Lemma 3.1. Using the definition of W, note that Pa(X)⊆IB(GW, Y)
and for all Z∈Ch(Pa(X))\{X}, there exists either Z∈IB(GW, Y)orDe(Z)\{Y} ∈IB(GW, Y).
Also, if there are such nodes in CC(X)\ {X, Y}which do not have a path to Xcomprised of
directed edges only, call such set of nodes T. IfT̸=ϕ, then for all t∈T, we have either
t∈IB(GW, Y)orDe(t)\ {Y} ∈ IB(GW, Y). Also, note that ∄Z∈De(X)∪ {X}such that
Z∈IB(GW, Y). Now consider DAG G′with the bi-directed edge between XandYmissing.
Assume by contradiction ∃W′⊆Vsuch that IB(GW, Y) =IB(G′
W′, Y). This, however, using
the aforementioned characterization of IB(GW, Y)implies that ∄Z∈Ch(Pa(X))\ {X}such that
Z∈MUCT (G′
W′, Y)and also ∄t∈Tsuch that t∈MUCT (G′
W′, Y)using the aforementioned
definition of T. However, note that we need Pa(X)⊆IB(G′
W′, Y), which under the given choice
ofWis only possible when X∈MUCT (G′
W′, Y), which would require is a bi-directed edge
between XandYin the DAG G′, which is a contradiction. Also, for the case when Pa(X) =ϕ,
we have a contradiction because we require the following to be true: ∄Z∈De(X)∪ {X}such that
Z∈IB(G′
W′, Y). For the given choice of W, it implies that there is a bi-directed edge between X
andYin the DAG G′, which is again a contradiction. Thus, by contradiction, we show that ∄W′⊆V
such that G′, i.e., IB(GW, Y)̸=IB(G′
W′, Y). This implies that we will miss at least one POMIS if
we do not learn or detect latent confounders between the reward node Yand any node X∈An(Y),
and may incur linear regret. This completes the proof of Lemma 3.2.
A.5 Proof of Theorem 3.1:
Before proving Theorem 3.1, we state and prove another Lemma. We then extend this Lemma to
prove Theorem 3.1.
Lemma A.1. Consider a causal graph G(V,E)and another graph G′such that they have the same
vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′being a
subset of the bidirected edges in G. The graphs will yield different collections of POMISs if there
exists some Z∈An(Y)such that either (a) or (b) is true:
(a) There is a bi-directed edge between ZandYinGbut not in G′.
(b)Neither of the graphs G′andGhave a bidirected edge between ZandY, and there exists a
bidirected edge in Gbetween some X∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)andZbut not in G′.
Proof: The first half of Lemma A.1, i.e., "The graphs will yield different collections of POMISs
if there exists some Z∈An(Y)such that there is a bi-directed edge between ZandYinGbut
not inG′," is the same as Lemma 3.2, and the same proof applies here. The reason is that in graph
G′, we miss a latent variable between reward and one of its ancestors, which was actually present
in the true graph G. We only need to proof the second half of Lemma A.1 i.e. graphs will yield
different collections of POMISs if there exists some Z∈An(Y)such that (b) is true. Consider
a causal graph G(V,E)and another DAG G′such that they have the same vertex set and directed
edges, but differ in bi-directed edges. Consider a causal graph G(V,E)and another DAG G′such
that they have the same vertex set and directed edges, but differ in bi-directed edges. We show
that if neither of the graphs G′andGhave a bidirected edge between ZandY, and there exists a
bidirected edge in Gbetween some X∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)andZ, then there exists one
such POMIS that we cannot learn from G′, which actually exists in the true causal graph G. To
prove this, consider a set of nodes W=Pa(Z)∪Ch(Pa(Z)\An(X))∪Bi(Z,G′)\ {X, Z, Y }. For
14the graph G′, note that Z /∈MUCT (G′
W, Y), and also there ∄N∈Ch(Pa(Z)\An(X))\ {Z}s.t.
N∈MUCT (G′
W, Y). This implies that ∄N∈Pa(Z)\An(X)s.t.N∈IB(G′
W, Y). However,
for the true graph G, we have a different IB(GW, Y)for the same definition of Wbecause it contains
the bi-directed edge between XandZ, which implies that Z∈MUCT (GW, Y), and as a result,
Pa(Z)\An(X)⊆IB(GW, Y). Also, in the case Pa(Z)\An(X) =∅, we have different a POMIS.
On this side, note that Z /∈MUCT (G′
W, Y), which implies that along the causal path from Z
toY, there must be one node Nsuch that N∈MUCT (G′
W, Y), which implies either Zor one
of its descendants on the path from ZtoYis in IB(G′
W, Y), which is not the case for Gsince
Z∈MUCT (GW, Y). Thus, we have different interventional boundary or POMIS for the two causal
graphs GandG′given the above choice of W.
The next step is to show that the particular POMIS IB(GW, Y)cannot be learned from the DAG G′,
i.e.,IB(GW, Y)̸=IB(G′
W′, Y)for any W′⊆V. We need to show this because of the graphical
characterization of POMISs in Lemma 3.1. Using the definition of W, note that Pa(Z)\An(X)⊆
IB(GW, Y)and for all N∈Ch(Pa(Z)\An(X))\ {Z}, there exists either N∈IB(GW, Y)or
De(N)\{Y} ∈IB(GW, Y). Also, if there are such nodes in Bi(Z,G′)\{X, Z, Y }which do not have
a path to Zcomprising of directed edges only, call such set of nodes T. IfT̸=ϕ, then for all t∈T,
we have either t∈IB(GW, Y)orDe(t)\{Y} ∈IB(GW, Y). Also, note that ∄N∈De(Z)∪{Z}such
thatN∈IB(GW′, Y). Now consider the DAG G′with the bi-directed edge between ZandYmissing.
Assume by contradiction ∃W′⊆Vsuch that IB(GW, Y) =IB(G′
W′, Y). This, however, using the
aforementioned characterization of IB(GW, Y)implies that ∄N∈Ch(Pa(Z)\An(X))\ {Z}such
thatN∈MUCT (G′
W′, Y)and also ∄t∈Tsuch that t∈MUCT (G′
W′, Y)for the aforementioned
definition of T. However, note that we need Pa(Z)\An(X)⊆IB(G′
W′, Y), which under the given
choice of Wis only possible when Z∈MUCT (G′
W′, Y), which would require a bi-directed edge
between ZandXin the DAG G′, which is a contradiction. Also, for the case when Pa(Z) =ϕ, we
have a contradiction because we require the following to be true: ∄N∈De(Z)∪ {Z}such that
N∈IB(G′
W′, Y). For the given choice of W, it implies that there is a bi-directed edge between Z
andXin the DAG G′, which is again a contradiction. Thus, by contradiction, we show that ∄W′⊆V
such that G′, i.e., IB(GW, Y)̸=IB(G′
W′, Y). This implies that we miss atleast one POMIS when
either of statements (a) and (b) hold. This completes the proof of Lemma A.1.
We now proceed to the formal proof for Theorem 3.1:
Theorem. 3.1: Consider a causal graph G(V,E)and another DAG G′such that they have the same
vertex set and directed edges but differ in bidirected edges, with the bidirected edges in G′being a
subset of the bidirected edges in G. The graphs will yield different collections of POMISs if and only
if there exists some Z∈An(Y)such that either (a) or (b) is true:
(a) There is a bi-directed edge between ZandYinGbut not in G′.
(b)Neither of the graphs G′andGhave a bidirected edge between ZandY, and there exists a
bidirected edge in Gbetween some X∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)andZbut not in G′.
Proof: One direction for Theorem 3.1 is proved already in Lemma A.1. We only to need to prove the
other direction which is that two causal graphs GandG′such that they have the same vertex set and
directed edges, but differ in bi-directed edges will yield same collections POMISs when neither of
statements (a) and (b) is true. Note when neither of (a) or (b) is true the graphs GandG′might still
have a different set of bi-directed edges. We will have two possible scenarios here. Suppose Ghas a
bi-directed edge between some Z∈An(Y)and some X∈An(Y), such that there is a bi-directed
edge between pair of vertices (Z, Y)and(X, Y)in both the graphs and the bi-directed edge between
XandZis absent in G′. Further, assume neither of statements (a) and (b) hold. In this case, despite
the absence of a bi-directed edge between XandZinG′, the graphs will yield the same set of
POMISs. This is because Z /∈MUCT (GW, Y)for some set of nodes Wonly when Z∈W, and the
same is the case for Gbecause they share a bi-directed edge between ZandY. By symmetry, we have
the argument hold for Xas well. So, the presence or absence of bi-directed edges between XandZ
does not change the set of POMISs learned from the graph when both XandZare confounded with
reward Yalready. Thus, we can delete all such bi-directed edges one by one from Gwhile the set of
POMISs learned from each of the intermediate causal graphs stays the same. Consider the second
scenario, where Ghas bi-directed edges between a node Z∈An(Y), such that there is no bi-directed
15edge between ZandYin both graphs ( GandG′) and a node Xthat has the following characteristics:
X∈MUCT (G′
W, Y)for some set W⊆VbutX /∈MUCT (G′
Pa(Z),Bi(Z,G′), Y). However, the
bi-directed edge between XandZis absent in G′. Further, assume neither of statements (a) and (b)
hold. The condition X∈MUCT (G′
W, Y)butX /∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)implies that either
∃N∈Pa(Z)such that N∈MUCT (G′
W, Y)or∃N∈Bi(Z,G′)such that N∈MUCT (G′
W, Y).
Since bi-directed edges in G′are a subset of bi-directed edges in G, we have: Either ∃N∈Pa(Z)
such that N∈MUCT (GW, Y)or∃N∈Bi(Z,G)such that N∈MUCT (GW, Y). Note that
anyMUCT is closed under the De(.)andCC(.)operations, i.e., for any MUCT, say T, we have
De(T) = TandCC(T) = T. if∃N∈Pa(Z)such that N∈MUCT (GW, Y)or∃N∈Bi(Z,G)
such that N∈MUCT (GW, Y), we already have Z∈MUCT (GW, Y)using the definition of
MUCT . The bi-directed edge between XandZwill play a role only when ∄N∈Pa(Z)such
thatN∈MUCT (GW, Y)and∄N∈Bi(Z,G)such that N∈MUCT (GW, Y)for any choice
ofW. Recall that the given condition X∈MUCT (G′
W, Y)butX /∈MUCT (G′
Pa(Z),Bi(Z,G′), Y)
already implies that either ∃N∈Pa(Z)such that N∈MUCT (GW, Y)or∃N∈Bi(Z,G)such that
N∈MUCT (GW, Y). Thus absence or presence of bi-directed edge between XandZwill have no
effect on POMISs learned from graph Gin this scenario as well. Combining both of the scenarios
when neither of the conditions of (a) and (b) hold, all other bi-directed edges from G, which are
absent in G′, can be removed one by one from Gwhile keeping the POMISs learned from both the
intermediate graphs the same. Since GandG′only differ in bi-directed edges, with bi-directed edges
inG′being a subset of those in G, eventually both graphs will become identical, which proves the
statement: Two graphs GandG′will have the same POMISs if neither of the statements (a) or (b)
hold true. This completes the proof of the Theorem 3.1.
A.6 Proof of Lemma 4.1:
Consider a causal graph G(V,E)andW⊆V. Furthermore, let X, T∈V\Wbe any two variables.
Fix some realization w∈[K]|W|. Under post interventional faithfulness Assumption 2.1 we want to
prove: (X∈An(T))GW⇐⇒ P(t|do(w))̸=P(t|do(w), do(x))for some x, t∈[K].
Forward Direction ( =⇒):(X∈An(T))GW=⇒P(t|do(w))̸=P(t|do(w), do(x))for some
x, t∈[K]. By contradiction, assume P(t|do(w)) =P(t|do(w), do(x)),∀x, t∈[K]. This implies
thatP(t|do(w), do(x)) = P(t|do(w)) = some function of only tandw. This implies that for
the sub-model MW,Xthe following CI statements holds: (T⊥ ⊥X)M W,X. However, note that if
(X∈An(T))GW, then we still have (X∈An(T))GW,X. This implies there is a directed path from X
toTin the post-interventional graph GW,X. Therefore, we have: (T̸⊥ ⊥dX)GW,X. Note that under
the post interventional faithfulness Assumption 2.1, the CI statement (T⊥ ⊥X)MW,Xcan hold only
if the d-separation statement holds (T⊥ ⊥dX)GW,X, which is clearly a contradiction. This completes
the proof for the forward direction.
Reverse Direction ( ⇐=):(X∈An(T))GW⇐=P(t|do(w))̸=P(t|do(w), do(x))for
some x, t∈[K]. We prove the contrapositive statement instead, i.e., (X /∈An(T))GW=⇒
P(t|do(w)) = P(t|do(w), do(x)),∀x, t∈[K]. Note that (X /∈An(T))GWclearly implies that
(X /∈An(T))GW,Xwhich implies that (T⊥ ⊥dX)GW,X. Thus, using Rule 3 of Pearl’s do calculus,
we have: P(t|do(w), do(x)) = P(t|do(w)),∀x, t∈[K]. This completes the proof of the reverse
direction.
A.7 Proof of Lemma 4.2:
Consider two variables XiandXjsuch that Xj/∈An(Xi)and a set of variables (Pa(Xi)∪Pa(Xj)\
{Xi})⊆WandXi&Xj/∈W. Fix some realization w∈[K]|W|. Under the post-interventional
faithfulness Assumption 2.1 we want to show that: There is latent confounder between XiandXj
⇐⇒ P(xj|do(xi), do(W=w))̸=P(xj|xi, do(W=w))for some realization xi, xj∈[K].
Forward Direction ( =⇒):There is latent confounder between XiandXjsuch that Xj/∈An(Xi)
=⇒P(xj|do(xi), do(W=w))̸=P(xj|xi, do(W=w))for some realization xi, xj∈[K]. By
contradiction assume P(xj|do(xi), do(W=w)) =P(xj|xi, do(W=w))∀xi, xj∈[K]. Recall
16that:Xj=fj(Pa(Xj),Uj). Since there is latent confounder between XiandXjcall it Lij. Also
note that Lij∈Uj. Define U′
j:=Uj\ {Li,j}
P(xj|do(xi), do(W)) =P(xj|do(xi), do(pa(Xi)), do(pa(Xj)\ {xi}))) (5)
where the interventions do(Pa(Xi))anddo(Pa(Xj)))are consistent with do(xi)anddo(W=w).
The equation 5 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set
W, we have (Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi, Xj/∈W. All the extra intervention targets
can simply be deleted, and we are left with intervention on Xi,Pa(Xi), and Pa(Xj).
P(xj|do(xi), do(W)) =X
u′
j, li,jP(xj|do(xi), do(pa(Xi)), do(pa(Xj)\ {xi}),U′
j=u′
j, Lij=lij)
×P(U′
j=u′
j, Lij=lij)
(6)
We have another application of Pearl’s do-calculus Rule 3 because interventions on observed variables
don’t affect unobserved variables, as there are no causal/directed paths from observed to unobserved
variables. Also we have:
P(xj|xi, do(W)) =P(xj|xi, do(pa(Xi)), do(pa(Xj)\ {xi}))) (7)
The equation 7 holds by the application of Pearl’s do-calculus Rule 3 because, by definition of the set
W, we have (Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi, Xj/∈W. All the extra intervention targets
can simply be deleted, and we are left with conditioning on Xi=xiand interventions on Pa(Xi)
andPa(Xj).
P(xj|xi, do(W)) =X
u′
j, li,jP(xj|xi, do(pa(Xi)), do(pa(Xj)\ {xi}),U′
j=u′
j, Lij=lij)
×P(U′
j=u′
j, Lij=lij|xi, do(pa(Xi)), do(pa(Xj)\ {xi}))
(8)
Using Pearl’s do-calculus Rule 2, we can replace the conditioning Xi=xiwith the intervention
do(xi)inP(xj|xi, do(pa(Xi)), do(pa(Xj)\ {xi}),U′j=u′j, Lij=lij)because Xj/∈An(Xi)
andPa(Xi)are already intervened on. Also, the latent confounder Lijis conditioned on, so there is
no open backdoor path from XitoXj. Thus, we have:
P(xj|xi, do(W)) =X
u′
j, li,jP(xj|do(xi), do(pa(Xi)), do(pa(Xj)\ {xi}),U′
j=u′
j, Lij=lij)
×P(U′
j=u′
j, Lij=lij|xi, do(pa(Xi)), do(pa(Xj)\ {xi}))
(9)
From the Equations 6 and 9 and assumption P(xj|do(xi), do(W=w)) =P(xj|xi, do(W=w))
∀xi, xj∈[K]we have:
X
u′
j, li,jP(xj|do(xi), do(pa(Xi)), do(pa(Xj)\ {xi}),U′
j=u′
j, Lij=lij)
×
P(U′
j=u′
j, Lij=lij|xi, do(pa(Xi)), do(pa(Xj)\ {xi}))−P(U′
j=u′
j, Lij=lij)
= 0
(10)
Since probabilities are non-negative, whenever P(xj|do(xi), do(pa(Xi)), do(pa(Xj)\
{xi}),U′j=u′j, Lij=lij)>0, we must have:
17P(U′
j=u′
j, Lij=lij|xi, do(pa(Xi)), do(pa(Xj)\ {xi})) =P(U′
j=u′
j, Lij=lij).(11)
However, since we know that Lijis a confounder between XiandXj, we have an edge Lij→Xi
in the causal graph, which implies that under any intervention do(Z)such that Xi/∈Z, we must
have(Lij̸⊥ ⊥Xi)MZby interventional faithfulness Assumption 2.1. This implies that there exists a
realization x∗
iandl∗
ijsuch that:
P(U′
j=u′
j, Lij=l∗
ij|x∗
i, do(pa(Xi)), do(pa(Xj)\ {xi}))̸=P(U′
j=u′
j, Lij=l∗
ij)(12)
Now, using the combination do(W=w)and a special choice of realizations x∗
iandl∗
ij, we must have
at least one special realization x∗
jsuch that: P(x∗
j|do(x∗
i), do(Pa(Xi)), do(Pa(Xj)\ {xi}),U′j=
u′j, Lij=l∗
ij)>0. Combining this with Equations 12 and 10, we conclude for some x∗
i, x∗
j∈[K],
we have P(x∗
j|do(x∗
i), do(W=w))̸=P(x∗
j|x∗
i, do(W=w)). Thus this leads to contradiction.
Thus if there is a latent confounder between XiandXj=⇒P(xj|do(xi), do(W=w))̸=P(xj|
xi, do(W=w))for some realization xi, xj∈[K]. This completes the proof of the forward direction.
Reverse Direction (⇐=): For a pair of variables XiandXjsuch that Xj/∈An(Xi), ifP(xj|
do(xi), do(W=w))̸=P(xj|xi, do(W=w))for some realizations xi, xj∈[K], then there is a
latent confounder between XiandXj. We prove the contrapositive statement instead, i.e., if there is no
latent confounder between XiandXj, then P(xj|do(xi), do(W=w)) =P(xj|xi, do(W=w)),
∀xi, xj∈[K]. Note that by construction, we have: (Pa(Xi)∪Pa(Xj)\ {Xi})⊆W. For such
choice of set Wand the fact that Xj/∈An(Xi)and there is no latent confounder between XiandXj,
we have (Xj⊥ ⊥Xi)GXiW. Thus, from Pearl’s do-calculus Rule 2, we have P(xj|do(xi), do(W=
w)) =P(xj|xi, do(W=w)),∀xi, xj∈[K]. This completes the proof of the reverse direction.
A.8 Proof of Lemma 4.3:
Suppose that Assumption 4.1 holds and we have access to max(8
ϵ2,8
γ2) log2K2
δ1samples from
do(Xi=xi,W=w)∀xi∈[K]and8
ϵ2log2K2
δ2samples from do(W=w)for a fixed w∈[K]|W|
for some W⊆V. We want to show that with probability at least 1−δ1−δ2, we have the following:
(Xi∈An(Xj))GW⇐⇒ ∃ xi, xj∈[K]s.t.bP(xj|do(w))−bP(xj|do(w), do(xi))>ϵ
2.(13)
Using Hoeffding’s inequality with Asamples from intervention do(xi,w),
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≥s
1
2Alog2K2
δ1w.p. at mostδ1
K2. (14)
If we choose A=max(8
ϵ2,8
γ2) log2K2
δ1, we have:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≥ϵ
4w.p. at mostδ1
K2. (15)
Similarly, using Hoeffding’s inequality with Bsamples from intervention do(w),
bP(xj|do(w))−P(xj|do(w))≥s
1
2Alog2K2
δ1w.p. at mostδ2
K2. (16)
If we choose B=8
ϵ2log2K2
δ2, we have:
bP(xj|do(w))−P(xj|do(w))≥ϵ
4w.p. at mostδ2
K2. (17)
18Since the realization w∈[K]|W|is fixed, while xiandxjare in [K], we have a total of K2possible
bad events when the estimates are not accurate. Given the choice of samples, AandB, we have:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤ϵ
4∀xi, xj∈[K]w.p. at least 1−δ1,(18)
bP(xj|do(w))−P(xj|do(w))≤ϵ
4∀xj∈[K]w.p. at least 1−δ2. (19)
Under the good event, which occurs with a probability of at least 1−δ1−δ2, the estimates are
accurate. We now consider the two possible scenarios. Suppose that Xi/∈An(Xj)inGW. In this case
by Pearl’s do-calculus Rule 3 we haveP(xj|do(xi), do(w))−P(xj|do(w))= 0,∀xi, xj∈[K].
By triangular inequality we have the following:
bP(xj|do(xi), do(w))−bP(xj|do(w))≤bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))+
bP(xj|do(w))−P(xj|do(w))≤ϵ
2∀xi, xj∈[K].(20)
However, when Xi∈An(Xj)inGWunder Assumption 4.1 we must have some configuration say
xi, xj∈[K]for any w∈[K]|W|such thatP(xj|do(xi), do(w))−P(xj|do(w))> ϵ. By triangular
inequality when Xi∈An(Xj)inGW,∃xi, xj∈[K]such that
bP(xj|do(xi), do(w))−bP(xj|do(w))≥P(xj|do(xi), do(w))−P(xj|do(w))
−bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))−bP(xj|do(w))−P(xj|do(w))>ϵ
2.(21)
Thus, using Assumption 4.1 with the given choice of number of samples with probability at least
1−δ1−δ2, we have the following result:
(Xi∈An(Xj))GW⇐⇒ ∃ xi, xj∈[K]s.t.bP(xj|do(w))−bP(xj|do(w), do(xi))>ϵ
2.(22)
This completes the proof for Lemma 4.3.
A.9 Proof of Lemma 4.4:
In order to prove that Algorithm 1 learns the true transitive closure under any intervention, i.e., Gtc
W,
we recall from the proof of Lemma 4.3 that the test for ancestrality works with high probability under
the event that the causal effects of the form P(xj|do(xi), do(w))andP(xj|do(w))are estimated
accurately with an error of at mostϵ
4for all xi, xj∈[K]and any fixed w∈[K]W. Now, since
Algorithm 1 takes B=8
ϵ2log2nK2
δ2samples from do(W=w)andA= max
8
ϵ2,8
γ2
log2nK2
δ1
samples from every do(Xi=xi,W=w)for all Xi∈V\Wand for all xi∈[K], the total number
of intervention samples collected is clearly at most KAn +B. In order to show that Algorithm 1
learns the true transitive closure under any intervention, i.e., Gtc
W, with high probability, we must
demonstrate that Algorithm 1 can estimate all causal effects with a maximum error ofϵ
4with high
probability, so that all the ancestrality tests work with high probability, as implied by the proof of
Lemma 4.3.
19Using Hoeffding’s inequality with B=8
ϵ2log2nK2
δ2samples from the intervention do(w), we have
for any Xj∈V\W:
bP(xj|do(w))−P(xj|do(w))≤ϵ
4∀xj∈[K]w.p. at least 1−δ2
n. (23)
Using the union bound we have the following:
bP(Xj=xj|do(w))−P(Xj=xj|do(w))≤ϵ
4∀xj∈[K],∀Xj∈V\Ww.p. at least 1−δ2.
(24)
Now, consider a fixed pair Xi, Xj∈V\W, and using A= max
8
ϵ2,8
γ2
log2nK2
δ1samples from
the intervention do(xi,w)for every xi∈[K], we have the following using Hoeffding’s inequality:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤min(ϵ
4,γ
4)∀xi, xj∈[K]w.p. at least 1−δ1
n
(25)
Using the union bound we have the following:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤min(ϵ
4,γ
4)
∀xi, xj∈[K],∀Xj∈V\(W∪ {Xi})w.p. at least 1−δ1
(26)
Again using the union bound over all intervention targets Xi∈Vwe have the following:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤min(ϵ
4,γ
4)
∀xi, xj∈[K],∀Xi∈V\W,∀Xj∈V\(W∪ {Xi})w.p. at least 1−nδ1
(27)
From Equations 24 and 27, using the union bound with probability at least 1−nδ1−δ2, all the
causal effects are estimated within an error ofϵ
4from the true values, ensuring that all ancestrality
tests work perfectly under this good event. Thus, Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc
W, with KAn +Bintervention samples with probability of at least
1−nδ1−δ2. Also, if we set δ1=δ
2nandδ2=δ
2, then Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc
Wwith a probability of 1−δ, with KAn +Bintervention samples,
where A= max
8
ϵ2,8
γ2
log4n2K2
δandB=8
ϵ2log4nK2
δ. This completes the proof of Lemma 4.4.
A.10 Proof of Theorem 4.1:
We start by revising the statement of Lemma 4.3: Algorithm 1 learns the true transitive closure
under any intervention, i.e., Gtc
W, with KAn +Bintervention samples with a probability of at least
1−nδ1−δ2. Algorithm 2 randomly samples a target set Wand calls Algorithm 1 to learn the active
true transitive closure of the post-interventional graph, i.e., Gtc
W. For every iteration, Algorithm 2
computes transitive reduction Tr(Gtc
W)and updates all the edges to construct the observable graph.
To prove the results in Theorem 4.1, we rely on Lemma 5 from [14], which is stated below:
20Lemma A.2. [14] Consider a graph Gwith observed variables Vand an intervention set W⊆V.
Consider post-interventional observable graph GWand a variable Xj∈V\W. LetXi∈Pa(Xj)
be such that all the parents of Xjabove Xiin partial order are included in the intervention set
W. This implies that {Wi:π(Wi)> π(Xi) &Wi∈Pa(Xj)} ⊆W. Then, the directed
edge (Xi, Xj)∈E(Tr(GW)). The properties of transitive reduction yields Tr(GW) =Tr(Gtc
W).
Consequently, the transitive reduction of Gtc
W, i.e., Tr(Gtc
W) =Tr(GW)may be used to learn the
directed edge (Xi, Xj).
(Note: E(G)denotes the edges of the graph Gandπis any total order that is consistent with the
partial order implied by the DAG, i.e., π(X)< π(Y)iff X is an ancestor of Y).
Assume that the number of the direct parents of Xjabove Xiisdijwhere dij≤dmax. LetEi(Xj)
be the following event: Xi, Xj/∈W&{Wi:π(Wi)> π(Xi) &Wi∈Pa(Xj)} ⊆W. The
probability of this event for one run of the outer loop in Algorithm 2 with the assumption that
2dmax>= 2is given by:
P[Ei(Xj)] =1
4d2max(1−1
2dmax)dij≥1
4d2max(1−1
2dmax)2dmax≥1
d2max1
16. (28)
The last inequality holds for 2dmax>= 2because (1−1
x)x≥0.25,∀x≥2. Based on Lemma
A.2, the event Ei(Xj)implies that the directed edge (Xj, Xj)will be present in Tr(Gtc
W)and
will be learned. The outer loop runs for 8αdmaxlog(n)iterations and elements of the set Ware
independently sampled. The probability of failure, i.e., the event under consideration does not happen
for all runs of the outer loop in Algorithm 2, is bounded as follows:
P[(Ei(V))c]≤(1−1
16d2max)8αdmaxlog(n)≤e−α
2dmaxlog(n)=1
nα
2dmax. (29)
For a graph with a total number of variables n, the total number of such bad events will be n
2
since
a graph can have at most n
2
edges. Using the union bound, the probability of bad event for any pair
of variables is given by:
P[Failure ]≤n
2
×1
nα
2dmax≤1
nα
2dmax−2. (30)
Under the event that Algorithm 1 learns the correct transitive closure Gtc
Wfor all the 8αdmaxlogn
randomly sampled intervention sets W⊆V, the above derivation shows that we will be able to learn
all edges in the true observable graph with a probability of at least 1−1
nα
2dmax−2. Now recall the
result from Lemma 4.3 that Algorithm 1 learns the true transitive closure under any intervention, i.e.,
Gtc
W, with KAn +Bintervention samples with a probability of at least 1−nδ1−δ2. Combining the
two results above using the union bound, we have the following result:
Algorithm 2 learns the true observable graph with a probability of at least 1−1
nα
2dmax−2−
8αdmaxlog(n)(nδ1+δ2)with a maximum 8αdmaxlogn(KAn +B)interventional samples. Also,
if we set α=2dmaxlog (2
δ+2)
logn,δ1=δ
32αdmaxnlogn, and δ2=δ
32αdmaxlogn, then Algorithm 2 learns the
true observable graph with a probability of at least 1−δ. Where A= max
8
ϵ2,8
γ2
log2nK2
δ1and
B=8
ϵ2log2nK2
δ2. This completes the proof of Theorem 4.1.
A.11 Proof of Lemma 4.5:
Consider two nodes XiandXjs.t.Xj/∈An(Xi)and suppose that Assumptions 4.2 4.3 holds
and we have access to max(8
ϵ2,8
γ2) log2K2
δ1samples from do(Xi=xi,W=w)∀xi∈[K]and
16
ηγ2log(2K2
δ3) +1
2η2log(2K2
δ4)from do(W=w)for a fixed w∈[K]|W|andW⊆Vsuch that
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W. We want to show that, with probability at
least1−δ1−δ3−δ4, we have the following:
21There exists a latent confounder between XiandXj⇐⇒
∃xi, xj∈[K]s.t.bP(xj|do(xi), do(w))−bP(xj|xi, do(w))>γ
2.
(31)
Using Hoeffding’s inequality with Asamples from intervention do(xi,w).
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≥s
1
2Alog2K2
δ1w.p. at mostδ1
K2. (32)
If we choose A=max(8
ϵ2,8
γ2) log2K2
δ1, we have:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≥γ
4w.p. at mostδ1
K2. (33)
Using Hoeffding’s inequality with Csamples from intervention do(xi).
bP(xj|xi, do(w))−P(xj|xi, do(w))≥s
1
2Cxilog2K2
δ3w.p. at mostδ3
K2. (34)
Where Cxiis the number of samples where Xi=xiamong the Csamples for the intervention do(w).
Note the we can’t directly control Cxiand it’s value depends on the true interventions distribution
P(xi, do(w))along-with the number of samples C. Suppose if we can set Cxi≥8
γ2log2K2
δ3, we
have:
bP(xj|xi, do(w))−P(xj|xi, do(w))≥γ
4w.p. at mostδ3
K2. (35)
We need to find the number of samples Csuch that Cxi≥8
γ2log2K2
δ3. Using the Hoeffding’s bound
we have:
P(Cxi≥CP(xi|do(w))−η)≥1−2e−2η2/C. (36)
Letδ4
K2= 2e−2η2/C, which implies η=q
C
2log2K2
δ4. Thus we have:
P
Cxi≥CP(xi|do(w))−s
C
2log2K2
δ4
≥1−δ4
K2(37)
Cxi≥CP(xi|do(w))−s
C
2log2K2
δ4w.p. at least 1−δ4
K2. (38)
Using Assumption 4.3, we have P(xi|do(w)) = 0 orP(xi|do(w))≥η. Note that if P(xi|do(w)) =
0, the event will never happen, and we don’t care about the accuracy of the estimate bP(xj|xi, do(w))
because it is already initialized to zero. Now the equation above can be rewritten as:
Cxi≥Cη−s
C
2log2K2
δ4w.p. at least 1−δ4
K2. (39)
Since we want Cxi≥8
γ2log2K2
δ3with high probability, we have the following relationship:
22Cη−s
C
2log2K2
δ4≥8
γ2log2K2
δ3(40)
Solving the equation for number of samples Cwe get:
C≥4η8 log
2K2
δ3
γ2 + ln
2K2
δ4
+r
8η8 log
2K2
δ3
γ2 ln
2K2
δ4
+ ln2
2K2
δ4
4η2(41)
In order to make the expression simpler we choose the number of samples Cas follows:
C=4η8 log
2K2
δ3
γ2 + ln
2K2
δ4
+r
8η8 log
2K2
δ3
γ2 ln
2K2
δ4
+ ln2
2K2
δ4
+ 
4η8 log
2K2
δ3
γ22
4η2
(42)
C=4η8 log
2K2
δ3
γ2 + ln
2K2
δ4
+s
4η8 log
2K2
δ3
γ2 + ln
2K2
δ42
4η2(43)
C=4η8 log
2K2
δ3
γ2 + ln
2K2
δ4
2η2(44)
C=16
ηγ2log(2K2
δ3) +1
2η2log(2K2
δ4) (45)
Suppose we take Csamples for intervention do(w)as given above. Now, from Equations 35, 39, and
40, using the union bound, we have the following:
bP(xj|xi, do(w))−P(xj|xi, do(w))≥γ
4w.p. at mostδ3+δ4
K2. (46)
Since the realization w∈[K]|W|is fixed, but xi, xj∈[K], we have a total of K2possible bad
events when estimates are not good. With the given choice of number of samples AandC, we have:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤γ
4∀xj∈[K]w.p. at least 1−δ1. (47)
bP(xj|xi, do(w))−P(xj|xi, do(w))≤γ
4∀xi, xj∈[K]w.p. at least 1−δ3−δ4. (48)
Under the good event, which has a probability of at least 1−δ1−δ3−δ4, both estimates are
accurate. We now consider the two possible scenarios. Suppose that there is no latent confounder
between XiandXj. In this case by Lemma 4.2 we haveP(xj|do(xi), do(w))−P(xj|xi, do(w))=
0,∀xixj∈[K]. By triangular inequality we have the following:
bP(xj|do(xi), do(w))−bP(xj|xi, do(w))≤bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))+
bP(xj|x,do(w))−P(xj|xi, do(w))≤γ
2∀xi, xj∈[K].(49)
23However, when there is a latent confounder between XiandXj, in this case, under Assump-
tion 4.2, we must have some configuration, say xi, xj∈[K], for any w∈[K]|W|, such thatP(xj|do(xi), do(w))−P(xj|xi, do(w))> γ. By triangular inequality when there is a latent
confounder between XiandXj,∃xi, xj∈[K]such that:
bP(xj|do(xi), do(w))−bP(xj|xi, do(w))≥P(xj|do(xi), do(w))−P(xj|xi, do(w))
−bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))−bP(xj|xi, do(w))−P(xj|xi, do(w))>γ
2
(50)
Thus, using Assumption 4.2 with the given choice of number of samples with probability at least
1−δ1−δ3−δ4, we have the following result:
There exists a latent confounder between XiandXj⇐⇒
∃xi, xj∈[K]s.t.bP(xj|do(xi), do(w))−bP(xj|xi, do(w))>γ
2.
(51)
This completes the proof for Lemma 4.5.
A.12 Proof of Theorem 4.2:
The Algorithm 3 first calls Algorithm 2 to learn the observable graph structure. We have already
proved in Theorem 4.1 that Algorithm 2 learns the true observable graph with a probability of at least
1−1
nα
2dmax−2−8αdmaxlog(n)(nδ1+δ2)with a maximum of 8αdmaxlogn(KAn +B)interventional
samples. The next phase in Algorithm 3 is to learn/detect latent confounders between any pair
of variables. For all pairs of nodes XiandXjsuch that Xj/∈An(Xi), we define a set of nodes
Wij⊆Vsuch that Xi, Xj/∈Si, where Wij= (Pa(Xi)∪Pa(Xj)\ {Xi}). Also, note that
|Wij| ≤2dmax. Let us define the event Eij= [Wij⊆W&Xj, Xi/∈W]. The probability of this
event for one run of the outer loop in Algorithm 2 with the assumption that 2dmax≥2is given by:
P[Eij] =1
4d2max(1−1
2dmax)|Wij|≥1
4d2max(1−1
2dmax)2dmax≥1
d2max1
16. (52)
The last inequality holds for dmax≥2. Note that we reuse all the interventional data samples from
Algorithm 2 in Algorithm 3. Under Assumption 4.2, if the event Eijhappens with a large enough
number of samples, we can detect the presence or absence of latent confounders between XiandXj.
The outer loop runs for 8αdmaxlog(n)iterations, and the elements of the set Ware independently
sampled. The probability of failure, i.e., the event under consideration does not happen for all runs of
the outer loop in Algorithm 2, is bounded as follows:
P[Ec
ij]≤(1−1
16d2max)8αdmaxlog(n)≤e−α
2dmaxlog(n)=1
nα
2dmax. (53)
For a graph with a total number of variables n, the total number of such bad events will be n
2
. Using
the union bound, the probability of bad event for any pair of variables is given by:
P[Failure ]≤n
2
×1
nα
2dmax≤1
nα
2dmax−2. (54)
This implies with a probability of 1−1
nα
2dmax−2, we will be able to find an appropriate interventional
dataset to test the presence of latent confounders between any pair of variables using Assumption 4.2
24after running Algorithm 2. We still need to make sure we have enough interventional samples to be
able to test the latents. This is because we need to accurately estimate conditional effects to carry out
the test, as in Assumption 4.2. We first consider estimation of the causal effect bP(xj|do(xi), do(w))
for any randomly sampled set W. Now, consider a fixed Xi, Xj∈V\W. We have access to
max
8
ϵ2,8
γ2
log2nK2
δ1samples for every xi∈[K]. We have already shown that under the good
event, we have the following:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤min(ϵ
4,γ
4)
∀xi, xj∈[K],∀Xi∈V\W,∀Xj∈V\(W∪ {Xi})w.p. at least 1−nδ1
(55)
Now, we consider estimation of the conditional causal effects, i.e., bP(xj|xi, do(w)). Note the while
running the Algorithm 2 we have access to B=8
ϵ2log2nK2
δ2samples form intervention do(w)
and in the step 7 of Algorithm 3 we add more samples to the data set and have access to at least
C=16
ηγ2log(2n2K2
δ3) +1
2η2log(2n2K2
δ4)samples instead. Now, consider a fixed Xi, Xj∈V\W.
With access to Csamples as given above, following from Equation 48 in the Proof of Lemma 4.5, we
have the following result:
bP(xj|xi, do(w))−P(xj|xi, do(w))≤γ
4∀xi, xj∈[K]w.p. at least 1−δ3
n2−δ4
n2.(56)
Note that in the above equation, we haveδ3
n2andδ4
n2instead of δ3andδ4as in Equation 48, because
here in the number of samples C, we also haveδ3
n2andδ4
n2instead of δ3andδ4when compared to the
number of samples in Equation 45. Now, using the union bound we have the following:
bP(xj|xi, do(w))−P(xj|xi, do(w))≤γ
4
∀xi, xj∈[K],∀Xj∈V\(W∪ {Xi})w.p. at least 1−δ3
n−δ4
n. (57)
Again using the union bound over all Xi∈V\Wwe have the following:
bP(xj|do(xi), do(w))−P(xj|do(xi), do(w))≤γ
4
∀xi, xj∈[K],∀Xi∈V\W,∀Xj∈V\(W∪ {Xi})w.p. at least 1−δ3−δ4(58)
This implies that under the good event, for every randomly sampled intervention set W⊆V, the
estimate of the conditional causal effect is accurate within the desiredγ
4threshold. This would imply
that the test for detection of latent variables is perfect under this good event. We have already shown
that to ensure we have access to sufficient datasets to detect latent variables between any pair of
nodes, the 8αdmaxlognrandomly sampled target sets in Algorithm 2 are sufficient. Combining these
results with the results from Theorem 4.1, we have the following:
The Algorithm 3 learns the true causal graph along with all latents with a probability of at least
1−1
nα
2dmax−2−1
nα
2dmax−2−8αdmaxlog(n)(nδ1+δ2)−8αdmaxlog(n)(δ3+δ4) = 1−2
nα
2dmax−2−
8αdmaxlog(n)(nδ1+ (δ2+δ3+δ4))with a maximum 8αdmaxlogn(KAn + max( B, C))inter-
ventional samples. Also If we set α=2dmaxlog (4
δ+2)
logn,δ1=δ
64αdmaxnlognandδ2=δ3=δ4=
δ
64αdmaxlogn, then Algorithm 2 learns the true causal graph with latents with a probability at least 1−δ.
Note that: A= max
8
ϵ2,8
γ2
log2nK2
δ1, B=8
ϵ2log2nK2
δ2, C=16
ηγ2log(2K2
δ3)+1
2η2log(2K2
δ4).This
completes the proof for Theorem 4.2.
25Algorithm 6: Full version of Algorithm for causal bandits with unknown graph structure
1Set the Parameter δ, dmax
2Calculate α, δ1, δ2, δ3, δ4as in Theorem 5.1
3Gtc=LearnTransitiveClosure (W=ϕ,δ
2n,δ
n)
4G,IData =LearnObservableGraph (An(Y)Gtc, α, d max, δ1, δ2)
5C=16
ηγ2log(2n2K2
δ3) +1
2η2log(2n2K2
δ4),B=8
ϵ2log2nK2
δ2
6#Learn the bi-directed edges between reward Yand all nodes Xi∈An(Y)and update G.
7forevery Xi∈An(Y)Gtcdo
8 SetXj:=Y
9 Find interventional data sets do(W=w)anddo(Xi=xi,W=w)fromIData s.t.
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W
10 Getmax(0 , B−C)new samples for do(W=w)
11 if∃xi, xj∈[K]s.t.|bP(xj|do(xi), do(w))−bP(xj|xi, do(w))|>γ
2then
12 Add bi-dirceted edge Xi← →Xjto graph G
13while There is a new pair that is tested do
14 Find a new pair (Z, X)s.t.Z∈An(Y)such that ZandYdon’t have a bi-directed edge
between them in GandX∈MUCT (GPa(Z),Bi(Z,G), Y)
15 #Test for the latent between the pair (Z, X)and update G.
16 SetXi:=Z, X j:=X
17 ifXj∈An(Xi)swap them.
18 Find interventional data sets do(W=w)anddo(Xi=xi,W=w)fromIData s.t.
(Pa(Xi)∪Pa(Xj)\ {Xi})⊆WandXi&Xj/∈W
19 Getmax(0 , B−C)new samples for do(W=w)
20 if∃xi, xj∈[K]s.t.|bP(xj|do(xi), do(w))−bP(xj|xi, do(w))|>γ
2then
21 Add bi-directed edge Xi← →Xjto graph G
22Learn the set of POMISs IGfrom the graph GUsing Algorithm 1 in [5].
23Run UCB algorithm over the arm set A={Ω(I)| ∀I∈ IG}.
A.13 Full Version of Algorithm 4 and Proof of Theorem 5.1:
Algorithm 4 or its full version (Algorithm 6) starts by learning the transitive closure of the graph,
denoted as Gtc. This is because Gtccan give us An(Y), and every possible POMIS is a subset of
An(Y). Thus, we can restrict ourselves to ancestors of the read node. From Lemma 4.4, we can
learn the transitive closure Gtcwith a probability of at least 1−δwith a maximum of KAn +B
interventional samples by setting δ1=δ
2nandδ2=δ
2. Then, Algorithm 1 learns the true transitive
closure with a probability of at least 1−δ. (We have A= max
8
ϵ2,8
γ2
log2nK2
δ1andB=
8
ϵ2log2nK2
δ2as in line 2 of Algorithm 1). Thus, the total interventional samples for this step turn out
to be Knmax
8
ϵ2,8
γ2
log4n2K2
δ+8
ϵ2log4nK2
δ.
The next step is to learn the complete observable graph induced on the reward node and its ancestors
and then learn/detect only a subset of latent confounders which are characterized to be necessary and
sufficient to learn the true set of POMISs (Theorem 3.1). Although this step saves us interventional
samples compared to the full discovery Algorithm 3, which learns/detects latents between all pairs of
variables, the exact saving will depend on the structure of the underlying causal graph. For the regret
upper bound, we can use the results from Theorem 4.2 to bound the number of interventional samples
for learning the true POMIS set from the ancestors of the reward node. This implies that given the
true set of ancestors of the reward An(Y), we can learn the true POMIS set with a probability of
at least 1−δusing 8αdmax
KAAn(Y)+B
log An(Y)
interventions, where AandBare
given by line 2 of Algorithm 1, and Cis given by line 3 of Algorithm 3 by setting α=2dmaxlog (4
δ+2)
logAn(Y),
δ1=δ
64αdmaxAn(Y)logAn(Y), and δ2=δ3=δ4=δ
64αdmaxlogAn(Y).
26The last phase is just running the UCB algorithm over the set of all possibly optimal arms, i.e.,
A={Ω(I)| ∀I∈ IG}. This phase has a regret bound ofP
s∈{Ω(I)|∀I∈IG}∆do(s)
1 +logT
∆2
do(s)
[26]. Now combining all the results we have the following:
Algorithm 4 learns the true set of POMISs IGwith probability at least 1−δ−δ= 1−2δ, and under
the good event Ethat it learns POMISs correctly, the cumulative regret is bounded as follows:
Rt≤Knmax8
ϵ2,8
γ2
log4n2K2
δ+8
ϵ2log4nK2
δ
(59)
+ 8αdmax
KAAn(Y)+ max( B, C)
log An(Y)
+X
s∈{Ω(I)|∀I∈IG}∆do(s)
1 +logT
∆2
do(s)
,
where AandBare given by line 2 of Algorithm 1, and Cis given by line 3 of Algorithm 3 by setting
α=2dmaxlog (4
δ+2)
logAn(Y),δ1=δ
64αdmaxAn(Y)logAn(Y)andδ2=δ3=δ4=δ
64αdmaxlogAn(Y). This
completes the proof of the Theorem 5.1.
A.14 Comparison with SCM-based Approximate Allocation Matching Algorithm from [6]:
Our proposed algorithm, Algorithm 4, consists of two phases. The first phase uses interventional
samples to learn the set of POMISs, and the second phase uses the UCB algorithm to find the
optimal arm among the POMISs. Note that in the second phase, we use the UCB algorithm, which
assumes that arms are independent of one another. However, in the case of causal bandits, the arms
are correlated, and every intervention provides some information about other interventions. The
UCB algorithm cannot exploit this information. However, [ 6] proposes an algorithm to exploit the
correlations between arms in a causal bandit setting, which accelerates the learning compared to the
simple UCB algorithm. The main limitation is that the algorithm requires access to the true causal
graph. Therefore, it is possible that we can use an alternative approach where instead of POMISs,
we learn the entire causal graph and then use the SCM-based Approximate Allocation Matching
Algorithm from [ 6] for our problem setup. This approach can also allow us to reuse the intervention
samples from the discovery phase to accelerate the next phase. However, the main drawback of this
approach is that the algorithm proposed in [ 6] faces issues when it comes to larger, densely connected
causal graphs. We explain the reasoning of our claim by reviewing some concepts from the paper [ 6].
In order to exploit the correlations between different arms in a causal bandit setting, the authors
in [6] rely on response variable formulation for causal effects, which we discuss very briefly
here. For any causal graph G, the observed variables Vcan be uniquely partitioned into c-
components C1, . . . ,Cnc(G). Consider a set of response variables M, which we also partition
intoM1, . . . ,Mnc(G), where each Mjcontains response variables corresponding to every observed
variable in the corresponding c-component Cj. Within a c-component, the response variables of all
the observed variables are correlated since they are connected by bidirected edges. However, across
two c-components, the response variables are independent. As a result, P(m) =Qnc(G)
j=1P(mj).
By concatenating P(mj)for each mj∈Ω(Mj), one can construct a vector pj∈∆(|Ω(Mj)|)
where ∆(|Ω(Mj)|)denotes the probability simplex over the discrete domain Ω(Mj). Let the
parent set of a c-component CjbePaCj:= S
i:Vi∈CjPai
\Cj. When taking intervention
do(S=s), the values of Cj∩Sare set to s[Cj], which denotes the values of Cj∩Sthat
are consistent with s.Mjpicks the mapping functions from PaitoVifor all Vi∈Cj. By
marking configurations in BG,s[Cj](Cj,paCj)⊆Ω(Mj)with 1 and 0, one constructs a vector
bG,s[Cj](Cj,paCj)∈ {0,1}|Ω(Mj)|such that:
Ps(v) =nc(G)Y
j=1P 
Mj∈BG,s[Cj](Cj,paCj)
=nc(G)Y
j=1b⊤
G,s[Cj](Cj,paCj)pj. (60)
The equation 60 is very useful since it enables us to exploit the correlations between different
interventions in the causal bandit setting. This is because every interventional distribution can be
27written as a deterministic linear function of the response variable distribution. Thus, it is possible
that using the response variable decomposition, we can reuse the samples from discovery into the
next phase and accelerate learning of the optimal arm. However, we need to discuss the scalability
of this approach. Note that every variable in the SCM can take values from the set [K], and in
total, there could be Kdifferent realizations for Vjfor every realization of its parents Pa(Vj).
As a result, there are a total of KK|Pa(Vj)|possible mappings from Pa(Vj)toVj. Also, note that
within a c-component, the response variables for every observed variable are correlated. This
implies that for every component Cj, the corresponding response variable Mjhas the domain
|Ω(Mj)|=Q
Vi∈CjKK|Pa(Vi)|. Thus, every vector pjwill have a total ofQ
Vi∈CjKK|Pa(Vi)|
components. Although the response variable decomposition is useful for smaller and sparse causal
graphs, the scaling for the length of vectors pjis clearly exponential, making the use of response
variable decomposition infeasible for larger or denser causal graphs. All in all, there are correlations
between different arms in causal bandits, but it is not clear how to exploit them effectively, especially
for larger and denser causal graphs, which is still an open problem.
A.15 Experimental Compute Resources and Runtime
We ran our experiments on a server equipped with the AMD Ryzen Threadripper PRO 5995WX
CPU, which has 64 cores and 128 threads, with a base clock speed of 2.7 GHz and a maximum boost
clock speed of 4.5 GHz, along with 128 GB of RAM. The total runtime for the experimental plots in
Figures 2 and 3 is around 2 hours. For the experimental plots in Figure 4, the total runtime is around
2 hours for each subplot since we run the full algorithm for multiple randomly sampled graphs.
A.16 Broader Impacts of our Work
This paper presents work with the goal of advancing the field of Machine Learning. Since the causal
bandit framework can be used to model real-life decision-making scenarios, there are some potential
societal consequences of our work. The possibility of biased or incomplete understanding of causal
relationships could lead to misguided decision-making or policy recommendations in real-world
situations. Thus, extra care and consideration of ethical boundaries regarding actions/interventions
are needed while applying our proposed methodology to practical problems.
28NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Our abstract and introduction clearly reflect the paper’s contributions, and we
provide a list of main contributions at the end of the introduction as well.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Our paper clearly discusses all the limitations and assumptions in sections 2
and 4.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
29Answer: [Yes]
Justification: All the theorems and lemmas in our paper are properly numbered, and formal
proofs are provided in the supplementary material.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We provide detailed explanation of our experiments in section 6 and also
provide the code with instructions to reproduce the results.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
30Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We have uploaded the code along with the instructions to reproduce the results
in our experiments section.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Question: Does the paper specify all the training and test details (e.g., data splits,
hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand
the results?
Answer: [Yes]
Justification: We provide all the details about our experimental setting in section 6.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We plot the error bars as part of the experimental results in section 6 and also
mention the method used to calculate them.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
31•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We provide all the information on computer resources and runtime for our
experiments in section A.15.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have looked at the NeurIPS code of ethics, and we believe there are no
potential harms caused by the research or potential future harmful consequences for our
work.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: We discuss possible broader impacts of our work in section A.16.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
32•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We mainly conduct synthetic experiments in our work, and we don’t see any
risk of misuse of our code.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: Our experiments are purely synthetic in nature, and we don’t use any datasets
or models that require licenses.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
33•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: We don’t create new assets in our work, and the main contributions of our
work lie predominantly on the theoretical side.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: Our paper does not involve crowdsourcing or research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: We don’t require any approval since our work does not involve crowdsourcing
or research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
34•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
35