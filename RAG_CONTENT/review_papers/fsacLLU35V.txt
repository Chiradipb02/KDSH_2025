Published in Transactions on Machine Learning Research (8/2022)
The Fundamental Limits of Neural Networks for Interval
Certiﬁed Robustness
Matthew Mirman matthew.mirman@inf.ethz.ch
Maximilian Baader maximilian.baader@inf.ethz.ch
Martin Vechev martin.vechev@inf.ethz.ch
Department of Computer Science, ETH Zurich
Reviewed on OpenReview: https: // openreview. net/ forum? id= fsacLLU35V
Abstract
Interval analysis (or interval bound propagation, IBP) is a popular technique for verifying and
training provably robust deep neural networks, a fundamental challenge in the area of reliable
machine learning. However, despite substantial eﬀorts, progress on addressing this key chal-
lenge has stagnated, calling into question whether interval analysis is a viable path forward.
In this paper we present a fundamental result on the limitation of neural networks for interval
analyzable robust classiﬁcation. Our main theorem shows that non-invertible functions
can not be built such that interval analysis is precise everywhere. Given this, we derive a
paradox: while every dataset can be robustly classiﬁed, there are simple datasets that can
not be provably robustly classiﬁed with interval analysis.
1 Introduction
As neural networks are increasingly used in safety critical environments, ensuring their behavior with formal
veriﬁcation has become a highly active research direction (Liu et al., 2019a; Huang et al., 2020). Because
neural networks are often too large for complete veriﬁcation methods, incomplete analysis techniques are
frequently employed (Gehr et al., 2018) – these can scale to larger models though may fail to prove a property
that actually holds (as demonstrated in Fig. 1). Indeed, recent progress in constructing provable neural
networks has been achieved thanks to leveraging incomplete methods, and particularly interval (box) bound
propagation (Mirman et al., 2018). However, while many improvements to provable defenses have been
published (Gowal et al., 2018; Zhang et al., 2018; 2020; Xiao et al., 2019; Wong et al., 2018; Liu et al.,
2021; Boopathy et al., 2021; Shi et al., 2021; Xu et al., 2021) (most building on IBP), progress remains far
from satisfactory: the state-of-the-art certiﬁed robust accuracy is roughly 60% on CIFAR10 (Balunovic &
Vechev, 2020), compared to state-of-the-art standard accuracies of above 95%. The stagnation of progress in
constructing provably robust neural networks has led to a fundamental theoretical question:
Do eﬃciently veriﬁable neural networks exist?
(Fundamental Theoretical Question)
The ﬁrst result addressing this question was investigated by Baader et al. (2020) which proved an analog to the
universal approximation theorem (Cybenko, 1989; Hornik et al., 1989) for interval-analyzable networks. Wang
et al. (2020) further showed that two hidden layer networks could also be interval-analyzable approximators.
Anonymous (2022) also demonstrated that training with interval propagation converges with high probability.
While it is helpful to know that searching for networks which can be easily analyzed might not be futile,
these results do not explain, and even contradict the provable training gap that is observed in practice. A
preliminary negative result was shown by Wang et al. (2020): verifying the robustness of arbitrary neural
networks in general and thus translating arbitrary neural networks into interval-analyzable forms is NP-hard.
1Published in Transactions on Machine Learning Research (8/2022)
x0
02
−20
1f(x)1
−1−1
11
−11
−10
01
−1
(a) Network. The circles ( ) which represent ReLUs contain their biases.
−3−1 1 3
x−11f(x) (b) Network values f(x)forx∈[−4,4].
−11−11
(c) 1st aﬃne
−11−11 (d) 1st ReLU
−11−11 (e) 2nd aﬃne
−1 1−11 (f) 2nd ReLU
−1 1−11 (g) 3rd aﬃne
−1 1−11 (h) 3rd ReLU
Figure 1: An example of a neural network which is in fact robust, yet which interval arithmetic fails to prove
is robust. The three intervals L= [−3,−1](),M= [−1,1]() andR= [1,3]() are depicted using dashed
lines in Fig. 1b. The interval propagation through the network is shown using the rectangles. The concrete
values are shown by the dashed lines. After the 2nd aﬃne layer (Fig. 1e) the orange and green box overlap
while the orange lines do not overlap, demonstrating a loss of precision. The output Interval is [−1,1]for all
three input intervals L,MandR. In graphs (c) through (h) the vertical axis corresponds to the outputs of
the upper set of neurons in (a) and the horizontal axis corresponds to the outputs of the lower set of neurons.
In our work, we provide a strong negative answer, thus explaining the provable training gap: we demonstrate
that non-trivial datasets can not be classiﬁed by interval-provable networks.
Formally, given a neural network, or more generally any program, f:X →Y, the goal of veriﬁcation is
to algorithmically prove that fmaps an input spec (speciﬁcation), SI⊆X, to a subset of an output spec ,
SO⊆Y, where the spec(SI,SO)is a member of a spec-setS⊆P (X)×P(Y). Interval analysis in particular
replaces the basic operations of fwith interval arithmetic (Moore, 1966; Hickey et al., 2001), producing an
interval extension, f#:Intervals (X)→Intervals (Y), offsuch that every element of SIis mapped by fto
an element of f#(SI). As representing and computing intervals is eﬃcient, fis proven to meet the spec
(SI,SO)by proxy of proving f#(SI)⊆SO. Here we consider interval robustness classiﬁcation specs where
the input specs are closed intervals, and the output specs are either R>0orR<0.
Main contributions. In this paper, we present the ﬁrst proofs capturing key limitations (incompleteness)
of using ReLUbased neural networks to build robust classiﬁers that can be certiﬁed with interval analysis:
•Fundamental Imprecision of Interval Analysis (Theorem 4.10) : In this theorem we identify
for the ﬁrst time the highly general conditions under which interval analysis looses precision.
Speciﬁcally, we show that non-invertible functions can not be built using aﬃne transformations
andReLUs such that over-approximation using interval analysis is precise everywhere. To make
proving this theorem possible, we need to keep track of a strict interior relationship even when the
dimension of the network increases in irrelevant ways. To do this, we develop the relative subset
relation (Deﬁnition 4.2) and prove various useful properties in Section 4.1.
•Impossibility of Interval-Provably Robust Classiﬁers (Section 5) : Here we show that classi-
ﬁers in particular can not be built such that they are provable robust with interval analysis in two key
ways. We ﬁrst demonstrate in Corollary 5.2 how this theorem can be immediately applied to show that
it is impossible to construct a feed-forward ReLU-neural network of any shape (e.g., residual, convo-
lutional, dense, fully-connected) that is perfectly provably robust (Deﬁnition 5.1) with interval analysis
for even an unrealistically simple dataset with only three points. Informally, perfecthere describes the
property that the spec-set is maximal in that it includes as many validrobustness specs describing the
dataset as possible without including any input specs which might render the spec-set unsatisﬁable,
including those that touch the shared border between two points. We then show in Theorem 5.8 that
even when the requirement for perfect provability is relaxed to regions that are distant from each
other (α-interval provable with α<1as in Deﬁnition 5.3), there are datasets with O(α−1)points
that can not be provably robustly classiﬁed with one-hidden layer networks using interval analysis.
2Published in Transactions on Machine Learning Research (8/2022)
•Possibility of Interval-Agnostic Robust Networks (Proposition 5.10 and 5.11) : Here
we demonstrate the paradox that in both of the previous two cases, perfectly robust classiﬁers
(Deﬁnition 5.1) can always be constructed, even if they are not necessarily provably robust using
interval analysis. In the case of 1-d datasets, these can furthermore be constructed to be one-layer
deep. Together with Theorem 5.8 and Corollary 5.2 this implies that the restriction that a network
be analyzable with interval-arithmetic is severely limiting.
2 Problem Motivation
Studying the robustness of artiﬁcial neural networks has become an important area of research as they are
increasingly deployed in safety-critical applications such as self-driving cars (Bojarski et al., 2016). Szegedy
et al. (2013) ﬁrst demonstrated that neural networks classifying images can be fooled into misclassiﬁcation by
imperceptible pixel changes in an otherwise correctly classiﬁed image.
Many of these fooling techniques, known as adversarial attacks, have been developed (Carlini & Wagner,
2017; Goodfellow et al., 2015; Kurakin et al., 2016; Shaham et al., 2015; Croce & Hein, 2019b; Papernot
et al., 2016a; Wong et al., 2019b). To defend against these attack, methods strengthening models have been
proposed (Papernot et al., 2016b; Tramèr et al., 2017; Wong et al., 2019a; Stutz et al., 2020; Bastani et al.,
2016; Croce & Hein, 2020). A particular line of research aims to provide formalguarantees (i.e., verify) that
neural networks behave correctly (Katz et al., 2017; Singh et al., 2018; 2019; Boopathy et al., 2019; Liu et al.,
2019b; Wang et al., 2018; Balunovic et al., 2019; Zhang et al., 2021; Lin et al., 2021; Croce & Hein, 2019a;
Croce et al., 2018). As complete veriﬁcation of a neural network is NP-Hard (Katz et al., 2017), the majority
of modern techniques are incomplete and based on over-approximating the behavior of a network (Gehr
et al., 2018). While incomplete methods can be highly eﬃcient, a correct classiﬁcation of a network might
not be provably correct, as illustrated in Fig. 1. In fact, for naturally trained neural networks, only a small
percentage of non-attackable input images are veriﬁable.
To improve veriﬁcation rates, techniques to train networks amenable to veriﬁcation (Raghunathan et al., 2018;
Mirman et al., 2018; Wong & Kolter, 2018; Wong et al., 2018) have been developed. While this has been
an active area of research, the state-of-the-art developed by Balunovic & Vechev (2020) achieves a certiﬁed
robust accuracy of 60.5% on CIFAR10, which is low given that state-of-the-art standard accuracy is over 95%.
The recent plateau of progress in closing this gap has raised concerns on whether there are theoretical
limitations to neural network analysis (Salman et al., 2019). In this work, we prove fundamental limitations,
which help explain the signiﬁcant gap between certiﬁed robust accuracy, and standard accuracy. We focus on
interval analysis, as some of the most successful and widely used methods are based on this relaxation (Mirman
et al., 2018; Gowal et al., 2018).
3 Background
We now introduce key concepts and notation, a reference to which can be found in Appendix C.
3.1 General Notation
We begin with some general notation. For some positive natural k∈Nwe write [k]:={1,...,k}. Given sets
T1,...,Tkand a setY⊆T1×...×Tkwe writeY|ifor the restriction to the dimension i, orY|i:={yi:y∈Y}.
Many of our proofs require spaces with slightly richer structure than d-dimensional real vector spaces.
We will call these real binary-tree tensor-spaces, the class of which can be deﬁned inductively as
T={T1×T2:T1,T2∈T}∪{R}. Given a space S∈T, we can inductively deﬁne the set BSof closed, non-
empty, axis-aligned boxes over S: IfS=T1×T2forT1,T2∈TthenBS={B1×B2:B1∈BT1,B2∈BT2}
and ifS=RthenBS={[a,b]|a,b∈R∧a<b}orBS=I, the set of real intervals.
In cases where this richer tree structure is unnecessary, we consider Rd∈Tford∈N>1to be a real binary-tree
tensor space by assuming a canonical ordering: Rd:=R×Rd−1. We abuse notation and say Bdis speciﬁcally
thesetofclosed, non-empty, axis-alignedboxesonthe d-dimensionalrealvectorspace. Wenotethat BRd=Bd.
3Published in Transactions on Machine Learning Research (8/2022)
We write the box with center c∈Rdand radius r∈Rd
≥0asBr(c):={x:∀i∈[d].∃ξ∈[−1,1].xi=ci+ξri}.
We also writeB◦/epsilon1(x):={y∈Rd:||x−y||∞</epsilon1}forx∈Rdand/epsilon1∈R>0for an open box. For a given box
B∈BdletC(B)denote its center and R(B)denote its radius vector such that B=BR(B)(C(B)).
For any bounded and non-empty set C⊂SforS∈T, thel∞-hull, writtenH∞(C), is the smallest axis
aligned box containing C, which we formally deﬁne inductively: H∞(C):=H∞(C|1)×H∞(C|2)ifS=S1×S2
forS1,S2∈TandH∞(C):= [inf(C),sup(C)]ifS=R.
For any set Swe writeP(S)to mean the powerset of S. Iff:A→A/primeandS⊆Awe writef[S]orfP(S)to
mean{f(s):s∈S}, but sometimes abuse notation and write f(S):=f[S]to avoid clutter. Similarly, we
also occasionally write f−1◦g−1even when fandgare non invertible to mean (g◦f)−1.
3.2 Robustness and Interval Certiﬁcation (IBP)
Supposef:Rd→Ris some function (i.e., neural network). We say that this network assigns a label
l∈{− 1,1}to a pointx∈Rdifsignf(x) =l. In our case, we discuss l∞-adversarial region speciﬁcations. In
this case, we say that fis/epsilon1-robust around xwithlabellif∀x/prime∈B/epsilon1(x).f(x/prime) =l.
The goal of robustness certiﬁcation is to provide a guarantee that a neural network is robust at some point.
However, an analysis not producing a proof of robustness at a point does not mean that the neural network is
non-robust at that point. This leads to eﬃcient methods in terms of over-approximation , originally described
asabstract-interpretation (Cousot & Cousot, 1977) and applied to neural networks by Gehr et al. (2018).
Interval Analysis In this paper, we focus on the Interval (or Box) relaxation, and in particular, Interval
Bound Propagation (IBP) (Gowal et al., 2018), also known as interval analysis, or the Interval domain for
abstract-interpretation. An interval, B∈Bd, can either be represented as a center c∈Rdand radiusr∈Rd
≥0
as before, or as a lower-bound and upper bound, ιl,ιu∈Rdrespectively such that for each dimension j∈[d],
we haveιl,j≤ιu,j. The two representations are related as follows: ιl=c−randιu=c+r, orc=1
2(ιl+ιu)
andr=1
2(ιu−ιl).
Analyzing Neural Networks The application of IBP to neural networks with ReLU-activations is
straightforward. In this paper, we consider (feed forward) neural networks deﬁned inductively as follows:
Deﬁnition 3.1 .Aσ-(neural) network with σ-activations is a program, f, inductively deﬁned by the grammar
f::=f◦f|/angbracketleftf,f/angbracketright|Sum|Dup|κ|κ/prime·|σforκ,κ/prime∈Randκ/prime/negationslash= 0, and interpreted as a function with domain I∈T
and codomain O∈Tas follows:
•Sequential Computation: Givenf=g1◦g2andg1,g2are interpreted as functions g1:B→Oand
g2:I→B, we sayf:I→Ocomputesf(x) =g1(g2(x)).
•Parallel: Givenf=/angbracketleftg1,g2/angbracketrightandg1,g2are interpreted as functions g1:I1→O1andg2:I2→O2and we
sayf:I1×I2→O1×O2computesf(x) = (g1(x1),g2(x2)).
•Addition: Givenf=Sumwe sayf:R2→Rcomputesf(x) =x1+x2.
•Duplication: Givenf=Dup, we sayf:I→I2computesf(x) = (x,x).
•Constant: Givenf=κwe sayf:R→Rcomputesf(x) =κ.
•Multiplication by a Constant: Givenf=κ·we sayf:R→Rcomputesf(x) =κ·x.
•Activation: Givenf=σwe sayf:R→Rcomputesf(x) =σ(x).
We note that duplication and addition are the only relational operations here.
For the purposes of exploring its limits, we view IBP as a method that implicitly constructs a transformed
function which acts on intervals. We describe this transformed function inductively as well:
Deﬁnition 3.2 (Interval Analysis). Theinterval transformation ,f#, of a ReLU-networkfis as follows:
4Published in Transactions on Machine Learning Research (8/2022)
(a)A /negationslash⊏B (b)A⊏B (c)A⊏B (d)A /negationslash⊏B
Figure 2: Visualization of the relative interior relation. Green ( ) boxes are Aand purple ( ) boxes are B.
•Sequential Computation: Iff=g1◦g2thenf#(B):=g#
1(g#
2(B)).
•Parallel: Iff=/angbracketleftg1,g2/angbracketrightthenf#(B):=g#
1(B|1)×g#
2(B|2).
•Addition: Iff=Sumthenf#(B):={a+b:a∈B|1∧b∈B|2}.
•Duplication: Iff=Dupthenf#(B):=B×B.
•Constant: Iff=κforκ∈Rthenf#(B):={κ}.
•Multiplication by a Constant: Iff=κ·for some non-zero κ∈R, thenf#(B):={κ·x:x∈B}.
•Activation: Iff= ReLU, thenf#(B):={ReLU(x):x∈B}.
Proposition 3.3 .The interval transformer, f#, over-approximates f, meaning that f[B]⊆f#(B).
4 Fundamental Imprecision of Interval Analysis
Here we show our main result, that no neural network can be perfectly provably robust with interval analysis
for simple functions. We ﬁrst introduce the necessary machinery (in particular, the concept of relative interior
outlined in Fig. 2) and lemmas that allow us to show a relationship between whether the network represents
an invertible function, and where there is an approximation error.
Counterintuitively, rather than being able to show that the transformed network is imprecise for a speciﬁc
input box (i.e., that for a speciﬁc box B, we knowf[B](f#(B)), we must, for any input box Bcontaining
non-invertible points on its surface, ﬁndan input box, A, that is a strict subset of B(via a particular notion
of strict deﬁned below), such that f[B]⊆f#(A). The fact that Ais a strict subset of the relative interior of
Bimplies that interval analysis is imprecise enough on the network such that it can not be used to prove
desired properties of B(such thatfis perfectly robust for B). It is however crucial that Anot be required
to betoostrict a subset of B. One might be tempted to ﬁnd subsets of the topological interior of B. This
however leads to signiﬁcant technical issues: we need to have a notion of strict subset that applies even when
some of the neurons in the network are unused (and zero). One can imagine the set representing the possible
activations of those neurons as a lower dimensional surface embedded in a higher dimensional space, as in
the case of Fig. 2(c) and (d). In this case, the interior of Bwould be empty, even though we might have
identiﬁed a subset of it that induces imprecision.
4.1 The Relative Subset Relation
We begin by formalizing the intuitive concept from Fig. 2 using the known notion of relative interior , and
demonstrating some useful lemmas related to it. First, recall for a set S⊆Rdthat the aﬃne hull ofS,
written aﬀ(S)is the smallest linear-subspace of Rdthat contains S.
Deﬁnition 4.1 .We recall the standard deﬁnition of relative interior :
relint(S):={x∈S:∃/epsilon1>0.B◦/epsilon1(x)∩aﬀ(S)⊆S}.
5Published in Transactions on Machine Learning Research (8/2022)
We note that if S∈Bd, we can restate the relative interior as relint (S) ={x∈S:∀i∈[d].xi∈S|◦
i∪{C(S)i}},
whereS|◦
iis the interior of S’s restriction to dimension i.
Deﬁnition 4.2 (Relative Subset). Ais arelative subset ofB, writtenA@B, if and only if A⊆relint(B).
We note that if A,B∈Bd, we can rephrase A@Bas follows:A⊆Band for each dimension, i, whereB|◦
iis
not empty, A|i⊆B|◦
ior more concisely, ∀i∈[d].(B|◦
i/negationslash=∅=⇒A|i⊆B|◦
i).In particular, in one dimension,
for real intervals [a,b]and[a/prime,b/prime]we have [a,b]@[a/prime,b/prime]if and only if a/prime<a≤b<b/primeora=a/prime=b/prime=b.
LetA,A/prime,B,B/prime,Cbe bounded and non-empty subsets of Rdin the following lemmas (the proofs of which
can be found in Appendix B.1):
Lemma 4.3 (Respects Projection). A@BimpliesA|i@B|i.
Lemma 4.4 (Respects Cartesian Product). A@BandA/prime@B/primeimpliesA×A/prime@B×B/prime.
Lemma 4.5 (Downward Union). A@CandB@CimpliesA∪B@C.
Lemma 4.6 (Downward Hull). C∈BdandA@CimpliesH∞(A)@C.
The following two lemmas are trivial and we frequently use them without mention:
Lemma 4.7 (Singleton Reﬂexivity). {a}@{a}.
Lemma 4.8 (Center-Singleton is Always a Relative Subset). A∈Bdimplies{C(A)}@A.
It is important to note that some simple related properties counterintuitively do not always hold. Namely, if
A@BandB⊆Cit is not always the case that A@C. Furthermore, if A@BandA/prime@B/primeit is not always
the case thatH∞(A∪A/prime)@H∞(B∪B/prime).
4.2 Inversion With Respect to The Relative Subset Relation
Here we demonstrate that neural networks can loosely invert sets with respect to the relative subset relation.
More formally, for any neural network fwith ReLU-activations, one can essentially always ﬁnd a strict subset,
X/primeof the relative interior of a box Xthat the neural network maps to a superset of a speciﬁed subset Yof
the relative interior of the l∞-hull off(X).
Lemma 4.9 (Concrete Relative Inversion). Supposefis a feed-forward network with ReLU-activations and
Y,X/prime∈BdandXis compact and non-empty. Then
Y@H∞(f(X)) =⇒ ∃X/prime@H∞(X).Y⊆f#(X/prime).
Proof Overview. (Full Proof in Appendix B.2) The proof is by structural induction on the construction
off. We use the lemma itself as the induction hypothesis. Below we outline three key cases of the structural
induction: sequential computations, relational parallel computations, and ReLU:
Case:f=g◦h. (Sequential Computation)
Subproof. By deﬁnition, Y@H∞(g◦h(X)). Thus, there is some H@H∞(h(X))such thatY⊆g#(H)by
the induction hypothesis on g. Applying the induction hypothesis again with the network h, we
get a setX/prime@H∞(X)such thatH⊆h#(X/prime). Thus,Y⊆g#(H)⊆g#◦h#(X/prime) =f#(X/prime)./triangleleft
Case:f=Dup. (Duplication)
Subproof. We knowY|1@H∞(X)andY|2@H∞(X)by Lemma 4.3. By Lemma 4.5 and Lemma 4.6, we
knowX/prime:=H∞(Y|1∪Y|2)is a relative subset of H∞(X), and thusY⊆X/prime×X/prime=f#(X/prime)./triangleleft
Case:f=/angbracketleftg1,g2/angbracketright. (Parallel)
6Published in Transactions on Machine Learning Research (8/2022)
Figure 3: A visualization of the claims of
Theorem 4.10. The neural network, fclassiﬁes
three inputs x=−2,0,2to respective labels
y=−1,1,−1as in Corollary 5.2. Here, y= 0
is the non-invertability and f−1(y) ={−1,1}.
These two points mapping to y, which constitute
N⊆f−1(y), are marked in red ( ). Thel∞-
hull,H∞(N), is marked in green ( ). The
perfect approximation of fonH∞(N)(i.e.,
{(v,f(v)):v∈N}) is marked in blue ( ). We
can see that the interval approximation of the
relative interior box M@H∞(N)looses precision
by looking at the orange region ( ).
−2−1 1 2
−11
f#(M)
H∞(N)M
fxy
Subproof. We know both that Y|1@H∞(g1(X|1))andY|2@H∞(g2(X|2)), so we can apply the induction
hypothesis twice to produce L@H∞(X|1)andR@H∞(X|2)such thatY|1⊆g#
1(L)and
Y|2⊆g#
2(R). We choose X/prime=L×R. By Lemma 4.4, we have X/prime@H∞(X). Then
Y⊆g#
1(X/prime|1)×g#
2(X/prime|2) =f#(X/prime). /triangleleft
Case:f= ReLU. (Activation)
Subproof. We know that f:R→R, which simpliﬁes the proof. In this case, l∞-hull off(X)must either be a
subset of R≥0so eitherYis the singleton set containing zero, or a subset of R>0. In the ﬁrst case,
we pickX/primeto be an easy-to-pick (the singleton set containing center as in Lemma 4.8) relative
subset of the hull of X. Otherwise, we can pick Yitself, since ReLU(Y) =Y⊆H∞(X)./triangleleft
Case:f=c·forc/negationslash= 0. (Mult. by a Constant)
Subproof. LetX/prime=B|c−1|R(Y)(c−1C(Y)). Then clearly, Y⊆f(X/prime). Because we know that d= 1we can write
xl=infX,xu=supX,yl=infYandyu=supY. We note that xl=C(H∞(X))−R(H∞(X)).
Similar expressions can be derived for xu,ylandyu. Supposing c>0(the other case is analogous)
andxl<xu(the proof is similar when equal), we have cxl<yl≤yu<cxubyY@H∞(f(X)).
Then we know xl<|c−1|yl≤|c−1|yu<xu, and thusX/prime@H∞(X). /triangleleft
(Further Cases in Appendix B.2)
4.3 Impossibility for Non-Invertibility
We now prove our central result, that non-invertible neural networks necessarily induce approximation
imprecision. Essentially, as visualized in Fig. 3, we show that there is a box, Mwhich is a relative subset (i.e.,
usually very strict subset) of the l∞-hull of any region for which the network is entirely not injective, such
that analyzing the network with Mincludes any of the non-invertible points in the inferred approximation.
The key idea is that while there may be non-invertibilities on the boundary, Mdoes not include these, as
it is a relative subset. Thus, we can use this theorem to infer areas where analyzing the network produces
approximations that include points that are not in the concrete, or true, set of possible network outputs.
Theorem 4.10 (Fundamental Imprecision of Interval). Supposef:S→TwithS,T∈Tis aReLU-network
andy∈RmandN⊆f−1(y)is compact and non-empty. Then assuming M∈BS:
∃M@H∞(N).y∈f#(M).
Proof Overview. (Full Proof in Appendix B.2) Again, the proof is by structural induction on the
construction of f, using the theorem itself as the induction hypothesis. Below we outline three key cases:
sequential computations, relational parallel computations, and addition:
7Published in Transactions on Machine Learning Research (8/2022)
Case:f=g◦h (Sequential Computation)
Subproof. We know that N⊆h−1◦g−1(y), and thus can use the induction hypothesis on hto produce
M/prime@H∞(h(N))such thaty∈g#(M/prime). By Lemma 4.9, we know that there is some M@H∞(N)
such thatM/prime⊆h#(M)and thus that y∈g#◦h#(M). /triangleleft
Case:f=Dup. (Duplication)
Subproof.N={y1}becauseN⊆{y1}∩{y2}. By singleton reﬂexivity, N@H∞(N). Thus,y∈f#(N)./triangleleft
Case:f=/angbracketleftg1,g2/angbracketright. (Parallel)
Subproof. First we know N|1⊆g−1
1(y1)andN|2⊆g−1
2(y2)by projection and that N|1andN|2are
still compact and non-empty. Thus, by the induction hypothesis twice we see that there are
boxesM1@H∞(N|1)andM2@H∞(N|2)such thaty1∈g#
1(M1)andy2∈g#
2(M2). Then
M1×M2@H∞(N)by Lemma 4.4. Then y1∈f#(M1×M2)|1andy2∈f#(M1×M2)|2by
soundness. Thus, there is some box M@H∞(N)such thaty∈f#(M). /triangleleft
Case:f=Sum. (Addition)
Subproof. Becausef:R2→R, we knowf−1(y) ={(a,y−a):a∈R}. We can pick M={C(H∞(N))}and
demonstrate that M@H∞(N)and thaty∈f#(M). /triangleleft
Case:f= ReLU. (Activation)
Subproof. In this case, y=ReLU (x)can either be zero or greater than zero. If y>0, thenN={y}by the
deﬁnition of ReLU, and thus that{y}@H∞(N)andy∈f#({y}). Otherwise, y= 0and thus
N= (−∞,0]. We thus know{C(H∞(N))}@H∞(N)and ﬁnally y∈f#({C(H∞(N))})./triangleleft
(Further Cases in Appendix B.2)
5 The Paradox of Interval Provable Network Construction
In this section we ﬁrst demonstrate a variety of unexpectedly and problematically simple scenarios (although
Theorem 4.10 implies many more) that if appear in a dataset, imply the impossibility of constructing an
interval-provably robust network. We then show the paradox that in each of these cases, and further for every
dataset, it is possible to build a perfectly robust classiﬁer without consideration of interval analysis.
5.1 Impossibility of Perfect Provable Robustness of Unconstrained Networks
Here we demonstrate an immediate application of Theorem 4.10: there are simple datasets that no neural
network can perfectly (as deﬁned below), and provably robustly with interval classify.
Deﬁnition 5.1 .We say that a neural network f:Rd→Ris aperfectlyν-(provable) robust classiﬁer with
ν∈(0,1]for pointsx1,...,xn∈Rdand labels l1,...,ln∈{− 1,1}if givenδ=1
2mini/negationslash=j||xi−xj||∞then
∀/epsilon1<νδ.∀i∈[n].f(B/epsilon1(xi))li>0.If it isprovable then we also have that ∀i∈[n].f#(B/epsilon1(xi))li>0.
We note that the speciﬁcation-set induced by this deﬁnition is perfect as described in the introduction, in that
it includes every valid robustness speciﬁcation describing the dataset (x1,l1),..., (xn,ln): every robustness
speciﬁcation (SI,i,SO,i)wherexi∈SI,iandli∈SO,iandSI,i(Bδ(xi)is part of the speciﬁcation-set, but
not robustness speciﬁcations for diﬀerent (and possibly diﬀerently classiﬁed) points that would be touching.
Corollary 5.2 (Perfectly Provably Robust Classiﬁers are Impossible). There is no feed forward ReLU-network
that is a perfectly 1-provably robust classiﬁer for the dataset D={(−2,−1),(0,1),(2,−1)}.
Proof. Supposef:R→Ris a perfectly 1-provably classiﬁer for this dataset. Then by continuity we
know that f(−1) =f(1) = 0, and thus that{−1,1}⊆f−1(0)(which is a compact non-empty set). Then
by application of Theorem 4.10, there is some set M@H∞({−1,1})such that 0∈f#(M). Rephrased, this
8Published in Transactions on Machine Learning Research (8/2022)
(a)ReLU(−x)
 (b)−ReLU(−x)
 (c)ReLU( x)
 (d)−ReLU( x)
Figure 4: The orientations of neurons captured by the sets L+,L−,R+, andR−.
means that there are a,b∈(−1,1)such that 0∈f#([a,b]). This contradicts the deﬁnition of a provably
1-provable robust classiﬁer however.
5.2 Impossibility of Imperfect Provable Robustness for One-Layer Networks
In this section we show a impossibility result for the case where the robust regions around inputs in the dataset
do not overlap one another, and are thus imperfectly robust. To do this, we focus on single layer neural
networks, as prior work shows possibility results here for deeper networks (Baader et al., 2020). Speciﬁcally,
we present an upper-bound on the number of points that can be proven to be robustly classiﬁed with interval
for a single-layer network. We do this by constructing a worst-case dataset, which we call ﬂips. We begin by
formalizing this dataset, and the notion of robust and provable robustness for a classiﬁer on this dataset.
Deﬁnition 5.3 .We say:
•Ad-ﬂipis a point ˆxi∈Rdwith ˆxi,1:= 2iandˆxi,j= 0withlabel ˆli:= (−1)i. Ifdis unspeciﬁed, it is
taken to mean a 1-ﬂip.
•f:R→Ris aclassiﬁer for kﬂipsif∀i∈[k].f(ˆxi) =ˆli.
•F:B→P(R)is anα-classiﬁer for kﬂipsif∀i∈[k].∀y∈F([ˆxi−α,ˆxi+α]).signy=ˆli∧F({ˆxi}) ={ˆli}.
•IffP(the perfect transformation) is an α-classiﬁer for kﬂips, we say fis anα-robust classiﬁer forkﬂips.
•Iff#(the interval transformation from Deﬁnition 3.2) is an α-classiﬁer for kﬂips, then we say that fis
aprovablyα-robust classiﬁer forkﬂips.
We now specify the notion of single-layer network for which we demonstrate bounds:
Deﬁnition5.4 .Asingle-layer σ-network,f:R→R, withn-neurons andσ-activations is a function with pre-
activation weights ,N∈Rn,pre-activation bias ,b∈Rn,post-activation weights ,M∈Rn, andpost-activation
bias,d∈R(the weights and biases are known as parameters ), such that f(x) =M·σ(Nx+b) +d.
We note that while Deﬁnition 3.2 deﬁnes an ordering of addition, the above deﬁnition does not. While
concrete-addition is associative, this does not necessarily hold for abstract addition. However, thankfully, for
the interval transformation, it is, and the bounds we demonstrate apply to any ordering of the operations.
Deﬁnition 5.5 .Given a single-layer ReLU-network,fwithnneurons and pre/post-activation weights N,M,
the absolute and standard imprecision-contributions (respectively) of fatxare:
AD,S(x):=/summationdisplay
Nix+bi≥0∧Mi∈S∧Ni∈D|MiNi|,
andID,S(x):=/summationdisplay
Nix+bi≥0∧Mi∈S∧Ni∈DMiNi
whereDcan be the set L:=R≤0, the setR:=R≥0orRandScan be +:=R≥0, the set−:=R≤0orR.
Intuitively, L+,L−,R+,R−correspond to the orientations that a neuron can take, as visualized in Fig. 4. L
(resp.R) results in contributions from neurons that activate as the argument xof the imprecision-contribution
function decreases (resp. increases). Note that f/prime(x) =IR,R(x)if the derivative of fis deﬁned at x.
9Published in Transactions on Machine Learning Research (8/2022)
Lemma 5.6 (End-Neuron Imprecision-Bound). For allκ≥0and single-layer ReLU-networksfthat classify
k-ﬂips fork=⌈κ⌉+ 5, we haveκ<max{AL,R(ˆx1),AR,R(ˆxk)}.
Proof Overview. We prove this by induction on c:=⌊κ⌋, using two simultaneous inductive invariants:
c≤AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆxk)−AL,+(ˆxk),
and
c≤AL,−(ˆx1)−AR,−(ˆx1) +AR,−(ˆxk−1)−AL,−(ˆxk−1).
This proof involves two key observations: (i) once imprecision-contribution in a direction has accumulated, it
will only be larger for points further in that direction, (ii) one must measure not just the accumulated growth
of the imprecision-contribution at the ends of the approximated data ( ˆx1andˆxk) in the out-wards directed
neurons, but the growth of the relativeimprecision-contribution excluding contribution from in-wards directed
neurons. We make these observations more precise in the full proof in the appendix.
(Full proof in Appendix A)
Before demonstrating the result for single layer networks, we require one further lemma, used to ﬁnd a speciﬁc
data-point with enough accumulated imprecision contribution to cause a violation:
Lemma 5.7 (Lower-Bound on Imprecision-Contribution). For anya≤1andk≥⌈2
a⌉+ 5and single-layer
ReLU-networkfthat classiﬁes kﬂips, there is some point j∈[k]such that
ˆlja−1(f(ˆxj+a) +f(ˆxj−a))
<AR,R(ˆxj) +AR,R(ˆxj−a) +AL,R(ˆxj+a).
Proof Overview. By usingc:=2
awe can apply Lemma 5.6 (with κ=c), to show bounds for either the
left or right-most ˆx(i.e.,j= 1orj=k). For this point, we use the knowledge that the function is continuous,
piecewise diﬀerentiable, to ﬁnd points l∈[ˆxj−a,ˆxj]andu∈[ˆxj,ˆxj+a]such thatf(ˆxj)−f(ˆxj−a)
a<f/prime(l)and
f/prime(u)<f(ˆxj+a)−f(ˆxj)
aso we can use that
f/prime(l)−f/prime(u) =IR,R(l)−IR,R(u)
≤AL,R(ˆxj−a)−AR,R(ˆxj+a),
that−c,c<AR,R(ˆxj),and that
ˆlja−1(f(ˆxj+a) +f(ˆxj−a))
=−ˆlj(f(ˆxj)−f(ˆxj−a)
a−f(ˆxj+a)−f(ˆxj)
a) +ˆljc
to produce the ﬁnal upper bound.
(Full proof in Appendix A)
We are now ready to show our main theorem, an upper bound on the number of ﬂips that can be provably
robustly classiﬁed with a single layer network.
Theorem 5.8 (Single-Layer Limit). No single-layer ReLU-network can provably α-robustly classify ⌈2
α⌉+ 5
or more ﬂips for any α∈(0,1].
Proof Overview. The proof is by direct application of Lemma 5.7, and expansion of the deﬁnition of the
derivative. We demonstrate that for the ˆxfound by Lemma 5.7, the center of the box must be strictly closer
to 0 than its radius. (Full proof in Appendix A)
Corollary 5.9 (Single-Layer Limit in Multiple Dimensions). No single-layer ReLU-network can provably
α-robustly classify ⌈2
α⌉+ 5or mored-ﬂips for any α∈(0,1].
10Published in Transactions on Machine Learning Research (8/2022)
Proof. Supposef:Rd→Ris a single-layer network that can provably α-robustly classify t≥⌈2
α⌉+ 5
d-ﬂips for some α∈(0,1].Then we construct a function f/prime:R→Rmappingx/mapsto→f(Mx)whereM∈Rd×1is
deﬁned as having M1,1= 1andMi,1= 0fori>1. Thenf/primecan provably α-robustly classify tﬂips for some
αand is only 1-layer which contradicts Theorem 5.8.
5.3 One-layer strong interval-agnostic possibility
Proposition 5.10 (Single-Layer Perfectly Robust Classiﬁers Always Exist). Foranydataset ofnpoints
xi∈Rand labels li∈{− 1,1}there is a one-hidden-layer ReLU-network that perfectly robustly (but not
necessarily provably) classiﬁes it.
Proof. We present the construction explicitly. Let δ:= min{|xi−xj|:i/negationslash=j}in
f(y):=n/summationdisplay
i=1li/parenleftBig
ReLU/bracketleftbig1
δ(y−(xi−δ))/bracketrightbig
−ReLU/bracketleftbig2
δ(y−xi)/bracketrightbig
+ReLU/bracketleftbig1
δ(y−(xi+δ))/bracketrightbig/parenrightBig
One can check that this works by plugging in xj, although a full proof is by induction. While this is not
immediately of the form described for one-hidden layer networks, one can see easily how to algebraically
convert this into that form. Because we only care about robustness, and not interval provability of f, this is
suﬃcient.
Proposition 5.11 (Perfectly Robust Multi-Dimensional Classiﬁers Always Exist). Foranydataset of n
pointsxi∈Rdand labelsli∈{− 1,1}there is a ReLU-network that perfectly robustly (but not necessarily
provably) classiﬁes it.
Proof. Here we present a special case of the proof shown by Baader et al. (2020), and do not worry
about the number of layers or implicit projections involved. Again, we present the construction explicitly.
Letδ:= min{||xi−xj||∞:i/negationslash=j}. We deﬁne a neural indicator function Bumpkfor each dimension k∈[d]:
Bumpi,k(y):=ReLU/bracketleftbig1
δ(yk−(xi,k−δ))/bracketrightbig
−ReLU/bracketleftbig2
δ(yk−xi,k)/bracketrightbig
+ReLU/bracketleftbig1
δ(yk−(xi,k+δ))/bracketrightbig
We furthermore inductively deﬁne a neural implementation of a d-value minimum:
nmin 2(a,b):=1
2(ReLU(a+b)−ReLU(−a−b)−ReLU(a−b)−ReLU(−a+b))
nmind(a1,...,ad):=nmin 2(a1,nmind−1(a2,...,ad)) givend>2
Finally, we bring this all together in one function:
f(y):=n/summationdisplay
i=1linmind(Bumpi,1(y),...,Bumpi,d(y))
We can ﬁrst see that nmind(a1,...,ad) =mini∈[d]ai. Given that Bumpi,k(y)is in (0,1]if||y−xi||∞<δand
is0otherwise, we can see that signf(y) = signliif||y−xi||∞<δ.
11Published in Transactions on Machine Learning Research (8/2022)
6 Discussion and Future Work
While we limited the scope of our discussion to ReLU-activations, we note that our theorems extend trivially
to any monotone bounded activation. However, we observe that non-monotonic activations functions (such as
absolute value) do not admit the same forms of theorems. Our preliminary experiments however indicate
that substituting ReLUwith these activation functions does not result in easier training or provability.
This suggests that there are more general versions of the theorems presented here, in particular relating
the diﬃculty of program synthesis with the relational expressiveness of the relaxation used to verify the
speciﬁcation.
7 Conclusion
In this work we proved two theorems that demonstrate fundamental limitations on the expressiveness of
interval provable neural networks. We showed that no ReLU-network can perfectly provably classify simple
one-dimensional datasets containing only three points. This indicates a fundamental loss of precision whenever
ReLU-networks are analyzed using interval arithmetic, which can not be regained, no matter the network.
Further, we showed that a single hidden layer ReLU-network can not provably classify simple datasets even
without the requirement for perfectness, which is in stark contrast to classical universal approximation
theorems, where a single hidden layer is suﬃcient. This shows that the approximate capabilities of interval
provable networks are lower compared to standard neural networks.
References
Anonymous. On the convergence of certiﬁed robust training with interval bound propagation. In
Submitted to The Tenth International Conference on Learning Representations , 2022. URL https:
//openreview.net/forum?id=YeShU5mLfLt . under review.
Maximilian Baader, Matthew Mirman, and Martin Vechev. Universal approximation with certiﬁed networks.
ICLR, 2020.
Mislav Balunovic and Martin Vechev. Adversarial training and provable defenses: Bridging the gap. In ICLR,
2020.
Mislav Balunovic, Maximilian Baader, Gagandeep Singh, Timon Gehr, and Martin Vechev. Certifying
geometric robustness of neural networks. In NeurIPS , 2019.
Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios Vytiniotis, Aditya V. Nori, and Antonio
Criminisi. Measuring neural net robustness with constraints. In NeurIPS , 2016.
Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal,
Lawrence D. Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, and Karol Zieba.
End to end learning for self-driving cars. arXiv preprint arxiv:1604.07316 , 2016.
Akhilan Boopathy, Tsui-Wei Weng, Pin-Yu Chen, Sijia Liu, and Luca Daniel. Cnn-cert: An eﬃcient framework
for certifying robustness of convolutional neural networks. In AAAI, volume 33, 2019.
Akhilan Boopathy, Tsui-Wei Weng, Sijia Liu, Pin-Yu Chen, Gaoyuan Zhang, and Luca Daniel. Fast training
of provably robust neural networks by singleprop. arXiv preprint arXiv:2102.01208 , 2021.
Nicholas Carlini and David A. Wagner. Towards evaluating the robustness of neural networks. In Symposium
on Security and Privacy (SP) , 2017.
Patrick Cousot and Radhia Cousot. Abstract interpretation: a uniﬁed lattice model for static analysis of
programs by construction or approximation of ﬁxpoints. In Symposium on Principles of Programming
Languages (POPL) , 1977.
Francesco Croce and Matthias Hein. Provable robustness against all adversarial lp-perturbations for p>= 1.
InICLR, 2019a.
12Published in Transactions on Machine Learning Research (8/2022)
Francesco Croce and Matthias Hein. Sparse and imperceivable adversarial attacks. In Proceedings of the
IEEE/CVF International Conference on Computer Vision (ICCV) , 2019b.
Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse
parameter-free attacks. In ICML, 2020.
Francesco Croce, Maksym Andriushchenko, and Matthias Hein. Provable robustness of relu networks via
maximization of linear regions. arXiv preprint arXiv:1810.07481 , 2018.
George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals
and Systems (MCSS) , 1989.
Timon Gehr, Matthew Mirman, Petar Tsankov, Dana Drachsler Cohen, Martin Vechev, and Swarat Chaudhuri.
Ai2: Safety and robustness certiﬁcation of neural networks with abstract interpretation. In Symposium on
Security and Privacy (SP) , 2018.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
InICLR, 2015.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Uesato,
Timothy Mann, and Pushmeet Kohli. On the eﬀectiveness of interval bound propagation for training
veriﬁably robust models. arXiv preprint arXiv:1810.12715 , 2018.
Timothy Hickey, Qun Ju, and Maarten H Van Emden. Interval arithmetic: From principles to implementation.
Journal of the ACM (JACM) , 48(5):1038–1068, 2001.
Kurt Hornik, Maxwell B. Stinchcombe, and Halbert White. Multilayer feedforward networks are universal
approximators. Neural Networks , 1989.
Xiaowei Huang, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu,
and Xinping Yi. A survey of safety and trustworthiness of deep neural networks: Veriﬁcation, testing,
adversarial attack and defence, and interpretability. Computer Science Review , 37:100270, 2020.
Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An eﬃcient smt
solver for verifying deep neural networks. In International Conference on Computer Aided Veriﬁcation
(CAV), 2017.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial examples in the physical world. arXiv
preprint arxiv:1607.02533 , 2016.
Wan-Yi Lin, Fatemeh Sheikholeslami, Leslie Rice, J Zico Kolter, et al. Certiﬁed robustness against physically-
realizable patch attack via randomized cropping. In ICLR, 2021.
Changliu Liu, Tomer Arnon, Christopher Lazarus, Christopher Strong, Clark Barrett, and Mykel J
Kochenderfer. Algorithms for verifying deep neural networks. arXiv preprint arXiv:1903.06758 , 2019a.
Chen Liu, Ryota Tomioka, and Volkan Cevher. On certifying non-uniform bound against adversarial attacks.
InICML, 2019b.
Chen Liu, Mathieu Salzmann, and Sabine Süsstrunk. Training provably robust models by polyhedral envelope
regularization. IEEE Transactions on Neural Networks and Learning Systems , 2021.
Matthew Mirman, Timon Gehr, and Martin Vechev. Diﬀerentiable abstract interpretation for provably robust
neural networks. In ICML, 2018.
Ramon E Moore. Interval analysis . Prentice-Hall Englewood Cliﬀs, NJ, 1966.
NicolasPapernot, PatrickMcDaniel, andIanGoodfellow. Transferabilityinmachinelearning: fromphenomena
to black-box attacks using adversarial samples. arXiv preprint arXiv:1605.07277 , 2016a.
13Published in Transactions on Machine Learning Research (8/2022)
Nicolas Papernot, Patrick D. McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami. Distillation as a defense
to adversarial perturbations against deep neural networks. In IEEE Symposium on Security and Privacy
(SP), 2016b.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certiﬁed defenses against adversarial examples. In
ICLR, 2018.
Hadi Salman, Greg Yang, Huan Zhang, Cho-Jui Hsieh, and Pengchuan Zhang. A convex relaxation barrier to
tight robustness veriﬁcation of neural networks. In NeurIPS , 2019.
Uri Shaham, Yutaro Yamada, and Sahand Negahban. Understanding adversarial training: Increasing local
stability of neural nets through robust optimization. arXiv preprint arxiv:1511.05432 , 2015.
Zhouxing Shi, Yihan Wang, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh. Fast certiﬁed robust training with
short warmup. Advances in Neural Information Processing Systems , 2021.
Gagandeep Singh, Timon Gehr, Matthew Mirman, Markus Püschel, and Martin Vechev. Fast and eﬀective
robustness certiﬁcation. In NeurIPS , 2018.
Gagandeep Singh, Timon Gehr, Markus Püschel, and Martin Vechev. An abstract domain for certifying
neural networks. In POPL, 2019.
David Stutz, Matthias Hein, and Bernt Schiele. Conﬁdence-calibrated adversarial training: Generalizing to
unseen attacks. In ICML, 2020.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfellow, and
Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 , 2013.
Florian Tramèr, Alexey Kurakin, Nicolas Papernot, Ian Goodfellow, Dan Boneh, and Patrick McDaniel.
Ensemble adversarial training: Attacks and defenses. arXiv preprint arXiv:1705.07204 , 2017.
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Eﬃcient formal safety analysis
of neural networks. In NeurIPS , 2018.
Zi Wang, Aws Albarghouthi, Gautam Prakriya, and Somesh Jha. Interval universal approximation for neural
networks. In POPL, 2020.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer adversarial
polytope. 2018.
Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial defenses. In
NeurIPS , 2018.
Eric Wong, Leslie Rice, and J Zico Kolter. Fast is better than free: Revisiting adversarial training. In ICLR,
2019a.
Eric Wong, Frank Schmidt, and Zico Kolter. Wasserstein adversarial examples via projected sinkhorn
iterations. In ICML, 2019b.
Kai Xiao, Vincent Tjeng, Nur Muhammad Shaﬁullah, and Aleksander Madry. Training for faster adversarial
robustness veriﬁcation via inducing relu stability. In International Conference on Learning Representations ,
2019.
Kaidi Xu, Huan Zhang, Shiqi Wang, Yihan Wang, Suman Jana, Xue Lin, and Cho-Jui Hsieh. Fast and
Complete: Enabling complete neural network veriﬁcation with rapid and massively parallel incomplete
veriﬁers. In International Conference on Learning Representations , 2021. URL https://openreview.net/
forum?id=nVZtXBI6LNn .
Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui Hsieh, and Luca Daniel. Eﬃcient neural network
robustness certiﬁcation with general activation functions. In Advances in Neural Information Processing
Systems (NuerIPS) , dec 2018.
14Published in Transactions on Machine Learning Research (8/2022)
Huan Zhang, Hongge Chen, Chaowei Xiao, Sven Gowal, Robert Stanforth, Bo Li, Duane Boning, and Cho-Jui
Hsieh. Towards stable and eﬃcient training of veriﬁably robust neural networks. In ICLR, 2020.
Yuhao Zhang, Aws Albarghouthi, and Loris D’Antoni. Certiﬁed robustness to programmable transformations
in lstms. In EMNLP, 2021.
15Published in Transactions on Machine Learning Research (8/2022)
A Extended Proofs for Single Hidden Layer Network Results
Here we restate the theorems and show the full proofs for the results in Section 5.2.
Lemma 5.6 (End-Neuron Imprecision-Bound). For allκ≥0and single-layer ReLU-networksfthat classify
k-ﬂips fork=⌈κ⌉+ 5, we haveκ<max{AL,R(ˆx1),AR,R(ˆxk)}.
Proof of 5.6. We prove this by induction on c.
Induction Hypothesis: Givenc∈N∪{0,−1,−2}there is some even natural number k≤ReLU (c+ 2) + 2
such that for any single-layer ReLU-network,fthat classiﬁes kﬂips we have
c≤AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆxk)−AL,+(ˆxk),
andc≤AL,−(ˆx1)−AR,−(ˆx1) +AR,−(ˆxk−1)−AL,−(ˆxk−1).
Base Case: Supposec≤0.
Subproof. Pickk= 2. Then
AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆx2)−AL,+(ˆx2) = 0≥c,and
AL,−(ˆx1)−AR,−(ˆx1) +AR,−(ˆx2−1)−AL,−(ˆx2−1) = 0≥c. /triangleleft
Induction Step: Supposec>0, and the induction hypothesis holds for c−2.
Subproof. Thenthereissomeevennatural k/prime≤ReLU (c−2+2)+2 suchthatforanysingle-layer ReLU-network,
f, that is a classiﬁer for k/primeﬂips we have
c−2≤AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆxk/prime)−AL,+(ˆxk/prime),
andc−2≤AL,−(ˆx1)−AR,−(ˆx1) +AR,−(ˆxk/prime−1)−AL,−(ˆxk/prime−1).
Pickk=k/prime+ 2. Thenkis even, and k≤ReLU(c) + 4≤ReLU(c+ 2) + 2 sincec>0.
Letfbe any single-layer ReLU-network that classiﬁes kﬂips. Then falso classiﬁes k/primeﬂips.
We only show the positive bound, that c≤AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆxk)−AL,+(ˆxk).
The proof for the negative bound is analogous.
There must be some point l∈[ˆxk/prime,ˆxk/prime+1]such thatf/prime(l)≤−1by the mean value theorem (since
ReLU-networks are continuous) and because f(ˆxk/prime) = 1 =−f(ˆxk/prime+1).
Similarly, there must be some point u∈[ˆxk/prime+1,ˆxk]such that 1≤f/prime(u). Thus,
2≤f/prime(u)−f/prime(l)
≤IL,+(u) +IL,−(u) +IR,+(u) +IR,−(u)
−IL,+(l)−IL,−(l)−IR,+(l)−IR,−(l).
We knowIL,−(u)−IL,−(l)≤0andIR,−(u)−IR,−(l)≤0andIL,+(t) =−AL,+(t)and
IR,+(t) =AR,+(t)for anytso
2≤−AL,+(u) +AR,+(u)
+AL,+(l)−AR,+(l).
We also knowAL,S(t)increases as tdecreases andAR,S(t)increases as tincreases, so
2≤−AL,+(ˆxk) +AR,+(ˆxk)
+AL,+(ˆxk/prime)−AR,+(ˆxk/prime).
16Published in Transactions on Machine Learning Research (8/2022)
By combining with the positive inductive bound, we get
(c−2) + 2 =c≤AL,+(ˆx2)−AR,+(ˆx2) +AR,+(ˆxk/prime)−AL,+(ˆxk/prime)
−AL,+(ˆxk) +AR,+(ˆxk) +AL,+(ˆxk/prime)−AR,+(ˆxk/prime)
≤AL,+(ˆx2)−AR,+(ˆx2)−AL,+(ˆxk) +AR,+(ˆxk),
which proves the positive bound of the induction hypothesis for c. /triangleleft
Thus, by induction, we ﬁnd that there is some k≤⌈c⌉+ 5such that, after removing the negative terms and
increasing by swapping ˆx2with ˆx1andˆxk−1with ˆxk:
c+ 1≤AL,+(ˆx1) +AR,+(ˆxk),
andc+ 1≤AL,−(ˆx1) +AR,−(ˆxk).
Summing these equations together gives us:
2c+ 2≤AL,+(ˆx1) +AR,+(ˆxk) +AL,−(ˆx1) +AR,−(ˆxk) = 2 max{AL,R(ˆx1),AR,R(ˆxk)},
and thus that c<max{AL,R(ˆx1),AR,R(ˆxk)}.
Lemma 5.7 (Lower-Bound on Imprecision-Contribution). For anya≤1andk≥⌈2
a⌉+ 5and single-layer
ReLU-networkfthat classiﬁes kﬂips, there is some point j∈[k]such that
ˆlja−1(f(ˆxj+a) +f(ˆxj−a))
<AR,R(ˆxj) +AR,R(ˆxj−a) +AL,R(ˆxj+a).
Proof of 5.7. Letk≥⌈2a−1⌉+ 5,and deﬁnec:=2
a.Becausek≥⌈|c|⌉+ 5, we can use Lemma 5.6 to get
that|c|<max{AL,R(ˆx1),AR,R(ˆxk)}.
For convenience, we deﬁne ˜fL(x) =a−1(f(x)−f(x−a))and ˜fR(x) =a−1(f(x+a)−f(x)).
We only show the proof when |c|<AL,R(ˆx1), the other case is analogous, but picking j=k.
In this case we know 0<AL,R(ˆx1)and thus,
ˆl1a−1(f(ˆx1+a) +f(ˆx1−a))≤˜fL(ˆx1)−˜fR(ˆx1) +c.
There must be a point l∈[ˆx1−a,ˆx1]such that ˜fL(l)≤f/prime(l)and a point u∈[ˆx1,ˆx1+a]such that
f/prime(u)≤˜fR(u).
We can thus derive, in a manner similar to what is seen in Lemma 5.6:
˜fL(ˆx1)−˜fR(ˆx1)≤f/prime(l)−f/prime(u)≤IL,+(l) +IL,−(l) +IR,+(l) +IR,−(l)
−IL,+(u)−IL,−(u)−IR,+(u)−IR,−(u)
≤IL,−(l)−IR,−(u)
≤AL,R(ˆx1−a)−AR,R(ˆx1+a).
˜fL(ˆx1)−˜fR(ˆx1) +c<AR,R(ˆx1) +AL,R(ˆx1−a) +AR,R(ˆx1+a)asc≤|c|<AL,R(ˆx1)≤AR,R(ˆx1).
17Published in Transactions on Machine Learning Research (8/2022)
Theorem 5.8 (Single-Layer Limit). No single-layer ReLU-network can provably α-robustly classify ⌈2
α⌉+ 5
or more ﬂips for any α∈(0,1].
Proof of 5.8. Supposeα∈(0,1], and assume, for the sake of contradiction, that fis a single-layer
ReLU-network with weights N,Mand biasesb,dthat provably α-robustly classiﬁes ⌈2
α⌉+ 5ﬂips.
We begin the proof by labeling the intermediate states of interval analysis for a point ˆxjwith interval radius
αof the network f:
v−
α,j:= ReLU(Nˆxj+b−|N|α)
v+
α,j:= ReLU(Nˆxj+b+|N|α)
wα,j:=v+
j,α−v−
j,α
cα,j:=v+
j,α+v−
j,α
f#(/angbracketleftˆxj,α/angbracketright):=/angbracketleft1
2Mcα,j+d,1
2|M|wα,j/angbracketright,
where the notation |X|means the point-wise absolute value (i.e., |X|i=|Xi|).
Then our assumption for contradiction tells us that for any j∈[k], we have that 0is not inf#(/angbracketleftˆxj,α/angbracketright)and
thus that (−1)j(Mcα,j+ 2d)≥|M|wα,j.
LetjbesuchthatLemma5.7tellsushas ˆljα−1(f(ˆxj+α)+f(ˆxj−α))<AR,R(ˆxj)+AR,R(ˆxj−α)+AL,R(ˆxj+α).
We note that by expanding the deﬁnitions, sums, and meaning of absolute value, we can derive that
Mcα,j+ 2d=M(v+
α,j+v−
α,j) + 2d=f(ˆxj+α) +f(ˆxj−α). so our assumption for contradiction thus implies
|M|wα,j≤(−1)j(Mcα,j+ 2d) = (−1)j(f(ˆxj+α) +f(ˆxj−α).
We perform the following deduction:
(−1)j(f(ˆxj+α) +f(ˆxj−α))≥/summationdisplay
Niˆxj+bi≥−α|Ni||Mi|(Nix+bi+α|Ni|)−|M|v−
α,j
≥/summationdisplay
Niˆxj+bi≥0|Mi|(Nix+bi+α|Ni|)−|M|v−
α,j
≥|M|ReLU(Nx+b) +/summationdisplay
Niˆxj+bi≥0α|MiNi|
−/summationdisplay
Niˆxj+bi≥α|Ni||Mi|(Nix+bi−α|Ni|)
≥/summationdisplay
Niˆxj+bi≥0α|MiNi|+/summationdisplay
Niˆxj+bi≥α|Ni|α|MiNi|
≥α
/summationdisplay
Niˆxj+bi≥0|MiNi|+/summationdisplay
Niˆxj+bi≥α|Ni||MiNi|

≥α(AR,R(ˆxj) +AR,R(ˆxj−α) +AL,R(ˆxj+α))
≥ˆlj(f(ˆxj+α) +f(ˆxj−α))
which is a contradiction.
18Published in Transactions on Machine Learning Research (8/2022)
B Extended Proofs for General Impossibility Results
Here we restate the theorems and show the full proofs for the results in Section 4.
B.1 Proofs for Relative Interior Lemmas
In the following lemmas, let A,A/prime,B,B/prime,Cbe bounded and non-empty subsets of Rd:
Lemma 4.3 (Respects Projection). A@BimpliesA|i@B|i.
Proof of 4.3. Lety∈A|i. Then there is some x∈Asuch thatxi=y. Thenx∈relint (B)by
A@B. Then there is some /epsilon1 >0such thatN/epsilon1(x)∩aﬀ(B)⊆B. ThenN/epsilon1(x)|i∩aﬀ(B)|i⊆B|i. We
know aﬀ(B|i)⊆aﬀ(B)|i: givenz∈aﬀ(B|i), it must be an aﬃne combination of the i’th dimension of
elements of B. Lettingz/primebe the same aﬃne combination of those elements, z/prime
i=z, soz∈aﬀ(B)|i. Then
N/epsilon1(x|i)∩aﬀ(B|i)⊆B|iand thusy∈relint(B|i).
Lemma 4.4 (Respects Cartesian Product). A@BandA/prime@B/primeimpliesA×A/prime@B×B/prime.
Proof of 4.4. Let(x,x/prime)∈A×A/prime. Then because x∈Awe knowx∈relint (B)and respectively
x/prime∈relint (B/prime). Then there is some /epsilon1 > 0such that N/epsilon1(x)∩aﬀ(B)⊆B, and/epsilon1/prime>0such that
N/epsilon1/prime(x/prime)∩aﬀ(B/prime)⊆B/prime. We know (A∩A/prime)×(B∩B/prime)⊆(A×B)∩(A/prime×B/prime):(a,b)∈(A∩A/prime)×(B∩B/prime)
impliesa∈A∩A/primeandb∈B∩B/prime, so(a,b)∈A×Band(a,b)∈A/prime×B/primeso(a,b)∈(A×B)∩(A/prime×B/prime).
Then, we know aﬀ(B×B/prime)⊆aﬀ(B)×aﬀ(B/prime):(b,b/prime)∈aﬀ(B×B/prime)implies (b,b/prime)is an aﬃne combination of
elements of B×B/primewhich implies bis an aﬃne combination of elements from Bandb/primeis an aﬃne combination
of elements from B/prime, so(b,b/prime)∈aﬀ(B)×aﬀ(B/prime).
Thus forλ= min{/epsilon1,/epsilon1/prime}we knowNλ(x,x/prime)∩aﬀ(B×B/prime)⊆B×B/prime. Thus (x,x/prime)∈relint(B×B/prime).
Lemma 4.5 (Downward Union). A@CandB@CimpliesA∪B@C.
Proof of 4.5. Supposex∈A∪B. Thenx∈Aorx∈B. Either way, we know x∈relint(C).
Lemma 4.6 (Downward Hull). C∈BdandA@CimpliesH∞(A)@C.
Proof of 4.6. C∈BdimpliesC|i∈B, and thus C|iis convex so relint (C|i)is convex. We know
A|i@C|iby Lemma 4.3, so H∞(A|i)@C|iby convexity of C|iand thatH∞is the convex hull in one
dimension. Thus, by Lemma 4.4, we know H∞(A|1)×···×H∞(A|d)@C|1×···×C|d. BecauseC∈Bdwe
knowC=C|1×···×C|dand similarly that H∞(A) =H∞(A|1)×···×H∞(A|d). Thus,H∞(A)@C.
19Published in Transactions on Machine Learning Research (8/2022)
B.2 Proofs for Inversion and Impossibility Theorems
Lemma 4.9 (Concrete Relative Inversion). Supposefis a feed-forward network with ReLU-activations and
Y,X/prime∈BdandXis compact and non-empty. Then
Y@H∞(f(X)) =⇒ ∃X/prime@H∞(X).Y⊆f#(X/prime).
Proof of 4.9. The proof is by structural induction on the construction of the network f, assuming
the lemma itself as the induction hypothesis for any network with fewer operations than f. First, assume
Y@H∞(f(X)).
Case:f=g◦h. (Sequential Computation)
Subproof. By deﬁnition, Y@H∞(g◦h(X)). Thus, there exists some H@H∞(h(X))such thatY⊆g#(H)
by the induction hypothesis on g. Applying the induction hypothesis again with the network h, we
get a setX/prime@H∞(X)such thatH⊆h#(X/prime). Thus,Y⊆g#(H)⊆g#◦h#(X/prime) =f#(X/prime)./triangleleft
Case:f=Dup. (Duplication)
Subproof. ThenY|1@H∞(X)andY|2@H∞(X)by Lemma 4.3, We choose X/prime=H∞(Y|1∪Y|2)which we
know by Lemma 4.5 and Lemma 4.6, is such that X/prime@H∞(X). Thus,Y|1⊆X/primeandY|2⊆X/prime, so
Y⊆X/prime×X/prime=f#(X/prime). /triangleleft
Case:f=/angbracketleftg1,g2/angbracketright. (Parallel)
Subproof. ThenY|1@H∞(g1(X|1))andY|2@H∞(g2(X|2))by deﬁnition. Then applying the induction
hypothesis twice produces L@H∞(X|1)andR@H∞(X|2)such thatY|1⊆g#
1(L)andY|2⊆g#
2(R).
Then we choose X/prime=L×Rwhich we know by Lemma 4.4, is such that X/prime@H∞(X). Then
Y⊆g#
1(X/prime|1)×g#
2(X/prime|2) =f#(X/prime). /triangleleft
Case:f=c. (Constant)
Subproof. Here, any subset X/prime@Xwill suﬃce. Then we can let X/prime={C(X)}. /triangleleft
Case:f=c·forc/negationslash= 0. (Multiplication by a Constant)
Subproof. LetX/prime=B|c−1|R(Y)(c−1C(Y)). Then clearly, Y⊆f(X/prime). It remains to show that X/prime@H∞(X). For
the remainder of this subproof, because we know that d= 1we will write xl=infX,xu=supX,
yl=infYandyu=supY. We note that xl=C(H∞(X))−R(H∞(X))and so on. Supposing
c>0(the other case is analogous) and xl<xu(the proof is similar when they are equal), we have
cxl<yl≤yu<cxubyY@H∞(f(X)).
Then we know xl<|c−1|yl≤|c−1|yu<xu, and thusX/prime@H∞(X). /triangleleft
Case:f= ReLU. (Activation)
20Published in Transactions on Machine Learning Research (8/2022)
Subproof. Again, because we know that d= 1we will write xl:=infX,xu:=supX, andyl:=infYand
yu:=supY. We know that infH∞(f(X))=ReLU (xl)andsupH∞(f(X))=ReLU (xu). Thus by
Y@H∞(f(X))we know ReLU (xl)≤yl≤yu≤ReLU (xu). We then have two cases we need to
address:
Suppose:xu>0.
Subproof. Here we deﬁne X/prime= [yl,yu]. We thus have xl≤ReLU(xl)<yl≤yu<ReLU(xu) =xu
providedxl<xu. Otherwise we know xl=ReLU (xl) =yl=yu=ReLU (xu) =xuso
we haveX/prime@H∞(X). /triangleleft
Suppose:xu≤0.
Subproof. DeﬁneX/prime={xu+xl
2}.ReLU(xu+xl
2) = 0 =yl=yuimpliesX/prime@H∞(X). /triangleleft
Thus, in both cases we can ﬁnd X/prime@H∞(X)such thatY⊆f(X/prime)⊆f#(X/prime) /triangleleft
Case:f=Sum. (Addition)
Subproof. Conveniently again, Yis one-dimensional. Either H∞(f(X))is a single point or it is not:
Assume:H∞(f(X))is a single point.
Subproof. Then infY=supY=infH∞(f(X))=supH∞(f(X)). Lety=infY. In this case, we
knowthereissomecompactandnon-emptyset Z⊆RsuchthatX={(x/prime,y−x/prime):x/prime∈Z}.
Thenwecanpick X/prime={(C(H∞(Z)),y−C(H∞(Z)))}whichisthesingleton-setcontaining
the center of the l∞-hull ofXand thusX/prime@H∞(X)by Lemma 4.8. /triangleleft
Otherwise:H∞(f(X))is not a single point.
Subproof. We know infH∞(f(X))<infY≤supY < supH∞(f(X)). Because Yis one-
dimensional and a relative subset of the non-singular H∞(f(X))we knowY@
H∞(f(H∞(X))).
Leta,b,ra,rb,y,rybe as follows:
a=C(H∞(X|1)), ra=R(H∞(X|1)),
b=C(H∞(X|2)), r b=R(H∞(X|2)),
y=C(Y), andry=R(Y).
ThenH∞(X) =Bra(a)×Brb(b)and thusY@f(Bra(a)×Brb(b)) =B(ra+rb)(a+b).
ChooseX/prime=Br(x)forxandrdeﬁned as:
x1=a+ray−a−b
ra+rb, r 1=ryra
ra+rb,
x2=b+rby−a−b
ra+rb,andr2=ryrb
ra+rb.
Then clearly, x1+x2=y, andr1+r2=rysoY⊆f(X/prime).
Thusry<ra+rbbyY@Bra+rb(a+b).
This also tells us that y+ry<a+b+ra+rbandy−ry>a+b−ra−rb. Ifra/negationslash= 0
we can derive x1+r1<a+raandx1−r1>a−ra. Similarly, if rb/negationslash= 0we can derive
x2+r2<b+rbandx2−r2>b−rb. Thus,X1@Bra(a)andX2@Brb(b), and thus by
Lemma 4.4 we have X/prime@Bra(a)×Brb(b) =H∞(X). /triangleleft
21Published in Transactions on Machine Learning Research (8/2022)
Thus, in both cases, there exists an X/prime@H∞(X)such thatY⊆f(X/prime)⊆f#(X/prime). /triangleleft
As any feed forward neural network (without input-value dependent loops) can be expressed using these
operations without modifying the result under interval analysis, by induction ∃X/prime@H∞(X).Y⊆f#(X/prime).
22Published in Transactions on Machine Learning Research (8/2022)
Theorem 4.10 (Fundamental Imprecision of Interval). Supposef:S→TwithS,T∈Tis aReLU-network
andy∈RmandN⊆f−1(y)is compact and non-empty. Then assuming M∈BS:
∃M@H∞(N).y∈f#(M).
Proof of 4.10. The proof is by structural induction on the construction of the network f, assuming the
theorem itself as the induction hypothesis for any network with fewer operations than f.
Letf:Rn→Rmbe a feed forward network with ReLUactivations, and let y∈Rmand letN⊆f−1(y)be
compact and non-empty. Then fis one of the following cases:
Case:f=g◦h (Sequential Computation)
Subproof. We ﬁrst know that N⊆h−1◦g−1(y)by the deﬁnition of f. We then infer that h(N)⊆H∞(N)is
compact and non-empty by application of the continuous function h. Thus, by induction on h(N)
andgthere is some M/prime@H∞(h(N))such thaty∈g#(M/prime). Thus, by Lemma 4.9, we know that
there is some M@H∞(N)such thatM/prime⊆h#(M). Thus,y∈g#◦h#(M) =f#(M)./triangleleft
Case:f=Dup. (Duplication)
Subproof. We haveN⊆{y1}∩{y2}soN={y1}. By singleton reﬂexivity, N@H∞(N). Thus,y∈f#(N).
/triangleleft
Case:f=/angbracketleftg1,g2/angbracketright. (Parallel)
Subproof. First we know N|1⊆g−1
1(y1)andN|2⊆g−1
2(y2)by projection and that N|1andN|2are
still compact and non-empty. Thus, by the induction hypothesis twice we see that there are
boxesM1@H∞(N|1)andM2@H∞(N|2)such thaty1∈g#
1(M1)andy2∈g#
2(M2). Then
M1×M2@H∞(N)by Lemma 4.4. Then y1∈f#(M1×M2)|1andy2∈f#(M1×M2)|2by
soundness. Thus, there is some box M@H∞(N)such thaty∈f#(M). /triangleleft
Case:f=c. (Constant)
Subproof. We knowy=cand thusf−1=R. If we letM={C(H∞(N))}@H∞(N), theny∈f#(M)./triangleleft
Case:f(y) =c·yforc/negationslash= 0. (Multiplication by a Constant)
Subproof. We knowf−1(y) ={c−1·y}=N@H∞(N)byNbeing non-empty and thus y∈f#(N)./triangleleft
Case:f= ReLU. (Activation)
Subproof. Theny= ReLU(x)can either be zero or greater than zero.
Case:y>0
Subproof.N={y}by def. of ReLU, and we know{y}@H∞(N)andy∈f#({y}). /triangleleft
23Published in Transactions on Machine Learning Research (8/2022)
Case:y= 0
Subproof.N= (−∞,0]by def. of ReLU. Thus{C(H∞(N))}@H∞(N)andy∈f#({C(H∞(N))}).
/triangleleft
Becauseyis the result of a ReLU, it must have been one of these two possibilities, and in both
cases we could ﬁnd some M@H∞(N)such thaty∈f#(M). /triangleleft
Case:f=Sum. (Addition)
Subproof. In this case, we know N⊆f−1(y) ={(a,y−a):a∈R}. We pickM={C(H∞(N))}@H∞(N).
GivenNis bounded, we know:
C(H∞(N)) =/parenleftbigginfN|1+ supN|1
2,infN|2+ supN|2
2/parenrightbigg
=/parenleftbigginfN|1+ supN|1
2,2y−infN|1−supN|1
2/parenrightbigg
.
We can rewrite f(C(H∞(N)))as
f(C(H∞(N))) =infN|1+ supN|1
2+2y−infN|1−supN|1
2=y.
Thus,y=f(C(H∞(N)))∈f#(M) /triangleleft
Thus,∃M@H∞(N).y∈f#(M).
24Published in Transactions on Machine Learning Research (8/2022)
C Reference of Symbols and Notation
General Notation (Sec. 3.1)
[k]Theindex set{1,...,k}fork∈N
Y|iTherestriction ofY⊆T1×...×Tk
to dimension i, or formally, the set
{yi:y∈Y}
PThepowerset operator
f[S]The lifted application of fto a subset
Sof its domain. Formally, the set
{f(x):x∈S}
S◦Thetopological interior ofS
ReLUThe function mapping x∈Rto
max{x,0}
Spaces and Domains (Sec. 3.1)
NThe set of natural numbers
RThe set of real numbers
TThe class of binary-tree tensor-spaces
deﬁned as{T1×T2:T1,T2∈T}∪{R}
BSThe set of closed, non-empty, axis-aligned
boxesoverS∈T
BdFord∈N, this is the set of closed, non-
empty, axis-aligned boxesoverRd
Notation for Boxes (Sec. 3.1)
Br(c)Theclosed box with center c∈Rdand
radiusr∈Rd
≥0
R(B)Theradiusof the boxB
C(B)Thecenterof the boxB
H∞(S)Thel∞-hull, or smallest axis aligned box
containingSNotation for Analysis (Sec. 3.2)
fP:P(S)→P(T)Theperfect transformer , deﬁned as the
mappingS/mapsto→{f(x):x∈S}
f#:BS→BTTheinterval transformation of aσ-
networkf:S→T
Relative Subsets (Sec. 4.1)
aﬀ(S)The smallest linear-subspace ofRd
containingS
relint(S)Therelative interior . Formally, the set
{x∈S:∃/epsilon1>0.B◦
/epsilon1(x)∩aﬀ(S)⊆S}
A@BTherelative subset relation, deﬁned
formally, as A⊆relint(B)
Single-Layer Networks (Sec. 5.2)
ˆxiAn input point in Rddeﬁned as ˆxi,1:= 2i
andˆxi,j= 0forj >1
ˆliAn output label equal to (−1)i
AD,S(x)The absolute imprecision-contribution
ID,S(x)The standard imprecision-contribution
25