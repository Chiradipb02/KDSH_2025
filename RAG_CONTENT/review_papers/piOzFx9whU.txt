Wasserstein Distributionally Robust Optimization
Through the Lens of Structural Causal Models and
Individual Fairness
Ahmad-Reza Ehyaei
Max Planck Institute for Intelligent Systems, Tübingen AI Center, Germany
ahmad.ehyaei@tuebingen.mpg.de
Golnoosh Farnadi∗
Mila Québec AI Institute ; McGill University, Montréal, Canada
farnadig@mila.quebec
Samira Samadi
Max Planck Institute for Intelligent Systems, Tübingen AI Center, Germany
ssamadi@tuebingen.mpg.de
Abstract
In recent years, Wasserstein Distributionally Robust Optimization (DRO) has
garnered substantial interest for its efficacy in data-driven decision-making under
distributional uncertainty. However, limited research has explored the application
of DRO to address individual fairness concerns, particularly when considering
causal structures and sensitive attributes in learning problems. To address this
gap, we first formulate the DRO problem from causality and individual fairness
perspectives. We then present the DRO dual formulation as an efficient tool to
convert the DRO problem into a more tractable and computationally efficient form.
Next, we characterize the closed form of the approximate worst-case loss quantity
as a regularizer, eliminating the max-step in the min-max DRO problem. We further
estimate the regularizer in more general cases and explore the relationship between
DRO and classical robust optimization. Finally, by removing the assumption of
a known structural causal model, we provide finite sample error bounds when
designing DRO with empirical distributions and estimated causal structures to
ensure efficiency and robust learning.
1 Introduction
Machine learning models must address discrimination because they often reflect and amplify biases
present in their training datasets [ 31]. These biases can significantly influence decisions in domains
such as healthcare [ 30], education [ 3], recruitment [ 18], and lending services [ 6]. Consequently,
these decisions disproportionately affect individuals based on sensitive attributes like race or gender,
perpetuating systemic discrimination.
To address and quantify unfairness, researchers have developed concepts like group fairness and
individual fairness [45,4]. Group fairness aims to achieve equitable outcomes across demographic
groups, while individual fairness ensures that similar individuals receive similar treatment. Formally,
withVas the feature space and Yas the label space, a model h:V → Y ensures individual fairness
∗Lead scientific advisor on the project
38th Conference on Neural Information Processing Systems (NeurIPS 2024).if it satisfies the condition in [20]:
dY(h(v), h(v′))≤LdV(v, v′)for all v, v′∈ V, (1)
where dVanddYare dissimilarity functions, often referred to as fair metrics on the input and output
spaces. These functions capture the proximity of individuals and L∈R+is a Lipschitz constant.
The metric dVreflects the intuition about which instances should be considered similar by the model.
Due to challenges in defining such metrics, group fairness is often prioritized in fairness literature
because it more straightforwardly addresses observable disparities among distinct groups, making
measurement and implementation easier in practice [ 8]. Therefore, it is crucial to study and formulate
individual fairness under different assumptions in machine learning.
Individual fairness can be achieved through robust optimization methods such as Wasserstein DRO ,
which has gained significant attention for its applications in learning and decision-making [ 55,43].
DRO incorporates a regularization term to mitigate overfitting [ 17,26,59]. By using a fair metric
as the transportation cost function in computing the Wasserstein distance, models are designed to
deliver consistent performance across varied data distributions, ensuring similar individuals receive
comparable outcomes, thus satisfying individual fairness.
Incorporating causal structures and sensitive attributes into data models complicates using an indi-
vidual fair metric as a cost function within the DRO framework. The fair metric must account for
perturbations in sensitive attributes based on counterfactuals to ensure counterfactual fairness [ 22].
This can violate the positive-definite property, where d(v, v′) = 0 implies v=v′, a key assumption
in many DRO theorems [55, 43].
Although previous works [ 42,67,70,69,57] have attempted to apply DRO to address individual
fairness, they often do not explore the implications when causal structures and sensitive attributes
are present in the learning problem. These studies are typically limited to linear Structural Causal
Model (SCM) with specific metrics and do not discuss the form of the regularizer for other classical
DRO theorems when using a fair metric. To accurately compare our work with related studies, we
will postpone this discussion until after presenting our results in Section 4.1.
1.1 Our Contributions
In this work, we adopt the definition of a fair metric from [ 22] to define a Causally Fair Dissimilarity
Function (CFDF) , which delineates how to establish a fair metric through causality and sensitive
attributes. Using CFDF, we introduce Causally Fair DRO and present a strong duality theorem for
our approach. Under mild assumptions about CFDF and causal structure, we demonstrate that the
DRO regularizer can be estimated, or in some cases can be explicitly solved. This estimation often
leads to being more practical and computationally efficient than solving the min-max problem in (4),
as supported by advancements in algorithms from previous research such as [ 14,15]. Finally, Our
numerical analysis of both real and synthetic data demonstrates the practicality of our theoretical
framework in real-world applications. ( §5). In summary, the main contributions of this work are:
•Define a causally fair dissimilarity function, an individual fair metric incorporating causal
structures and sensitive attributes (Def. 1), along with its representation form (Prop. 1).
• Define a causally fair DRO problem with a causally fair dissimilarity function cost ( §4).
• Present the strong duality theorem for causally fair DRO (Thm. 1).
•Provide the exact regularizer for linear SCM under mild conditions for the loss function in
regression and classification problems (Thm. 2 and Thm. 3).
• Estimate the first-order causally fair DRO regularizer for non-linear SCM (Thm. 4).
•Provide the relation between classical robust optimization and causally fair DRO (Prop. 2).
•Demonstrate that under unknown SCM assumptions, by estimating the SCM or cost function,
we have finite sample guarantees for convergence of empirical DRO problems (Thm. 5).
2 Preliminaries & Notations
Data Model. LetV∈ V denote a vector of feature space (predictor variables) and let Y∈ Y
represent the response variable, such that Z= (V,Y)comprises the observation variables with an
2underlying probability P∗. Furthermore, assume that the feature vector V= (A,X)comprises both
sensitive attributes A∈ A and non-sensitive attributes X∈ X. Let{zi= (vi, yi)}N
i=1represent
the observations used to construct the empirical distribution PN, defined as PN:=1
NPN
i=1δzi,
where δzis the Dirac delta function. Given a loss function ℓ:Z ×Θ→R, the risk function for a
parameter θ∈Θand a probability measure PisR(P, θ) =EP[ℓ(Z, θ)]. This leads to the common
empirical risk minimization approach. This method seeks to find the minimizer θerm
Nwithin the
setθerm
N∈arg min θ∈ΘR(PN, θ), as an empirical way to obtaining the optimal solution θ∗, which is
given by θ∗= inf θ∈ΘR(P∗, θ).
Assume the feature space is represented by a structural causal model (SCM) M =
⟨G,V,U,PU⟩[51]. This model includes structural equations {Vi:=fi(VPa(i),Ui)}n
i=1, which
delineate the causal relations among an endogenous variable Vi, its causal predecessors VPa(i), and
an exogenous variable Uirepresenting unobservable factors. The model’s structure is encapsulated
in a directed acyclic graph G. Exogenous variables are posited as mutually independent, enabling PU
to be expressed asQn
i=1PUi, assuming causal sufficiency and excluding hidden confounders [53].
Counterfactuals. In causal structures, data perturbation is achieved through counterfactuals ,
which are derived from interventions in SCMs. These interventions, conducted using do-calculus,
include both hard andsofttypes [ 51]. Hard interventions fix a subset I ⊆ { 1, . . . , n }of features
VIto a constant τ, modifying their causal connections within the causal graph while maintaining the
structural equations of other features [ 51]. This type of intervention is denoted as Mdo(VI:=τ)and
its structural equations are obtained by:
{Vi:=τi,∀i∈ I;Vi:=fi(VPa(i),Ui),∀i /∈ I}.
Soft interventions, on the other hand, adjust the functions in the structural equations, such as
through additive interventions, without disrupting existing causal links [ 53]. In an additive (or shift)
intervention, a value ∆∈Rnis added to each feature within the SCM to enact manipulation:
{Vi:=fi(VPa(i),Ui) + ∆ i}n
i=1.
In SCMs, counterfactuals are computed by modifying structural equations to reflect hard interventions
on specific variables, thus exploring what would occur if the intervention was applied. Under the
assumption of acyclicity, a unique function F:U → V exists such that F(u) =v. Acyclicity remains
unchanged by either hard or shift interventions, allowing for the existence of modified functions
Fdo(VI:=τ)andFdo(VI+=∆)corresponding to these interventions, respectively. The counterfactual
outcome for a hard intervention can thus be calculated using CF(v, τ) =Fdo(VI:=τ)(F−1(v)), and
similarly, for a shift intervention, it is defined as CF(v,∆). These interventions are frequently applied
in this analysis.
Counterfactuals involving the modification of sensitive attributes (termed twins ) are essential for
addressing individual-level fairness [ 40,64]. Twins are generated by altering the sensitive attribute
from atoa′across its domain A. For any instance, v∈ V, a set of counterfactual twins is produced
as{¨va=CF(v, a) :a∈ A} , facilitating the analysis of fairness by comparing outcomes under
different sensitive attribute values.
Counterfactual Identifiability. To estimate the effects of interventions from observational data,
counterfactuals must be identifiable within a causal framework. A notable example of such identifi-
able SCMs is the additive noise models (ANMs) , which suggest that structural equations can be
represented as:
{Vi:=fi(VPa(i)) +Ui}n
i=1=⇒U= (I−f)(V) =⇒V= (I−f)−1(U) (2)
leading to a bijective mapping between UiandVi, ensuring no loss of information from exogenous to
endogenous variables[ 50]. This relationship implies that Vcan be derived from Uthrough a bijective
reduced-form mapping F= (I−f)−1, where I(x) =xis the identity function. Besides ANM,
there are other counterfactually identifiable models such as LSNM [ 34] and PNL [ 71]. However, for
the sake of simplicity, our focus remains on ANM. Linear SCMs is a specific instance of ANMs,
characterized by linear functions fi.
Individual Fairness Through Robustness. In machine learning, individual fairness [ 20] is achieved
through robustness by ensuring that similar individuals receive similar outcomes, regardless of
3variations in their inputs. This concept aligns with the notion of Lipschitz continuity in decision
functions (Eq. 1), where small changes in input should not lead to excessively large changes in output.
Depending on how the uncertainty set is defined, various types of robust optimization can be employed.
Inadversarially robust optimization [44,7], the uncertainty set is defined by introducing a slight
perturbation δbased on the metric dto the input data. The goal is to find the optimal θthat minimizes
risk even under the worst-case perturbation quantity:
Radv
δ(P, θ) =E
v∼P"
sup
dp(v,v+∆)≤δℓ(v+ ∆, y, θ)#
, (3)
where p∈[0,∞]. This formulation ensures that the optimization considers the maximum potential
loss within the defined perturbation bounds.
Incounterfactually robust optimization [40,37,64,23,24], the uncertainty set is generated by
twins, which are obtained by creating counterfactuals concerning all levels of the sensitive attribute.
In this scenario, the worst-case loss quantity is obtained by calculating the maximum loss over the
twins of the input data:
Rcf
δ(P, θ) =E
v∼P
sup
a∈Aℓ(¨va, y, θ)
.
Distributionally Robust Optimization [43,55] is a data-driven approach designed to minimize the
discrepancies between in-sample and out-of-sample expected losses, using ambiguity sets based on
Wasserstein distances. Consider a lower semi-continuous cost function c(·,·) :Z × Z → [0,∞]that
satisfies c(z, z) = 0 for all z∈ Z, serving as a fair metric. The optimal transport cost between two
distributions P,Q∈ P(Z), is represented by:
Wc,p(P,Q)≜ min
π∈P(Z×Z )(
E
(z,z′)∼π[cp(z, z′)]1
p
:π1=P, π2=Q)
,
Here, π∈ P(Z × Z )denotes the set of all joint probability distributions, and π1andπ2are the
marginals of πunder first and second coordinates [ 54,63]. When c(z, z′)acts as a metric (in
mathematics term) on Z,Wc,pis called the Wasserstein distance [63].
An important ingredient in the DRO formulation is the description of the distributional uncertainty
region Bδ(P)that is defined by optimal transport cost:
Bδ(P):={Q∈ P(V) :Wc,p(Q,P)≤δ}.
DRO problem minimizes worst-case loss quantity:
Rδ(P, θ)≜ sup
Q∈Bδ(P)
EQ[ℓ(Z, θ)]	
, (4)
and obtained the θdro
N∈arg min θ∈ΘRδ(PN, θ). The main tool in DRO is the strong duality
theorem [26,46], which converts an infinite-dimensional problem into a finite optimization problem.
The theorem states that:
sup
Q∈Bδ(P)
E
v∼Q[ψ(v)]
= inf
λ≥0n
λδp+E
v∼P[ψλ(v)]o
, (5)
where ψλ(v)is defined as ψλ(v):= supv′∈V{ψ(v′)−λdp(v, v′)}.
3 Causally Fair Dissimilarity Function
The key to robust optimization and individual fairness is the metric that measures individual similarity.
This section outlines the properties of such a metric in a causal framework to protect sensitive
attributes. We begin with an illustrative example.
Example 1 LetM1andM2represent two SCMs describing the relationships among the variables
gender ( G), education ( E), and income ( I).M1models these variables as independent, whereas
M2specifies a linear causal relationship:
M1=

G:=UG,UG∼ B(0.5)
E:=UE,UE∼ N(0,1)
I:=UI,UI∼ N(0,1),M2=

G:=UG, UG∼ B(0.5)
E:=G+UE, UE∼ N(0,1)
I:=G+ 2E+UI,UI∼ N(0,1),
4Where UGrepresents the population distribution of gender, modeled by a Bernoulli distribution, while
UEandUIare intrinsic talents for academic and income achievements, respectively, modeled by
normal distributions. To compare individuals, let’s consider the L1norm on non-sensitive attributes
(d(v, v′) =|e−e′|+|i−i′|). If two individuals have less than a 0.1 unit difference, they are deemed
similar. Now, consider an individual with data v= (M,1,1). Based on experience, we expect
that a perturbation in educational talent by .05 units will not significantly alter this individual’s
status. We model this perturbation with a shift intervention ∆ = (0 , .05,0). In Model 1, the result
CF(v,∆) = ( M,1.05,1)is considered similar to v. However, in Model 2, CF(v,∆) = ( M,1.05,1.1)
results in a distance of d(v,CF(v,∆)) = 0 .15, indicating dissimilarity. In the presence of causality,
one attribute can be amplified multiple times in the final feature space. Therefore, we need to control
our intuition of dissimilarity between the exogenous variables and the feature space.
To protect against gender bias, we need to ensure that people with the same intrinsic characteristics
but different genders behave similarly. This is modeled by a counterfactual change in gender.
In Model 1, CF(v, F) = ( F,1,1)shows no difference ( d(v,¨vF) = 0 ). However, in Model 2,
CF(v, F) = (F,0,−2)results d(v,¨vF) = 4 , which means that they are not similar.
The example 1 demonstrates that in the presence of causality and protected variables, the standard
lp-norm or any metric fails to accurately capture the intuition of similarity. In these scenarios, a
dissimilarity function should incorporate counterfactuals and uniformly control for non-sensitive
perturbations to effectively capture proximity. This approach is further elaborated in the following
definition. Before proceeding, we introduce some notation. For a vector voru, we define PA(·)and
PX(·)as the projections onto the sensitive and non-sensitive parts, respectively.
Definition 1 (Causally Fair Dissimilarity Function) Letd:V × V → [0,∞]be a dissimilarity
function defined on the feature space V, generated by a SCM M. LetAdenote a set of sensitive
attributes, and Irepresent their corresponding index within {1, . . . , n }. The metric is called a
causally fair dissimilarity function or CFDF if it adheres to the following properties:
•Zero Dissimilarity for Twin Pairs: For any v∈ V anda∈A, the dissimilarity d(v,¨va)
between an instance and its twins is zero.
•Guaranteed Similarity for Minor Perturbations: For every v∈ V and any δ >0, there
exists an ϵsuch that for any sufficiently small intervention ( ∥∆∥ ≤ϵ) on the non-sensitive
attributes ( PA(∆) = 0 ), the distance d(v,CF(v,∆))remains less than δ.
To understand the shape of dunder the assumptions of Def. 1, we must first recognize that the CFDF
needs to be defined on a larger space than Range( M)[22]. This is because, generally, when Mis in-
tervened upon by some sensitive attribute level a, we have Range( M)⊆S
a∈ARange( Mdo(A:=a)).
The complete space encompassing all counterfactual values can be defined as follows.
Definition 2 (Parent-Free Sensitive Attribute SCM) Consider Mwith sensitive attributes in-
dexed by I. The parent-free sensitive attribute SCM denoted as M0, is derived from Mby removing
the causal effects of parents of sensitive attributes and replacing their exogenous variables with
indigenous ones. The structural equations for M0are as follows:
V0
i:=(
Ui Ui:=Vi∼PVi, i∈ I
fi(V0
pa(i)) +UiUi∼PUi, i / ∈ I
The exogenous space corresponding to M0, denoted by U0, includes the sensitive attributes and the
non-sensitive parts of the exogenous variables of M. This space called the semi-latent space, is
constructed as U0=A × U X, where UXis the non-sensitive part of the exogenous space in M.
If we know the structural equations of M, we can first map the CFDF to the exogenous space. In
this space, the exogenous variables are assumed to be independent. Therefore, we can design a
dissimilarity function for each variable separately and then combine them using product topology
(§.2 [48]). Following this intuition, we introduce the bijective map g:V → U 0from the feature space
to the semi-latent space, along with its inverse, defined as follows:
gi(v):=vi i∈ I
Fi(v)i /∈ I, g−1
i(u):=(
ui i∈ I
fi(g−1
pa(i)(u)) +uii /∈ I(6)
5If all sensitive attributes have no parents, the semi-latent space is equivalent to the exogenous space,
andg=F−1. The counterfactual with respect to M0is denoted by CF0(v,∆). We can now present
the following proposition to determine the shape of d.
Proposition 1 LetMbe an ANM, with gas its corresponding map to the semi-latent space 6 , and
PX(u)the projection of vector uto the non-sensitive part UX. Then:
(i) IfdXis a continuous dissimilarity function on diagonal UX× UX, then the function ddefined as:
d(v, v′) =dX(PX(g(v)), PX(g(v′))) (7)
satisfies the definitions of a CFDF .
(ii) If d:V × V → [0,∞]satisfies the CFDF definition and the triangle inequality property, then d
can be represented as a dissimilarity function dXdependent solely on the non-sensitive components
UXi.e.,d(v, v′) =dX(PX(g(v)), PX(g(v′))).
Since dXis defined on independent coordinates, its relation to the components is less complex than
the CFDF d. We assume the dissimilarity function dX(x, x′)is translation-invariant. Therefore, for
simplicity, we assume dX(x′, x) =∥x′−x∥. The dual of ∥ · ∥ is defined as ∥x∥∗= supx′{xTx′|
∥x′∥ ≤1}. Now we establish our assumptions about the SCM and its CFDF.
Assumption 1 (i)Mis an ANM with known structural equations and a semi-latent map g.
(ii) The CFDF is defined as d(v, v′) =∥PX(g(v))−PX(g(v′))∥, where ∥.∥is a some norm.
(iii) Cost function over Zhas form c((v, y),(v′, y′)) =d(v, v′) +∞ · |y−y′|.
(iv) The ambiguity set is defined as: Bδ(P) ={Q∈ P(V) :Wc,p(P,Q)≤δ}, forp∈[1,∞).
Remark 1 All results of this work apply to the homogeneous dissimilarity function (Def. 6), which
includes a broad family of dissimilarity functions, such as norms.
4 Causally Fair Distributionally Robust Optimization
To find out the impact of the CFDF in DRO problems, we first consider the dual form of the worst-case
loss quantity, which simplifies the infinite-dimensional primal problem into a more tractable and
computationally manageable form.
Theorem 1 (Causally Fair Strong Duality) If Assumption 1 is satisfied, then for any reference
probability distribution Pand any function ψ:V →Rthat is both upper semi-continuous and
L1-integrable, the following duality holds:
sup
Q∈Bδ(P)
E
v∼Q[ψ(v)]
= inf
λ≥0
λδp+E
v∼P
sup
a∈Aψλ(¨va)
, (8)
where ψλ(v)is defined as
ψλ(v):= sup
∆∈X{ψ(CF0(v,∆))−λpd(v,CF0(v,∆))}, (9)
andCF0is counterfactual regarding parent-free SCM M0.
Remark 2 The intuition behind the above formula is as follows: In the case where all features are
independent, let v= (a, x). The CFDF should exhibit no difference between (a, x)and(a′, x)for
eacha, a′∈ A. Consequently, the distance metric satisfies d((a, x),(a′, x′)) = dX(x, x′). Under
this condition, the classical strong duality theorem (Eq. 5) provides the following relationship:
ψλ(v) = sup
(a′,x′)∈V{ψ((a′, x′))−λdp
X(x, x′)}= sup
a∈A
sup
∆∈Xψ((a, x+ ∆)) −λdp
X(x, x+ ∆)
When we incorporate causal structure instead of coordinating aandx, the two dimensions ¨vaand
CF0(v,∆)are replaced accordingly.
6In the DRO formulation, the worst-case loss is expressed in a dual form and can act as a regularizer
for parameter learning. Explicitly solving the dual problem eliminates the need to compute the
worst-case distribution, resulting in faster, more efficient learning algorithms [ 14,16,62,73]. Before
presenting the general theorem, the next two theorems show that, under mild conditions, the dual
formula for specific loss functions in classification and regression problems can be explicitly solved.
Theorem 2 (Higher Order Linear Loss) Given Assumptions 1, let Mbe a linear SCM and the
loss function ℓ(z, θ)p, where ℓ(z, θ)is of the form h(y− ⟨θ, v⟩)orh(y· ⟨θ, v⟩)for functions h(t)
such as |t|,max(0 , t),|t−τ|, ormax(0 , t−τ)for some τ≥0, and p∈[1,∞). Then the DRO
problem 4 can be reduced to:
Rδ(PN, θ) =


Rcf
δ(PN, θ)1
p+δPX(MTθ)
∗p
, diam (A)<∞

R(PN, θ)1
p+δPX(MTθ)
∗p
,s.t.PA(MTθ) = 0; diam (A) =∞
where Mis the corresponding matrix for the linear map g−1(see Eq. 6).
Remark 3 In real-world datasets, the sensitive part always satisfies diam (A)<∞. According to
the above theorem, Rδ(PN, θ)≥ Rcf
δ(PN, θ). For practical applications, if the worst-case loss must
not exceed a certain value, we can replace ∞with some constant in the above theorem.
Example 2 Here are specific examples of the above theorem. We offer a framework to study the
equivalence between the worst-case loss in the DRO problem, with the cost function derived from the
CFDF , and the regularization scheme for classification and regression problems.
Regression Lower Partial Moments
EP[|Y− ⟨θ,V⟩|p], p≥1 E P[(Y− ⟨θ,V⟩ −τ)p
+], p≥1, τ∈R
Ridge Linear Regression τ-Insensitive Regression
EP[(Y+⟨θ,V⟩)2] E P[(|Y− ⟨θ,V⟩| −τ)p
+],p≥1,τ∈R
Hinge Loss Binary Classification Support Vector Machine Classification
EP[(1−Y· ⟨θ,V⟩)p
+],p≥1 E P[|1−Y· ⟨θ,V⟩|p],p≥1
The Thm. 2 can be extended to the non-linear regression loss function.
Theorem 3 (Nonlinear Loss) Let assumptions 1 be satisfied, with p= 1,Mlinear with matrix M
corresponding to map g−1, and a loss function ℓ(z, θ)of the form h(y− ⟨θ, v⟩)for regression and
h(y· ⟨θ, v⟩)for classification, where hhas the following two properties:
(i)his Lipschitz on RwithLhconstant, i.e., |h(t2)−h(t1)| ≤Lh|t2−t1|,∀t1, t2∈R.
(ii)There exists sequence of {tk}∞
k=1goes to ∞such that for each t0∈Rwe have
limk→∞|h(t0+tk)−h(t0)|
|tk|=Lh.
By the above assumption, DRO problem 4 can be reduced as:
Rδ(PN, θ) =

Rcf
δ(PN, θ) +δLhPX(MTθ)
∗, diam(A)<∞
R(PN, θ) +δLhPX(MTθ)
∗,s.t.PA(MTθ) = 0; diam(A) =∞
Example 3 The following forms of the loss function satisfy the conditions of hin Thm. 3:
Now, the first-order estimation of the regularizer for non-linear SCM and loss function is ready to be
stated.
Theorem 4 (First-Order Estimation of DRO Regularizer) Assume Mhas structural equation f,
which fand loss function ℓare both twice continuously differentiable respect to non-sensitive
7Log-cosh Loss Huber Loss
h:t7→log(cosh( t)) h:t7→1
2t2if|t| ≤1,
|t| −1
2otherwise ;
Quantile Loss Log-exponential Loss
h:t7→γt ift≥0,
−totherwise ,withγ∈(0,1); h:t7→log(1 + exp( −t))
Smooth Hinge Loss Truncated Pinball Loss
h:t7→

0 ift≥1,
1
2(1−t)2if0< t < 1,
1
2−t otherwise ;h:t7→

1−t ift≤1,
τ1(t−1) if1< t < τ 2+ 1,
τ1τ2 otherwise ,
where τ1∈[0,1], τ2≥0are two given constants.
attributes, diam (U)<∞andcsatisfies the assumption 1 with p∈[2,∞]. The necessary condition
for the existence of a finite DRO solution is that for each v∈ V:
sup
a∈A{ℓ(¨va, y, θ)}<∞.
By these conditions, the worst-case loss quantity is equal to:
Rδ(PN, θ) =E
v∼PN
sup
a∈Aℓ(¨va, y, θ)
+δ·
E
v∼PN
sup
a∈A∥∇CFℓ(¨va, y, θ)∥q
∗1/q
+O(δ2),(10)
where the O(δ2)term is uniform over all θ∈Θ,qisp’s conjugate, and the gradient ∇CFℓequals to:
∇CFℓ(v, y, θ ) = lim
∆→0ℓ(CF0(v,∆), y, θ)−ℓ(v, y, θ )
∥∆∥
where CF0is counterfactual regarding parent-free SCM M0.
By applying Prop. 2 from Gao’s work [ 28], the next proposition presents the relationship between
classical adversarial optimization 3 and DRO for CFDF.
Proposition 2 (Approximation by Robust Optimization) Suppose Ais a finite set and let
{(vi, yi)}N
i=1be observational data. Under Assumption 1, assume that for the loss function ℓ
there exist constants L, M≥0such that
|ℓ(v, y, θ )−ℓ(v′, y, θ)|< Ldp(v, v′) +M for all v, v′∈ V andp∈[1,∞).
For an arbitrary K∈N, consider the adversarial loss within the setting:
˜Radv
δ(PN) := sup
(wik)i,k∈˜Bδ(
1
NKNX
i=1KX
k=1sup
a∈Aℓ( ¨wik
a, yi, θ))
,
where the uncertainty set ˜Bδis defined as:
˜Bδ:=(
(wik)i,k:1
NNX
i=1KX
k=1dp(vi, wik)≤δ, wik∈ V)
.
Then, the DRO can be approximated by adversarial optimization as follows:
˜Radv
δ(PN)≤ R δ(PN)≤˜Radv
δ(PN) +LD+M
NK,
where Dis independent of K.
One of the main challenges in designing DRO for SCMs is that the CFDF depends on the causal
structure. When the functional structure is unknown, it must be estimated from data. This empirical
estimation impacts the DRO learning process. Therefore, it is crucial to control the uniform conver-
gence error of the DRO problem between the true metric and distribution and the DRO estimated
from the data. The following theorem guarantees learning from sample data, but certain assumptions
need to be established first.
8Assumption 2 (i)Mis an unknown ANM, diam (V)<∞, and Θis a compact subset of Rd.
(ii)The loss function ℓis uniformly bounded: there exists a positive constant Msuch that
0≤ℓ(z, θ)≤Mfor all θ∈Θ. Moreover, ℓis Lipschitz with respect to the counterfactual
inM0; that is, there exists a constant Lsuch that:
|ℓ(v, y, θ )−ℓ(CF0(v,∆), y, θ)| ≤ ∥ℓ∥Lip).
(iii) ˆdis an estimation of the CFDF such that, with probability 1−ϵ, there exists Mdsuch that,
at a rate of N−η, the discrepancy is uniformly bounded by:
∀v, v′∈ V:|d(v, v′)−ˆd(v, v′)| ≤MdN−η,for some η >0.
The following theorem states that the efforts to estimate the metric or causal structures and the
parameter ˆθdro
N,
ˆθdro
N:= inf
θ∈Θ(
sup
Q:Wˆc,p(Q,PN)≤δE
z∼Q[ℓ(z, θ)])
Where ˆcis the ˆdcorresponding cost on Z, leading to the estimation of the true parameters of the
DRO problem. To state our result, we need the Dudley entropy integral [ 61], which measures the
complexity of the loss function class.
Theorem 5 (Learning Finite Sample Guarantee) With assumption 1 and 2, then for ˆθdro
Nwe have:
Rδ(P∗,ˆθdro
N)−inf
θ∈ΘRδ(P∗, θ)≤N−1/2h
c0+c1δ1−p+c2δ1−pN−η+1/2+c3p
log(2/ϵ)i
,
With probability at least 1−2ϵ. With C(L)denoting the Dudley entropy integral for the function
class{ℓ(·, θ) :θ∈Θ}, the constants c0,c1andc2are identified as follows:
c0:= 96C(L), c1:= 96L·diam (V)p, c2:= 2pL·diam (V)p−1·Md,andc3:= 2√
2×M.
The final theorem completes our framework, enabling us to perform DRO on real-world datasets
without knowing the SCM structures while providing performance bounds.
4.1 Related Works
Causally Fair Dissimilarity Function. Various studies have addressed the specification and learning
of individual fair metrics, such as [ 33,68,70,47], but their construction based on causal structure
and sensitive attributes remains unclear. Our work adopts and extends the concept of a causal fair
metric, as discussed in the works [23, 24].
DRO and Individual Fairness. Previous works, such as [ 68,70,47], address the DRO problem with
an individual fairness metric but are limited to linear SCMs and p= 2. These studies do not discuss
the duality theorem or regularizers. Additionally, [ 42] studied DRO, but its connection to causality
remains unclear.
Strong Duality Theorem. Various versions of the strong duality theorem have been explored in
prior works. For instance, in [ 59,46,9,14,27,28,66], the cost function must be a metric or [ 74]
has convex property. Additionally, in [ 72,11,58], the distance function dmust be positive-definite,
meaning d(v, v′) = 0 if and only if v=v′. However, these conditions are not met for CFDF,
necessitating a new formulation of the duality theorem 1.
DRO as Regularizer. Previous works on using DRO as a regularizer, explicitly solved [ 60,14,16,29]
or through k-order estimation [ 5,9,6,66,27], only consider cases where the cost function is derived
from a metric or a positive-definite dissimilarity function. Therefore, their theorems do not apply
directly to our CFDF. We present new results in Theorems 2, 3, and 4 tailored for our cases.
Finite Sample Guarantee. Various works provide bounds on the performance of DRO solutions
with finite samples [ 41,25,10,12], but these do not apply to our CFDF due to previously mentioned
reasons. The studies [ 68,70,47] offer performance bounds only for the case of linear SCMs with
p= 2. Therefore, we present a general case in Theorem 5.
Optimal Transport and Causality. Recent works [ 39,35,13,32,21,1,2] on causal optimal
transport focus on the causal structure of the transport map or plan, which differs from our problem.
In our case, causality pertains to the transportation cost derived from SCMs.
95 Numerical Studies
In our numerical studies, we evaluate the impact of using causally fair DRO to mitigate individual
unfairness, henceforth referred to as CDRO . We compare CDRO’s performance against Empirical
Risk Minimization (ERM), non-causal Adversarial Learning (AL) [ 44], and the Ross method [ 56].
Our experiments employ real-world datasets, namely the Adult [ 38] and COMPAS [ 65] datasets,
pre-processed according to [ 19]. Additionally, we use a synthetic dataset for linear SCM (LIN) with
formulations detailed in Appendix C.1. We first fit a linear structural equation model for both the
AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0%10%20%30%Unfair Area (D =0.05)LINSynthetic Data
AL
CDROERMROSS0%10%20%30%40%
AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0%20%40%60%80%AccuracyLINSynthetic Data
AL
CDROERMROSS0%20%40%60%
Figure 1: Displays the findings from our numerical experiment, assessing the performance of DRO across
different models and datasets. (left) Bar plot showing the comparison of models based on the unfair area
percentage (lower values are better) for ∆ =.05. (right) Bar plot comparing methods by prediction accuracy
performance (higher values are better).
Adult and COMPAS datasets. Logistic regression is employed for classification, and performance
is evaluated based on accuracy. Fairness is assessed using the Unfair Area Index (UAI), which is
defined by the following equation:
U∆:=P 
{v∈ V:∃v′∈ V s.t. d(v, v′)≤∆∧h(v)̸=h(v′)}
.
We evaluate UAI across different ∆values, specifically 0.05 and 0.01. Additionally, we calculate
the UAI for scenarios where no sensitive attributes are considered, representing the percentage of
non-robust data. Detailed computational experiment procedures are provided in Section C.1.
Our experiments, conducted using 100 different seeds, are summarized in Table 1. Figures 1, 2 and 3
illustrate that the CDRO method achieves a lower unfair area ( U∆) for∆ =.05, and ∆ = 0 .01in all
scenarios. Although CDRO shows slightly lower accuracy than ERM, this trade-off is a common
observation in several studies [52]. Additional results can be found in § C.6.
6 Discussion and Limitations
Our study introduces a novel framework for causally fair DRO, integrating causal structures and
sensitive attributes into the DRO paradigm. This framework is supported by several theoretical
advancements, including a strong duality theorem, explicit regularizer formulation, first-order regu-
larizer estimation, and finite sample guarantees with unknown SCMs, enhancing its efficiency and
practicality for real-world applications. Our experimental results demonstrate its effectiveness in
various settings, highlighting its potential for mitigating biases in machine learning models.
Despite the promising results, our study has several limitations that warrant further investigation.
Firstly, the assumption of an additive noise model may not capture the complexity of all real-
world causal relationships, posing challenges in computing additive interventions in general SCMs.
Secondly, while Theorem 2 and Theorem 3 could be extended to more general cases, we omitted these
extensions to avoid complexity. Lastly, further work is needed to explore the relationship between
our method and causal optimal transport [13, 32].
Acknowledgments
The authors thank the Max Planck Institute for Intelligent Systems, Tübingen AI Center, for supporting
this project. Partial funding support was also provided by the Canada CIFAR AI Chair program.
10References
[1]Beatrice Acciaio, Julio Backhoff-Veraguas, and Anastasiia Zalashko. Causal optimal transport
and its links to enlargement of filtrations and continuous-time stochastic optimization. Stochastic
Processes and their Applications , 130(5):2918–2953, 2020.
[2]Julio Backhoff, Mathias Beiglbock, Yiqing Lin, and Anastasiia Zalashko. Causal transport in
discrete time and applications. SIAM Journal on Optimization , 27(4):2528–2562, 2017.
[3]Ryan S Baker and Aaron Hawn. Algorithmic bias in education. International Journal of
Artificial Intelligence in Education , pages 1–41, 2022.
[4]Solon Barocas, Moritz Hardt, and Arvind Narayanan. Fairness and machine learning: Limita-
tions and opportunities . MIT Press, 2023.
[5]Daniel Bartl, Mathias Beiglböck, and Gudmund Pammer. The wasserstein space of stochastic
processes. arXiv preprint arXiv:2104.14245 , 2021.
[6]Robert Bartlett, Adair Morse, Richard Stanton, and Nancy Wallace. Consumer-lending discrim-
ination in the fintech era. Journal of Financial Economics , 143(1):30–56, 2022.
[7]Dimitris Bertsimas, David B Brown, and Constantine Caramanis. Theory and applications of
robust optimization. SIAM review , 53(3):464–501, 2011.
[8]Reuben Binns. On the apparent conflict between individual and group fairness. In Proceedings
of the 2020 conference on fairness, accountability, and transparency , pages 514–524, 2020.
[9]Jose Blanchet, Yang Kang, and Karthyek Murthy. Robust wasserstein profile inference and
applications to machine learning. Journal of Applied Probability , 56(3):830–857, 2019.
[10] Jose Blanchet, Jiajin Li, Sirui Lin, and Xuhui Zhang. Distributionally robust optimization and
robust statistics. arXiv preprint arXiv:2401.14655 , 2024.
[11] Jose Blanchet and Karthyek Murthy. Quantifying distributional model risk via optimal transport.
Mathematics of Operations Research , 44(2):565–600, 2019.
[12] Jose Blanchet, Karthyek Murthy, and Nian Si. Confidence regions in wasserstein distributionally
robust estimation. Biometrika , 109(2):295–315, 2022.
[13] Patrick Cheridito and Stephan Eckstein. Optimal transport and wasserstein distances for causal
models. arXiv preprint arXiv:2303.14085 , 2023.
[14] Hong Chu, Meixia Lin, and Kim-Chuan Toh. Wasserstein distributionally robust optimization
and its tractable regularization formulations. arXiv preprint arXiv:2402.03942 , 2024.
[15] Hong TM Chu, Kim-Chuan Toh, and Yangjing Zhang. On regularized square-root regression
problems: distributionally robust interpretation and fast computations. The Journal of Machine
Learning Research , 23(1):13885–13923, 2022.
[16] Hong TM Chu, Kim-Chuan Toh, and Yangjing Zhang. On regularized square-root regression
problems: distributionally robust interpretation and fast computations. Journal of Machine
Learning Research , 23(308):1–39, 2022.
[17] Zac Cranko, Zhan Shi, Xinhua Zhang, Richard Nock, and Simon Kornblith. Generalised Lips-
chitz regularisation equals distributional robustness. In International Conference on Machine
Learning , pages 2178–2188. PMLR, 2021.
[18] Jeffrey Dastin. Amazon scraps secret ai recruiting tool that showed bias against women. In
Ethics of data and analytics , pages 296–299. Auerbach Publications, 2022.
[19] Ricardo Dominguez-Olmedo, Amir H Karimi, and Bernhard Schölkopf. On the adversarial
robustness of causal algorithmic recourse. In International Conference on Machine Learning ,
pages 5324–5342. PMLR, 2022.
11[20] Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness
through awareness. In Proceedings of the 3rd innovations in theoretical computer science
conference , pages 214–226, 2012.
[21] Stephan Eckstein and Gudmund Pammer. Computational methods for adapted optimal transport.
The Annals of Applied Probability , 34(1A):675–713, 2024.
[22] Ahmad-Reza Ehyaei, Golnoosh Farnadi, and Samira Samadi. Causal fair metric: Bridging
causality, individual fairness, and adversarial robustness. arXiv preprint arXiv:2310.19391 ,
2023.
[23] Ahmad-Reza Ehyaei, Amir-Hossein Karimi, Bernhard Schölkopf, and Setareh Maghsudi.
Robustness implies fairness in causal algorithmic recourse. In Proceedings of the 2023 ACM
Conference on Fairness, Accountability, and Transparency , pages 984–1001, 2023.
[24] Ahmad-Reza Ehyaei, Kiarash Mohammadi, Amir-Hossein Karimi, Samira Samadi, and Gol-
noosh Farnadi. Causal adversarial perturbations for individual fairness and robustness in
heterogeneous data spaces. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 38, 10, pages 11847–11855, 2024.
[25] Rui Gao. Finite-sample guarantees for wasserstein distributionally robust optimization: Break-
ing the curse of dimensionality. Operations Research , 71(6):2291–2306, 2023.
[26] Rui Gao, Xi Chen, and Anton J Kleywegt. Wasserstein distributionally robust optimization and
variation regularization. arXiv preprint arXiv:1712.06050 , 2017.
[27] Rui Gao, Xi Chen, and Anton J Kleywegt. Wasserstein distributionally robust optimization and
variation regularization. Operations Research , 2022.
[28] Rui Gao and Anton Kleywegt. Distributionally robust stochastic optimization with wasserstein
distance. Mathematics of Operations Research , 48(2):603–655, 2023.
[29] Camilo Andrés García Trillos and Nicolás García Trillos. On the regularized risk of distribu-
tionally robust learning over deep neural networks. Research in the Mathematical Sciences ,
9(3):54, 2022.
[30] Milena A Gianfrancesco, Suzanne Tamang, Jinoos Yazdany, and Gabriela Schmajuk. Potential
biases in machine learning algorithms using electronic health record data. JAMA internal
medicine , 178(11):1544–1547, 2018.
[31] Melissa Hall, Laurens van der Maaten, Laura Gustafson, Maxwell Jones, and Aaron Adcock. A
systematic study of bias amplification. arXiv preprint arXiv:2201.11706 , 2022.
[32] Bingyan Han. Distributionally robust risk evaluation with a causality constraint and structural
information. arXiv preprint arXiv:2203.10571 , 2022.
[33] Christina Ilvento. Metric learning for individual fairness. In 1st Symposium on Foundations
of Responsible Computing (FORC 2020) . Schloss-Dagstuhl-Leibniz Zentrum für Informatik,
2020.
[34] Alexander Immer, Christoph Schultheiss, Julia E V ogt, Bernhard Schölkopf, Peter Bühlmann,
and Alexander Marx. On the identifiability and estimation of causal location-scale noise models.
arXiv preprint arXiv:2210.09054 , 2022.
[35] Yifan Jiang. Duality of causal distributionally robust optimization: the discrete-time case. arXiv
preprint arXiv:2401.16556 , 2024.
[36] Olav Kallenberg and Olav Kallenberg. Foundations of modern probability , volume 2. Springer,
1997.
[37] Amir-Hossein Karimi, Bernhard Schölkopf, and Isabel Valera. Algorithmic recourse: from
counterfactual explanations to interventions. In Proceedings of the 2021 ACM conference on
fairness, accountability, and transparency , pages 353–362, 2021.
12[38] Ronny Kohavi and Barry Becker. Uci adult data set. UCI Meachine Learning Repository , 5,
1996.
[39] Daniel Kršek and Gudmund Pammer. General duality and dual attainment for adapted transport.
arXiv preprint arXiv:2401.11958 , 2024.
[40] Matt J Kusner, Joshua Loftus, Chris Russell, and Ricardo Silva. Counterfactual fairness. In
Advances in Neural Information Processing Systems , pages 4069–4079, 2017.
[41] Jaeho Lee and Maxim Raginsky. Minimax statistical learning with wasserstein distances.
Advances in Neural Information Processing Systems , 31, 2018.
[42] Peizhao Li, Ethan Xia, and Hongfu Liu. Learning antidote data to individual unfairness. In
International Conference on Machine Learning , pages 20168–20181. PMLR, 2023.
[43] Fengming Lin, Xiaolei Fang, and Zheming Gao. Distributionally robust optimization: A review
on theory and applications. Numerical Algebra, Control and Optimization , 12(1):159–212,
2022.
[44] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 ,
2017.
[45] Ninareh Mehrabi, Fred Morstatter, Nripsuta Saxena, Kristina Lerman, and Aram Galstyan. A
survey on bias and fairness in machine learning. ACM computing surveys (CSUR) , 54(6):1–35,
2021.
[46] Peyman Mohajerin Esfahani and Daniel Kuhn. Data-driven distributionally robust optimization
using the wasserstein metric: Performance guarantees and tractable reformulations. Mathemati-
cal Programming , 171(1):115–166, 2018.
[47] Debarghya Mukherjee, Mikhail Yurochkin, Moulinath Banerjee, and Yuekai Sun. Two simple
ways to learn individual fairness metrics from data. In International Conference on Machine
Learning , pages 7097–7107. PMLR, 2020.
[48] James R Munkres. Topology, 2nd edn of [mr0464128], 2000.
[49] Razieh Nabi and Ilya Shpitser. Fair inference on outcomes. In Proceedings of the AAAI
Conference on Artificial Intelligence , volume 32, 1, 2018.
[50] Arash Nasr-Esfahany, Mohammad Alizadeh, and Devavrat Shah. Counterfactual identifiability
of bijective causal models. In International Conference on Machine Learning , pages 25733–
25754. PMLR, 2023.
[51] Judea Pearl. Causality: Models, Reasoning, and Inference . Cambridge University Press, 2009.
[52] Dana Pessach and Erez Shmueli. A review on fairness in machine learning. ACM Computing
Surveys (CSUR) , 55(3):1–44, 2022.
[53] Jonas Peters, Dominik Janzing, and Bernhard Schölkopf. Elements of causal inference: founda-
tions and learning algorithms . The MIT Press, 2017.
[54] Gabriel Peyré, Marco Cuturi, et al. Computational optimal transport. Center for Research in
Economics and Statistics Working Papers , 2017-86, 2017.
[55] Hamed Rahimian and Sanjay Mehrotra. Frameworks and results in distributionally robust
optimization. Open Journal of Mathematical Optimization , 3:1–85, 2022.
[56] Alexis Ross, Himabindu Lakkaraju, and Osbert Bastani. Learning models for actionable
recourse. Advances in Neural Information Processing Systems , 34:18734–18746, 2021.
[57] Anian Ruoss, Mislav Balunovic, Marc Fischer, and Martin Vechev. Learning certified individu-
ally fair representations. In Advances in Neural Information Processing Systems , 2020.
13[58] Soroosh Shafieezadeh-Abadeh, Liviu Aolaritei, Florian Dörfler, and Daniel Kuhn. New per-
spectives on regularization and computation in optimal transport-based distributionally robust
optimization. arXiv preprint arXiv:2303.03900 , 2023.
[59] Soroosh Shafieezadeh-Abadeh, Daniel Kuhn, and Peyman Mohajerin Esfahani. Regularization
via mass transportation. Journal of Machine Learning Research , 20(103):1–68, 2019.
[60] Soroosh Shafieezadeh Abadeh, Peyman M Mohajerin Esfahani, and Daniel Kuhn. Distribu-
tionally robust logistic regression. Advances in Neural Information Processing Systems , 28,
2015.
[61] Michel Talagrand. Upper and lower bounds for stochastic processes , volume 60. Springer,
2014.
[62] Peipei Tang, Chengjing Wang, Defeng Sun, and Kim-Chuan Toh. A sparse semismooth newton
based proximal majorization-minimization algorithm for nonconvex square-root-loss regression
problem. The Journal of Machine Learning Research , 21(1):9253–9290, 2020.
[63] Cédric Villani et al. Optimal transport: old and new , volume 338. Springer, 2009.
[64] Julius V on Kügelgen, Amir-Hossein Karimi, Umang Bhatt, Isabel Valera, Adrian Weller, and
Bernhard Schölkopf. On the fairness of causal algorithmic recourse. In Proceedings of the
AAAI conference on artificial intelligence , volume 36, 9, pages 9584–9594, 2022.
[65] Anne L Washington. How to argue with an algorithm: Lessons from the compas-propublica
debate. Colo. Tech. LJ , 17:131, 2018.
[66] Qinyu Wu, Jonathan Yu-Meng Li, and Tiantian Mao. On generalization and regularization via
wasserstein distributionally robust optimization. arXiv preprint arXiv:2212.05716 , 2022.
[67] Samuel Yeom and Matt Fredrikson. Individual fairness revisited: transferring techniques
from adversarial robustness. In Proceedings of the Twenty-Ninth International Conference on
International Joint Conferences on Artificial Intelligence , 2021.
[68] Mikhail Yurochkin, Amanda Bower, and Yuekai Sun. Training individually fair ml models with
sensitive subspace robustness. arXiv preprint arXiv:1907.00020 , 2019.
[69] Mikhail Yurochkin, Amanda Bower, and Yuekai Sun. Training individually fair ml models with
sensitive subspace robustness. In International Conference on Learning Representations , 2020.
[70] Mikhail Yurochkin and Yuekai Sun. Sensei: Sensitive set invariance for enforcing individual
fairness. In International Conference on Learning Representations , 2021.
[71] K Zhang and A Hyvärinen. On the identifiability of the post-nonlinear causal model. In 25th
Conference on Uncertainty in Artificial Intelligence (UAI 2009) , pages 647–655. AUAI Press,
2009.
[72] Luhao Zhang, Jincheng Yang, and Rui Gao. A simple and general duality proof for wasserstein
distributionally robust optimization. arXiv preprint arXiv:2205.00362 , 2022.
[73] Yangjing Zhang, Ning Zhang, Defeng Sun, and Kim-Chuan Toh. An efficient hessian based
algorithm for solving large-scale sparse group lasso problems. Mathematical Programming ,
179:223–263, 2020.
[74] Jianzhe Zhen, Daniel Kuhn, and Wolfram Wiesemann. A unified theory of robust and dis-
tributionally robust optimization via the primal-worst-equals-dual-best principle. Operations
Research , 2023.
14A Supplementary Theoretical Details
Notations. In this work random variables are denoted by bold letters (e.g., V), their corresponding
probability spaces by calligraphic letters (e.g., V), and instances by normal letters (e.g., v). The space
of probability measures on Vis represented by P(V)and probability measures by blackboard bold
letters (e.g., P).
Non-Sensitive Part. LetF:U → V be the reduced-form map of M. The vector vdecomposes
into sensitive and non-sensitive parts, v= (a, x), and we have a corresponding decomposition in the
exogenous space denoted by u= (ua, ux)andUA,UXare corresponding spaces. Using the ANM
model, we can assume that both VandUare equivalent, and therefore, the non-sensitive feature
space is the same as the non-sensitive part of the exogenous space. If Pis a probability measure in
P(V), then (P)Xrefers to the marginal probability over the non-sensitive part. We also refer to Q)X
for marginal probability over the non-sensitive part of the exogenous space.
Definition 3 (Push-forward Measure) LetP∈ P(V),Q∈ P(U)be two probability measures and
T:V → U is map, the measure Qis called the push-forward of Pthrough Tis denoted by T#Pif:
Q(B) =P(T−1(B)),∀B⊂ U
Definition 4 (Set of Couplings) The set Γ(P,Q)represents the couplings of probability distributions
P∈ P(V),Q∈ P(U), comprising distributions over V × U with margins PandQ. A measure π
belongs to Γ(P,Q)if and only if
π(A× U) =P(A)and π(V ×B) =Q(B)∀A⊂ V, B⊂ U
By extension, a random pair (X, Y)∼π, where π∈Γ(P,Q), will also be called a coupling of P
andQ.
Definition 5 (Diameter of a Set) LetAbe a set in a metric space with a distance function d. The
diameter ofA, denoted diam (A), is defined as:
diam(A) = sup {d(x, y) :x, y∈A}
where suprepresents the supremum of the set of distances d(x, y)for all pairs (x, y)inA.
Definition 6 (Homogeneous dissimilarity function) LetΛbe an extended-valued function
Λ:X → [0,∞]on a real vector space Xwith absolutely homogeneous assumption i.e. Λ(tx) =
|t|Λ(x)for any t∈Randz∈ X. In addition, Λis proper it means there exists x0∈ X such that
Λ(x0) = 1 . The cost function d:X × X → [0,∞]is called Homogeneous dissimilarity function if is
defined as d(x′, x):= Λ(x′−x)for any x′, x∈ X.
Lemma 1 IfMis an additive noise model with mutually independent exogenous variables, then the
parent-free sensitive M0attribute model retains both of these properties. Moreover, the map-reduced
form mapping of M0is equivalent to g−1, where grepresents the mapping to the semi-latent space.
Proof. First, M0is an additive noise model because its structure is derived from the initial equations
ofMby removing those equations related to the sensitive attributes and replacing the exogenous
variable UibyVi.
Regarding the mutual independence of the exogenous variables, in the original model M, the variables
Vifori∈ Iare not independent of Ujforj /∈ Iif they have parents. However, assuming a hard
intervention for each instance of Vi— where a do-action is executed for this intervention — it implies
that the intervened variable Vican be considered independent from the other variables. Therefore,
since we apply hard interventions to all sensitive variables, we can assume that Vifori∈ I are
mutually independent, and also that Viare independent of Ujfor all j /∈ I.
Finally, by referencing equations 6, it is observable that the map-reduced form mapping of M0is
equivalent to the inverse of the map to the semi-latent space.
Lemma 2 LetMbe an additive noise model with a mapping gto semi-latent space U0. Assume
Mincludes the sensitive attributes Aand other non-sensitive attributes Xthat belong to the vector
15spaceX. Consider v= (a, x)as an instance in M, and let ∆∈ X represent a shift intervention
value. Then, the counterfactual corresponding to additive shit is obtained by:
PX(CF(v,∆)) = PX(g−1(g(v) + (0 ,∆))).
Moreover, if a′∈ A represents another level of sensitive attributes, then the hard intervention
concerning A:=a′is achieved by:
¨va′=CF(v, do(A:=a′)) =g−1((a′, PX(g(v)))).
Proof. In additive noise models, an additive intervention can be conceptualized as adding a value δ
to the exogenous variables, while all structural equations remain unchanged. Consequently, during
such an intervention, the reduced-form mapping FM∆of the intervened SCM remains unchanged.
Therefore by definition of intervention, it follows that:
CF(v, do(X+=∆)) = FM∆(F−1(v) + (0 ,∆)) = F(F−1(v) + (0 ,∆)).
Since Fandg−1are coincide in non-sensitive coordinates then PX(ψ(F−1(v) + (0 ,∆))) =
PX(g−1(g(v) + (0 ,∆))) and it completes the first part. In this case, we denote FasM, which
is an invertible matrix. Consequently, the counterfactual CF(v, do(X+=∆)) can be expressed as
v+M−1(0,∆).
To prove the second part, when intervention is performed on sensitive attributes, Mtransforms into a
parent-free sensitive attribute model where the sensitive attribute ais replaced by a′. Given that the
map-reduced form of the parent-free sensitive attribute model aligns with g−1, and since gandF−1
coincide on the non-sensitive parts, the counterfactual can be expressed as follows:
¨va′=CF(v, do(A:=a′)) =g−1((a′, PX(g(v)))).
B Proof Section
Proof of Proposition 1.
(i) If dadheres to Eq. 7, it means that for each v∈ V , the mapping g(v) = ( a, x). For its
counterfactual ¨va, we have g(¨va′) = (a′, x). Using Eq. 7, we can express:
d(v,¨va) =dX(PX(g(v)), PX(g(¨va))) = dX(x, x) = 0
This demonstrates that dretains the first property of Def. 1.
Additionally, since dXis continuous, for each xand any ϵ >0, there exists a δ >0such that if
∥∆∥< δ, then dX(x, x+ ∆) < ϵ. Referencing Lemma 2 and the formulation of d, it follows that for
∥∆∥< δand for each a∈ A:
d(v,CF(v,∆)) = d(PX(g(v)), PX(g(CF(v,∆)))) = dX(x, x+ ∆) < ϵ
Thus, it satisfies property (ii) of the CFDF.
(ii) Let’s consider a CFDF denoted as d:V × V → R, with an embedding g:V → Q that
maps from the feature space to a semi-latent space. We define d∗as the pull-back of dontoQ,
d∗(q1, q2) =d(g−1(q1), g−1(q2))where d∗is a dissimilarity function, and we aim to clarify which
properties it inherits from Def. 1. We utilize a decomposition of QintoA × X , where q=g−1(v)
andv∈ V, denoting qas(a, x). Property (i) of the CFDF ensures:
d(v,¨va′) =d∗((a, x),(a′, x)) = 0 ∀a′∈ A
This property confirms that d∗is insensitive to changes in the sensitive part A. To demonstrate,
consider any two points q1= (a1, x1)andq2= (a2, x2), with an arbitrary a0∈ A. By triangle
property of dissimilarity function dit can be seen:
d∗((a1, x1),(a2, x2))≤d∗((a1, x1),(a0, x1)) +d∗((a0, x1),(a2, x2)) =⇒
d∗((a1, x1),(a2, x2))≤d∗((a0, x1),(a2, x2))
Here, d∗((s1, x1),(s0, x1))is zero due to property (i). Similarly, we can argue:
d∗((a0, x1),(a2, x2))≤d∗((a0, x1),(a1, x1)) +d∗((a1, x1),(a2, x2)) =⇒
d∗((a0, x1),(a2, x2))≤d∗((a1, x1),(a2, x2))
16This results in d∗((a1, x1),(a2, x2)) =d∗((a0, x1),(a2, x2)). With similar reasoning, we have:
d∗((a1, x1),(a2, x2)) =d∗((a1, x1),(a0, x2)) =⇒d∗((a1, x1),(a2, x2)) =d∗((a0, x1),(a0, x2))
Hence, d∗is invariant to the sensitive subspace. If dXis the dissimilarity function induced by d∗on
X, then d∗((a1, x1),(a2, x2)) =dX(x1, x2). In accordance with Lemma 2, the second property of
Def. 1 states that for each ϵ >0, there exists a δsuch that if |∆|< δ, then dX(x, x+ ∆) < ϵ. This
property demonstrates the continuity of dXalong the diagonal.
Finally, dcan be embedded in semi-latent space and described by another dissimilarity function on it
that only depends on the non-sensitive part of exogenous space:
d(v, w) =dX(PX(g(v)), PX(g(w)))
This concludes the proof.
Lemma 3 (Transformation by a Bijective Map) Letg:V → U be an invertible function and let
the transportation cost function cbe constructed by c(v, v′) =d(g(v), g(v′))where dis a metric on
the space U. For every P,Q∈ P(V), the following equation holds:
Wc,p(P,Q) =Wd,p(g#P, g#Q)
where WcandWdrepresent the Wasserstein distances with respect to the metrics candd, respectively.
Proof. By the definition of the Wasserstein distance,
Wc,p(P,Q) = inf
π∈Γ(P,Q)Z
V×Vcp(v, v′)dπ(v, v′).
Substituting c(v, v′) =d(g(v), g(v′))andu=g(v)gives:
Wc,p(P,Q) = inf
π∈Γ(P,Q)Z
V×Vdp(g(v), g(v′))dπ(v, v′).
Consider a coupling πofPandQ. Define a measure ˜πonU×U by˜π(A×B) =π(g−1(A)×g−1(B)).
˜πis a coupling of g#Pandg#Qbecause:
˜π(A× U) =π(g−1(A)× V) =g#P(A); ˜π(U ×B) =π(V ×g−1(B)) =g#Q(B).
Therefore, the p-Wasserstein distance for the push-forward measures is
inf
π∈Γ(P,Q)Z
V×Vdp(g(v), g(v′))dπ(v, v′) = inf
˜π∈Γ(g#P,g#Q)Z
U×Udp(u, u′)d˜π(u, u′)
=Wd,p(g#P, g#Q).
Since ˜πarises from πviag, and gis invertible and measure-preserving in this context, the values
in the integrals of the definitions of Wc,p(P,Q)andWd,p(g#P, g#Q)match. Thus, we have shown
thatWc,p(P,Q) =Wd,p(g#P, g#Q).
Lemma 4 (Optimal Transportation Cost on Subspace) LetU ⊆Rnand suppose Uis decom-
posed into two subspaces, U= (A,X), where Acorresponds to the subset of some coordinates and
Xto its complements. Let PXdenote the projection function onto the Xspace, i.e., PX(u)projects
u∈ U ontoXcomponents. Define a cost function c(u, u′) =d(PX(u), PX(u′)), where dis a cost
function on the space X. Consider probability measures P,Q∈ P(U), and define PX=PX#P
andQX=PX#Qas the pushforward measures of PandQunder the projection PX, respectively,
placing them in P(X). Letπ∗
Xbe the optimal transport plan concerning the Wasserstein distance
Wd(PX,QX). Then, any transport plan π∈ P(U × U ), whose marginal distribution over X × X
equals π∗
X, should also be an optimal solution for the Wasserstein distance Wc(P,Q)concerning the
cost function c.
Proof. Given any coupling π∈Γ(P,Q), we consider elements u= (a, x)andu′= (a′, x′)in
U=A × X . The cost function cis defined by c((a, x),(a′, x′)) =d(x, x′), where dis a metric on
17the space X. By definition of optimal transport cost Wc(P,Q)we have:
sup
π∈Γ(P,Q)Z
U×Uc((a, x),(a′, x′))dπ
= sup
π∈Γ(P,Q)Z
U×Ud(x, x′)dπ
=
sup
π∈Γ(P,Q)Z
X×XZ
A×Ad(x, x′)dπ((a, a′)|X=x,X′=x′)
d(π)X×X
=
sup
π∈Γ(P,Q)Z
X×Xd(x, x′)d(π)X×X
= sup
π∈Γ((P)X,(Q)X)Z
X×Xd(x, x′)π
where (P)Xand(π)X×X is marginal distribution over XandX × X respectively. π(.|X=x,X′=
x′)is conditional distribution of πcondition to the first and second Xcomponents equal to xandx′.
We observe that this integral effectively only depends on the Xcomponent since the cost function c
does not involve A. Hence, we reduce the expression to:
sup
π∈Γ((P)X,(Q)X)Z
X×Xd(x, x′)π
(11)
The Eq. 11 shows that the optima cost function of Wc(P,Q)equals to Wc((P)X,(Q)X). Therefore
ifπ∗
Xbe the optimal transport plan for PXtoQXwith respect to donX, then any coupling πin
U × U that its marginal distribution (π)X×X equals π∗
Xis the solution of optimal transport. It results
that the conditional distribution π((., .)|X=x,X′=x′)could be any distribution. This completes
the proof.
Lemma 5 LetXandAbe sets, and let f:X×A→Rbe a function. Then
sup
x∈Xsup
a∈Af(x, a) = sup
a∈Asup
x∈Xf(x, a).
Proof. Define:
L= sup
x∈Xsup
a∈Af(x, a)and R= sup
a∈Asup
x∈Xf(x, a).
To show that L=R, we need to prove that L≤RandR≤L. Consider any x∈Xanda∈A. By
definition, f(x, a)≤supa∈Af(x, a)for each fixed x. Therefore,
f(x, a)≤sup
a∈Af(x, a)≤sup
x∈Xsup
a∈Af(x, a) =R.
Since f(x, a)was arbitrary, we have:
sup
a∈Af(x, a)≤Rfor all x∈X,
and thus,
L= sup
x∈Xsup
a∈Af(x, a)≤R.
Similarly, for any fixed a∈A,f(x, a)≤supx∈Xf(x, a). Hence,
f(x, a)≤sup
x∈Xf(x, a)≤sup
a∈Asup
x∈Xf(x, a) =L.
As before, since f(x, a)was arbitrary, we conclude:
sup
x∈Xf(x, a)≤Lfor all a∈A,
and thus,
R= sup
a∈Asup
x∈Xf(x, a)≤L.
Since L≤RandR≤L, it follows that L=R. Therefore, we have proven that:
sup
x∈Xsup
a∈Af(x, a) = sup
a∈Asup
x∈Xf(x, a).
This demonstrates the Principle of the Iterated Suprema.
18B.1 Proof of Theorem 1.
We prove the assertion in two steps: first, we assume that none of the sensitive attributes have parents,
and second, we address and prove the general case. When all sensitive attributes do not have parents,
in this case by definition2 semi-latent space equivalent with exogenous space and therefore g=F−1.
First, we show that the worst-case loss quantity can be decomposed into sensitive and non-sensitive
components like as below equation:
sup
Q∈Bδ(P)
E
v∼Q[ψ(v)]
= sup
Q∈Bδ((F−1
#P)X)
E
ux∼Q
sup
ua∈UA{ψ(F((ua, ux)))}
. (12)
By the assumption, the CFDF has a form d(v, v′) =dX(PX(F−1(v)), PX(F−1(v′))). By Def. 2 in
a case that sensitive attributes have no parents then the semi-latent space coincides with exogenous
space and the map between feature space and semi-latent space equals g=F−1. Therefore in the
following equations, we use ginstead of F−1. Moreover since gis invertible by Lemma 3, we can
write:
sup
Q∈Bδ(P)
E
v′∼Q[ψ(v′)]
= sup
Q∈Bδ(g#P)
E
u′∼Q[ψ(F(u′))]
=
sup
π∈P(U×U )
E
u′∼π2[ψ(F(u′))]u∼g#P,E
(u,u′)∼π[˜dX(u, u′)]≤δ
=
sup
π∈P(U×U )
E
u′∼π2[ψ(F((u′
a, u′
x)))]u∼g#P,E
(u,u′)∼π[dX(ux, u′
x)]≤δ
=
sup
π∈P(U×U )Z
Uψ(F((u′
a, u′
x)))dπ2(u′)u∼g#P, E
(ux,u′x)∼πX×X[dX(ux, u′
x)]≤δ
=∗,
where ˜dbe a cost function on Udefined as ˜d(u, u′) =dX(PX(u), PX(u′)),π2denotes the marginal
distribution on second part and Bδ(g#P) ={Q∈ P(U) :W˜d(Q, g#P)≤δ}. Using the disintegra-
tion theorem ( [ 36] Chapter 3), the joint distribution π2can be decomposed into the product of the
conditional distribution of UAgivenUXand the marginal distribution on UX. Therefore we have
Z
Uψ(F((u′
a, u′
x)))dπ2(u′) =Z
UXZ
UAψ(F((ua, ux)))dπ2(u′
a|UX=u′
x)
dX(π2)X(u′
x),
where (π2)Xis the marginal distribution of π2over the non-sensitive part and π2(u′
a|UX=u′
x)
is a conditional distribution of the sensitive part of exogenous space condition by UX=u′
x. By
disintegration formula, (*) can be rewritten as:
sup
π2∈P(U)Z
Uψ(F((u′
a, u′
x)))dπ2(u′)π∈ P(U × U ), π1=g#P, E
(ux,u′x)∼(π)X×X[d(ux, u′
x)]≤δ
= sup
π2∈P(U)(Z
UXZ
UAψ(F(ua, ux))dπ2(u′
a|UX=u′
x)
dX(π2)X(u′
x)
π∈ P(U × U ), π1=g#P, E
(ux,u′x)∼(π)X×X[d(ux, u′
x)]≤δ)
= sup
(π2)X∈P(UX)(Z
UXsup
π2(.|UX=u′x)nZ
UAψ(F((u′
a, u′
x)))dπ2(u′
a|UX=u′
x)o
d(π2)X(u′
x)
π∈ P(U × U ), π2X= (g#P)X, E
(ux,u′x)∼(π)X×X[dX(ux, u′
x)]≤δ)
(13)
Since dXdepends only on the non-sensitive components, it follows from Lemma 4 that π2(.|UX=
u′
x)can achieve any distribution. Moreover, since it does not depend on the Wasserstein distance in
each coupling, the marginal distribution of the sensitive attribute can be considered independent of the
marginal distribution of the non-sensitive attributes. Therefore, the supremum over π2(.|UX=u′
x)of
integral equals the supremum of ψ(F((u′
a, u′
x)))over all values of u′
a. Furthermore, the distribution
19π2(u′
a|u′
x)does not influence the value of the Wasserstein distance. Based on these points, the last
equation can be rewritten as:
sup
π2∈P(UX)(Z
UXsup
u′a∈UAψ(F((u′
a, u′
x)))dπ2π∈ P(UX× UX),
π1= (g#P)X,E
(ux,u′x)∼π[d(ux, u′
x)]≤δ)
=
sup
π2∈P(UX)(
E
u′x∼π2"
sup
u′a∈UAψ(F((u′
a, u′
x)))#π∈ P(UX× UX),
π1= (g#P)X,E
(ux,u′x)∼π[d(ux, u′
x)]≤δ)
=
sup
Q∈Bδ((g#P)X)(
E
u′x∼Q"
sup
u′a∈UA{ψ(F((u′
a, u′
x)))}#)
.
The last equation concludes the proof of Eq. 12. Similarly, by altering the order of integration in
Eq. 13, we arrive at the following equation:
sup
Q∈Bδ(P)
E
v∼Q[ψ(v)]
= sup
ua∈UA(
sup
Q∈Bδ((g#P)X)
E
ux∼Q[ψ(F((ua, ux)))])
. (14)
To proceed with the proof, we utilize the strong duality theorem. There are various kinds of duality
theorems for DRO, but we apply the one proposed by Blanchet et al. [11].
Strong duality [ 11].Suppose the transportation cost c:Z × Z → [0,∞]satisfies c(z, z) = 0 for
allz∈ Z and lower semi-continuous. Then for any reference probability distribution Pand upper
semi-continuous ψ:Z →Rsatisfying E
P[f(Z)]<∞, we have
sup
Q∈Bδ(P)E
Q[ψ(Z)] = inf
λ≥0λδ+E
P[ψλ(Z)], (15)
where ψλ(z):= supz′∈Z{ψ(z′)−λc(z, z′)}.
Based on the assumption about the CFDF, where only d(v,¨va′) = 0 , it follows that d(x, x′) = 0 only
ifx=x′. Therefore, we can apply the duality theorem to Eq. 12. According to the duality theorem,
it can be expressed as follows:
sup
ua∈UA(
sup
Q∈Bδ((g#P)X)
E
ux∼Q[ψ(F((ua, ux)))])
= inf
λ≥0
λδ+ E
ux∼(g#P)X[ηλ(ux)]
(16)
where ηλ(ux) = supu′x∈UX
supua∈UA{ψ(F((ua, u′
x))} −λdX(ux, u′
x)	
. By using lemma 5
supu′
x∈UX
supua∈UA{ψ(F((ua, u′
x))}	
= supua∈UAn
supu′
x∈UX{ψ(F((ua, u′
x))}o
.
Now, since sensitive attributes don’t have parents then two spaces UAandAare equal. By applying
Lemma 2, we can replace the above equation with hard and soft interventions as follows:
ηλ(ux) = sup
a∈A(
sup
u′x∈UX{ψ(F((a, u′
x)))−λdX(ux, u′
x)})
=
sup
a∈A
sup
∆∈UX{ψ(F((a, ux+ ∆))) −λdX(ux, ux+ ∆)}
=
sup
a∈A
sup
∆∈UXψ(F((a, ux+ ∆))) −λdX(PX((a, ux)), PX((a, ux+ ∆)))
=
sup
a∈A
sup
∆∈UXψ(F((a, ux+ ∆))) −λdX(PX(g−1(g((a, ux)))), PX(g−1(g((a, ux+ ∆)))))
=
sup
a∈A
sup
∆∈UXψ(CF(¨va,∆))−λc(¨va,CF(¨va,∆))
= sup
a∈An
˜ψλ(¨va)o
(17)
20Where ˜ψλ(¨va) := sup∆∈UXψ(CF(¨va,∆))−λd(¨va,CF(¨va,∆)). The equations F((a, ux+ ∆)) =
CF(v,∆)andF((a′, ux+∆)) = CF(¨va′,∆)hold true according to Lemma 2. Finally, by substituting
¨va=CF(v, a)into the equation, we prove the equation:
sup
Q∈Bδ(P)
E
v∼Q[ψ(v)]
= inf
λ≥0
λδp+E
v∼P
sup
a∈Aψλ(¨va)
,
where ψλ(v)is defined as
ψλ(v):= sup
∆∈X{ψ(CF0(v,∆))−λpd(v,CF0(v,∆))},
Since, in this case, CFis equivalent to CF0, this completes the proof for case one.
Now consider the scenario where sensitive attributes have parents. Eq. 17 shows in strong duality
computation it needs to compute function in intervened Mconcerning the sensitive attributes levels.
In this case, instead of using the structural causal model M, it is sufficient to employ the parent-free
sensitive attribute SCM (Def. 2), M0.M0aligns with the semi-latent space and is compatible with
the representation form outlined in Proposition 1. By adopting this strategy, we transform Minto a
model where sensitive attributes do not have parents. The proof procedure for M0remains the same
as forMand completes the proof.
Lemma 6 Let(Z, c)be a space with cost function c,PNan empirical probability measure based on
observations {zi}N
i=1, and define Qas:
Q=PN−1
Nδz1+1
Nδz′
1
where δz1andδz′
1are Dirac measures at z1andz′
1, respectively. Then, the p-Wasserstein distance
between PNandQis given by:
Wc,p(PN,Q) = (1
N)1
pc(z1, z′
1).
Proof. The definition of the p-Wasserstein distance between two probability measures PNandQis:
Wc,p(PN,Q) =
inf
π∈Γ(PN,Q)Z
Z×Zc(z, z′)pdπ(z, z′)1
p
,
where Γ(PN,Q)represents the set of all couplings of PNandQ. Since Qis obtained by transferring
a mass of1
Nfromz1toz′
1, the optimal transport plan under the constraint that PNandQdiffer only
at two points involves only moving the mass1
Nfrom z1toz′
1. The cost of this transportation is
c(z1, z′
1)p, and because the entire mass1
Nis being moved:
Z
Z×Zc(z, z′)pdπ(z, z′) =c(z1, z′
1)p·1
N.
Therefore, substituting this into the formula for Wp, we obtain:
Wc,p(PN,Q) =
c(z1, z′
1)p·1
N1
p
=1
N1
p
c(z1, z′
1),
thus proving the lemma.
Lemma 7 Assume that f(a, x)is convex in xfor each fixed aand continuous in both aandx. Also,
assume fis uniformly continuous in xacross a. IfAis compact, then the function defined by
g(x) = sup
a∈Af(a, x)
is convex and continuous in x.
21Proof. To show that g(x)is convex, consider any x1, x2in the domain and λ∈[0,1]. By the
definition of supremum and the convexity of f(a, x)inx,
f(a, λx 1+ (1−λ)x2)≤λf(a, x1) + (1 −λ)f(a, x2).
Taking the supremum over ainAon both sides, we get:
sup
a∈Af(a, λx 1+ (1−λ)x2)≤sup
a∈A(λf(a, x1) + (1 −λ)f(a, x2)).
Using the properties of supremum,
sup
a∈Af(a, λx 1+ (1−λ)x2)≤λsup
a∈Af(a, x1) + (1 −λ) sup
a∈Af(a, x2).
Thus,
g(λx1+ (1−λ)x2)≤λg(x1) + (1 −λ)g(x2),
proving that g(x)is convex.
To show continuity of g(x)at a point x0, consider any sequence {xn}converging to x0. Since fis
uniformly continuous in x, given ϵ >0, there exists δ >0such that for all x, ywith|x−y|< δ,
|f(a, x)−f(a, y)|< ϵ for all a∈A.
Thus,
f(a, xn)< f(a, x0) +ϵand f(a, x0)< f(a, xn) +ϵfor all a∈Aand|xn−x0|< δ.
Taking the supremum over ainA,
g(xn)≤g(x0) +ϵand g(x0)≤g(xn) +ϵ.
This implies
|g(xn)−g(x0)| ≤ϵ,
establishing the continuity of g(x)atx0.
Hence, we conclude that supa∈Af(a, x)is convex and continuous in x.
B.2 Proof of Theorem 2.
Let’s consider the ℓ(v, y, θ ) =h(Y− ⟨θ,V⟩)(or in abbreviation ℓ(y)) orh(Y· ⟨θ,V⟩)where
h:R→Rhas one of the forms |t|,max(0 , t),|t−τ|, ormax(0 , t−τ)for some τ≥0
First consider the case diam (A) =∞. By property of CFDF for each Since the distance of vby
its twins ¨vais zero.Let z∈ {zi}IfPNthe empirical distribution by lemma 6 it can be seen for
observation Z= (v, y)the distribution
Qa=PN−1
Nδz+1
Nδ(¨va,y1)=⇒Wc,p(Qa,PN) = 0 = ⇒Qa∈Bδ(PN).
This equation results that
Rδ(PN, θ)≥sup
a∈ARδ(Qa, θ)≥ R(PN, θ)−1
Nℓ(v1) +1
Nsup
a∈Aℓ(¨va)| ≥1
Nsup
a∈Aℓ(¨va)|
Letu= (uA, uX)such that v=Mu. By definition of hard intervention ¨vais obtained by the
formula
¨va= (M−Mpa)×(u−(0, . . . ,:=αz}|{
a−uA, . . . , 0)T)
=M×u−
 :MA×α
M×(0, . . . , α, . . . , 0)− :CMpa×u+
 :0
Mpa×(0, . . . , α, . . . , 0)
=v−MA×α−C
22where Mparefers to the effect of parents of sensitive variables and MAis the columns of matrix M
related to sensitive attributes that show the effects of sensitive attributes on non-sensitive variables.
By substituting that last equation in the loss function we have:
Rδ(PN, θ)≥1
Nsup
a∈Aℓ(v−MA×α−C)≥1
Nsup
α→∞O(θTMA×α)
where Bis some constant value. with the assumptions about loss function, all of them by choosing
proper z1, its behavior when αis large enough is linear so can be approximated by its input value.
Now Since the diam (A) =∞therefore the value of αgoes to the infinity. Therefore to prevent the
value of Rδ(PN, θ)it needs that the expression θTMA×α= 0 in the other word the PA(MTθ)
needs to be zero. This condition implies that for all a∈ A we have ℓ(v) =ℓ(¨va). By using strong
duality 8 we have:
sup
Q∈Bδ(P)
E
v∼Q[ℓ(v)]
= inf
λ≥0
λδ+E
v∼P
sup
a∈Aℓλ(¨va)
= inf
λ≥0n
λδ+E
v∼P[ℓλ(v)]o
, (18)
where
ℓλ(v) = sup
∆∈X{ℓ(CF(v,∆))−λd(v,CF(v,∆))}=
sup
∆∈Xh(θTM0((ua, ux+ ∆))) −λdX(ux, ux+ ∆) =
sup
∆∈Xh(PX(MTθ)T(ux+ ∆)) −λdX(ux, ux+ ∆) =
sup
∆∈Xh(⟨θ0, ux+ ∆⟩)−λ∥∆∥=hλ(ux) (19)
In the equation 19, M0is reduced-form mapping of the parent-free sensitive attribute M0. By the
definition it is easy in both SCM, the effect of the sensitive attributes is equal therefore PA(MT
0θ) =
PA(MTθ) = 0 . Moreover since in M0the structure of non-sensitive attribute has not changed then
PX(MT
0θ) =PX(MTθ). Finally, by substituting θ0=PX(MTθ), it can be seen that the problem
of finding worst-case loss quantity converts to the regular problem in space X. This problem was
solved previously in works of [ 14,58,25,66]. By using Theorem 3.2 and 3.3 and Proposition 4.1
and 4.2, of work by Chu et al. [14], we can write
inf
λ≥0
λδ+E
v∼PN[ℓλ(v)]
= inf
λ≥0
λδ+ E
ux∼(g#PN)X[hλ(ux)]
=

R((g#PN)X, θ0)1
p+δ∥θ0∥∗p
=
R(PN, θ)1
p+δPX(MTθ)
∗p
The equality R((g#PN)X, θ0) =R(PN, θ)holds by definition and property PA(MTθ) = 0 . The
last equation completes the proof of the first case.
Now let’s consider the case that diam (A)<∞.
Case: p∈(1,∞).Lets consider Eq. 16 it implies that:
Rδ(P) = inf
λ≥0
λδ+ E
ux∼(g#P)Xh
˜ℓλ(ux)i
(20)
where, ˜ℓ(ux) = supua∈UA{ℓ(M(ua, u′
x)}andηλ(ux) = sup∆∈UX˜ℓ(ux+∆)−λdX(ux, ux+∆)}.
By assumption, the whole type of loss functions are form h(⟨θ, v⟩)and convex and continuous. h
can be written by Min the form h(⟨θ, M(ua, ux)⟩). Then ˜ℓ(ux) = supua∈UAh(PA(MTθ)ua+
PX(MTθ)ux). Since all forms of function are uniformly continuous concerning the uxthen lemma 7
implies that the ˜ℓ(ux)is still continuous and convex. Theorem 6 and 7 of work [66] states that:
Theorem. [ 66]Letℓ:R→Rbe a non-negative, Lipschitz continuous and convex function. For an
integer p∈(1,∞), suppose that for any P∈ P(X), and ϵ≥0, we have:
sup
Q∈Bδ(P)Ex∼Q[ℓp(θTx)] = 
Ex∼P[ℓp(θTx)]1/p+δ∥θ∥∗p
.
23By applying above theorem in Eq. 20 it can be seen:
Rδ(P) =
Eux∼(g#P)X[˜ℓp(ux)]1/p
+δPX(MTθ)
∗p
=
 
Ev∼P[sup
a∈Aℓp(¨va)]1/p
+δPX(MTθ)
∗!p
Case: p= 1.To complete the proof we use Theorem 2 and Corollary 2 of Gao et al. work [27].
Theorem [ 27]Ifℓis Lipschitz |ℓ(x1)−ℓ(x2)| ≤L∥xk−x0∥and satisfies tightness at infinity, i.e.
for every v0there exists sequence {vk}∞
k=1∈ V such that ∥xk−x0∥ → ∞ we have:
lim
∥xk−x0∥→∞|ℓ(xk)−ℓ(x0)|
∥xk−x0∥=L (21)
then we have Rδ(P) =R(P) +δ.L.
Now back to the Eq. 20. It is necessary to show that ˜ℓsatisfies the Gao’s theorem. Let h(t)be one
of the functions |t|,(t−τ)+,(|t| −τ)+. All of loss function can be written as form h(y− ⟨θ, v⟩)
orh(y.⟨θ, v⟩). It is easy to check that his Lipschitz with constant 1 and there exist tksuch that for
eacht0we have limk→∞|h(t0+tk)−h(t0)|
|tk|= 1.
To use this theorem for ˜ℓ, we need to prove that ˜ℓis Lipschitz and has a tightness condition at infinity.
Since the his Lipschitz we know that:
∀ua∈ UA:|h(PA(MTθ)ua+PX(MTθ)ux)−h(PA(MTθ)ua+PX(MTθ)u′
x)| ≤
|PX(MTθ)(ux−u′
x)| ≤PX(MTθ)
∗∥ux−u′
x∥ ⇒
sup
ua∈UA|h(PA(MTθ)ua+PX(MTθ)ux)−h(PA(MTθ)ua+PX(MTθ)u′
x)|
sup
ua∈UA|h(PA(MTθ)ua+PX(MTθ)ux)−h(PA(MTθ)ua+PX(MTθ)u′
x)|=
|sup
ua∈UAh(PA(MTθ)ua+PX(MTθ)ux)−sup
ua∈UAh(PA(MTθ)ua+PX(MTθ)u′
x)|=
|˜ℓ(ux)−˜ℓ(u′
x)| ≤PX(MTθ)
∗∥ux−u′
x∥ ⇒ ˜ℓis Lipbschitz.
To satisfy the condition of Gao’s theorem, it remains to show for u0
xthere exists sequence {uk
x}∞
k=1
such that lim
∥ukx−u0x∥→∞|˜ℓ(uk
x)−˜ℓ(u0
x)|
∥ukx−u0x∥=LTo prove it we consider that for function hthere exists
sequence such that limk→∞|h(t0+tk)−h(t0)|
|tk|= 1. consider the specific point u0
xandua∈ UA.
Lets define t0=PA(MTθ)ua+PX(MTθ)u0
x. Then there exists tkthat satisfies infinity tightness.
Therefore there exist ∆k∈ UXsuch that PX(MTθ)uk
x−PX(MTθ)u0
x=tktherefore it can be
written:
1 =limk→∞|h(t0+tk)−h(t0)|
|tk|=
limk→∞|h(PA(MTθ)ua+PX(MTθ)uk
x)−h(PA(MTθ)ua+PX(MTθ)u0
x)|
|PX(MTθ)ukx|⇒
limk→∞|h(MTθ(ua, uk
x))−h(MTθ(ua, u0
x)|
∥ukx∥=PX(MTθ)
∗⇒
sup
ua∈UA
limk→∞|h(MTθ(ua, uk
x))−h(MTθ(ua, u0
x)|
∥ukx∥
=PX(MTθ)
∗⇒
limk→∞ sup
ua∈UA|h(MTθ(ua, uk
x))−h(MTθ(ua, u0
x)|
∥ukx∥
=PX(MTθ)
∗⇒
limk→∞|˜ℓ(uk
x)−˜ℓ(u0
x)|
∥ukx∥=PX(MTθ)
∗
24In the above equation, since we have uniform convergence, we can change the limit and supremum.
The last equation shows that there exits sequence of {uk
x}∞
k=1satisfies tightness condition in ∞. By
applying Gao’s theorem we have:
Rδ(P) =Eux∼(g#P)X[˜ℓ(ux)] +δPX(MTθ)
∗=Ev∼P[sup
a∈Aℓp(¨va)] +δPX(MTθ)
∗
The last equation completes the proof.
B.3 Proof of Theorem 3.
The case diam (A) =∞corresponds exactly to the first part of the proof of Theorem 2, with the only
difference being that in that theorem we have ∥h∥Lip= 1, while in this case, we have ∥h∥Lip=Lh.
Therefore we have the below equation:
Rδ(P) =R(P) +LhPX(MTθ)
∗
Now consider the case diam (A)<∞. To prove our assertion, we use Eq. 16 and it implies that:
Rδ(P) = inf
λ≥0
λδ+ E
ux∼(g#P)Xh
˜ℓλ(ux)i
where, ˜ℓ(ux) = supua∈UA{ℓ(M(ua, u′
x)}andηλ(ux) = sup∆∈UX˜ℓ(ux+∆)−λdX(ux, ux+∆)}.
To compute the right side of the above equation, we use the theorem 3.2 of work [14] that states.
Theorem [ 14].LetZN:={z1, . . . , z n} ⊂ Z be a given dataset and PNbe the corresponding
empirical distribution. In addition, let c(·,·)be a cost function on Z × Z andδ∈(0,∞)be a scalar.
Suppose the loss function ℓ:Z ×Θ→R, where satisfies the following assumptions:
(A1) ℓis Lipschitz respect o the cost function dat setZNwithLZN
θ∈(0,∞);
(A2) for any ϵ∈(0, LZN
θ)and each zi∈ ZN, there exists ˜zi∈ Z such that δ≤d(˜zi, zi)<∞
and
ℓ(˜zi)−ℓ(zi)≥(LZN
θ−ϵ)c(˜zi, zi).
Then we have:
sup
P:Wd,1(Q,PN)≤δEQ[ℓ(Z, θ)] = E PN[ℓ(Z, θ)] +LZN
θδ.
To use the above theorem we need that ˜ℓsatisfies conditions (A1) and (A2).
A1. To prove the Lipschitz condition it can be seen:
∀ua∈ UX:|h(y−θTM(ua, ux))−h(y−θTM(ua, u′
x))|
≤Lh|PX(MTθ)(ua−u′
a)| ≤LhPX(MTθ)
∗∥ua−u′
a∥ ⇒
sup
ua∈UX|h(y−θTM(ua, ux))−h(y−θTM(ua, u′
x))|=
|˜ℓ(ua)−˜ℓ(u′
x)| ≤LhPX(MTθ)
∗∥ux−u′
x∥
The case h(y.⟨θ, y⟩)is similar so we omit it.
A2. To check that ˜ℓsatisfies (A2) condition we show that there exists sequence {∆k}such that the
∥∆k∥ → ∞ for every v∈ V and sequence vk=CF(v,∆k)and we have:
limk→∞|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
d(vk, v)=Lh.PX(MTθ)
∗(22)
By assumption about hwe have: For each t0∈Rthere exists sequence of {tk}∞
k=1goes to
∞thenlimk→∞|h(t0+tk)−h(t0)|
|tk|=Lh. By changing variable v=M(ua, ux). Let t0=
25y−θTM(ua, ux)and∆k∈ X such that PX(MTθ)∆k=tkit is clear ∆kexist. No if we define
vk=CF(v,∆k)we have:
Lh=limk→∞|h(t0+tk)−h(t0)|
|tk|=
limk→∞|h(y−θTM(ua, ux) +PX(MTθ)∆k)−h(y−θTM(ua, ux))|
|PX(MTθ)∆k|=
limk→∞|h(y−θTM(ua, ux+ ∆ k))−h(y−θTM(ua, ux))|
|PX(MTθ)∆k|=
limk→∞|h(y−θTvk)−h(y−θTv)|
∥PX(MTθ)∥∗∥∆k∥=limk→∞|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
∥PX(MTθ)∥∗d(vk, v)
=⇒limk→∞|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
d(vk, v)=PX(MTθ)
∗.Lh
The Last equation is valid because, by Holder inequality, there exists ∆such that for all λ∆the
Holder inequality converts to equality. Now it is sufficient that find proper λsuch that λk=
tk/PX(MTθ)∆
∗so by define ∆k=λk∆we find sequence that holds the assertion.
The case of h(y.⟨θ, v⟩is similar. By discussion of the first part, we can find ∆k. Now since we have
binary classification, so y∈ {− 1,1}we define ˜∆k=sign(y)∆ktherefore for such ∆k, we have
y.PX(MTθ)˜∆k) =tk. By assumption, it can be written as:
Lh=limk→∞|h(t0+tk)−h(t0)|
|tk|=
limk→∞|h(y.θTM(ua, ux) +y.PX(MTθ)˜∆k)−h(y.θTM(ua, ux))|
|PX(MTθ)˜∆k|=
limk→∞|h(y.θTM(ua, ux) +y.PX(MTθ)∆k)−h(y.θTM(ua, ux))|
|PX(MTθ)∆k|=
limk→∞|h(y.θTM(ua, ux+ ∆ k))−h(y.θTM(ua, ux))|
|PX(MTθ)∆k|=
limk→∞|h(y.θTvk)−h(y.θTv)|
∥PX(MTθ)∥∗∥∆k∥=limk→∞|h(y.⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
∥PX(MTθ)∥∗d(vk, v)
=⇒limk→∞|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
d(vk, v)=PX(MTθ)
∗.Lh
Letℓ(v) =h(y−PX(MTθ)ux−PA(MTθ)ua). By assumption his Lipschitz so it ℓis Lipschitz
concerning each uxanduaandUAis bounded so it is compact. Then these properties imply uniformly
continuous so we have:
sup
ua∈UAlimk→∞|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
d(vk, v)=
limk→∞ sup
ua∈UA|h(y− ⟨θ, vk⟩)−h(y− ⟨θ, v⟩)|
d(vk, v)=limk→∞|˜ℓ(ux)−˜ℓ(∆k)|
∥ux−∆k∥=PX(MTθ)
∗.Lh
The last equation satisfies the ( A2) condition because since limk→∞|˜ℓ(ux)−˜ℓ(∆k)|
∥ux−∆k∥=
PX(MTθ)
∗.Lhin other hand we have |˜ℓ(ua)−˜ℓ(u′
x)| ≤LhPX(MTθ)
∗∥ux−u′
x∥, then for
eachϵthere exist ∆ksuch that |˜ℓ(ux)−˜ℓ(∆k)|>(LhPX(MTθ)
∗∥ux−∆k∥ −ϵ)∥ux−∆k∥
Now we can use Chu’s Theorem and it implies that: Rδ(P) =Rcf(P) +LhPX(MTθ)
∗. The
classification case is the same and it completes the proof.
26B.4 Proof of Theorem 4.
Let’s prove the necessary condition. By first part proof of theorem 2, we have
Rδ(PN, θ)≥1
Nsup
a∈Aℓ(¨va, y, θ).
Therefore, for a finite solution to exist for the DRO problem, it is necessary that:
sup
a∈Aℓ(¨va, y, θ)<∞.
To prove Eq. 10, we use again some parts of the proof of strong duality theorem1 and idea of proof of
theorem 9.1 of Garcia’s work [29]. It states:
Rδ(PN) = sup
Q∈Bδ(PN)
E
v∼Q[ℓ(v′, y, θ)]
= sup
Qx∈Bδ((g#PN)X)
Qa∈P(A)

E
u′
x∼Qx
u′
a∼Qa
ℓ 
g−1((u′
a, u′
x)), y, θ,


where by discussion in lemma 4, we can suppose that QxandQaare independent of each other.
For simplicity, we define J(ux, ua, θ) =ℓ(g−1((ua, ux)), y, θ). By assumption, since the fis twice
differentiable, then (I−f)−1is also twice differentiable. Because the function gis obtained by
I−fby removing the functional structure of sensitive attributes and is a set identity function instead
of them, there are two functions gandg−1. These results show that combination ℓ(g−1)is also twice
differentiable, so the gradient of Jexists concerning the ux. By using Taylor’s expansion theorem if
f:R→Ris the function that has gradient then the first order estimation of fequals:
f(x+h) =f(x) +∇f(x)⊤h+Z1
0(∇f(x+th)− ∇f(x))⊤h dt.
Letux∼(g#P)Xby writing Taylor’s expansion around uxwe have:
E[J(u′
x, u′
a, θ)] =E[J(ux, u′
a, θ) +∇xJ(ux, u′
a, θ)·(u′
x−ux)
+Z1
0{∇xJ(ux+λ(u′
x−ux), u′
a, θ)− ∇ xJ(ux, u′
a, θ)} ·(u′
x−ux)dλ
.
Since the diam (U)<∞we can suppose that the space Uis compact. By assumption Jis twice
differentiable, so ∇xJ(., ua, θ)is Lipschitz with constant ∥∇xJ(., ua, θ)∥Lipthat there exist L <∞
such that ∥∇xJ(., ua, θ)∥Lip≤L. By these assumptions, it can be written:
EZ1
0{∇xJ(ux+λ(u′
x−ux), u′
a, θ)− ∇ xJ(ux, u′
a, θ)} ·(u′
x−ux)dλ
≤
EZ1
0∥∇xJ(ux+λ(u′
x−ux), u′
a, θ)− ∇ xJ(ux, u′
a, θ)∥∥u′
x−ux∥2
edλ
=
EZ1
0∥∇xJ(., u′
a, θ)∥Lip∥u′
x−ux∥2
edλ
=E1
2∥∇xJ(., u′
a, θ)∥Lip∥u′
x−ux∥2
e
≤
C
2∥∇xJ(., u′
a, θ)∥LipE
∥u′
x−ux∥2
≤CL
2E
∥u′
x−ux∥2
≤O(δ2),
where Cis a constant that arises from the equivalence of norms in Rd, it means that there
exists C∥.∥e≤C∥.∥. The inequality E
∥u′
x−ux∥2
≤δ2is valid because by definition
Qx∈Bδ((g#PN)X)and the cost function in the space UXis expressed by the ∥u′
x−ux∥so
by definition of Bδ((g#PN)X), forp≥2by applying Jensen’s inequality we have
Qx∈Bδ((g#PN)X)⇒EQx[∥u′
x−ux∥p]1
p≤δ⇒
EQx
∥u′
x−ux∥2
≤EQx[∥u′
x−ux∥p]2
p≤δ2.
Since by assumption ∇Jxis uniformly Lipschitz for different value of θanduatherefore we have:
Rδ(PN) = sup
Qx∈Bδ((g#PN)X)
Qa∈P(A)n
E[J(ux, u′
a, θ) +∇xJ(ux, u′
a, θ)·(u′
x−ux)]o
+O(δ2),
27forO(δ2)independent of θandua. The first expression of the above equation has the simple form:
sup
Qa∈P(UA)

E
ux∼(g#PN)X
u′
a∼Qa[J(ux, u′
a, θ)]

= E
ux∼(g#PN)X"
sup
Qa∈P(UA)
E
u′a∼Qa[J(ux, u′
a, θ)]#
=
E
ux∼(g#PN)X"
sup
u′
a∈UA{J(ux, u′
a, θ)}#
= E
ux∼(g#PN)X"
sup
u′a∈UA
ℓ(g−1((ux, u′
a)), y, θ)	#
=
E
v∼PN
sup
a∈Aℓ(¨va, y, θ)
The only term in the above equation that still depends on the Qis that term ∇xJ(ux, u′
a, θ)·(u′
x−ux).
To remove this term we use extended Hölder inequality with the expectation that can be expressed
using the following formula:
E[|XY|]≤(E[|X|p])1
p(E[|Y|q])1
q,
and equality holds if and only if there exist constants c≥0such that:
|Y|=c|X|p
qalmost surely , c≥0.
. By using Hölder inequality, with the same reasoning we have:
sup
Qx∈Bδ((g#PN)X)
Qa∈P(A)

E
u′
x∼Qx
u′
a∼Qa[∇xJ(ux, u′
a, θ)·(u′
x−ux)]

=
sup
Qx∈Bδ((g#PN)X)(
E
u′
x∼Qx[ sup
u′a∈UA{∇xJ(ux, u′
a, θ)·(u′
x−ux)}])
=
 
E
ux∼(g#PN)X[ sup
u′a∈UA{∥∇ xJ(ux, u′
a, θ)∥q
∗}]!1
q
sup
Qx∈Bδ((g#PN)X)


 E
u′
x∼Qx
ux∼(g#PN)X[∥u′
x−ux∥p]
1
p


=δ 
E
ux∼(g#PN)X[ sup
u′a∈UA{∥∇ xJ(ux, u′
a, θ)∥q
∗}]!1
p
where equality can be attained whenever 1≤p≤ ∞ for a proper choice of u′
x−uxwith
(E[∥u′
x−ux∥p])1/p=δ. Therefore,
Rδ(PN) =E
v∼PN
sup
a∈Aℓ(¨va, y, θ)
+δ
E
v∼PN[sup
a∈A{∥∇CFℓ(¨v, y, θ )∥q
∗}]1/q
+O(δ2)
where
∇CFℓ(v, y, θ ) = lim
∆→0ℓ(CF0(v,∆))−f(v)
∥∆∥
the last equation completes the proofs.
B.5 Proof of Proposition 2.
By Eq. 16 we have:
Rδ(P) = inf
λ≥0
λδ+ E
ux∼(g#P)Xh
˜ℓλ(ux)i
where, ˜ℓ(ux) = supua∈UA{ℓ(M(ua, u′
x)}andηλ(ux) = sup∆∈UX˜ℓ(ux+ ∆)−λdX(ux, ux+
∆)}. To prove we use Corollary 2 [ 28] for the ˜ℓ. First, we need to show that ˜ℓsatisfies the
condition of Corollary 2 [ 28]. By assumption for v′∈ V ,L, M ≥0such that |ℓ(v, y, θ )−
28ℓ(v′, y, θ)|< Ldp(v, v′) +M for all v∈ V andp∈[1,∞). By setting v=g−1((ua, ua))and
v′=g−1((u′
a, u′
a)), and for simplicity ℓ(v) =ℓ(v, y, θ )we have:
|ℓ(g−1((ua, ux)))−ℓ(g−1((u′
a, u′
x)))|< L∥ux−u′
x∥p+M,∀ux∈ UX, ua∈ UA⇒
|˜ℓ(ux)−˜ℓ(u′
x)| ≤L∥ux−u′
x∥p+M
where ˜ℓ(ux) =supua∈UAℓ(g−1((ua, ux))). This equation implies that ˜ℓsatisfies the condition of
corollary 2. So in consequence of corollary 2 and the equation 16 if we define uncertainty set:
˜Bδ=(
(ωik
x)i,k:1
NNX
i=1KX
k=1ui
x−ωik≤δ, ωik∈ UX)
Since the casual fair metric dand loss function ˜ℓdo not depend on the sensitive part then ˜Bδis
equivalent to the below uncertainty set.
Bδ=(
(wik)i,k:1
NNX
i=1KX
k=1dp(vi, wik)≤δ, wik∈ V)
.
By applying the uncertainty ˜Bδfor˜ℓ, the robust optimization problem has a form:
˜Radv
δ(PN) =
sup
(ωik)i,k∈˜Bδ(
1
NKNX
i=1KX
k=1˜ℓ(ωik))
= sup
(ωik)i,k∈˜Bδ(
1
NKNX
i=1KX
k=1max
ua∈UAℓ(g−1((ua, ωik))))
=
sup
(wik)i,k∈Bδ(
1
NKNX
i=1KX
k=1max
a∈Aℓ( ¨wik
a))))
and finally for ˜Radv
δ(PN)we have:
˜Radv
δ(PN)≤ Rn
δ(PN)≤˜Radv
δ(PN) +LD+M
NK,
and it completes the proof.
Lemma 8 Assume that the cost functions candˆcsatisfy |c(x, x′)−ˆc(x, x′)|< α for all x, x′∈Rn
and for some α≥0. Then, for any λ≥0, the difference between the λ-conjugates of fwith respect
tocandˆcis bounded by λα:
|fλ(x)−ˆfλ(x)| ≤λα for all x∈Rn.
Proof. To prove the proposition, we consider any x∈Rnand examine the definitions of fλ(x)and
ˆfλ(x). Begin by expressing the bounds on ˆc:
ˆc(x, x′)≤c(x, x′) +αand ˆc(x, x′)≥c(x, x′)−α.
From these inequalities, for any x′∈Rn,
f(x′)−λˆc(x, x′)≥f(x′)−λ(c(x, x′) +α) =f(x′)−λc(x, x′)−λα,
f(x′)−λˆc(x, x′)≤f(x′)−λ(c(x, x′)−α) =f(x′)−λc(x, x′) +λα.
Taking the supremum over all x′in the above expressions, we obtain:
ˆfλ(x)≥fλ(x)−λα and ˆfλ(x)≤fλ(x) +λα.
These two bounds together imply:
|fλ(x)−ˆfλ(x)| ≤λα.
Thus, the proof is complete, showing that the difference between the λ-conjugates of fis indeed
bounded by λα.
Lemma 9 Letc,ˆc:Rn×Rn→Rbe two functions such that |c(x, y)−ˆc(x, y)|< α for all
x, y∈Rnand some α >0. For any real number p≥1, the following inequality holds:
|c(x, y)p−ˆc(x, y)p| ≤p·Mp−1·α,
where M≥max{|c(x, y)|,|ˆc(x, y)|}for all x, y.
29Proof. Consider the functions candˆcand any x, y∈Rn. By the hypothesis, we have |c(x, y)−
ˆc(x, y)|< α. To find a bound on the difference of their powers, apply the mean value theorem to the
function f(t) =tp, which is differentiable over R(or over R+ifpis not an integer). The derivative
offisf′(t) =ptp−1.
Since fis continuously differentiable, there exists some ξbetween c(x, y)andˆc(x, y)such that
f(c(x, y))−f(ˆc(x, y)) =f′(ξ)·(c(x, y)−ˆc(x, y)).
Therefore,
|c(x, y)p−ˆc(x, y)p|=|pξp−1(c(x, y)−ˆc(x, y))|.
Using the bound |c(x, y)−ˆc(x, y)|< α and noting that ξmust be within the range of values between
c(x, y)andˆc(x, y), we have ξp−1≤Mp−1. Thus,
|c(x, y)p−ˆc(x, y)p| ≤pMp−1|c(x, y)−ˆc(x, y)|< pMp−1α.
Lemma 10 ([41]) Fix some P∈ P(Z),θ∈Θandλ∗≥0via
λ∗:= argminλ≥0{λδp+EP[ℓλ(Z, θ)]}.
Then under ℓLipschitz and diam (Z)<∞assumptions, we have λ∗≤Lδ−(p−1).
Proof. First, note that:
λ∗δp≤λ∗δp+EP
sup
z′∈Z{ℓ(z′, θ)−ℓ(z, θ)−λ∗cp(z, z′)}
=∗,
since the left-hand side, is greater than the case where z′=zso it is positive. By the optimality of
λ∗inℓ, the right-hand side can be further upper-bounded as follows for any λ≥0:
∗ ≤λδp+EP
sup
z′∈Z{ℓ(z′, θ)−ℓ(z, θ)−λcp(z, z′)}
≤λδp+EP
sup
z′∈Z{Lc(z, z′)−λcp(z, z′)}
≤λδp+ sup
t≥0{Lt−λtp},
using the Lipschitz property for the second line and setting t=c(z, z′)in the third line. If p= 1, by
setting λ=L, we obtain:
λ∗δ≤Lδ+ sup
t≥0{Lt−Lt}=Lδ,
which implies λ∗≤L. For p >1, using the optimal value t= (L/pλ )1/(p−1), we derive:
λ∗δp≤λδp+Lp
p−1p−p
p−1(p−1)λ−1
p−1.
Minimizing the right-hand side with λ=L/pδp−1yields:
λ∗δp≤Lδ⇒λ∗≤Lδ−(p−1),
resulting in the stated bound on λ∗.
Lemma 11 Iff:A×Rn→Ris Lipschitz with respect to xuniformly in a, i.e., there exists a
constant Lsuch that for all a∈Aand for all x, y∈Rn,
|f(a, x)−f(a, y)| ≤L∥x−y∥,
thensupa∈Af(a, x)is also Lipschitz in x.
30Proof. LetF(x) = supa∈Af(a, x). We aim to show that there exists a constant L′such that for all
x, y∈Rn,
|F(x)−F(y)| ≤L′∥x−y∥.
Since fis Lipschitz continuous with respect to xuniformly in awith Lipschitz constant L, it holds
for each a∈Aand any x, y∈Rnthat
|f(a, x)−f(a, y)| ≤L∥x−y∥.
Consider F(x)andF(y). By definition,
F(x) = sup
a∈Af(a, x)and F(y) = sup
a∈Af(a, y).
For any a∈A, since |f(a, x)−f(a, y)| ≤L∥x−y∥, we can infer that
f(a, x)≤f(a, y) +L∥x−y∥.
Taking the supremum over all a∈Aon both sides, we obtain
F(x)≤F(y) +L∥x−y∥.
Similarly,
F(y)≤F(x) +L∥x−y∥.
Combining these two inequalities, we find
|F(x)−F(y)| ≤L∥x−y∥.
Therefore, F(x) = supa∈Af(a, x)is Lipschitz continuous with Lipschitz constant L. This completes
the proof.
B.6 Proof of Theorem 5.
Let define define ˆRδ(P, θ) := supQ:Wˆc,p(Q,P)≤δEQ[ℓ(Z, θ)], the worst-case loss quantity over esti-
mation of the metric dandθ∗:= inf θ∈Θn
supQ:Wc,p(Q,P∗)≤δEQ[ℓ(Z, θ)]o
. Therefore by definition,
we can write:
Rδ(P∗,ˆθdro
N)− R δ(P∗, θ∗)≤ R δ(P∗,ˆθdro
N)−ˆRδ(PN,ˆθdro
N)−(Rδ(P∗, θ∗)−ˆRδ(PN, θ∗))(23)
because we have ˆRδ(PN,ˆθdro
N)≤ R δ(P∗, θ∗).
We estimate two expression |Rδ(P∗,ˆθdro
N)−ˆRδ(PN,ˆθdro
N)|and|Rδ(P∗, θ∗)−ˆRδ(PN, θ∗)|. By the
general strong duality theorem [26] we have:
Rδ(P∗, θ∗)−ˆRδ(PN, θ∗) = sup
Q:Wc,p(Q,P∗)≤δEQ[ℓ(Z, θ∗)]− sup
Q:Wˆc,p(Q,PN)≤δEQ[ℓ(Z, θ∗)] =
inf
λ≥0{λδp+EP∗
ℓc
λ(Z, θ∗)	
−inf
λ≥0{λδp+EPN
ℓˆc
λ(Z, θ∗)	
≤
λNδp+EP∗
ℓc
λN(Z, θ∗)	
−(λNδp+EPN
ℓˆc
λN(Z, θ∗)
) =
EP∗
ℓc
λN(Z, θ∗)	
−EPN
ℓˆc
λN(Z, θ∗)
where the λN:= arginfλ≥0
λδp+EPN
ℓˆc
λ(Z, θ∗)	
By assumption 2 and lemma 9,
|ℓc
λN(z, θ)−ℓˆc
λN(z, θ)|=sup
v′∈Vℓ(z′, y, θ)−λNdp(v′, v)−sup
v′∈Vℓ(v′, y, θ)−λNˆdp(v′, v)
≤sup
v′∈VλN|dp(v′, v)−ˆdp(v′, v)| ≤λNpdiam (V)p−1MdN−η.
This implies
Rδ(P∗, θ∗)−ˆRδ(PN, θ∗)≤EP∗
ℓc
λN(Z, θ)
−EPN
ℓc
λN(Z, θ)
+λNpdiam (V)p−1MdN−η.
31If define λ∗:= arginfλ≥0
λδp+EP
ℓc
λ(Z, θ∗)	
, similarly,
ˆRδ(PN, θ∗)− R δ(P∗, θ∗)≤EPN
ℓˆc
λ∗(Z, θ)
−EP∗
ℓc
λ∗(Z, θ)
≤
EPN
ℓc
λ∗(Z, θ)
−EP∗
ℓc
λ∗(Z, θ)
+λ∗pdiam (V)p−1MdN−η.
We need to estimate the λNandλ∗. By using strong duality theorem by Eq. 16 we have:
Rδ(P) = inf
λ≥0
λδp+ E
ux∼(g#P)Xh
˜ℓλ(ux)i
(24)
So instead the solve problem for ℓis it sufficient to prove our result for ˜ℓ(ux) =
supua∈UAℓ(g−1((ua, ux)). At first, we show that ˜ℓis Lipschitz on the space UXconcerning the
norm∥.∥. By assumption, for each a∈ A the function ℓ(g−1((ua, ux))is also Lipschitz:ℓ(g−1((ua, ux)), y, θ)−ℓ(g−1((ua, ux+ ∆)) , y, θ)=
∥ℓ(CF(v, a), y, θ)−ℓ(CF(v, a,∆), y, θ)∥ ≤Ld(CF(v, a),CF(v, a,∆)) = L∥∆∥
Now by using lemma 11 it can be concluded that the function ˜ℓ(ux) = supua∈UAℓ(g−1((ua, ux))
also has Lipschitz property with constant L. By Applying lemma 10 for equation 24 and (g#PN)X,
it can be seen λN, λ∗≤Lδ−(p−1). Therefore until now, we have two inequalities:
Rδ(P∗, θ∗)−ˆRδ(PN, θ∗)≤EP∗
ℓc
λN(Z, θ)
−EPN
ℓc
λN(Z, θ)
+λNpdiam (V)p−1MdN−η,
ˆRδ(PN, θ∗)− R δ(P∗, θ∗)≤EPN
ℓc
λ∗(Z, θ)
−EP∗
ℓc
λ∗(Z, θ)
+λ∗pdiam (V)p−1MdN−η⇒
|Rδ(P∗, θ∗)−ˆRδ(PN, θ∗)| ≤sup
f∈LcR
Zf(z)d(PN−P∗)(z)+Lδ1−ppdiam (V)p−1MdN−η,
where Lc={ℓc
λ(·, θ) :λ∈[0, Lδ1−p], θ∈Θ}is the DR loss class.
In the remaining part of the proof, we estimate supf∈Lc|R
Zf(z)d(P∗−PN)(z)|using conventional
methods from statistical learning theory. According to assumption 2, the functions within Fare
limited as shown:
0≤ℓc
λ(v, θ)≤sup
v′∈Vℓ(v′, y, θ)−λd(v, v′)≤sup
v′∈Vℓ(v′, y, θ)≤M.
similar to the proof Theorem 3 [ 41], by utilizing the bounded-differences inequality and symmetriza-
tion, we derive that:
sup
f∈LcR
Zf(z)d(PN−P∗)(z)≤2RN(Lc) +Ms
log2
ϵ
2N
holds with a probability of at least 1−ϵ, where Rn(Lc)represents the Rademacher complexity of
Lc:
RN(Lc) =E
sup
f∈Lc1
NNX
i=1σif(Zi)
.
In the proof of Theorem 2 [41], the authors has proved:
RN(Lc)≤24C(L)√
N+24L.diam (V)p
√
Nδp−1.
whereC(L), the entropy integral of of loss class. By applying this result it can be written:
|Rδ(P∗, θ∗)−ˆRδ(PN, θ∗)| ≤Ms
log2
ϵ
2N+48C(L)√n+48L.diam (V)p
√nδp−1+Lδ1−ppdiam (V)p−1MdN−η
Since the prove does depend on value of θ, then|Rδ(P∗,ˆθdro
N)−ˆRδ(PN,ˆθdro
N)|also satisfies in the
above inequality. By combining two terms with probability 1−ϵwe have,
Rδ(P∗,ˆθdro
N)−Rδ(P∗, θ∗)≤Ms
2 log2
ϵ
N+96C(L)√n+96L.diam (V)p
√nδp−1+2Lδ1−ppdiam (V)p−1MdN−η
Since by assumption, with probability 1−ϵwe have inequality
∀z, z′∈ |c(z, z′)−ˆc(z, z′)| ≤MdN−η, η > 0
therefore by probability 1−2ϵthe main inequality is true and it completes the proof.
32C Numerical Analysis Supplementary
C.1 Synthetic Data Models
The structural equations used to generate the SCMs in § 5 are listed below. For the LIN SCM, we
generate the protected feature Aand variables Xiaccording to the following structural equations:
• linear SCM (LIN):


A:=UA, UA∼ B(0.5)
X1:= 2A+U1, U 1∼ N(0,1)
X2:=A−X1+U2, U2∼ N(0,1)
Y∼ B((1 + exp(−(X1+X2))−1)
Here,B(p)represents Bernoulli random variables with probability p, andN(µ, σ2)represents normal
random variables with mean µand variance σ2. To generate the ground truth h(A, X1, X2), we
use a linear model for the LIN method. In all the synthetic models considered, we treat Aas a
binary-sensitive attribute.
C.2 Real-World Data
In our research, we have utilized the Adult dataset [ 38] and the COMPAS dataset [ 65] for our
experimental analysis. To employ these datasets, we initially constructed an SCM based on the
causal graph proposed by Nabi et al. [ 49]. For the Adult dataset, we incorporate features such as sex,
age,native-country ,marital-status ,education-num ,hours-per-week , and consider gender as a
sensitive attribute. In the case of the COMPAS dataset, the utilized features comprise age,race,sex,
andpriors count , which function as variables. Additionally, sex is considered a sensitive attribute.
For classification purposes, we apply data standardization before the learning process.
Adult =

A=UA Sex
X2=U2 Age
X3=U3 Country
X4=U4 Marital Status
X5=β51X1+β52X2+β53X3+β54X4+U5 Education Level
X6=β61X1+β62X2+β63X3+β64X4+β65X5+U6Hours per Week
COMPAS =

X1=U1 Sex
X2=U2 Age
X3=U3 Race
X4=β41X1+β42X2+β43X3+U4Priors Count
In these above equations, βijare the coefficients for the linear combinations of the Xvariables, and
Uiare the exogenous variables.
C.3 Training Methods
In our study, we utilize various training objectives to train decision-making classifiers, with loss
function ℓ(v). The training objectives are as follows:
•Empirical Risk Minimization (ERM) : This approach minimizes the expected risk con-
cerning the classifier parameters ψ, represented by
inf
θ∈ΘEz∼P[ℓ(z, θ)]
33•Adversarial Learning (AL) : This method trains the model to withstand or defend against
adversarial perturbations, represented by
inf
θ∈Θ(
Ez∼P"
sup
∥∆∥≤δℓ(z+ ∆, θ)#)
•ROSS : Based on the work of Ross et al. [ 56], this method minimizes the expected risk along
with an adversarial perturbation term, represented by
inf
θ∈Θ
E(v,y)∼P
ℓ(v, y, θ ) + inf
∥∆∥≤δℓ(v+ ∆,1, θ)
•CDRO : Our approach, as described in this paper, is formulated as follows:
inf
θ∈Θ(
sup
Q∈Bδ(P)Ez∼Q[ℓ(z, θ)])
For our loss function ℓ, we use the binary cross-entropy loss.
C.4 Hyperparameter Tuning
The majority of the experimental setup is based on the work of Ehyaei et al. [ 22]. For each dataset
and its respective label, we use a generalized linear model (GLM). Each training objective is applied
to four different datasets, using 100 different random seeds. The optimization process is performed
using the Adam optimizer with a learning rate of 10−3and a batch size of 100. After optimizing
the benchmark time and considering the training rate, we set the number of epochs to 10 to ensure
comparability in benchmarking.
C.5 Metrics
To assess the performance of various training methods concerning accuracy, unfair area, counterfactual
fairness, and adversarial robustness, we employ seven distinct metrics as outlined below:
•Acc : The accuracy of the classifier, is represented as a percentage.
•Uδ: The proportion of data points within the unfair area with a radius of δ.
Uδ:=P 
{v∈ V:∃v′∈ V s.t. d(v, v′)≤δ∧h(v)̸=h(v′)}
.
•Rδ: The fraction of data points that are vulnerable to adversarial perturbations within a
radius of δ. This metric coincides with the unfair area in cases where no sensitive attribute
is considered.
Rδ:=P 
{v∈ V:∃∆∈ V s.t. d(v,CF(v,∆))≤δ∧h(v)̸=h(CF(v,∆))}
.
•CF: The percentage of data points that exhibit counterfactual unfairness. This metric aligns
with the unfair area when the perturbation radius is zero.
CF := P 
{v∈ V:∃a∈ A s.t. h(v)̸=h(¨va)}
.
C.6 Additional Results
In this section, we present additional simulation results. CDRO performs well across all datasets
except for the Rδmeasure in the Adult dataset, likely because the linear model does not fit the SCM
well. Nevertheless, CDRO demonstrates robustness and counterfactual fairness, as shown in Table 1,
making it the preferred model when balancing both accuracy and fairness.
34AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0%10%20%30%Counterfactual Unfair AreaLINSynthetic Data
AL
CDROERMROSS0%10%20%30%40%
AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0%1%2%3%4%Non-robust Area (D =0.05)LINSynthetic Data
AL
CDROERMROSS0%5%10%15%Figure 2: Displays the findings from our numerical experiment, assessing the performance of DRO across
different models and datasets. (left) Counterfactual unfair area percentage (lower values are better). (right)
Non-robust area performance of classifier (higher values are better) for ∆ =.05.
AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0%10%20%30%Unfair Area (D =0.01)LINSynthetic Data
AL
CDROERMROSS0%10%20%30%40%
AdultCOMPASReal-world Data
AL
CDROERMROSSAL
CDROERMROSS0.00%0.25%0.50%0.75%Non-robust (D =0.01)LINSynthetic Data
AL
CDROERMROSS0%5%10%15%
Figure 3: Displays the findings from our numerical experiment, assessing the performance of DRO across
different models and datasets. (Left) Bar plot showing the comparison of models based on the unfair area
percentage U(δ)(lower values are better) at ∆ =.01. (Right) Bar plot showing the comparison of models based
on the robustness area percentage R(δ)(lower values are better) at ∆ =.01.
Broader Impact Statement
Our theoretical framework bridges adversarial robustness, distributional robustness, individual fair-
ness, and causality, aligning with the core pillars of responsible AI. By demonstrating the connection
between these areas, we aim to inspire further research at their intersection and contribute to the
development of safer, more equitable AI models for society. This approach holds the promise of
improving decision-making under uncertainty while ensuring fairness and mitigating the impact of
adversarial perturbations.
However, we acknowledge several limitations and ethical implications inherent in our approach.
While our method produces fair and robust predictions under specific conditions, it is important
to note that it fundamentally relies on a machine learning model, which may inherit the same
vulnerabilities as the original model in areas not explicitly addressed in this work such as multiplicity,
Real-World Data Synthetic Data
Adult COMPAS LIN
Trainer AccU0.5U0.1CFR.05R.01 AccU0.5U0.1CFR.05R.01 AccU0.5U0.1CFR.05R.01
AL 0.79 0.06 0.04 0.04 0.03 0.01 0.67 0.2 0.17 0.16 0.04 0.01 0.67 0.2 0.19 0.19 0.11 0.1
CDRO 0.73 0.04 0.01 0 0.04 0.01 0.66 0.05 0.02 0.01 0.04 0.01 0.66 0.04 0.03 0.03 0.02 0.02
ERM 0.79 0.05 0.02 0.02 0.03 0 0.68 0.26 0.23 0.22 0.04 0.01 0.69 0.4 0.39 0.38 0.15 0.13
ROSS 0.78 0.06 0.04 0.03 0.03 0.01 0.67 0.33 0.3 0.3 0.04 0.01 0.69 0.44 0.43 0.43 0.18 0.17
Table 1: The table presents the results of our numerical experiment, comparing various trainers
based on their input sets in terms of accuracy (Acc, higher values are better), unfairness areas ( U.05,
lower values are better), unfairness areas ( U.01, lower values are better), Counterfactual Unfair area
(CF, lower values are better), the non-robust percentage concerning adversarial perturbation with
radii 0.05(R.05, lower values are better), and the non-robust percentage concerning adversarial
perturbation with radii 0.01(R.01, lower values are better). The top-performing techniques for each
trainer, dataset, and metric are highlighted in bold. The findings demonstrate that CDRO excels in
reducing unfair areas. The average standard deviation for CDRO is .029, while for the other methods,
it is .031.
35privacy breaches, lack of explainability, and safety/security concerns. Additionally, our work operates
under simplifying assumptions regarding the fairness notion. In real-world applications, fairness is a
complex and context-dependent concept. Therefore, it is essential to define fairness carefully and
consider multiple dimensions of fairness when applying our approach. We emphasize that this work
is a proof of concept, and we strongly recommend involving diverse stakeholders, including ethicists,
domain experts, and affected communities, before applying our approach to high-risk application
domains. It’s important for users to be aware of these limitations and potential biases that might not
be fully addressed by our framework.
36D NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Our claims in the abstract and the introduction match the body of the text, the
provided proofs, and the reported experimental results.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss the main limitations of our work in the conclusion.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We provide general assumptions in the beginning, and all the lemmas and
theorems have either a full proof or a general intuition in the main body of the paper, with
the remainder of proofs in the appendix.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: We mention the used datasets and models, the random seeds, and details about
the data splits in the main body of the paper and the appendix. Information about libraries
and used algorithms is also provided.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We mention the used datasets and models, the random seeds, and details about
the data splits in the main body of the paper and the appendix. Information about libraries
and used algorithms is also provided.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We give detailed results in the form of tables (with mean and std), while we
only plot the mean values to not overcrowd the figures and just report the standard deviation
in the table caption.
8.Experiments Compute Resources
37Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [No]
Justification: The experiments are hardware agnostic and use fairly small models and
datasets.
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: We include a broader impact statement in the appendix.
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: Our paper does not create new data or models.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We properly credit the used datasets.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We documented the code.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
38