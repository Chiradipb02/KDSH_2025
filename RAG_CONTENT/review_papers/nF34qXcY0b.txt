Identification of Analytic Nonlinear Dynamical
Systems with Non-asymptotic Guarantees
Negin Musavi
nmusavi2@illinois.eduZiyao Guo
ziyaog2@illinois.edu
Geir Dullerud
dullerud@illinois.eduYingying Li
yl101@illinois.edu
Coordinated Science Laboratory
University of Illinois Urbana-Champaign
Abstract
This paper focuses on the system identification of an important class of nonlinear
systems: nonlinear systems that are linearly parameterized, which enjoy wide
applications in robotics and other mechanical systems. We consider two system
identification methods: least-squares estimation (LSE), which is a point estimation
method; and set-membership estimation (SME), which estimates an uncertainty
set that contains the true parameters. We provide non-asymptotic convergence
rates for LSE and SME under i.i.d. control inputs and control policies with i.i.d.
random perturbations, both of which are considered as non-active-exploration
inputs. Compared with the counter-example based on piecewise-affine systems
in the literature, the success of non-active exploration in our setting relies on a
key assumption about the system dynamics: we require the system functions to
be real-analytic. Our results, together with the piecewise-affine counter-example,
reveal the importance of differentiability in nonlinear system identification through
non-active exploration. Lastly, we numerically compare our theoretical bounds
with the empirical performance of LSE and SME on a pendulum example and a
quadrotor example.
1 Introduction
Learning control-dynamical systems with statistical methodology has received significant attention in
the past decade (Sarker et al., 2023; Li et al., 2023b; Chen and Hazan, 2021; Simchowitz and Foster,
2020; Wagenmaker and Jamieson, 2020; Simchowitz et al., 2018; Dean et al., 2018; Abbasi-Yadkori
and Szepesvári, 2011; Li et al., 2021b). In particular, the estimation of linear dynamical systems, e.g.
xt+1=A∗xt+B∗ut+wt, is relatively well-studied: it has been shown that non-active exploration by
i.i.d. noises on control inputs utand system disturbances wtare already enough for accurate system
identification, and least square estimation (LSE) can achieve the optimal estimation convergence rate
(Simchowitz and Foster, 2020; Simchowitz et al., 2018).
However, nonlinear control systems are ubiquitous in real-world applications, e.g. robotics (Siciliano
et al., 2010; Alaimo et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong
et al., 2015), etc. Motivated by this, there has been a lot of attention on learning nonlinear systems
recently. One natural and popular direction to study nonlinear system identification is on learning
linearly parameterized nonlinear systems as defined below, which is a straightforward extension from
38th Conference on Neural Information Processing Systems (NeurIPS 2024).the standard linear systems (Mania et al., 2022; Khosravi, 2023; Foster et al., 2020)
xt+1=θ∗ϕ(xt, ut) +wt
where θ∗is a vector of unknown parameters and ϕ(xt, ut)is a known vector of nonlinear features.
On the one hand, some classes of these systems are shown to enjoy similar benefits of linear systems.
For example, bilinear systems can also be estimated by LSE under non-active exploration with i.i.d.
noises (Sattar et al., 2022), as well as linear systems with randomly perturbed nonlinear policies (Li
et al., 2023b).
On the other hand, it is also known that non-active exploration is insufficient for general linearly
parameterized nonlinear systems. In particular, (Mania et al., 2022) provides a counter example
showing that non-active exploration is insufficient to learn accurate models under piece-wise affine
feature functions. This motivates a sequence of follow-up work on the design of active exploration
for nonlinear system estimation, which is largely motivated by the non-smooth feature functions such
as ReLu in neural networks (Mania et al., 2022; Kowshik et al., 2021; Khosravi, 2023).
However, there is a big gap between bilinear systems, which is infinitely differentiable, and the
counter example by non-smooth systems. A natural question is: to what extent can non-active
exploration still work for linearly parameterized nonlinear systems?
Contributions. One major contribution of this paper is showing that LSE with non-active i.i.d.
noises can efficiently learn any linearly parameterized nonlinear systems with real-analytic feature
functions and provide a non-asymptotic convergence rate. Notice that real-analytic feature functions
are common in physical systems. For example, polynomial systems satisfy this requirement and have
wide applications in power systems (Simpson-Porco et al., 2016), fluid dynamics (Noack et al., 2003),
etc. Further, trigonometric functions also satisfy the real-analytic property so a large range of robotics
and mechanical systems also satisfy this requirement (Siciliano et al., 2010; Alaimo et al., 2013).
A side product of our LSE convergence rate analysis is the convergence rate for another commonly
used uncertainty quantification method in control: set membership estimation (SME).
Numerically, we test our theoretical results in pendulum and quadrotor systems. Simulations show
that LSE and SME can indeed efficiently explore the system and converge to the true parameter under
non-active exploration noises.
Technically, the key step in our proof is establishing the block-martingale-small-ball condition
(BMSB) for general analytic feature functions, which greatly generalizes the bilinear feature function
in Sattar et al. (2022). Our result is built on an intuition inspired by the counter example in (Mania
et al., 2022): the counter example in (Mania et al., 2022) requires that some feature function is zero
in a certain region, so nothing can be learned about its parameter if the states stay in this region.
However, analytic functions cannot be a constant zero in a positive-measure region unless it is a
constant zero everywhere. Therefore, the counter example does not work, and non-active exploration
around any states can provide some useful information. Our proof formalizes this intuition by utilizing
the Paley-Zygmund Petrov inequality (Petrov, 2007).
Related work. Inspired by neural network parameterization, nonlinear systems of the form xt+1=
ϕ(A∗xt) +wtis also studied in the literature, where ϕ(·)is a known nonlinear link function and
A∗is unknown. The least square cost is no longer quadratic or even convex in this case and various
optimization methods have been proposed to learn this type of systems (Kowshik et al., 2021; Sattar
et al., 2022; Foster et al., 2020).
Another related line of research focuses on nonlinear regression with dependent data (Ziemann and
Tu, 2022; Ziemann et al., 2023, 2024),1which can be applied to nonlinear system identification.
The nonlinear regression in (Ziemann and Tu, 2022; Ziemann et al., 2023, 2024) is based on non-
parametric LSE and its variants, and their convergence rates under different scenarios have been
analyzed. It is interesting to note that this line of work usually assumes certain persistent excitation
assumptions,2whereas our paper demonstrates that persistent excitation holds by establishing the
BMSB condition for linearly parameterized and real-analytic nonlinear control systems.
1yt=f∗(xt) +wtis considered, where xtandytcorrelate with the historical data.
2For example, (Ziemann and Tu, 2022) assumes hyper-contractivity, and (Ziemann et al., 2024) assumes the
empirical covariance of the {xt}t≥0process is invertible with high probability (Corollary 3.2).
2Uncertainty set estimation is crucial for robust control under model uncertainties Lu and Cannon
(2023); Lorenzen et al. (2019); Li et al. (2021a). SME is a widely adopted uncertainty set estimation
method in robust adaptive control (Lorenzen et al., 2019; Lu and Cannon, 2023; Bertsekas, 1971; Bai
et al., 1995). Recently, there is an emerging interest in analyzing SME’s convergence and convergence
rate for dynamical systems (Li et al., 2024; Lu et al., 2019; Xu and Li, 2024), because previous
analysis focus more on the linear regression problem (e.g. (Akçay, 2004; Bai et al., 1998)). There are
also recent applications of SME to online control Yu et al. (2023), power systems Yeh et al. (2024),
and computer vision Gao et al. (2024); Tang et al. (2024).
Notation. The set of non-negative real numbers is denoted by R≥0. The notation ⌈·⌉stands for the
ceiling function. For a real vector z∈Rn,∥z∥2represents its ℓ2norm,∥z∥∞represents its ℓ∞norm,
andzirepresents its i-th component with i= 1···n. The set of real symmetric matrices is denoted
bySn. For a real matrix Z,Z⊺represents its transpose, ∥Z∥2its maximum singular value, ∥Z∥Fits
Frobenius norm, σmin(Z)its minimum singular value, vec(Z)its vectorization obtained by stacking
its columns, and for a real square matrix Z,tr(Z)represents its trace. For a real symmetric matrix
Z,Z≻0andZ⪰0indicate that Zis positive definite and positive semi-definite, respectively.
For a measurable set E ⊂Rn,λn(E)represents its Lebesgue measure in RnandEcrepresents its
complement in Rn. The notation ∅stands for the empty set. For a set Tof matrices θ∈Rn×m,
diam(T)denotes its diameter and it is defined as diam(T) = supθ,θ′∈T∥θ−θ′∥F. Forzi∈Rwith
i= 1,···, ℓ, the notation diag(z1,···, zℓ)denotes a matrix in Rℓ×ℓwith diagonal entries of zi.
This paper uses truncated-Gaussian (0, σw,[−wmax, wmax])to refer to the truncated Gaussian
distribution generated by Gaussian distribution with zero mean and σ2
wvariance with truncated range
[−wmax, wmax]. The same applies to multi-variate truncated Gaussian distributions.
2 Problem Formulation and Preliminaries
This paper studies the system identification/estimation of linearly parameterized nonlinear systems:
xt+1=θ∗ϕ 
xt, ut
+wt, (1)
where xt∈Rnx,ut∈Rnu, and wt∈Rnxdenote the state, control input, and system disturbance
respectively; θ∗∈Rnx×nϕdenotes the unknown parameters to be estimated, and ϕ(·)denotes a
vector of known nonlinear feature/basis functions, i.e., ϕ(·) = (ϕ1(·),···, ϕnϕ(·))⊺, where ϕi(·) :
Rnx+nu→R. Without loss of generality, we consider zero initial condition, i.e., x0= 0, and linearly
independent feature functions, that is,Pnϕ
i=1ciϕi(xt, ut) = 0 implies that ci= 0for all i.3
The linearly parameterized nonlinear system (1)is a natural generalization of linear control systems
xt+1=A∗xt+B∗ut+wtand has wide applications in, e.g. robotics (Siciliano et al., 2010; Alaimo
et al., 2013), power systems (Simpson-Porco et al., 2016), transportation (Kong et al., 2015), etc.
Therefore, there has been a lot of research on learning this type of systems (1)by utilizing the
methodology and insights from linear system estimation. For example, it is common to estimate a
linearly parameterized nonlinear system by least square estimation (LSE), which enjoys desirable
performance in linear systems.
In particular, LSE for (1) is reviewed below
ˆθT= arg min
ˆθT−1X
t=0xt+1−ˆθϕ(xt, ut)2
2. (2)
For linear systems, LSE enjoys the following good property: LSE can achieve the optimal rate of
convergence with i.i.d. noises wtand i.i.d. control inputs utunder proper conditions ( (Simchowitz
et al., 2018)). This good property has been generalized to some linearly parameterized nonlinear
systems, such as bilinear systems, and linear systems with nonlinear control policies. Unfortunately,
general linearly parameterized nonlinear systems do not enjoy this good property of linear systems,
meaning i.i.d. random inputs may not provide enough exploration for non-smooth feature functions
ϕ(·). Therefore, a sequence of follow-up work focuses on the design of active exploration methods.
However, due to the simplicity of implementation, i.i.d. random inputs remain a popular method in
empirical research of system identification and enjoy satisfactory performance sometimes, despite
3If the features are not independent, they can be converted to independent ones since the features are known.
3the lack of theoretical guarantees. Therefore, this paper aims to establish more general conditions
that allow provable convergence of nonlinear system estimation under i.i.d. random inputs.
In the rest of this paper, we will show that with certain smoothness and continuous conditions, i.i.d.
random inputs are sufficient for estimation of (1), which recovers the good property of linear systems.
2.1 Assumptions
In the following, we formally describe the smoothness and continuity conditions that enables efficient
exploration of (1) by i.i.d. random inputs.
Assumption 1 (Analytic feature functions) .All the components of feature vector ϕ(·)are real
analytic functions in Rnx+nu,4i.e., for every 1≤i≤nϕ,ϕi(x, u)is an infinitely differentiable
function such that the Taylor expansion at every (¯x,¯u)converges point-wisely to the ϕi(x, u)in a
neighborhood of (¯x,¯u).
Analytic functions include polynomial functions and trigonometric functions, which are important
components of many physical systems in real-world applications, e.g. power systems, robotics,
transportation systems, etc. In particular, we provide two illustrative examples below.
Example 1 (Pendulum) .Many multi-link robotic manipulators can be understood as interconnected
pendulum dynamics. The motion equations of a single pendulum, consisting of a mass msuspended
from a weightless rod of length lfixed at a pivot with no friction, can be expressed as:
¨α=−g
lsin(α) +u
ml2+w,
where αrepresents the angle of the rod relative to the vertical axis, gis the gravity constant, uis the
torque input, and wis the disturbance applied to this system. After discretization the system dynamics
can be rewritten in the structure of (1) with the feature vector consisting of expressions involving
sin(α)andu, all of which are analytic functions. The matrix of unknown parameters contains terms
of the pendulum’s mass and the rod’s length.
Example 2 (Quadrotor (Alaimo et al., 2013)) .Letp∈R3andv∈R3represent the center of
mass position and velocity of the quadrotor in the inertial frame, respectively; let ω∈R3denote its
angular velocity in the body-fixed frame, and q∈R4denote the quaternion vector. The quadrotor’s
equations of motion can then be expressed as:
d
dt
p
v
q
ω
=
v
−gez+1
mQfu
1
2Ωq
I−1(τu−ω×Iω)
+w,
where gis the gravity constant, mis its total mass, I=diag(Ixx, Iyy, Izz)its inertia matrix with
respect to the body-fixed frame, fu∈Rthe total thrust, τu∈R3the total moment in the body-fixed
frame, ez= (0,0,1)⊺,Q=
q2
0+q2
1−q2
2−q2
32(q1q2−q0q3) 2( q0q2−q1q3)
2(q1q2−q0q3)q2
0−q2
1+q2
2−q2
32(q2q3−q0q1)
2(q1q3−q0q2) 2( q0q1−q2q3)q2
0−q2
1−q2
2+q2
3
,and
Ω =
0−ω1−ω2−ω3
ω10 ω3−ω2
ω2−ω30 ω1
ω3ω2−ω10
.
Similar to the pendulum example, after discretization the system dynamics can be rewritten in the
structure of (1) with the feature vector consisting of cubic polynomials in states and inputs, which
are real-analytic. The unknown parameters contain terms of the mass and inertial moments of the
quadrotor.
Next, we introduce the assumption on the random inputs, which relies on the following definition.
Definition 1 (Semi-continuous distribution) .We define a probability distribution Pas semi-continuous
if there does not exist a set Ewith Lebesgue measure zero such that P(E) = 1 .
4This assumption can be relaxed to locally analytic functions in a large enough bounded set.
4The semi-continuous distribution is a weaker requirement than continuous distributions. In particular,
any continuous distributions, or a mixture distribution with one component as a continuous distribution
can satisfy the requirement of semi-continuity. The semi-continuity can also be interpreted by the
Lebesgue Decomposition Theorem (Chapter 6 of (Halmos, 2013)) as discussed below.
Remark 1 (Connection with Lebesgue Decomposition Theorem) .Definition 1 can be interpreted
by the Lebesgue Decomposition Theorem, which suggests that any probability distribution can be
decomposed into a purely atomic component and a non-atomic component (see more details in
Halmos (2013)). A semi-continuous distribution as defined in Definition 1 requires the distribution’s
non-atomic component to be nonzero.
In the following, we provide the assumptions on wtandutusing the semi-continuity definition.
Assumption 2 (Bounded i.i.d. and semi-continuous disturbance) .wtis i.i.d. following a semi-
continuous distribution with zero mean and a positive definite covariance matrix Σw⪰σ2
wInx≻0
and a bounded support, i.e. ∥wt∥∞≤wmaxalmost surely for all t.
The i.i.d. assumption is common in the literature of system identification for linear and nonlinear
systems. As for the bounded assumption on wt, though being stronger than the sub-Gaussian
assumption on wtin the literature of linear system estimation, it is a common assumption in the
literature of nonlinear system estimation (Mania et al., 2022; Shi et al., 2021; Kim and Lavaei, 2024).
Further, in many physical applications, noises are usually bounded, e.g. the wind disturbances in
quadrotor systems are bounded, the renewable energy injections in power systems are also bounded,
etc.
The semi-continuity assumption may seem restrictive, since it rules out the discrete distributions.
However, the disturbances in many realistic systems can satisfy the semi-continuity because realistic
noises are usually generated from a mixture distribution where at least one component is continuous,
e.g. the wind disturbances and renewable generations are continuous.
As for the control inputs ut, we first impose the same assumption as Assumption 2 for simplicity.
Later in Section 3, we will also discuss the relaxation of this assumption to include control policies.
Assumption 3 (Bounded i.i.d. and semi-continuous inputs) .utis i.i.d. following a semi-continuous
distribution with zero mean and a positive definite covariance Σu⪰σ2
uInx≻0and bounded support,
i.e.∥ut∥∞≤umaxalmost surely for all t.
Lastly, we introduce our stability assumption based on the input-to-state stability definition below.
Definition 2 (Locally input-to-state stability (LISS)) .Consider the general nonlinear system xt+1=
f(xt, dt)withxt∈Rnx,dt∈Rnd,fbeing a continuous function such that f(0,0) = 0 . This
system is called locally input-to-state stable (LISS) if there exist constants ρx>0,ρ > 0and
functions γ∈ K ,β∈ KL such that for all x0∈ {x0∈Rnx:∥x0∥2≤ρx}and any input
dt∈ {d∈Rnd: supt∥dt∥∞≤ρ}, it holds that ∥xt∥2≤β 
∥x0∥2, t
+γ 
supt∥dt∥∞
for all
t≥0.5
Assumption 4 (LISS system) .System (1)is LISS with parameters ρxandρsuch that ρx≥ ∥x0∥2
andρ≥max( wmax, umax), respectively.
Assumption 4 is imposed, together with the bounded disturbances and inputs in Assumptions 2 and 3,
to guarantee bounded states during the control dynamics (for instance, see the proof of Theorem 1in
Appendix A). Notably, many studies on learning-based nonlinear control require certain boundedness
on the states for theoretical analysis Sattar and Oymak (2022); Foster et al. (2020); Li et al. (2023a).
In addition, it is interesting to note that this paper only requires local stability of the dynamics, whereas
several learning-based nonlinear control papers assume certain global properties, such as global
exponential stability in (Foster et al., 2020), global exponential incremental stability in (Sattar and
Oymak, 2022; Li et al., 2023a; Lin et al., 2024), or global Lipschitz smoothness in (Lee et al., 2024).6
This difference in the dynamics assumption reflects a trade-off with the disturbance assumptions:
we assume a stronger assumption on the boundedness of disturbances and a weaker assumption
5A function γ:R≥0→R≥0is aKfunction if it is continuous, strictly increasing and γ(0) = 0 . A function
β:R≥0×R≥0→R≥0is aKLfunction if, for each fixed t≥0, the function β(·, t)is aKfunction, and for
each fixed s≥0, the function β(s,·)is decreasing and β(s, t)→0ast→ ∞ .
6Global Lipschitz smoothness may exclude system dynamics with higher-order polynomials.
5on local stability, whereas much of the literature considers (sub)Gaussian distributions (which can
be unbounded) but requires stronger global properties for dynamics. Since this paper is largely
motivated by physical systems, which typically encounter bounded disturbances/inputs and generally
only satisfy local stability (Slotine and Li, 1991), we address this trade-off through our current set of
assumptions, leaving it as an exciting future direction to consider relaxing these assumptions.
3 Main Results
In this section, we provide the estimation error bounds of LSE for linearly parameterized nonlinear
systems under i.i.d. random inputs. The estimation error bounds rely on the establishment of
probabilistic persistent excitation, which will be introduced in the first subsection. Later, we also
generalize the results to include control policies and discuss the convergence rate of another popular
uncertainty quantification method in the control literature, set membership estimation, whose formal
definition is deferred to the corresponding subsection.
3.1 Probabilistic Persistent Excitation
It is well-known that persistent excitation (PE) is a crucial condition for successful system identifi-
cation (Narendra and Annaswamy, 1987). In the following, we introduce the persistent excitation
condition for our linearly parameterized nonlinear systems.
Definition 3 (Persistent excitation (Skantze et al., 2000; Sastry and Bodson, 2011)) .System (1)is
persistently excited if there exist s >0andm≥1such that for any t0≥0, we have
1
mt0+m−1X
t=t0ϕ 
xt, ut
ϕ⊺ 
xt, ut
⪰s2Inϕ.
In the stochastic setting, PE is closely related with a block-martingale small-ball (BMSB) condition
proposed in Simchowitz et al. (2018), which can be viewed as a probabilistic version of PE.
Definition 4 (BMSB (Simchowitz et al., 2018)) .Let{Ft}t≥1denote a filtration and let {yt}t≥1be
an{Ft}t≥1-adapted random process taking values in Rny. We say {yt}t≥1satisfies the (k,Γsb, p)-
block martingale small-ball (BMSB) condition for a positive integer k, aΓsb≻0, and a p∈[0,1],
if for any fixed v∈Rnysuch that ∥v∥2= 1, the process {yt}t≥1satisfies1
kPk
i=1P 
|v⊺yt+i| ≥√v⊺Γsbv| Ft
≥palmost surely for any t≥1.
One major contribution of this paper is formally establishing the BMSB condition for linearly
parameterized nonlinear systems with real-analytic feature functions.
In the following, we first investigate the open-loop system with i.i.d. inputs and later extend the
results to the closed-loop systems with inputs ut=π(xt) +ηt, where ηtrepresents the noise and
π:Rnx→Rnudenotes a control policy. The following theorem considers the open-loop systems.
Theorem 1 (BMSB for open-loop systems) .Letut=ηtand consider the filtration Ft=
F(w0,···, wt−1, x0,···, xt, η0,···, ηt). Suppose Assumptions 1, 2, 3, 4 hold, then there ex-
istsϕ>0andpϕ∈(0,1)such that the {Ft}t≥1-adapted process
ϕ 
xt, ut	
t≥1satisfies the 
1, s2
ϕInϕ, pϕ
-BMSB condition.
Proof Sketch. Intuitively, BMSB requires that any linear combination of feature functions remains
positive with a non-vanishing probability. Notice that a linear combination of real-analytic functions
is itself real-analytic, and the zeros of an analytic function have measure zero. These facts allow us to
show that the probability of a linear combination of linearly independent feature functions equaling
zero is less than one, as long as the noises follow semi-continuous distributions, by the connection of
the Lebesgue measure and the probability measure in Definition 1.
In more detail, the proof leverages a variant of the Paley-Zygmund argument (Petrov, 2007), which
provides a lower bound for the tail properties of positive random variables. Specifically, it states that
the probability of a positive random variable being small depends on the ratio of its even moments.
We apply this result to the random variable |vTϕ 
xt+1, ut+1
| Ft|with∥v∥2= 1and aim to show
6that the lower bound is non-trivial for any direction vwith∥v∥2= 1and any filtration Ft,t≥0. We
then use results from measure theory to demonstrate the existence of such a non-trivial lower bound.
This is done by showing that the Lebesgue measure of the set where |vTϕ 
xt+1, ut+1
|= 0is zero,
and thus the even moments of |vTϕ 
xt+1, ut+1
| Ft|are non-zero, provided that the noise and
disturbance distributions are semi-continuous. For further details, please refer to Appendix A.
It is worth pointing out that Theorem 1 only establishes the existence of the constants (sϕ, pϕ),
and deriving explicit formulas of these constants are left for future work. In particular, it can be
challenging to derive a generic formula for all linearly parameterized nonlinear systems, but an
exciting direction is to study reasonable sub-classes of systems and construct their corresponding
formulas of the constants (sϕ, pϕ).
3.2 Non-asymptotic Bounds for LSE
We are now prepared to present the non-asymptotic convergence rate for the LSE in learning the
unknown parameters of the system (1).
Theorem 2 (LSE’s convergence rate for open-loop systems) .Consider the dynamical system de-
scribed in (1) with i.i.d. inputs ut=ηtand assume that Assumptions 1, 2, 3, 4 are satisfied. Let sϕ
andpϕbe as defined in Theorem 1, and define ¯bϕ= supt≥0E
∥ϕ(zt)∥2
2
. For a fixed δ∈(0,1)and
T≥1, ifTsatisfies the condition
T≥10
pϕ
log1
δ
+ 2nϕlog10
pϕ
+nϕlog¯bϕ
δs2
ϕ
,
then LSE’s estimation ˆθTsatisfies the following error bound with probability at least 1−3δ.
ˆθT−θ∗
2≤90σw
pϕvuuutnx+ log
1
δ
+nϕlog
10
pϕ
+nϕlog
¯bϕ
δs2
ϕ
Ts2
ϕ.
The proof relies on Theorem 1 and Theorem 2.4 in (Simchowitz et al., 2018). The complete proof is
provided in Appendix B.1.
Theorem 2 demonstrates that LSE converges to the true parameters under random control inputs and
random disturbances (non-active exploration) at a rate of1√
Tfor linearly parameterized nonlinear
systems. This is consistent with the convergence rates of LSE for linear systems in terms of T.
Regarding the dimension dependence in the convergence rate, the explicit dependence is√nx+nϕ,
where nxandnϕrefer to the dimensions of the state and the feature vector, respectively. Besides, it is
worth mentioning that other parameters, such as sϕ, pϕ,¯bϕ, may implicitly depend on the dimensions
as well. For some special systems, such as bilinear systems, it has been shown that these constants are
independent of the dimensions (Sattar et al., 2022). It is left as future work to explore other nonlinear
systems’ implicit dimension dependence.
Next, we can generalize the i.i.d. inputs utto include control policies, i.e., ut=π(xt) +ηt, where
ηtsatisfies Assumption 3 and π(xt)is analytic.
Corollary 1 (LSE’s convergence rate for closed-loop systems) .Consider inputs ut=π(xt) +
ηt, where π(·)is real-analytic, ηtsatisfies Assumption 3, and the closed-loop system xt+1=
θ∗ϕ(xt, π(xt) +ηt) +wtsatisfies Assumption 4 for both wtandηt. Then, the same convergence
rate in Theorem 2 holds.
The proof is provided in Appendix B.2.
3.3 Non-asymptotic Diameter Bounds for SME
Set membership estimation (SME) is another popular method for uncertainty quantification in control
system estimation (Bertsekas, 1971; Fogel and Huang, 1982; Lu and Cannon, 2023; Li et al., 2024).
Unlike LSE, SME is a set-estimator and directly estimates the uncertainty set. Since the analysis
of SME also relies on the probabilistic persistent excitation analysis, we can also establish the
7convergence rate of SME for linearly parameterized nonlinear systems under i.i.d. noises in the
following. In particular, SME estimates the uncertainty set as
ΘT=T−1\
t=0
ˆθ:xt+1−ˆθϕ(xt, ut)∈ W
, (3)
where Wis a bounded set such that wt∈ W for all t≥0.
The convergence of SME relies on an additional assumption as shown below: the tightness of the
bound Wonwt’s support. This tightness assumption is commonly considered in SME’s literature
(Li et al., 2024; Lu et al., 2019; Akçay, 2004). Further, (Li et al., 2024) discusses the relaxation of
this assumption by learning a tight bound at the same time of learning the uncertainty set of θ∗for
linear systems. Similar tricks can be applied to nonlinear systems, but this paper only considers the
vanilla case of SME for simplicity.
Assumption 5 (Tight bound on disturbances) .Assume for any ϵ >0, there exists qw(ϵ)>0, such
that for any 1≤j≤nandt≥0, we have P(wj
t+wmax≤ϵ)≥qw(ϵ)>0,P(wmax−wj
t≤ϵ)≥
qw(ϵ)>0.
Assumption 5 requires that wtcan visit set W’s boundary arbitrarily closely with a positive probability.
For example, for a one-dimensional wtbounded by −wmax≤wt≤wmax, Assumption 5 requires
that there is a positive probability that wtis close to wmaxand−wmax, i.e., for any ϵ >0, we have
P(wmax−ϵ≤wt≤wmax)>0andP(−wmax≤wt≤ −wmax+ϵ)>0.
Next, we state a non-asymptotic bound on the diameter of the uncertainty set estimated by SME.
Theorem 3 (SME’s diameter bound for open-loop systems) .Consider system (1) with i.i.d. inputs
ut=ηt. Suppose Assumptions 1, 2, 3, 4 are satisfied. Consider sϕandpϕdefined in Theorem 1 and
letbϕ= supt≥0∥ϕ(zt)∥2. For any m≥0andδ∈(0,1), when T > m , we have
P
diam(ΘT)> δ
≤T
m˜O 
n2.5
ϕ
anϕ
2exp(−a3m) + ˜O 
n2.5
xn2.5
ϕ
anxnϕ
4
1−qwa1δ
4√nx T
m
,
where a1=sϕpϕ
4,a2=64b2
ϕ
s2
ϕp2
ϕ,a3=p2
ϕ
8,a4=16bϕ√nx
sϕpϕ. The constants hidden in ˜Oare provided in
the Appendix C.1.
The proof of Theorem 3 relies on Theorem 1 in this paper and Theorem 1 from (Li et al., 2024). The
detailed proof is provided in Appendix C.1.
Theorem 3 establishes an upper bound on the "failure" probability of SME, i.e., the probability that
the uncertainty set’s diameter exceeds δ. To ensure the failure probability is less than 1, one can select
m=O(log(T))and choose a sufficiently large Tsuch that T≥m=O(log(T)). Ifwtis more
likely to visit the boundaries of the set W(meaning a larger q(ℓ)), SME is less likely to estimate an
uncertainty set with a diameter greater than δ.
To provide more intuitions on the diameter bound in Theorem 3, we consider qw(ℓ) =cwℓfor some
cw>0. Note that several common distributions, including the uniform distribution and the truncated
Gaussian distribution, satisfy this property on qw(ℓ)(see Appendix C.2 for explicit formulas of cw).
With qw(ℓ) =cwℓ, we can provide a convergence rate of SME in terms of Tin the following.
Corollary 2 (SME’s convergence rate when qw(ℓ) =cwℓ).For any ϵ >0, let
m≥O log T
ϵ
+nϕlog 8bϕ
sϕpϕ
p2
ϕ!
.
Ifwt’s distribution satisfies qw(ℓ) =cwℓfor all ℓ >0, then when T > m with probability at least
1−2ϵ, we have:
diam(ΘT)≤O m√nxlog 1
ϵ
+mn1.5
xnϕlog bϕnx
sϕpϕ
cwsϕpϕT!
,
where the constants hidden in O(·)are provided in Appendix C.
8The proof of Corollary 2 is provided in Appendix C.2.
Finally, similar to LSE, we can extend SME’s convergence rates from open-loop systems to closed-
loop systems with real-analytic control policies, i.e., ut=π(xt) +ηt, where ηtsatisfies Assumption
3 and π(xt)is real-analytic.
Corollary 3 (SME’s convergence rate for closed-loop systems) .Consider inputs ut=π(xt) +
ηt, where π(·)is real-analytic, ηtsatisfies Assumption 3, and the closed-loop system xt+1=
θ∗ϕ(xt, π(xt) +ηt) +wtsatisfies Assumption 4 in terms of both wtandηt. Then, the same
convergence rates in Theorem 3 and Corollary 2 still hold.
The proof of Corollary 3 is provided in Appendix C.3.
4 Numerical Experiments
In this section, we evaluate the performance of LSE in estimating the unknown parameter θ∗and
SME in estimating the uncertainty set for the unknown parameters using the pendulum and quadrotor
examples outlined in Section 2. We compare the empirical convergence rates of LSE and SME with
the theoretical rates in Theorem 2 and Corollary 2. In each case, the input utis composed of a
control policy and i.i.d. noise, such that ut=π(xt) +ηt. For our experiments, we employ noise
and disturbances drawn from uniform and truncated-Gaussian distributions. To compute theoretical
rates, we numerically estimate parameters such as sϕandpϕ(see Appendix E). Further details can be
found in our source code.7
The details for these scenarios are outlined below:
•Pendulum 1: In the pendulum example described in Section 2, the control input is ut=
−k˙αt+ηt. This scenario includes two unknown parameters: θ1=1
landθ2=1
ml2.
•Quadrotor 2: For the quadrotor example in Section 2, the control input is defined as
ut=π(xt) +ηt, where π(xt)follows the controller proposed by Alaimo et al. (2013). The
quadrotor system involves 13states and 4inputs, with the unknown parameter matrix θ∗
containing 7parameters, including the mass mand specific elements of the inertia matrix I.
Further details on controller gains and unknown parameters are provided in Appendix D.
LSE Results: Figures 1a and 1b present a comparison between the LSE theoretical bound from
Theorem 2 with its empirical estimation error of the unknown parameters θ∗versus trajectory length
Tfor the pendulum example, with uniform and truncated-Gaussian noises and disturbances. Similarly,
Figures 1c and 1d show this comparison for the quadrotor example. In each figure, both the theoretical
bound and empirical error are normalized by the l2norm of the nominal parameter θ∗. The log-log
plots for both scenarios demonstrate that the empirical error rate achieves O(1√
T)which in consistent
with the theoretical rate in Theorem 2.
SME Results: Figures 2a and 2b show the empirical convergence rate of SME for the pendulum
example, for uniform and truncated-Gaussian noises and disturbances, in comparison to the theoretical
rate from Corollary 2. Both the theoretical bound and empirical error in the figures are normalized by
thel2norm of the nominal parameter θ∗. The log-log plots indicate that the empirical rate achieves
O(1
T), which is consistent with the results from Corollary 2 and with the related results for linear
systems in (Li et al., 2024). A similar result can be observed for the quadrotor example, in Figures 2c
and 2d. Additionally, Figure 3 shows the uncertainty sets estimated by SME for the two unknown
parameters, labeled θ1andθ2, in the pendulum example, along with the diameters of these sets as
trajectory length grows. We observe that these sets contract as trajectory length increases, with the
true values of the unknown parameters lying within the estimated uncertainty sets. The illustration of
uncertainty sets for the quadrotor example is provided in Appendix D.2.
7https://github.com/NeginMusavi/real-analytic-nonlinear-sys-id
9(a) Uniform
 (b) Truncated-Gaussian
 (c) Uniform
 (d) Truncated-Gaussian
Figure 1: Convergence rate of the LSE for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform ([−1,1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian (0,0.1,[−1,1]). "theo" denotes the theoretical convergence rate, and "empr" represents
the empirical rate. The mean error across 20 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation.
(a) Uniform
 (b) Truncated-Gaussian
 (c) Uniform
 (d) Truncated-Gaussian
Figure 2: Convergence rate of the SME for pendulum and quadrotor scenarios: (a) Pendulum example with
uniform, (b) Pendulum example with truncated-Gaussian, (c) Quadrotor example with uniform, and (d) Quadrotor
example with truncated-Gaussian noises and disturbances. Here, uniform noises and disturbances are i.i.d.
generated from uniform ([−1,1]), and truncated-Gaussian noises and disturbances are i.i.d. generated from
truncated-Gaussian (0,0.5,[−1,1]). "theo" denotes the theoretical convergence rate, and "empr" represents
the empirical rate. The mean error across 10 trials is shown by dots on the empirical plots, with shaded areas
illustrating empirical standard deviation.
5 Concluding Remarks
Conclusion. This study examines the probabilistic persistent excitation in a class of nonlinear systems
influenced by i.i.d. noise and stochastic disturbances, with the stipulation that their distributions do
not concentrate on sets of Lebesgue measure zero. Based on this we then present an explicit bound
on the convergence rate of SME estimations and LSE estimations for this class of dynamical systems.
Additionally, numerical experiments in the context of robotics are provided to illustrate both methods.
Limitations. One limitation of this work is that our analysis relies on a specific class of i.i.d. noises
and stochastic disturbances, where the probability distribution is not concentrated on sets of Lebesgue
measure zero. While this is a sufficient condition, it is possible that the BMSB conditions are satisfied
under other circumstances. Another limitation is that, though we provide sufficient conditions for the
existence of parameters satisfying the BMSB condition, the explicit dependence is not detailed here.
Lastly, imperfect observations are not considered here.
Future Work. Our future work includes several promising directions, e.g., to explore cases that do
not satisfy our semi-continuity assumption, such as discrete noises, and to investigate the explicit
dependence of the BMSB parameter on system attributes, such as state, input, and feature dimensions,
etc. Furthermore, extending this work to imperfect state observations is an important next step.
Finally, a potential direction is to provide a non-asymptotic analysis of the volumes of uncertainty
sets estimated by SME uncertainty sets, as opposed to the current focus on their diameters.
10(a) Pendulum (b) Uncertainty set diameter (c) Uncertainty set
Figure 3: Performance of SME for pendulum in (a) with control input ut=−k˙αt+ηtwhere k= 0.1,
ηti.i.d. generated from truncated-Gaussian (0,2,[−2,2])and disturbed with wti.i.d. generated from
truncated-Gaussian (0,1,[−1,1]). (b) Diameter of the uncertainty set estimated by SME. (c) Uncertainty
set depicted for T= 50,200,250,400,500.
Broader Impact
This paper is a foundation research and develops theoretical insight to estimation of nonlinear control
systems. We do not see a direct path to negative applications in general. But we want to mention that
successful applications of our theoretical results rely on verifying the assumptions in this paper.
References
Yasin Abbasi-Yadkori and Csaba Szepesvári. Regret bounds for the adaptive control of linear
quadratic systems. In Proceedings of the 24th Annual Conference on Learning Theory , pages 1–26.
JMLR Workshop and Conference Proceedings, 2011.
Hüseyin Akçay. The size of the membership-set in a probabilistic framework. Automatica , 40(2):
253–260, 2004.
Andrea Alaimo, Valeria Artale, C Milazzo, Angela Ricciardello, and LUCA Trefiletti. Mathematical
modeling and control of a hexacopter. In 2013 International conference on unmanned aircraft
systems (ICUAS) , pages 1043–1050. IEEE, 2013.
Er-Wei Bai, Roberto Tempo, and Hyonyong Cho. Membership set estimators: size, optimal inputs,
complexity and relations with least squares. IEEE Transactions on Circuits and Systems I:
Fundamental Theory and Applications , 42(5):266–277, 1995.
Er-Wei Bai, Hyonyong Cho, and Roberto Tempo. Convergence properties of the membership set.
Automatica , 34(10):1245–1249, 1998.
Dimitri P Bertsekas. Control of uncertain systems with a set-membership description of the uncertainty.
PhD thesis, Massachusetts Institute of Technology, 1971.
Vladimir Igorevich Bogachev and Maria Aparecida Soares Ruas. Measure theory , volume 1. Springer,
2007.
Xinyi Chen and Elad Hazan. Black-box control for linear dynamical systems. In Conference on
Learning Theory , pages 1114–1143. PMLR, 2021.
Alexandru Cr ˘aciun and Debarghya Ghoshdastidar. On the stability of gradient descent for large
learning rate. arXiv preprint arXiv:2402.13108 , 2024.
Sarah Dean, Horia Mania, Nikolai Matni, Benjamin Recht, and Stephen Tu. Regret bounds for robust
adaptive control of the linear quadratic regulator. Advances in Neural Information Processing
Systems , 31:4188–4197, 2018.
Eli Fogel and Yih-Fang Huang. On the value of information in system identification—bounded noise
case. Automatica , 18(2):229–238, 1982.
11Dylan Foster, Tuhin Sarkar, and Alexander Rakhlin. Learning nonlinear dynamical systems from a
single trajectory. In Learning for Dynamics and Control , pages 851–861. PMLR, 2020.
Yihuai Gao, Yukai Tang, Han Qi, and Heng Yang. Closure: Fast quantification of pose uncertainty
sets. arXiv preprint arXiv:2403.09990 , 2024.
Paul R Halmos. Measure theory , volume 18. Springer, 2013.
Mohammad Khosravi. Representer theorem for learning koopman operators. IEEE Transactions on
Automatic Control , 2023.
Jihun Kim and Javad Lavaei. Online bandit control with dynamic batch length and adaptive learning
rate. 2024.
Jason Kong, Mark Pfeiffer, Georg Schildbach, and Francesco Borrelli. Kinematic and dynamic vehicle
models for autonomous driving control design. In 2015 IEEE intelligent vehicles symposium (IV) ,
pages 1094–1099. IEEE, 2015.
Suhas Kowshik, Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. Near-optimal offline and
streaming algorithms for learning non-linear dynamical systems. Advances in Neural Information
Processing Systems , 34:8518–8531, 2021.
Steven G Krantz and Harold R Parks. A primer of real analytic functions . Springer Science &
Business Media, 2002.
Bruce D Lee, Ingvar Ziemann, George J Pappas, and Nikolai Matni. Active learning for control-
oriented identification of nonlinear systems. arXiv preprint arXiv:2404.09030 , 2024.
Yingying Li, Subhro Das, and Na Li. Online optimal control with affine constraints. In Proceedings
of the AAAI Conference on Artificial Intelligence , volume 35, pages 8527–8537, 2021a.
Yingying Li, Yujie Tang, Runyu Zhang, and Na Li. Distributed reinforcement learning for decentral-
ized linear quadratic control: A derivative-free policy optimization approach. IEEE Transactions
on Automatic Control , 67(12):6429–6444, 2021b.
Yingying Li, James A Preiss, Na Li, Yiheng Lin, Adam Wierman, and Jeff S Shamma. Online
switching control with stability and regret guarantees. In Learning for Dynamics and Control
Conference , pages 1138–1151. PMLR, 2023a.
Yingying Li, Tianpeng Zhang, Subhro Das, Jeff Shamma, and Na Li. Non-asymptotic system
identification for linear systems with nonlinear policies. IFAC-PapersOnLine , 56(2):1672–1679,
2023b.
Yingying Li, Jing Yu, Lauren Conger, Taylan Kargin, and Adam Wierman. Learning the uncertainty
sets of linear control systems via set membership: A non-asymptotic analysis. In Proceedings of
the 41st International Conference on Machine Learning , pages 29234–29265. PMLR, 2024. URL
https://proceedings.mlr.press/v235/li24ci.html .
Yiheng Lin, James A Preiss, Emile Anand, Yingying Li, Yisong Yue, and Adam Wierman. On-
line adaptive policy selection in time-varying systems: No-regret via contractive perturbations.
Advances in Neural Information Processing Systems , 36, 2024.
Matthias Lorenzen, Mark Cannon, and Frank Allgöwer. Robust mpc with recursive model update.
Automatica , 103:461–471, 2019.
Xiaonan Lu and Mark Cannon. Robust adaptive model predictive control with persistent excitation
conditions. Automatica , 152:110959, 2023.
Xiaonan Lu, Mark Cannon, and Denis Koksal-Rivet. Robust adaptive model predictive control:
Performance and parameter estimation. International Journal of Robust and Nonlinear Control ,
2019.
Horia Mania, Michael I Jordan, and Benjamin Recht. Active learning for nonlinear system identifica-
tion with guarantees. Journal of Machine Learning Research , 23(32):1–30, 2022.
12Kumpati S Narendra and Anuradha M Annaswamy. Persistent excitation in adaptive systems.
International Journal of Control , 45(1):127–160, 1987.
Bernd R Noack, Konstantin Afanasiev, Marek Morzy ´nski, Gilead Tadmor, and Frank Thiele. A
hierarchy of low-dimensional models for the transient and post-transient cylinder wake. Journal of
Fluid Mechanics , 497:335–363, 2003.
Valentin V Petrov. On lower bounds for tail probabilities. Journal of statistical planning and
inference , 137(8):2703–2705, 2007.
Arnab Sarker, Peter Fisher, Joseph E Gaudio, and Anuradha M Annaswamy. Accurate parameter
estimation for safety-critical systems with unmodeled dynamics. Artificial Intelligence , page
103857, 2023.
Shankar Sastry and Marc Bodson. Adaptive control: stability, convergence and robustness . Courier
Corporation, 2011.
Yahya Sattar and Samet Oymak. Non-asymptotic and accurate learning of nonlinear dynamical
systems. Journal of Machine Learning Research , 23(140):1–49, 2022.
Yahya Sattar, Samet Oymak, and Necmiye Ozay. Finite sample identification of bilinear dynamical
systems. In 2022 IEEE 61st Conference on Decision and Control (CDC) , pages 6705–6711. IEEE,
2022.
Guanya Shi, Kamyar Azizzadenesheli, Michael O’Connell, Soon-Jo Chung, and Yisong Yue. Meta-
adaptive nonlinear control: Theory and algorithms. Advances in Neural Information Processing
Systems , 34:10013–10025, 2021.
B. Siciliano, L. Sciavicco, L. Villani, and G. Oriolo. Robotics: Modelling, Planning and Con-
trol. Advanced Textbooks in Control and Signal Processing. Springer London, 2010. ISBN
9781846286414. URL https://books.google.com/books?id=jPCAFmE-logC .
Max Simchowitz and Dylan Foster. Naive exploration is optimal for online lqr. In International
Conference on Machine Learning , pages 8937–8948. PMLR, 2020.
Max Simchowitz, Horia Mania, Stephen Tu, Michael I Jordan, and Benjamin Recht. Learning without
mixing: Towards a sharp analysis of linear system identification. In Conference On Learning
Theory , pages 439–473. PMLR, 2018.
John W Simpson-Porco, Florian Dörfler, and Francesco Bullo. V oltage stabilization in microgrids via
quadratic droop control. IEEE Transactions on Automatic Control , 62(3):1239–1253, 2016.
Fredrik P Skantze, A Koji ´c, A-P Loh, and Anuradha M Annaswamy. Adaptive estimation of
discrete-time systems with nonlinear parameterization. Automatica , 36(12):1879–1887, 2000.
Jean-Jacques E Slotine and Weiping Li. Applied nonlinear control , volume 199. Prentice hall
Englewood Cliffs, NJ, 1991.
Yukai Tang, Jean-Bernard Lasserre, and Heng Yang. Uncertainty quantification of set-membership
estimation in control and perception: Revisiting the minimum enclosing ellipsoid. In 6th Annual
Learning for Dynamics & Control Conference , pages 286–298. PMLR, 2024.
Andrew Wagenmaker and Kevin Jamieson. Active learning for identification of linear dynamical
systems. In Conference on Learning Theory , pages 3487–3582. PMLR, 2020.
Haonan Xu and Yingying Li. On the convergence rates of set membership estimation of linear
systems with disturbances bounded by general convex sets. arXiv preprint arXiv:2406.00574 ,
2024.
Christopher Yeh, Jing Yu, Yuanyuan Shi, and Adam Wierman. Online learning for robust voltage
control under uncertain grid topology. IEEE Transactions on Smart Grid , 2024.
Jing Yu, Dimitar Ho, and Adam Wierman. Online adversarial stabilization of unknown networked
systems. Proceedings of the ACM on Measurement and Analysis of Computing Systems , 7(1):1–43,
2023.
13Ingvar Ziemann and Stephen Tu. Learning with little mixing. Advances in Neural Information
Processing Systems , 35:4626–4637, 2022.
Ingvar Ziemann, Anastasios Tsiamis, Bruce Lee, Yassir Jedra, Nikolai Matni, and George J Pappas.
A tutorial on the non-asymptotic theory of system identification. In 2023 62nd IEEE Conference
on Decision and Control (CDC) , pages 8921–8939. IEEE, 2023.
Ingvar Ziemann, Stephen Tu, George J Pappas, and Nikolai Matni. Sharp rates in dependent learning
theory: Avoiding sample size deflation for the square loss. arXiv preprint arXiv:2402.05928 , 2024.
14Appendix
Roadmap
• Appendix A provides a proof of Theorem 1.
• Appendix B provides proofs of Theorem 2 and Corollary 1.
• Appendix C presents a proof of Theorem 3 and Corollaries 2 and 3.
• Appendix D provides more details of the simulation settings.
•Appendix E discusses the numerical estimation of the BMSB parameters (sϕ, pϕ)in Theo-
rem 1.
• The NeurIPS Paper Checklist is provided after the appendices.
A Proof Theorem 1
Proof. Given that ut=ηtand satisfies the conditions in Assumption 3, utis bounded, meaning
ut∈ U, where Uis a compact set. Moreover, since the system is LISS, there exist functions γ∈ K
andβ∈ KL , such that for all t≥0, the following holds:
xt∈ X=
x∈Rn:∥x∥2≤β(ρx,0) +γ(ρ)
with parameters ρx≥ ∥x0∥2andρ≥max( wmax, umax). LetZ=X ×U , then zt∈ Z for all t≥0.
The set Zis a compact subset of Rnx+nu.
To show that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1satisfies the BMSB condition, it is sufficient
to demonstrate that there exist sϕ>0andpϕ∈(0,1)such that for all t≥0and for any v∈Rnϕ
with∥v∥2= 1, the following holds:
P
|vTϕ(zt+1)| ≥sϕ∥v∥2Ft
≥pϕ. (4)
To establish this, we apply the Paley-Zygmund inequality, which gives a lower bound on the tail
probability of a non-negative random variable:
Lemma 1. (Paley-Zygmund (Petrov, 2007)) Let xbe a non-negative random variable. Then for any
r∈(0,1), the following holds:
P
x > rp
E[x2]
≥(1−r2)2E[x2]2
E[x4].
Based on this result, for any r∈(0,1), we have:
P 
v⊺ϕ(zt+1)> rs
E 
v⊺ϕ(zt+1)2FtFt!
≥(1−r2)2E 
v⊺ϕ(zt+1)2Ft2
E 
v⊺ϕ(zt+1)4Ft.(5)
LetV={v∈Rnϕ:∥v∥2= 1}. To show that the BMSB condition holds, it is sufficient to establish
the following two points:
•inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
>0,
• and sup
Ft, t≥0sup
v∈VE 
v⊺ϕ(zt+1)4Ft
<∞.
15These conditions ensure that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1satisfies the BMSB condition
with some constants sϕ>0andpϕ∈(0,1). We will divide the proof into two parts:
Step 1. Showing that inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
>0:
We begin by noting the following:
inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
= inf
Ft, t≥0inf
v∈VE 
v⊺ϕ 
xt+1, ut+12Ft
= inf
Ft, t≥0inf
v∈VE 
v⊺ϕ 
θ∗ϕ(zt) +wt, ut+12Ft
.
Since zt∈ Ftwhile wt, ut+1̸∈ Ft, we can treat ztas a constant and wt, ut+1=ηt+1as random
variables. From the continuity of features ϕ(·), we can conclude that:
inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
= inf
z∈Zinf
v∈VE 
v⊺ϕ 
θ∗ϕ(z) +w|{z}
=: h(z,w), η2
,
where w,ηare independent random variables, as assumed in Assumptions 2 and 3. Now, let
Nz
v=
(w, η)∈ W × U :v⊺ϕ 
h(z, w), η
= 0	
, and we have:
E 
v⊺ϕ 
h(z, w), η2
=E 
v⊺ϕ 
h(z, w), η21
v⊺ϕ 
h(z, w), η
= 0	
| {z }
=0
+E 
v⊺ϕ 
h(z, w), η21
v⊺ϕ 
h(z, w), η
̸= 0	
=E 
v⊺ϕ 
h(z, w), η2(w, η)̸∈ Nz
v
P
(w, η)̸∈ Nz
v
=E 
v⊺ϕ 
h(z, w), η2(w, η)̸∈ Nz
v
1−P
(w, η)∈ Nz
v
.
Therefore, we have:
inf
z∈Zinf
v∈VE 
v⊺ϕ 
h(z, w), η2
= inf
z∈Zinf
v∈VE 
v⊺ϕ 
h(z, w), η2(w, η)̸∈ Nz
v
×
1−sup
z∈Zsup
v∈VP
(w, η)∈ Nz
v
.(6)
It is evident that if Nz
v=∅, then
inf
z∈Zinf
v∈VE 
v⊺ϕ 
h(z, w), η2
̸= 0,andsup
z∈Zsup
v∈VP
(w, η)∈ Nz
v
= 0,
leading to inf
z∈Zinf
v∈VE 
v⊺ϕ 
h(z, w), η2
>0. Now we proceed with the case where Nz
v̸=∅.
For this, we can use the following lemma concerning the zero set of real-analytic functions in terms
of Lebesgue measure.
Lemma 2 (The zero set of real-analytic functions (Cr ˘aciun and Ghoshdastidar, 2024)) .The set of
zeros of a non-trivial real-analytic function f:Rn→Rhas a Lebesgue measure zero in Rn.
This is a known result and can be proved using the identity theorem along with Fubini’s theorem. For
further information on this topic, see sources such as (Krantz and Parks, 2002; Bogachev and Ruas,
2007).
Recall that we defined h(z, w) =θ∗ϕ(z) +w. Notice that h(·,·)is real-analytic. Now consider
v⊺ϕ 
h(z, w), η
=nϕX
i=1viϕi 
h(z, w), η
,
16where ϕi 
h(z, w), η
are linearly independent. Hence, the sumPnϕ
i=1viϕi 
h(z, w), η
̸≡0for any
v∈ V. This implies that v⊺ϕ 
h(z, w), η
is real-analytic and non-zero. Consequently, by Lemma 2,
λnx+nu(Nz
v) = 0 for any v∈ V.
Under Assumptions 3 and 2, there cannot exist a set E ⊂ Z of Lebesgue measure zero in Rnx+nufor
which the P 
(w, η)∈ E
= 1. Taking this into account, along with the fact that λnx+nu(Nz
v) = 0
and that the sets VandZare closed sets (implying they include all their limit points), we can conclude
that
sup
z∈Zsup
v∈VP
(w, η)∈ Nz
v
̸= 1.
Moreover, since λnx+nu(Nz
v) = 0 andλnx+nu(W × U )̸= 0, it follows that (Nz
v)c̸=∅. This
implies
inf
z∈Zinf
v∈VE 
v⊺ϕ 
h(z, w), η2(w, η)̸∈ Nz
v
̸= 0.
Substituting these results into (6), we obtain:
inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
>0.
Step 2. Showing that sup
Ft, t≥0sup
v∈VE 
v⊺ϕ(zt+1)4Ft
<∞:
Since zt∈ Z fort≥0, and considering that the noise and disturbances are bounded while the
features are real-analytic, it follows that zt+1|Ftis a bounded random variable. Consequently,
v⊺ϕ(zt+1)|Ftis also bounded. Given that both ZandVare compact sets—meaning they contain
all their limit points—and that any random variable with bounded support has finite moments, we
conclude that
sup
Ft, t≥0sup
v∈VE 
v⊺ϕ(zt+1)4Ft
<∞.
We finalize the proof by combining the results from Step 1 and Step 2.
B Proofs for Theorem 2 and Corollary 1
B.1 Proof of Theorem 2
Proof. The proof hinges on the following key meta-theorem about the LSE convergence rate:
Theorem 4 (LSE meta-theorem (Simchowitz et al., 2018)) .Fixδ∈(0,1),T≥1, and 0≺Γsb≺¯Γ.
Consider a random process {(yt, xt)}t≥1∈(Rny×Rnx)T, and a filtration {Ft}t≥1. Suppose the
following conditions hold:
•xt=θ∗yt+wt, where wt|Ftis a zero mean σ2
w-sub-Gaussian,
•{yt}t≥1is an{Ft}t≥1-adapted random process satisfying the (k,Γsb, p)-BMSB condition,
•P PT
t=1yty⊺
t̸⪯T¯Γ
≤δ.
If the trajectory length Tsatisfies
T≥10k
p2 
log1
δ
+ log det
¯ΓΓ−1
sb
+ 2nylog10
p!
,
then with probability at least 1−3δ, LSE estimation error is bounded by:
ˆθT−θ∗
2≤90σw
pvuuutnx+ log
1
δ
+ log det
¯ΓΓ−1
sb
+nylog
10
p
Tσmin(Γsb).
17Since wtsatisfies the Assumption 2), and wt/∈ Ft, then σw|Ftis sub-Gaussian with parameter σw.
Additionally, system (1) is linear in unknown parameters θ∗. From Theorem 1, the {Ft}t≥1-adapted
process {ϕ(zt)}t≥1satisfies the (1, s2
ϕInϕ, pϕ)-BMSB condition for some sϕ>0andpϕ∈(0,1].
To complete the proof, it is left to show that for any δ∈(0,1), there exists a ¯Γ≻s2
ϕInϕ, such that
PTX
t=1ϕ(zt)ϕ⊺(zt)⪯̸T¯Γ
≤δ.
To see this, note that for ¯bϕ= supt≥0E
∥ϕ(zt)∥2
2
, we have:
PTX
t=1ϕ(zt)ϕ⊺(zt)⪯̸¯bϕT
δInϕ
=P 
λmaxTX
t=1ϕ(zt)ϕ⊺(zt)
≻λmax¯bϕT
δInϕ!
=PTX
t=1ϕ(zt)ϕ⊺(zt)
2≻¯bϕT
δ
≤δEPT
t=1ϕ(zt)ϕ⊺(zt)
2
¯bϕT.
In addition, we have:
ETX
t=1ϕ(zt)ϕ⊺(zt)
2
≤TX
t=1Eϕ(zt)ϕ⊺(zt)
2
≤TX
t=1E
∥ϕ(zt)∥2
2
≤Tsup
t≥0E
∥ϕ(zt)∥2
2
,
which implies that:
PTX
t=1ϕ(zt)ϕ⊺(zt)⪯̸T¯Γ
≤δ, (7)
where ¯Γ =¯bϕ
δInϕ. since zt∈ Z for all t≥0, withZbeing a compact set (due to the system’s LISS
property and features ϕ(·)being real-analytic), such a bounded ¯bϕexists, completing the proof.
B.2 Proof of Corollary 1
Proof. We start the proof by stating the following lemma which is extension of Theorem 1 to the case
withut=π(xt) +ηt.
Lemma 3. Letut=π(xt)+ηt,π(·)is real-analytic, ηtsatisfies Assumption 3. Consider the filtration
Ft=F(w0,···, wt−1, x0,···, xt, π(x0),···, π(xt), η0,···, ηt). Suppose Assumptions 1, 2 hold
and that the closed-loop system xt+1=θ∗ϕ(xt, π(xt) +ηt) +wtsatisfies Assumption 4 for both
wtandηt. Then there exist sϕ>0, and pϕ∈(0,1)such that the {Ft}t≥1-adapted process
ϕ 
xt, ut	
t≥1satisfies the 
1, s2
ϕInϕ, pϕ
-BMSB condition.
Proof of Lemma 3. The proof closely follows the steps of Theorem 1. First, observe that ut=
π(xt) +ηt. Since ηtsatisfies the conditions outlined in Assumption 3, and the closed-loop system
xt+1=θ∗ϕ(xt, π(xt) +ηt) +wtadheres to Assumption 4 with respect to both wtandηt, there
exist functions γ∈ K andβ∈ KL such that for all t≥0the following holds:
xt∈ X=
x∈Rn:∥x∥2≤β(ρx,0) +γ(ρ)
with parameters ρx≥ ∥x0∥2andρ≥max( wmax, umax). LetZ=X × U , where Uis a compact set
containing utfor all t≥0. Thus, zt∈ Z for all t≥0. The set Zis a compact subset of Rnx+nu.
The remaining part of the proof, specifically to show that sup
Ft, t≥0sup
v∈VE 
v⊺ϕ(zt+1)4Ft
<∞
follows similarly to the proof in Theorem 1.
18It remains to show that inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
>0. This can be shown as follows:
inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
= inf
Ft, t≥0inf
v∈VE 
v⊺ϕ 
xt+1, ut+12Ft
= inf
Ft, t≥0inf
v∈VE
v⊺ϕ 
xt+1, π(xt+1) +ηt+12Ft
= inf
Ft, t≥0inf
v∈VE
v⊺ϕ
θ∗ϕ(zt) +wt,
π 
θ∗ϕ(zt) +wt
+ηt+12Ft
.
Since zt∈ Ftandwt, ηt+1̸∈ Ftthenztis treated as constant while wt, ηt+1are considered random
variables. Then, by the continuity of ϕwe conclude that
inf
Ft, t≥0inf
v∈VE 
v⊺ϕ(zt+1)2Ft
= inf
z∈Zinf
v∈VE
v⊺ϕ
θ∗ϕ(z) +w|{z}
=: h(z,w), π 
θ∗ϕ(z) +w|{z}
=: h(z,w)
+η2
= inf
z∈Zinf
v∈VE
v⊺ϕ
h(z, w), π 
h(z, w)
+η2
where wandηare independent random variables constrained as described in Assumptions 2 and 3.
By letting Nz
v=
(w, η)∈ W × U :v⊺ϕ 
h(z, w), π 
h(z, w)
+η
= 0	
, similar to (6) we have:
inf
z∈Zinf
v∈VE
v⊺ϕ
h(z, w),π 
h(z, w)
+η2
= inf
z∈Zinf
v∈VE
v⊺ϕ
h(z, w), π 
h(z, w)
+η2(w, u)̸∈ Nz
v
×
1−sup
z∈Zsup
v∈VP
(w, η)∈ Nz
v
.
We aim to show that λnx+nu(Nz
v) = 0 by applying Lemma 2. Note that ϕ(·),h(·), andπ(·)are real-
analytic. To use the results of Lemma 2, we need to establish that v⊺ϕ
h(z, w), π 
h(z, w)
+η
is
non-zero for any v∈ V. First, observe that:
v⊺ϕ 
h(z, w), π(h(z, w)) +η
=nϕX
i=1viϕi 
h(z, w), π(h(z, w)) +η)
.
Now consider two scenarios:
• All components of π 
h(z, w)
are linearly independent with any component of h(z, w).
•At least one component of π 
h(z, w)
is linearly dependent with one or more components
ofh(z, w).
In both cases, due to the additive nature of η, all the functions ϕi 
h(z, w), π(h(z, w)) +η)
with
i= 1,···, nϕare linearly independent, ensuring that v⊺ϕ 
h(z, w), π(h(z, w)) +η
̸≡0for any
v∈ V. The remainder of the proof follows similarly to the argument in Theorem 1.
Using this Lemma, Theorem 4, and reasoning similar to that in the proof of Theorem 2, the proof can
be completed.
19C Proofs for Theorem 3, Corollary 2, and Corollary 3
C.1 Proof of Theorem 3
Proof. The proof follows from applying the following meta-theorem on the convergence rate of SME.
Theorem 5 (SME meta-theorem (Li et al., 2024)) .Consider a general time series model with linear
responses as follows:
xt=θ∗yt+wt, t≥0.
Also, define the filtration Ft=F(w0,···, wt−1, y0,···, yt). Assume the following conditions are
met:
•wtare i.i.d. with variance σ2
wInx, and box-constrained, i.e., wt∈ W ={w∈Rnx:
∥w∥∞≤wmax}for some wmax>0.
•{yt}t≥1is an{Ft}t≥1-adapted random process satisfying the (k, s2
yIny, py)-BMSB condi-
tion.
•There exists by>0such that ∥yt∥2≤byalmost surely for all t≥0.
•For any ℓ >0, there exists qw(ℓ)>0, such that for any 1≤j≤nandt≥0, we have
P(wj
t+wmax≤ℓ)≥qw(ℓ)>0,P(wmax−wj
t≤ℓ)≥qw(ℓ)>0.
Then for any m≥1and any δ∈(0,1), when T > m , the diameter of the uncertainty set
ΘT=T−1\
t=0
ˆθ:xt−ˆθyt∈ W
satisfies:
P
diam(ΘT)> δ
≤544T
mn2.5
ylog(a2ny)any
2exp(−a3m)
+ 544 n2.5
xn2.5
ylog(a4nxny)anxny
4
1−qwa1δ
4√nx⌈T/m⌉
,
where a1=sypy
4,a2=64b2
y
s2yp2y,a3=p2
y
8,a4= max
4by√nx
a1,1
.
Observe that system (1) is linear in the unknown parameters θ∗, and we can prove Theorem 3
by showing that the {Ft}t≥1-adapted process {ϕ(zt)}t≥1andwtmeet the conditions of the meta-
theorem. By Assumptions 2 and 5, and since wt̸∈ Ft, the noise wtfulfills all the requirements of the
meta-theorem. Moreover, according to Theorem 1, the {Ft}t≥1-adapted process ϕ(zt)t≥1satisfies
the(1, s2
ϕInϕ, pϕ)-BMSB condition for some sϕ>0andpϕ∈(0,1]. Lastly, since the system is
LISS, we have zt∈ Z for all t≥0, where Zis the compact set defined in the proof of Theorem 1.
Therefore, there exists a constant bϕ>0such that supt≥0∥ϕ(zt)∥2≤bϕ, completing the proof of
the theorem.
Explicitly, this means that for any m≥1, for any δ∈(0,1), when T > m , we have:
P
diam(ΘT)> δ
≤544T
mn2.5
ϕlog(a2nϕ)anϕ
2exp(−a3m)
+ 544 n2.5
xn2.5
ϕlog(a4nxnϕ)anxnϕ
4
1−qwa1δ
4√nx⌈T/m⌉
,(8)
where a1=sϕpϕ
4,a2=64b2
ϕ
s2
ϕp2
ϕ,a3=p2
ϕ
8,a4=16bϕ√nx
sϕpϕ.
20C.2 Proof of Corollary 2
Let us provide two example distributions, truncated Gaussian and uniform, along with their corre-
sponding qw(·)(from (Li et al., 2024)):
•Ifwtfollows a uniform distribution on [−wmax, wmax]nx, then qw(ℓ) =cwℓwithcw=
1
2wmax.
•Ifwtfollows a truncated-Gaussian distribution on [−wmax, wmax]nx, generated by a Gaus-
sian distribution with zero mean and covariance matrix σ2
wInx, then qw(ℓ) =cwℓwith
cw=1
min(√
2πσw,2wmax)exp(−w2
max
2σ2w).
Now, fix ϵ∈(0,1). We want to show that if q a1δ
4√nϕ
=cwa1δ
4√nϕand we choose m≥1such that
m≥1
a3
logT
ϵ
+nϕlog(a2) + 2.5 log( nϕ) + log log( a2nϕ) + log(544)
, (9)
then for all T≥m, we have
δ≤O √nxlog 1
ϵ
+n1.5
xnϕlog bϕ√nx
sϕpϕ
cwsϕpϕT!
(10)
with probability at least 1−2ϵ.
Let the two terms in right hand-side of (8)be denoted by "term 1" and "term 2". We proceed with the
proof in two steps as follows:
Step 1: showing that with choice of min(9), term 1 ≤ϵ:
With this choice of m, it is straightforward to see that
544Tn2.5
ϕlog(a2nϕ)anϕ
2exp(−a3m)≤ϵ,
and thus term 1 ≤ϵ.
Step 2: letting term 2 =ϵand showing that δsatisfies the inequality in (10):
Assuming without loss of generality thatT
mis an integer, note that term 2 =ϵimplies:
qwa1δ
4√nx
=
1−ϵ
544n2.5xn2.5
ϕlog(a4nxnϕ)anxnϕ
4m
T
≤ −logϵ
544n2.5xn2.5
ϕlog(a4nxnϕ)anxnϕ
4m
T
=−m
Tlogϵ
544n2.5xn2.5
ϕlog(a4nxnϕ)anxnϕ
4
=m
T
log1
ϵ
+ log( a4)nxnϕ+ 2.5 log( nxnϕ) + log log( a4nxnϕ) + log(544)
.
Ifqw a1δ
4√nx
=cwa1δ
4√nxfor some constant cw>0, then:
δ≤4√nxm
cwa1T
log1
ϵ
+ log( a4)nxnϕ+ 2.5 log( nxnϕ) + log log( a4nxnϕ) + log(544)
≤16√nxm
cwsϕpϕTO 
log1
ϵ
+nxnϕlog16bϕ√nx
sϕpϕ!
≤O √nxlog 1
ϵ
+n1.5
xnϕlog bϕnx
sϕpϕ
cwsϕpϕT!
.
Combining these two steps, we conclude that, with probability at least 1−2ϵ,
diam(ΘT)≤O √nxlog 1
ϵ
+n1.5
xnϕlog bϕnx
sϕpϕ
cwsϕpϕT!
.
21C.3 Proof of Corollary 3
This corollary’s proof builds on Lemma 3 in Appendix B.2 and closely aligns with the proofs of
Theorem 3 and Corollary 2.
D Numerical Experiments
This section provides details on the simulation experiments.
D.1 Pendulum
The ground truth for the unknown parameters for pendulum example in Example 1 is set to be
m= 0.1(kg), l= 0.5(m),
and discretization time step in our numerical experiments is dt= 0.01(s). The control input is a
simple feedback controller ut=−k˙αt+ηt. In Figures 1a and 1b we choose k= 2and in Figures 2a,
2b and 3 we choose k= 0.1. Note there are two unknown parameters in this pendulum example as
follows:
θ1=1
l, θ2=1
ml2.
D.2 Quadrotor
The ground truth for the unknown parameters for quadrotor example in Example 2 is set to be
m= 0.468 ( kg),
Ixx= 4.856×10−3(kg/m2), Iyy= 4.856×10−3(kg/m2), Izz= 8.801×10−3(kg/m2).
The discretization time step in our numerical experiments is dt= 0.01(s). The control input is a
control policy plus i.i.d. noise. The control policy on altitude and the three Euler angles is borrowed
from (Alaimo et al., 2013). The controller gains in our numerical experiments are chosen as:
kpz= 0.75, kd z= 1.25,
kpϕ= 0.03, kd ϕ= 0.00875 ,
kpθ= 0.03, kd θ= 0.00875 ,
kpψ= 0.03, kd ψ= 0.00875 .
Note that there are seven unknown parameters in this quadrotor example, as follows:
θ1=1
m,
θ2=1
Ixx, θ3=Iyy−Izz
Ixx, θ4=1
Iyy, θ5=Izz−Ixx
Iyy, θ6=1
Izz, θ7=Ixx−Izz
Izz.
Figure 4 displays the uncertainty set estimated by SME for the seven unknown parameters in the
quadrotor example for various trajectory lengths, with ηtandwtbeing i.i.d. samples from truncated-
Gaussian distributions. The uncertainty sets are observed to shrink as the trajectory length increases,
consistent with our theoretical results. Note that the ground truth value is contained within all the
uncertainty sets.
E Numerical Estimation of BMSB Parameters (sϕ, pϕ)
We compare the empirical rates of LSE and SME with their theoretical counterparts in Section 4. The
theoretical results presented in Theorem 2 and Corollary 2 rely on the parameters bϕ,¯bϕ, and the
BMSB parameters (sϕ, pϕ). However, the explicit relationship of these parameters with system, noise,
and disturbance characteristics such as nx,nu,nϕ,σu, and σwis not known and we will address
this in our future work. Consequently, we estimate these parameters numerically and utilize these
22Figure 4: 2D projections of the uncertainty set estimated by SME for the unknown parameters of the quadrotor
example. The noises and disturbances are i.i.d generated from truncated-Gaussian (0,0.5,[−1,1]).
estimates to calculate the theoretical rates discussed in Section 4. While bϕand¯bϕare straightforward
to estimate, special attention is required to estimate the BMSB parameters. This section is dedicated
to describing this estimation process.
For this, consider a system of the form (1). For this system, our goal is to estimate sϕandpϕ, where
pϕ= inf
Ft,t≥0inf
∥v∥2=1P
|vTϕ(zt+1)| ≥sϕFt
numerically. First, observe that ϕ(zt+1)| Ft=ϕ(θT
∗ϕ(zt) +wt, ut+1), where zt∈ Ft. This implies
thatϕ(zt+1)| Ftis a random variable influenced by wtandut+1. We proceed by fixing sϕ= ¯s(for
some ¯s >0) and empirically estimate pϕ. To accomplish this, we first select a time horizon Tand
generate several trajectories of length Tfor the system. Let DTrepresent the set of these trajectories,
whileDtdenotes a subset containing all trajectories up to t≤T. Additionally, we create multiple
vectors v∈Rnϕsuch that ∥v∥2= 1; we refer to this collection as ¯V. These vectors are randomly
sampled from a Gaussian distribution and subsequently normalized.
We then estimate ¯pas:
¯p= min
t∈[T]min
z∈Dtmin
v∈¯VP
|vTϕ(θT
∗ϕ(z) +wt, ut+1)| ≥¯s
.
AsTincreases, along with the number of trajectories and vectors v, the minimum estimates will more
accurately reflect the infimums. In this context, ¯prepresents the minimum of P
|vTϕ(θT
∗ϕ(z) +
wt, ut+1)| ≥¯s
across all combinations in [T]× DT×¯V. For each combination in this set, we
estimate the probability P
|vTϕ(θT
∗ϕ(z) +wt, ut+1)| ≥¯s
using Monte Carlo simulations. This
process entails generating multiple random samples based on the distributions of wtandut+1,
verifying whether each sample satisfies the condition |¯vTϕ(z)| ≥¯s, and tallying how many samples
meet this criterion. We repeat this procedure for various values of ¯suntil we identify a pair of (¯s,¯p)
such that ¯p∈(0,1). The estimated probability is calculated as the ratio of the count of successful
samples to the total number of samples. According to the law of large numbers, this ratio converges
to the true probability as the number of samples increases. For our estimations, we select T= 50 ,
|¯V|= 1000 , and|DT|= 20 .
23