Published in Transactions on Machine Learning Research (05/2024)
Regret Bounds for
Noise-Free Cascaded Kernelized Bandits
Zihan Li lizihan@u.nus.edu
National University of Singapore
Jonathan Scarlett scarlett@comp.nus.edu.sg
National University of Singapore
Reviewed on OpenReview: https: // openreview. net/ forum? id= oCfamUtecN
Abstract
We consider optimizing a function network in the noise-free grey-box setting with RKHS
function classes, where the exact intermediate results are observable. We assume that the
structure of the network is known (but not the underlying functions comprising it), and we
study three types of structures: (1) chain: a cascade of scalar-valued functions, (2) multi-
output chain: a cascade of vector-valued functions, and (3) feed-forward network: a fully
connected feed-forward network of scalar-valued functions. We propose a sequential upper
confidence bound based algorithm GPN-UCB along with a general theoretical upper bound
on the cumulative regret. In addition, we propose a non-adaptive sampling based method
along with its theoretical upper bound on the simple regret for the Matérn kernel. We also
provide algorithm-independent lower bounds on the simple regret and cumulative regret.
Our regret bounds for GPN-UCB have the same dependence on the time horizon as the
best known in the vanilla black-box setting, as well as near-optimal dependencies on other
parameters (e.g., RKHS norm and network length).
1 Introduction
Black-box optimization of an expensive-to-evaluate function based on point queries is a ubiquitous problem
in machine learning. Bayesian optimization (or Gaussian process optimization) refers to a class of methods
usingGaussianprocesses(GPs),whosemainideaistoplaceapriorovertheunknownfunctionandupdatethe
posterior according to point query results. Bayesian optimization has a wide range of applications including
parameter tuning (Snoek et al., 2012), experimental design (Griffiths and Hernández-Lobato, 2020), and
robotics (Lizotte et al., 2007). While function evaluations are noisy in most applications, there are also
scenarios where noise-free modeling can be suitable, such as simulation (Nguyen et al., 2016), goal-driven
dynamics learning (Bansal et al., 2017), and density map alignment (Singer and Yang, 2023).
In the literature on Bayesian optimization, the problem of optimizing a real-valued black-box function is
usually studied under two settings: (1) Bayesian setting: the target function is sampled from a known GP
prior, and (2) non-Bayesian setting: the target function has a low norm in reproducing kernel Hilbert space
(RKHS).
In this work, we consider a setting falling “in between” the white-box setting (where the full definition of
the target function is known) and the black-box setting, namely, a grey-box setting in which the algorithms
can leverage partial internal information of the target function beyond merely the final outputs or even
slightly modify the target function (Astudillo and Frazier, 2021b). Existing grey-box optimization methods
exploit internal information such as observations of intermediate outputs for composite functions (Astudillo
and Frazier, 2019) and lower fidelity but faster approximation of the final output for modifiable functions
(Huang et al., 2006). Numerical experiments show that the grey-box methods significantly outperform
standard black-box methods (Astudillo and Frazier, 2021b).
1Published in Transactions on Machine Learning Research (05/2024)
Though any real-valued network can be treated as a single black-box function and solved with classical
Bayesianoptimizationmethods, weexplorethebenefitsofferedbyutilizingthenetworkstructureinformation
and the exact intermediate results under the noise-free grey-box setting. Several practical applications of
the cascaded setting (e.g., alloy heat treatment and simulation) are highlighted in Appendix A.
1.1 Related Work
Numerous works have proposed Bayesian optimization algorithms for optimizing a single real-valued black-
box function under the RKHS setting. For the noisy setting, (Srinivas et al., 2010; Chowdhury and Gopalan,
2017; Gupta et al., 2022) provided a typical cumulative regret /tildewideO(√
TγT), whereTis the time horizon, γT
is the maximum information gain associated to the underlying kernel, and the /tildewideO(·)notation hides the poly-
logarithmic factors. Recently, (Camilleri et al., 2021; Salgia et al., 2021; Li and Scarlett, 2022) achieved
cumulative regret /tildewideO(√TγT), which nearly matches algorithm-independent lower bounds for the squared
exponential and Matérn kernels (Scarlett et al., 2017; Cai and Scarlett, 2021). For the noise-free setting,
(Bull, 2011) achieved a nearly optimal simple regret O(T−ν/d)for the Matérn kernel with smoothness ν.
This result implies a two-batch algorithm that uniformly selects Td
ν+dpoints in the first batch and repeatedly
picks the returned point in the second batch, has cumulative regret O(Td
ν+d). In addition, (Lyu et al., 2019)
provided deterministic cumulative regret O(√TγT), with the rough idea being to substitute zero noise into
the analysis of GP-UCB (Srinivas et al., 2010). Recently, (Salgia et al., 2023) proposed a batch algorithm
based on random sampling, attaining cumulative regret /tildewideO(T1−ν/d)whenν < dandO(poly(logT))when
ν≥d.
Meanwhile, several Bayesian optimization algorithms for optimizing a composition of multiple functions
under the noise-free setting have been proposed. (Nguyen et al., 2016) provides a method for cascade
Bayesianoptimization; (AstudilloandFrazier,2019)studiesoptimizingacompositionofablack-boxfunction
and a known cheap-to-evaluate function; and (Astudillo and Frazier, 2021a) studies optimizing a network
of functions sampled from a GP prior under the grey-box setting. Both (Astudillo and Frazier, 2019) and
(Astudillo and Frazier, 2021a) prove the asymptotic consistency of their expected improvement sampling
based methods.
The most related works to ours are (Kusakawa et al., 2022) and (Sussex et al., 2023). (Kusakawa et al., 2022)
introduces two confidence bound based algorithms along with their regret guarantees for both noise-free and
noisy settings, as well as an expected improvement based algorithm without theory. (Sussex et al., 2023)
considers directed grey-box networks representing a causal structure, and proposes an expected improvement
based method with regret guarantee. A detailed comparison regarding problem setup and theoretical perfor-
mance is provided in Appendix K. In short, we significantly improve certain dependencies in their regret for
a UCB-type approach, and we study two new directions – non-adaptive sampling and algorithm-independent
lower bounds – that were not considered therein (summarized in Section 1.2).
For function networks with mlayers, our cumulative regret bounds are expressed in terms of
ΣT= max
i∈[m]max
z1,...,zT∈X(i)T/summationdisplay
t=1σ(i)
t−1(zt),
whereX(i)andσ(i)
t−1(·)denote the domain and posterior standard deviation of the i-th layer respectively.
This is a term for general layer-composed networks associated to domains X(1),...,X(m)and kernel k.
Whenm= 1, the term maxx1,...,xT∈X/summationtextT
t=1σt−1(xt)often appears in the cumulative regret analysis of
classic black-box optimization (Srinivas et al., 2010; Lyu et al., 2019; Vakili, 2022). Explicit upper bounds
onΣTwill be discussed in Section 3.4.
1.2 Contributions
We study the problem of optimizing an m-layer function network in the noise-free grey-box setting, where
the exact intermediate results are observable. We focus on three types of network structures: (1) chain:
2Published in Transactions on Machine Learning Research (05/2024)
Lower bound Ω(B(cL)m−1T1−ν/d)
Upper bound (chains) O(2mBLm−1ΣT)(c)=O(2mBLm−1T1−ν/d)
Upper bound (multi-output chains) O(5mBLm−1ΣT)(c)=O(5mBLm−1T1−ν/dmax)
Upper bound (feed-forward networks) O(2m/radicalbig
D2,mBLm−1ΣT)(c)=O(2m/radicalbig
D2,mBLm−1T1−ν/dmax)
Table 1: Summary of cumulative regret bounds for the Matérn kernel when d≥ν≥1andT=
Ω/parenleftbig
(B(cL)m−1)d/ν/parenrightbig
for somec= Θ(1). Here(c)=indicates the behavior when a conjecture of (Vakili, 2022)
on the black-box setting holds.
x=x(1)x(2) ··· x(m) yg
f(1)f(1)f(2)f(2)f(m−1)f(m−1)f(m)f(m)
d=d1 d2 dm dm+1= 1
Figure 1: A function network gofmlayers with input xand output y.
a cascade of scalar-valued functions, (2) multi-output chain: a cascade of vector-valued functions, and (3)
feed-forward network: a fully connected feed-forward network of scalar-valued functions. Then:
•We propose a fully sequential upper confidence bound based algorithm GPN-UCB along with its
upper bound on cumulative regret for each network structure. Our regret bound significantly re-
duces certain dependencies compared to (Kusakawa et al., 2022), in particular showing that their
dependence on a “posterior standard deviation Lipschitz constant” can be completely removed.
•We introduce a non-adaptive sampling based method, and provide its theoretical upper bound on
the simple regret for the Matérn kernel.
•We provide algorithm-independent lower bounds on the simple and cumulative regret for an arbi-
trary algorithm optimizing any chain, multi-output chain, or feed-forward network associated to the
Matérn kernel. In broad regimes of interest, these provide evidence or even proof that our upper
bounds are near-optimal.
•While the goals of this paper are essentially entirely theoretical, we show in Appendix L that (slight
variations of) our algorithms can be effective in at least simple experimental scenarios.
Letddenote the dimension of the domain, dmaxdenote the maximum dimension among all the mlayers,
andD2,mdenote the product of dimensions from the second layer to the last layer. With B > 0restricting
the magnitude and smoothness of each layer and L>1restricting the slope of each layer, a partial summary
of the proposed cumulative regret bounds for the Matérn kernel with smoothness ν≥1whend≥νand
T= Ω/parenleftbig
(B(cL)m−1)d/ν/parenrightbig
forc= Θ(1)is displayed in Table 1. From this table, we note the following:
•The upper and lower bounds share the same BLm−1T1−ν/ddependence when d=dmaxand simul-
taneously a conjecture of (Vakili, 2022) holds.
•Even without such a conjecture, the dependence on ΣTis precisely that given in state-of-the-art
bounds for the vanilla black-box setting (Vakili, 2022), and rigorous upper bounds on it are known.
See Section 3.4 for further details on the conjecture and rigorous bounds.
To our knowledge, we are the first to attain provably near-optimal scaling (in broad cases of interest),
and doing so requires both improving the existing upper bounds and attaining novel lower bounds. A full
summary of our theoretical results is provided in Appendix J. Perhaps our most restrictive assumption is
noise-free observations, but we believe this is a crucial stepping stone towards the noisy setting (as was the
case with regular black-box optimization, e.g., (Bull, 2011)).
3Published in Transactions on Machine Learning Research (05/2024)
2 Problem Setup
We consider optimizing a real-valued grey-box function gonX= [0,1]dbased on noise-free point queries.
As shown in Figure 1, the target function gis known to be a network of munknown layers f(i)withi∈[m].
In general, for any input x∈X, the network ghasx(1)=xand
x(i+1)=f(i)(x(i)) fori∈[m−1],
y=g(x) =f(m)(x(m))∈R,
where x(i)has dimension difor eachi∈[m]. The domain of f(i)isX(i), and the range of f(i)isX(i+1).1
For any z∈X(i), there exists x∈Xsuch that x(i)=z.
We aim to find x∗= arg maxx∈Xg(x)based on a sequence of point queries up to time horizon T. When we
querygwith input xtat time step t, the intermediate noise-free results x(2)
t,...,x(m)
tand the final noise-free
outputytare accessible. We measure the performance as follows:
•Simple regret : With x∗
Tbeing the additional point returned after Trounds, the simple regret is
defined asr∗
T=g(x∗)−g(x∗
T);
•Cumulative regret : The cumulative regret incurred over Trounds is defined as RT=/summationtextT
i=1rt
withrt=g(x∗)−g(xt).
2.1 Kernelized Bandits
We assume gis a composition of multiple constituent functions, for which we consider both scalar-valued
functions and vector-valued functions based on a given kernel. For a scalar-valued kernel kand a known
constantB > 0, we consider scalar-valued functions that lie in Hk(B), the reproducing kernel Hilbert space
(RKHS) associated to k, with norm at most B. In this work, we focus on the Matérn kernel kMatérnwith
smoothness ν > 0. Similarly, for an operator-valued kernel Γand a known constant B > 0, we consider
vector-valued functions in HΓ(B), the RKHS corresponding to Γwith norm at most B. More details on
RKHS and kMatérnare given in Appendix B.
2.2 Surrogate GP Model
As is common in kernelized bandit problems, our algorithms employ a surrogate Bayesian GP model for
f∈Hk(B). For prior with zero mean and kernel k, given a sequence of points (x1,...,xt)and their noise-
free observations yt= (y1,...,yt)up to timet, the posterior distribution of the function is a GP with mean
and variance given by (Rasmussen and Williams, 2006)
µt(x) =kt(x)TK−1
tyt (1)
σt(x)2=k(x,x)−kt(x)TK−1
tkt(x), (2)
where kt(x) = [k(x,xi)]t
i=1∈Rt×1andKt= [k(xi,xj)]t
i,j=1∈Rt×t. The following lemma shows that the
posterior confidence region defined with parameter Bis always deterministically valid.
Lemma 1. (Kanagawaetal.,2018, Corollary3.11) Forf∈Hk(B), letµt(x)andσt(x)2denote the posterior
mean and variance based on tpoints (x1,...,xt)and their noise-free observations (y1,...,yt)using(1)and
(2). Then, it holds for all x∈Xthat
|f(x)−µt(x)|≤Bσt(x).
We also impose a surrogate GP model for functions in HΓ(B). The posterior mean and covariance matrix
based on (x1,...,xt)and the noise-free observations Yt= (y1,...,yt)are (Chowdhury and Gopalan, 2021)
µt(x) =Gt(x)TG−1
tYt, (3)
Γt(x,x) = Γ( x,x)−Gt(x)TG−1
tGt(x), (4)
1Note the equivalent notation X(1)=Xandd1=d.
4Published in Transactions on Machine Learning Research (05/2024)
Algorithm 1 GPN-UCB (Gaussian Process Network - Upper Confidence Bound)
1:fort←1,2,...,T do
2:Select xt←arg maxx∈XUCBt−1(x)
3:Obtain observations x(2)
t,...,x(m)
t,andyt.
4:Compute UCBtusing (11), (15), or (19) based on {x(1)
s,...,x(m)
s,ys}t
s=1.
whereGt(x) = [Γ( x,xi)]t
i=1∈Rnt×n,Gt= [Γ(xi,xj)]t
i,j=1∈Rnt×nt, andYt= [yi]t
i=1∈Rnt×1. With∥·∥ 2
denoting the spectral norm, the following lemma provides a deterministic confidence region.
Lemma 2. Forf∈H Γ(B), letµt(x)andΓt(x,x)denote the posterior mean and variance based on tpoints
(x1,...,xt)and their noise-free observations (y1,...,yt)using(3)and(4). Then, it holds for all x∈X
that
∥f(x)−µt(x)∥2≤B∥Γt(x,x)∥1/2
2.
The proof is given in Appendix D.
2.3 Lipschitz Continuity
We also assume that each constituent function in the network gis Lipschitz continuous. For a constant
L>1, we denote byF(L)the set of functions such that
F(L) ={f:∥f(x)−f(x′)∥2≤L∥x−x′∥2,∀x,x′},
whereLis called the Lipschitz constant. This is a mild assumption, as (Lee et al., 2022) has shown that
Lipschitz continuity is a guarantee for functions in Hk(B)for the commonly-used squared exponential kernel
and Matérn kernel with smoothness ν >1.
2.4 Network Structures
In this work, we consider three types of network structure; example figures are included in Appendix C:
•Chain: For a scalar-valued kernel k, a chain is a cascade of scalar-valued functions. Specifically,
d1≥1,d2=d3=···=dm= 1, andf(i)∈Hk(B)∩F(L)for eachi∈[m].
•Multi-output chain : For an operator-valued kernel Γ, a multi-output chain is a cascade of vector-
valued functions. Specifically, di≥1andf(i)∈H Γ(B)∩F(L)for eachi∈[m].
•Feed-forward network : For a scalar-valued kernel k, a feed-forward network is a fully-connected
feed-forward network of scalar-valued functions: di≥1andf(i)(z) = [f(i,j)(z)]di+1
j=1withf(i,j)∈
Hk(B)∩F(L)for eachi∈[m],j∈[di+1].
In each case, the network gis scalar-valued with the dimension of the final output ybeingdm+1= 1.
3 GPN-UCB Algorithm and Regret Bounds
In this section, we propose a fully sequential algorithm GPN-UCB (see Algorithm 1) for chains, multi-output
chains, and feed-forward networks. The algorithm works with structure-specific upper confidence bounds.
Similar to GP-UCB for scalar-valued functions (Srinivas et al., 2010), the proposed algorithm repeatedly
queries the point with the highest posterior upper confidence bound, while the posterior upper confidence
bound UCBt−1used here is computed based on not only the historical final outputs {ys}t−1
s=1but also the
intermediate results {x(2)
s,...,x(m)
s}t−1
s=1.
5Published in Transactions on Machine Learning Research (05/2024)
3.1 GPN-UCB for Chains
A chain is a cascade of scalar-valued functions. For each i∈[m], we denote by µ(i)
tandσ(i)
tthe posterior
mean and standard deviation of f(i)computed using (1) and (2) based on {x(i)
s,x(i+1)
s}t
s=1.2Then, based on
Lemma 1, the upper confidence bound and lower confidence bound of f(i)(z)based ontexact observations
are defined as follows:
UCB(i)
t(z) =µ(i)
t(z) +Bσ(i)
t(z), (5)
LCB(i)
t(z) =µ(i)
t(z)−Bσ(i)
t(z). (6)
Sincef(i)∈F(L), we have for any z,z′that
UCB(i)
t(z′) +L∥z−z′∥2≥f(i)(z′) +L∥z−z′∥2≥f(i)(z), (7)
LCB(i)
t(z′)−L∥z−z′∥2≤f(i)(z′)−L∥z−z′∥2≤f(i)(z). (8)
It follows that
UCB(i)
t(z) := min
z′/parenleftbig
UCB(i)
t(z′) +L∥z−z′∥2/parenrightbig
, (9)
LCB(i)
t(z) := max
z′/parenleftbig
LCB(i)
t(z′)−L∥z−z′∥2/parenrightbig
(10)
are also valid confidence bounds for f(i)(z).UCB(i)
t(z)is the lower envelope of a collection of upper bounds
forf(i)(z), which can be obtained by considering multiple values of z′in (7). Then, since gis a cascade of
f(i)’s, for any input x, we can recursively construct a confidence region of x(i+1)based on the confidence
region of x(i), and the following UCB for g(x)is valid:
UCBt(x) = max
z∈∆(m)
t(x)UCB(m)
t(z), (11)
where ∆(i)
t(x)denotes the confidence region of x(i):
∆(1)
t(x) ={x}
∆(i+1)
t(x) =/bracketleftigg
min
z∈∆(i)
t(x)LCB(i)
t(z),max
z∈∆(i)
t(x)UCB(i)
t(z)/bracketrightigg
fori∈[m−1]. The theoretical performance of Algorithm 1 for chains using the upper confidence bound in
(11) is provided in the following theorem.
Theorem 1 (GPN-UCB for chains) .Under the setup of Section 2, given B > 0andL>1, a scalar-valued
kernelk, and a chain g=f(m)◦f(m−1)◦···◦f(1)withf(i)∈Hk(B)∩F(L)for eachi∈[m], Algorithm 1
achieves
RT≤2m+1BLm−1ΣT,
where ΣT= max
i∈[m]max
z1,...,zT∈X(i)/summationtextT
t=1σ(i)
t−1(zt).3
The proof is given in Appendix F.1, and upper bounds on ΣTwill be discussed in Section 3.4. Regardless
of such upper bounds, we note that BΣTserves as a noise-free regret bound for standard GP optimization
(Vakili, 2022), and thus, the key distinction here is the multiplication by Lm−1. See Section 5 for a study of
the extent to which this dependence is unavoidable.
2Note the equivalent notation x(1)=xandx(m+1)=y.
3In this definition and analogous definitions below, σ(i)
t−1is defined according to the hypothetical sampled points x(i)
τ=zτ
forτ= 1,...,t−1.
6Published in Transactions on Machine Learning Research (05/2024)
We note that GPN-UCB may be difficult to implement exactlyin practice; in particular: (i) Since
X(2),...,X(m)are not known, (9) and (10) are computed based on all z′∈Rdi; (ii) Recursively com-
puting (11) is also resource consuming. However, these problems can be alleviated by (i) only considering
z′sufficiently close to z(since distant ones should have no impact) and (ii) replacing each confidence region
by its intersection with a fixed discretedomain (e.g., a finite grid). In Appendix L, we show that such a
practical variant can be effective, at least in simple experimental scenarios.
3.2 GPN-UCB for Multi-Output Chains
A multi-output chain is a cascade of vector-valued functions. For any input zof the multi-output function
f(i), we define the confidence region of f(i)(z)as
C(i)
t(z) =/intersectiondisplay
z′C(i)
t(z,z′), (12)
where
C(i)
t(z′) ={µ(i)
t(z′) +u:u∈Rdi+1,∥u∥2≤B∥Γ(i)
t(z,z)∥1/2
2}, (13)
C(i)
t(z,z′) ={v+w:v∈C(i)
t(z′),∥w∥2≤L∥z−z′∥2}. (14)
Lemma 2 shows that C(i)
t(z′)is a valid deterministic confidence region for f(i)(z′). Assuming f(i)∈F(L),
{f(i)(z′) +w:w∈Rdi+1,∥w∥2≤L∥z−z′∥2}containing all the points satisfying the Lipschitz property
is a valid confidence region for f(i)(z), and therefore its superset C(i)
t(z,z′)is also a valid confidence region
forf(i)(z). Sincef(i)(z)must belong to the intersection of all its confidence regions, C(i)
t(z)is again a valid
deterministic confidence region for f(i)(z). Hence, noting that C(m)
tis a subset of R(unlike the vector-valued
layers), the upper confidence bound for g(x)for any input xbased ontobservations is
UCBt(x) = max
z∈∆(m)
t(x)C(m)
t(z), (15)
where ∆(i)
t(x)denotes the confidence region of x(i)based ontobservations such that
∆(1)
t(x) ={x}
∆(i+1)
t(x) =/uniondisplay
z∈∆(i)
t(x)C(i)
t(z) fori∈[m−1]. (16)
The cumulative regret achieved by Algorithm 1 for multi-output chains using the upper confidence bound
in (15) is provided in the following theorem.
Theorem 2 (GPN-UCB for multi-output chains) .Under the setup of Section 2, given B > 0andL>1, an
operator-valued kernel Γ, and a multi-output chain g=f(m)◦f(m−1)◦···◦f(1)withf(i)∈H Γ(B)∩F(L)
for eachi∈[m], Algorithm 1 achieves
RT≤5mBLm−1ΣΓ
T,
where ΣΓ
T= max
i∈[m]max
z1,...,zT∈X(i)/summationtextT
t=1∥Γ(i)
t−1(zt,zt)∥1/2
2.
The proof is given in Appendix F.2.
Remark 1. FixX(1),X(2),...,X(m)with dimension d1,d2,...,dm≥1respectively. For Γ(·,·) =k(·,·)I
withkbeing a scalar-valued kernel and Ibeing the identity matrix of size di+1, it follows from Lemma 4
(see Appendix E) that ΣΓ
T= ΣT.
The upper bound on ΣΓ
Tfor general operator-valued kernels will be discussed in Section 3.4.
7Published in Transactions on Machine Learning Research (05/2024)
3.3 GPN-UCB for Feed-Forward Networks
In the feed-forward network structure, f(i)(z) = [f(i,j)(z)]di+1
j=1and eachf(i,j)∈Hk(B)∩F(L)is a scalar-
valuedfunction. Similarto(9)and(10), with µ(i,j)
t(z)andσ(i,j)
t(z)2denotingtheposteriormeanandvariance
off(i,j)(z)using (1) and (2), the following confidence bounds on f(i,j)(z)based on{(x(i)
s,x(i+1,j)
s )}t
s=1are
valid:
UCB(i,j)
t(z) = min
z′(UCB(i,j)
t(z′) +L∥z−z′∥2),
LCB(i,j)
t(z) = max
z′(LCB(i,j)
t(z′)−L∥z−z′∥2), (17)
where
UCB(i,j)
t(z) =µ(i,j)
t(z) +Bσ(i,j)
t(z),
LCB(i,j)
t(z) =µ(i,j)
t(z)−Bσ(i,j)
t(z). (18)
Then, the upper confidence bound of g(x)based ontobservations is
UCBt(x) = max
z∈∆(m)
t(x)UCB(m,1)
t(z), (19)
where
∆(1)
t(x) ={x},
∆(i+1,j)
t (x) =/bracketleftigg
min
z∈∆(i)
t(x)LCB(i,j)
t(z),max
z∈∆(i)
t(x)UCB(i,j)
t(z)/bracketrightigg
fori∈[m−1],j∈[di+1],
∆(i)
t(x) =∆(i,1)
t(x)×···× ∆(i,di)
t(x) fori∈[m].(20)
The following theorem provides the theoretical performance of Algorithm 1 for feed-forward networks using
the upper confidence bound in (19).
Theorem 3 (GPN-UCB for feed-forward networks) .Under the setup of Section 2, given B > 0andL>1,
a scalar-valued kernel k, and a feed-forward network g=f(m)◦f(m−1)◦···◦f(1)withf(i)(z) = [f(i,j)(z)]di+1
j=1
andf(i,j)∈Hk(B)∩F(L)for eachi∈[m],j∈[di+1], Algorithm 1 achieves
RT≤2m+1/radicalbig
D2,mBLm−1ΣT,
whereD2,m=/producttextm
i=2diandΣT= max
i∈[m]max
z1,...,zT∈X(i)/summationtextT
t=1σ(i,1)
t−1(zt).
The proof is given in Appendix F.3.
Sinceσ(i,1)in the feed-forward network setting is computed using (2), which is exactly the same as how
σ(i)is computed in the chain setting, despite the slightly different superscripts, the ΣTterm in Theorem 3
represents the same quantity as in Theorem 1 (depending on X(1),X(2),...,X(m)). In particular, when
d2=···=dm= 1, Theorem 3 recovers Theorem 1.
3.4 Upper Bounds on ΣTandΣΓ
T
A simple way to establish an upper bound on the ΣTterm in Theorem 1, Remark 1, and Theorem 3 is to
essentially set the noise term to be zero in a known result for the noisy setting. For the scalar-valued function
(GP bandit) optimization problem under the noisy setting, most existing upper bounds on cumulative
regret are expressed in terms of the maximum information gain corresponding to the kernel defined as
γt= max x1,...,xt1
2log det( It+λ−1Kt)for a free parameter λ>0(Srinivas et al., 2010), and (Srinivas et al.,
2010) has shown that the sum of posterior variances in the noisy setting satisfies/summationtextT
t=1σ′
t−1(xt)2=O(γT),
8Published in Transactions on Machine Learning Research (05/2024)
Algorithm 2 Non-Adaptive Sampling Based Method
1:Choosing{xs}T
s=1such thatδT=O(T−1
d).
2:Obtain observations {x(2)
s,...,x(m)
s,ys}T
s=1.
3:Computeµg
Tbased on{x(2)
s,...,x(m)
s,ys}T
s=1.
Output: x∗
T= arg maxx∈Xµg
T(x).
whereσ′
t(x)2=k(x,x)−kt(x)T(Kt+λIt)−1kt(x).Usingσt(x)≤σ′
t(x)and the Cauchy-Schwartz inequality,
we have ΣT=O/parenleftbig√TγT/parenrightbig
. An existing upper bound on γTfor the Matérn kernel with dimension dand
smoothness νon a fixed compact domain is γMatérn
T =/tildewideO/parenleftbig
Td
2ν+d/parenrightbig
(Vakili et al., 2021). In our setting, a
simple sufficient condition for this bound to apply is that dmax= maxi∈[m]di,L, andmare constant, since
thentheLipschitzassumptionimpliesthateachdomain X(1),X(2),...,X(m)isalsocompact/bounded. More
generally, we believe that uniformly bounded domains is a mild assumption, and when it holds, the bound
ΣT=O/parenleftbig√TγT/parenrightbig
simplifies to ΣT=O/parenleftbig
Tν+dmax
2ν+dmax/parenrightbig
.
In addition, (Vakili, 2022) provides the following conjecture on the upper bound on ΣTfor the Matérn
kernel4
ΣMatérn
T =

O(T1−ν/dmax)whendmax>ν,
O(logT) whendmax=ν,
O(1) whendmax<ν.
We will discuss in Section 6 how if this conjecture is true, we can deduce the near-optimality of GPN-UCB for
the Matérn kernel. We note that (Vakili, 2022) primarily conjectured on vanilla noise-free cumulative regret
by conjecturing an upper bound on ΣT. Recently, (Salgia et al., 2023) used a random sampling algorithm
with elimination to attain the conjectured cumulative regret, while leaving open the conjecture on ΣTand
whether GP-UCB attains the same regret (though arguably further increasing its plausibility).
Foranarbitrary operator-valuedkernel Γ :X×X→ Rn×nanda freeparameter λ, themaximuminformation
gain is defined as γΓ
t= max x1,...,xt1
2log det( Int+λ−1Gt)(Chowdhury and Gopalan, 2021). (Chowdhury and
Gopalan, 2021) has shown that/summationtextT
t=1∥Γt−1(xt,xt)∥2=O(γΓ
T), and therefore ΣΓ
T=O/parenleftbig/radicalig
TγΓ
T/parenrightbig
by similar
reasoning to above.
4 Non-Adaptive Sampling Based Method
Inthissection,weproposeasimplenon-adaptivesamplingbasedmethod(seeAlgorithm2)foreachstructure,
and provide the corresponding theoretical simple regret for the Matérn kernel. For a set of Tsampled points
{xs}T
s=1, its fill distance is defined as the largest distance from a point in the domain to the closest sampled
pointδT= max x∈Xmins∈[T]∥x−xs∥2(Wendland,2004). Algorithm2samples Tpointswith δT=O(T−1/d).
ForX= [0,1]d, a simple way to construct such a sample is to use a uniform d-dimensional grid with step
sizeT−1/d. The algorithm observes the selected points in parallel, computes a structure-specific “composite
mean”µg
T(to be defined shortly) for the overall network g, and returns the point that maximizes µg
T.
The composite posterior mean of g(x)with chain structure is defined as
µg
T(x) = (µ(m)
T◦µ(m−1)
T◦···◦µ(1)
T)(x), (21)
whereµ(i)
Tdenotes the posterior mean of f(i)computed using (1) based on {(x(i)
s,x(i+1)
s)}T
s=1for eachi∈[m].
Then, the following theorem provides the theoretical upper bound on the simple regret of Algorithm 2
4In more detail, (Vakili, 2022) shows that an analysis of GP-UCB gives rise to the quantity Θ∗
T=
maxx1,...,xT/summationtextT
t=1σt−1(xt), where the maximum is over an arbitrary sequence of points (not necessarily those of GP-UCB).
For(x∗
1,...,x∗
T)where the maximum is achieved, (Vakili, 2022) conjectures that (x∗
1,...,x∗
T)are roughly uniformly distributed
across the domain. The desired upper bound on Θ∗
T(and, in turn, our ΣT) is derived by assuming that this conjecture holds.
9Published in Transactions on Machine Learning Research (05/2024)
using (21). Note that the notation /tildewideO(·)hides poly-logarithmic factors with respect to the argument , e.g.,
/tildewideO(√
T) =O(√
T·(logT)O(1))and/tildewideO(2n) =O(2n·nO(1)).
Theorem 4 (Non-adaptive sampling method for chains) .Under the setup of Section 2, given B= Θ(L),
k=kMatérnwith smoothness ν, and a chain g=f(m)◦f(m−1)◦···◦f(1)withf(i)∈Hk(B)∩F(L)for each
i∈[m], we have
•Whenν≤1, Algorithm 2 achieves
r∗
T=/tildewideO(BLm−1T−νm/d);
•Whenν >1, Algorithm 2 achieves
r∗
T=/tildewideO/parenleftbig
max/braceleftbig
BL(m−1)νT−ν/d,B1+ν+ν2+···+νm−2Lνm−1T−ν2/d/bracerightbig/parenrightbig
.
The proof is given in Appendix G.1, and the optimality will be discussed in Section 6. When ν > 1,
the simple regret upper bound takes the maximum of two terms. The first term has a smaller con-
stant factor, while the second term has a smaller T-dependent factor. By taking the highest-order con-
stant factor and the highest-order T-dependent factor, we can deduce the weaker but simpler bound
r∗
T=O(B1+ν+ν2+···+νm−2Lνm−1T−ν/d).
We also consider two more restrictive cases, where we remove the assumption of B= Θ(L), but have
additional assumptions on gas follows:
•Case 1: We additionally assume that µ(i)
T◦···◦µ(1)
T(x∗)∈X(i+1)andµ(i)
T◦···◦µ(1)
T(x∗
T)∈X(i+1)
for alli∈[m−1].
•Case 2: We additionally assume that all the domains X(i)are known. Defining
/tildewideµ(i)
T(z) = arg min
z′∈X(i+1)|µ(i)
T(z)−z′|,
we slightly modify the algorithm to return
x∗
T= arg max
x∈X(/tildewideµ(m)
T◦···◦/tildewideµ(1)
T)(x).
Remark 2. Under the assumptions of either Case 1 or Case 2, Algorithm 2 achieves for chains that
r∗
T=/braceleftigg
O(BLm−1T−ν/d)whenν≤1,
O(BL(m−1)νT−ν/d)whenν >1.(22)
The proof is given in Appendix G.2.
The composite posterior means and simple regret upper bounds for multi-output chains and feed-forward
networksareprovidedinAppendixG.3andAppendixG.4respectively, wherethesimpleregretupperbounds
are stated only for the case that the domain of each layer is a hyperrectangle. Removing this restrictive
assumption is left for future work.
5 Algorithm-Independent Lower Bounds
In this section, we provide algorithm-independent lower bounds on the simple regret and cumulative regret
for any algorithm optimizing chains, multi-output chains, or feed-forward networks for the scalar-valued
kernelkMatérnor the operator-valued ΓMatérn (·,·) =kMatérn (·,·)Iwith smoothness ν.
Theorem 5 (Lower bound on simple regret) .Fixϵ∈(0,1
2], sufficiently large B > 0,k=kMatérn, and
Γ = Γ Matérnwith smoothness ν≥1. Suppose that there exists an algorithm (possibly randomized) that
10Published in Transactions on Machine Learning Research (05/2024)
achieves average simple regret E[r∗
T]≤ϵafterTrounds for any m-layer chain, multi-output chain, or feed-
forward network on [0,1]dwith someL= Θ(B). Then, provided thatϵ
Bis sufficiently small, it is necessary
that
T= Ω/parenleftigg/parenleftigB(cL)m−1
ϵ/parenrightigd/ν/parenrightigg
for somec= Θ(1).
TheproofisgiveninAppendixH,andthehigh-levelstepsaresimilarto(Bull,2011), butthemaindifferences
are significant. For each structure, we consider a collection of Mhard functionsG={g1,...,gM}, where
eachgjis obtained by shifting a base function gof the specified structure and cropping the shifted function
into [0,1]d. Then, we show that there exists a worst-case function in Gwith the provided lower bound.
Different from (Bull, 2011), the hard functions we construct here are function networks. We define the first
layer as a “needle” function with much smaller height and width than (Bull, 2011). For subsequent layers,
we construct a function with corresponding RKHS norm such that the output is always larger than the
input. As a consequence, the “needle” function gets higher when being fed into subsequent layers, and the
composite function is a “needle” function with some specified height but a much smaller width.
Remark 3. It will be evident from the proof that the constant cis always strictly less than 1. Ideally, we
would like it to be close to 1so that (cL)mis similar to Lm, with the latter quantity appearing in our upper
bounds. It turns out that ccan indeed be arbitrarily close to 1in most cases. Specifically, we will show in
Appendix H.5 that when ν >1andϵis small enough, csimply becomes the ratio of the minimum slope to
the maximum slope of the kernel function (as a function of the Euclidean distance ∥x−x′∥) on[u−/tildewideu,u+/tildewideu],
whereuand/tildewideucan be arbitrarily small. Since the squared exponential (SE) and Matérn kernels have no
sharp changes as a function of ∥x−x′∥, this ensures that ccan be arbitrarily close to one when ν >1and
ϵis small. In Appendix H.5, we will also demonstrate cases where cis not too small (e.g., c >0.93) even
when the above-mentioned quantities (u,/tildewideu)are moderate (e.g., (u,/tildewideu) = (0.5,0.3)).
The lower bound on simple regret readily implies the following lower bound on cumulative regret.
Theorem 6 (Lowerboundoncumulativeregret) .Fix sufficiently large B > 0,k=kMatérn, and Γ = Γ Matérn
with smoothness ν≥1. Suppose that there exists an algorithm (possibly randomized) that achieves average
cumulative regret E[RT]afterTrounds for any m-layer chain, multi-output chain, or feed-forward network
on[0,1]dwith someL= Θ(B). Then, it is necessary that
E[RT] =/braceleftigg
Ω/parenleftbig
min{T,B(cL)m−1T1−ν/d}/parenrightbig
whend>ν,
Ω/parenleftbig
min{T,/parenleftbig
B(cL)m−1/parenrightbigd/ν}/parenrightbig
whend≤ν,
for somec= Θ(1).
The proof is given in Appendix I.
6 Comparison of Bounds
In this section, we compare the algorithmic upper bounds of GPN-UCB (Algorithm 1) and non-adaptive
sampling (Algorithm 2) to the algorithmic-independent lower bounds in Section 5. We present our discussion
conditioned on the conjecture of (Vakili, 2022) being true, but we re-iterate that even without this, any ΣT
dependence still matches the vanilla setting, and has known rigorous upper bounds as detailed in Section 3.4,
A table summarizing the regret bounds for the Matérn kernel is provided in Appendix J.
For GPN-UCB, the cumulative regret upper bound for chains (Theorem 1) matches the lower bound (The-
orem 6) up to a 2mfactor when d≥ν≥1andT= Ω/parenleftbig
(B(cL)m−1)d/ν/parenrightbig
. The upper bound for multi-output
chains (Theorem 2) is similarly optimal (up to a 5mterm) when dmax=d≥ν≥1, while there is always
anO(/radicalbig
D2,m)gap for the T-independent factor of feed-forward networks (Theorem 3). When d < νand
T= Ω/parenleftbig
(B(cL)m−1)d/ν/parenrightbig
, the cumulative regret lower bound for all the three structures is Ω/parenleftbig
(B(cL)m−1)d/ν/parenrightbig
,
11Published in Transactions on Machine Learning Research (05/2024)
while the upper bound always contains an O(BLm−1)factor; hence, the terms behave similarly but some
gaps still remain.
We expect that the discrepancies for multi-output chains and feed-forward networks are due to the looseness
of the proposed lower bound. Since the hard functions Gused in analysis always produce a single-entry
vector output for intermediate layers, for a fixed value of B, there might exist a worse hard function network
with more nonzero entries for intermediate outputs and a probably higher final regret.
For non-adaptive sampling, when ν= 1, the upper bound for chains (Theorem 4) matches the lower bound
(Theorem 5) up to a cm−1factor. When ν >1, Theorem 4 shows that the simple regret upper bound takes
the maximum of two terms, where the first term has a matched T-dependent factor. However, both terms
have a larger T-independent factor than the lower bound when ν > 1; this arises due to magnifying the
uncertainty from each layer to the next.
7 Conclusion
We have proposed an upper confidence bound based method GPN-UCB and a non-adaptive sampling based
method for optimizing chains, multi-output chains, and feed-forward networks in the noise-free grey-box
setting. Our regret bounds significantly improve certain dependencies compared to previous works, and we
provide lower bounds that are near-matching in broad cases of interest. An immediate direction for future
work is to explore noisy extensions of our algorithms (as well as lower bounds), ideally attaining analogous
improvements over existing works (Kusakawa et al., 2022; Sussex et al., 2023) as those that we attained in
the noiseless setting (as discussed in Appendix K).
Acknowledgment
This work was supported by the Singapore Ministry of Education Academic Research Fund Tier 1 under
grant number A-8000872-00-00.
12Published in Transactions on Machine Learning Research (05/2024)
References
Astudillo, R. and Frazier, P. (2019). Bayesian optimization of composite functions. In Int. Conf. Mach.
Learn. (ICML) .
Astudillo, R. and Frazier, P. (2021a). Bayesian optimization of function networks. In Conf. Neur. Inf. Proc.
Sys. (NeurIPS) .
Astudillo, R. and Frazier, P. I. (2021b). Thinking inside the box: A tutorial on grey-box Bayesian optimiza-
tion. InIEEE Winter Simulation Conference (WSC) .
Bansal, S., Calandra, R., Xiao, T., Levine, S., and Tomlin, C. J. (2017). Goal-driven dynamics learning via
Bayesian optimization. In 2017 IEEE 56th Annual Conference on Decision and Control (CDC) , pages
5168–5173. IEEE.
Bull, A. D. (2011). Convergence rates of efficient global optimization algorithms. J. Mach. Learn. Research ,
12(10).
Cai, X. and Scarlett, J. (2021). On lower bounds for standard and robust Gaussian process bandit optimiza-
tion. InInt. Conf. Mach. Learn. (ICML) .
Camilleri, R., Jamieson, K., and Katz-Samuels, J. (2021). High-dimensional experimental design and kernel
bandits. In Int. Conf. Mach. Learn. (ICML) .
Carmeli, C., De Vito, E., and Toigo, A. (2006). Vector valued reproducing kernel Hilbert spaces of integrable
functions and mercer theorem. Analysis and Applications , 4(04):377–408.
Chowdhury, S. R. and Gopalan, A. (2017). On kernelized multi-armed bandits. In Int. Conf. Mach. Learn.
(ICML).
Chowdhury, S. R. and Gopalan, A. (2021). No-regret algorithms for multi-task Bayesian optimization. In
Int. Conf. Art. Intel. Stats. (AISTATS) .
Drusvyatskiy, D. and Paquette, C. (2019). Efficiency of minimizing compositions of convex functions and
smooth maps. Mathematical Programming , 178:503–558.
Griffiths, R.-R. and Hernández-Lobato, J. M. (2020). Constrained Bayesian optimization for automatic
chemical design using variational autoencoders. Chemical Science , 11(2):577–586.
Gupta, S., Rana, S., Venkatesh, S., et al. (2022). Regret bounds for expected improvement algorithms in
Gaussian process bandit optimization. In Int. Conf. Art. Intel. Stats. (AISTATS) .
Huang, D., Allen, T. T., Notz, W. I., and Miller, R. A. (2006). Sequential kriging optimization using
multiple-fidelity evaluations. Structural and Multidisciplinary Optimization , 32(5):369–382.
Kanagawa, M., Hennig, P., Sejdinovic, D., and Sriperumbudur, B. K. (2018). Gaussian processes and kernel
methods: A review on connections and equivalences. https://arxiv.org/abs/1807.02582.
Kusakawa, S., Takeno, S., Inatsu, Y., Kutsukake, K., Iwazaki, S., Nakano, T., Ujihara, T., Karasuyama, M.,
andTakeuchi, I.(2022). Bayesianoptimizationforcascade-typemultistageprocesses. Neural Computation ,
34(12):2408–2431.
Lee, M., Shekhar, S., and Javidi, T. (2022). Multi-scale zero-order optimization of smooth functions in an
RKHS. In IEEE Int. Symp. Inf. Theory (ISIT) .
Li, Z. and Scarlett, J. (2022). Gaussian process bandit optimization with few batches. In Int. Conf. Art.
Intel. Stats. (AISTATS) .
Lizotte, D., Wang, T., Bowling, M., and Schuurmans, D. (2007). Automatic gait optimization with Gaussian
process regression. In Int. Joint Conf. Art. Intel. (IJCAI) .
13Published in Transactions on Machine Learning Research (05/2024)
Lyu, Y., Yuan, Y., and Tsang, I. W. (2019). Efficient batch black-box optimization with deterministic regret
bounds. https://arxiv.org/abs/1905.10041.
Nguyen, T. D., Gupta, S., Rana, S., Nguyen, V., Venkatesh, S., Deane, K. J., and Sanders, P. G. (2016).
Cascade Bayesian optimization. In Aust. Joint Conf. Art. Intel. (AJCAI) .
Rasmussen, C. E. and Williams, C. K. I. (2006). Gaussian processes for machine learning. MIT Press.
Salgia, S., Vakili, S., and Zhao, Q. (2021). A domain-shrinking based Bayesian optimization algorithm with
order-optimal regret performance. In Conf. Neur. Inf. Proc. Sys. (NeurIPS) .
Salgia, S., Vakili, S., and Zhao, Q. (2023). Random exploration in bayesian optimization: Order-optimal
regret and computational efficiency. https://arxiv.org/abs/2310.15351.
Scarlett, J., Bogunovic, I., and Cevher, V. (2017). Lower bounds on regret for noisy Gaussian process bandit
optimization. In Conf. Learn. Theory (COLT) .
Singer, A. and Yang, R. (2023). Alignment of density maps in Wasserstein distance.
https://arxiv.org/abs/2305.12310.
Snoek, J., Larochelle, H., and Adams, R. P. (2012). Practical Bayesian optimization of machine learning
algorithms. In Conf. Neur. Inf. Proc. Sys. (NeurIPS) .
Srinivas, N., Krause, A., Kakade, S. M., and Seeger, M. (2010). Gaussian process optimization in the bandit
setting: No regret and experimental design. In Int. Conf. Mach. Learn. (ICML) .
Sussex, S., Makarova, A., and Krause, A. (2023). Model-based causal Bayesian optimization. In Int. Conf.
on Learn. Repr. (ICLR) .
Vakili, S. (2022). Open problem: Regret bounds for noise-free kernel-based bandits. In Conf. Learn. Theory
(COLT).
Vakili, S., Khezeli, K., and Picheny, V. (2021). On information gain and regret bounds in Gaussian process
bandits. In Int. Conf. Art. Intel. Stats. (AISTATS) .
Wang, M., Fang, E. X., and Liu, H. (2017). Stochastic compositional gradient descent: algorithms for
minimizing compositions of expected-value functions. Mathematical Programming , 161:419–449.
Wendland, H. (2004). Scattered data approximation , volume 17. Cambridge University Press.
14