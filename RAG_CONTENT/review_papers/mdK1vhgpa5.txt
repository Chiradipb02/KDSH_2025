Variational Continual Test-Time Adaptation
Anonymous Author(s)
Affiliation
Address
email
Abstract
Continual Test-Time Adaptation (CTTA) task investigates effective domain adapta- 1
tion under the scenario of continuous domain shifts during testing time. Due to the 2
utilization of solely unlabeled samples, there exists significant uncertainty in model 3
updates, leading CTTA to encounter severe error accumulation issues. In this paper, 4
we introduce VCoTTA, a variational Bayesian approach to measure uncertainties 5
in CTTA. At the source stage, we transform a pretrained deterministic model into 6
a Bayesian Neural Network (BNN) via a variational warm-up strategy, injecting 7
uncertainties into the model. During the testing time, we employ a mean-teacher 8
update strategy using variational inference for the student model and exponential 9
moving average for the teacher model. Our novel approach updates the student 10
model by combining priors from both the source and teacher models. The evidence 11
lower bound is formulated as the cross-entropy between the student and teacher 12
models, along with the Kullback-Leibler (KL) divergence of the prior mixture. 13
Experimental results on three datasets demonstrate the method’s effectiveness in 14
mitigating error accumulation within the CTTA framework. Our code is anony- 15
mously available at https://anonymous.4open.science/r/vcotta-D2C3/ . 16
1 Introduction 17
Continual Test-Time Adaptation (CTTA) [ 51] aims to enable a model to accommodate a sequence 18
of distinct distribution shifts during the testing time, making it applicable to various risk-sensitive 19
applications in open environments, such as autonomous driving and medical imaging. However, real- 20
world non-stationary test data exhibit high uncertainty in their temporal dynamics [ 23], presenting 21
challenges related to error accumulation [ 51]. Previous CTTA studies rely on methods that enforce 22
prediction confidence, such as entropy minimization. However, these approaches often lead to 23
predictions that are overly confident and less well-calibrated, thus limiting the model’s ability to 24
quantify risks during predictions. The reliable estimation of uncertainty becomes particularly crucial 25
in the context of continual distribution shift [ 40]. It is meaningful to design a model capable of 26
encoding the uncertainty associated with temporal dynamics and effectively handling distribution 27
shifts. The objective of this paper is to devise a CTTA procedure that not only enhances predictive 28
accuracy under distribution shifts but also provides reliable uncertainty estimates. 29
To address the above problem, we refer to the Bayesian Inference (BI) [ 1], which retains a distribution 30
over model parameters that indicates the plausibility of different settings given the observed data, and 31
it has been witnessed as effective in traditional continual learning tasks [ 38]. In Bayesian continual 32
learning, the posterior in the last learning task is set to be the current prior which will be multiplied 33
by the current likelihood. This kind of prior transmission is designed to reduce catastrophic forgetting 34
in continual learning. However, this is not feasible in CTTA because unlabeled data may introduce 35
unreliable prior. As shown in Fig. 1, an unreliable prior may lead to a poor posterior, which may then 36
propagate errors to the next inference, leading to the accumulation of errors. 37
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.BNNBNN
BNNSour ce
BNNDomain shiftDomain shift
Adaptation using
unreliable priorErroraccumulation
...
Domainshift
Train TestFigure 1: In CTTA task, a BNN model is first trained on a source dataset, and then is used to adapt
to updated with unreliable priors, which may result in error accumulations.
Thus, we delve into the utilization of BI framework to evaluate model uncertainty in CTTA, aiming 38
to mitigate the impact of unreliable priors and reduce the error propagation. To approximate the 39
intractable likelihood in BI, we adopt to use online Variational Inference (VI) [ 49,42], and accordingly 40
name our method Variational Continual Test-Time Adaptation (VCoTTA). At the source stage, 41
we first transform a pretrained deterministic model, say CNN, into a Bayesian Neural Network 42
(BNN) by a variational warm-up strategy, where the local reparameterization trick [ 27] is used to 43
inject uncertainties into the source model. During the testing phase, we employ a mean-teacher 44
update strategy, where the student model is updated via VI and the teacher model is updated by 45
the exponential moving average. Specifically, for the update of the student model, we propose to 46
use a mixture of priors from both the source and teacher models, then the Evidence Lower BOund 47
(ELBO) becomes the cross-entropy between the student and teachers plus the KL divergence of the 48
prior mixture. We demonstrate the effectiveness of the proposed method on three datasets, and the 49
results show that the proposed method can mitigate the error accumulation in CTTA and obtain clear 50
performance improvements. 51
Our contributions are three-fold: 52
(1)This paper develops VCoTTA, a simple yet general framework for continual test-time adaptation 53
that leverages online VI within BNN. 54
(2)We propose to transform an off-the-shelf model into a BNN via a variational warm-up strategy, 55
which injects uncertainties into the model. 56
(3)We build a mean-teacher structure for CTTA, and propose a strategy to blend the teacher’s prior 57
with the source’s prior to mitigate unreliable prior problem. 58
2 Related Work 59
2.1 Continual Test-Time Adaptation 60
Test-Time Adaptation (TTA) enables the model to dynamically adjust to the characteristics of the 61
test data, i.e. target domain, in a source-free and online manner [ 25,46,50]. Previous works have 62
enhanced TTA performance through the designs of unsupervised loss [ 37,58,32,9,7,17]. These 63
endeavours primarily focus on enhancing adaptation within a fixed target domain, representing a 64
single-domain TTA setup, where models adapt to a specific target domain and then reset to their 65
original pretrained state with the source domain, prepared for the next target domain adaptation. 66
Recently, CTTA [ 51] has been introduced to tackle TTA within a continuously changing target 67
domain, involving long-term adaptation. This configuration often grapples with the challenge of error 68
accumulation [ 47,51]. Specifically, prolonged exposure to unsupervised loss from unlabeled test 69
data during long-term adaptation may result in significant error accumulation. Additionally, as the 70
model is intent on learning new knowledge, it is prone to forgetting source knowledge, which poses 71
challenges when accurately classifying test samples similar to the source distribution. 72
To solve the two challenges, the majority of the existing methods focus on improving the confidence of 73
the source model during the testing phase. These methods employ the mean-teacher architecture [ 47] 74
to mitigate error accumulation, where the student learns to align with the teacher and the teacher 75
2updates via moving average with the student. As to the challenge of forgetting source knowledge, 76
some methods adopt augmentation-averaged predictions [ 51,2,11,55] for the teacher model, 77
strengthening the teacher’s confidence to reduce the influence from highly out-of-distribution samples. 78
Some methods, such as [ 11,6], propose to adopt the contrastive loss to maintain the already learnt 79
semantic information. Some methods believe that the source model is more reliable, thus they are 80
designed to restore the source parameters [ 51,2]. Though the above methods keep the model from 81
confusion of vague pseudo labels, they may suffer from overly confident predictions that are less 82
calibrated. To mitigate this issue, it is helpful to estimate the uncertainty in the neural network. 83
2.2 Bayesian Neural Network 84
Bayesian framework is natural to incorporate past knowledge and sequentially update the belief with 85
new data [ 59]. The bulk of work on Bayesian deep learning has focused on scalable approximate 86
inference methods. These methods include stochastic VI [ 22,34], dropout [ 16,27] and Laplace 87
approximation [ 41,15] etc., and leveraging the stochastic gradient descent (SGD) trajectory, either 88
for a deterministic approximation or sampling. In a BNN, we specify a prior p(θ)over the neural 89
network parameters, and compute the posterior distribution over parameters conditioned on training 90
data, p(θ|D)∝p(θ)p(D|θ). This procedure should give considerable advantages for reasoning 91
about predictive uncertainty, which is especially relevant in the small-data setting. 92
Crucially, when performing Bayesian inference, we need to choose a prior distribution that accurately 93
reflects the prior beliefs about the model parameters before seeing any data [ 18,14]. In conventional 94
static machine learning, the most common choice for the prior distribution over the BNN weights 95
is the simplest one: the isotropic Gaussian distribution. However, this choice has been proved 96
indeed suboptimal for BNNs [ 14]. Recently, some studies estimate uncertainty in continual learning 97
within a BNN framework, such as [ 38,12,13,28]. They set the current prior to the previous 98
posterior to mitigate catastrophic forgetting. However, the prior transmission is not reliable in the 99
unsupervised CTTA task. Any prior mistakes will be enlarged by adaptation progress, manifesting 100
error accumulation. To solve the unreliable prior problem, this paper proposes a prior mixture method 101
based on VI. 102
3 Variational Inference in CTTA 103
We start from the supervised BI in typical continual learning, where the model aims to learn multiple 104
classification tasks in sequence. Let D={(xn, yn)}N
n=1be the training set, where xnandyn 105
denotes the training sample and the corresponding class label. The task tis to learn a direct posterior 106
approximation over the model parameter θas follows. 107
p(θ|D1:t)∝pt(θ)p(Dt|θ), (1)
where p(θ|D1:t)denotes the posterior of sequential tasks on the learned parameter and p(Dt|θ)is 108
the likelihood of the current task. The current prior pt(θ)is regarded as the given knowledge. [ 38] 109
proposes that this current prior can be the posterior learned in the last task, i.e.,pt(θ) =p(θ|D1:t−1), 110
where the inference becomes 111
p(θ|D1:t)∝p(θ|D1:t−1)p(Dt|θ). (2)
The detailed process can be shown in Appendix A. 112
In contrast to continual learning, CTTA faces a sequence of learning tasks in test time without any 113
label information, requiring the model to adapt to each novel domain sequentially. In this case, 114
we assume that each domain is i.i.d. and the classes are separable following many unsupervised 115
studies [ 36,48,5], more details about the assumption can be seen in Appendix B.1. We use 116
U={xn}N
n=1to represent the unlabeled test dataset. The CTTA model is first trained on a source 117
dataset D0, and then adapted to unlabeled test domains starting from U1. For the t-th adaptation, we 118
have 119
p(θ|U1:t∪ D0)∝pt(θ)p(Ut|θ). (3)
Similarly, we can set the last posterior to be the current prior, i.e.,pt(θ) =p(θ|U1:t−1∪ D 0)and 120
p1(θ) =p(θ|D0). However, employing BI for adaptation on unlabeled testing data can result 121
in untrustworthy posterior estimates. Therefore, during subsequent adaptation, the untrustworthy 122
posterior automatically transform into unreliable priors, leading to error accumulation. In other words, 123
3Sour ce Prior
  EMA  Student Posterior
 Next
Teacher  Prior
 Test Data     
 Mix Teacher  Prior
 Figure 2: VCoTTA is built on mean-teacher structure, and conducts VI in CTTA using a mixture of
teacher prior and source prior. The next teacher prior is updated by the exponential moving average.
an unreliable prior pt(θ)will make the current posterior even less trustworthy. Moreover, the joint 124
likelihood p(Ut|θ)fort >0is intractable on unlabeled data. 125
To make the BI feasible in CTTA task, in this paper, we transform the question to an easy-to-compute 126
form. Referring to [20], the unsupervised inference can be transformed into 127
p(θ|U)∝p(θ) exp (−λH(U|θ)), (4)
where Hdenotes the conditional entropy and λis a scalar hyperparameter to weigh the entropy term. 128
This simple form reveals that the prior belief about the conditional entropy of labels is given by the 129
inputs. The observation of the input Uprovides information on the drift of the input distribution, which 130
can be used to update the belief over the learned parameters θthrough Eq. (4). Consequently, this 131
allows the utilization of unlabeled data for BI. More detailed derivations can be seen in Appendix B.2. 132
In a BNN, the posterior distribution is often intractable and some approximation methods are required, 133
even when calculating the initial posterior. In this paper, we leverage online VI, as it typically 134
outperforms the other methods for complex models in the static setting [ 4]. VI defines a variational 135
distribution q(θ)to approxmiate the posterior p(θ|U). The approximation process is as follows. 136
qt(θ) = arg min
q∈QKL
q(θ)∥1
Ztpt(θ)e−λH(Ut|θ)
, (5)
where Qis the distribution searching space and Ztis the intractable normalizing hyperparameter. 137
Thus, referring to the derivations in Appendix C, the ELBO is computed by 138
ELBO =−λEθ∼q(θ)H(Ut|θ)−KL(q(θ)||pt(θ)). (6)
Optimizing with Eq. (6)makes model adapt to domain shift. While VI offers a good framework 139
for measuring uncertainty in CTTA, it is noteworthy that VI does not directly address the issue of 140
unreliable priors. The error accumulation remains a significant concern. 141
Despite this, the form of the ELBO in variational inference offers a pathway for mitigating the impact 142
of unreliable priors. In Eq. (6), the entropy term may result in overly confident predictions that are 143
less calibrated, while the KL term may be directly affected by an unreliable prior. In the following 144
section, we will discuss how to solve the problems when computing the two terms. 145
4 Adaptation and Inference in VCoTTA 146
4.1 Entropy term: VI by Mean-Teacher Architecture 147
In the above section, we introduce the VI in CTTA but challenges remain, i.e., the unreliable prior. 148
To mitigate the challenge in the entropy term, we adopt a Mean-Teacher (MT) structure [ 47] in the 149
Bayesian inference process. MT is initially proposed in semi-supervised and unsupervised learning, 150
where the teacher model guides the unlabeled data, helping the model generalize and improve 151
performance with the utilization of large-scale unlabeled data. 152
MT structure is composed of a student model and a teacher model, where the student model learns 153
from the teacher and the teacher updates using Exponential Moving Average (EMA) [ 24]. In VI, the 154
student is set to be the variational distribution q(θ), which is a Gaussian mean-field approximation 155
for its simplicity. It is achieved by stacking the biases and weights of the network as follows. 156
q(θ) =Y
dN 
θd;µd,diag(σ2
d)
, (7)
4where ddenotes each dimension of the parameter. The teacher model ¯p(θ)(we use bar to distinguish 157
the general prior) is also a Gaussian distribution. Thus, the student model is updated by aligning it 158
with the teacher model through the use of a cross-entropy (CE) loss 159
LCE(q,¯p) =−Eθ∼q(θ)Ex∼U[¯p(x|θ) logq(x|θ)]. (8)
In our implementation, we also try to use Symmetric Cross-Entropy (SCE) [53] in CTTA, 160
LSCE(q,¯p) =−Eθ∼q(θ)Ex∼U
¯p(x|θ) logq(x|θ) +q(x|θ) log ¯p(x|θ)
. (9)
SCE balances the gradient for high and low confidence, benefiting the unsupervised learning. 161
4.2 KL term: Mixture-of-Gaussian Prior 162
For the KL term, to reduce the impact of unreliable prior, we propose a mixing-up approach to 163
combining the teacher and source prior adaptatively. The source prior is warmed up upon the 164
pretrained deterministic model p1(θ) =p(θ|D0)(see Sec. 4.3.1). The teacher model ¯pt(θ)is 165
updated by EMA (see Sec. 4.3.3). We assume that the prior should be the mixture of the two Gaussian 166
priors. Using only the source prior, the adaptation is limited. While using only the teacher prior, the 167
prior is prone to be unreliable. 168
We use the mean entropy derived from a given serious data augmentation to represent the confidence 169
of the two prior models, and mix up the two priors with a modulating factor 170
α=1
|I|X
i∈IeH(x|θ0)/τ
eH(x|θ0)/τ+eH(x|¯θ)/τ, (10)
whereIdenotes augmentation types. θ0and¯θare the parameters of the source model and the teacher 171
model. τmeans the temperature factor. Thus, as shown in Fig. 3(b), the current prior pt(θ)is set to 172
the mixture of priors as 173
pt(θ) =α·p1(θ) + (1 −α)·¯pt(θ). (11)
In the VI, we use the upper bound to update the KL term [31] (see Appendix D.1) for simplicity, 174
KL(q||pt)≤α·KL(q||p0) + (1 −α)·KL(q||¯pt). (12)
Furthermore, we also improve the teacher-student alignment in the entropy term (see Eq. (9)) by 175
picking up the augmented logits with a larger confidence than the raw data. That is, we replace the 176
teacher log-likelihood log ¯p(x|θ)by 177
log ¯p′(x|θ) =P
i∈I1(f(¯p(x′
i))> f(¯p(x)) +ϵ)·log ¯p(x′
i)P
i∈I1(f(¯p(x′
i))> f(¯p(x)) +ϵ), (13)
where, for brevity, we let ¯p(x′
i) = ¯p(x′
i|θ)and¯p(x) = ¯p(x)|θ)in short. f(·)is the confidence 178
function. ϵdenotes the confidence margin and 1(·)is an indicator function. Eq. (13) can be regarded 179
as a filter, meaning that for each sample, the reliable teacher is represented by the average of its 180
augmentations with ϵmore confidence. In Appendix D.2, we prove that the proposed mixture-of- 181
Gaussian is benifical to CTTA. In Appendix E.1, we discuss the influence of different ϵ. 182
4.3 Adaptation and Inference 183
4.3.1 Variational Warm-up 184
To obtain a source BNN, instead of training a model from scratch on the source data D0, we transform 185
a pretrained deterministic CNN to a BNN by variational warm-up strategy. Specifically, we leverage 186
the local reparameterization trick [27] to add stochastic parameters, and warm up the model: 187
q0(θ) = arg min
q∈QKL
q(θ)∥1
Z0p(θ)p(D0|θ)
, (14)
where p(θ)represents the prior distribution, say the pretrained deterministic model. Eq. (14) denotes 188
a standard VI on the source data, and we optimize the ELBO to obtain the variational distribution [ 49]. 189
By the variational warm-up, we can easily transform an off-the-shelf pretrained model into a BNN 190
with a stochastic dynamic. The variational warm-up strategy is outlined in Algorithm 1. 191
5Algorithm 1 Variational warm-up
1:Input: Source data D0, pretrained model p0(θ)
2:Initialize prior distribution p(θ)withp0(θ)
3:Update p(θ|D0)≈q0(θ)byp(θ)andD0using Eq. (14)
4:Output: Source prior p1(θ) =p(θ|D0)The warm-up strategy is a common 192
approach in TTA and CTTA tasks to 193
further build knowledge structure for 194
the source model, such as [ 26,45,11, 195
8]. Some other methods may not use 196
warm-up but still use the source data, 197
such as [ 39]. The warm-up strategy 198
uses the source data only before deploying the model to CTTA scenario, and it is regarded as a part 199
of pretraining. All of these methods using source data are operationalized in source-free at test time 200
and find it is beneficial to CTTA. We use the warm-up to inject the uncertainties into a given source 201
model, i.e., turning an off-the-shelf pretrained CNN model into a pretrained BNN model. This is 202
convenient to obtain a pretrained BNN, because the warm-up strategy uses only a few epochs. We 203
offer more discussions and experiments on the proposed variational warm-up strategy in Appendix F. 204
4.3.2 Student update via VI 205
The student model qt(θ)is adapted by approximating using Eq. (5), and is optimized on: 206
L(qt) =LSCE(qt,¯p′
t) +α·KL(qt||q0) + (1 −α)·KL(qt||¯qt), (15)
where ¯p′
tis the current augmented teacher model in Eq. (13), and p1(θ)≈q0(θ),¯pt(θ)≈¯qt(θ). 207
The KL term between two Gaussians can be computed in a closed form. 208
4.3.3 Teacher update via EMA 209
The teacher model is updated using EMA. Let (µ,σ)and(¯µ,¯σ)be the mean and standard deviation 210
of the student and teacher model, respectively. At test time, the teacher model ¯qt(θ)is updated by 211
¯µ←β¯µ+ (1−β)µ,¯σ←β¯σ+ (1−β)σ. (16)
Although the std is not used in the cross entropy to compute the likelihood, the teacher prior 212
distribution is important to adjust the student distribution via the KL term. 213
4.3.4 Model inference 214
At any time, CTTA model needs to predict and adapt to the unlabeled test data. In our VCoTTA, we 215
also use the mixed prior to serve as the inference model. That is, for a test data point x, the model 216
inference is represented by 217
pt(x) =Z
p(x|θ)pt(θ)dθ=Z
αp(x|θ)p1(θ) + (1 −α)p(x|θ)¯pt(θ)dθ, (17)
For the data prediction, the model only uses the expectation to reduce the stochastic, but leverages 218
stochastic dynamics in domain adaptation. 219
4.3.5 The algorithm 220
Algorithm 2 Variational CTTA
1:Input: Source data D0, pretrained model p0(θ), Un-
labeled test data from different domain U1:T
2:p1(θ) =Variational warm-up (D0, p0(θ)). // Alg. 1
3:forDomain shift t= 1toTdo
4: forTest data x∼ Utdo
5: Model predict for x(Eq. (17))
6: Update student model using x(Eq. (15))
7: Update teacher model via EMA (Eq. (16))
8: end for
9:end forWe illustrate the whole algorithm in Al- 221
gorithm 2. We first transform an off-the- 222
shelf pretrained model into BNN via the 223
variational warm-up strategy (Sec. 4.3.1). 224
After that, we obtain a BNN, and for each 225
domain shift, we forward and adapt each 226
test data point in an MT architecture. For 227
a data point x, we first predict the class la- 228
bel using the mixture of the source model 229
and the teacher model (Sec. 4.3.4). Then, 230
we update the student model using VI, 231
where we use cross entropy to compute 232
the entropy term and use the mixture of 233
priors for the KL term (Sec. 4.3.2). Finally, we update the BNN teacher model via EMA (Sec. 4.3.3). 234
See more details in Appendix G. The process is feasible for any test data without labels. 235
6Table 1: Classification error rate (%) for the standard CIFAR10-to-CIFAR10C CTTA task. All results
are evaluated with the largest corruption severity level 5 in an online fashion. C1 to C15 are 15
corruptions for the datasets (see Sec. 5.1). CIFAR100C and ImagenetC use the same setup.
Method C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 Avg
Source 72.3 65.7 72.9 46.9 54.3 34.8 42.0 25.1 41.3 26.0 9.3 46.7 26.6 58.5 30.3 43.5
BN 28.1 26.1 36.3 12.8 35.3 14.2 12.1 17.3 17.4 15.3 8.4 12.6 23.8 19.7 27.3 20.4
Tent [50] 24.8 20.6 28.5 15.1 31.7 17.0 15.6 18.3 18.3 18.1 11.0 16.8 23.9 18.6 23.9 20.1
CoTTA [51] 24.5 21.5 25.9 12.0 27.7 12.2 10.7 15.0 14.1 12.7 7.6 11.0 18.5 13.6 17.7 16.3
RoTTA [56] 30.3 25.4 34.6 18.3 34.0 14.7 11.0 16.4 14.6 14.0 8.0 12.4 20.3 16.8 19.4 19.3
PETAL [2] 23.7 21.4 26.3 11.8 28.8 12.4 10.4 14.8 13.9 12.6 7.4 10.6 18.3 13.1 17.1 16.2
SATA [6] 23.9 20.1 28.0 11.6 27.4 12.6 10.2 14.1 13.2 12.2 7.4 10.3 19.1 13.3 18.5 16.1
DSS [52] 24.1 21.3 25.4 11.7 26.9 12.2 10.5 14.5 14.1 12.5 7.8 10.8 18.0 13.1 17.3 16.0
SWA [55] 23.9 20.5 24.5 11.2 26.3 11.8 10.1 14.0 12.7 11.5 7.6 9.5 17.6 12.0 15.8 15.3
VCoTTA (Ours) 18.1 14.9 22.0 9.7 22.6 11.0 9.5 11.4 10.6 10.5 6.5 9.4 15.6 11.0 14.5 13.1
Table 2: Classification error rate (%) for the standard CIFAR100-to-CIFAR100C CTTA task.
Method C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 Avg
Source 73.0 68.0 39.4 29.3 54.1 30.8 28.8 39.5 45.8 50.3 29.5 55.1 37.2 74.7 41.2 46.4
BN 42.1 40.7 42.7 27.6 41.9 29.7 27.9 34.9 35 41.5 26.5 30.3 35.7 32.9 41.2 35.4
Tent [50] 37.2 35.8 41.7 37.9 51.2 48.3 48.5 58.4 63.7 71.1 70.4 82.3 88.0 88.5 90.4 60.9
CoTTA [51] 40.1 37.7 39.7 26.9 38.0 27.9 26.4 32.8 31.8 40.3 24.7 26.9 32.5 28.3 33.5 32.5
RoTTA [56] 49.1 44.9 45.5 30.2 42.7 29.5 26.1 32.2 30.7 37.5 24.7 26.9 32.5 28.3 33.5 32.5
PETAL [2] 38.3 36.4 38.6 25.9 36.8 27.3 25.4 32.0 30.8 38.7 24.4 26.4 31.5 26.9 32.5 31.5
SATA [6] 36.5 33.1 35.1 25.9 34.9 27.7 25.4 29.5 29.9 33.1 23.6 26.7 31.9 27.5 35.2 30.3
DSS [52] 39.7 36.0 37.2 26.3 35.6 27.5 25.1 31.4 30.0 37.8 24.2 26.0 30.0 26.3 31.1 30.9
SWA [55] 39.4 36.4 37.4 25.0 36.0 26.6 25.0 29.1 28.4 35.0 23.5 25.1 28.5 25.8 29.6 30.0
VCoTTA (Ours) 35.3 32.8 38.9 23.8 34.6 25.5 23.2 27.5 26.7 30.4 22.1 23.0 28.1 24.2 30.4 28.4
5 Experiment 236
5.1 Experimental Setting 237
Dataset . In our experiments, we employ the CIFAR10C, CIFAR100C, and ImageNetC datasets as 238
benchmarks to assess the robustness of classification models. Each dataset comprises 15 distinct 239
types of corruption, each applied at five different levels of severity (from 1 to 5). These corruptions 240
are systematically applied to test images from the original CIFAR10 and CIFAR100 datasets, as well 241
as validation images from the original ImageNet dataset. For simplicity in tables, we use C1 to C15 242
to represent the 15 types of corruption, i.e., C1: Gaussian, C2: Shot, C3: Impulse C4: Defocus, C5: 243
Glass, C6: Motion, C7: Zoom, C8: Snow, C9: Frost, C10: Fog, C11: Brightness, C12: Contrast, C13: 244
Elastic, C14: Pixelate, C15: Jpeg. 245
Pretrained Model . Following previous studies [ 50,51], we adopt pretrained WideResNet-28 [ 57] 246
model for CIFAR10to-CIFAR10C, pretrained ResNeXt-29 [ 54] for CIFAR100-to-CIFAR100C, and 247
standard pretrained ResNet-50 [ 21] for ImageNet-to-ImagenetC. Note in our VCoTTA [ 51], we 248
further warm up the pretrained model to obtain the stochastic dynamics for each dataset. Similar to 249
CoTTA, we update all the trainable parameters in all experiments. The augmentation number is set to 250
32 for all compared methods that use the augmentation strategy. 251
5.2 Methods to be Compared 252
We compare our VCoTTA with multiple state-of-the-art (SOTA) methods. SOURCE denotes the 253
baseline pretrained model without any adaptation. BN [ 30,43] keeps the network parameters frozen, 254
but only updates Batch Normalization. TENT [ 50] updates via Shannon entropy for unlabeled 255
test data. CoTTA [ 51] builds the MT structure and uses randomly restoring parameters to the 256
source model. SATA [ 6] modifies the batch-norm affine parameters using source anchoring-based 257
self-distillation to ensure the model incorporates knowledge of newly encountered domains while 258
avoiding catastrophic forgetting. SWA [ 55] refines the pseudo-label learning process from the 259
perspective of the instantaneous and long-term impact of noisy pseudo-labels. PETAL [ 2] tries to 260
estimate the uncertainty in CTTA, which is similar to BNN, but it ignores the unreliable prior problem. 261
All compared methods adopt the same backbone, pretrained model and hyperparameters. 262
7Table 3: Classification error rate (%) for the standard ImageNet-to-ImageNetC CTTA task.
Method C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 C13 C14 C15 Avg
Source 95.3 95.0 95.3 86.1 91.9 87.4 77.9 85.1 79.9 79.0 45.4 96.2 86.6 77.5 66.1 83.0
BN 87.7 87.4 87.8 88.0 87.7 78.3 63.9 67.4 70.3 54.7 36.4 88.7 58.0 56.6 67.0 72.0
Tent [50] 85.6 79.9 78.3 82.0 79.5 71.4 59.5 65.8 66.4 55.2 40.4 80.4 55.6 53.5 59.3 67.5
CoTTA [51] 87.4 86.0 84.5 85.9 83.9 74.3 62.6 63.2 63.6 51.9 38.4 72.7 50.4 45.4 50.2 66.7
RoTTA [56] 88.3 82.8 82.1 91.3 83.7 72.9 59.4 66.2 64.3 53.3 35.6 74.5 54.3 48.2 52.6 67.3
PETAL [2] 87.4 85.8 84.4 85.0 83.9 74.4 63.1 63.5 64.0 52.4 40.0 74.0 51.7 45.2 51.0 67.1
DSS [52] 84.6 80.4 78.7 83.9 79.8 74.9 62.9 62.8 62.9 49.7 37.4 71.0 49.5 42.9 48.2 64.6
VCoTTA (Ours) 81.8 78.9 80.0 83.4 81.4 70.8 60.3 61.1 61.7 46.4 35.7 71.7 50.1 47.1 52.9 64.2
5.3 Comparison Results 263
We show the major comparisons with the SOTA methods in Tables 1, 2 and 3. We have the following 264
observations. First, no adaptation at the test time ( SOURCE ) suffers from serious domain shift, which 265
shows the necessity of the CTTA. Second, traditional TTA methods that ignore the continual shift 266
in test time perform poorly such as TENT andBN. We also find that simple Shannon entropy is 267
effective in the first several domain shifts, especially in complex 1,000-classes ImageNetC, but shows 268
significant performance drops in the following shifts. Third, the mean-teacher structure is very useful 269
in CTTA, such as COTTA andPETAL , which means that the pseudo-label is useful in domain shift. 270
In the previous method, the error accumulation leads to the unreliable pseudo labels, then the model 271
may get more negative transfers in CTTA along the timeline. The proposed VCOTTA outperforms 272
other methods on all the three datasets, such as 13.1% vs. 15.3% ( SWA ) on CIFAR10C, 28.4% 273
vs. 30.0% ( SWA ) on CIFAR100C and 64.2% vs. 66.7% ( COTTA ) on ImageNetC. We hold the 274
opinion that the prior will inevitably drift in CTTA, but VC OTTA slows down the process via the 275
prior mixture. We also find that the superiority is more obvious in the early adaptation, which may be 276
influenced by the different corruption orders. We analyze the order problem in Appendix H. 277
5.4 Ablation Study 278
We evaluate the two components in Table 4, i.e., the Variational Warm-Up (VWU) and the Symmetric 279
Cross-Entropy (SCE) via ablation. The ablation results show that the two components are both 280
important for VCOTTA . First, the VWU is used to inject stochastic dynamics into an off-the-shelf 281
pretrained model. Without the VWU, the performance of VC OTTA drops to 18.4% from 13.9% on 282
CIFAR10C, 31.5% from 28.8% on CIFAR100C and 68.1% from 64.2% on ImageNetC. Also, the 283
SCE can further improve the performance on CIFAR10C and CIFAR100C, because SCE balances 284
the gradient for high and low confidence predictions. We also find that SCE is ineffective for complex 285
ImageNetC, and the reason may be the class sensitivity imbalance, causing the model to lean more 286
towards one direction during optimization. 287
Table 4: Ablation study on under severity 5.
No. VWU SCE CIFAR10C CIFAR100C ImageNetC
1 18.4 31.5 68.1
2√17.1 31.2 68.3
3√13.9 28.8 64.2
4√ √13.1 28.4 64.7Table 5: Different weights for mixture of priors.
No. α1−αCIFAR10C CIFAR100C ImageNetC
1 1 0 17.4 35.0 69.9
2 0 1 16.3 33.7 71.2
3 0.5 0.5 14.7 31.3 67.0
4 Eq. (10) 13.1 28.4 64.7
5.5 Mixture of Priors 288
In Sec. 4.2, we introduce a Gaussian mixture strategy, where the current prior is approximated as the 289
weighted sum of the source prior and the teacher prior. The weights are determined by computing the 290
entropy over multiple augmentations of two models. To assess the effectiveness of these weights, we 291
compare them with three naive weighting configurations: using only the source model, using only the 292
teacher model, and a simple average with equal weights for both models. The results, as presented in 293
Table 5, reveal that relying solely on the source model or the teacher model (i.e., weighting with (1,0) 294
and(0,1)) results in suboptimal performance. Additionally, naive weighting with equal contributions 295
from both models (i.e., (0.5,0.5)) proves ineffective for CTTA due to the inherent uncertainty in both 296
models. In contrast, the proposed adaptive weights for the Gaussian mixture in CTTA demonstrate its 297
effectiveness. This underscores the significance of striking a balance between the two prior models in 298
8an unsupervised environment. The trade-off implies the need to discern when the source model’s 299
knowledge is more applicable and when the teacher model’s shifting knowledge takes precedence. 300
5.6 Uncertainty Estimation 301
To evaluate the uncertainty estimation, we use negative loglikelihood (NLL) and Brier Score (BS) [ 3]. 302
Both NLL and BS are proper scoring rules [ 19], and they are minimized if and only if the predicted 303
distribution becomes identical to the actual distribution: 304
NLL =−E(x,y)∈Dtestlog(p(y|x,θ)),BS=E(x,y)∈Dtest(p(y|x,θ)−Onehot (y))2,
whereDtestdenotes the test set, i.e., the unsupervised test dataset Uwith labels. We evaluate NLL and 305
BS with a severity level of 5 for all corruption types, and the compared results with SOTAs are shown 306
in Table 6. We have the following observations. First, most methods suffer from low confidence in 307
terms of NLL and BS because of the drift priors, where the model is unreliable gradually, and the error 308
accumulation makes the model perform poorly. Our approach outperforms most other approaches in 309
terms of NLL and BS, demonstrating the superiority in improving uncertainty estimation. We also 310
find that PETAL [2] shows good NLL and BS, because PETAL forces the prediction over-confident 311
to unreliable priors, thus PETAL shows unsatisfactory results on adaptation accuracy, such as 31.5% 312
vs. 28.4% (Ours) on CIFAR100C. 313
Table 6: Uncertainty estimation via NLL and BS.
MethodCIFAR10C CIFAR100C ImageNetC
NLL BS NLL BS NLL BS
Source 3.0566 0.7478 2.4933 0.6707 5.0703 0.9460
BN 0.9988 0.3354 1.3932 0.4740 3.9971 0.8345
Tent 1.9391 0.3713 7.1097 1.0838 3.6902 0.8281
CoTTA 0.7192 0.2761 1.2907 0.4433 3.6235 0.7972
PETAL 0.5899 0.2458 1.2267 0.4327 3.6391 0.8017
VCoTTA 0.5421 0.2130 1.2287 0.4307 3.4469 0.8092Table 7: Gradually changing on severity 5.
Method CIFAR10C CIFAR100C ImageNetC
Source 23.9 32.9 81.7
BN 13.5 29.7 54.1
TENT 39.1 72.7 53.7
CoTTA 10.6 26.3 42.1
PETAL 10.5 27.1 60.5
VCoTTA 8.9 24.4 39.9
5.7 Gradually Corruption 314
We also show gradual corruption results instead of constant severity in the major comparison, and the 315
results are reported in Table 7. Specifically, each corruption adopts the gradual changing sequence: 316
1→2→3→4→5→4→3→2→1, where the severity level is the lowest 1 when corruption 317
type changes, therefore, the type change is gradual. The distribution shift within each type is also 318
gradual. Under this situation, our VCoTTA also outperforms other methods, such as 8.9% vs. 10.5% 319
(PETAL ) on CIFAR10C, and 24.4% vs. 26.3% ( COTTA ) on CIFAR100C. The results show that the 320
proposed VC OTTA based on BNN is also effective when the distribution change is uncertain. 321
6 Conclusion and Limitation 322
Conclusion : In this paper, we proposed a variational Bayesian inference approach, termed VCoTTA, 323
to estimate uncertainties in CTTA. At the pretrained stage, we first transformed an off-the-shelf 324
pretrained deterministic CNN into a BNN using a variational warm-up strategy, thereby injecting 325
uncertainty into the source model. At the test time, we implemented a mean-teacher update strategy, 326
where the student model is updated via variational inference, while the teacher model is refined by the 327
exponential moving average. Specifically, to update the student model, we proposed a novel approach 328
that utilizes a mixture of priors from both the source and teacher models. Consequently, the ELBO 329
can be formulated as the cross-entropy between the student and teacher models, combined with the 330
KL divergence of the prior mixture. We demonstrated the effectiveness of the proposed method on 331
three datasets, and the results show that the proposed method can mitigate the issue of unreliable 332
prior within the CTTA framework. 333
Limitation : The efficacy of the proposed method relies on injecting uncertainty into the model during 334
the pre-training phase, which may be unavailable in scenarios where pretraining is already completed, 335
and original data is inaccessible. Additionally, constructing and training BNN models are inherently 336
more complex compared to CNNs, highlighting the importance of enhancing computational efficiency. 337
The Gaussian mixture method relies on multiple data augmentations, which also incurs computational 338
costs. Future endeavors could explore more efficient approaches for Gaussian mixture. 339
9References 340
[1] George EP Box and George C Tiao. Bayesian inference in statistical analysis . John Wiley & Sons, 2011. 341
[2]Dhanajit Brahma and Piyush Rai. A probabilistic framework for lifelong test-time adaptation. In Proceed- 342
ings of the Computer Vision and Pattern Recognition , 2023. 343
[3]Glenn W Brier. Verification of forecasts expressed in terms of probability. Journal of the Monthly Weather 344
Review , 78(1):1–3, 1950. 345
[4]Thang Bui, Daniel Hernández-Lobato, Jose Hernandez-Lobato, Yingzhen Li, and Richard Turner. Deep 346
gaussian processes for regression using approximate expectation propagation. In Proceedings of the 347
International Conference on Machine Learning , 2016. 348
[5]Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsupervised 349
learning of visual features. In Proceedings of the European Conference on Computer Vision , pages 350
132–149, 2018. 351
[6]Goirik Chakrabarty, Manogna Sreenivas, and Soma Biswas. Sata: Source anchoring and target alignment 352
network for continual test time adaptation. arXiv preprint arXiv:2304.10113 , 2023. 353
[7]Dian Chen, Dequan Wang, Trevor Darrell, and Sayna Ebrahimi. Contrastive test-time adaptation. In 354
Proceedings of the Computer Vision and Pattern Recognition , 2022. 355
[8]Ziyang Chen, Yiwen Ye, Mengkang Lu, Yongsheng Pan, and Yong Xia. Each test image deserves a 356
specific prompt: Continual test-time adaptation for 2d medical image segmentation. arXiv preprint 357
arXiv:2311.18363 , 2023. 358
[9]Sungha Choi, Seunghan Yang, Seokeon Choi, and Sungrack Yun. Improving test-time adaptation via shift- 359
agnostic weight regularization and nearest source prototypes. In Procedings of the European Conference 360
on Computer Vision , 2022. 361
[10] Thomas M Cover. Elements of information theory . John Wiley & Sons, 1999. 362
[11] Mario Döbler, Robert A Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-time 363
adaptation. In Proceedings of the Computer Vision and Pattern Recognition , 2023. 364
[12] Sayna Ebrahimi, Mohamed Elhoseiny, Trevor Darrell, and Marcus Rohrbach. Uncertainty-guided continual 365
learning with bayesian neural networks. In Procedings of the International Conference on Learning 366
Representations , 2019. 367
[13] Sebastian Farquhar and Yarin Gal. A unifying bayesian view of continual learning. arXiv preprint 368
arXiv:1902.06494 , 2019. 369
[14] Vincent Fortuin, Adrià Garriga-Alonso, Sebastian W Ober, Florian Wenzel, Gunnar Ratsch, Richard E 370
Turner, Mark van der Wilk, and Laurence Aitchison. Bayesian neural network priors revisited. In 371
Procedings of the International Conference on Learning Representations , 2021. 372
[15] Karl Friston, Jérémie Mattout, Nelson Trujillo-Barreto, John Ashburner, and Will Penny. Variational free 373
energy and the laplace approximation. Journal of the Neuroimage , 34(1):220–234, 2007. 374
[16] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertainty 375
in deep learning. In Procedings of the International Conference on Machine Learning , 2016. 376
[17] Yossi Gandelsman, Yu Sun, Xinlei Chen, and Alexei Efros. Test-time training with masked autoencoders. 377
InProcedings of the Advances in Neural Information Processing Systems , 2022. 378
[18] Andrew Gelman, John B Carlin, Hal S Stern, and Donald B Rubin. Bayesian data analysis . Chapman and 379
Hall/CRC, 1995. 380
[19] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation. Journal 381
of the American Statistical Association , 102(477):359–378, 2007. 382
[20] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Proceedings 383
of the Advances in Neural Information Processing Systems , 2004. 384
[21] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. 385
InProceedings of the Computer Vision and Pattern Recognition , 2016. 386
10[22] José Miguel Hernández-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learning of 387
bayesian neural networks. In Procedings of the International Conference on Machine Learning , 2015. 388
[23] Hengguan Huang, Xiangming Gu, Hao Wang, Chang Xiao, Hongfu Liu, and Ye Wang. Extrapolative 389
continuous-time bayesian neural network for fast training-free test-time adaptation. In Proceedings of the 390
Advances in Neural Information Processing Systems , 2022. 391
[24] J Stuart Hunter. The exponentially weighted moving average. Journal of the Quality Technology , 18(4):203– 392
210, 1986. 393
[25] Vidit Jain and Erik Learned-Miller. Online domain adaptation of a pre-trained cascade of classifiers. In 394
Proceedings of the Computer Vision and Pattern Recognition , 2011. 395
[26] Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, and Jaegul Choo. Cafa: 396
Class-aware feature alignment for test-time adaptation. In Proceedings of the IEEE/CVF International 397
Conference on Computer Vision , pages 19060–19071, 2023. 398
[27] Durk P Kingma, Tim Salimans, and Max Welling. Variational dropout and the local reparameterization 399
trick. In Proceedings of the Advances in Neural Information Processing Systems , 2015. 400
[28] Richard Kurle, Botond Cseke, Alexej Klushyn, Patrick Van Der Smagt, and Stephan Günnemann. Continual 401
learning with bayesian neural networks for non-stationary data. In Procedings of the International 402
Conference on Learning Representations , 2019. 403
[29] Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural 404
networks. In Workshop on Challenges in Representation Learning, International Conference on Machine 405
Learning , volume 3, page 896, 2013. 406
[30] Zhizhong Li and Derek Hoiem. Learning without forgetting. Journal of the IEEE Transactions on Pattern 407
Analysis and Machine Intelligence , 40(12):2935–2947, 2017. 408
[31] GuoJun Liu, Yang Liu, MaoZu Guo, Peng Li, and MingYu Li. Variational inference with gaussian mixture 409
model and householder flow. Journal of the Neural Networks , 109:43–55, 2019. 410
[32] Yuejiang Liu, Parth Kothari, Bastien Van Delft, Baptiste Bellot-Gurlet, Taylor Mordan, and Alexandre 411
Alahi. Ttt++: When does self-supervised test-time training fail or thrive? In Procedings of the Advances in 412
Neural Information Processing Systems , 2021. 413
[33] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation with 414
residual transfer networks. In Proceedings of the Advances in Neural Information Processing Systems , 415
2016. 416
[34] Christos Louizos and Max Welling. Multiplicative normalizing flows for variational bayesian neural 417
networks. In Procedings of the International Conference on Machine Learning , 2017. 418
[35] Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A simple 419
baseline for bayesian uncertainty in deep learning. In Proceedings of the Advances in Neural Information 420
Processing Systems , 2019. 421
[36] David J Miller and Hasan Uyar. A mixture of experts classifier with learning based on both labelled and 422
unlabelled data. In Proceedings of the Advances in Neural Information Processing Systems , 1996. 423
[37] Chaithanya Kumar Mummadi, Robin Hutmacher, Kilian Rambach, Evgeny Levinkov, Thomas Brox, and 424
Jan Hendrik Metzen. Test-time adaptation to distribution shift by confidence maximization and input 425
transformation. arXiv preprint arXiv:2106.14999 , 2021. 426
[38] Cuong V Nguyen, Yingzhen Li, Thang D Bui, and Richard E Turner. Variational continual learning. In 427
Proceedings of the International Conference on Learning Representations , 2018. 428
[39] Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan. 429
Efficient test-time model adaptation without forgetting. In Proceedings of the International Conference on 430
Machine Learning , pages 16888–16905, 2022. 431
[40] Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua Dillon, 432
Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty? evaluating predictive 433
uncertainty under dataset shift. In Proceedings of the Advances in Neural Information Processing Systems , 434
2019. 435
11[41] Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks. 436
InProcedings of the International Conference on Learning Representations , 2018. 437
[42] Masa-Aki Sato. Online model selection based on the variational bayes. Journal of the Neural Computation , 438
13:1649–1681, 2001. 439
[43] Steffen Schneider, Evgenia Rusak, Luisa Eck, Oliver Bringmann, Wieland Brendel, and Matthias Bethge. 440
Improving robustness against common corruptions by covariate shift adaptation. In Proceedings of the 441
Advances in Neural Information Processing Systems , 2020. 442
[44] Yoram Singer and Manfred KK Warmuth. Batch and on-line parameter estimation of gaussian mixtures 443
based on the joint entropy. In Procedings of the Advances in Neural Information Processing Systems , 1998. 444
[45] Junha Song, Jungsoo Lee, In So Kweon, and Sungha Choi. Ecotta: Memory-efficient continual test-time 445
adaptation via self-distilled regularization. In Proceedings of the IEEE/CVF Conference on Computer 446
Vision and Pattern Recognition , pages 11920–11929, 2023. 447
[46] Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei Efros, and Moritz Hardt. Test-time training with 448
self-supervision for generalization under distribution shifts. In Procedings of the International Conference 449
on Machine Learning , 2020. 450
[47] Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency tar- 451
gets improve semi-supervised deep learning results. In Proceedings of the Advances in Neural Information 452
Processing Systems , 2017. 453
[48] Jesper E Van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine Learning , 454
109(2):373–440, 2020. 455
[49] Chong Wang, John Paisley, and David M Blei. Online variational inference for the hierarchical dirichlet 456
process. In Proceedings of the International Conference on Artificial Intelligence and Statistics , 2011. 457
[50] Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test- 458
time adaptation by entropy minimization. In Proceedings of the International Conference on Learning 459
Representations , 2020. 460
[51] Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. In 461
Proceedings of the Computer Vision and Pattern Recognition , 2022. 462
[52] Yanshuo Wang, Jie Hong, Ali Cheraghian, Shafin Rahman, David Ahmedt-Aristizabal, Lars Petersson, and 463
Mehrtash Harandi. Continual test-time domain adaptation via dynamic sample selection. In Proceedings 464
of the IEEE/CVF Winter Conference on Applications of Computer Vision , pages 1701–1710, 2024. 465
[53] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross entropy 466
for robust learning with noisy labels. In Proceedings of the Computer Vision and Pattern Recognition , 467
2019. 468
[54] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual trans- 469
formations for deep neural networks. In Proceedings of the Computer Vision and Pattern Recognition , 470
2017. 471
[55] Xu Yang, Yanan Gu, Kun Wei, and Cheng Deng. Exploring safety supervision for continual test-time 472
domain adaptation. In Proceedings of the International Joint Conference on Artificial Intelligence , 2023. 473
[56] Longhui Yuan, Binhui Xie, and Shuang Li. Robust test-time adaptation in dynamic scenarios. In 474
Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition , pages 15922– 475
15932, 2023. 476
[57] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Procedings of the British Machine 477
Vision Conference , 2016. 478
[58] Marvin Zhang, Sergey Levine, and Chelsea Finn. Memo: Test time robustness via adaptation and 479
augmentation. In Procedings of the Advances in Neural Information Processing Systems , 2022. 480
[59] Tingting Zhao, Zifeng Wang, Aria Masoomi, and Jennifer Dy. Deep bayesian unsupervised lifelong 481
learning. Journal of the Neural Networks , 149:95–106, 2022. 482
[60] Aurick Zhou and Sergey Levine. Bayesian adaptation for covariate shift. In Proceedings of the Advances 483
in Neural Information Processing Systems , 2021. 484
12Variational Continual Test-Time Adaptation
(Appendix)
A Bayesian Inference (BI) in Traditional CL and CTTA 485
As described in Sec. 3, we first illustrate the BI has been studied in traditional Continual Learning 486
(CL) methods. In this section, we compare the BI in CL and CTTA in detail and show the differences 487
with some related works. The comparison can be seen in Fig. 3. For the CL, BI is conducted by the 488
posterior propagation, that is, the prior of next task is equal to the current posterior. This is feasible in 489
supervised CL, where the data label is provided. For the CTTA, the posterior is not trustworthy using 490
only pseudo labels to adapt to a new domain. Thus, propagate the untrustworthy posterior to the next 491
stage would make unreliable prior, which will result in error accumulation. In the proposed VCoTTA, 492
we propose to solve the problem via enhancing the two terms in VI (see Sec. 4). 493
Prior
 EqualPosterior
 Next Prior
 Labeled
Data     
(a) BI in continual learning
Source Prior
 EMA
Posterior
 Next
Teacher Prior
 Unlabeled
Data     Teacher Prior
 
Mix
(b) BI in CTTA
Figure 3: Bayesian inference comparison between continual learning and CTTA. We find the
traditional prior transmission is infeasible in CTTA because of the unreliable prior from unlabeled
data. In our method, we place CTTA in a mean-teacher structure, and design BI in CTTA using a
mixture of teacher prior and source prior. The next teacher prior is updated by the exponential moving
average.
VCL [ 38] is a classic CL study that uses VI, our work is also inspired by VCL but has the following 494
difference. (1) The tasks are different : VCL studies supervised CL task, while our VCoTTA studies 495
unsupervised CTTA task. (2) The challenges are differnt : CL only suffers from catastrophic forgetting 496
(CF), while CTTA sufffers from both CF and error accumulation. (3) Ways of BI are different : To 497
conduct BI, one needs to compute prior and likelihood. For the prior, the current prior of VCL is set 498
to be the previous posterior, while in CTTA such a prior may be unreliable. For the likelihood, VCL 499
can directly compute likelihood, CTTA is under unsupervised setting, thus in our work, we deduce 500
the BI in CTTA using conditional entropy. (4) The update strategies are different : To reduce error 501
accumulation in unsupervised scenario, we employ a mean-teacher update strategy using VI for the 502
student model and exponential moving average for the teacher model, and compute a prior mixture 503
to guide the student update. Moreover, VCL maintains an extra coreset from the training set, while 504
VCoTTA never store any data during the test time. 505
13We also find another recent work named PETAL [ 2] that estimates uncertainties in CTTA. The 506
BI formulation is similar between PETAL and ours, which is derived from [ 20], but PETAL use 507
different method to conduct the inference: (1) PETAL only uses CNN and does not estimate the model 508
uncertainties, while VCoTTA uses BNN to model the uncertainties during test time. (2) PETAL 509
ignores the unreliable prior in CTTA, and follow the VCL setting that use the previous posterior 510
as the current prior. (3) We conduct BI using variational inference while PETAL use SWAG [ 35]. 511
SWAG has advantages in terms of computational efficiency and stability during training, especially in 512
scenarios where computational resources are limited. However, SWAG might not handle unreliable 513
priors as effectively as VI since it doesn’t explicitly model the posterior distribution. (4) We have 514
compared with PETAL in our experiment (see Tables 1, 2, 3), and our method outperforms PETAL 515
on all datasets. 516
B CTTA Approximation by BI 517
B.1 Assumption on Class Separability 518
In our method, we use the conditional entropy to alternate the intractable computing of likelihood. 519
Note that the use of entropy in unsupervised scenario needs to satisfy the class-separable assumption. 520
In fact, unlabeled data do not convey category information but still carry information. Miller and 521
Uyar [ 36] theoretically proved that utilizing unlabeled samples to train classifiers can improve 522
classification performance if there is a connection between the target and sample distributions. 523
It is a common practice in unsupervised/semi-supervised learning to establish the relationship 524
between unlabeled data and the target by making some reasonable assumptions to obtain category- 525
relevant information from unlabeled data. Common assumptions include the Smoothness assumption , 526
Cluster assumption ,Manifold assumption ,Low-density separation assumption , etc. For example, 527
the well-known clustering-based methods utilize the cluster assumption to generate pseudo-labels 528
for unsupervised learning [ 48]. Caron et al. [ 5] assumes that "the model trained on labeled data 529
will produce high uncertainty estimation for unseen data" in domain adaptation tasks to benefit the 530
classifier from unlabeled data lacking category information. 531
Bengio et al. in [ 20] proposed the conditional entropy and point out that "These studies conclude that 532
the (asymptotic) information content of unlabeled examples decreases as classes overlap. Thus, the 533
assumption that classes are well separated is sensible if we expect to take advantage of unlabeled 534
examples." This assumption has been applied to many studies, for example in [ 29,33,60,2]. In 535
the CTTA task of this paper, as the task progresses, the domain shifts, but the categories in the task 536
remain unchanged. Therefore, under the assumption that unlabeled data contains information, we 537
can reasonably continue to use conditional entropy in the current scenario. To sum up, whether in 538
unsupervised TTA or in the Bayesian field, this assumption is not difficult to achieve or has never 539
been applied. We can quite naturally continue to use this assumption in the context of this paper. 540
B.2 BI during Test Time 541
The goal of CTTA is to learn a posterior distribution p(θ|U1:T∪ D 0)from a source dataset D0, 542
and a sequence of unlabeled test data from U1toUT. Following [ 60], assuming we have multiple 543
input-generating distributions that the source dataset D0is drawn from a distribution ϕ, and ˜ϕt 544
specifies the shifted of the t-th unlabeled test dataset which we aim to adapt to. Let the parameters 545
of the model be θ,then following the semi-supervised learning framework [ 20], we incorporate all 546
input-generating distributions into the belief over the model parameters θas follows 547
p(θ|ϕ,˜ϕ1,···,˜ϕT)∝p(θ) exp (−λ0Hθ,ϕ(Y|X))TY
t=1exp
−λtHθ,˜ϕt(Y|X)
, (18)
where the inputs Xare sampled i.i.d. from a generative model with parameters ϕ, while the corre- 548
sponding labels Yare sampled from a conditional distribution p(Y|X,θ), which is parameterized 549
by the model parameters θ.p(θ)is a prior distribution over θ.{λ0, λ1,···, λT}are the factors for 550
approximation weighting. Generally, the entropy term Hθ,ϕ(Y|X)represents the cross entropy of 551
the supervised learning, and the entropy term Hθ,˜ϕt(Y|X)fort >0denotes the Shannon entropy of 552
the unsupervised learning. 553
14Following [ 60], we can empirically use a point estimation to get a plug-in Bayesian approach to 554
approximate the above formula: 555
p(θ|U1:T∪ D0)
∝p(θ)Y
∀x,y∈D0p(y|x,θ) exp 
−λ0
|D0|X
∀x∈D0H(Y|x,θ)!TY
t=1exp 
−λt
|Ut|X
∀x∈UtH(Y|x,θ)!
.
(19)
To make the formula feasible to CTTA, that is, no source data is available at the test time, we set 556
λ0= 0. And the source knowledge can be represented by p(θ|D0)∝p(θ)Q
∀x,y∈D0p(y|x,θ). 557
Thus, for the t-th test domain, the Bayesian inference in CTTA can be represented as follows: 558
p(θ|U1:t∪ D0)∝p(θ|D0)tY
i=1exp 
−λi
|Ui|X
∀x∈UiH(Y|x,θ)!
∝p(θ|U1:t−1∪ D0) exp 
−λt
|Ut|X
∀x∈UtH(Y|x,θ)!
,(20)
where H(Ut|θ) =1
|Ut|P
∀x∈UtH(Y|x,θ)and the above formula can be rewritten in simplicity as 559
p(θ|U1:t∪ D0)∝p(θ|U1:t−1∪ D0)e−λH(Ut|θ)=pt(θ)e−λH(Ut|θ), (21)
which specifies the Bayesian inference process on continuously arriving unlabeled data in CTTA. 560
C ELBO of the VI in CTTA 561
We built VI for CTTA in Sec. 3, where we initialize a variational distribution q(θ)to approximate the 562
real posterior. For the test domain t, we optimize the variational distribution as follows: 563
qt(θ) = arg min
q∈QKL
q(θ)∥1
Ztpt(θ)e−λH(Ut|θ)
, (22)
where Qis the distribution searching space, and pt(θ)is the current prior. 564
Following the definition of KL divergence and the standard derivation of the Evidence Lower BOund 565
(ELBO) is as the following formulas. Specifically, the KL divergence is expanded as 566
KL
q(θ)∥1
Ztpt(θ)e−λH(Ut|θ)
=−Z
θq(θ) log1
Ztpt(θ)e−λH(Ut|θ)
q(θ)dθ
=−Z
θq(θ) log1
Zte−λH(Ut|θ)dθ−Z
θq(θ) logpt(θ)
q(θ)dθ
=Z
θq(θ) logZtdθ+λZ
θq(θ)H(Ut|θ)dθ−Z
θq(θ) logpt(θ)
q(θ)dθ
= log Zt+λEθ∼q(θ)H(Ut|θ) + KL ( q(θ)∥pt(θ)),(23)
where the first constant term can be reduced in the optimization. Thus, we can optimize the variational 567
distribution via the ELBO: 568
qt(θ) = arg min
q∈QKL
q(θ)∥1
Ztpt(θ)e−λH(Ut|θ)
= arg max
q∈Q−λEθ∼q(θ)H(Ut|θ)−KL (q(θ)∥pt(θ))
= arg max
q∈QELBO .(24)
15In our case, the former entropy term can be more effectively replaced by the cross entropy or 569
symmetric cross entropy (SCE) between the student model and the teacher model in a mean-teacher 570
architecture (see Sec. 4.1). For the latter KL term, we can substitute a variational approximation 571
that we deem closest to the current-stage prior pt(θ)into the KL divergence. When the prior is a 572
multivariate Gaussian distribution, this term can be computed in closed form as 573
KL (N(µ1,Σ1)∥ N(µ2,Σ2))
=1
2
tr(Σ−1
2Σ1) + (µ2−µ1)⊤Σ−1
2(µ2−µ1)−k+ lndet(Σ2)
det(Σ1)
.(25)
where Σ=diag(σ2),krepresents the dimensionality of the distributions, tr(·)denotes the trace of a 574
matrix, and det(·)stands for the determinant of a matrix. For the case that the prior is a mixture of 575
Gaussian distributions, we can refer to the next section to get its upper bound. 576
D Mixture-of-Gaussian Prior 577
D.1 Upper Bound of the Mixture of Two KL Divergencies 578
We refer to the lemma that was stated for the mixture of Gaussian in [ 44]. The KL divergence 579
between two mixture distributions p=Pk
i=1αipiandp′=Pk
i=1αip′
iis upper-bounded by 580
KL(p∥p′)≤KL(α∥α′) +kX
i=1αiKL(pi∥p′
i), (26)
where α= (α1, α2,···, αk)andα′= (α′
1, α′
2,···, α′
k)are the weights of the mixture components. 581
The equality holds if and only if αipi/Pk
j=1αjpj=α′
ip′
i/Pk
j=1α′
jp′
jfor all i. Using the log-sum 582
inequality [10], we have 583
KL(kX
i=1αipi∥kX
i=1αip′
i) =Z kX
i=1αipi!
logPk
i=1αipiPk
i=1αip′
i
≤ZkX
i=1αipilogαipi
αip′
i
=kX
i=1αiZ
pilogαi
α′
i+Z
pilogpi
p′
i
= KL( α∥α′) +kX
i=1αiKL(pi∥p′
i).
In our algorithm, q(θ)is set to be a mixture of Gaussian distributions, i.e.,pt(θ) =α·p1(θ) + (1− 584
α)·¯pt(θ). In the above inequality, let q(θ) =Pk
i=1αiq(θ), we can get the upper bound of the KL 585
divergence between q(θ)andpt(θ): 586
KL(q∥pt)≤α·KL(q||p1) + (1 −α)·KL(q||¯pt). (27)
So the lower bound (24) can be redefined as 587
L=−λEθ∼q(θ)H(Ut|θ)−KL (q(θ)∥pt(θ))
≥ −λEθ∼q(θ)H(Ut|θ)−α·KL(q||p1)−(1−α)·KL(q||¯pt)
def=L′,(28)
Then, we have obtained a lower bound that can be optimized through closed-form calculations as 588
the source prior distribution q0(θ)and the teacher prior distribution ¯qt(θ)are multivariate Gaussian 589
distributions, which means we can also optimize L′with Eq. (25). 590
16D.2 Advantage of the Mixture of Gaussian Prior 591
In this subsection, we illustrate why the mixture of Gaussian prior are beneficial to CTTA. First of 592
all, we can start from defining what is a better distribution for CTTA. Assume there exists an ideal 593
prior distribution ˆpt, which effectively represents the distribution of the model after learning all past 594
knowledge, including that from the source and unlabeled datasets. Then we can use the difference 595
between a distribution and the ideal distribution ˆpt(here we use KL divergence) to measure the 596
goodness of a distribution, i.e., KL (·||ˆpt). 597
Generally, neither the source prior p1(trained on labeled data) nor the adapted prior ¯pt(adapt 598
on unlabeled data, being unreliable) can be completely consistent with ˆpt. Considering that, as t 599
increases, the difference between ¯ptandˆptwill increase without an upper bound due to the error 600
accumulation (since tis infinitely growing). The source prior p1cannot adapt to the unlabeled data, 601
but it contains important information from the labeled data, and the ideal distribution cannot forget the 602
source information too much, so we can assume that the difference between p1andˆptis a constant, 603
i.e.,KL(p1||ˆpt)< U , where Uis a constant upper bound. Accordingly, it can be considered that 604
mixing the source prior p1and the adapted prior ¯ptin some way is beneficial for reducing KL(·||ˆpt). 605
In our paper, we consider using a simple Gaussian mixture, i.e., pt=αtp1+ (1−αt)¯pt, where αis 606
computed by Eq. (10). It is easy to illustrate the benefits of this idea using the following inequality: 607
KL(pt||ˆpt) =KL[(αtp1+ (1−αt)¯pt)||ˆpt]
≤αtKL(p1||ˆpt) + (1 −αt)KL(¯pt||ˆpt)
≤αtU+ (1−αt)KL(¯pt||ˆpt).(29)
In Eq. (29), if KL (¯pt||ˆpt)≥U, which can be satisfied as mentioned above, then we have
KL(pt||ˆpt)≤KL(¯pt||ˆpt),
This indicates that the mixed distribution ptis closer to the ideal distribution ˆptthan the adapted 608
prior ¯pt. A similar idea can be found in the stochatic restoration in CoTTA [ 51], where the author 609
randomly restore parts of parameters of the current model into the parameters of source model. 610
E Augmentation Analysis 611
In our method, we use the standard augmentation following CoTTA [ 51]. In this subsection, we 612
analyze the some characteristics via experiments. 613
E.1 Confidence Margin 614
First, we analyze the margin ϵin Eq. (13). We experimentally validate different margins with more 615
choices. Experimental results are shown in Tables 8. The results indicate that different datasets 616
may require different margins to control confidence. Moreover, Eq. (13) signifies that the reliable 617
teacher likelihood is represented by the mean of its augmentations with ϵmore confidence than the 618
teacher itself. Tables 8 illustrates the selection of ϵin our approach on CIFAR10C, CIFAR100C 619
and ImageNetC. Note that when ϵ=−1, it means no margin is used and the method will use all 620
augmentated samples, i.e., without using Eq. (13). The results show that the proposed margin can 621
effectively filter out unreliable augmented samples and achieve a better teacher log-likelihood. 622
Table 8: Analysis on confidence margin.
No. ϵ CIFAR10C ϵ CIFAR100C ϵ ImageNetC
1 -1 15.1 -1 29.3 -1 66.4
2 0 13.23 0 28.78 0 65.0
3 1e-4 13.23 0.1 28.55 1e-3 65.0
4 1e-3 13.22 0.2 28.45 1e-2 64.8
5 1e-2 13.14 0.3 28.43 1e-1 64.7
6 1e-1 13.31 0.4 28.54 2e-1 66.2
17E.2 Different Number of Augmentation 623
In our method, we also use augmentation to enhance the confidence. We then evaluate the the number 624
of augmentation in Eq. (10). The results can be seen in Table 9, and shows that increasing the number 625
of augmentations can enhance effectiveness, but this hyperparameter ceases to have a significant 626
impact after reaching 32. 627
Table 9: Different number of augmentation.
Method 0 4 8 16 32 64
CoTTA 17.5 17.0 16.6 16.5 16.3 16.2
PETAL 17.3 16.9 16.4 16.1 16.0 16.0
VCoTTA 14.9 13.8 13.6 13.3 13.1 13.1
F Further Discussion on Variational Warm-up Strategy 628
We have discussed the Variational Warm-Up (VWU) strategy in Sec. 4.3.1, and explain that the 629
warm-up strategy is a common practice in TTA and CTTA. In this section, we further discuss some 630
attributes of the proposed variational warm-up strategy. 631
In our method, the VWU strategy is used to turn an off-the-shelf CNN to a pretrained BNN. The 632
advantage of this approach is that pretrained CNNs are readily available (e.g., directly leveraging 633
official models in PyTorch), while pretrained BNNs are challenging to obtain, especially for large- 634
scale datasets. Moreover, training BNNs is more difficult compared to training CNNs. Therefore, 635
constructing BNN pretrained models based on existing CNN pretrained models is a feasible approach. 636
Additionally, we find that such a warm-up strategy requires only a few epochs to achieve satisfactory 637
results. To validate the characteristics of the proposed VWU strategy, we designed the following 638
experiments. 639
F.1 Warm-up on CNN vs. Directly Pretraining BNN 640
First, we conducted experiments to compare the performance of obtaining pretrained BNN models 641
using the warm-up approach versus directly training the source model with BNN. We pretrain the 642
BNN also use VI as describing in Sec. 4.3.1. The results can be seen in Table 10. As we can see, the 643
results are at the same level, for example VI pretraining is with 13.2% error rate while the proposed 644
VWU achieves 13.1% on CIFAR10C. However, if we direct turn a pretrained CNN to a BNN by 645
adding random stochastic parameters, without warm-up strategy, the results drop to 17.1%. This 646
shows that VWU is a feasible strategy to obtain a pretrained BNN. 647
Table 10: Error comparison between varional warm-up on CNN and directly pretraining BNN.
Method CIFAR10C CIFAR100C ImagenetC
BNN (Random) →BNN + VI pretraining 13.2 29.0 65.5
CNN (Pretrained) →BNN w/o VWU 17.1 31.2 68.3
CNN (Pretrained) →BNN w/ VWU 13.1 28.4 64.7
F.2 Number of Warm-up Epochs 648
In our implementation, we employ only a limited number of epochs for variational warm-up, say 5 649
epochs. This is due to the fact that the pretrained model fits well in CNN, thus requiring minimal 650
adjustments to the mean of BNN. Additionally, the standard deviation (std) is initialized to be small. 651
Consequently, only a small number of iterations are necessary to update the BNN, and the step size is 652
also kept small. Experimentation on the epoch number of variational warm-up reveals that keeping 653
increasing epochs ( >5) will diminishes performance, as shown in Fig. 5. 654
18Error64.064.565.065.566.0
Number of epoch12345678910
Error13.013.514.014.515.0
Data portion1/101/41/21/41
1Figure 4: Comparisons on different warm-up
epochs (CIFAR10C).
Error64.064.565.065.566.0
Number of epoch12345678910
Error13.013.514.014.515.0
Data portion1/101/41/21/41
1Figure 5: Comparisons on different warm-up data
scale (CIFAR10C).
F.3 Only Portion Usage of Source Dataset in Warm-up 655
As we response to the weakness, the warm-up strategy is a common approach in TTA and CTTA 656
tasks and it is regarded as a part of pretraining stage. We also evaluate how if we only use partial 657
data for warm-up, and the results are as follow. The experimental results demonstrate that a moderate 658
reduction in sample size still maintains certain effectiveness of the warmup strategy. However, 659
excessive reduction, such as reducing to 1/10, leads to a certain decline in effectiveness. This is 660
because the warmup strategy aims to incorporate statistical information of the dataset into the model, 661
and insufficient data may result in inaccurate performance. 662
G Recursive Variational Approximation Process in VCoTTA 663
In this section, we show the algorithmic workflow utilizing variational approximation in VCoTTA. 664
Before testing time : First, we adopt a variational warm-up strategy to inject stochastic dynamics into 665
the model before adaptation. Given the source dataset D0, we can use a variational approximation of 666
p(θ|D0)as follows 667
p(θ|D0) =p1(θ)≈q0(θ) = arg min
q∈QKL
q(θ)∥1
Z0p(θ)p(D0|θ)
, (30)
where we use the pretrained deterministic model p0(θ)as the prior distribution. 668
When the domain shift : Then, at the beginning of the test time, we set the prior in task tas 669
pt(θ) =α·p1(θ) + (1 −α)·¯pt(θ)and variational approximation, where p1(θ)≈q0(θ)and 670
¯pt(θ)≈¯qt(θ). For ¯qt(θ), which means the real-time posterior probability of the teacher model for 671
thet-th test domain, is constantly updated by qt(θ)via EMA (see Sec. 4.3.3) during the test phase. 672
Note that we do not have ¯qt(θ)for the first update in the t-th phase. In fact, we use qt−1(θ)construct 673
the prior, thus we have pt(θ)≈α·p1(θ) + (1 −α)·qt−1(θ). This is the variational distribution 674
that should be used to approximate the prior in the absence of a teacher model in the first step, as 675
well as the approximation that should be used when not employing the MT architecture. Note that 676
the process is not required to inform the model that the domain produces a shift. 677
During the testing time of a domain : With the approximation to pt(θ)and analysis from Ap- 678
pendix B.2, we get qt(θ)for student model at the test domain tas follows: 679
qt(θ) = arg min
q∈QKL
q(θ)∥1
Ztpt(θ)e−λH(Ut|θ)
, (31)
which means, we can recursively derive pt+1(θ)and the following variational distributions, thereby 680
achieving the goal of VCoTTA. 681
H Different Orders of Corruption 682
As we discuss in the major comparisons (see Sec 5.3), the performance may be affected by the 683
corruption order. To provide a more comprehensive evaluation of the matter of the order, we conduct 684
1910 different orders from Sec 5.3, and show the average performance of all compared methods. 685
10 independent random orders of corruption are all under the severity level of 5. The results 686
are shown in Table 11. We find that the order of corruption is minor on simple datasets such as 687
CIFAR10C and CIFAR100C, but small std on difficult datasets such as ImageNetC. The proposed 688
VCOTTA outperforms other methods on the average error of CIFAR10C and CIFAR100C under 10 689
different corruption orders, which shows the effectiveness of the prior calibration in CTTA. Moreover, 690
VCOTTA has comparable results with PETAL on ImageNetC, but smaller std over 10 orders, which 691
shows the robustness of the proposed method. 692
Table 11: Comparisons over 10 orders (avg ±std).
Method CIFAR10C CIFAR100C ImageNetC
CoTTA 17.3 ±0.3 32.2 ±0.3 63.4 ±3.0
PETAL 16.0 ±0.1 33.8 ±0.3 62.7±2.6
VCoTTA 13.1±0.1 28.2 ±0.2 62.8±1.1
I Corruption Loops 693
In the real-world scenario, the testing domain may reappear in the future. We evaluate the test 694
conditions continually 10 times to evaluate the long-term adaptation performance on CIFAR10C. 695
That is, the test data will be re-inference and re-adapt for 9 more turns under severity 5. Full 696
results can be found in Fig. 6. The results show that most compared methods obtain performance 697
improvement in the first several loops, but suffer from performance drop in the following loops. This 698
means that the model drift can be even useful in early loops, but the drift becomes hard because of 699
the unreliable prior. The results also indicate that our method outperforms others in this long-term 700
adaptation situation and has only small performance drops. 701
1 2 3 4 5 6 7 8 9 101314151617Error
CoTTA
PETAL
VCoTTA
Figure 6: 10 loops under a same corruption order (CIFAR10C).
J Experiment on Online Setting 702
CTTA does operate in an online setting, where all testing data is used only once. However, the current 703
focus of CTTA research primarily revolves around batch-mode online settings, with batch sizes 704
typically set to 200 in our experiments like other SOTAs. In CTTA, strict online learning settings 705
where each data point is processed individually are under-researched. In fact, our method can be 706
applied in scenarios with online learning or small batch sizes. However, it’s important to note that the 707
batch normalization (BN) layers is disabled when the batch size is 1. We experimented with batch 708
size of 1 on CIFAR10C, and compare the results with some baseline methods. The comparison results 709
are shown in Table 12. The results show that small batch size in CTTA makes worse performance. 710
We believe this is because a small batch size amplifies the uncertainty in model training. 711
20Table 12: Error comparisons of strict online learning (batch size = 1).
Method Batch size 1 Batch size 200
TENT 43.5 20.1
CoTTA 42.4 16.3
VCoTTA 39.1 13.1
K Time and Memory Cost 712
We implement our method using a single RTX-4090 GPU card. We provide the memory and time cost 713
in Table 13. Our proposed VCoTTA method does not offer an advantage in terms of memory usage. 714
This is because in the BNN framework, additional standard deviations are required for implementing 715
local reparameterization tricks. However, during the testing phase, this does not significantly impact 716
the efficiency of the model. This is because during testing, only the student model employs variational 717
inference, which requires uncertainty parameters. 718
Table 13: Time and memory cost comparisons.
Method Memory Time per corruption
CoTTA 10.3Gb 272s
PETAL 10.2Gb 261s
VCoTTA 11.1Gb 279s
21NeurIPS Paper Checklist 719
The checklist is designed to encourage best practices for responsible machine learning research, 720
addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove 721
the checklist: The papers not including the checklist will be desk rejected. The checklist should 722
follow the references and follow the (optional) supplemental material. The checklist does NOT count 723
towards the page limit. 724
Please read the checklist guidelines carefully for information on how to answer these questions. For 725
each question in the checklist: 726
• You should answer [Yes] , [No] , or [NA] . 727
•[NA] means either that the question is Not Applicable for that particular paper or the 728
relevant information is Not Available. 729
• Please provide a short (1–2 sentence) justification right after your answer (even for NA). 730
The checklist answers are an integral part of your paper submission. They are visible to the 731
reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it 732
(after eventual revisions) with the final version of your paper, and its final version will be published 733
with the paper. 734
The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. 735
While "[Yes] " is generally preferable to "[No] ", it is perfectly acceptable to answer "[No] " provided a 736
proper justification is given (e.g., "error bars are not reported because it would be too computationally 737
expensive" or "we were unable to find the license for the dataset we used"). In general, answering 738
"[No] " or "[NA] " is not grounds for rejection. While the questions are phrased in a binary way, we 739
acknowledge that the true answer is often more nuanced, so please just use your best judgment and 740
write a justification to elaborate. All supporting evidence can appear either in the main paper or the 741
supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification 742
please point to the section(s) where related material for the question can be found. 743
IMPORTANT, please: 744
•Delete this instruction block, but keep the section heading “NeurIPS paper checklist" , 745
•Keep the checklist subsection headings, questions/answers and guidelines below. 746
•Do not modify the questions and only use the provided macros for your answers . 747
1.Claims 748
Question: Do the main claims made in the abstract and introduction accurately reflect the 749
paper’s contributions and scope? 750
Answer: [Yes] 751
Justification: We made clear claims to illustrate that we evaluate the uncertainty in CTTA 752
task using variational inference. 753
Guidelines: 754
•The answer NA means that the abstract and introduction do not include the claims 755
made in the paper. 756
•The abstract and/or introduction should clearly state the claims made, including the 757
contributions made in the paper and important assumptions and limitations. A No or 758
NA answer to this question will not be perceived well by the reviewers. 759
•The claims made should match theoretical and experimental results, and reflect how 760
much the results can be expected to generalize to other settings. 761
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 762
are not attained by the paper. 763
2.Limitations 764
Question: Does the paper discuss the limitations of the work performed by the authors? 765
Answer: [Yes] 766
22Justification: We discuss the limitation in the last section. 767
Guidelines: 768
•The answer NA means that the paper has no limitation while the answer No means that 769
the paper has limitations, but those are not discussed in the paper. 770
• The authors are encouraged to create a separate "Limitations" section in their paper. 771
•The paper should point out any strong assumptions and how robust the results are to 772
violations of these assumptions (e.g., independence assumptions, noiseless settings, 773
model well-specification, asymptotic approximations only holding locally). The authors 774
should reflect on how these assumptions might be violated in practice and what the 775
implications would be. 776
•The authors should reflect on the scope of the claims made, e.g., if the approach was 777
only tested on a few datasets or with a few runs. In general, empirical results often 778
depend on implicit assumptions, which should be articulated. 779
•The authors should reflect on the factors that influence the performance of the approach. 780
For example, a facial recognition algorithm may perform poorly when image resolution 781
is low or images are taken in low lighting. Or a speech-to-text system might not be 782
used reliably to provide closed captions for online lectures because it fails to handle 783
technical jargon. 784
•The authors should discuss the computational efficiency of the proposed algorithms 785
and how they scale with dataset size. 786
•If applicable, the authors should discuss possible limitations of their approach to 787
address problems of privacy and fairness. 788
•While the authors might fear that complete honesty about limitations might be used by 789
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 790
limitations that aren’t acknowledged in the paper. The authors should use their best 791
judgment and recognize that individual actions in favor of transparency play an impor- 792
tant role in developing norms that preserve the integrity of the community. Reviewers 793
will be specifically instructed to not penalize honesty concerning limitations. 794
3.Theory Assumptions and Proofs 795
Question: For each theoretical result, does the paper provide the full set of assumptions and 796
a complete (and correct) proof? 797
Answer: [Yes] 798
Justification: We provide the assumption and proofs mostly in appendix. 799
Guidelines: 800
• The answer NA means that the paper does not include theoretical results. 801
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 802
referenced. 803
•All assumptions should be clearly stated or referenced in the statement of any theorems. 804
•The proofs can either appear in the main paper or the supplemental material, but if 805
they appear in the supplemental material, the authors are encouraged to provide a short 806
proof sketch to provide intuition. 807
•Inversely, any informal proof provided in the core of the paper should be complemented 808
by formal proofs provided in appendix or supplemental material. 809
• Theorems and Lemmas that the proof relies upon should be properly referenced. 810
4.Experimental Result Reproducibility 811
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 812
perimental results of the paper to the extent that it affects the main claims and/or conclusions 813
of the paper (regardless of whether the code and data are provided or not)? 814
Answer: [Yes] 815
Justification: We use open-source dataset and provide a anonymous code link. 816
Guidelines: 817
• The answer NA means that the paper does not include experiments. 818
23•If the paper includes experiments, a No answer to this question will not be perceived 819
well by the reviewers: Making the paper reproducible is important, regardless of 820
whether the code and data are provided or not. 821
•If the contribution is a dataset and/or model, the authors should describe the steps taken 822
to make their results reproducible or verifiable. 823
•Depending on the contribution, reproducibility can be accomplished in various ways. 824
For example, if the contribution is a novel architecture, describing the architecture fully 825
might suffice, or if the contribution is a specific model and empirical evaluation, it may 826
be necessary to either make it possible for others to replicate the model with the same 827
dataset, or provide access to the model. In general. releasing code and data is often 828
one good way to accomplish this, but reproducibility can also be provided via detailed 829
instructions for how to replicate the results, access to a hosted model (e.g., in the case 830
of a large language model), releasing of a model checkpoint, or other means that are 831
appropriate to the research performed. 832
•While NeurIPS does not require releasing code, the conference does require all submis- 833
sions to provide some reasonable avenue for reproducibility, which may depend on the 834
nature of the contribution. For example 835
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 836
to reproduce that algorithm. 837
(b)If the contribution is primarily a new model architecture, the paper should describe 838
the architecture clearly and fully. 839
(c)If the contribution is a new model (e.g., a large language model), then there should 840
either be a way to access this model for reproducing the results or a way to reproduce 841
the model (e.g., with an open-source dataset or instructions for how to construct 842
the dataset). 843
(d)We recognize that reproducibility may be tricky in some cases, in which case 844
authors are welcome to describe the particular way they provide for reproducibility. 845
In the case of closed-source models, it may be that access to the model is limited in 846
some way (e.g., to registered users), but it should be possible for other researchers 847
to have some path to reproducing or verifying the results. 848
5.Open access to data and code 849
Question: Does the paper provide open access to the data and code, with sufficient instruc- 850
tions to faithfully reproduce the main experimental results, as described in supplemental 851
material? 852
Answer: [Yes] 853
Justification: We provide the anonymous code link. 854
Guidelines: 855
• The answer NA means that paper does not include experiments requiring code. 856
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 857
public/guides/CodeSubmissionPolicy ) for more details. 858
•While we encourage the release of code and data, we understand that this might not be 859
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 860
including code, unless this is central to the contribution (e.g., for a new open-source 861
benchmark). 862
•The instructions should contain the exact command and environment needed to run to 863
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 864
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 865
•The authors should provide instructions on data access and preparation, including how 866
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 867
•The authors should provide scripts to reproduce all experimental results for the new 868
proposed method and baselines. If only a subset of experiments are reproducible, they 869
should state which ones are omitted from the script and why. 870
•At submission time, to preserve anonymity, the authors should release anonymized 871
versions (if applicable). 872
24•Providing as much information as possible in supplemental material (appended to the 873
paper) is recommended, but including URLs to data and code is permitted. 874
6.Experimental Setting/Details 875
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 876
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 877
results? 878
Answer: [Yes] 879
Justification: We follow previous to set the experiments. 880
Guidelines: 881
• The answer NA means that the paper does not include experiments. 882
•The experimental setting should be presented in the core of the paper to a level of detail 883
that is necessary to appreciate the results and make sense of them. 884
•The full details can be provided either with the code, in appendix, or as supplemental 885
material. 886
7.Experiment Statistical Significance 887
Question: Does the paper report error bars suitably and correctly defined or other appropriate 888
information about the statistical significance of the experiments? 889
Answer: [Yes] 890
Justification: We offer the 10 different task orders to reduce the influence of stochastic and 891
provide the avg ±std in Appendix H. 892
Guidelines: 893
• The answer NA means that the paper does not include experiments. 894
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 895
dence intervals, or statistical significance tests, at least for the experiments that support 896
the main claims of the paper. 897
•The factors of variability that the error bars are capturing should be clearly stated (for 898
example, train/test split, initialization, random drawing of some parameter, or overall 899
run with given experimental conditions). 900
•The method for calculating the error bars should be explained (closed form formula, 901
call to a library function, bootstrap, etc.) 902
• The assumptions made should be given (e.g., Normally distributed errors). 903
•It should be clear whether the error bar is the standard deviation or the standard error 904
of the mean. 905
•It is OK to report 1-sigma error bars, but one should state it. The authors should 906
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 907
of Normality of errors is not verified. 908
•For asymmetric distributions, the authors should be careful not to show in tables or 909
figures symmetric error bars that would yield results that are out of range (e.g. negative 910
error rates). 911
•If error bars are reported in tables or plots, The authors should explain in the text how 912
they were calculated and reference the corresponding figures or tables in the text. 913
8.Experiments Compute Resources 914
Question: For each experiment, does the paper provide sufficient information on the com- 915
puter resources (type of compute workers, memory, time of execution) needed to reproduce 916
the experiments? 917
Answer: [Yes] 918
Justification: We provide the compute resources in Appendix K. 919
Guidelines: 920
• The answer NA means that the paper does not include experiments. 921
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 922
or cloud provider, including relevant memory and storage. 923
25•The paper should provide the amount of compute required for each of the individual 924
experimental runs as well as estimate the total compute. 925
•The paper should disclose whether the full research project required more compute 926
than the experiments reported in the paper (e.g., preliminary or failed experiments that 927
didn’t make it into the paper). 928
9.Code Of Ethics 929
Question: Does the research conducted in the paper conform, in every respect, with the 930
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 931
Answer: [Yes] 932
Justification: We confirm that we conducted in the paper conform with the NeurIPS Code of 933
Ethics. 934
Guidelines: 935
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 936
•If the authors answer No, they should explain the special circumstances that require a 937
deviation from the Code of Ethics. 938
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 939
eration due to laws or regulations in their jurisdiction). 940
10.Broader Impacts 941
Question: Does the paper discuss both potential positive societal impacts and negative 942
societal impacts of the work performed? 943
Answer: [NA] 944
Justification: Nor applicable. We study machine learning problem on public dataset such as 945
CIFAR10. 946
Guidelines: 947
• The answer NA means that there is no societal impact of the work performed. 948
•If the authors answer NA or No, they should explain why their work has no societal 949
impact or why the paper does not address societal impact. 950
•Examples of negative societal impacts include potential malicious or unintended uses 951
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 952
(e.g., deployment of technologies that could make decisions that unfairly impact specific 953
groups), privacy considerations, and security considerations. 954
•The conference expects that many papers will be foundational research and not tied 955
to particular applications, let alone deployments. However, if there is a direct path to 956
any negative applications, the authors should point it out. For example, it is legitimate 957
to point out that an improvement in the quality of generative models could be used to 958
generate deepfakes for disinformation. On the other hand, it is not needed to point out 959
that a generic algorithm for optimizing neural networks could enable people to train 960
models that generate Deepfakes faster. 961
•The authors should consider possible harms that could arise when the technology is 962
being used as intended and functioning correctly, harms that could arise when the 963
technology is being used as intended but gives incorrect results, and harms following 964
from (intentional or unintentional) misuse of the technology. 965
•If there are negative societal impacts, the authors could also discuss possible mitigation 966
strategies (e.g., gated release of models, providing defenses in addition to attacks, 967
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 968
feedback over time, improving the efficiency and accessibility of ML). 969
11.Safeguards 970
Question: Does the paper describe safeguards that have been put in place for responsible 971
release of data or models that have a high risk for misuse (e.g., pretrained language models, 972
image generators, or scraped datasets)? 973
Answer: [NA] 974
Justification: No such risks. 975
26Guidelines: 976
• The answer NA means that the paper poses no such risks. 977
•Released models that have a high risk for misuse or dual-use should be released with 978
necessary safeguards to allow for controlled use of the model, for example by requiring 979
that users adhere to usage guidelines or restrictions to access the model or implementing 980
safety filters. 981
•Datasets that have been scraped from the Internet could pose safety risks. The authors 982
should describe how they avoided releasing unsafe images. 983
•We recognize that providing effective safeguards is challenging, and many papers do 984
not require this, but we encourage authors to take this into account and make a best 985
faith effort. 986
12.Licenses for existing assets 987
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 988
the paper, properly credited and are the license and terms of use explicitly mentioned and 989
properly respected? 990
Answer: [Yes] 991
Justification: We referred to open-source code from various methods and developed our own 992
implementation of the core algorithm. 993
Guidelines: 994
• The answer NA means that the paper does not use existing assets. 995
• The authors should cite the original paper that produced the code package or dataset. 996
•The authors should state which version of the asset is used and, if possible, include a 997
URL. 998
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 999
•For scraped data from a particular source (e.g., website), the copyright and terms of 1000
service of that source should be provided. 1001
•If assets are released, the license, copyright information, and terms of use in the 1002
package should be provided. For popular datasets, paperswithcode.com/datasets 1003
has curated licenses for some datasets. Their licensing guide can help determine the 1004
license of a dataset. 1005
•For existing datasets that are re-packaged, both the original license and the license of 1006
the derived asset (if it has changed) should be provided. 1007
•If this information is not available online, the authors are encouraged to reach out to 1008
the asset’s creators. 1009
13.New Assets 1010
Question: Are new assets introduced in the paper well documented and is the documentation 1011
provided alongside the assets? 1012
Answer: [NA] 1013
Justification: No new assets will be released. 1014
Guidelines: 1015
• The answer NA means that the paper does not release new assets. 1016
•Researchers should communicate the details of the dataset/code/model as part of their 1017
submissions via structured templates. This includes details about training, license, 1018
limitations, etc. 1019
•The paper should discuss whether and how consent was obtained from people whose 1020
asset is used. 1021
•At submission time, remember to anonymize your assets (if applicable). You can either 1022
create an anonymized URL or include an anonymized zip file. 1023
14.Crowdsourcing and Research with Human Subjects 1024
Question: For crowdsourcing experiments and research with human subjects, does the paper 1025
include the full text of instructions given to participants and screenshots, if applicable, as 1026
well as details about compensation (if any)? 1027
27Answer: [NA] 1028
Justification: We use public dataset. 1029
Guidelines: 1030
•The answer NA means that the paper does not involve crowdsourcing nor research with 1031
human subjects. 1032
•Including this information in the supplemental material is fine, but if the main contribu- 1033
tion of the paper involves human subjects, then as much detail as possible should be 1034
included in the main paper. 1035
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 1036
or other labor should be paid at least the minimum wage in the country of the data 1037
collector. 1038
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 1039
Subjects 1040
Question: Does the paper describe potential risks incurred by study participants, whether 1041
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 1042
approvals (or an equivalent approval/review based on the requirements of your country or 1043
institution) were obtained? 1044
Answer: [NA] 1045
Justification: We do not involve crowdsourcing nor research with human subjects. 1046
Guidelines: 1047
•The answer NA means that the paper does not involve crowdsourcing nor research with 1048
human subjects. 1049
•Depending on the country in which research is conducted, IRB approval (or equivalent) 1050
may be required for any human subjects research. If you obtained IRB approval, you 1051
should clearly state this in the paper. 1052
•We recognize that the procedures for this may vary significantly between institutions 1053
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 1054
guidelines for their institution. 1055
•For initial submissions, do not include any information that would break anonymity (if 1056
applicable), such as the institution conducting the review. 1057
28