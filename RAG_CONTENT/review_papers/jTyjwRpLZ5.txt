Stochastic Zeroth-Order Optimization under Strongly
Convexity and Lipschitz Hessian: Minimax Sample
Complexity
Qian Yu
University of California, Santa Barbara
qianyu02@ucsb.eduYining Wang
University of Texas at Dallas
yining.wang@utdallas.edu
Baihe Huang
University of California, Berkeley
baihe_huang@berkeley.eduQi Lei
New York University
ql518@nyu.eduJason D. Lee
Princeton University
Jasondl@princeton.edu
Abstract
Optimization of convex functions under stochastic zeroth-order feedback has been
a major and challenging question in online learning. In this work, we consider the
problem of optimizing second-order smooth and strongly convex functions where
the algorithm is only accessible to noisy evaluations of the objective function it
queries. We provide the first tight characterization for the rate of the minimax
simple regret by developing matching upper and lower bounds. We propose an
algorithm that features a combination of a bootstrapping stage and a mirror-descent
stage. Our main technical innovation consists of a sharp characterization for the
spherical-sampling gradient estimator under higher-order smoothness conditions,
which allows the algorithm to optimally balance the bias-variance tradeoff, and a
new iterative method for the bootstrapping stage, which maintains the performance
for unbounded Hessian.
1 Introduction
Stochastic optimization of an unknown function with access to only noisy function evaluations is
a fundamental problem in operations research, optimization, simulation and bandit optimization
research, commonly known as zeroth-order optimization (Chen et al., 2017), derivative-free opti-
mization (Conn et al., 2009; Rios & Sahinidis, 2013) or bandit optimization (Bubeck et al., 2021).
In this problem, an optimization algorithm interacts sequentially with an oracle and obtains noisy
function evaluations at queried points every time. The algorithm produces an approximately optimal
solution after Tsuch evaluations, with its performance evaluated by the expected difference between
the function values at the approximate optimal solution produced and the optimal solution. A more
rigorous formulation of the problem is given in Sec. 2 below.
Existing works and results on stochastic zeroth-order optimization could be broadly categorized into
two classes:
1.Convex functions . In the first thread of research, the unknown objective function to be
optimized is assumed to be concave (for maximization problems) or convex (for minimization
problems). For these problems, with minimal smoothness (e.g. objective function being
Lipschitz continuous) it is possible to achieve a sample complexity of ˜O(ε−2)for an
expected optimization error or ε, which is also a polynomial function of domain dimension
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Lower Bound
Bach & Perchet (2016) Akhavan et al. (2020)
O(dT−1
2M−1
2) O(d2T−2
3M−1)
Novitskii & Gasnikov (2021)
O(d5
3T−2
3M−1)Upper Bounds
Ω(dT−2
3M−1)Ours
O(dT−2
3M−1)
Table 1: The dependence of simple regret on T(number of function evaluations), d(dimension) and
M(parameter describing strong convexity). Our results are highlighted in comparison to the prior
works.
d; see for example the works of Agarwal et al. (2013); Lattimore & Gyorgy (2021); Bubeck
et al. (2021);
2.Smooth functions . In the second thread of research, the unknown objective function to be
optimized is assumed to be highly smooth , but not necessary concave/convex. Typical results
assume the objective function is Hölder smooth of order k≥1, meaning that the (k−1)-th
derivative of the objective function is Lipschitz continuous. Without additional conditions,
the optimal sample complexity with such smoothness assumptions is ˜O(ε−(2+d/k))(Wang
et al., 2019), which scales exponentially with the domain dimension d.
In this paper, we study the optimal sample complexity of stochastic zeroth-order optimization when
the objective function exhibits both (strong) convexity and a high degree of smoothness. As we
have remarked in the first bullet point above, with convexity and Hölder smoothness of order k= 1
(equivalent to the objective function being Lipschitz continuous), the works of Agarwal et al. (2013);
Lattimore & Gyorgy (2021); Bubeck et al. (2021) established an ˜O(ε−2)upper bound. With higher
order of Hölder smoothness, i.e., k= 2(equivalent to the gradient of the objective being Lipschitz
continuous), it is shown that simpler algorithms exist but the sample complexity remains ˜O(ε−2)
(Besbes et al., 2015; Agarwal et al., 2010; Hazan & Levy, 2014), which seemingly suggests the
relatively smaller role smoothness plays in the presence of convexity. In this paper we show that
with even higher order of Hölder smoothness, i.e., k= 3(specifically, the Hessian of the objective
being Lipschitz continuous), the optimal sample complexity is improved to O(ε−1.5), which is
significantly smaller than the sample complexity of the convex-without-smoothness setting ˜O(ε−2),
or the smooth-without-convexity setting ˜O(ε−(2+d/3)). More importantly, when the Lipschitzness of
Hessian is defined in Frobenius norm (see condition A1), we propose an algorithm that also achieves
the optimal dimension dependency, which fully characterizes the optimal sample complexity.
Summary of technical contributions. We developed several important techniques in this paper
to achieve the optimal sample complexity when the objective function is strongly convex and has
Lipschitz Hessian. First, we show that when estimating the gradient under a stochastic environment,
even with an unbounded action space, it could be beneficial to sample with non-isotropic distributions
(as opposed to conventional standard Gaussian, or uniform distributions on hyperspheres). Second,
we present a new approach to analyze the bias and variance of the hyperellipsoid-sampling-based
gradient estimators, which enables obtaining sharp bounds with tight constants and strengthens the
best-known results in the higher-order smoothness case. Third, we present a two-stage bootstrap-type
framework for the algorithmic design, which extends the perturbative analysis in the final stage to the
full regime. This extension relies on a non-trivial modification of Newton’s method, and we proved
its robustness under stochastic observation. We complete the characterization of the minimax regret
by deriving a lower bound using the KL-divergence-based approach.
Additional related works on higher-order smoothness. Recent years have seen increasing atten-
tion on exploiting higher order smoothness in bandit optimization. Remarkably, it was shown that
when the Hölder smoothness condition holds simultaneously for both k= 2andk= 3, the optimal
sample complexity can be improved to O(ε−1.5). (Akhavan et al., 2020; Novitskii & Gasnikov,
2021). We list our results together with the most relevant work in Table 1. While this line of work
also demonstrates the benefit of higher-order smoothness in improving the sample complexity, their
setting is related but slightly different from what we considered in this work. (See reference therein:
Bach & Perchet (2016); Akhavan et al. (2020); Novitskii & Gasnikov (2021)). On one hand, the prior
work concentrates on projected gradient-descent-like algorithms, which require a Lipschitz gradient
(i.e., the k= 2 requirement, and we do not). This additional requirement can not be removed by
2simply replacing the gradient steps with Newton’s methods, which can lead to unbounded expectation
in simple regret in the stochastic case.1On the other hand, their results are based on the generalized
Hölder condition, which is different from our assumption that the Hessian is Lipschitz in Frobenius
norm. Therefore we only emphasize the dependence of d, T andMin Table 1 and omit other
parameters. We provide a detailed comparison on the implication of these results in Appendix A.
Our results are also related to a special case discussed in (Shamir, 2013), which shows that for
quadratic functions it is possible to achieve a sample complexity of ˜O(ε−1). As quadratic functions
are infinitely differentiable with bounded derivatives on orders, they are Hölder smooth of any
arbitrary order k→ ∞ , which could be regarded as an extreme of the results established in this paper
which only require k= 3.
Related works on gradient estimators. Gradient estimation serves as a key building block for
stochastic zeroth-order optimization algorithms. For instance, a classical one-point estimator was
proposed as early as in Flaxman et al. (2005); Blair (1985), where the gradient ∇f(x)is estimated
based on empirical measures of f(x+ru)for some fixed rand i.i.d. uniformly random uon the unit
hypersphere. This was later refined to be two-point estimators, and the sampling distribution of u
was generalized to isotropic distributions such as standard Gaussian (e.g., see Agarwal et al. (2010);
Bach & Perchet (2016); Zhang et al. (2020)). A majority of prior work focused on the analysis for
such estimators under the Lipschitz gradient assumption, where the best guaranteed bound for the
bias is at the order of Θ(r), with a polynomial factor dependent on d. The line of works by Bach &
Perchet (2016); Akhavan et al. (2020); Novitskii & Gasnikov (2021) also adopted isotropic sampling,
and it was shown that with higher-order smoothness of k= 3, this bound can be improved to Θ(r2).
The improvement of sample complexity in our work is mainly due to the tight characterization of
our gradient estimator, which covers the special case of isotropic sampling and provides a bound of
r2ρ√
d
2(d+2)in the estimation bias. This strengthens or improves the bounds presented in prior works, and
a detailed comparison can be found in Appendix A.
On the other hand, non-isotropic sampling was used as early as in Abernethy et al. (2008), then
extended in Saha & Tewari (2011); Hazan & Levy (2014). Primarily, they were used to ensure that
the sampling points are contained within a bounded action set. (Suggala et al., 2021) showed the
necessity of non-isotropic sampling over quadratic loss function in the adversarial setting. In this
work, we essentially demonstrated that non-isotropic sampling can be used to refine a preliminary
algorithm by adding a mirror-descent-like final stage. More recently, non-isotropic sampling was
also adopted in Lattimore & György (2023) to optimize convex and global Lipschitz functions.
Notations. We follow the convention of machine learning theory where ∇2f(x)denotes the
Hessian of fat point x, while the trace of Hessian is denoted by Tr 
∇2f(x)
. This should not be
confused with the notation in classical field theory, where ∇2f(x)instead denotes the trace of the
Hessian. We use ∥ · ∥ 2to denote vector ℓ2norms, and ∥ · ∥ Fto denote matrix Frobenius norms. We
useIdto denote the identity matrix, and Sd−1to denote the unit hypersphere centered at the origin,
both for the d-dimensional Euclidean space Rd. We adopt the conventional notations (i.e., O,Ω,o,
andω) to describe regret bounds in the asymptotic sense with respect to the total number of samples
(denoted by T).
2 Problem Formulation
We consider the stochastic optimization problem under the class of functions that are strongly convex
and have Lipschitz Hessian. The goal in this setting is to design learning algorithms to achieve
approximately the global minimum of an unknown objective function f:Rd→R.
A learning algorithm Acan interact with the function by adaptively sampling their value for Ttimes,
and receive noisy observations. At each time t∈[T], the algorithm selects xt∈Rd, and receives the
1We note that even in the classical analysis of Newton’s method, which assumes zero-error observations, the
additional k= 2smoothness condition was adopted to obtain non-trivial complexity bounds (e.g., see Boyd &
Vandenberghe (2004), Section 9.5.3), implying the non-trivialness of removing the k= 2smoothness condition.
In this work, we provided an analysis for our proposed bootstrapping algorithm, which ensures the achievability
of bounded expected regret even with unbounded hessian.
3following observation,
yt=f(xt) +wt, (1)
where {wt}T
t=1are independent random variables with zero mean and bounded variance. Formally,
the algorithm can be described by a list of conditional distributions where each xtis selected based
on all historical data {xτ, yτ}τ<tand the corresponding distribution. Then for any t, we assume
thatE[wt|{xτ, yτ}τ<t,xt] = 0 andVar[wt|{xτ, yτ}τ<t,xt]≤1for any t.2For simplicity, we
also adopt a common assumption that the additive noises are subgaussian, particularly, P[|wt|>
s|{xτ, yτ}τ<t,xt]≤2e−s2for all s >0andt∈[T]. However, the subgaussian assumption can be
removed by adopting more sophisticated mean-estimation methods (e.g., see Nemirovskii & Yuom
(1983); Jerrum et al. (1986); Alon et al. (1999); Lee & Valiant (2022); Yu et al. (2023a)).
We assume that the objective function fis second-order differentiable. Furthermore, we impose the
following conditions.
(A1) (Lipschitz Hessian). There exist a constant ρ∈(0,+∞)such that for all x,x′∈Rd, it
holds that ∥∇2f(x)− ∇2f(x′)∥F≤ρ∥x′−x∥2, where ∥ · ∥ Fdenotes the Frobenius norm;
(A2) (Strong Convexity). There exists a constant M∈(0,+∞)such that for any x∈Rd, the
minimum eigenvalue of the Hessian ∇2f(x)is greater than M.
(A3) (Bounded Distance from Initialization to Optimum Point). There exists a constant R∈
(0,+∞)such that the infimum of f(x)within the hyperball ∥x∥2≤Ris identical to the
infimum of f(x)over the entire Rd.
In the rest of this paper, we let F(ρ, M, R )denote the set of all second-order differentiable functions
that satisfy the above conditions, with corresponding constants given by ρ, M , and R. We aim to
find algorithms to achieve asymptotically the following minimax simple regret, which measures the
expected difference of the objective function on xTand the optimum.
R(T;ρ, M, R ) := inf
Asup
f∈F(ρ,M,R )E[f(xT)−f(x∗)],
where x∗denotes the global minimum point of f.
3 Main Results
Theorem 3.1. For any dimension dand constants ρ, M, R , the minimax simple regrets are upper
bounded by lim supT→∞R(T;ρ, M, R )·T2
3≤C·
ρ2
3
Md
, where Cis a universal constant.
Theorem 3.2. For any fixed dimension dand constants ρ, M, R , the minimax simple regrets are lower
bounded by lim inf T→∞R(T;ρ, M, R )·T2
3≥C·
ρ2
3
Md
when the additive noises w1, ..., w Tare
standard Gaussian, where Cis a universal constant.
4 Proof Ideas for Theorem 3.1
The proposed algorithm operates in two stages (see Algorithm 4). In the first stage, the algorithm uses
a small fraction of samples to obtain a rough estimation of the global minimum point. We ensure that
the estimation in the first stage is sufficiently accurate with high probability, so that in the following
final stage, the objective function can be approximated by a quadratic function and the resulting
approximation error can be bounded using tensor analysis.
4.1 Key Techniques and The Final Stage
We first present the key steps of our algorithm, which relies on the subroutines presented in Algorithm
1-3, i.e., GradientEst, BootstrappingEst, and HessianEst. These subroutines estimate the (linearly
2If the variances of wt’s are bounded by a different constant, all our results can be reproduced by normalizing
the values of f.
4transformed) gradients and Hessian functions of fat any given point by sampling the values of f
on hyperellipsoids. The key ingredient of our proof is the sharp characterizations for the biases and
variances of the GradientEst estimator, stated in Theorem 4.1.
Algorithm 1 GradientEst
Input :x, Z, n ▷ Z is ad×dmatrix, return ˆgas an estimator of Z∇f(x)
fork←1tondo
Letukbe a point sampled uniformly randomly from the standard hypersphere Sd−1
Lety+,y−be samples of fatx+Zukandx−Zuk, respectively, let gk=d
2(y+−y−)uk
end for
Return ˆg=1
nPn
k=1gk
Algorithm 2 BootstrappingEst
Input :x, r, n ▷ Goal: estimate ∇f(x)coordinate wise with O(nd)samples
Lete1, ...,edbe any orthonormal basis of Rd
fork←1toddo
Lety+,k,y−,keach be the average of nsamples of fatx+rekandx−rekrespectively
Letmk= (y+−y−)/2r ▷ Estimate the kth entry
end for
Return ˆm={mk}k∈[d]
Algorithm 3 HessianEst
Input :x, r, n ▷ Goal: estimate ∇2f(x)coordinate wise with O(nd2)samples
Lete1, ...,edbe any orthonormal basis of Rd
Letybe the average of nsamples of fatx
fork←1toddo
Lety+,k,y−,keach be the average of nsamples of fatx+rekandx−rekrespectively
LetHkk= (y++y−−2y)/r2▷Diagonal entries
forℓ←k+ 1toddo
LetHkℓ=Hℓkbe the average of nsamples of (f(x+rek+reℓ) +f(x−rek−reℓ)−
f(x+rek−reℓ)−f(x−rek+reℓ))/4r2▷Off-diagonal entries
end for
end for
LetˆH0={Hjk}(i,j)∈[d]2, and ˆHbe the matrix with same eigenvectors but with each eigenvalue
λreplaced by max{λ, M} ▷Projecting to the set where ˆH−MIdis positive semidefinite
Return ˆH
Theorem 4.1. For any fixed inputs x,Z,n, and any function fsatisfying the Lipschitz Hessian
condition with parameter ρ, the output ˆgreturned by the GradientEst subroutine satisfies the following
properties
||E[ˆg]−Z∇f(x)||2≤λ3
Zρ√
d
2(d+ 2), (2)
Tr(Cov[ˆg])≤2d
n||Z∇f(x)||2
2+d2
18n 
ρλ3
Z2+d2
2n, (3)
where λZis the largest singular value of Z.
Remark 4.2. Inequality (2)provides a sharp characterization for the bias of the gradient estimator,
as it can be matched for any λZanddwith a cubic polynomial f. Inequality (3)is sharp in the
asymptotic regime when both ∇fandλZapproaches zero.
We also provide rough estimates on the high-probability bounds for the BootstrappingEst and the
HessianEst functions. Specifically, we show that their errors have sub-Gaussain tails in distribution,
as stated in the following theorem.
5Theorem 4.3. For any fixed inputs x,r,n, any function fsatisfying the Lipschitz Hessian condition
with parameter ρ, and any variable K > 0, the outputs ˆmandˆHreturned by the BootstrappingEst
and the HessianEst subroutine satisfy the following conditions.
P[||ˆm− ∇f(x)||2≥K]≤2 exp 
−K2
3dρ2r4
4+12d
nr2!
, (4)
PhˆH− ∇2f(x)
F≥Ki
≤2 exp 
−K2
2d2ρ2r2+144d2
nr4!
. (5)
We postpone the proof of the above theorems to Section 4.2 and Appendix C and proceed to describe
how these results are used in the algorithm.
For brevity, let ϵ≜ρ2
3
MdT−2
3be the minimax regret we aim to achieve, and let xBdenote the estimator
xstored at the end of the first stage. The role of the final stage is to ensure that if f(xB)−f(x∗)
is sufficiently small with high probability, the final result of the proposed algorithm achieves the
stated simple regret guarantees. Formally, we require the following achievability result from the
Bootstrapping stage.
Theorem 4.4. For any fixed ρ, M andR, the result returned by the first stage of Algorithm 4 satisfies
lim
T→∞sup
f∈F(ρ,M,R )Eh
(f(xB)−f(x∗))3
2i
/ϵ= 0. (6)
Note that the above condition implies that f(xB)−f(x∗)concentrates below o
ϵ2
3
, which is
weaker than the O(ϵ)rates stated in our main theorems.3The bottleneck of the overall algorithm is
on the final stage, and one can achieve equation (6)using any suboptimal algorithm with an expected
simple regret of o(T−4
9). For example, one can run the suboptimal algorithm twice, estimate their
achieved function values by averaging over o(T)samples, and then choose the outcome with the
smaller estimated function value as xB. In the rest of this section, we prove Theorem 3.1 assuming the
correctness of the above theorem. A self-contained proof for Theorem 4.4 is provided in Appendix E.
Before proceeding with the proof, we provide a high-level description of the algorithm in the final
stage. At the beginning, we perform a Hessian estimation near xBusing the HessianEst subroutine
withO(T)samples. From Theorem 4.3, our choice of parameters results in an expected estimation
error of o(1)for sufficiently large T.
The algorithm proceeds to find a real matrix ZH, which essentially serves as a linear transformation
on the action domain such that the Hessian of the transformed function is approximately the identity
matrix. Note that the projection step in the HessianEst function ensures the eigenvalues of the
estimator are no less than M. There is always a valid solution of ZH.
Then, we estimate the gradient at xBusing the GradientEst subroutine, which samples on a hyperel-
lipsoid with a shape characterized by ZH. We chose the hyperellipsoid sampling in the final stage
due to its superior performance in the small-gradient regime compared to coordinate-wise sampling.
In contrast, the coordinate-wise estimator is used in the bootstrapping stage to eliminate the depen-
dency of the local gradient on its bias-variance tradeoff, which is beneficial for the non-asymptotic
analysis. Particularly, we scale the hyperellipsoid with a carefully designed factor (see the definition
of variable rg) to minimize the estimation error. Then, the remaining steps can be interpreted as a
modified Newton step, which essentially approximates the global minimum point with a quadratic
approximation.
The analysis in our proof relies on the following proposition, which is proved in Appendix D.
Proposition 4.5. For any given point xBand any function fthat satisfies strong convexity and
Lipschitz Hessian, let ˜x≜xB−(∇2f(xB))−1∇f(xB)and˜f(x)denote the quadratic approximation
3With more sophisticated analysis, this concentration requirement can be improved to only requiring a similar
upper bound of o
ϵ1
2
. However, we choose equation (6)to provide a simpler proof, as it does not affect the
asymptotic sample complexity.
6Algorithm 4 An Example Algorithm to Achieve the Minimax Rates
Input T, ρ, M
Letx=0
The First Stage:
fork←1to⌊T0.1⌋do
Letnm=⌊T0.9
10d⌋,nH=⌊T0.9
10d2⌋,rm=
8
nmρ21
6,rH=
144
nHρ21
6
Letˆm=BootstrappingEst (x, rm, nm),ˆH=HessianEst (x, rH, nH)
LetHm∗denote the matrix with the same eigenvectors of ˆHbut each eigenvalue λreplaced by
max{λ, m∗}, choose m∗to be the smallest value such that ||H−1
m∗ˆm||2≤M
ρ.
Letx=x−H−1
m∗ˆm
end for
The Final Stage:
Letng=⌊T
10⌋,nH=⌊T
10d2⌋,rg=
d3
ngρ21
6,rH=
144
nHρ21
6
LetˆH=HessianEst (x, rH, nH),ZHbe any symmetric matrix such that Z2
H=ˆH−1, andλZHbe
the largest eigenvalue of ZH
LetZ=rgZH/λZH,ˆg=GradientEst (x, Z, n g),r=−ˆH−1Z−1ˆg
Project rto the L2ball of radiusM
ρ, i.e.,r=r·min{1,M
ρ||r||2}
Return x=x+r
1
2(x−˜x)⊺∇2f(xB)(x−˜x), we have the following inequality for all xwith||x−xB||2≤M
ρ.
f(x)−f∗≤2˜f(x) +12ρ(f(xB)−f∗)3
2
M3
2. (7)
Furthermore, if xis generated by the final stage of Algorithm 4 with any parameter values that satisfy
ng≥d3,nH≥64ρ4d6
M6and the first-stage output is set to xB, then
Eh
˜f(x)|xBi
≤ 
14d2ρ4
3
M2n1
3
H+52d
ng!
(f(xB)−f(x∗)) +82ρ
M3
2(f(xB)−f(x∗))3
2+3dρ2
3
Mn2
3g.(8)
Now, we use Proposition 4.5 to prove the achievability result.
Proof of Theorem 3.1 given Theorem 4.4. First, recall our construction ensures that ||xT−xB||2≤
M
ρ. Inequality (7) can always be applied and we have
R(T;ρ, M, R )≤ sup
f∈F(ρ,M,R )E"
2˜f(x) +12ρ(f(xB)−f∗)3
2
M3
2#
.
Then, when Tis sufficiently large, the conditions of (8) holds and we have
R(T;ρ, M, R )≤ sup
f∈F(ρ,M,R )E" 
28d2ρ4
3
M2n1
3
H+104d
ng!
(f(xB)−f(x∗)) +176ρ(f(xB)−f∗)3
2
M3
2#
+6dρ2
3
Mn2
3g.
Note that inequality (6)implies that E[f(xB)−f(x∗)] = o(ϵ2
3) =o(T−4
9)and we have that
n−1
3
H+n−1
g=o(T−2
9). The RHS of the above inequality is dominated by the last term. Hence,
lim sup
T→∞R(T;ρ, M, R )·T2
3≤lim sup
T→∞6dρ2
3T2
3
Mn2
3g=O 
ρ2
3
Md!
.
7To complete the proof, we show that the proposed algorithm samples the function values of fat
most T−1times. In the first stage, both BootstrappingEst and HessianEst are executed once per
loop, with BootstrappingEst requiring at most 2dnm≤T0.9
5samples and HessianEst requiring at
most 2d2nH≤T0.9
5samples each time. Therefore, the total number of samples used in the first stage
is bounded by ⌊T⌋
T0.9
5+T0.9
5
≤2T
5. In the final stage, we make one call to both HessianEst
and GradientEst, which together require nH(2d2) + 2ng≤2T
5samples. Thus, the overall number of
samples is bounded by4T
5, which ensures that it is no greater than T−1.
4.2 Proof of Theorem 4.1
To prove inequality (2), we investigate the following function
G(r;x)≜Eu∼Unif(Sd−1)d
2r(f(x+ru)−f(x−ru))u
,
where Unif(Sd−1)denotes the uniform distribution on Sd−1. Recall that in our algorithm we have
E[ˆg] =rG(r;x)ifZ=rIdfor some r∈(0,+∞), and by differentiability we have ∇f(x) =
limz→0+G(z;x). Under this condition, we can bound ||E[ˆg]−r∇f(x)||2by integration, i.e.,
||E[ˆg]−r∇f(x)||2=rG(r;x)−lim
z→0+G(z;x)
2≤rZr
0+d
dzG(z;x)
2dz. (9)
Note that G(z;x)can be written into the following equivalent form.
G(z;x) =R
Sd−1d
2z(f(x+zu)−f(x−zu))dAR
Sd−1||dA||2,
where the integration is with respect to uover the surface Sd−1, anddAis the vector surface element,
i.e., with the magnitude being the infinitesimally small surface area and the direction perpendicular to
the surface (pointing outward). The differential of G(z;x)overzcan be written as
d
dzG(z;x) =R
Sd−1∂
∂z d
2z(f(x+zu)−f(x−zu))
dAR
Sd−1||dA||2
=R
Sd−1−d
2z2(f(x+zu)−f(x−zu))dAR
Sd−1||dA||2
+R
Sd−1d
2zu·(∇f(x+zu) +∇f(x−zu))dAR
Sd−1||dA||2.
The gist of this proof is to note that for any u∈Swe have uanddAare parallel (i.e., uis parallel
to the normal vector of the hypersphere at the same point), so the second term in the integral above
on the numerator can be written as
Z
Sd−1d
2zu(∇f(x+zu) +∇f(x−zu))·dA.
Hence, by divergence theorem, we have
d
dzG(z;x) =1R
Sd−1||dA||2·Z
Bd∇u·
−d
2z2Id(f(x+zu)−f(x−zu))
+ (∇f(x+zu) +∇f(x−zu))d
2zu
dV
=d
2·R
BduTr(∇2f(x+zu)− ∇2f(x−zu))dVR
Sd−1||dA||2, (10)
where Bddenotes the standard hyperball.
8Now consider any unit vector e. Letuedenote the reflection of uwith respect to the hyperplane
orthogonal to e, i.e.,ue≜u−2(u·e)e. Because the hyperball Bis invariant under the reflection
u→ue, equation (10) can also be written as
d
dzG(z;x) =d
2·R
BdueTr(∇2f(x+zue)− ∇2f(x−zue))dVR
Sd−1||dA||2. (11)
Hence, by averaging equation (10) and (11), we have
d
dzG(z;x)·e=d
4R
BduTr(∇2f(x+zu)− ∇2f(x−zu))dVR
Sd−1||dA||2·e
+d
4R
BdueTr(∇2f(x+zue)− ∇2f(x−zue))dVR
Sd−1||dA||2·e
=d
4R
Bdu·eTr(∇2f(x+zu)− ∇2f(x+zue))dVR
Sd−1||dA||2
+d
4R
Bd−u·eTr(∇2f(x−zu)− ∇2f(x−zue))dVR
Sd−1||dA||2. (12)
By the Lipschitz Hessian condition and Cauchy’s inequality, the difference between the differential
terms above can be bounded as follows.
Tr 
∇2f(x±zu)− ∇2f(x±zue)≤√
d||∇2f(x±zu)− ∇2f(x±zue)||F
≤ρ√
d||zu−zue||2= 2zρ√
d|u·e|. (13)
Consequently,
d
dzG(z;x)·e≤zρd√
dR
Bd(u·e)2dVR
Sd−1||dA||2=zρ√
d
d+ 2.
Note that ecan be any unit vector. We have essentially bounded the ℓ2norm ofd
dzG(z;x), i.e.,
d
dzG(z;x)
2≤zρ√
d
d+ 2.
As mentioned earlier, when Z=rIdinequality (2)is obtained by applying this gradient-norm bound
to inequality (9) .
For general input matrix Z, we can view GradientEst as a subroutine that operates on the same
function fbut with a linear transformation applied to the input domain. Formally, let f′(y)≜
f(x+Z
λZ(y−x)). We have that f′satisfies the Lipschitz Hessian condition with parameter ρas
well. Therefore, inequality (2)can be obtained following the same analysis by replacing fwithf′
andZwithλZId.
Now we present the proof for inequality (3). Formally, let w+,w−be two independent samples
of additive noises. Then the trace of covariance matrix of ˆgcan upper bounded using the second
moments of single measurements.
Tr(Cov[ˆg])≤1
nEu∼Unif(Sd−1),w+,w−"d
22 
f(x+Zu)−f(x−Zu) +w−−w−2#
=d2
4nEu∼Unif(Sd−1)h
(f(x+Zu)−f(x−Zu))2+ 2i
. (14)
The identity above uses the fact that additive noises are unbiased and have bounded variances.
Note that from the Lipschitz Hessian condition, we have that
|f(x±Zu)−f2(x±Zu)| ≤1
6ρ||Zu||3
2≤1
6ρλ3
Z,
9where f2is the Taylor polynomial of fexpanded at xup to the quadratic terms. Consequently,
inequality (14) implies
Tr(Cov[ˆg])≤d2
4nE"
|f2(x+Zu)−f2(x−Zu)|+1
3ρλ3
Z2
+ 2#
=d2
4nE"
|2Zu· ∇f(x)|+1
3ρλ3
Z2
+ 2#
≤d2
4nE"
2· |2Zu· ∇f(x)|2+ 21
3ρλ3
Z2
+ 2#
=2d
n||Z∇f(x)||2
2+d2
18n 
ρλ3
Z2+d2
2n
where the expectations are taken of u∼Unif(Sd−1), and the last equality is due to the well-known
fact that E[uu⊺] =1
dId.
5 Conclusion and Future Work
In this work, we achieve the first minimax simple regret for bandit optimization of second-order
smooth and strongly convex functions. We derived the matching upper and lower bounds and
proposed an algorithm that integrates a bootstrapping stage with a mirror-descent stage. Our key
technical innovations include a sharp characterization of the spherical-sampling gradient estimator
under higher-order smoothness conditions and a novel iterative method for the bootstrapping stage
that remains effective with unbounded Hessians.
While these advancements settle the fundamental problem of optimizing second-order smooth and
strongly convex functions with zeroth-order feedback, the techniques and insights presented in this
paper also pave the way for further research in this domain. One interesting follow-up direction is to
generalize our analysis to the online setting for the average regret metric. Additionally, investigating
the fundamental tradeoff between simple regret and average regret could yield valuable insights for
task-specific algorithmic designs.
Acknowledgement
JDL acknowledges the support of the NSF CCF 2002272, NSF IIS 2107304, and NSF CAREER
Award 2144994.
References
Jacob Abernethy, Elad Hazan, and Alexander Rakhlin. Competing in the dark: An efficient algorithm
for bandit linear optimization. pp. 263–273, 2008. 21st Annual Conference on Learning Theory,
COLT 2008 ; Conference date: 09-07-2008 Through 12-07-2008.
Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimization with
multi-point bandit feedback. In Colt, pp. 28–40. Citeseer, 2010.
Alekh Agarwal, Dean P. Foster, Daniel Hsu, Sham M. Kakade, and Alexander Rakhlin. Stochastic
convex optimization with bandit feedback. SIAM Journal on Optimization , 23(1):213–240, 2013.
Arya Akhavan, Massimiliano Pontil, and Alexandre Tsybakov. Exploiting higher order smoothness in
derivative-free optimization and continuous bandits. Advances in Neural Information Processing
Systems , 33:9017–9027, 2020.
Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency
moments. Journal of Computer and System Sciences , 58(1):137–147, 1999. ISSN 0022-0000.
doi: https://doi.org/10.1006/jcss.1997.1545. URL https://www.sciencedirect.com/
science/article/pii/S0022000097915452 .
10Francis Bach and Vianney Perchet. Highly-smooth zero-th order online optimization. In Conference
on Learning Theory , pp. 257–283. PMLR, 2016.
Omar Besbes, Yonatan Gur, and Assaf Zeevi. Non-stationary stochastic optimization. Operations
research , 63(5):1227–1244, 2015.
Charles Blair. Problem complexity and method efficiency in optimization (as nemirovsky and db
yudin). Siam Review , 27(2):264, 1985.
Stephen P Boyd and Lieven Vandenberghe. Convex optimization . Cambridge university press, 2004.
Sébastien Bubeck, Ronen Eldan, and Yin Tat Lee. Kernel-based methods for bandit convex optimiza-
tion. Journal of the ACM (JACM) , 68(4):1–35, 2021.
Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. Zoo: Zeroth order
optimization based black-box attacks to deep neural networks without training substitute models.
InProceedings of the 10th ACM workshop on artificial intelligence and security , pp. 15–26, 2017.
Andrew R Conn, Katya Scheinberg, and Luis N Vicente. Introduction to derivative-free optimization .
SIAM, 2009.
Abraham D. Flaxman, Adam Ta uman Kalai, and H. Brendan McMahan. Online convex optimization
in the bandit setting: gradient descent without a gradient. In Proceedings of the Sixteenth Annual
ACM-SIAM Symposium on Discrete Algorithms , SODA ’05, pp. 385–394, USA, 2005. Society for
Industrial and Applied Mathematics. ISBN 0898715857.
Elad Hazan and Kfir Levy. Bandit convex optimization: Towards tight bounds. Advances in Neural
Information Processing Systems , 27, 2014.
Mark R. Jerrum, Leslie G. Valiant, and Vijay V . Vazirani. Random generation of combina-
torial structures from a uniform distribution. Theoretical Computer Science , 43:169–188,
1986. ISSN 0304-3975. doi: https://doi.org/10.1016/0304-3975(86)90174-X. URL https:
//www.sciencedirect.com/science/article/pii/030439758690174X .
Tor Lattimore and Andras Gyorgy. Improved regret for zeroth-order stochastic convex bandits. In
Conference on Learning Theory , pp. 2938–2964. PMLR, 2021.
Tor Lattimore and András György. A second-order method for stochastic bandit convex optimisation.
In Gergely Neu and Lorenzo Rosasco (eds.), Proceedings of Thirty Sixth Conference on Learning
Theory , volume 195 of Proceedings of Machine Learning Research , pp. 2067–2094. PMLR, 12–15
Jul 2023. URL https://proceedings.mlr.press/v195/lattimore23a.html .
Jasper C.H. Lee and Paul Valiant. Optimal sub-gaussian mean estimation in R. In 2021 IEEE
62nd Annual Symposium on Foundations of Computer Science (FOCS) , pp. 672–683, 2022. doi:
10.1109/FOCS52979.2021.00071.
A. Nemirovskii and D. Yuom. Problem Complexity and Method Efficiency in Optimization," . Wiley,
1983.
Vasilii Novitskii and Alexander Gasnikov. Improved exploiting higher order smoothness in derivative-
free optimization and continuous bandit. arXiv preprint arXiv:2101.03821 , 2021.
Luis Miguel Rios and Nikolaos V Sahinidis. Derivative-free optimization: a review of algorithms
and comparison of software implementations. Journal of Global Optimization , 56(3):1247–1293,
2013.
Ankan Saha and Ambuj Tewari. Improved regret guarantees for online smooth convex optimization
with bandit feedback. In Geoffrey Gordon, David Dunson, and Miroslav Dudík (eds.), Proceedings
of the Fourteenth International Conference on Artificial Intelligence and Statistics , volume 15 of
Proceedings of Machine Learning Research , pp. 636–642, Fort Lauderdale, FL, USA, 11–13 Apr
2011. PMLR. URL https://proceedings.mlr.press/v15/saha11a.html .
11Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In Shai
Shalev-Shwartz and Ingo Steinwart (eds.), Proceedings of the 26th Annual Conference on Learning
Theory , volume 30 of Proceedings of Machine Learning Research , pp. 3–24, Princeton, NJ, USA,
12–14 Jun 2013. PMLR. URL https://proceedings.mlr.press/v30/Shamir13.
html .
Arun Sai Suggala, Pradeep Ravikumar, and Praneeth Netrapalli. Efficient bandit convex optimization:
Beyond linear losses. In Mikhail Belkin and Samory Kpotufe (eds.), Proceedings of Thirty Fourth
Conference on Learning Theory , volume 134 of Proceedings of Machine Learning Research , pp.
4008–4067. PMLR, 15–19 Aug 2021. URL https://proceedings.mlr.press/v134/
suggala21a.html .
Roman Vershynin. High-dimensional probability: An introduction with applications in data science ,
volume 47. Cambridge university press, 2018.
Yining Wang, Sivaraman Balakrishnan, and Aarti Singh. Optimization of smooth functions with
noisy observations: Local minimax rates. IEEE Transactions on Information Theory , 65(11):
7350–7366, 2019.
Qian Yu, Yining Wang, Baihe Huang, Qi Lei, and Jason D Lee. Sample complexity for
quadratic bandits: Hessian dependent bounds and optimal algorithms. In A. Oh, T. Nau-
mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (eds.), Advances in Neural
Information Processing Systems , volume 36, pp. 35121–35138. Curran Associates, Inc.,
2023a. URL https://proceedings.neurips.cc/paper_files/paper/2023/
file/6e60a9023d2c63f7f0856910129ae753-Paper-Conference.pdf .
Qian Yu, Yining Wang, Baihe Huang, Qi Lei, and Jason D. Lee. Optimal sample complexity bounds
for non-convex optimization under kurdyka-lojasiewicz condition. In Proceedings of The 26th
International Conference on Artificial Intelligence and Statistics , volume 206 of Proceedings
of Machine Learning Research , pp. 6806–6821. PMLR, 25–27 Apr 2023b. URL https://
proceedings.mlr.press/v206/yu23a.html .
Yan Zhang, Yi Zhou, Kaiyi Ji, and Michael M Zavlanos. Boosting one-point derivative-free online
optimization via residual feedback. arXiv preprint arXiv:2010.07378 , 2020.
12A Detailed Comparison on Different Smoothness Conditions
In a relevant line of work, the higher-order smoothness of the objective function in the k= 3case is
characterized by the following generalized Hölder condition.
f(z)−f(x)− ∇f(z)(z−x)−1
2(z−x)⊺ 
∇2f(z)
(z−x)≤L||z−x||3
2.
Note that the ρ-Lipschitz Hessian condition in our work implies an Hölder condition with parameter
L=ρ
6. A direct application of the works in Table 1 requires order-wise larger sample complexities
in our setting on top of the additional k= 2smoothness condition. On the other hand, the L-Holder
condition implies ρ=O(√
dL)-Lipschitz Hessian. Hence, a direct application of our algorithm
order-wise improves the sample complexity in the setting of generalized Hölder condition in a
polynomial factor of das well.
In terms of the characterization of gradient estimators, the prior works of Bach & Perchet (2016);
Akhavan et al. (2020); Novitskii & Gasnikov (2021) used isotropic sampling over a bounded set of
radius rand presented upper bounds on the estimation bias of O(Lr2),O(Ldr2), and O(L√
dr2),
respectively. In this special case, our Theorem 4.1 implies an upper bound of O(ρr2/√
d), and similar
to the above analysis, this bound strengths the bounds in prior works.
B Proof of Theorem 3.2
To illustrate the proof idea, we start with the case of d= 1.
B.1 Illustrating example: 1D case
The gist of our proof is to construct a pair of hard-instance functions that need to sufficiently distant
from each other to avoid trivial optimizers with low simple regret. We also require them to be
sufficiently close to each other so that they are indistinguishable without sufficiently many samples.
These requirements are captured quantitatively in the following result, which is proved using an
analysis of KL divergence. Here we assume their correctness and focus on the construction.
Definition B.1. For any (Borel measurable) function class FHand any distribution pdefined on FH,
we define the uniform sampling error to be
Pϵ≜inf
xPf∼p[f(x)−inff≥ϵ].
We also define the maximum local variance to be
V≜sup
xVarf∼p[f(x)].
Lemma B.2 (Restatement of Proposition 7 in Yu et al. (2023b)) .For any sampling algorithm to
achieve an expected simple regret of ϵ >0over a function class FH, ifP2ϵ/c≥cfor some universal
constant c∈(0,1), and the observation noises are standard Gaussian, then the required sample
complexity to achieve a minimax regret of ϵis at least Ω(1/V).
We construct our hard instances using the following function
g(x) =

1
2 
sin 1
2x
+ 1
ifx∈(−π,3π]
−cosx−1 ifx∈(−3π,−π]
0 otherwise .
Some key properties of g(x)to be used are that its differential g′(x)is1-Lipschitz, and we have
|g′(x)| ≤1for all x. Our hard instances consist of two functions. We define
f1(x) =Mx2+y0Zx/x 0
−πg(z)dz,
f2(x) =Mx2+y0Z−x/x 0
−πg(z)dz,
13where y0,x0are normalization factors given by y0=1
π√
T,x0=
y0
ρ1
3.The normalization factors
are chosen to satisfy the Lipschitz Hessian condition and a maximum local variance bound required
for a KL-divergence based approach presented in Lemma B.2.
Specifically, the choice of x0and the fact that g′(x)is1-Lipschitz imply that both f1andf2satisfy
the Lipschitz Hessian condition. Then because the absolute value of integration of g(x)is bounded
by2π, one can show that the maximum local variance for the function class {f1, f2}is no greater
thanπ2y2
0=1
Tfor the uniform prior distribution, which is to be used to show the sample complexity
lower bound.
We first check that both f1andf2are within our function class of interests. Note that both f′′
1(x)
andf′′
2(x)belong to the intervalh
2M−5
4y0
x2
0,2M−3
4y0
x2
0i
. From the fact that limT→∞y0
x2
0= 0and
M > 0, we have both f′′
1(x)> M andf′′
2(x)> M for all xfor sufficiently large T. So the strong
convexity requirement is satisfied. On the other hand, consider any global minimum point x∗of
either f1orf2. Because of their differentiability, we must have f′
1(x) = 0 orf′
2(x) = 0 . Note that
for all x, we have |g(x)| ≤2, and
f′
1(x) = 2 Mx+gx
x0y0
x0
f′
2(x) = 2 Mx−gx
x0y0
x0.
We must have |x∗| ≤y0
x0/M, where the RHS is o(1)for large T. Combined with strong convexity,
this inequality implies that assumption A3 holds for both functions. To conclude, we have proved
thatf1, f2∈ F(ρ, M, R )for sufficiently large T.
Now we let ϵ=1
128M
y0
x02
andc=1
2to apply Lemma B.2. Note that
lim inf
T→∞T2
3ϵ=ρ2
3
128π4
3M.
The quantity ϵexactly matches the lower bounds we aim to prove. Therefore, it remains to check that
the required condition on uniform sampling errors in Definition B.1 are satisfied.
Formally, we need to show that fk(0)−infxfk(x)≥4ϵfork∈ {1,2}, so that the uniform sampling
errorP4ϵunder uniform distribution over FHis lower bounded by1
2and Lemma B.2 can be applied.
Without loss of generality, we focus on the case of k= 1. Note that f′′
1(x)≤2M+y0
4x2
0for all
x∈[−πx0,0]. Therefore, we have
f1(x)−f1(0)≤f′
1(0)x+1
2x2sup
z∈[−πx0,0]f′′
1(z)
≤y0
2x0x+1
2x2
2M+y0
4x2
0
forx∈[−πx0,0], and limT→∞x0= 0. Consider any sufficiently large Tsuch thaty0
4x2
0≤2M, we
can choose x=−y0
2x01
2M+y0
4x2
0for the above bound, which falls into the interval of [−πx0,0]. Then
we have
inf
xf1(x)≤f1 
−y0
2x01
2M+y0
4x2
0!
≤f1(0)−1
2y0
2x021
2M+y0
4x2
0
≤f1(0)−4ϵ.
We use this inequality to lower bound the minimum sampling error. Note that f1is an increasing
function for x≥0andinfxf1(x) = inf xf2(x). We have f1(x)≥infxf2(x) + 4 ϵforx≥0.
14Following the same arguments, we also have f2(x)≥infxf1(x) + 4 ϵforx≤0. Recall the
definition of uniform sampling error in Definition B.1. We have essentially proved that P4ϵ≥1
2.
According to earlier discussions, this implies that the minimax simple regret is lower bounded by
ϵ= Ω
ρ2
3T−2
3
M
.
B.2 Proof for the General Case
The generalization of the earlier 1D lower bound is obtained by constructing a set of hard-instance
functions where the optimization problem over this subset consists of dbinary hypothesis estimation
problems, each identical to a 1D construction. Formally, for any s= (s1, s2, ..., s d)∈ {1,2}dand
any input x= (x(1), x(2), ..., x (d)), we let
fs(x) =dX
j=1fsj(x(j)).
One can verify that fs∈ F(ρ, M, R )for all sfor sufficiently large T.
Note that the simple regret for the above function class can be written as the sum of dindividual
termsPd
j=1 
fsj(x(j))−infxfsj(x)
. As proved earlier, the expectation of each term associated
with any index jis at least Ω
ρ2
3T−2
3
M
even if all entries of sexcept sjis known. Therefore, the
total expected regret is lower bounded by Ω
dρ2
3T−2
3
M
.
C Proof of Theorem 4.3
We use the following elementary facts, which are versions of well-known properties of subgaussian
and subexponential distributions in Vershynin (2018), but with explicit and possibly improved
constant factors. For completeness, we provide their proofs in Appendix F.
Proposition C.1. For any real-valued zero-mean independent random variables z1, ..., z k, if
P[|zj| ≥K]≤2 exp 
−K2
σ2
j!
∀j∈[k], K∈[0,+∞), (15)
for some σ1, ..., σ k, then
P
kX
j=1zj≥K
≤2 exp 
−K2
4Pk
j=1σ2
j!
∀K∈[0,+∞). (16)
Proposition C.2. For any real-valued independent random variables z1, ..., z k, if
P[|zj| ≥K]≤2 exp
−K
σj
∀j∈[k], K∈[0,+∞), (17)
for some positive σ1, ..., σ k, then
P
kX
j=1zj≥K
≤2 exp 
−K
3Pk
j=1σj!
∀K∈[0,+∞). (18)
Proof of equation (4).We first prove the bound entry-vise. Consider any mk, which contains a
summation of 2nindependent subgaussian variables. By Prop. C.1 we have that
P[|mk−E[mk]| ≥K]≤2 exp
−K2
2/nr2
∀K∈[0,+∞). (19)
15Then, by the Lipschitz Hessian condition, the bias for each entry is bounded as follows.
E[mk]−∂
∂xkf(x)≤1
6ρr2, (20)
where xkdenotes the kth entry of x. Hence, eachmk−∂
∂xkf(x)2
is subexpoential, i.e.,
P"mk−∂
∂xkf(x)2
≥K2#
≤P
|mk−E[mk]| ≥K−E[mk]−∂
∂xkf(x)
≤P
|mk−E[mk]| ≥K−1
6ρr2
≤max(
2 exp 
− 
max{K−1
6ρr2,0}2
2/nr2!
,1)
≤2 exp 
−K2
ρ2r4
4+4
nr2!
. (21)
By the independence of mk’s, we can apply Prop. C.2 to the inequality. Therefore,
P[||ˆm− ∇f(x)||2≥K] =P"dX
k=1|mk−∂
∂xkf(x)|2≥K2#
≤2 exp 
−K2
3dρ2r4
4+12d
nr2!
∀K∈[0,+∞). (22)
Proof of equation (5).We first provide the entry-wise bounds for the intermediate estimator ˆH0.
Each diagonal entry Hkkcontains the weighted average of 3nsubgaussian variables. Conditioned on
any realization of y, which is shared among all diagonal elements, Prop. C.1 can be applied for the
rest of the 2nterms, and provides the following bounds.
P[|Hkk−E[Hkk|y]| ≥K]≤2 exp
−K2
8/nr4
∀K∈[0,+∞). (23)
Then, because the off-diagonal entries are independent, we have the following bounds for any j̸=k.
P[|Hjk−E[Hjk]| ≥K]≤2 exp
−K2
1/nr4
∀K∈[0,+∞). (24)
Hence, similar to the earlier proof steps, Prop. C.2 implies that
Ph
||ˆH0−E[ˆH0|y]||2
F≥K2i
≤2 exp
−K2
6d(d+ 3)/nr4
≤2 exp
−K2
24d2/nr4
. (25)
Now, we take into account the estimation bias and the error of y. By Lipschitz Hessian, it is clear that
Hjk−∂
∂xj∂
∂xkf(x)≤(
1
3ρr ifj=k,√
2
3ρr otherwise.
Hence,
ˆH0− ∇2f(x)
F≤√
2dρr
3. (26)
16Furthermore, note that E[ˆH0]−E[ˆH0|y] = 2( y−f(x))Id/r2, where Iddenotes the identity matrix.
The subgaussian condition and Prop. C.1 imply that
P[||E[ˆH0]−E[ˆH0|y]||F≥K] =P
|y−f(x)| ≥Kr2
2√
d
≤2 exp
−K2
8d/nr4
∀K∈[0,+∞). (27)
We can combine the above bounds using triangle inequality and the union bound. Specifically, from
inequalities (25), (26), and (27), we have the following bound for any K≥√
2dρr
3.
Ph
||ˆH0− ∇2f(x)||F≥Ki
≤P"
||ˆH0−E[ˆH0]||F≥2
3 
K−√
2dρr
3!#
≤P"
||ˆH0−E[ˆH0|y]||F≥1
3 
K−√
2dρr
3!#
+P"
||E[ˆH0]−E[ˆH0|y]||F≥ 
K−√
2dρr
3!#
≤2 exp
−
K−√
2dρr
32
54d2/nr4
+ 2 exp
−
K−√
2dρr
32
72d/nr4
.
Utilize the fact that any probability measure is no greater than 1, the above inequality implies that
Ph
||ˆH0− ∇2f(x)||F≥Ki
≤2 exp
−
maxn
K−√
2dρr
3,0o2
128d2/nr4

≤2 exp 
−K2
2d2ρ2r2+144d2
nr4!
∀K∈[0,+∞).(28)
Finally, the needed bound for ˆHis due to the projection to a convex set where the target ∇2f(x)
belongs. Hence, the distance is not increased w.p.1, i.e., we always have ||ˆH− ∇2f(x)||F≤
||ˆH0− ∇2f(x)||F.
D Proof of Proposition 4.5
Inequality (7)is derived from the following approximations, which are due to the Lipschitz Hessian
condition at xB.
f(x)≤f(xB) +˜f(x)−˜f(xB) +1
6ρ||x−xB||3
2, (29)
f(x∗)≥f(xB) +˜f(x∗)−˜f(xB)−1
6ρ||x∗−xB||3
2. (30)
Noting that ˜f(x∗)≥0, the above inequalities imply that
f(x)−f(x∗)≤˜f(x) +1
6ρ||x−xB||3
2+1
6ρ||x∗−xB||3
2. (31)
By strong convexity, we have ||x∗−xB||2
2≤2(f(xB)−f(x∗))
M. Hence, it remains to provide an upper
bound for1
6ρ||x−xB||3
2.
When||x−xB||2≤√
3||x−˜x||2, we apply the condition ||x−xB||2≤M
ρto obtain that
1
6ρ||x−xB||3
2≤1
2M||x−˜x||2
2≤˜f(x),
17where the last step is due to the strong convexity of ˜f. This implies inequality (7).
For the other case, we have ||x−xB||2≥√
3||x−˜x||2. We replace the variable xin inequality (29)
with˜xto obtain that
f(x∗)≤f(˜x)≤f(xB)−˜f(xB) +1
6ρ||˜x−xB||3
2. (32)
By strong convexity,
˜f(xB)≥1
2M||˜x−xB||2
2, (33)
and by triangle inequality, we have that
||˜x−xB||2≤ ||x−xB||2+||x−˜x||2≤
1 +1√
3M
ρ.
Hence, to summarize,
f(xB)−f(x∗)≥1
3−1
6√
3
M||˜x−xB||2
2,
and the needed result is obtained by applying the above to inequality (31).
Now we prove inequality (8). The proof consists of three steps. For brevity, let H≜∇2f(xB)and
x+=xB−ˆH−1Z−1ˆg. We first prove that
˜f(x)≤˜f(x+) + 1
˜f(xB)≥M3
8ρ2
·˜f(xB). (34)
We shall repetitively use the fact that ||z−˜x||2≤q
2˜f(z)/Mfor any z∈Rd, which is due
to strong convexity. When both ˜f(x+)and˜f(xB)are no greater thanM3
8ρ2, both ||x+−˜x||2
and||xB−˜x||2are no greater thanM
2ρ. By triangle inequality, we have ||x+−xB||2≤M
ρ.
Recall the construction of x, which is identical to x+in this case, inequality (34) clearly holds.
Otherwise, note that xbelongs to the line segment between xBandx+. By convexity, we always
have ˜f(x)≤max{˜f(x+),˜f(xB)}.Recall that in this case, ˜f(xB)≥˜f(x+)can only hold when
˜f(xB)≥M3
8ρ2, we have ˜f(x)≤ 1
˜f(xB)≤M3
8ρ2
˜f(x+)+ 1
˜f(xB)≥M3
8ρ2
max{˜f(x+),˜f(xB)},
which implies inequality (34).
As the second step, we prove that
Eh
˜f(x+)|xBi
≤ 
7d2ρ4
3
M2n1
3
H+26d
ng!
˜f(xB) +3dρ2
3
Mn2
3g. (35)
Note that the estimation error of ˜xcan be decomposed into two terms, i.e.,
x+−˜x=H−1∇f(xB)−ˆH−1Z−1ˆg
= (H−1−ˆH−1)∇f(xB) +ˆH−1Z−1(Z∇f(xB)−ˆg),
where the first term is due to the error of the Hessian estimator, and the second is mostly contributed
by the GradientEst estimator. We apply the AM-QM inequality to their quadratic forms, i.e.,
˜f(x+) =H1
2
(H−1−ˆH−1)∇f(xB) +ˆH−1Z−1(Z∇f(xB)−ˆg)2
2
≤ ||H1
2(H−1−ˆH−1)∇f(xB)||2
2+||H1
2ˆH−1Z−1(Z∇f(xB)−ˆg)||2
2.
=||H1
2(H−1−ˆH−1)∇f(xB)||2
2+λZH
rg2
||H1
2ˆH−1
2||2· ||Z∇f(xB)−ˆg||2
2,
where λZH,rgare defined in Algorithm 4 and || · || denotes the spectrum norm. By theorem 4.1, we
can first take the expectation of the above bound conditioned on any realization of ˆH. Specifically,
Eh
||Z∇f(xB)−ˆg||2
2|ˆH,xBi
≤Z∇f(xB)−Eh
ˆg|ˆH,xBi2
2+Tr
Covh
ˆg|ˆH,xBi
≤ 
r3
gρ√
d
2(d+ 2)!2
+2d
ng||Z∇f(xB)||2
2+d2
18ng 
ρr3
g2+d2
2ng.
18Recall the definition of Z, we have
||Z∇f(xB)||2
2=r2
g
λ2
ZH||ˆH−1
2∇f(xB)||2
2.
Hence, by our choice of rgin Algorithm 4 and note that λZH≤M−1
2is implied by strong convexity,
Eh
˜f(x+)|ˆH,xBi
≤||H1
2(H−1−ˆH−1)∇f(xB)||2
2
+||H1
2ˆH−1
2||2 
3dρ2
3
4Mn2
3g
1 +2d3
27ng
+2d
ng||ˆH−1
2∇f(xB)||2
2!
≤
||H1
2(H−1−ˆH−1)H1
2||2+2d
ng||H1
2ˆH−1
2||4
· ||H−1
2∇f(xB)||2
2
+||H1
2ˆH−1
2||2 
3dρ2
3
4Mn2
3g
1 +2d3
27ng!
.
To characterize the above bound, we first note that the singular values of H1
2ˆH−1
2equals the
eigenvalues of ˆH−1
2HˆH−1
2=Id+ˆH−1
2(H−ˆH)ˆH−1
2. As the eigenvalues of ˆHare no less
thanM, by triangle inequality, all eigenvalues of (Id+ˆH−1
2(H−ˆH)ˆH−1
2)are bounded within
[1−||H−ˆH||F
M,1 +||H−ˆH||F
M]. Hence, we have
||H1
2ˆH−1
2||2≤1 +||H−ˆH||F
M.
Similarly, bounds on the singular values of H1
2ˆH−1
2imply bounds on the eigenvalues of H1
2ˆH−1H1
2,
i.e.,
||H1
2(H−1−ˆH−1)H1
2|| ≤||H−ˆH||F
M.
Therefore, we have
Eh
˜f(x+)|ˆH,xBi
≤
 
||H−ˆH||F
M!2
+2d
ng 
1 +||H−ˆH||F
M!2
· ||H−1
2∇f(xB)||2
2
+ 
1 +||H−ˆH||F
M!
· 
3dρ2
3
4Mn2
3g
1 +2d3
27ng!
.
Now that the above bound is simply a polynomial of ||H−ˆH||F. We can use Theorem 4.3 to
obtain PhˆH−H
F≥Ki
≤2 exp
−K2
16d2ρ4
3/n1
3
H
then apply a direct integration. We utilize the
assumptions in the statement of proposition to obtain a simpler estimate, expressed as follows.
Eh
˜f(x+)|xBi
≤ 
7d2ρ4
3
M2n1
3
H+26d
ng!
· ||H−1
2∇f(xB)||2
2+3dρ2
3
Mn2
3g.
Then, inequality (8) is implied by the definition of ˜f.
For the third step, we observe that the earlier proof steps imply that
Eh
˜f(x)|xBi
≤ 
7d2ρ4
3
M2n1
3
H+26d
ng+ 1
˜f(xB)≥M3
8ρ2!
·˜f(xB) +3dρ2
3
Mn2
3g, (36)
and it remains characterize ˜f(xB). To that end, we reuse inequality (32) and(33), which implies that
˜f(xB)≤2(f(xB)−f(x∗))when||˜x−xB||2≤3M
2ρ. For the other case, we have ||˜x−xB||2≥3M
2ρ.
We instead let xr≜xB+q
3M
2ρ||˜x−xB||2(˜x−xB)and the Lipschitz Hessian condition implies that
f(x∗)≤f(˜xr)≤f(xB)−˜f(xB) +˜f(xr) +1
6ρ||˜x−xr||3
2.
19By convexity, we have ˜f(xB)−˜f(xr)≥q
3M
2ρ||˜x−xB||2˜f(xB), which can be applied to the above
bound. Then, together with inequality (33) and the condition of ||˜x−xB||2, we have
f(xB)−f(x∗)≥s
3M
2ρ||˜x−xB||2
˜f(xB)−M
4||˜x−xB||2
2
(37)
≥1
23M
2ρ||˜x−xB||22
3˜f(xB)
≥32
3M
4ρ2
3˜f(xB)2
3.
To summarize, the following inequality holds in both cases.
˜f(xB)≤max
2(f(xB)−f(x∗)),8ρ
3M3
2(f(xB)−f(x∗))3
2
. (38)
To apply inequality (36), we use the following implications.
˜f(xB)≤2(f(xB)−f(x∗)) +8ρ
3M3
2(f(xB)−f(x∗))3
2,
1
˜f(xB)≥M3
8ρ2
˜f(xB)≤8ρ
M3
2(f(xB)−f(x∗))3
2.
Then, the derived inequality can be simplified using our assumptions on ngandnH.
E Remaining details for Theorem 3.1
To complete the proof, we essentially need to prove Theorem 4.4. To illustrate the main ideas, we
start with an analysis in a simplified setting where estimation errors for the BootstrapingEst and
HessianEst functions are zero. Then, we show how the proof steps can be modified to have the errors
and uncertainties incorporated.
E.1 Analysis for the zero-error case
We prove that when the estimation errors are set to zero, the first stage of Algorithm 4 reduces ∇f(zt)
to a vector of bounded length in boundedly many iterations. This is summarized in the following
proposition.
Proposition E.1. For any fixed parameter values ρ, M ,R, let{zt}t∈N+be sequences defined for
anyf∈ F(ρ, M ,R), such that z1=0and(zt+1−zt)equals −˜H−1
t∇f(zt), where ˜Htis a
matrix that has the same eigenvectors of ∇2f(zt), with each eigenvalue λreplaced by max{λ, m t},
andmtbeing the smallest value for ||˜H−1
t∇f(zt)||2≤M
ρ. There exists an explicit function
T(ρ, M, R )≤5R2ρ2/M2+ 1such that ∇f(zt)≤M2
2ρholds for any fand any t≥T(ρ, M, R ).
Proof. For convenience, let ˜rt≜−(∇2f(zt))−1∇f(zt)andrt≜−˜H−1
t∇f(zt). To investigate
the evolution of gradients, we integrate the Lipschitz Hessian condition and obtain that
||∇f(zt+1)− ∇f(zt)− ∇2f(zt)rt||2≤1
2ρ||rt||2
2. (39)
From the definition of rt, if||˜rt||2≤M/ρ , we have
||∇f(zt+1)||2≤1
2ρ||˜rt||2
2≤M2
2ρ. (40)
Note that by strong convexity, when the above bound holds,
||˜rt+1||2≤||∇f(zt+1)||2
M≤M
2ρ≤M
ρ. (41)
20Hence, once ||˜rt||2reaches below M/ρ for some t0, our desired bound on ||∇f(zt+1)||2remain
hold for any t > t 0. Therefore, for the purpose of our proof, we can focus on the case where
||˜rt||2> M/ρ and show that this condition can only hold for boundedly many iterations.
Consider any fixed function f∈ F(ρ, M, R ), letx∗denote its global minimum point. A crucial step
in our proof is to show that
(x∗−zt)·rt≥0.6||rt||2
2. (42)
For brevity, let βdenote the minimum eigenvalue of ˜Ht, and ˜fdenote the following quadratic
approximation.
˜f(x)≜f(zt) + (x−zt)∇f(zt) +1
2(x−zt)(∇2f(zt))(x−zt).
We apply the strong convexity condition at point y≜zt+1−0.4β˜H−1
trt. Recall that fis minimized
atx∗, we have
0≥f(x∗)−f(y)≥∇f(y)·(x∗−y) +M
2||x∗−y||2
2. (43)
By integrating the Lipschitz Hessian, similar to inequality (39),∇f(y)can be approximated with
∇f(zt) +∇2f(zt)(y−zt) =∇˜f(y). Formally,
||∇f(y)− ∇˜f(y)||2≤1
2ρ||y−zt||2
2. (44)
Hence, inequality (43) implies that
0≥∇˜f(y)·(x∗−y) +M
2||x∗−y||2
2−1
2ρ||y−zt||2
2||x∗−y||2. (45)
To characterize the terms in the above inequality, we first note that
||y−zt||2
2=||rt||2
2−0.8rt·˜H−1
tβrt+ 0.16||˜H−1
tβrt||2
2
≤ ||rt||2
2−0.64||˜H−1
tβrt||2
2.
For convenience, we denote c≜||˜H−1
tβrt||2/||rt||2. We have that c∈(0,1]and
||y−zt||2
2≤ 
1−0.64c2
||rt||2
2. (46)
We also consider the following vector,
q≜(∇2f(zt))−1
∇˜f(y) + (β+ 0.36cM)rt−0.6cM(y−zt)
= 0.6˜H−1
t
βrt+ 0.4cM
˜H−1
tβrt−rt
,
of which the L2 norm is no greater than 0.6c||rt||2≤0.6cM/ρ , which can be proved in the eigenbasis
of∇2f(zt). By Cauchy’s inequality, we have that
q· ∇˜f(x∗)≥ −||q||2||∇˜f(x∗)||2
≥ −0.6cM
ρ||∇˜f(x∗)||2. (47)
Note that x∗−y= (∇2f(zt))−1
∇˜f(x∗)− ∇˜f(y)
. The LHS of the above inequality can be
written as (x∗−y)·(∇2f(zt))·q+q· ∇˜f(y), where the first term contains ∇˜f(y)·(x∗−y),
and the second term is bounded as follows.
q· ∇˜f(y) =−0.6˜H−1
t
˜H−1
tβ2rt+ (β−0.4cM)(rt−˜H−1
tβrt)
·
0.4βrt+ 0.6
˜Ht− ∇2f(zt)
rt
≤ − 0.6˜H−1
t·˜H−1
tβ2rt·0.4βrt
=−0.24c2β||rt||2
2. (48)
21On the other hand, observe that inequality (44) holds for any generic y∈Rd. The RHS of inequality
(47) can be characterized as follows.
||∇˜f(x∗)||2=||∇f(x∗)− ∇˜f(x∗)||2
≤1
2ρ||x∗−zt||2
2
=1
2ρ||x∗−y||2
2+ρ(x∗−y)·(y−zt) +1
2ρ||y−zt||2
2. (49)
Therefore, by combining inequalities (45), (47), and (49), we have that
(x∗−y)·(β+ 0.36cM)rt≥ −q· ∇˜f(y) + (0 .5−0.3c)M||x∗−y||2
2
−0.5ρ||y−zt||2
2· ||x∗−y||2−0.3cM||y−zt||2
2
≥ −q· ∇˜f(y)−ρ2||y−zt||4
2
(8−2.4c)M−0.3cM||y−zt||2
2,
where the second line is obtained by taking the infimum w.r.t. ||x∗−y||2. Then, we apply inequalities
(46), (48), and ||rt||2≤M/ρ to obtain the following bound.
(x∗−y)·rt≥0.24c2β−M(1−0.64c2)2
(8−2.4c)−0.3cM 
1−0.64c2
β+ 0.36cM· ||rt||2
2.
Note that the above bound is non-decreasing w.r.t. β, and our construction implies β≥M. We can
substitute βin the above inequality with M. Further, note that
(y−zt)·rt=||rt||2
2−rt·0.4β˜H−1
trt
≥(1−0.4c)||rt||2.
We have obtained a lower bound of (x∗−zt)·rtas a function of c. This dependency is removed by
taking the infimum, i.e.,
(x∗−zt)·rt≥inf
c∈(0,1]
0.24c2−(1−0.64c2)2
(8−2.4c)−0.3c 
1−0.64c2
1 + 0 .36c+ 1−0.4c
· ||rt||2,
then inequality (42) is obtained.
We use this key inequality to obtain the following recursion rule.
||x∗−zt||2
2− ||x∗−zt+1||2
2= 2rt·(x∗−zt)− ||rt||2
2≥0.2||rt||2
2.
Recall that for f∈ F(ρ, M, R ), we assumed that ||x∗||2≤R. Therefore, for z1=0, the above
recursion implies that the inequality ||˜rt||2> M/ρ can hold for no greater than 5R2ρ2/M2iterations
as||x∗−zt||2
2has to be non-negative for any t. Hence, based on the earlier discussion, we have
proved that either ||˜rt||2≤M/ρ or∇f(zt+1) =0for all t≥5R2ρ2/M2and all f∈ F(ρ, M, R ).
Recall inequality (40), this implies that ||∇f(zt)||2≤M2
2ρfor all t≥5R2ρ2/M2+ 1.
Remark E.2. Recall the recursion provided by inequality (40) and (41). The gradients for the
sequence ztdecay double-exponentially once they are sufficiently close to zero. Hence, Proposition
E.1 proves that it takes finitely many iterations for the bootstrapping stage of Algorithm 4 to get
arbitrarily close to x∗in the zero-error case.
E.2 Generalization to the noisy case
Now we prove that, given a bounded number of iterations, the bootstrapping stage in Algorithm 4
provides an xBthat is sufficiently close to x∗with high probability even in the presence of noise.
Similar to the zero-error case, we provide the following guarantee.
Theorem E.3. For any fixed ρ, M andR, the result returned by the first stage of Algorithm 4 satisfies
lim
T→∞sup
f∈F(ρ,M,R )E∇f(x(B)
N)3
2·T2
3
= 0. (50)
22For convenience, let x(B)
kdenote the realization of vector xat the end of the kth iteration in the
bootstrapping stage and N≜⌊T0.1⌋denote the number of iterations. Therefore, we have xB=x(B)
N.
Further, we define x(B)
0≜0. We let mk, Hkdenote the realization of ˆm, Hm∗in the (k+ 1) th
iteration of the bootstrapping stage. Therefore, we have x(B)
k+1=x(B)
k−H−1
kmk. As a Benchmark
for our analysis, we use ˜Hkto denote the value of Hm∗in the zero-error case, i.e., they denotes the
value of Hm∗under the special case of ˆm=∇f
x(B)
k
andˆH=∇2f
x(B)
k
. Hence, the update
in the zero-error case can be denoted as rk≜−˜H−1
k∇f
x(B)
k
.
We let Ekbe the indicator function of the event where there exists an j < k such thatx(B)
j+1−
x(B)
j−rj
2≥MT−0.2/ρ. Intuitively, Ek= 0describes the event that the optimization steps can
be characterized similar to the zero-error case. Notice that Ekis non-decreasing. We have either
EN= 0, orEk0= 1for some k0∈ {1,2, ..., N}. We provide the analysis of Theorem E.3 separately
for each of these two cases.
For the first case, i.e., when EN= 0, we can follow the earlier arguments and prove the following
proposition (see Appendix F.3 for details).
Proposition E.4. For any function f∈ F(ρ, M, R )and any sequence x(B)
0,x(B)
1, ...,x(B)
N−1∈Rd
that satisfies x(B)
0=0andEN−1= 0, we have ||rN−1||2≤2MT−0.2/ρwhen Tis sufficiently
large.
Recall the definition of EN= 0. The above proposition immediately implies that
x(B)
N−x(B)
N−1
2≤3MT−0.2/ρ < M/ρ
when Tis large. Hence, in such cases, x(B)
Nis obtained by the Newton update. Formally, if ˆHdenotes
the estimator returned by the HessianEst function in the Nth iteration, we have
(x(B)
N−x(B)
N−1)·ˆH=−mN−1, (51)
Therefore, by applying the above results to the Lipschitz Hessian condition, we have
∇f(x(B)
N)
2≤∇f(x(B)
N−1) + (x(B)
N−x(B)
N−1)· ∇2f(x(B)
N−1)
2+ρ
2||x(B)
N−x(B)
N−1||2
2
≤∇f(x(B)
N−1)−mN−1+ (x(B)
N−x(B)
N−1)·
∇2f(x(B)
N−1)−ˆH
F+9M2
2ρT0.4
≤∇f(x(B)
N−1)−mN−1
2+3M
ρT0.2·∇2f(x(B)
N−1)−ˆH
F+9M2
2ρT0.4. (52)
Hence, by direct integration of the tail bounds in Theorem 4.3, we can conclude that
lim sup
T→∞sup
f∈F(ρ,M,R )E∇f(x(B)
N)3
2· 1(EN= 0)·T2
3
= 0. (53)
Now we consider the second case, i.e., when EN= 1. By its definition, we must have the event of
Ek= 0toEk+1= 1for a unique k∈ {0,1, ..., N −1}, which implies thatx(B)
k+1−x(B)
k−rk
2≥
MT−0.2/ρ. We prove that conditioned on any of these events, the random variable ||∇f(x(B)
k+1)||2
has a super-polynomial tail, which contributes vanishingly to their moments in the asymptotic sense.
Formally, let
Mk≜Eh
||∇f(x(B)
k+1)||3
2· 1(Ek+1= 1, Ek= 0)i
,
We aim to prove that
lim sup
T→∞max
k∈{0,1,...,N−1}sup
f∈F(ρ,M,R )Mk·NT2
3= 0. (54)
Consider any fixed k∈ {0,1, ..., N −1}and conditioned on any realization of x(B)
k, we characterize
the distribution of x(B)
k+1by providing the following proposition, which is proved in Appendix F.4.
23Proposition E.5. Consider any vectors m,m′∈Rn, any positive definite matrices H, H′∈Rnwith
all eigenvalues lower bounded by M, and any fixed parameter R0∈N+. LetHm∗be the symmetric
matrix sharing the same eigenbasis of Hbut with each eigenvalue λreplaced with max{λ, m∗},
where m∗is chosen to be the smallest value such that ||H−1
m∗m||2≤R0. Let H′
m′∗be defined
correspondingly for m′andH′. We have that
H−1
m∗m−H′−1
m′∗m′2
2≤2R0
M·(||m−m′||2+R0· ||H−H′||F). (55)
Furthermore, whenH−1
m∗m−H′−1
m′∗m′
2>0, we have
H′
m′∗ 
H−1
m∗m−H′−1
m′∗m′
2
≤
3 +2R0
||H−1
m∗m−H′−1
m′∗m′||2
(||m−m′||2+R0||H−H′||F).(56)
By choosing R0=M/ρ ,Hm∗=HN−1,H′
m′∗=∇2f(x(B)
N−1),m=mN−1, andm′=
∇f(x(B)
N−1)for Proposition E.5, the condition of Ek+1can be characterized by the estimation
errors of the gradient and Hessian. For brevity, we define
Ψ≜||m−m′||2+R0||H−H′||F.
We also let βdenote the minimum eigenvalue of Hk. The condition of Ek+1= 1andEk= 0implies
that||H−1
m∗m−H′−1
m′∗m′||2≥R0T−0.2, which implies that Ψ≥βR0T−0.2
3+2T0.2according to inequality
(56). Hence, Mkcan be bounded as follows.
Mk≤E
||∇f(x(B)
k+1)||3
2· 1
Ψ≥βR0T−0.2
3 + 2 T0.2
,
On the other hand, by generalizing inequality (52), we have
∇f(x(B)
k+1)
2≤∇f(x(B)
k) + (x(B)
k+1−x(B)
k)· ∇2f(x(B)
k)
2+ρ
2||x(B)
k+1−x(B)
k||2
2
≤∇f(x(B)
k)−mk
2+x(B)
k+1−x(B)
k
2·∇2f(x(B)
k)−ˆH
F
+
x(B)
k+1−x(B)
k
ˆH−Hk
2+ρ
2||x(B)
k+1−x(B)
k||2
2
≤Ψ +R0β+R0M
2. (57)
Therefore,
lim sup
T→∞sup
f∈F(ρ,M,R )Mk·NT2
3
≤lim sup
T→∞E"
Ψ +R0β+R0M
23
· 1
Ψ≥βR0T−0.2
3 + 2 T0.2
·NT2
3#
= 0. (58)
Since the above bounds are uniform over the index k, equation (54) is implied. The above arguments
also show that
lim sup
T→∞sup
f∈F(ρ,M,R )P[EN= 1]·N3T2
3
≤lim sup
T→∞sup
f∈F(ρ,M,R )N·max
kP[Ek+1= 1, Ek= 0]·N3T2
3= 0. (59)
So far, we have proved that the moments of the gradient norm∇f(x(B)
k)
2is bounded after entering
theEk= 1 phase. We proceed to bound their contribution to the Nth iteration. To that end, we
denote
Gk≜Eh
||∇f(x(B)
k)||3
2· 1(Ek= 1)i
.
24This sequence is initialized with G0= 0 by definition. We establish the following recursion for
sufficiently large T.
Gk+1≤Gk
1 +1
N
+ 6N2(ρR2
0)3·P[EN= 1] + Mk.
We note that conditioned on any fixed x(B)
kthe gradient norm function ||∇f(x(B)
k+1)||2can be
approximated with its linear expansion. Formally, let ˜g(x)≜∇f(x(B)
k) + (x−x(B)
k)· ∇2f(x(B)
k),
we have
∇f(x(B)
k+1)
2≤˜g(x(B)
k+1)
2+1
2ρx(B)
k+1−x(B)
k2
2
≤˜g(x(B)
k+1)
2+1
2ρR2
0.
Then, in the eigenbasis of ˆH, it is clear that
˜g(x(B)
k+1)
2≤∇f(x(B)
k) + (x(B)
k+1−x(B)
k)·ˆH
2
+(x(B)
k+1−x(B)
k)·
ˆH− ∇2f(x(B)
k)
2
≤∇f(x(B)
k)
2+mk− ∇f(x(B)
k)
2+R0ˆH− ∇2f(x(B)
k)
F.
Recall that by Theorem 4.3, when Tis sufficiently large, the moments ofmk− ∇f(x(B)
k)
2+
R0ˆH− ∇2f(x(B)
k)
Fis upper bounded by any fixed quantity. Therefore, as a rough estimate, we
have
Eh
||∇f(x(B)
k+1)||3
2· 1(Ek= 1)i
≤Eh
||∇f(x(B)
k) +ρR2
0||3
2· 1(Ek= 1)i
≤Gk
1 +1
N
+ 6N2(ρR2
0)3·P[Ek= 1]
when Tis sufficiently large. Consequently, our needed recursion is implied by the monotonicity of
Ek, and we have
lim sup
T→∞sup
f∈F(ρ,M,R )GN·T2
3
≤lim sup
T→∞sup
f∈F(ρ,M,R )
max
kMk+ 6N2(ρR2
0)3·P[Ek= 1]
·N
1 +1
NN
T2
3
= 0. (60)
Finally, Theorem E.3 is proved by noting that
E∇f(x(B)
N)3
2
=E∇f(x(B)
N)3
2· 1(EN= 0)·T2
3
+GN. (61)
Hence, equation (50) is implied by equation (53) and inequality (60).
E.3 Proof of Theorem 4.4
Proof. Given Theorem E.3, our needed inequality (6)is implied by the strong convexity assumption.
Particularly, the implication is due to the fact that||∇f(x)||2
2
2M≥f(x)−f∗for any x∈Rd.
Remark E.6. Note that compared to the simple regret guarantee stated in inequality (6), we have
essentially proved a stronger statement that the moments of the gradient at the outcome of the
bootstrapping stage follow similar power decay laws. Therefore, while we presented a final stage
algorithm that uses non-isotropic sampling to be compatible with general bootstrapping stages, our
specific bootstrapping stage actually allows for the use of isotropic (hyperspherical) sampling for
gradient estimation in the final stage.
25F Proofs of some useful propositions
F.1 Proof of Proposition C.1
Proof. Recall that all zj’s have zero expectations. By subgaussianity, we have that all even moments
ofzjare bounded as follows.
E
z2ℓ
j
=Z+∞
K=02ℓK2ℓ−1P[|zj| ≥K]dK
≤Z+∞
K=02ℓK2ℓ−1min(
2 exp 
−K2
σ2
j!
,1)
dK
≤

(1 + ln 2) σ2
j ifℓ= 1,
(2 + 2 ln 2 + ln22)σ4
j ifℓ= 2,
2·ℓ!σ2ℓ
j ifℓ >2.(62)
Using AM-GM inequality, the odd moments of zjcan then be bounded using the even moments.
Specifically,
E
z2ℓ+1
j
≤1
2sE
z2ℓ
j
+s
2E
z2ℓ+2
j
.
Therefore, we have obtained the following upper bounds for the moment-generating function.
E[exp( szj)] = 1 +∞X
m=2sm
m!E
zm
j
≤1 +7s2
12E
z2
j
+∞X
ℓ=2
2ℓ+ 2 +1
2ℓ+ 1s2ℓ
(2ℓ)!·2E
z2ℓ
j
.
Applying inequality (62), the expression above can be bounded with a series of (sσj)2. The coefficient
of each (sσj)2ℓis no greater than1
ℓ!, which can be verified numerically for ℓ≤2and inductively for
ℓ≥3. Hence, we have
E[exp( szj)]≤∞X
ℓ=0(sσj)2ℓ
ℓ!=e(sσj)2. (63)
Because zj’s are independent,
E
exp
sX
jzj

=Y
jE[exp( szj)]≤exp
s2X
jσ2
j
.
Inequality (16) is implied by Markov’s bound. Specifically, for any K≥0,
P
kX
j=1zj≥K
≤inf
s≥0E
exp
sX
jzj

·exp (−sK)
≤inf
s≥0exp
s2X
jσ2
j−sK

= exp 
−K2
4P
jσ2
j!
.
For the same reason, we also have
P
kX
j=1zj≤ −K
≤exp 
−K2
4P
jσ2
j!
.
26Hence, by union bound,
P
kX
j=1zj≥K
≤P
kX
j=1zj≥K
+P
kX
j=1zj≤ −K
≤2 exp 
−K2
4P
jσ2
j!
. (64)
F.2 Proof of Proposition C.2
Proof. By subexponentiality, the moment-generating function of each |zj|is bounded as follows for
anys <1
σj.
E[exp( s|zj|)] = 1 +Z+∞
K=0sexp(sK)·P[|zj| ≥K]dK
≤1 +Z+∞
K=0sexp(sK)·min
2 exp
−K
σj
,1
dK
=2sσj
1−sσj. (65)
Because zj’s are independent,
E
exp
sX
jzj

≤E
exp
sX
j|zj|

=Y
jE[exp( s|zj|)]
≤2sP
jσj
Q
j(1−sσj). (66)
We choose s= 1/(3P
jσj), note that sσj≤1/3, we have (1−sσj)≥ 2
33sσj. Hence,
E
exp
sX
jzj

≤e(ln 2−3 ln2
3)(sP
jσj)= 3/22
3<2.
Then, inequality (18) is implied by Markov’s bound, i.e.,
P
kX
j=1zj≥K
≤E
exp
sX
jzj

·exp (−sK)
≤2 exp 
−K
3P
jσj!
.
F.3 Proof of Proposition E.4
To prove the proposition for sufficiently large T, we focus on the regime where N≥10R2ρ2/M2+2.
We first use proof by contradiction to show the existence of k0≤10R2ρ2/M2such that ||rk0||2<
M/ρ . Assume the contrary, we have ||rk||2≥M/ρ for all k≤10R2ρ2/M2. Recall we have proved
earlier that (see inequality (42))
x∗−x(B)
k
·rk≥0.6||rk||2
2. (67)
This assumption implies that R≥0.6M/ρ andx∗−x(B)
k
2≥0.6M/ρ for all k≤10R2ρ2/M2.
We characterize the evolution of x(B)
k. By Cauchy’s inequality and inequality (67),

x∗−x(B)
k
·
x(B)
k+1−x(B)
k
≥
x∗−x(B)
k
·rk−M
ρT0.2x∗−x(B)
k
2
≥0.6||rk||2
2−M
ρT0.2x∗−x(B)
k
2.
27Note that our assumed lower bound on Nimplies a lower bound on T. Numerically, one can prove
thatT0.2≥20ρR/M . Hence, the above inequality implies that

x∗−x(B)
k
·
x(B)
k+1−x(B)
k
≥0.6||rk||2
2−0.05M2
ρ2Rx∗−x(B)
k
2.
Then, by following the proof steps in Proposition E.1, we have that
x∗−x(B)
k+12
2−x∗−x(B)
k2
2=−2
x∗−x(B)
k
·
x(B)
k+1−x(B)
k
+x(B)
k+1−x(B)
k2
2
≤ −1.2||rk||2
2+0.1M2
ρ2Rx∗−x(B)
k
2+M
ρ2
, (68)
where the second step is due to the construction of x(B)
k+1in Algorithm 4. Recall thatx∗−x(B)
0
2≤
R. The above inequality implies that if ||rk||2≥M/ρ for all k≤10R2ρ2/M2, thenx∗−x(B)
k
2
is non-increasing and reaches below 0atk=⌊10R2ρ2/M2⌋+ 1. However, this contradicts the
fact that ||rk||2is non-negative, and we must conclude the existence of k0≤10R2ρ2/M2such that
||rk0||2< M/ρ .
Now consider any index kwith||rk||2< M/ρ . By the construction of rk, we have that ∇f(xk) =
−rk· ∇2f(xk). Then, by the Lipschitz Hessian condition,
∇f(xk+1)−(xk+1−xk−rk)· ∇2f(xk)
2
=||∇f(xk+1)− ∇f(xk)−(xk+1−xk)· ∇2f(xk)||2
≤ρ
2||xk+1−xk||2
2. (69)
Using the strong convexity assumption and triangle inequality, the above bound implies that
(∇2f(xk+1))−1∇f(xk+1)
2
≤(xk+1−xk−rk)· ∇2f(xk)·(∇2f(xk+1))−1
2+ρ
2M||xk+1−xk||2
2.
Note that the first term in the bound above is upper bounded by the product of ||xk+1−xk−rk||2
and the spectral norm of ∇2f(xk)·(∇2f(xk+1))−1. By the Lipschitz Hessian condition and strong
convexity, this spectrum norm is further bounded by 1 +ρ
M||xk+1−xk||2. Therefore,
(∇2f(xk+1))−1∇f(xk+1)
2
≤ ||xk+1−xk−rk||2·
1 +ρ
M||xk+1−xk||2
+ρ
2M||xk+1−xk||2
2. (70)
We use inequality (70) to bound ||rk||2recursively. Assume Tis sufficiently large such that T0.2≥20.
As a rough estimate, we have
(∇2f(xk+1))−1∇f(xk+1)
2≤M
20ρ·2 +M
2ρ≤0.6M
ρ.
Recall we can find k0≤10R2ρ2/M2such that ||rk0||2< M/ρ . By induction, we have ||rk||2≤
0.6M/ρ for all k > k 0. Hence, when k > k 0, inequality (70) implies the following relation, where
the RHS is obtained by triangle inequality and the definition of EN−1= 0.
||rk+1||2≤M
ρT0.2·
1 +ρ
M||rk||2+1
T0.2
+ρ
2M
||rk||2+M
ρT0.22
.
Therefore, by induction, we have
||rk||2≤M
ρmax0.6
22k−k0−2,2
T0.2
for any k > k 0+ 1, and numerically, ||rN−1||2≤2MT−0.2/ρifT0.1≥2k0+ 6.
28F.4 Proof of Proposition E.5
Proof of inequality (55).We prove the inequality by considering two possible cases. In the first case,
we assume that the ℓ2norms of both H−1mandH′−1m′are no greater than R0. In this case, we
haveHm∗=HandH′
m′∗=H′. Hence,
H−1
m∗m−H′−1
m′∗m′=H−1m−H′−1m′
=H−1 
(m−m′) + (H′−H)H′−1m′
. (71)
By the fact that all eigenvalues of Hare lower bounded by Mand the triangle inequality,
H−1
m∗m−H′−1
m′∗m′
2≤M−1 
||m−m′||2+||H′−H||F||H′−1m′||2
≤M−1(||m−m′||2+||H′−H||F·R0). (72)
Then, the needed inequality is obtained byH−1
m∗m−H′−1
m′∗m′
2≤2R0, which follows from the
construction of Hm∗,H′
m′∗and triangle inequality.
For the other case, we have max
||H−1m||2,||H′−1m′||2	
> R 0. Without loss of generality, we
assume that m∗≥m′∗. To be rigorous, here we adopted the convention that m∗=−∞ if the ℓ2
norms of H−1mis no greater than R0, and the same for m′∗accordingly. Based on this assumption,
the condition in this case can be simplified as ||H−1m||2> R 0, and we have that ||H−1
m∗m||2=R0.
Furthermore, we also have m∗> M .
To prove the needed inequality, we introduce an intermediate variable H′
m∗, which is defined as the
symmetric matrix sharing the eigenbasis of H′, but with each eigenvalue λreplaced with max{λ, m∗}.
Note that Hm∗andH′
m∗are obtained by projecting HandH′to a convex set of matrices under the
Frobenius norm. We have that
||H′
m∗−Hm∗||F≤ ||H′−H||F. (73)
Therefore, by following the same steps in the first case and noting that all eigenvalues of H′
m∗are
lower bounded by m∗, we have that
H−1
m∗m−H′−1
m∗m′
2≤m∗−1(||m−m′||2+||H′−H||F·R0).
Compare the above to inequality (55), it remains to prove that
H−1
m∗m−H′−1
m′∗m′2
2≤2R0m∗
M·H−1
m∗m−H′−1
m∗m′
2. (74)
For brevity, we denote that
a≜H−1
m∗m,
b≜H′−1
m∗m′,
c≜H′−1
m′∗m′,
α≜M/m∗.
In the eigenbasis of H′, it is clear that
||b−αc||2≤(1−α)||c||2.
Hence, by Cauchy’s inequality,
a·(b−αc)≤ ||a||2· ||b−αc||2≤(1−α)||a||2· ||c||2. (75)
Recall that ||c||2≤R0and in this case we have ||a||2=R0. Therefore, the RHS of the above
inequality is upper bounded by (1−α)||a||2
2, and we have
a·(a−c)≤1
αa·(a−b)≤1
αR0||a−b||2,
where the first step above is equivalent to inequality (75), and the second step is due to Cauchy’s
inequality. Finally, it remains to notice that the LHS of inequality (74) equals ||a−c||2
2, which
is upper bounded by the LHS of the above inequality, and its RHS equals the RHS of the above
inequality. Hence, inequality (74) is proved.
29Proof of inequality (56).Firstly, if m∗=m′∗, we follow similar arguments from equation (71) to
inequality (72). I.e., in this case, we have
H′
m′∗ 
H−1
m∗m−H′−1
m′∗m′
= (m−m′) + (H′
m′∗−Hm∗)H−1
m∗m. (76)
Hence, by triangle inequality and inequality (73),
H′
m′∗ 
H−1
m∗m−H′−1
m′∗m′
2≤ ||m−m′||2+||H′
m′∗−Hm∗||FH−1
m∗m
2
≤ ||m−m′||2+||H′−H||F·R0. (77)
Then, for m∗> m′∗, we define H′
m∗anda,b,cas in the earlier proof steps. We first prove the
following key inequality.
||a−c||2· ||b−c||2≤2||a−b||2· ||a||2. (78)
Recall the assumption in this case implies that ||a||2=R0. By taking the squares on both sides, the
inequality above is equivalent to the following linear inequality of vector a.
a· 
8R2
0b−2||b−c||2
2c
≤4R2
0· 
R2
0+||b||2
2
− ||b−c||2
2· 
R2
0+||c||2
2
. (79)
By Cauchy’s inequality, the LHS of inequality (79) is upper bounded by ||a||2·||8R2
0b−2||b−c||2
2c||2.
The coefficient of ||a||2in this expression can be further characterized as follows.
8R2
0b−2||b−c||2
2c2
2=4· 
4R2
0− ||b−c||2
2 
4R2
0||b||2
2− ||b−c||2
2||c||2
2
+ 16R2
0· ||b−c||4
2
=1
R2
0 
4R2
0· 
R2
0+||b||2
2
− ||b−c||2
2· 
R2
0+||c||2
22
−1
R2
0 
4R2
0· 
R2
0− ||b||2
2
− ||b−c||2
2· 
R2
0− ||c||2
22
+ 16R2
0· ||b−c||4
2. (80)
We prove that the contribution from the second term and the third term in the above expression is
non-positive. To that end, note that the definition of H′
m∗,H′
m′∗and the assumption of m∗> m′∗
imply that (c−b)·b≥0. We have the following inequalities.
||b−c||2
2+||b||2
2≤ ||c||2
2≤R2
0. (81)
Therefore, 0≤4R2
0· 
R2
0− ||b||2
2
− ||b−c||2
2· 
R2
0− ||c||2
2
≤4R2
0· ||b−c||2
2, and equation (80)
implies that
a· 
8R2
0b−2||b−c||2
2c
≤4R2
0· 
R2
0+||b||2
2
− ||b−c||2
2· 
R2
0+||c||2
2.
By utilizing the above bound, inequality (79) is proved by noting that its RHS is non-negative, which
can be proved using inequality (81). As mentioned earlier, this implies inequality (78).
To proceed further, we note that b−clies in the eigenspace of H′
m∗associated with eigenvalue m∗.
Hence,
H′
m∗(a−c) =H′
m∗(a−b) +m∗(b−c).
Therefore, by triangle inequality, we have
H′
m∗ 
H−1
m∗m−H′−1
m′∗m′
2≤||H′
m∗(a−b)||2+m∗||b−c||2. (82)
Note that by inequality (78) and the fact that all eigenvalues of H′
m∗are lower bounded by m∗, we
have
m∗||b−c||2≤2R0
||a−c||2||H′
m∗(a−b)||2.
Therefore, it remains to upper bound the ℓ2norm of H′
m∗(a−b).
By the definition of vectors a,b,
H′
m∗(a−b) = (m−m′) + (H′
m∗−Hm∗)a. (83)
30The triangle inequality implies that
||H′
m∗(a−b)||2≤ ||m−m′||2+R0||H′
m∗−Hm∗||F. (84)
Hence,
H′
m∗ 
H−1
m∗m−H′−1
m′∗m′
2≤
1 +2R0
||a−c||2
·(||m−m′||2+R0||H′
m∗−Hm∗||F)
≤
1 +2R0
||H−1
m∗m−H′−1
m′∗m′||2
·(||m−m′||2+R0||H−H′||F),
where the last step is due to inequality (73). Thus, inequality (56) is implied by the semi-positive-
definiteness of H′
m∗−H′
m′∗.
Finally, when m∗< m′∗, we let Hm′∗denote the symmetric matrix sharing the same eigenbasis of
H, but with each eigenvalue λreplaced by max{λ, m′∗}. Due to the equivalence of HandH′, our
earlier proof steps imply that
Hm∗ 
H−1
m∗m−H′−1
m′∗m′
2≤
1 +2R0
||H−1
m∗m−H′−1
m′∗m′||2
·(||m−m′||2+R0||H−H′||F).
Hence, by triangle inequality, we can use the above bound as follows.
H′
m′∗ 
H−1
m∗m−H′−1
m′∗m′
2≤(Hm′∗−H′
m′∗) 
H−1
m∗m−H′−1
m′∗m′
2
+Hm′∗ 
H−1
m∗m−H′−1
m′∗m′
2
≤||Hm′∗−H′
m′∗||FH−1
m∗m−H′−1
m′∗m′
2
+Hm′∗ 
H−1
m∗m−H′−1
m′∗m′
2.
Note thatH−1
m∗m−H′−1
m′∗m′
2≤2R0. By inequality (73), it is clear that
H′
m′∗ 
H−1
m∗m−H′−1
m′∗m′
2≤
3 +2R0
||H−1
m∗m−H′−1
m′∗m′||2
·(||m−m′||2+R0||H−H′||F).
31NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: The main claims are included in our theorem statements.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We have included a discussion of constraints of our work.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
32Justification: We have provided the full set of assumptions and a complete proof.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
33Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [NA]
Justification: the paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
34•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [NA]
Justification: This paper does not include experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: This paper follows the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: This is a theory paper and there is no societal impact of the work performed.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
35generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: This paper poses no such risks.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [NA]
Justification: This paper does not use existing assets
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the license
of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
36Answer: [NA]
Justification: This paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: This paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
37