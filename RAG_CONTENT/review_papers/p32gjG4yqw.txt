Constructive Universal Approximation Theorems for
Deep Joint-Equivariant Networks by Schur’s Lemma
Anonymous Author(s)
Affiliation
Address
email
Abstract
We present a unified constructive universal approximation theorem covering a wide 1
range of learning machines including both shallow and deep neural networks based 2
on the group representation theory. Constructive here means that the distribution 3
of parameters is given in a closed-form expression (called the ridgelet transform ). 4
Contrary to the case of shallow models, expressive power analysis of deep models 5
has been conducted in a case-by-case manner. Recently, Sonoda et al. [33,32] 6
developed a systematic method to show a constructive approximation theorem 7
from scalar-valued joint-group-invariant feature maps, covering a formal deep 8
network. However, each hidden layer was formalized as an abstract group action, so 9
it was not possible to cover real deep networks defined by composites of nonlinear 10
activation function. In this study, we extend the method for vector-valued joint- 11
group-equivariant feature maps, so to cover such real networks. 12
1 Introduction 13
An ultimate goal of the deep learning theory is to characterize the internal data processing procedure 14
inside deep neural networks obtained by deep learning. We may formulate this problem as a functional 15
equation problem: Let Fdenote a class of data generating functions, and let DNN[γ]denote a certain 16
deep neural network with parameter γ. Given a function f∈ F, find an unknown parameter γso that 17
network DNN[γ]represents function f, i.e. 18
DNN[γ] =f, (1)
which we call a DNN equation . An ordinary learning problem by empirical risk minimization, such 19
as minimizingPn
i=1|DNN[γ](xi)−f(xi)|2with respect to γ, is understood as a weak form (or a 20
variational form) of this equation. Therefore, characterizing the solution space of this equation leads 21
to understanding the parameters obtained by deep learning. Following previous studies [ 21,3,28– 22
31], we call a solution operator Rthat satisfies DNN[R[f]] =faridgelet transform . Once such a 23
solution operator Ris found, we can conclude a universality of the DNN in consideration because the 24
reconstruction formula DNN[R[f]] =fimplies for any f∈ F there exists a DNN that represents f. 25
In particular, when R[f]is found in a closed-form manner, then it leads to a constructive proof of the 26
universality since R[f]could indicate how to assign parameters. 27
When the network has only one infinitely-wide hidden layer, though it is not deep but shallow, the 28
characterization problem has been well investigated. For example, the learning dynamics and the 29
global convergence property (of SGD) are well studied in the mean field theory [ 22,25,20,5] and the 30
Langevin dynamics theory [ 35], and even closed-form solution operator to a “shallow” NN equation, 31
the original ridgelet transform, has already been presented [28–31]. 32
On the other hand, when the network has more than one hidden layer, the problem is far from 33
solved, and it is common to either consider infinitely-deep mathematical models such as Neural 34
Submitted to 38th Conference on Neural Information Processing Systems (NeurIPS 2024). Do not distribute.ODEs [ 27,9,17,12,4], or handcraft inner feature maps depending on the problem. For example, 35
construction methods such as the Telgarsky sawtooth function (or the Yarotsky scheme) and bit 36
extraction techniques [ 7,36–39,8,6,26,24,11] have been developed to demonstrate the depth 37
separation, super-convergence, and minmax optimality of deep ReLU networks. Various feature maps 38
have also been handcrafted in the contexts of geometric deep learning [ 1] and deep narrow networks 39
[19,13,18,14,23,16,2,15]. Needless to say, there is no guarantee that these handcrafted feature 40
maps are acquired by deep learning, so these analyses are considered to be analyses of possible 41
worlds. 42
Recently, Sonoda et al. [33,32]discovered a rich class of ridgelet transforms for learning machines 43
defined by scalar-valued joint-group-invariant feature maps, covering both depth-2 fully-connected 44
networks and the formal deep network (FDN), yielding the first ridgelet transform for deep models. 45
Their theory is indeed a breakthrough because it could cover both deep and shallow models simulta- 46
neously. However, each hidden layer in the FDN has to be formalized as an abstract group action, 47
so it was not possible to cover real deep networks defined by composites of nonlinear activation 48
function. In this study, we extend their arguments for vector-valued joint-group-equivariant feature 49
maps (Theorem 3 and Corollary 1), so to cover such real networks. As an important example, in 50
§ 4.2, we obtained the ridgelet transform for a more realistic DNN, the depth- nfully-connected 51
network with an arbitrary activation function (not limited to ReLU), without handcrafting network 52
architecture. In other words, it is a constructive proof of the L2(Rm;Rm)-universality of the DNNs, 53
and an explicit characterization of the solution space of the DNN equation for more realistic setup. 54
Thanks to Schur’s lemma, a basic and useful result in the representation theory, the proof of the main 55
theorem is surprisingly simple, yet the scope of application is wide. The significance of this study 56
lies in revealing the close relationship between machine learning theory and modern algebra. With 57
this study as a catalyst, we expect a major upgrade to machine learning theory from the perspective 58
of modern algebra. 59
2 Preliminaries 60
We quickly introduce the original integral representation and the ridgelet transform, a mathematical 61
model of depth-2 fully-connected network and its right inverse. Then, we list a few facts in the group 62
representation theory. In particular, Schur’s lemma and the Haar measure play key roles in the proof 63
of the main results. 64
Notation. For any topological space X,Cc(X)denotes the Banach space of all compactly supported 65
continuous functions on X. For any measure space X,Lp(X)denotes the Banach space of all p- 66
integrable functions on X.S(Rd)andS′(Rd)denote the classes of rapidly decreasing functions (or 67
Schwartz test functions) and tempered distributions on Rd, respectively. 68
2.1 Integral Representation and Ridgelet Transform for Depth-2 Fully-Connected Network 69
Definition 1. For any measurable functions σ:R→Candγ:Rm×R→C, put 70
Sσ[γ](x) :=Z
Rm×Rγ(a, b)σ(a·x−b)dadb,x∈Rm. (2)
We call Sσ[γ]an (integral representation of) neural network, and γa parameter distribution. 71
The integration over all the hidden parameters (a, b)∈Rm×Rmeans all the neurons {x7→ 72
σ(a·x−b)|(a, b)∈Rm×R}are summed (or integrated, to be precise) with weight γ, hence 73
formally Sσ[γ]is understood as a continuous neural network with a single hidden layer. We note, 74
however, when γis a finite sum of point measures such as γp=Pp
i=1ciδ(ai,bi)(by appropriately 75
extending the class of γto Borel measures), then it can also reproduce a finite width network 76
Sσ[γp](x) =pX
i=1ciσ(ai·x−bi). (3)
In other words, the integral representation is a mathmatical model of depth-2 network with anywidth 77
(ranging from finite to continuous). 78
Next, we introduce the ridgelet transform, which is known to be a right-inverse operator to Sσ. 79
2Definition 2. For any measurable functions ρ:R→Candf:Rm→C, put 80
Rρ[f](a, b) :=Z
Rmf(x)ρ(a·x−b)dx,(a, b)∈Rm×R. (4)
We call Rρa ridgelet transform. 81
To be precise, it satisfies the following reconstruction formula. 82
Theorem 1 (Reconstruction Formula) .Suppose σandρare a tempered distribution ( S′) and a rapid 83
decreasing function ( S) respectively. There exists a bilinear form ( (σ, ρ) )such that 84
Sσ◦Rρ[f] = ( ( σ, ρ) )f, (5)
for any square integrable function f∈L2(Rm). Further, the bilinear form is given by ( (σ, ρ) ) = 85R
Rσ♯(ω)ρ♯(ω)|ω|−mdω,where ♯denotes the 1-dimensional Fourier transform. 86
See Sonoda et al. [29, Theorem 6 ]for the proof. In particular, according to Sonoda et al. [29, 87
Lemma 9 ], for any activation function σ, there always exists ρsatisfying ( (σ, ρ) ) = 1 . Here, σ 88
being a tempered distribution means that typical activation functions are covered such as ReLU, step 89
function, tanh , gaussian, etc... We can interpret the reconstruction formula as a universality theorem 90
of continuous neural networks, since for any given data generating function f, a network with output 91
weight γf=Rρ[f]reproduces f(up to factor ( (σ, ρ) )), i.e. S[γf] =f. In other words, the ridgelet 92
transform indicates how the network parameters should be organized so that the network represents 93
an individual function f. 94
The original ridgelet transform was discovered by Murata [21] and Candès [3]. It is recently extended 95
to a few modern networks by the Fourier slice method [ 34, see e.g.]. In this study, we present a 96
systematic scheme to find the ridgelet transform for a variety of given network architecture based on 97
the group theoretic arguments. 98
2.2 Irreducible Unitary Representation and Schur’s Lemma 99
LetGbe a locally compact group, Hbe a nonzero Hilbert space, and U(H)be the group of unitary 100
operators on H. For example, any finite group, discrete group, compact group, and finite-dimensional 101
Lie group are locally compact, while an infinite-dimensional Lie group is not locally compact. A 102
unitary representation πofGonHis a group homomorphism that is continuous with respect to 103
the strong operator topology—that is, a map π:G→ U(H)satisfying π(gh) =π(g)π(h)and 104
π(g−1) =π(g)−1, and for any ψ∈ H, the map G∋g7→π(g)[ψ]∈ H is continuous. 105
Suppose Mis a closed subspace of H.Mis called an invariant subspace when π(g)M ⊂ M for all 106
g∈G. Particularly, πis called irreducible when it does not admit any nontrivial invariant subspace 107
M ̸={0}norH. The following theorem is a fundamental result of group representation theory that 108
characterizes the irreducibility. 109
Theorem 2 (Schur’s lemma) .A unitary representation (π,H)is irreducible iff any bounded operator 110
TonHthat commutes with πis always a constant multiple of the identity. In other words, if 111
π(g)T=Tπ(g)for all g∈G, then T=cIdHfor some c∈C. 112
See Folland [10, Theorem 3.5(a) ]for the proof. We use this as a key step in the proof of our main 113
theorem. 114
2.3 Calculus on Locally Compact Group 115
By Haar’s theorem, if Gis a locally compact group, then there uniquely exist left and right invariant 116
measures dlganddrg, satisfying for any s∈Gandf∈Cc(G), 117Z
Gf(sg)dlg=Z
Gf(g)dlg, andZ
Gf(gs)drg=Z
Gf(g)drg.
LetXbe aG-space with transitive left (resp. right) G-action g·x(resp. x·g) for any (g, x)∈G×X. 118
Then, we can further induce the left (resp. right) invariant measure dlx(resp. drx) so that for any 119
f∈Cc(G), 120Z
Xf(x)dlx:=Z
Gf(g·o)dlg, resp.Z
Xf(x)drx:=Z
Gf(o·g)drg,
where o∈Xis a fixed point called the origin. 121
3g.xinput 
ξ
g.youtput 
φparameter 
G-equivariance g.xinput 
g.ξ
g.youtput 
φparameter 
joint-G-equivariance Figure 1: An ordinary G-equivariant feature map ϕ:X×Ξ→Yis a subclass of joint- G-equivariant
map where the G-action on parameter domain Ξistrivial , i.e.g·ξ=ξ
3 Main Results 122
We introduce the joint-group-equivariant feature map, and present the ridgelet transforms for learning 123
machines defined by joint-group-equivariant feature maps, yielding the universality of deep models. 124
LetGbe a locally compact group equipped with a left invariant measure dg. Let XandΞbe 125
G-spaces equipped with G-invariant measures dxanddξ, called the data domain and the parameter 126
domain, respectively. Particularly, we call the product space X×Ξthedata-parameter domain (like 127
time-frequency domain), and call any map ϕon data-parameter domain X×Ξafeature map . LetH 128
be a separable Hilbert space, let U(H)be the space of unitary operators on H, and let υ:G→ U(H) 129
be a unitary representation of GonH. If there is no danger of confusion, we use the same symbol · 130
for the G-actions on X,H, and Ξ(e.g., g·x,g·v, and g·ξ). 131
In the main theorem, the irreducibility of the following unitary representation πwill be a sufficient 132
condition for the universality. Let L2(X;H)denote the space of H-valued square-integrable functions 133
onXequipped with the inner product ⟨ϕ, ψ⟩L2(X;H):=R
X⟨ϕ(x), ψ(x)⟩Hdx. Put 134
πg[f](x) :=g·f(g−1·x), x∈X, f∈L2(X;H), g∈G. (6)
Then, it is a unitary representation of GonL2(X;H). In fact, πg[πh[f]](x) =g·h·f(h−1·g−1·x) = 135
(gh)·f((gh)−1·x) =πgh[f](x), and⟨πg[f1], πg[f2]⟩L2(X;H)=R
X⟨υg[f1](g−1·x), υg[f2](g−1· 136
x)⟩Hdx=R
X⟨f1(x), υ∗
g[υg[f2]](x)⟩Hdx=⟨f1, f2⟩L2(X;H). 137
In addition, let L2(Ξ)denote the space of C-valued square-integrable functions on Ξ, and let bπbe 138
the left-regular representation of GonL2(Ξ)given by 139
bπg[γ](ξ) :=γ(g−1·ξ), ξ∈Ξ, γ∈L2(Ξ), g∈G. (7)
Similarly to π,bπis also a unitary representation. 140
Definition 3 (Joint G-Equivariant Feature Map) .LetX, Y be data domains, and Ξbe a parameter 141
domain (with G-actions). We say a feature map ϕ:X×Ξ→Yisjoint-G-equivariant when 142
ϕ(g·x, g·ξ) =g·ϕ(x, ξ),(x, ξ)∈X×Ξ, (8)
holds for all g∈G. In other words, ϕis a homomorphism (or G-map) of G-sets from X×Ξto 143
Y. So by hom G(X×Ξ, Y), we denote the collection of all joint- G-equivariant maps. Additionally, 144
when G-action on Yis trivial, i.e. ϕ(g·x, g·ξ) =ϕ(x, ξ), we say it is joint-G-invariant . 145
Remark 1.The joint- G-equivariance extends an ordinary notion of G-equivariance , i.e.ϕ(g·x, ξ) = 146
g·ϕ(x, ξ). In fact, G-equivariance is a special case of joint- G-equivariance where Gacts trivially on 147
parameter domain, i.e. g·ξ=ξ(see also Figure 1). 148
In order to construct a (non-joint) group-equivariant network, we must carefully and precisely design 149
the network architecture [see, e.g., a textbook of geometric deep learning 1]. On the other hand, we 150
can easily and systematically construct joint- G-equivariant network from (not at all equivariant but) 151
anymapf:X→Yaccording to the following Lemmas 1 and 2. 152
Lemma 1. Suppose group Gacts on sets XandY. Fix an arbitrary map f:X→Y, and put 153
ϕ(x, g) :=g·f(g−1·x)for every x∈Xandg∈G. Then, ϕ:X×G→Yis joint- G-equivariant. 154
Proof. Straightforward. For any g∈G,ϕ(g·x, g·h) = (gh)·f((gh)−1·(g·x)) =g·ϕ(x, h). 155
4Lemma 2 (Depth- nFeature Map ϕ1:n).Given a sequence of G-equivariant feature maps ϕi: 156
Xi−1×Ξi→Xi(i= 1, . . . , n ), putϕ1:n:X0×Ξ1× ··· × Ξn→Xnby 157
ϕ1:n(x, ξ1, . . . , ξ n) :=ϕn(•, ξn)◦ ··· ◦ ϕ1(x, ξ1). (9)
Then, ϕ1:nisG-equivariant. Following the custom of counting the number of parameter domains 158
(Ξi)n
i=1, we say ϕ1:nis depth- n. 159
Proof. In fact, 160
ϕ1:n(g·x, g·ξ1, . . . , g ·ξn) =ϕn(•, g·ξn)◦ ··· ◦ ϕ2(•, g·ξ2)◦ϕ1(g·x, g·ξ1)
=ϕn(•, g·ξn)◦ ··· ◦ ϕ2(g· •, g·ξ2)◦ϕ1(x, ξ1)
...
=ϕn(g· •, g·ξn)◦ ··· ◦ ϕ2(•, ξ2)◦ϕ1(x, ξ1)
=g·ϕn(•, ξn)◦ ··· ◦ ϕ2(•, ξ2)◦ϕ1(x, ξ1)
=g·ϕ1:n(x, ξ1, . . . , ξ n).
Definition 4 (ϕ-Network) .For any vector-valued map ϕ:X×Ξ→ H and scalar-valued map 161
γ: Ξ→C, define a vector-valued map X→ H by 162
NN[γ;ϕ](x) :=Z
Ξγ(ξ)ϕ(x, ξ)dξ, x ∈X, (10)
where the integral is understood as the Bocher integral. 163
We call the integral transform NN[•;ϕ]aϕ-transform, and each individual image NN[γ;ϕ]aϕ-network 164
for short. The ϕ-network extends the original integral representation. In particular, it inherits the 165
concept of integrating all the possible parameters ξand indirectly select which parameters to use 166
by weighting on them, which linearize parametrization by lifting nonlinear parameters ξto linear 167
parameter γ. 168
Definition 5 (ψ-Ridgelet Transform) .For any H-valued feature map ψ:X×Ξ→ H andH-valued 169
Borel measurable function fonX, put a scalar-valued integral transform 170
R[f;ψ](ξ) :=Z
X⟨f(x), ψ(x, ξ)⟩Hdx, ξ ∈Ξ. (11)
We call the integral transform R[•;ψ]aψ-ridgelet transform for short. 171
As long as the integrals are convergent, ϕ-ridgelet transform is the dual operator of ϕ-transform, since 172
⟨γ,R[f;ϕ]⟩L2(Ξ)=Z
X×Ξγ(ξ)⟨ϕ(x, ξ), f(x)⟩Hdxdξ=⟨NN[γ;ϕ], f⟩L2(X;H). (12)
Theorem 3 (Reconstruction Formula) .Assume (1) H-valued feature maps ϕ, ψ:X×Ξ→ H are 173
joint- G-equivariant, (2) composite operator NNϕ◦Rψ:L2(X;H)→L2(X;H)is bounded (i.e., 174
Lipschitz continuous), and (3) the unitary representation πdefined in (6)is irreducible. Then, there 175
exists a bilinear form ( (ϕ, ψ) )∈C(independent of f) such that for any H-valued square-integrable 176
function f∈L2(X;H), 177
NNϕ◦Rψ[f] = ( ( ϕ, ψ) )f. (13)
In other words, the ψ-ridgelet transform Rψis a right inverse operator of ϕ-transform NNϕas long as 178
( (ϕ, ψ) )̸= 0,∞. 179
Proof. We write NN[•;ϕ]asNNϕandR[•;ϕ]asRϕfor short. By using the unitarity of representation 180
υ:G→ U(H), left-invariance of measure dx, and G-equivariance of feature map ψ, for all g∈G, 181
we have 182
Rψ[πg[f]](ξ) =Z
X⟨g·f(g−1·x), ψ(x, ξ)⟩Hdx=Z
X⟨f(x), g−1·ψ(g·x, ξ)⟩Hdx
=Z
X⟨f(x), ψ(x, g−1·ξ)⟩Hdx=bπg[Rψ[f]](ξ). (14)
5xG-space 
input 
ξ1vector-space 
output 
φ1G-space 
parameter 
x1ξ2
φ2 x2ξ3
φ3 yG-space 
feature Figure 2: Deep H-valued joint- G-equivariant network on G-space XisL2(X;H)-universal when
unitary representation πofGonL2(X;H)is irreducible, and the distribution of parameters for the
network to represent a given map f:X→ H is exactly given by the ridgelet transform R[f]
Similarly, 183
NNϕ[bπg[γ]](x) =Z
Ξγ(g−1·ξ)ϕ(x, ξ)dξ=Z
Ξγ(ξ)ϕ(x, g·ξ)dξ
=Z
Ξγ(ξ) 
g·ϕ(g−1·x, ξ)
dξ=πg[NNϕ[γ]](x). (15)
Here,bπ∗denotes the dual representation of bπwith respect to L2(Ξ). 184
As a consequence, NNϕ◦Rψ:L2(X;H)→L2(X;H)commutes with πas below 185
NNϕ◦Rψ◦πg=NNϕ◦bπg◦Rψ=πg◦NNϕ◦Rψ (16)
for all g∈G. Hence by Schur’s lemma (Theorem 2), there exist a constant Cϕ,ψ∈Csuch that 186
NNϕ◦Rψ=Cϕ,ψIdL2(X). Since NNϕ◦Rψis bilinear in ϕandψ,Cϕ,ψis bilinear in ϕandψ. 187
In particular, because depth- nfeature map ϕ1:nisG-equivariant (Lemma 2), the following depth- n 188
H-valued deep network DNN[γ;ϕ1:n]isL2(X;H)-universal. 189
Corollary 1 (Deep Ridgelet Transform) .For any maps γ:X→Candf∈L2(X;H), put 190
DNN[γ;ϕ1:n](x) :=Z
Ξ1×···× Ξnγ(ξ1, . . . , ξ n)ϕn(•, ξn)◦ ··· ◦ ϕ1(x, ξ1)dξ, x∈X, (17)
R[f;ψ1:n](ξ) :=Z
Ξ⟨f(x), ψn(•, ξn)◦ ··· ◦ ψ1(x, ξn)⟩Hdx,ξ∈Ξ1× ··· × Ξn. (18)
Under the assumptions that DNNϕ1:n◦Rψ1:nis bounded, and that πis irreducible, there exists a 191
bilinear form ( (ϕ1:n, ψ1:n) )satisfying DNNϕ1:n◦Rψ1:n= ( (ϕ1:n, ψ1:n) ) IdL2(X;H). 192
Again, it extends the original integral representation, and inherits the linearization trick of nonlinear 193
parameters ξby integrating all the possible parameters (beyond the difference of layers) and indirectly 194
select which parameters to use by weighting on them. 195
4 Example: Depth- nFully-Connected Network with Arbitrary Activation 196
As a concrete example, we present the ridgelet transform for depth- nfully-connected network. 197
First, we show the depth-2 case based on a joint-affine- invariant argument, which was originally 198
demonstrated by Sonoda et al. [33]. Then, we show the depth- ncase based on a joint- equivariant 199
argument by extending the original arguments. 200
We use the following known facts. 201
Lemma 3. The regular representation πof the affine group Aff(m)onL2(Rm)(defined below) is 202
irreducible. 203
See Folland [10, Theorem 6.42] for the proof. 204
Lemma 4. Suppose σandρare a tempered distribution ( S′) and a Schwartz test function, respectively. 205
Then, Sσ◦Rρ:L2(Rm)→L2(Rm)is bounded. 206
See Sonoda et al. [29, Lemmas 7 and 8] for the proof. 207
64.1 Depth-2 208
SetX:=Rm(data domain), Ξ :=Rm×R(parameter domain), and G:= Aff( m) =GL(m)⋉Rm209
be the m-dimensional affine group, acting on data domain Xby 210
g·x:=Lx+t, g = (L,t)∈GL(m)⋉ Rm,x∈X. (19)
Addition to this, let πbe the regular representation of Aff(m)onL2(X), namely 211
π(g)[f](x) :=|detL|−1/2f(L−1(x−t)), f∈L2(X)andg= (L,t)∈GL(m)⋉ Rm.(20)
Further, define a dual action ofAff(m)on the parameter domain Ξas 212
g·(a, b) = (L−⊤a, b+t⊤L−⊤a), g = (L,t)∈GL(m)⋉ Rm,(a, b)∈Ξ. (21)
Then, we can see the feature map ϕ(x,(a, b)) := σ(a·x−b)is joint- G-invariant. In fact, 213
ϕ(g·x, g·(a, b)) =σ 
L−⊤a·(Lx+t)−(b+t⊤L−⊤a)
=σ(a·x−b) =ϕ(x,(a, b)).
By Lemma 3, the regular representation πofG= Aff( m)is irreducible. Therefore, by Theorem 3, 214
the depth- 2neural network and corresponding ridgelet transform: 215
NN[γ](x) =Z
Rm×Rγ(a, b)σ(a·x−b)dadb,and R2[f](a, b) =Z
Rmf(x)ρ(a·x−b)dx,
satisfy the reconstruction formula NN◦R2= ( (σ, ρ) ) IdL2(Rm). In Appendix A, we supplemented a 216
detailed proof. In Appendix B, we discussed a geometric interpretation of dual G-action (21). 217
4.2 Depth- n 218
Following Corollary 1, we derive the ridgelet transform for depth- nfully-connected network by 219
constructing a joint-equivariant network. 220
LetO(m)be the m-dimensional orthogonal group acting on RmbyQvforQ∈O(m)andv∈Rm, 221
and (re)set G:=O(m)×Aff(m)be the product group, acting on the data domain Xby 222
g·x:=Lx+t,x∈X, g= (Q, L,t)∈G=O(m)×(GL(m)⋉ Rm). (22)
Namely, we set the O(m)-action on Xis trivial. Define a unitary representation πofGon vector- 223
valued square-integrable functions L2(X;X)as 224
πg[f](x) :=Qf(L−1(x−t)),x∈X, g= (Q, L,t)∈G,f∈L2(X;X). (23)
Lemma 5. The above π:G→L2(Rm;Rm)is an irreducible unitary representation. 225
Proof. Recall that a tensor product of irreducible representations is irreducible. Since both O(m)- 226
action on RmandAff(m)-action on L2(Rm)are irreducible, and L2(Rm;Rm)is a tensor product 227
Rm⊗L2(Rm), so the action πof product group O(m)×Aff(m)on tensor product Rm⊗L2(Rm) = 228
L2(Rm;Rm)is irreducible. 229
Following the same arguments in Lemma 1, we first construct a depth- 2joint-G-equivariant network. 230
Take an arbitrary square-integrable (not yet joint- G-equivariant) vector-field f0∈L2(X;X). Then, 231
the following network is joint- G-equivariant: 232
NN(x, ξ) := NN[R2[πξ[f0]]](x) =Z
Rm×RQR2[f0](a, b)σ 
a⊤L−1(x−t)−b
dadb, (24)
for every x∈X, ξ = (Q, L,t)∈O(m)×GL(m)⋉ Rm. Here R2is the ridgelet transform for 233
depth-2 case (applied for vector-valued function by element-wise manner). This is joint- G-equivariant 234
because NN(x, ξ) =πξ[f0](x). Henceforth, we (re)set Ξ := G. 235
Finally, we construct a depth- njoint-G-equivariant network by composing the above depth- 2networks 236
as below. Write ξ:= (ξ1, . . . , ξ n)∈Ξnfor short. For any measurable function γ: Ξn→Cand 237
vector-field f:Rm→Rm, put 238
DNN(x) :=Z
Ξnγ(ξ)NN(•, ξn)◦ ··· ◦ NN(x, ξ1)dξ,x∈X (25)
Rn[f](ξ) :=Z
Xf(x)⊤NN(•, ξn)◦ ··· ◦ NN(x, ξ1)dx,ξ∈Ξn. (26)
Then, as a consequence of Corollary 1, there exists a constant c∈Csatisfying DNN◦Rn[f] =cffor 239
anyf∈L2(X;X). 240
75 Example: Formal Deep Network 241
We explain the formal deep network (FDN) introduced by Sonoda et al. [32]. Compared to the 242
depth- nfully-connected network introduced in the previous section, the FDN (introduced in the 243
previous study) is more abstract because the network architecture is not specified. Yet, we consider 244
this is still useful for theoretical study of deep networks as it covers a wide range of groups and data 245
domains (i.e., not limited to the affine group and the Euclidean space). 246
5.1 Formal Deep Network 247
LetGbe an arbitrary locally compact group equipped with left-invariant measure dg, letXbe a 248
G-space equipped with left-invariant measure dx, and set Ξ := Gwith right-invariant measure dξ. 249
The key concept is to identify each feature map ϕ:X×Ξ→Xwith a G-action g:X→Xwith 250
parameter domain Ξbeing identified with group G, and the composite of feature maps, say g◦h, 251
with product gh. Since a group is closed under its operation by definition, the proposed network can 252
represent literally any depth such as a single hidden layer g, double hidden layers g◦h, triple hidden 253
layers g◦h◦k, and infinite hidden layers g◦h◦ ··· . Besides, to lift the group action on a linear 254
space, the network is formulated as a regular action of group Gon a hidden layer, say ψ∈L2(X). 255
Definition 6 (Formal Deep Network) .For any functions ψ∈L2(X)andγ: Ξ→C, put 256
DNN[γ;ψ](x) :=Z
G1⋊···⋊Gnγ(ξ1, . . . , ξ n)ψ◦ξn◦ ··· ◦ ξ1(x)dξ1···dξn, x∈X. (27)
Here, G=G1⋊···⋊Gndenotes the semi-direct product of groups, suggesting that the network 257
gets much complex and expressive as it gets deeper. 258
To see the universality, define the dual action of Gon the parameter domain Ξ =Gas 259
g·ξ:=ξg−1, g∈G, ξ∈Ξ. (28)
Then, we can see ϕ(x, ξ) :=ψ◦ξ(x)is joint- G-invariant . In fact, 260
ϕ(g·x, g·ξ) =ψ◦(g·ξ)(g·x) =ψ◦(ξ◦g−1)(g(x)) =ψ◦ξ(x) =ϕ(x, ξ).
Therefore, by Theorem 3, assuming that the regular representation π:G→ U(L2(X))is irreducible, 261
the ridgelet transform is given by 262
R[f](ξ1, . . . , ξ n) =Z
Xf(x)ψ◦ξn◦ ··· ◦ ξ1(x)dx,(ξ1, . . . , ξ n)∈G1⋊···⋊Gn (29)
satisfying NN◦R= ( (σ, ρ) ) IdL2(X). 263
5.2 Depth Separation 264
To enjoy the advantage of abstract formulation, we discuss the effect of depth. For the sake of 265
simplicity, we assume Gto be a finite group, which may be acceptable given that the data domain 266
Xin practice is often discretized (or coarse-grained) into finite sets of representative points, say 267
X≈X:={xi}p
i=1, and if so the G-action is also reduced to finite representative actions. 268
Following the concept of the formal deep network, we call group Gacting on Xa network. Let us 269
consider depth-1 network Gand depth- nnetwork G1⋊···⋊Gnsatisfying G=G1⋊···⋊Gn. The 270
equation indicates that two networks have the same expressive power, because they can implement 271
the same class of maps g:X→X. 272
Next, let us define the width of a single layer Gas the cardinality |G|. This is reasonable because 273
the set Gparametrizes each map g:X→X. Then, under the assumption that each Giis simple, 274
the depth- nnetwork G1⋊···⋊Gncan express the same class of depth-1 network exponentially- 275
effectively, because the total widths arePn
i=1|Gi|=O(n)for depth- nandQn
i=1|Gi|= exp O(n) 276
for depth-1. This estimate can be interpreted as the classical thought that the hierarchical models 277
such as deep networks can represent complex functions combinatorially more efficient than shallow 278
models. 279
86 Discussion 280
We have developed a systematic method for deriving a ridgelet transform for a wide range of learning 281
machines defined by joint-group-equivariant feature maps, yielding the universal approximation 282
theorems as corollaries. The previous results by Sonoda et al. [33] was limited to scalar-valued 283
joint-invariant functions, which were insufficient to deal with practical learning machines defined by 284
composite mappings of vector-valued functions, such as deep neural networks. For example, they 285
could only deal with abstract composite structures like formal deep network [ 32]. By extending their 286
argument to vector-valued joint-equivariant functions, we were able to deal with deep structures. 287
Traditionally, the techniques used in the expressive power analysis of deep networks were different 288
from those used in the analysis of shallow networks, as overviewed in the introduction. Nonetheless, 289
our main theorem cover both deep and shallow networks from the unified perspective (joint-group- 290
action on the data-parameter domain). Technically, this unification is due to Schur’s lemma, a basic 291
and useful result in the representation theory. Thanks to this lemma, the proof of the main theorem is 292
simple, yet the scope of application is wide. The significance of this study lies in revealing the close 293
relationship between machine learning theory and modern algebra. With this study as a catalyst, we 294
expect a major upgrade to machine learning theory from the perspective of modern algebra. 295
6.1 Limitations 296
In the main theorem, we assume the following: (1) joint-equivariance of feature map ϕ, (2) bound- 297
edness of composite operator NN◦R, (3) irreducibility of unitary representation π. In addition, 298
throughout this study, we assume (4) local compactness of group G, and (5) that the network is given 299
by the integral representation. 300
As discussed in the main text, satisfying (1) is much easier than (non-joint) equivariance. Also, (2) is 301
often a textbook excersise when the specific expression is given. (3) is required for Schur’s lemma, and 302
it is often sufficient to synthesize the known results such as the one for the example of depth- nfully- 303
connected network. (4) is quite a frequent assumption in the standard group representation theory, but 304
it excludes infinite-dimensional groups. When formulated natively , nonparametric learning models 305
including DNN can be infinite-dimensional groups. However, from the perspective of learnability, 306
it is nonsense to consider too large a model, and it is common to assume regularity conditions 307
such as sparsity and low rank in usual theoretical analysis. So, it is natural to impose additional 308
regularity conditions for satisfying local compactness. (5) may be rather an advantage because 309
there are established techniques to show the cc-universaity of finite models by discretizing integral 310
representations. Moreover, there is a fast discretization scheme called the Barron’s rate based on the 311
quasi-Monte Carlo method. On the other hand, problems like the minimum width in the field of deep 312
narrow networks are analyses of finite parameters, and they could be a different type of parameters. 313
Yet, the current mainstream solutions are the information theoretic method by Park et al. [23] and the 314
neural ODE method by Cai [2], and both arguments contain the discretization of continuous models. 315
Therefore, we may expect a high affinity with the integral representation theory. 316
This study is the first step in extending the harmonic analysis method, which was previously applicable 317
only to shallow models, to deep models. The above limitations will be resolved in our future works. 318
7 Broader Impact 319
This work studies theoretical aspects of neural networks for expressing square integrable functions. 320
Since we do not propose a new method nor a new dataset, we expect that the impact of this work on 321
ethical aspects and future societal consequences will be small, if any. Our work can help understand 322
the theoretical benefit and limitations of neural networks in approximating functions. Our work and 323
the proof technique improve our understanding of the theoretical aspect of deep neural networks and 324
other learning machines used in machine learning, and may lead to better use of these techniques 325
with possible benefits to the society. 326
References 327
[1]M. M. Bronstein, J. Bruna, T. Cohen, and P. Veli ˇckovi ´c. Geometric Deep Learning: Grids, Groups, Graphs, 328
Geodesics, and Gauges. arXiv preprint: 2104.13478 , 2021. 329
9[2]Y . Cai. Achieve the Minimum Width of Neural Networks for Universal Approximation. In The Eleventh 330
International Conference on Learning Representations , 2023. 331
[3] E. J. Candès. Ridgelets: theory and applications . PhD thesis, Standford University, 1998. 332
[4]R. T. Q. Chen, Y . Rubanova, J. Bettencourt, and D. Duvenaud. Neural Ordinary Differential Equations. In 333
Advances in Neural Information Processing Systems , volume 31, pages 6572–6583, Palais des Congrès de 334
Montréal, Montréal CANADA, 2018. 335
[5]L. Chizat and F. Bach. On the Global Convergence of Gradient Descent for Over-parameterized Models 336
using Optimal Transport. In Advances in Neural Information Processing Systems 32 , pages 3036–3046, 337
Montreal, BC, 2018. 338
[6]A. Cohen, R. DeV ore, G. Petrova, and P. Wojtaszczyk. Optimal Stable Nonlinear Approximation. Founda- 339
tions of Computational Mathematics , 22(3):607–648, 2022. 340
[7]N. Cohen, O. Sharir, and A. Shashua. On the Expressive Power of Deep Learning: A Tensor Analysis. In 341
29th Annual Conference on Learning Theory , volume 49, pages 1–31, 2016. 342
[8]I. Daubechies, R. DeV ore, S. Foucart, B. Hanin, and G. Petrova. Nonlinear Approximation and (Deep) 343
ReLU Networks. Constructive Approximation , 55(1):127–172, 2022. 344
[9]W. E. A Proposal on Machine Learning via Dynamical Systems. Communications in Mathematics and 345
Statistics , 5(1):1–11, 2017. 346
[10] G. B. Folland. A Course in Abstract Harmonic Analysis . Chapman and Hall/CRC, New York, second 347
edition, 2015. 348
[11] P. Grohs, A. Klotz, and F. V oigtlaender. Phase Transitions in Rate Distortion Theory and Deep Learning. 349
Foundations of Computational Mathematics , 23(1):329–392, 2023. 350
[12] E. Haber and L. Ruthotto. Stable architectures for deep neural networks. Inverse Problems , 34(1):1–22, 351
2017. 352
[13] B. Hanin and M. Sellke. Approximating Continuous Functions by ReLU Nets of Minimal Width. arXiv 353
preprint: 1710.11278 , 2017. 354
[14] P. Kidger and T. Lyons. Universal Approximation with Deep Narrow Networks. In Proceedings of Thirty 355
Third Conference on Learning Theory , volume 125 of Proceedings of Machine Learning Research , pages 356
2306–2327. PMLR, 2020. 357
[15] N. Kim, C. Min, and S. Park. Minimum width for universal approximation using ReLU networks on 358
compact domain. In The Twelfth International Conference on Learning Representations , 2024. 359
[16] L. Li, Y . Duan, G. Ji, and Y . Cai. Minimum Width of Leaky-ReLU Neural Networks for Uniform Universal 360
Approximation. In Proceedings of the 40th International Conference on Machine Learning , volume 202 of 361
Proceedings of Machine Learning Research , pages 19460–19470, 2023. 362
[17] Q. Li and S. Hao. An Optimal Control Approach to Deep Learning and Applications to Discrete-Weight 363
Neural Networks. In Proceedings of The 35th International Conference on Machine Learning , volume 80, 364
pages 2985–2994, Stockholm, 2018. PMLR. 365
[18] H. Lin and S. Jegelka. ResNet with one-neuron hidden layers is a Universal Approximator. In Advances in 366
Neural Information Processing Systems , volume 31, Montreal, BC, 2018. 367
[19] Z. Lu, H. Pu, F. Wang, Z. Hu, and L. Wang. The Expressive Power of Neural Networks: A View from the 368
Width. In Advances in Neural Information Processing Systems , volume 30, 2017. 369
[20] S. Mei, A. Montanari, and P.-M. Nguyen. A mean field view of the landscape of two-layer neural networks. 370
Proceedings of the National Academy of Sciences , 115(33):E7665–E7671, 2018. 371
[21] N. Murata. An integral representation of functions using three-layered networks and their approximation 372
bounds. Neural Networks , 9(6):947–956, 1996. 373
[22] A. Nitanda and T. Suzuki. Stochastic Particle Gradient Descent for Infinite Ensembles. arXiv preprint: 374
1712.05438 , 2017. 375
[23] S. Park, C. Yun, J. Lee, and J. Shin. Minimum Width for Universal Approximation. In International 376
Conference on Learning Representations , 2021. 377
10[24] G. Petrova and P. Wojtaszczyk. Limitations on approximation by deep and shallow neural networks. 378
Journal of Machine Learning Research , 24(353):1–38, 2023. 379
[25] G. Rotskoff and E. Vanden-Eijnden. Parameters as interacting particles: long time convergence and 380
asymptotic error scaling of neural networks. In Advances in Neural Information Processing Systems 31 , 381
pages 7146–7155, Montreal, BC, 2018. 382
[26] J. W. Siegel. Optimal Approximation Rates for Deep ReLU Neural Networks on Sobolev and Besov 383
Spaces. Journal of Machine Learning Research , 24(357):1–52, 2023. 384
[27] S. Sonoda and N. Murata. Transportation analysis of denoising autoencoders: a novel method for analyzing 385
deep neural networks. In NIPS 2017 Workshop on Optimal Transport & Machine Learning (OTML) , pages 386
1–10, Long Beach, 2017. 387
[28] S. Sonoda, I. Ishikawa, and M. Ikeda. Ridge Regression with Over-Parametrized Two-Layer Networks 388
Converge to Ridgelet Spectrum. In Proceedings of The 24th International Conference on Artificial 389
Intelligence and Statistics (AISTATS) 2021 , volume 130, pages 2674–2682. PMLR, 2021. 390
[29] S. Sonoda, I. Ishikawa, and M. Ikeda. Ghosts in Neural Networks: Existence, Structure and Role of 391
Infinite-Dimensional Null Space. arXiv preprint: 2106.04770 , 2021. 392
[30] S. Sonoda, I. Ishikawa, and M. Ikeda. Universality of Group Convolutional Neural Networks Based 393
on Ridgelet Analysis on Groups. In Advances in Neural Information Processing Systems 35 , pages 394
38680–38694, New Orleans, Louisiana, USA, 2022. 395
[31] S. Sonoda, I. Ishikawa, and M. Ikeda. Fully-Connected Network on Noncompact Symmetric Space 396
and Ridgelet Transform based on Helgason-Fourier Analysis. In Proceedings of the 39th International 397
Conference on Machine Learning , volume 162, pages 20405–20422, Baltimore, Maryland, USA, 2022. 398
[32] S. Sonoda, Y . Hashimoto, I. Ishikawa, and M. Ikeda. Deep Ridgelet Transform: V oice with Koopman 399
Operator Proves Universality of Formal Deep Networks. In Proceedings of the 2nd NeurIPS Workshop on 400
Symmetry and Geometry in Neural Representations , Proceedings of Machine Learning Research. PMLR, 401
2023. 402
[33] S. Sonoda, H. Ishi, I. Ishikawa, and M. Ikeda. Joint Group Invariant Functions on Data-Parameter Domain 403
Induce Universal Neural Networks. In Proceedings of the 2nd NeurIPS Workshop on Symmetry and 404
Geometry in Neural Representations , Proceedings of Machine Learning Research. PMLR, 2023. 405
[34] S. Sonoda, I. Ishikawa, and M. Ikeda. A unified Fourier slice method to derive ridgelet transform for a 406
variety of depth-2 neural networks. Journal of Statistical Planning and Inference , 233:106184, 2024. 407
[35] T. Suzuki. Generalization bound of globally optimal non-convex neural network training: Transportation 408
map estimation by infinite dimensional Langevin dynamics. In Advances in Neural Information Processing 409
Systems 33 , pages 19224–19237, 2020. 410
[36] M. Telgarsky. Benefits of depth in neural networks. In 29th Annual Conference on Learning Theory , pages 411
1–23, 2016. 412
[37] D. Yarotsky. Error bounds for approximations with deep ReLU networks. Neural Networks , 94:103–114, 413
2017. 414
[38] D. Yarotsky. Optimal approximation of continuous functions by very deep ReLU networks. In Proceedings 415
of the 31st Conference On Learning Theory , volume 75 of Proceedings of Machine Learning Research , 416
pages 639–649. PMLR, 2018. 417
[39] D. Yarotsky and A. Zhevnerchuk. The phase diagram of approximation rates for deep neural networks. In 418
Advances in Neural Information Processing Systems , volume 33, pages 13005–13015, 2020. 419
A Depth- 2Fully-Connected Neural Network and Ridgelet Transform 420
A non group theoretic proof by reducing to a Fourier expression is given in Sonoda et al. [29, 421
Theorem 6]. 422
11A.1 Proof 423
In the following, we identify the group Gacting on data domain Rmwith the affine group Aff(Rm), 424
and introduce the so-called twisted dual group action that leaves a function θinvariant. Then, we see 425
the regular action πofGon functions space L2(Rm)commutes with composite Sσ◦Rρ. Hence, by 426
Schur’s lemma, Sσ◦Rρis a constant multiple of identity, which concludes the assertion. 427
Proof. LetGbe the affine group Aff(Rm) =GL(Rm)⋉ Rm. For any g= (L,t)∈G, let 428
g·x:=Lx+t,x∈Rm(30)
be its action on Rm, and let 429
π(g)[f](x) :=|detL|−1/2f(g−1·x)
=|detL|−1/2f(L−1(x−t)), f∈L2(Rm) (31)
be its left-regular action on L2(Rm). 430
Besides, putting 431
θ((a, b),x) :=a·x−b,(a, b)∈Rm×R,x∈Rm(32)
we define the twisted dual action ofGonRm×Ras 432
g·(a, b) := ( L−⊤a, b+a·(L−1t)),(a, b)∈Rm×R (33)
so that the following invariance hold: 433
θ(g·(a, b), g·x) =θ((a, b),x) =a·x−b. (34)
To see this, use matrix expressions with extended variables 434
θ((a, b),x) = 
a⊤b
Im 0
0−1
x
1
=:˜a⊤˜I˜x, (35)
gg·x:=
g·x
1
=
Lt
0 1
x
1
=:˜L˜x (36)
and calculate 435
˜a⊤˜I˜x= (˜a⊤˜I˜L−1˜I−1)˜I(˜L˜x) = ( ˜I˜L−⊤˜I˜a)⊤˜I(˜L˜x), (37)
which suggests ^g·(a, b) :=˜I˜L−⊤˜I˜a, and we have 436
˜I˜L−⊤˜I=
Im 0
0−1
Lt
0 1−⊤
Im 0
0−1
=
Im 0
0−1
L−⊤0
−t⊤L−⊤1
Im 0
0−1
=
L−⊤0
t⊤L−⊤1
.
Further, we define its regular-action by 437
bπ(g)[γ](a, b) :=|detL|1/2γ(g−1·(a, b))
=|detL|1/2γ(L⊤a, b−a·t),(a, b)∈Rm×R. (38)
Then we can see that, for all g= (L,t)∈G, 438
Rρ◦π(g) =bπ(g)◦Rρ,and Sσ◦bπ(g) =π(g)◦Sσ. (39)
In fact, at every g= (L,t)∈Gand(a, b)∈Rm×R, 439
Rρ[π(g)[f]](a, b) =|detL|−1/2Z
Rmf(g−1·x)ρ(θ((a, b),x))dx
by putting x=g·y=Ly+twithdx=|detL|dy, 440
=|detL|1/2Z
Rmf(y)ρ(θ((a, b), g·y)))dy
12=|detL|1/2Z
Rmf(y)ρ(θ(g−1·(a, b),y)))dy
=bπ(g)[Rρ[f]](a, b). (40)
Similarly, at every g= (L,t)∈Gandx∈Rm, 441
Sσ[bπ(g)[γ]](x) =|detL|1/2Z
Rm×Rγ(g−1·(a, b))σ(θ((a, b),x))dadb
by putting (a, b) :=g·(ξ, η) = (L−⊤ξ, η+ξ·(L−1t))withdadb=|detL|dξdη, 442
=|detL|−1/2Z
Rm×Rγ(ξ, η)σ(θ(g·(ξ, η),x))dξdη
=|detL|−1/2Z
Rm×Rγ(ξ, η)σ(θ((ξ, η), g−1·x))dξdη
=π(g)[Sσ[γ]](x). (41)
Hence Sσ◦Rρcommutes with π(g)because 443
Sσ◦Rρ◦π(g) =Sσ◦bπ(g)◦Rρ=π(g)◦Sσ◦Rρ.
Since Sσ◦Rρ:L2(Rm)→L2(Rm)is bounded (Lemma 4), and (π, L2(Rm))is an irreducible 444
unitary representation of G(Lemma 3), Schur’s lemma (Theorem 2) yields that there exist a constant 445
Cσ,ρ∈Csuch that 446
Sσ◦Rρ[f] =Cσ,ρf (42)
for all f∈L2(Rm). 447
Finally, by directly computing the left-hand-side, namely Sσ◦Rρ[f], we can verify that the constant 448
Cσ,ρis given by 449
Cσ,ρ= ( (σ, ρ) ) := (2 π)m−1Z
Rσ♯(ω)ρ♯(ω)|ω|−mdω. (43)
450
A.2 Proof for (33) 451
Use matrix expressions with extended variables 452
θ((a, b),x) = 
a⊤b
Im 0
0−1
x
1
=:˜a⊤˜I˜x, (44)
gg·x:=
g·x
1
=
Lt
0 1
x
1
=:˜L˜x (45)
and calculate 453
˜a⊤˜I˜x= (˜a⊤˜I˜L−1˜I−1)˜I(˜L˜x) = ( ˜I˜L−⊤˜I˜a)⊤˜I(˜L˜x), (46)
which suggests ^g·(a, b) :=˜I˜L−⊤˜I˜a, and we have 454
˜I˜L−⊤˜I=
Im 0
0−1
Lt
0 1−⊤
Im 0
0−1
=
Im 0
0−1
L−⊤0
−t⊤L−⊤1
Im 0
0−1
=
L−⊤0
t⊤L−⊤1
.
13A.3 Proof for (39) 455
In fact, at every g= (L,t)∈Gand(a, b)∈Rm×R, 456
Rρ[π(g)[f]](a, b) =|detL|−1/2Z
Rmf(g−1·x)ρ(θ((a, b),x))dx
by putting x=g·y=Ly+twithdx=|detL|dy, 457
=|detL|1/2Z
Rmf(y)ρ(θ((a, b), g·y)))dy
=|detL|1/2Z
Rmf(y)ρ(θ(g−1·(a, b),y)))dy
=bπ(g)[Rρ[f]](a, b). (47)
Similarly, at every g= (L,t)∈Gandx∈Rm, 458
Sσ[bπ(g)[γ]](x) =|detL|1/2Z
Rm×Rγ(g−1·(a, b))σ(θ((a, b),x))dadb
by putting (a, b) :=g·(ξ, η) = (L−⊤ξ, η+ξ·(L−1t))withdadb=|detL|dξdη, 459
=|detL|−1/2Z
Rm×Rγ(ξ, η)σ(θ(g·(ξ, η),x))dξdη
=|detL|−1/2Z
Rm×Rγ(ξ, η)σ(θ((ξ, η), g−1·x))dξdη
=π(g)[Sσ[γ]](x). (48)
460
B Geometric Interpretation of Dual Action for Original Ridgelet Transform 461
We explain a geometric interpretation of the dual action (33) in the previous section. We note that 462
in general θdoes not require any geometric interpretation as long as it is joint group invariant on 463
data-parameter domain. 464
For each (a, b)∈Rm×R, putξ(a, b) :={x∈Rm|a·x−b= 0}. Then it is a hyperplane in Rm465
through point x0=ba/|a|2with normal vector u:=a/|a|. 466
o
ξ(a, b)uy0y
ξ(a,a·x)x
x0
yx
Figure 3: The invariant ϕ((a, b),x) =σ(a·x−b)is the euclidean distance between point xand
hyperplane ξ(a, b)followed by scaling and nonlinearity σ
For any point yin the hyperplane ξ(a, b), by definition a·y=b, thus 467
a·x−b=a·(x−y). (49)
But this means a·x−bis a scaled distance between point xand hyperplane ξ(a, b), 468
=|a|dE(x, ξ(a, b)), (50)
14and further a scaled distance between hyperplanes ξ(a,a·x)through xwith normal a/|a|and
ξ(a, b), 469
=|a|dE(ξ(a,a·x), ξ(a, b)). (51)
Now, we can interpret the invariant θ((a, b),x) :=a·x−bin a geometric manner, that is, it is the 470
distance between point and hyperplane, or between hyperplanes. We note that we can regard entire 471
σ(a·x−b)—the distance modulated by both scaling and nonlinearity—as the invariant, say ϕ. 472
Furthermore, the dual action g·(a, b)is understood as a parallel translation of hyperplane ξ(a, b)to 473
ξ(g·(a, b))so as to leave the scaled distance θinvariant, namely 474
dE(g·x, g·ξ(a, b)) =dE(x, ξ(a, b)). (52)
Indeed, for any g= (L,t)∈G, 475
g·ξ(a, b) ={g·x|a·x−b= 0}
={y|a·(g−1·y)−b= 0} (by letting y=g·x)
={y|(L−⊤)·y−(b+a·(L−1t)) = 0}
=ξ(g·(a, b)),
meaning that the hyperplane with parameter (a, b)translated by gis identical to the hyperplane with 476
parameter g·(a, b). 477
To summarize, in the case of fully-connected neural network (and its corresponding ridgelet trans- 478
form), the invariant is a modulated distance σ(a·x−b), and the dual action is the parallel translation 479
of hyperplane so as to keep the distance invariant. Further, from this geometric perspective, we can 480
rewrite the fully-connected neural network in a geometric manner as 481
S[γ](x) :=Z
R×Ξγ(ξ)σ(adE(x, ξ))dadξ, (53)
where a∈Rdenotes signed scale and Ξdenotes the space of all hyperplanes (not always through 482
the origin). Since each hyperplane is parametrized by normal vectors u∈m−1and distance p≥0 483
from the origin, we can induce the product of spherical measure duand Lebesgue measure dpas a 484
measure dξon the space Ξof hyperplanes. 485
15NeurIPS Paper Checklist 486
1.Claims 487
Question: Do the main claims made in the abstract and introduction accurately reflect the 488
paper’s contributions and scope? 489
Answer: [Yes] 490
Justification: Theorem 3 and Corollary 1 491
Guidelines: 492
•The answer NA means that the abstract and introduction do not include the claims 493
made in the paper. 494
•The abstract and/or introduction should clearly state the claims made, including the 495
contributions made in the paper and important assumptions and limitations. A No or 496
NA answer to this question will not be perceived well by the reviewers. 497
•The claims made should match theoretical and experimental results, and reflect how 498
much the results can be expected to generalize to other settings. 499
•It is fine to include aspirational goals as motivation as long as it is clear that these goals 500
are not attained by the paper. 501
2.Limitations 502
Question: Does the paper discuss the limitations of the work performed by the authors? 503
Answer: [Yes] 504
Justification: § 6.1 505
Guidelines: 506
•The answer NA means that the paper has no limitation while the answer No means that 507
the paper has limitations, but those are not discussed in the paper. 508
• The authors are encouraged to create a separate "Limitations" section in their paper. 509
•The paper should point out any strong assumptions and how robust the results are to 510
violations of these assumptions (e.g., independence assumptions, noiseless settings, 511
model well-specification, asymptotic approximations only holding locally). The authors 512
should reflect on how these assumptions might be violated in practice and what the 513
implications would be. 514
•The authors should reflect on the scope of the claims made, e.g., if the approach was 515
only tested on a few datasets or with a few runs. In general, empirical results often 516
depend on implicit assumptions, which should be articulated. 517
•The authors should reflect on the factors that influence the performance of the approach. 518
For example, a facial recognition algorithm may perform poorly when image resolution 519
is low or images are taken in low lighting. Or a speech-to-text system might not be 520
used reliably to provide closed captions for online lectures because it fails to handle 521
technical jargon. 522
•The authors should discuss the computational efficiency of the proposed algorithms 523
and how they scale with dataset size. 524
•If applicable, the authors should discuss possible limitations of their approach to 525
address problems of privacy and fairness. 526
•While the authors might fear that complete honesty about limitations might be used by 527
reviewers as grounds for rejection, a worse outcome might be that reviewers discover 528
limitations that aren’t acknowledged in the paper. The authors should use their best 529
judgment and recognize that individual actions in favor of transparency play an impor- 530
tant role in developing norms that preserve the integrity of the community. Reviewers 531
will be specifically instructed to not penalize honesty concerning limitations. 532
3.Theory Assumptions and Proofs 533
Question: For each theoretical result, does the paper provide the full set of assumptions and 534
a complete (and correct) proof? 535
Answer: [Yes] 536
16Justification: We put the proof right after Theorem 3 537
Guidelines: 538
• The answer NA means that the paper does not include theoretical results. 539
•All the theorems, formulas, and proofs in the paper should be numbered and cross- 540
referenced. 541
•All assumptions should be clearly stated or referenced in the statement of any theorems. 542
•The proofs can either appear in the main paper or the supplemental material, but if 543
they appear in the supplemental material, the authors are encouraged to provide a short 544
proof sketch to provide intuition. 545
•Inversely, any informal proof provided in the core of the paper should be complemented 546
by formal proofs provided in appendix or supplemental material. 547
• Theorems and Lemmas that the proof relies upon should be properly referenced. 548
4.Experimental Result Reproducibility 549
Question: Does the paper fully disclose all the information needed to reproduce the main ex- 550
perimental results of the paper to the extent that it affects the main claims and/or conclusions 551
of the paper (regardless of whether the code and data are provided or not)? 552
Answer: [NA] 553
Justification: This study does not include experiments. 554
Guidelines: 555
• The answer NA means that the paper does not include experiments. 556
•If the paper includes experiments, a No answer to this question will not be perceived 557
well by the reviewers: Making the paper reproducible is important, regardless of 558
whether the code and data are provided or not. 559
•If the contribution is a dataset and/or model, the authors should describe the steps taken 560
to make their results reproducible or verifiable. 561
•Depending on the contribution, reproducibility can be accomplished in various ways. 562
For example, if the contribution is a novel architecture, describing the architecture fully 563
might suffice, or if the contribution is a specific model and empirical evaluation, it may 564
be necessary to either make it possible for others to replicate the model with the same 565
dataset, or provide access to the model. In general. releasing code and data is often 566
one good way to accomplish this, but reproducibility can also be provided via detailed 567
instructions for how to replicate the results, access to a hosted model (e.g., in the case 568
of a large language model), releasing of a model checkpoint, or other means that are 569
appropriate to the research performed. 570
•While NeurIPS does not require releasing code, the conference does require all submis- 571
sions to provide some reasonable avenue for reproducibility, which may depend on the 572
nature of the contribution. For example 573
(a)If the contribution is primarily a new algorithm, the paper should make it clear how 574
to reproduce that algorithm. 575
(b)If the contribution is primarily a new model architecture, the paper should describe 576
the architecture clearly and fully. 577
(c)If the contribution is a new model (e.g., a large language model), then there should 578
either be a way to access this model for reproducing the results or a way to reproduce 579
the model (e.g., with an open-source dataset or instructions for how to construct 580
the dataset). 581
(d)We recognize that reproducibility may be tricky in some cases, in which case 582
authors are welcome to describe the particular way they provide for reproducibility. 583
In the case of closed-source models, it may be that access to the model is limited in 584
some way (e.g., to registered users), but it should be possible for other researchers 585
to have some path to reproducing or verifying the results. 586
5.Open access to data and code 587
Question: Does the paper provide open access to the data and code, with sufficient instruc- 588
tions to faithfully reproduce the main experimental results, as described in supplemental 589
material? 590
17Answer: [NA] . 591
Justification: This study does not include experiments. 592
Guidelines: 593
• The answer NA means that paper does not include experiments requiring code. 594
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/ 595
public/guides/CodeSubmissionPolicy ) for more details. 596
•While we encourage the release of code and data, we understand that this might not be 597
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not 598
including code, unless this is central to the contribution (e.g., for a new open-source 599
benchmark). 600
•The instructions should contain the exact command and environment needed to run to 601
reproduce the results. See the NeurIPS code and data submission guidelines ( https: 602
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details. 603
•The authors should provide instructions on data access and preparation, including how 604
to access the raw data, preprocessed data, intermediate data, and generated data, etc. 605
•The authors should provide scripts to reproduce all experimental results for the new 606
proposed method and baselines. If only a subset of experiments are reproducible, they 607
should state which ones are omitted from the script and why. 608
•At submission time, to preserve anonymity, the authors should release anonymized 609
versions (if applicable). 610
•Providing as much information as possible in supplemental material (appended to the 611
paper) is recommended, but including URLs to data and code is permitted. 612
6.Experimental Setting/Details 613
Question: Does the paper specify all the training and test details (e.g., data splits, hyper- 614
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the 615
results? 616
Answer: [NA] 617
Justification: This study does not include experiments 618
Guidelines: 619
• The answer NA means that the paper does not include experiments. 620
•The experimental setting should be presented in the core of the paper to a level of detail 621
that is necessary to appreciate the results and make sense of them. 622
•The full details can be provided either with the code, in appendix, or as supplemental 623
material. 624
7.Experiment Statistical Significance 625
Question: Does the paper report error bars suitably and correctly defined or other appropriate 626
information about the statistical significance of the experiments? 627
Answer: [NA] 628
Justification: This study does not include experiments. 629
Guidelines: 630
• The answer NA means that the paper does not include experiments. 631
•The authors should answer "Yes" if the results are accompanied by error bars, confi- 632
dence intervals, or statistical significance tests, at least for the experiments that support 633
the main claims of the paper. 634
•The factors of variability that the error bars are capturing should be clearly stated (for 635
example, train/test split, initialization, random drawing of some parameter, or overall 636
run with given experimental conditions). 637
•The method for calculating the error bars should be explained (closed form formula, 638
call to a library function, bootstrap, etc.) 639
• The assumptions made should be given (e.g., Normally distributed errors). 640
•It should be clear whether the error bar is the standard deviation or the standard error 641
of the mean. 642
18•It is OK to report 1-sigma error bars, but one should state it. The authors should 643
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis 644
of Normality of errors is not verified. 645
•For asymmetric distributions, the authors should be careful not to show in tables or 646
figures symmetric error bars that would yield results that are out of range (e.g. negative 647
error rates). 648
•If error bars are reported in tables or plots, The authors should explain in the text how 649
they were calculated and reference the corresponding figures or tables in the text. 650
8.Experiments Compute Resources 651
Question: For each experiment, does the paper provide sufficient information on the com- 652
puter resources (type of compute workers, memory, time of execution) needed to reproduce 653
the experiments? 654
Answer: [NA] 655
Justification: This study does not include experiments. 656
Guidelines: 657
• The answer NA means that the paper does not include experiments. 658
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, 659
or cloud provider, including relevant memory and storage. 660
•The paper should provide the amount of compute required for each of the individual 661
experimental runs as well as estimate the total compute. 662
•The paper should disclose whether the full research project required more compute 663
than the experiments reported in the paper (e.g., preliminary or failed experiments that 664
didn’t make it into the paper). 665
9.Code Of Ethics 666
Question: Does the research conducted in the paper conform, in every respect, with the 667
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ? 668
Answer: [Yes] 669
Justification: We have reviewed the NeurIPS Code of Ethics. 670
Guidelines: 671
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. 672
•If the authors answer No, they should explain the special circumstances that require a 673
deviation from the Code of Ethics. 674
•The authors should make sure to preserve anonymity (e.g., if there is a special consid- 675
eration due to laws or regulations in their jurisdiction). 676
10.Broader Impacts 677
Question: Does the paper discuss both potential positive societal impacts and negative 678
societal impacts of the work performed? 679
Answer: [Yes] 680
Justification: § 7 681
Guidelines: 682
• The answer NA means that there is no societal impact of the work performed. 683
•If the authors answer NA or No, they should explain why their work has no societal 684
impact or why the paper does not address societal impact. 685
•Examples of negative societal impacts include potential malicious or unintended uses 686
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations 687
(e.g., deployment of technologies that could make decisions that unfairly impact specific 688
groups), privacy considerations, and security considerations. 689
•The conference expects that many papers will be foundational research and not tied 690
to particular applications, let alone deployments. However, if there is a direct path to 691
any negative applications, the authors should point it out. For example, it is legitimate 692
to point out that an improvement in the quality of generative models could be used to 693
19generate deepfakes for disinformation. On the other hand, it is not needed to point out 694
that a generic algorithm for optimizing neural networks could enable people to train 695
models that generate Deepfakes faster. 696
•The authors should consider possible harms that could arise when the technology is 697
being used as intended and functioning correctly, harms that could arise when the 698
technology is being used as intended but gives incorrect results, and harms following 699
from (intentional or unintentional) misuse of the technology. 700
•If there are negative societal impacts, the authors could also discuss possible mitigation 701
strategies (e.g., gated release of models, providing defenses in addition to attacks, 702
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from 703
feedback over time, improving the efficiency and accessibility of ML). 704
11.Safeguards 705
Question: Does the paper describe safeguards that have been put in place for responsible 706
release of data or models that have a high risk for misuse (e.g., pretrained language models, 707
image generators, or scraped datasets)? 708
Answer: [NA] 709
Justification: This study does not contain any code, data nor trained model 710
Guidelines: 711
• The answer NA means that the paper poses no such risks. 712
•Released models that have a high risk for misuse or dual-use should be released with 713
necessary safeguards to allow for controlled use of the model, for example by requiring 714
that users adhere to usage guidelines or restrictions to access the model or implementing 715
safety filters. 716
•Datasets that have been scraped from the Internet could pose safety risks. The authors 717
should describe how they avoided releasing unsafe images. 718
•We recognize that providing effective safeguards is challenging, and many papers do 719
not require this, but we encourage authors to take this into account and make a best 720
faith effort. 721
12.Licenses for existing assets 722
Question: Are the creators or original owners of assets (e.g., code, data, models), used in 723
the paper, properly credited and are the license and terms of use explicitly mentioned and 724
properly respected? 725
Answer: [NA] 726
Justification: This study does not contain any code, data nor trained model 727
Guidelines: 728
• The answer NA means that the paper does not use existing assets. 729
• The authors should cite the original paper that produced the code package or dataset. 730
•The authors should state which version of the asset is used and, if possible, include a 731
URL. 732
• The name of the license (e.g., CC-BY 4.0) should be included for each asset. 733
•For scraped data from a particular source (e.g., website), the copyright and terms of 734
service of that source should be provided. 735
•If assets are released, the license, copyright information, and terms of use in the 736
package should be provided. For popular datasets, paperswithcode.com/datasets 737
has curated licenses for some datasets. Their licensing guide can help determine the 738
license of a dataset. 739
•For existing datasets that are re-packaged, both the original license and the license of 740
the derived asset (if it has changed) should be provided. 741
•If this information is not available online, the authors are encouraged to reach out to 742
the asset’s creators. 743
13.New Assets 744
Question: Are new assets introduced in the paper well documented and is the documentation 745
provided alongside the assets? 746
20Answer: [NA] 747
Justification: This study does not provide any code, data nor trained model 748
Guidelines: 749
• The answer NA means that the paper does not release new assets. 750
•Researchers should communicate the details of the dataset/code/model as part of their 751
submissions via structured templates. This includes details about training, license, 752
limitations, etc. 753
•The paper should discuss whether and how consent was obtained from people whose 754
asset is used. 755
•At submission time, remember to anonymize your assets (if applicable). You can either 756
create an anonymized URL or include an anonymized zip file. 757
14.Crowdsourcing and Research with Human Subjects 758
Question: For crowdsourcing experiments and research with human subjects, does the paper 759
include the full text of instructions given to participants and screenshots, if applicable, as 760
well as details about compensation (if any)? 761
Answer: [NA] 762
Justification: This study does not involve crowdsourcing nor research with human subjects. 763
Guidelines: 764
•The answer NA means that the paper does not involve crowdsourcing nor research with 765
human subjects. 766
•Including this information in the supplemental material is fine, but if the main contribu- 767
tion of the paper involves human subjects, then as much detail as possible should be 768
included in the main paper. 769
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, 770
or other labor should be paid at least the minimum wage in the country of the data 771
collector. 772
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human 773
Subjects 774
Question: Does the paper describe potential risks incurred by study participants, whether 775
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) 776
approvals (or an equivalent approval/review based on the requirements of your country or 777
institution) were obtained? 778
Answer: [NA] 779
Justification: This study does not involve crowdsourcing nor research with human subjects. 780
Guidelines: 781
•The answer NA means that the paper does not involve crowdsourcing nor research with 782
human subjects. 783
•Depending on the country in which research is conducted, IRB approval (or equivalent) 784
may be required for any human subjects research. If you obtained IRB approval, you 785
should clearly state this in the paper. 786
•We recognize that the procedures for this may vary significantly between institutions 787
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the 788
guidelines for their institution. 789
•For initial submissions, do not include any information that would break anonymity (if 790
applicable), such as the institution conducting the review. 791
21