Convergence Analysis of Split Federated Learning on
Heterogeneous Data
Pengchao Han∗
Guangdong University of Technology, China
hanpengchao@gdut.edu.cnChao Huang∗
Montclair State University, USA
huangch@montclair.edu
Geng Tian
Southern University of Science and Technology, China
12332463@mail.sustech.edu.cn
Ming Tang†
Southern University of Science and Technology, China
tangm3@sustech.edu.cnXin Liu
University of California, Davis, USA
xinliu@ucdavis.edu
Abstract
Split federated learning (SFL) is a recent distributed approach for collaborative
model training among multiple clients. In SFL, a global model is typically split into
two parts, where clients train one part in a parallel federated manner, and a main
server trains the other. Despite the recent research on SFL algorithm development,
the convergence analysis of SFL is missing in the literature, and this paper aims to
fill this gap. The analysis of SFL can be more challenging than that of federated
learning (FL), due to the potential dual-paced updates at the clients and the main
server. We provide convergence analysis of SFL for strongly convex and general
convex objectives on heterogeneous data. The convergence rates are O(1/T)and
O(1/3√
T), respectively, where Tdenotes the total number of rounds for SFL
training. We further extend the analysis to non-convex objectives and the scenario
where some clients may be unavailable during training. Experimental experiments
validate our theoretical results and show that SFL outperforms FL and split learning
(SL) when data is highly heterogeneous across a large number of clients.
1 Introduction
1.1 Motivation
Federated learning (FL) [ 18,9] allows distributed clients to train a global machine learning model
collaboratively without sharing raw data. FL leverages the parallel computing capabilities of clients
to enhance model training efficiency. However, FL is usually computationally intensive. Clients
need to train the entire global model multiple times, which can be infeasible for resource-constrained
edge devices. This challenge is further exacerbated as the trend towards increasingly larger model
architectures demands more substantial resources [ 1]. Moreover, FL suffers from the client drift
*Equal contribution.
†Corresponding author.
This work was partially supported by the National Natural Science Foundation of China (Grants 62202214
and 62401161), Guangdong Basic and Applied Basic Research Foundation (Grants 2023A1515012819 and
2022A1515110056), and USDA-020-67021-32855.
38th Conference on Neural Information Processing Systems (NeurIPS 2024)....
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . . . . . . . . . . . . . . . . . . . . . . . .Fed ServerMain ServerClientsCut Layerxc,1xs,1xc,2xc,Nxc...
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
 . . . . . . . . . . . . . . . . . . . . . . . .Fed ServerMain ServerClientsCut Layerxc,1xsxc,2xc,Nxc . . . . . . . . . . . .xs,2 . . . . . . . . . . . .xs,NSFL-V1SFL-V2Figure 1: An illustration of SFL framework, and there are two major algorithms, i.e., SFL-V1 (left)
and SFL-V2 (right) [27]. More discussions on SFL-V1 and SFL-V2 are given in Sec. 2.
problem when clients’ data distributions are heterogeneous, aka non-identically and independently
distributed (non-IID). A large number of studies have proposed algorithms to address the client drift
issue, e.g., [15, 10, 14, 25].
Split learning (SL) [ 28] is another distributed approach. By splitting the model across clients and a
main server, SL can substantially reduce the computational workload on edge devices. Moreover,
recent studies in [ 34,17] show that SL can outperform FL when data is highly heterogeneous.
However, SL’s sequential training among clients can lead to high latency in each training round
and potential performance loss (e.g., caused by catastrophic forgetting), which impedes its practical
applicability in real-world distributed systems.
In light of above challenges, Thapa et. al in [ 27] proposed split federated learning (SFL) as a hybrid
approach that synergizes the strengths of both FL and SL. SFL combines parallel training of FL with
partial model training of SL. They proposed two major SFL algorithms: SFL-V1 and SFL-V2. An
illustration of these SFL algorithms are shown in Fig. 1. Specifically, the global model (to be trained)
is first split at a cut layer into two parts: a client-side model and a server-side model. Then, the clients
are responsible for training only the client-side model under the coordination of a fed server (similar
to FL). Another server, known as the main server , is tasked with training the server-side model by
collaborating with the clients (similar to SL). SFL aims to leverage parallel processing to reduce
latency, while benefiting from the reduced computational workloads and enhanced data heterogeneity
handling of SL.
Following [ 27], there has been an emerging volume of empirical studies on SFL. e.g., [ 22,21,3,
23,8,31,5]. However, a convergence analysis of SFL is missing in the literature , and this paper
aims to provide a comprehensive convergence analysis under different conditions. Convergence
theory is crucial for understanding the learning performance of SFL, particularly in the context of
heterogeneous data andpartial participation scenarios. In practical distributed systems, clients are
prone to have different data distributions. Moreover, not all clients may be active or available at all
times. These two issues can significantly affect the learning performance of SFL. We aim to provide
convergence guarantees for SFL on heterogeneous data (under both full and partial participation). We
further compare the results to FL and SL, which provides insights into the practical deployment of
various distributed approaches.
1.2 Related Work
Convergence theories of FL and SL . There are many convergence results on FL. Most studies
focus on data heterogeneity, e.g., [ 30,16,11,10,12]. Some studies look at partial participation, e.g.,
[35,29,26]. There are also convergence results on Mini-Batch SGD, e.g., [ 24,33,32], where [ 33]
argued that the key difference between FL and Mini-Batch SGD is the communication frequency.
To our best knowledge, there is only one recent study [ 17] discussing the convergence of SL. The
major difference to SL analysis lies in the sequential training manner across clients, while SFL clients
perform parallel training.
21.3 Challenges and Contributions
Challenges of SFL convergence analysis . When data is homogeneous (IID) across clients, the
convergence theory in [ 12] (mainly developed for FL) can be applied to SFL. When data is het-
erogeneous, however, the theory cannot be directly applied due to the client drift problem. The
challenge is intensified with clients’ partial participation, which induces bias in the training process.
Despite that prior FL theories have handled data heterogeneity [ 16] and partial participation [ 29],
SFL convergence analysis imposes unique challenges due to the dual-paced model aggregation and
model updates at the client-side and server-side. More specifically,
Dual-paced model aggregation in SFL-V1 : In SFL-V1, the main server maintains one server-side
model for each client, and it periodically aggregates the server-side models. When the main server
aggregates its models at the same frequency as the clients, the analysis is the same to that of FL.
However, FL analysis cannot be applied when aggregations occur at different frequencies, and it is
challenging to analyze the impact of such discrepancy on SFL convergence.
Dual-paced model updates in SFL-V2 : In SFL-V2, the main server only maintains one version of
server-side model. The clients update the client-side models in a parallel manner while the main
server updates the server-side model in a sequential fashion. Hence, each client’s local update depends
on the randomness of the previous clients who have interacted with the main server. While [ 17]
handled sequential client training, their theory cannot be applied to SFL-V2 as they did not consider
the aggregation of client-side models. This makes our analysis more challenging than FL and SL.
Contributions . We summarize our contributions as follows:
•We provide the first comprehensive convergence analysis of SFL. The analysis is more
challenging than prior FL analysis due to the dual-paced model aggregation and model
updates. To this end, we derive a key decomposition result (Proposition 3.5) that enables us
to analyze the convergence from the server-side and client-side separately.
•Based on the decomposition result, we prove that the convergence guarantees of both SFL-
V1 and SFL-V2 are O(1/T)for strongly convex objective and O(1/3√
T)for general convex
objective, where Tdenotes the total number of rounds for SFL training. We further extend
the analysis to non-convex objectives and more practical scenarios where some clients may
be unavailable during training.
•We conduct simulations on various datasets. We show that the results are consistent with
our theories. We further show two surprising results: (i) SFL achieves a better performance
when clients maintain a larger portion of the global model; (ii) SFL-V2 outperforms FL and
SL when clients have highly heterogeneous data and the number of client is large.
The rest of the paper is organized as follows. Sec. 2 formulates the SFL model. Sec. 3 presents the
convergence results for SFL. We conduct experiments in Sec. 4 and conclude in Sec. 5.
2 Problem Formulation
2.1 Model
We consider a set of clients N={1,2,···, N}, where each client n∈ N has a local private dataset
Dnof size Dn=|Dn|. Suppose the global model parameterized by xhasLlayers. In SFL, the
global model is split at the Lc-th layer (i.e., the cut layer) into two segments: a client-side model
xc(from the first layer to layer Lc) and a server-side model xs(from layer Lc+ 1to layer L),
where x= [xc;xs]. Letxc,ndenote the local client-side model of client n. The clients train models
with the help of two servers: (i) fed server, which periodically aggregates clients’ local models xc,n
(similar to FL), and (ii) main server, who trains the server-side model xs. In this work, we consider
two major SFL algorithms: SFL-V1 and SFL-V2 [ 27]. In SFL-V1, the main server maintains a
separate server-side model xs,ncorresponding to each client n. In comparison, in SFL-V2, the main
server only maintains one model xs.
LetFn(x;ζn)denote the loss of model xover client n’s mini-batch instance ζn, which is randomly
sampled from client n’s dataset Dn. Let Fn(x)≜Eζn∼Dn[Fn(x;ζn)]denote the expected loss of
model xover client n’s dataset. The goal of SFL is to minimize the expected loss of the model x
3over the datasets of all clients:
min
xf(x) =NX
n=1anFn(x), (1)
where an∈[0,1]is the weight of client nsatisfyingP
n∈Nan= 1 . Typically, an=
Dn/P
n′∈NDn′, where a client with a larger data size is assigned a larger weight [34].
2.2 Algorithm Description
We provide a brief description of SFL. Refer to Appendix B for a more detailed discussion. SFL
takes a total number of Trounds to solve (1). At the beginning of each round t, clients download the
recent global client-side model from the fed server, where the model is an aggregated version of the
client-side models of the clients from the previous round t−1. Each round tcontains two stages:
Stage 1: model training . Clients and the main server train the full global model for τiterations in
each round. In each iteration i < τ , there are three steps:
Step 1: client forward propagation . Each client nsamples a mini-batch of data ζt,i
nfromDn,
computes the intermediate features (e.g., activation values at the cut layer) over its current model
xt,i
c,n, and sends the activation to the main server. The clients perform forward propagation in parallel.
Step 2: main server training . Upon receiving the activation of each client n,
•SFL-V1: the main server computes the loss using the current server-side model xt,i
s,n. It then
computes the gradients over xt,i
s,nto update the model. It also computes the gradient over
the activation at the cut layer, and sends it to client n.
•SFL-V2: the main server computes the loss Fn(
xt,i
c,n,xt,i
s	
), based on which it then
updates the server-side model xt,i
s. It also computes and sends the gradient over activation
at the cut layer to client n. Note that the main server sequentially interacts with the clients
in a randomized order.
Step 3: client backward propagation . Receiving gradient at the cut layer, each client ncomputes the
client-side gradient using the chain rule, and then updates its model xt,i
c,n.
Stage 2: model aggregation . Model aggregation can occur for both client-side and server-side
models. For the client side, after τiterations of model training (i.e., at the end of round t), each client
sends its current client-side model to the fed server. The fed server aggregates the clients’ models
(e.g., weighted averaging), which will be downloaded in the next round t+ 1:
xt+1
c←X
n∈Nanxt,τ
c,n. (2)
For the server side, (i) in SFL-V1, after ˜τiterations of training, the main server aggregates all server-
side models. Note that ˜τdoes not necessarily need to equal τ, but when equality holds, SFL-V1 can
be regarded as FL (despite the model splitting). (ii) In SFL-V2, no aggregation occurs since the main
server only maintains one model.
2.3 Client Participation
We consider two cases: (i) full participation where all clients are available during training. This
can model the scenarios where clients are organizations or companies who likely have sufficient
computation and communication resources [ 7]; (ii) partial participation where some clients may be
unavailable during training. This can model the cases where clients are edge devices (e.g., mobile
phones) that are usually resource-constrained and may be disconnected from the SFL process.
To model partial participation, we consider independent participation probabilities for each client,
allowing for arbitrary and heterogeneous participation probabilities. Specifically, we use qn∈[0,1]
to denote client n’s participation level (or probability), and q= (qn, n∈ N). Ifqn= 1, client
nparticipates in every round of SFL with probability one. If qn<1, client nis unavailable in
some rounds. Denote Pt(q)as the set of participating clients in round t. In the presence of partial
4participation, we need to modify (2) (and the potential server-side aggregation) to offset the incurred
bias:
xt+1
c←X
n∈Pt(q)an
qnxt,τ
c,n. (3)
3 Convergence Analysis
We first make technical assumptions in Sec. 3.1. Then, we present a key technical result in Sec. 3.2
to support the SFL convergence analysis. Finally, we provide the convergence results under full
participation and partial participation in Sec. 3.3 and Sec. 3.4, respectively.
3.1 Assumptions
We start with some conventional assumptions for convergence analysis in the FL literature.
Assumption 3.1. (S-Smoothness ) Each client n’s loss function FnisS-smooth. That is, for all
x,y∈Rd,
Fn(y)≤Fn(x) +⟨∇Fn(x),y−x⟩+S
2∥y−x∥2. (4)
The smoothness assumption holds for many loss functions in, for example, logistic regression,
softmax classifier, and l2-norm regularized linear regression [16].
Assumption 3.2. (Unbiased and bounded stochastic gradients with bounded variance ) The stochastic
gradients gn(·)ofFn(·)is unbiased with the variance bounded by σ2
n.
Eζn∼Dn[gn(x, ζn)] =∇Fn(x), (5)
Eζn∼Dnh
∥gn(x, ζn)− ∇Fn(x)∥2i
≤σ2
n. (6)
Assumption 3.3. (Bounded gradients ) The expected squared norm of stochastic gradients is bounded
byG2.
Eζn∼Dn∥gn(x, ζn)∥2≤G2. (7)
The value of σnmeasures the level of stochasticity.
Assumption 3.4. (Heterogeneity ) There exists an ϵ2such that the divergence between local and
global gradients is bounded by ϵ2.
∥∇Fn(x)− ∇f(x)∥2≤ϵ2. (8)
A larger ϵ2indicates a larger degree of data heterogeneity.
3.2 Decomposition
As discussed in Sec. 1.3, analyzing the performance bound of SFL can be more challenging than that
of conventional FL counterparts due to the dual-paced model aggregation and model updates. To
address this challenge, we decompose the convergence analysis into the server-side and client-side
updates, respectively. We give the decomposition below.
Proposition 3.5. (Convergence decomposition) Let x∗≜[x∗
c;x∗
s]denote the optimal global model
that minimizes f(·), andxT≜[xT
c;xT
s]is the global model obtained after Trounds of SFL training.
Under Assumption 3.1, we have
E
f(xT)
−f(x∗)≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
. (9)
The proof is given in Appendix C.4. Proposition 3.5 is particularly useful. It shows that despite the
challenging dual-paced updates, to bound the SFL performance gap, it suffices to separately bound
the gap at the server-side and client-side models. Note that our decomposition can be easily applied
to other distributed approaches such as SL. In addition, such a decomposition is not necessarily loose,
as our derived bounds for SFL achieve the same order as in FL (see Appendix H.2 for details).
53.3 Results under Full Participation
Built upon Proposition 3.5, we first present the convergence results under full participation. For
convenience, define
Ierr≜x0−x∗2, γ≜8S/µ−1, τ min≜min{τ,˜τ}, τ max≜max{τ,˜τ},(10)
and let ηtrepresent the learning rate at round t. Let f∗denotes the optimal global loss, i.e.,
f∗≜f(x∗). All results are obtained based on Assumptions 3.1-3.4. The convergence results for
SFL-V1 and SFL-V2 are summarized in Theorems 3.6 and 3.7, respectively1.
Theorem 3.6. ( SFL-V1: full participation )
µ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and ηt=4
µ˜τ(γ+t)for client-side model and
ηt=4
µτ(γ+t)for server-side model,
E
f(xT)
−f∗≤8SNPN
n=1a2
n 
2σ2
n+G2
µ2(γ+T)+768S2PN
n=1an 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+ 1)Ierr
2(γ+T).(11)
General convex : Let Assumptions 3.1 - 3.3 hold, and ηt≤1
2Sτmax,
E
f 
xT
−f∗≤SIerr
2(T+ 1)+1
2 
(˜τ2+τ2)IerrN
τ2
min(T+ 1)NX
n=1a2
n 
2σ2
n+G2!1
2
+1
2 
24(˜τ2+τ2)SIerr
τ2
min(T+ 1)NX
n=1an 
2σ2
n+G2!1
3
.(12)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and ηt≤minn
1
16Sτmax,τmin
8SNτ2maxPN
n=1a2no
,
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτmin 
f 
x0
−f∗
+8NS(τ2+˜τ2)
TτminNX
n=1a2
n 
σ2
n+ϵ2T−1X
t=0 
ηt2.(13)
Theorem 3.7. ( SFL-V2: full participation )
µ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and ηt=4
µ˜τ(γ+t)for client-side model and
ηt=4
µτ(γ+t)for server-side model,
E
f(xT)
−f∗≤8SNPN
n=1(a2
n+1) 
2σ2
n+G2
µ2(γ+T)+768S2PN
n=1(an+1) 
2σ2
n+G2
µ3(γ+T) (γ+1)+S(γ+1)Ierr
2(γ+T).
(14)
General convex : Let Assumptions 3.1 - 3.3 hold, and ηt≤1
2Sτ,
E
f 
xT
−f∗≤SIerr
2 (T+1)+1
2 
NIerr
T+1NX
n=1(a2
n+1 ) 
2σ2
n+G2!1
2
+1
2 
24SIerr
T+1NX
n=1(an+1 ) 
2σ2
n+G2!1
3
.
(15)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and ηt≤min1
16Sτ,1
8SN2τ	
,
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτ 
f 
x0
−f∗
+8NSτ
TNX
n=1(a2
n+ 1) 
σ2
n+ϵ2T−1X
t=0 
ηt2.(16)
1Following many existing works in FL (e.g., [ 10]), we consider E
f(xT)
−f∗and
1
TPT−1
t=0ηtE[∥∇xf(xt)∥2]as the performance metrics for (strongly) convex and non-convex objectives,
respectively.
6Proofs of Theorems 3.6-3.7 are given in Appendices D-E, respectively. We summarize the key
findings below.
Convergence rate . The convergence bounds of both SFL-V1 and SFL-V2 achieve an order of O(1/T)
on strongly convex (and non-convex) objectives. For general convex objectives, the convergence rate
becomes O(1/3√
T).2Note that our bounds match the existing bounds for FL and SL (in terms of the
order of T) on heterogeneous data for strongly convex objectives. For a more detailed comparison,
please refer to Appendix H.2.3
Impact of data heterogeneity . The convergence bounds increase as the level of data heterogeneity
increases. For example, in (13), the bound increases in ϵ2(see Assumption 3.4). This means that SFL
tends to perform worse when clients’ data are more heterogeneous, which is a commonly observed
phenomenon in distributed learning, e.g., FL.
Choice of learning rate. One should use a smaller learning rate when the number of local iteration τ
increases. This bears a similar spirit to [ 16]. In addition, our results indicate that a proper choice of
constant learning rate suffices for SFL convergence. It would be an interesting direction to investigate
whether diminishing learning rates are able to achieve faster convergence.
Comparison between SFL-V1 and SFL-V2 . The convergence results between the two SFL versions
are very similar, except that a2
n(andan) in SFL-V1 are replaced by a2
n+ 1(andan+ 1) in SFL-V2.
See (11) and (14) for an inspection. We will show in Sec. 4 that SFL-V1 and SFL-V2 achieve similar
accuracy (except under highly heterogeneous data).
3.4 Results under Partial Participation
Now, we present the results under partial participation.
Theorem 3.8. ( SFL-V1: partial participation )
µ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and ηt=4
µ˜τ(γ+t)for client-side model and
ηt=4
µτ(γ+t)for server-side model,
E
f(xT)
−f∗≤8SNPN
n=1a2
n
2σ2
n+G2+G2
qn
µ2(γ+T)+768S2PN
n=1an 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+1)Ierr
2(γ+T).(17)
General convex : Let Assumptions 3.1 - 3.3 hold, and ηt≤1
2Sτmax,
E
f 
xT
−f∗≤SIerr
2(T+ 1)+1
2 
(˜τ2+τ2)IerrN
τ2
min(T+ 1)NX
n=1a2
n
2σ2
n+G2+G2
qn!1
2
+1
2 
24(˜τ2+τ2)SIerr
τ2
min(T+ 1)NX
n=1an 
2σ2
n+G2!1
3
.(18)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and ηt≤min{1
16Sτmax,τmin
8SNτ2maxPN
n=1a2n
qn},
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτmin 
f 
x0
−f∗
+8NS(τ2+˜τ2)
TτminNX
n=1a2
n
qn 
σ2
n+ϵ2T−1X
t=0 
ηt2.(19)
Theorem 3.9. ( SFL-V2: partial participation )
µ-strongly convex : Let Assumptions 3.1 - 3.3 hold, and ηt=4
µ˜τ(γ+t)for client-side model and
ηt=4
µτ(γ+t)for server-side model,
E
f 
xT
−f∗≤8SNPN
n=1(a2
n+1 )
2σ2
n+G2+G2
qn
µ2(γ+T)+768S2PN
n=1(an+1 ) 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+1)Ierr
2(γ+T).
(20)
2Note that it might be counter-intuitive to observe looser bounds on general convex objectives than on
non-convex objectives. This is associated with different performance metrics used in the analysis, e.g., see the
left hand side of (12) and (13).
3We also compared SFL to FL and SL in terms of communication/computation overheads in Appendix H.3.
70 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
Lc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 2: Impact of the choice of cut layer on SFL performance.
General convex : Let Assumptions 3.1 - 3.3 hold, and ηt≤1
2Sτ,
E
f 
xT
−f∗≤SIerr
2(T+ 1)+1
2 
NIerr
T+ 1NX
n=1(a2
n+ 1)
2σ2
n+G2+G2
n
qn!1
2
+1
2 
24SIerr
T+ 1NX
n=1(an+ 1) 
2σ2
n+G2!1
3
.(21)
Non-convex : Let Assumptions 3.1, 3.2, and 3.4 hold, and ηt≤min
1
16Sτ,1
8SN2τPN
n=1a2n
qn
,
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτ(f(x0)−f∗)+8NSτ
TNX
n=1a2
n+ 1
qn 
σ2
n+ϵ2T−1X
t=0 
ηt2.(22)
The proofs are given in Appendices F-G.
Impact of partial participation . In practical cross-device settings, some clients may not participate
in all rounds of training, i.e., qn<1for some n. This brings an additional term G2/qnto the conver-
gence bound (e.g., see (12) and (18)), meaning that partial participation worsens SFL performance.
This is also observed in FL literature (e.g., [29]) and is consistent with our experimental results.
4 Experimental Results
4.1 Setup
We conduct experiments on CIFAR-10 and CIFAR-100 [ 13].4To simulate data heterogeneity, we
adopt the widely used Dirichlet distribution [ 6] with a controlling parameter β. Here, a smaller
βcorresponds to a higher level of data heterogeneity across clients. We use ResNet-18, which
contains four blocks, as the model structure and consider four types of model splitting represented
byLc={1,2,3,4}, where Lc=nmeans the model is split after the n-th residual block. We
consider two major distributed approaches as the benchmark, i.e., FL (in particular FedAvg [ 18])
and SL [ 28]. The learning rates for SFL-V1, SFL-V2, FL, and SL are set as 0.01. The batch-
sizebsis 128, and we run experiments for T= 200 rounds. Unless stated otherwise, we use
N= 10 ,β= 0.1,E= 5, where Eis the number of local epochs for client-side model aggregation
(i.e., every Etimes of training performed over each client’s dataset, their client-side models are
aggregated at the fed server), and hence τ=⌈Dn
bs⌉ ×E. We set τ= ˜τfor the fair comparison
to vanilla FL. The experiments are run on a CPU (Intel(R) Xeon(R) Gold 5320 at 2.20GHz) and
a GPU (A100-PCIE-80GB). Our codes are provided in https://github.com/TIANGeng708/
Convergence-Analysis-of-Split-Federated-Learning-on-Heterogeneous-Data .
4.2 Impact of system parameters on SFL performance
Impact of cut layer . We first investigate how the choice of the cut layer Lcaffects the SFL
performance. The results are reported in Fig. 2. We observe that for both SFL-V1 and SFL-V2,
4More experiments on FEMNIST are given in Appendix I.5.
80 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
=0.1
=0.5
=1
=
 (d) SFL-V2 on CIFAR-100.
Figure 3: Impact of data heterogeneity on SFL performance.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
q=0.2
q=0.5q=1 (d) SFL-V2 on CIFAR-100.
Figure 4: Impact of client participation on SFL performance.
the performance increases in Lc(i.e., clients have a larger proportion of the global model). This is
associated with our empirical observation that the average client gradient variance gets smaller with
Lc. Intuitively, a smaller gradient variance implies a lower degree of the client drift issue, which
leads to a better algorithm performance.5Based on this observation, we use Lc= 4for SFL (and SL)
for the following experiments.
Impact of data heterogeneity . We study the impact of data heterogeneity on SFL performance,
where we use β∈ {0.1,0.5,1,∞}, andβ=∞means clients have IID data. The results are reported
in Fig. 3. We observe that a higher level of data heterogeneity (i.e., a smaller β) leads to slower
algorithm convergence and a lower accuracy for both SFL-V1 and SFL-V2. The observation is
consistent with our convergence bound, e.g., in (16), the performance bound increases in ϵ2. Note
that the negative impact of heterogeneity is commonly observed in distributed learning literature
including FL [7] and SL [21].
Impact of partial participation . We study the impact of client participation and let qn=q∈
{0.2,0.5,1},∀n.The results are reported in Fig. 4. We observe that a lower level of participation
leads to less stable convergence and also a smaller accuracy. This is consistent with our convergence
results, e.g., in (20), the bound decreases in clients’ participation level qn. Partial participation is
expected in practical cross-device scenarios where clients are resourced-constrained edge devices. It
is important to develop efficient algorithms as well as effective incentive mechanisms to encourage
clients’ participation in SFL.
4.3 Comparison among SFL, FL, and SL.
We now compare SFL to FL and SL. We consider different combinations of data heterogeneity
β∈ {0.1,0.5}and cohort sizes N∈ {10,50,100}. The results are reported in Fig. 5. When data
is mildly heterogeneous (i.e., β= 0.5), SFL and FL have similar convergence rates and accuracy
performance. Note that SL seems to under-perform SFL and FL. We think this is mainly due to the
catastrophic forgetting issue, which has been observed in [21, 2].
SFL outperforms FL and SL under highly heterogeneous data and a large client number .
When data becomes more non-IID (i.e., β= 0.1), SFL-V2 tends to outperform FL and SL. The
improvement becomes more significant as the cohort size gets larger. The bottleneck of FL is the client
drift issue caused by data heterogeneity. The bottleneck of SL is associated with the catastrophic
forgetting. SFL-V2 is a hybrid combination of FL and SL, which can lead to a better tradeoff
between client drift and forgetting. By appropriately choosing the cut layer, SFL-V2 outperforms
5See Appendix I.4 for more detailed discussions on this point.
90 50 100 150 200
Training Round020406080100Accuracy
SFL-V1
SFL-V2FL
SL(a)β= 0.5, N= 10 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (b)β= 0.1, N= 10 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (c)β= 0.1, N= 50 .
0 50 100 150 200
Training Round020406080100AccuracySFL-V1
SFL-V2FL
SL (d)β= 0.1, N= 100 .
Figure 5: Performance comparison on CIFAR-10.
FL and SL. This observation also indicates that SFL-V2 can be a more appealing solution than
FL for practical cross-device systems, as it achieves a better performance while requiring smaller
computation overheads from edge devices.
5 Conclusion
In this work, we provided the first comprehensive convergence analysis of SFL for strongly convex,
general-convex, and non-convex objectives on heterogeneous data. One key challenge is the dual-
paced model updates. We get around this issue by decomposing the performance gap of the global
model into the client-side and server-side gaps. We further extend our analysis to the more practical
scenario with partial client participation. Experimental experiments validate our theories and further
show that SFL can outperform FL and SL under highly heterogeneous data and a large client number.
One limitation of our work is that our bounds for SFL achieve the same order (in terms of training
rounds) as in FL, yet the experiments showed that SFL outperforms FL under high heterogeneity.
This is possibly due to that tighter bounds for SFL are to be derived, which is an important future
work. For future work, one can apply our derived bounds to optimize SFL system performance,
considering model accuracy, communication overhead, and computational workload of clients. It is
also interesting to theoretically analyze how the choice of the cut layer affects the SFL performance.
10References
[1]Ahmed M Abdelmoniem, Atal Narayan Sahu, Marco Canini, and Suhaib A Fahmy. Refl:
Resource-efficient federated learning. In Proceedings of the Eighteenth European Conference
on Computer Systems , pages 215–232, 2023.
[2]Yansong Gao, Minki Kim, Sharif Abuadbba, Yeonjae Kim, Chandra Thapa, Kyuyeon Kim,
Seyit A Camtepe, Hyoungshick Kim, and Surya Nepal. End-to-end evaluation of federated
learning and split learning for internet of things. arXiv preprint arXiv:2003.13376 , 2020.
[3]Dong-Jun Han, Hasnain Irshad Bhatti, Jungmoon Lee, and Jaekyun Moon. Accelerating
federated learning with split learning on locally generated losses. In ICML workshop on
federated learning for user privacy and data confidentiality , 2021.
[4]Dong-Jun Han, Do-Yeon Kim, Minseok Choi, Christopher G Brinton, and Jaekyun Moon.
Splitgp: Achieving both generalization and personalization in federated learning. Proc. of IEEE
INFOCOM , 2023.
[5]Pengchao Han, Chao Huang, Xingyan Shi, Jianwei Huang, and Xin Liu. Incentivizing partici-
pation in splitfed learning: Convergence analysis and model versioning. In 2024 IEEE 44th
International Conference on Distributed Computing Systems (ICDCS) , pages 846–856, 2024.
[6]Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical
data distribution for federated visual classification. arXiv preprint arXiv:1909.06335 , 2019.
[7]Chao Huang, Shuqi Ke, and Xin Liu. Duopoly business competition in cross-silo federated
learning. IEEE Transactions on Network Science and Engineering , 2023.
[8]Chao Huang, Geng Tian, and Ming Tang. When minibatch sgd meets splitfed learning: Conver-
gence analysis and performance evaluation. arXiv preprint arXiv:2308.11953 , 2023.
[9]Yang Jiao, Kai Yang, Tiancheng Wu, Chengtao Jian, and Jianwei Huang. Provably convergent
federated trilevel learning. In Proceedings of the AAAI Conference on Artificial Intelligence ,
volume 38, pages 12928–12937, 2024.
[10] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In
International conference on machine learning , pages 5132–5143. PMLR, 2020.
[11] Ahmed Khaled, Konstantin Mishchenko, and Peter Richtárik. Tighter theory for local sgd on
identical and heterogeneous data. In International Conference on Artificial Intelligence and
Statistics , pages 4519–4529. PMLR, 2020.
[12] Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A
unified theory of decentralized sgd with changing topology and local updates. In International
Conference on Machine Learning , pages 5381–5393. PMLR, 2020.
[13] Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
[14] Qinbin Li, Bingsheng He, and Dawn Song. Model-contrastive federated learning. In Proceedings
of the IEEE/CVF conference on computer vision and pattern recognition , pages 10713–10722,
2021.
[15] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia
Smith. Federated optimization in heterogeneous networks. Proceedings of Machine learning
and systems , 2:429–450, 2020.
[16] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence
of fedavg on non-iid data. In Proc. of ICLR , 2020.
[17] Yipeng Li and Xinchen Lyu. Convergence analysis of sequential federated learning on het-
erogeneous data. In Thirty-seventh Conference on Neural Information Processing Systems ,
2023.
11[18] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
Communication-efficient learning of deep networks from decentralized data. In Artificial
intelligence and statistics , pages 1273–1282. PMLR, 2017.
[19] Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub Kone ˇcn`y,
Sanjiv Kumar, and H Brendan McMahan. Adaptive federated optimization. arXiv preprint
arXiv:2003.00295 , 2020.
[20] Sashank Reddi, Zachary Burr Charles, Manzil Zaheer, Zachary Garrett, Keith Rush, Jakub
Kone ˇcný, Sanjiv Kumar, and Brendan McMahan, editors. Adaptive Federated Optimization ,
2021.
[21] Jinglong Shen, Nan Cheng, Xiucheng Wang, Feng Lyu, Wenchao Xu, Zhi Liu, Khalid Al-
dubaikhy, and Xuemin Shen. Ringsfl: An adaptive split federated learning towards taming
client heterogeneity. IEEE Transactions on Mobile Computing , 2023.
[22] Chamani Shiranthika, Zahra Hafezi Kafshgari, Parvaneh Saeedi, and Ivan V Baji ´c. Splitfed
resilience to packet loss: Where to split, that is the question. In International Conference on
Medical Image Computing and Computer-Assisted Intervention , pages 367–377. Springer, 2023.
[23] Veronika Stephanie, Ibrahim Khalil, and Mohammed Atiquzzaman. Digital twin enabled
asynchronous splitfed learning in e-healthcare systems. IEEE Journal on Selected Areas in
Communications , 41(11):3650–3661, 2023.
[24] Sebastian U Stich. Unified optimal analysis of the (stochastic) gradient method. arXiv preprint
arXiv:1907.04232 , 2019.
[25] Yue Tan, Yixin Liu, Guodong Long, Jing Jiang, Qinghua Lu, and Chengqi Zhang. Federated
learning on non-iid graphs via structural knowledge sharing. In Proceedings of the AAAI
conference on artificial intelligence , volume 37, pages 9953–9961, 2023.
[26] Ming Tang and Vincent WS Wong. Tackling system induced bias in federated learning:
Stratification and convergence analysis. In Proc. of IEEE INFOCOM , pages 1–10, 2023.
[27] Chandra Thapa, Pathum Chamikara Mahawaga Arachchige, Seyit Camtepe, and Lichao Sun.
Splitfed: When federated learning meets split learning. In Proc. of AAAI , volume 36, pages
8485–8493, 2022.
[28] Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. Split learning for
health: Distributed deep learning without sharing raw patient data. ICLR Workshop on AI for
Social Good , 2019.
[29] Shiqiang Wang and Mingyue Ji. A unified analysis of federated learning with arbitrary client
participation. Advances in Neural Information Processing Systems , 35:19124–19137, 2022.
[30] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He,
and Kevin Chan. Adaptive federated learning in resource constrained edge computing systems.
IEEE journal on selected areas in communications , 37(6):1205–1221, 2019.
[31] Dinah Waref and Mohammed Salem. Split federated learning for emotion detection. In 2022
4th Novel Intelligent and Leading Emerging Sciences Conference (NILES) , pages 112–115.
IEEE, 2022.
[32] Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan
Mcmahan, Ohad Shamir, and Nathan Srebro. Is local sgd better than minibatch sgd? In
International Conference on Machine Learning , pages 10334–10343. PMLR, 2020.
[33] Blake E Woodworth, Kumar Kshitij Patel, and Nati Srebro. Minibatch vs local sgd for heteroge-
neous distributed learning. Advances in Neural Information Processing Systems , 33:6281–6292,
2020.
[34] Wen Wu, Mushu Li, Kaige Qu, Conghao Zhou, Xuemin Shen, Weihua Zhuang, Xu Li, and
Weisen Shi. Split learning over wireless networks: Parallel design and resource management.
IEEE Journal on Selected Areas in Communications , 41(4):1051–1066, 2023.
[35] Haibo Yang, Minghong Fang, and Jia Liu. Achieving linear speedup with partial worker
participation in non-iid federated learning. Proc. of ICLR , 2021.
12A Appendix / supplemental material
We organize the entire appendix file as follows:
In Sec. B, we provide detailed algorithmic descriptions.
In Sec. C, we provide notations and some technical lemmas.
• In Sec. C.1, we provide some notations
• In Sec. C.2, we recall SFL-V1 and SFL-V2
• In Sec. C.3, we recall the assumptions
• In Sec. C.4, we provide some useful technical lemmas together with their proofs
In Sec. D, we prove Theorem 3.6, i.e., convergence of SFL-V1 under full participation .
• In Sec. D.1, we prove the strongly convex case
• In Sec. D.2, we prove the general convex case
• In Sec. D.3, we prove the non-convex case
In Sec. E, we prove Theorem 3.7, i.e., convergence of SFL-V2 under full participation .
• In Sec. E.1, we prove the strongly convex case
• In Sec. E.2, we prove the general convex case
• In Sec. E.3, we prove the non-convex case
In Sec. F, we prove Theorem 3.8, i.e., convergence of SFL-V1 under partial participation .
• In Sec. F.1, we prove the strongly convex case
• In Sec. F.2, we prove the general convex case
• In Sec. F.3, we prove the non-convex case
In Sec. G, we prove Theorem 3.9, i.e., convergence of SFL-V2 under partial participation .
• In Sec. G.1, we prove the strongly convex case
• In Sec. G.2, we prove the general convex case
• In Sec. G.3, we prove the non-convex case
In Sec. H, we SFL to other distributed approaches, i.e., FL, SL, and Mini-Batch SGD.
• In Sec. H.2, we compare their convergence bounds
• In Sec. H.3, we compare their overheads in terms of communication and computation
In Sec. I, we provide more experimental results.
13B Algorithm description
For version 1, the client-side model parameter and M-server-side model parameter are aggregated
every τand˜τiterations, respectively. In iteration iof round t, each client nsamples a mini-batch
of data ζt,i
nfromDn, computes the intermediate features h(xt,i
c,n;ζt,i
n)(e.g., activation values at
the cut layer) over its current model xt,i
c,n, and sends h(xt,i
c,n;ζt,i
n)to the M-server. For each client
n, the M-server computes the loss Fn(h(xt,i
c,n;ζt,i
n),xt,i
s,n)based on xt,i
s,n. Let∇denote a gradient
operator and ∇wFrepresents the gradient of Fw.r.t.w. The M-server computes the M-server-side
gradient gt,i
s,n(xt,i
s,n;ζt,i
n) =∇xsFn(h(xt,i
c,n;ζt,i
n),xt,i
s,n), the gradient over the intermediate features
(activations) at the cut layer rt,i
c,n(xt,i
s,n;ζt,i
n) =∇hFn(h(xt,i
c,n;ζt,i
n),xt,i
s,n), and sends rt,i
c,n(xt,i
s,n;ζt,i
n)
to client n. Each client ncomputes the client-side gradient gt,i
c,n(xt,i
c,n;ζt,i
n)based on rt,i
c,n(xt,i
s,n;ζt,i
n)
using the chain rule.
For version 2, the client-side model is aggregated every τiterations, while the M-server trains only
one version of the M-server-side model.
Algorithm 1: SFL-V1 under clients’ partial participation
Input: τ,˜τ, T, and learning rate ηt
Output: Global model xT={xT
c,xT
s}
1Initialize x0={x0
c,x0
s};
2fori= 0, . . . , (T−1)τmaxdo
3 Determine participating client set Pt⊆ N according to qn;
Phase 1: model training.
4 each client n∈ Pt:
5 Sample a mini-batch ζt,i
n;
6 Send h(xt,i
c,n;ζt,i
n)to the M-server;
7 the M-server:
8 Compute Fn(h(xt,i
c,n;ζt,i
n),xt,i
s),gt,i
s,n(xt,i
s,n;ζt,i
n), and
rt,i
c,n(xt,i
s,n;ζt,i
n);
9 Sendrt,i
c,n(xt,i
s,n;ζt,i
n)to client n∈ Pt;
10 xt,i+1
s,n←xt,i
s,n−ηtgt,i
s,n(xt,i
s,n;ζt,i
n);
11 Compute gt,i
c,n(xt,i
c,n;ζt,i
n);
12 xt,i+1
c,n←xt,i
c,n−ηtgt,i
c,n(xt,i
c,n;ζt,i
n);
Phase 2: model aggregation.
13 ifi%τ= 0then
14 each client n∈ Pt:
15 Sendxt,τ
c,nto the F-server;
16 the F-server:
17 xt+1
c←P
n∈Ptan
qnxt,τ
c,n;
18 each client n∈ N :
19 xt,0
c,n←xt
c;
20 ifi%˜τ= 0then
21 the M-server:
22 xt+1
s←P
n∈Ptan
qnxt,˜τ
s,n.
23 xt,0
s,n←xt
s,∀n∈ N ;
14Algorithm 2: SFL-V2 under clients’ partial participation
Input: τ, T, and learning rate ηt
Output: Global model xT={xT
c,xT
s}
1Initialize x0={x0
c,x0
s};
2fort= 0, . . . , T −1do
3 Determine participating client set Pt⊆ N according to qn;
Phase 1: model training.
4 each client n∈ Pt:
5 xt,0
c,n←xt
c;
6 fori= 0, . . . , τ −1do
7 Sample a mini-batch ζt,i
n;
8 Send h(xt,i
c,n;ζt,i
n)to the M-server;
9 the M-server:
10 Compute Fn(h(xt,i
c,n;ζt,i
n),xt,i
s),gt,i
s,n(xt,i
s;ζt,i
n), and
rt,i
c,n(xt,i
s;ζt,i
n);
11 Sendrt,i
c,n(xt,i
s;ζt,i
n)to client n∈ Pt;
12 xt,i+1
s←xt,i
s−ηt
qngt,i
s,n(xt,i
s;ζt,i
n);
13 Compute gt,i
c,n(xt,i
c,n;ζt,i
n);
14 xt,i+1
c,n←xt,i
c,n−ηtgt,i
c,n(xt,i
c,n;ζt,i
n);
15 the M-server:
16 xt+1,0
s←xt,τ
s;
Phase 2: model aggregation.
17 each client n∈ Pt:
18 Sendxt,τ
c,nto the F-server;
19 the F-server:
20 xt+1
c←P
n∈Ptan
qnxt,τ
c,n.
15C Notations and technical lemmas
C.1 Notations
Recall that the objective of SFL is given by
min
xf(x) :=NX
n=1anFn(x) (23)
We define
•xcandxs: global model parameter on the clients and server sides, respectively.
•xc,nandxs,n: local forms of parameter on client nand on the main server corresponding
to client n(in SFL-V1).
•∇Fc,n(·)and∇Fs,n(·): the gradients of Fn(·)overxcandxs, respectively.
•gc,n(·)andgs,n(·): the stochastic gradients of Fn(·)overxcandxs, respectively.
For convenience, we omit the notation for mini-batch training data when referring to stochastic
gradients.
Further, we recall how SFL-V1 and SFL-V2 update models below.
C.2 SFL-V1 and SFL-V2 model updates
Letqndenote the participating probability of client nand define q:={q1, . . . , q N}. We denote It
n
as a binary variable, taking 1 if client nparticipates in model training in round t, and 0 otherwise. It
n
follows a Bernoulli distribution with an expectation of qn. Denote Pt(q)as the set of participating
clients in round t.
Parameter update for SFL-V1:
• Local training of client n:xt,0
c,n←xt
c,xt,i+1
c,n←xt,i
c,n−ηtgt,i
c,n 
xt,i
c,n
,xt+1
c,n←xt,τ
c,n;
• Client-side global aggregation:
–Full participation: xt+1
c←xt
c−ηtP
n∈NanPτ
i=0gt,i
c,n 
xt,i
c,n
;
–Partial participation: xt+1
c←xt
c−ηtP
n∈Pt(q)an
qnPτ
i=0gt,i
c,n 
xt,i
c,n
;
• M-server-side model update:
–Full participation: xt+1
s←xt
s−ηtP
n∈NanP˜τ−1
i=0gt,i
s,n 
xt,i
s,n
;
–Partial participation: xt+1
s←xt
s−ηtP
n∈Pt(q)an
qnP˜τ−1
i=0gt,i
s,n 
xt,i
s,n
.
Parameter update for SFL-V2:
• Local training of client n:xt,0
c,n←xt
c,xt,i+1
c,n←xt,i
c,n−ηtgt,i
c,n 
xt,i
c,n
,xt+1
c,n←xt,τ
c,n;
• Client-side global aggregation:
–Full participation: xt+1
c←xt
c−ηtP
n∈NanPτ
i=0gt,i
c,n 
xt,i
c,n
;
–Partial participation: xt+1
c←xt
c−ηtP
n∈Pt(q)an
qnPτ
i=0gt,i
c,n 
xt,i
c,n
;
• M-server-side model update:
–Full participation: xt+1
s←xt
s−ηtP
n∈NPτ−1
i=0gt,i
s,n 
xt,i
s,n
;
–Partial participation: xt+1
s←xt
s−ηtP
n∈Pt(q)1
qnPτ−1
i=0gt,i
s,n 
xt,i
s,n
.
C.3 Assumptions
We further recall the following assumptions for clients’ loss functions in the proof.
Assumption C.1. For each client n∈ N :
16• The loss Fn(·)isS-smooth:
∥∇Fn(x)− ∇Fn(y)∥ ≤S∥x−y∥,∀x,y, (24)
Fn(y)≤Fn(x) +⟨∇Fn(x),y−x⟩+S
2∥y−x∥2,∀x,y∈Rd. (25)
• The stochastic gradients of Fn(·)are unbiased with the variance bounded by σ2
n:
E[gn(x)] =∇Fn(x), (26)
Eh
∥gn(x)− ∇Fn(x)∥2i
≤σ2
n. (27)
• The expected squared norm of stochastic gradients is bounded by G2:
E∥gn(x)∥2≤G2. (28)
•(Bounded gradient divergence) There exists a constant ϵ >0, such that the divergence
between local and global gradients is bounded by ϵ2:
∥∇Fn(x)− ∇f(x)∥2≤ϵ2. (29)
Assumption C.2. For each client n∈ N :
• The loss Fn(·)isµ-strongly convex for some µ≥0:
Fn(y)≥Fn(x) +⟨∇Fn(x),y−x⟩+µ
2∥y−x∥2,∀x,y∈Rd. (30)
Here, we allow that µ= 0, referring to this case of the general convex.
C.4 Technical Lemmas
Lemma C.3. [Lemma 5 in [ 10]] The following holds for any S-smooth and µ-strongly convex
function h, and any x, y, z in the domain of h:
⟨∇h(x),z−y⟩ ≥h(z)−h(y) +µ
4∥y−z∥2−S∥z−x∥2. (31)
Proof of Proposition 3.5
Proposition 3.5 (Convergence decomposition) Let x∗≜[x∗
c;x∗
s]denote the optimal global model
that minimizes f(·), andxT≜[xT
c;xT
s]is the global model obtained after Trounds of SFL training.
Under Assumption 3.1, we have
E
f(xT)
−f(x∗)≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
. (32)
Proof. Since Fn’s are S-smooth, it is easy to show that the global loss function f(·)is also S-smooth.
Thus, we have
E
f(xT)
−f(x∗)≤E
⟨xT−x∗,∇f(x∗)⟩
+S
2E
||xT−x∗||2
=S
2E
||xT−x∗||2
. (33)
SincexT≜[xT
c;xT
s], andx∗≜[x∗
c;x∗
s], we have
E
||xT−x∗||2
=E
||[xT
c;xT
s]−[x∗
c;x∗
s]||2
=E
||[xT
c−x∗
c;xT
s−x∗
s]||2
=E
||xT
c−x∗
c||2
+E
||xT
s−x∗
s||2
.(34)
Substituting (34) into (33), we complete the proof.
Proposition C.4 (Decomposition in each round) .Under Assumption C.1, we have
E
f 
xt+1
−f 
xt
≤E
∇xcf 
xt
,xt+1
c−xt
c
+S
2Ehxt+1
c−xt
c2i
+ (35)
E
∇xsf 
xt
,xt+1
s−xt
s
+S
2Ehxt+1
s−xt
s2i
. (36)
17Proof. The proposition can be easily proved by the S-smoothness of f(·).
Lemma C.5. [Multiple iterations of local training in each round] Under Assumption C.1, if we let
ηt≤1√
6Sτand run client n’s local model for τiteration continuously in any round t, we have
τ−1X
i=0Ehxt,i
n−xt2i
≤12τ3 
ηt2 
2σ2
n+G2
. (37)
Proof. Similar to Lemma 3 in [20], we have
Ehxt,i
n−xt2i
≤Ehxt,i−1
n−ηtgt,i−1
n−xt2i
≤Ehxt,i−1
n−xt−ηt 
gt,i−1
n−∇xFn 
xt,i−1
n
+∇xFn 
xt,i−1
n
−∇xFn 
xt
+∇xFn 
xt2i
≤
1 +1
τ
Ehxt,i−1
n−xt2i
+ 3 (1 + τ)Ehηt 
gt,i−1
n− ∇xFn 
xt,i−1
n2i
+ 3 (1 + τ)Ehηt 
∇xFn 
xt,i−1
n
− ∇xFn 
xt2i
+ 3 (1 + τ)Ehηt 
∇xFn 
xt2i
≤
1 +1
τ
Ehxt,i−1
n−xt2i
+ 3 (1 + τ) 
ηt2σ2
n
+ 3 (1 + τ) 
ηt2S2Ehxt,i−1
n−xt2i
+ 3 (1 + τ) 
ηt2Eh∇xFn 
xt2i
≤
1 +1
τ+ 6τ 
ηt2S2
Ehxt,i−1
n−xt2i
+ 6τ 
ηt2σ2
n+ 6τ 
ηt2Eh∇xFn 
xt2i
≤
1 +2
τ
Ehxt,i−1
n−xt2i
+ 6τ 
ηt2σ2
n+ 6τ 
ηt2Eh∇xFn 
xt2i
,
≤
1+2
τ
Ehxt,i−1
n−xt2i
+6τ 
ηt2σ2
n+6τ 
ηt2
Eh∇xFn 
xt
−gt
n2i
+Eh∇xgt
n2i
,
≤
1 +2
τ
Ehxt,i−1
n−xt2i
+ 6τ 
ηt2 
2σ2
n+G2
, (38)
where we use Assumption C.1, (X+Y)2≤(1 +a)X2+ 
1 +1
a
Y2for some positive a, and
ηt≤1√
6Sτ.
Let
At,i:=Ehxt,i
n−xt2i
B:= 6τ 
ηt2 
2σ2
n+G2
C:= 1 +2
τ
We have
At,i≤CAt,i−1+B (39)
We can show that
At,1≤CAt+B
At,2≤CAt,1+B≤C2At+CB+B
At,3≤CAt,2+B≤C3At+C2B+CB+B
. . .
At,i≤CiAt+Bi−1X
j=0Cj
18Note that At:=At,0=Eh
∥xt−xt∥2i
= 0. Accumulate the above for τiterations, we have
τ−1X
i=0Ehxt,i
n−xt2i
=τ−1X
i=0Bi−1X
j=0Cj
=Bτ−1X
i=0Ci−1
C−1=B
C−1τ−1X
i=0 
Ci−1
=B
C−1Cτ−1
C−1−τ
=B
2
τ  
1 +2
ττ−1
2
τ−τ!
(40)
≤τ2B
2e2−1
2−1
≤2τ2B
≤2τ26τ 
ηt2 
2σ2
n+G2
≤12τ3 
ηt2 
2σ2
n+G2
. (41)
The first inequality is due toPN−1
i=0xi=xN−1
X−1and the third line results from (1 +n
x)x≤en. Thus,
we finish the proof.
Lemma C.6. [Multiple iterations of local training in each round] Under Assumption C.1, if we let
ηt≤1√
8Sτand run client n’s local model for τiteration continuously in any round t, we have
τ−1X
i=0Ehxt,i
n−xt2i
≤2τ2
8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xf 
xt2
. (42)
Proof.
Ehxt,i
n−xt2i
≤Ehxt,i−1
n−ηtgt,i−1
n−xt2i
≤Ext,i−1
n−xt−ηt 
gt,i−1
n− ∇xFn 
xt,i−1
n
+∇xFn 
xt,i−1
n
− ∇xFn 
xt
+∇xFn 
xt
− ∇xf 
xt
+∇xf 
xt2i
≤
1 +1
τ
Ehxt,i−1
n−xt2i
+ 8τEhηt 
gt,i−1
n− ∇xFn 
xt,i−1
n2i
+ 8τEhηt 
∇xFn 
xt,i−1
n
− ∇xFn 
xt2i
+ 8τEhηt 
∇xFn 
xt
− ∇xf 
xt2i
+ 8τηt∇xf 
xt2
≤
1 +1
τ
Ehxt,i−1
n−xt2i
+ 8τ 
ηt2σ2
n+ 8τ 
ηt2S2Ehxt,i−1
n−xt2i
+ 8τ 
ηt2ϵ2
+ 8τ 
ηt2∇xf 
xt2
≤
1+1
τ+8τ 
ηt2S2
Ehxt,i−1
n−xt2i
+8τ 
ηt2σ2
n+8τ 
ηt2ϵ2+8τ 
ηt2∇xf 
xt2
≤
1 +2
τ
Ehxt,i−1
n−xt2i
+ 8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xf 
xt2(43)
where we have applied Assumption C.1, (X+Y)2≤(1 +a)X2+ 
1 +1
a
Y2for some positive
a, and ηt≤1√
8Sτ.
Let
At,i:=Ehxt,i
n−xt2i
19B:= 8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xf 
xt2
C:= 1 +2
τ
We have
At,i≤CAt,i−1+B (44)
We can show that
At,i≤CiAt+Bi−1X
j=0Cj
Note that At=Eh
∥xt−xt∥2i
= 0. Accumulate the above for τiterations, we have
τ−1X
i=0Ehxt,i
n−xt2i
=τ−1X
i=0Bi−1X
j=0Cj
≤2τ2B
≤2τ2
8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xf 
xt2
(45)
where we usePN−1
i=0xi=xN−1
X−1and(1 +n
x)x≤en. Therefore, we complete the proof.
Lemma C.7. [Multiple iterations of local gradient accumulation in each round] Under Assumption
C.1, if we let ηt≤1
2Sτand run client n’s local model for τiteration continuously in any round t, we
have
τ−1X
i=0Ehgt,i
n−gt
n2i
≤8τ3 
ηt2S2∇xFn 
xt2+σ2
n
. (46)
Proof.
Ehgt,i
n−gt
n2i
≤Ehgt,i
n−gt,i−1
n+gt,i−1
n−gt
n2i
≤(1 +τ)Ehgt,i
n−gt,i−1
n2i
+
1 +1
τ
Ehgt,i−1
n−gt
n2i
≤(1 +τ)S2Ehxt,i
n−xt,i−1
n2i
+
1 +1
τ
Ehgt,i−1
n−gt
n2i
≤(1 +τ) 
ηt2S2Ehgt,i−1
n2i
+
1 +1
τ
Ehgt,i−1
n−gt
n2i
≤(1 +τ) 
ηt2S2Ehgt,i−1
n−gt
n+gt
n2i
+
1 +1
τ
Ehgt,i−1
n−gt
n2i
≤2 (1 + τ) 
ηt2S2Ehgt,i−1
n−gt
n2i
+ 2 (1 + τ) 
ηt2S2Ehgt
n2i
+
1 +1
τ
Ehgt,i−1
n−gt
n2i
≤
1 +2
τ
Ehgt,i−1
n−gt
n2i
+ 2 (1 + τ) 
ηt2S2Ehgt
n2i
. (47)
We define the following notation for simplicity:
At,i:=Ehgt,i
n−gt
n2i
(48)
20B:= 2 (1 + τ) 
ηt2S2Ehgt
n2i
(49)
C:=
1 +2
τ
(50)
We have
At,i≤CAt,i−1+B (51)
We can show that
At,i≤CiAt+Bi−1X
j=0Cj
Note that At=Eh
∥gt
n−gt
n∥2i
= 0. For the second part, we have
τ−1X
i=0Ehgt,i
n−gt
n2i
=τ−1X
i=0Bi−1X
j=0Cj≤2τ2B
≤4τ2(1 +τ) 
ηt2S2Ehgt
n2i
≤8τ3 
ηt2S2Ehgt
n2i
≤8τ3 
ηt2S2∇xFn 
xt2+σ2
n
. (52)
21D Proof for Theorem 3.6
We organize the proof of Theorem 3.6 as follows:
• In Sec. D.1, we prove the strongly convex case.
• In Sec. D.2, we prove the general convex case.
• In Sec. D.3, we prove the non-convex case.
D.1 Strongly convex case for SFL-V1
D.1.1 One-round Parallel Update for M-Server-Side Model
Lemma D.1. Under Assumptions C.1 and C.2, if ηt≤1
2S˜τ, in round t, the M-server-side model
evolves as
Ehxt+1
s−x∗
s2i
≤
1−ηt˜τµ
2
Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2(˜τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(˜τ)3 
ηt3NX
n=1an 
2σ2
n+G2
. (53)
We prove Lemma D.1 as follows.
Proof. We use xt,i
s,nas the M-server-side model when the M-server interacts with client nfor
thei-th iteration of model training at round t. Using the (sequential) gradient update rule of
xt+1
s=xt
s−ηtPN
n=1P˜τ−1
i=0angt,i
s,n 
xt,i
c,n,xt,i
s,n	
, we have
Ehxt+1
s−x∗
s2i
=E
xt
s−ηt˜τ−1X
i=0gt,i
s−x∗
s−ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
+ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

=E
xt
s−x∗
s−ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

+ 2ηtE"*
xt
s−x∗
s−ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
,˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
−˜τ−1X
i=0gt,i
s+#
+E
 
ηt2˜τ−1X
i=0gt,i
s−˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

≤E
xt
s−x∗
s−ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

+ 
ηt2E
NX
n=1˜τ−1X
i=0angt,i
s,n−˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2
. (54)
where the second equality is from (a+b)2=a2+ 2ab+b2and the last inequality is due to
E
∇xsf 
xt,i
c,xt,i
s	
−gt,i
s
= 0.
The first part in (54) is
E
xt
s−x∗
s−ηt˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

22≤Ehxt
s−x∗
s2i
+ 
ηt2˜τNNX
n=1˜τ−1X
i=0a2
nEh∇xsFn 
xt,i
c,n,xt,i
s,n	2i
−2ηtE"NX
n=1˜τ−1X
i=0an
xt
s−x∗
s,∇xsFn 
xt,i
c,xt,i
s	#
, (55)
where we use ∇xsf({xc,xs}) =PN
n=1an∇xsFn({xc,xs}).
For (55), we have
 
ηt2˜τNNX
n=1˜τ−1X
i=0a2
nEh∇xsFn 
xt,i
c,n,xt,i
s,n	2i
= 
ηt2˜τNNX
n=1˜τ−1X
i=0a2
nE∇xsFn 
xt,i
c,n,xt,i
s,n	
−gt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
+Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
≤ 
ηt2(˜τ)2NNX
n=1a2
n 
σ2
n+G2
, (56)
where the first inequality applies triangle inequality. In the last inequality, we apply the bound of
variance and expected squared norm for stochastic gradients in Assumption C.1.
Since Fn(x)isS-smooth and µ-strongly convex, using Lemma C.3 we have
−2ηtE"NX
n=1˜τ−1X
i=0an
xt
s−x∗
s,∇xsFn 
xt,i
c,n,xt,i
s,n	#
≤ −2ηtNX
n=1˜τ−1X
i=0anE 
Fn 
xt
−Fn(x∗)
+µ
4xt
s−x∗
s2−Sxt,i
s,n−xt
s2i
. (57)
By Lemma C.5, we have
NX
n=1˜τ−1X
i=0anEhxt,i
s,n−xt
s2i
≤12NX
n=1an(˜τ)3 
ηt2 
2σ2
n+G2
. (58)
From Assumption C.1, the second part in (54) is bounded by
ENX
n=1˜τ−1X
i=0angt,i
s,n−˜τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2
≤˜τ˜τ−1X
i=0ENX
n=1an 
gt,i
s,n− ∇xsFn 
xt,i
c,xt,i
s	2
≤NNX
n=1a2
nσ2
n(˜τ)2. (59)
Thus, byPN
n=1an= 1, (54) becomes
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
+ 
ηt2(˜τ)2NNX
n=1a2
n 
σ2
n+G2
23−2ηt˜τNX
n=1anE
f 
xt
−f(x∗)
−µ˜τηtPN
n=1an
2xt
s−x∗
s2+ 2ηt 
12NX
n=1anS(˜τ)3 
ηt2 
2σ2
n+G2!
+NNX
n=1a2
n 
ηt2σ2
n(˜τ)2
≤
1−ηt˜τµ
2
Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2(˜τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(˜τ)3 
ηt3NX
n=1an 
2σ2
n+G2
. (60)
We now prove the convergence error. Let ∆t+1≜Ehxt+1
s−x∗
s2i
. We can rewrite (60) as:
∆t+1≤
1−ηt˜τµ
2
∆t−2ηt˜τE
f 
xt
−f(x∗)
,
+ 
ηt2(˜τ)2NNX
n=1 
2σ2
n+G2
+ 24S(˜τ)3 
ηt3NX
n=1 
2σ2
n+G2
,
≤
1−ηt˜τµ
2
∆t+(ηt)2(˜τ)2
4B1+(ηt)3(˜τ)3
8B2. (61)
where B1:= 4NPN
n=1a2
n 
2σ2
n+G2
andB:= 192 SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
˜τ(γ+t), i.e,ηt˜τ
2=β
γ+t, where β=2
µ, γ=8S
µ−1. It
is easy to show that ηt≤1
2S˜τfor all t. Next, we will prove that ∆t+1≤v
γ+t+1, where v=
maxn
4B1
µ2+8B2
µ3(γ+1),(γ+ 1)∆0o
. We prove this by induction. First, the definition of vensures
that it holds for t=−1. Assume the conclusion holds for some t, it follows that
∆t+1≤
1−ηt˜τµ
2
∆t+(ηt)2(˜τ)2
4B1+(ηt)3(˜τ)3
8B2 (62)
≤
1−µβ
γ+tv
γ+t+(ηt)2(˜τ)2
4B1+(ηt)3(˜τ)3
8B2 (63)
=γ+t−1
(γ+t)2v+β2B1
(γ+t)2+β3B2
(γ+t)3−βµ−1
(γ+t)2v
(64)
=γ+t−1
(γ+t)2v+β2B1
(γ+t)2+β3B2
(γ+t)3−βµ−1
(γ+t)2max4B1
µ2+8B2
µ3(γ+ 1),(γ+ 1)∆0
(65)
=γ+t−1
(γ+t)2v+β2B1
(γ+t)2+β3B2
(γ+t)3−βµ−1
(γ+t)2maxβ2B1
βµ−1+β3B2
(βµ−1)(γ+ 1),(γ+ 1)∆0
(66)
≤γ+t−1
(γ+t)2v (67)
≤v
γ+t+ 1. (68)
24Hence, we have proven that ∆t≤v
γ+t,∀t. Therefore, we have
Ehxt
s−x∗
s2i
= ∆t≤v
γ+t=maxn
4B1
µ2+8B2
µ3(γ+1),(γ+ 1)Ehx0
s−x∗
s2io
γ+t
≤16NPN
n=1a2
n 
2σ2
n+G2
µ2(γ+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γ+t) (γ+ 1)+(γ+ 1)Ehx0
s−x∗
s2i
γ+t.
(69)
D.1.2 One-round Parallel Update for Client-Side Models
Under Assumptions C.1 and C.2, if ηt≤1
2Sτ, in round t, Lemma D.1 gives
Ehxt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2(τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(τ)3 
ηt3NX
n=1an 
2σ2
n+G2
. (70)
Let∆t+1≜Ehxt+1
c−x∗
c2i
. We can rewrite (70) as:
∆t+1≤
1−ηtτµ
2
∆t+(ηt)2(τ)2
4B1+(ηt)3(τ)3
8B2. (71)
where B1:= 4NPN
n=1a2
n 
2σ2
n+G2
andB2:= 192 SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
τ(γ+t), i.e,ηtτ
2=β
γ+t, where β=2
µ, γ=8S
µ−1. It is easy
to show that ηt≤1
2Sτfor all t. For v= maxn
4B1
µ2+8B2
µ3(γ+1),(γ+ 1)∆0o
, we can prove that
∆t≤v
γ+t,∀t. Therefore, we have
Ehxt
c−x∗
c2i
= ∆t≤v
γ+t=maxn
4B1
µ2+8B2
µ3(γ+1),(γ+ 1)Ehx0
c−x∗
c2io
γ+t
≤16NPN
n=1a2
n 
2σ2
n+G2
µ2(γ+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γ+t) (γ+ 1)+(γ+ 1)Ehx0
c−x∗
c2i
γ+t.
(72)
D.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (69) and(72) using Proposition 3.5 by setting
ηt≤1
2Smax{τ,˜τ}. We have
E
f(xT)
−f(x∗)
≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
≤8SNPN
n=1a2
n 
2σ2
n+G2
µ2(γ+T)+768S2PN
n=1an 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+ 1)Ehx0−x∗2i
2(γ+T).
(73)
25D.2 General convex case for SFL-V1
D.2.1 One-round Parallel Update for M-Server-Side Model
By Lemma D.1 with µ= 0andηt≤1
2S˜τ, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2˜τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24S˜τ3 
ηt3NX
n=1an 
2σ2
n+G2
. (74)
D.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (75)
D.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (74) and (75) as follows
Ehxt+1−x∗2i
≤Ehxt+1
s−x∗
s2i
+Ehxt+1
c−x∗
c2i
,
≤Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2˜τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24S˜τ3 
ηt3NX
n=1an 
2σ2
n+G2
+Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
=Ehxt−x∗2i
−4ηtmin{τ,˜τ}E
f 
xt
−f(x∗)
+ 
ηt2NNX
n=1a2
n(˜τ2+τ2) 
2σ2
n+G2
+ 24S 
ηt3NX
n=1an(˜τ3+τ3) 
2σ2
n+G2
. (76)
Then, we can obtain the relation between Ehxt+1−x∗2i
andEh
∥xt−x∗∥2i
, which is related to
E[f(xt)−f(x∗)]. Applying Lemma 8 in [ 17] and let τmin:= min {˜τ, τ}andηt≤1
2Smax{τ,˜τ},
we obtain the performance bound as
E
f 
xT
−f(x∗)
≤1
2 
˜τ2+τ2
τ2
minNNX
n=1a2
n 
2σ2
n+G2!1
2 x0−x∗2
T+ 1!1
2
+1
2 
˜τ2+τ2
τ2
min24SNX
n=1an 
2σ2
n+G2!1
3 x0−x∗2
T+ 1!1
3
+Sx0−x∗2
2(T+ 1). (77)
26D.3 Non-convex case for SFL-V1
D.3.1 One-round Parallel Update for M-Server-Side Model
For the server, we have
E
∇xsf 
xt
,xt+1
s−xt
s
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηt˜τ∇xsf 
xt
−ηt˜τ∇xsf 
xt
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηt˜τ∇xsf 
xt
−
∇xsf 
xt
s
, ηt˜τ∇xsf 
xt
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0angt,i
s,n#
+ηt˜τ∇xsf 
xt+
−ηt˜τ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0an∇xsFn 
xt,i
c,n,xt,i
s,n	#
+ηt˜τ∇xsf 
xt+
−ηt˜τ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0an∇xsFn 
xt,i
c,n,xt,i
s,n	
+ηtNX
n=1˜τ−1X
i=0an∇xsFn 
xt#+
−ηt˜τ∇xsf 
xt2
≤ηt˜τ*
∇xsf 
xt
,E"
−1
˜τNX
n=1˜τ−1X
i=0an∇xsFn 
xt,i
c,n,xt,i
s,n	
+1
˜τNX
n=1˜τ−1X
i=0an∇xsFn 
xt#+
−ηt˜τ∇xsf 
xt2
≤ηt˜τ
2∇xsf 
xt2+ηt
2˜τE
NX
n=1˜τ−1X
i=0an∇xsFn 
xt,i
c,n,xt,i
s,n	
−NX
n=1˜τ−1X
i=0an∇xsFn 
xt2

−ηt˜τ∇xsf 
xt2
≤ −ηt˜τ
2∇xsf 
xt2+ηt
2˜τE
NX
n=1an˜τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηt˜τ
2∇xsf 
xt2+Nηt
2˜τNX
n=1a2
nE
˜τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηt˜τ
2∇xsf 
xt2+NηtS2
2NX
n=1a2
n˜τ−1X
i=0Ehxt,i
s,n−xt
s2i
, (78)
where we apply Assumption C.1, ∇xsf(xt) =PN
n=1an∇xsFn(xt), and⟨a, b⟩ ≤a2+b2
2.
By Lemma C.6 with ηt≤1√
8S˜τ, we have
˜τ−1X
i=0Ehxt,i
s,n−xt
s2i
≤2˜τ2
8˜τ 
ηt2σ2
n+ 8˜τ 
ηt2ϵ2+ 8˜τ 
ηt2∇xsf 
xt
s2
.(79)
Thus, (78) becomes
E
∇xsf 
xt
,xt+1
s−xt
s
≤−ηt˜τ
2∇xsf 
xt2+NηtS2
2NX
n=1a2
n2˜τ2
8˜τ 
ηt2σ2
n+8˜τ 
ηt2ϵ2+8˜τ 
ηt2∇xsf 
xt
s2
≤ 
−ηt˜τ
2+ 8N 
ηt3˜τ3S2NX
n=1a2
n!
∇xsf 
xt2+ 8NηtS2˜τ3NX
n=1a2
n 
ηt2 
σ2
n+ϵ2
.
(80)
27Furthermore, we have
S
2Ehxt+1
s−xt
s2i
=SN(ηt)2
2NX
n=1E
˜τ−1X
i=0angt,i
s,n2

≤SN(ηt)2
2NX
n=1a2
nE
˜τ−1X
i=0gt,i
s,n2

≤SN(ηt)2˜τ
2NX
n=1a2
n˜τ−1X
i=0Ehgt,i
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n˜τ−1X
i=0Ehgt,i
s,n−gt
s,n+gt
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n˜τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Ehgt
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n˜τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Eh∇xsFn 
xt2+σ2
ni
, (81)
where the last line uses Assumption C.1 and E
∥z∥2
=∥E[z]∥2+E[∥z−E[z]∥2
for any random
variable z.
By Lemma C.7 with ηt≤1
2S˜τ, we have
˜τ−1X
i=0Ehgt,i
s,n−gt
s,n2i
≤8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
. (82)
Thus, (81) becomes
S
2Ehxt+1
s−xt
s2i
≤SN(ηt)2˜τ
2NX
n=1a2
n
8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
+ ˜τEh∇xsFn 
xt2+σ2
ni
≤SN(ηt)2˜τ
2NX
n=1a2
n
˜τ+ 8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
≤SN(ηt)2˜τ
2NX
n=1a2
n
˜τ+ 8˜τ3 
ηt2S2∇xsFn 
xt
− ∇xsf 
xt
+∇xsf 
xt2+σ2
n
≤SN(ηt)2˜τ
2NX
n=1a2
n
˜τ+ 8˜τ3 
ηt2S2
2∇xsf 
xt2+ 2ϵ2+σ2
n
. (83)
D.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is similar to the server. Thus, we have
E
∇xcf 
xt
,xt+1
c−xt
c
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=1a2
n!
∇xcf 
xt2+ 8NηtS2τ3NX
n=1a2
n 
ηt2 
σ2
n+ϵ2
.
(84)
28Forηt≤1
2Sτ,
S
2Ehxt+1
c−xt
c2i
≤SN(ηt)2τ
2NX
n=1a2
n
τ+ 8τ3 
ηt2S2
2∇xcf 
xt2+ 2ϵ2+σ2
n
. (85)
D.3.3 Superposition of M-Server and Clients
Applying (80),(83),(85) and(84) into (36) in Proposition C.4 and define τmin≜min{τ,˜τ},
τmax≜max{τ,˜τ}, we have
E
f 
xt+1
−f 
xt
≤E
∇xcf 
xt
,xt+1
c−xt
c
+S
2Ehxt+1
c−xt
c2i
+E
∇xsf 
xt
,xt+1
s−xt
s
+S
2Ehxt+1
s−xt
s2i
≤ 
−ηtmin{τ,˜τ}
2+ 8N 
ηt3(max{τ,˜τ})3S2NX
n=1a2
n!
∇xf 
xt2
+ 8NηtS2 
τ3+ ˜τ3NX
n=1 
ηt2a2
n 
σ2
n+ϵ2
+SN(ηt)2max{τ,˜τ}
2NX
n=1a2
n
max{τ,˜τ}+ 8 (max {τ,˜τ})3 
ηt2S2
2∇xf 
xt2
+SN(ηt)2τ
2NX
n=1a2
n
τ+ 8τ3 
ηt2S2 
2ϵ2+σ2
n
+SN(ηt)2˜τ
2NX
n=1a2
n
˜τ+ 8˜τ3 
ηt2S2 
2ϵ2+σ2
n
(86)
≤ 
−ηtτmin
2+8N 
ηt3S2τ3
maxNX
n=1a2
n+SN 
ηt2τmaxNX
n=1a2
n
τmax+8τ3
max 
ηt2S2!
∇xf 
xt2
+ 8NηtS2 
τ3+ ˜τ3NX
n=1a2
n 
ηt2 
σ2
n+ϵ2
+1
2SN 
ηt2τ
τ+ 8τ3 
ηt2S2NX
n=1a2
n 
2ϵ2+σ2
n
+1
2SN 
ηt2˜τ
˜τ+8˜τ3 
ηt2S2NX
n=1a2
n 
2ϵ2+σ2
n
≤ 
−ηtτmin
2+SN 
ηt2τ2
maxNX
n=1a2
n+8N 
ηt3vS2τ3
maxNX
n=1a2
n+8S3N 
ηt4τ4
maxNX
n=1a2
n!
∇xf 
xt2
+ 8N 
ηt3S2τ3NX
n=1a2
nσ2
n+ 8N 
ηt3S2τ3ϵ2NX
n=1a2
n
+SN 
ηt2τ2ϵ2NX
n=1a2
n+1
2SN 
ηt2˜τ2NX
n=1a2
nσ2
n+8NS3 
ηt4τ4ϵ2NX
n=1a2
n+ 4NS3 
ηt4τ4NX
n=1a2
nσ2
n
+ 8N 
ηt3S2˜τ3NX
n=1a2
nσ2
n+ 8N 
ηt3S2˜τ3ϵ2NX
n=1a2
n
+SN 
ηt2˜τ2ϵ2NX
n=1a2
n+1
2SN 
ηt2˜τ2NX
n=1a2
nσ2
n+8NS3 
ηt4˜τ4ϵ2NX
n=1a2
n+4NS3 
ηt4˜τ4NX
n=1a2
nσ2
n
29≤ −ηtτmin
2 
1−2SNηtτ2
max
τminNX
n=1a2
n
1 + 8 Sηtτ+ 8S2 
ηt2τ2
max!
∇xf 
xt2
+1
2NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 4NS3 
ηt4τ4NX
n=1a2
nσ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 8NSL3 
ηt4τ4NX
n=1a2
nϵ2
+1
2NS 
ηt2˜τ2+ 8N 
ηt3S2˜τ3+ 4NS3 
ηt4˜τ4NX
n=1a2
nσ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2˜τ3+ 8NSL3 
ηt4˜τ4NX
n=1a2
nϵ2
≤ −ηtτmin
2 
1−2NSηtτ2
max
τminNX
n=1a2
n
1 +1
2+1
32!
∇xf 
xt2
+NS 
ηt2τ21
2+1
2+1
64NX
n=1a2
nσ2
n+ 2SN 
ηt2τ21
2+1
4+1
64NX
n=1a2
nϵ2
+NS 
ηt2˜τ21
2+1
2+1
64NX
n=1a2
nσ2
n+ 2SN 
ηt2˜τ21
2+1
4+1
64NX
n=1a2
nϵ2
≤ −ηtτmin
2 
1−4NSηtτ2
max
τminNX
n=1a2
n!
∇xf 
xt2+ 2NS 
ηt2 
τ2+ ˜τ2NX
n=1a2
n 
σ2
n+ϵ2
≤ −ηtτmin
4∇xf 
xt2+ 2NS 
ηt2 
τ2+ ˜τ2NX
n=1a2
n 
σ2
n+ϵ2
, (87)
where we first let ηt≤1
16Sτmaxand then let ηt≤1
8SNτ2max
τminPN
n=1a2n. We also use ∥∇xf(xt)∥2=
∥∇xcf(xt)∥2+∥∇xsf(xt)∥2.
Rearranging the above we have
ηt∇xf 
xt2≤4
τmin 
f 
xt
−E
f 
xt+1
s
+ 8NS 
ηt2τ2+ ˜τ2
τminNX
n=1a2
n 
σ2
n+ϵ2
.
(88)
Taking expectation and averaging over all t, we have
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτmin(f(x0)−f∗) +8NSτ2+˜τ2
τmin
TNX
n=1a2
n 
σ2
n+ϵ2T−1X
t=0 
ηt2.
(89)
30E Proof of Theorem 3.7
• In Sec. E.1, we prove the strongly convex case.
• In Sec. E.2, we prove the general convex case.
• In Sec. E.3, we prove the non-convex case.
E.1 Strongly convex case for SFL-V2
E.1.1 One-round Sequential Update for M-Server-Side Model
Lemma E.1. Under Assumptions C.1 and C.2, if ηt≤1
2Sτ, in round t, the M-server-side model
evolves as
Ehxt+1
s−x∗
s2i
≤
1−Nηtτµ
2
Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
. (90)
We prove Lemma E.1 as follows.
Proof. We use xt,i
s,nas the M-server-side model when the M-server interacts with client nfor
thei-th iteration of model training at round t. Using the (sequential) gradient update rule of
xt+1
s=xt
s−ηtPN
n=1Pτ−1
i=0gt,i
s 
xt,i
c,n,xt,i
s,n	
, we have
Ehxt+1
s−x∗
s2i
=E
xt
s−ηtτ−1X
i=0gt,i
s−x∗
s−ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
+ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

=E
xt
s−x∗
s−ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

+ 2ηtE"*
xt
s−x∗
s−ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
,τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	
−τ−1X
i=0gt,i
s+#
+E
 
ηt2τ−1X
i=0gt,i
s−τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

≤E
xt
s−x∗
s−ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

+ 
ηt2E
NX
n=1τ−1X
i=0gt,i
s,n−τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2
. (91)
where the first equality is from (a+b)2=a2+ 2ab+b2and the last inequality is due to
E
∇xsf 
xt,i
c,xt,i
s	
−gt,i
s
= 0.
The first part in (91) is
E
xt
s−x∗
s−ηtτ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2

31≤Ehxt
s−x∗
s2i
+ 
ηt2τNNX
n=1τ−1X
i=0Eh∇xsFn 
xt,i
c,n,xt,i
s,n	2i
−2ηtE"NX
n=1τ−1X
i=0
xt
s−x∗
s,∇xsFn 
xt,i
c,xt,i
s	#
, (92)
where we use ∇xsf({xc,xs}) =PN
n=1∇xsFn({xc,xs}).
For (92), we have
 
ηt2τNNX
n=1τ−1X
i=0Eh∇xsFn 
xt,i
c,n,xt,i
s,n	2i
= 
ηt2τNNX
n=1τ−1X
i=0E∇xsFn 
xt,i
c,n,xt,i
s,n	
−gt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
+Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
≤ 
ηt2τ2NNX
n=1 
σ2
n+G2
, (93)
where the first inequality applies triangle inequality. In the last inequality, we apply the bound of
variance and expected squared norm for stochastic gradients in Assumption C.1.
Since Fn(x)isS-smooth and µ-strongly convex, using Lemma C.3 we have
−2ηtE"NX
n=1τ−1X
i=0
xt
s−x∗
s,∇xsFn 
xt,i
c,n,xt,i
s,n	#
≤ −2ηtNX
n=1τ−1X
i=0E 
Fn 
xt
−Fn(x∗)
+µ
4xt
s−x∗
s2−Sxt,i
s,n−xt
s2i
. (94)
By Lemma C.5, we have
NX
n=1τ−1X
i=0Ehxt,i
s,n−xt
s2i
≤12NX
n=1τ3 
ηt2 
2σ2
n+G2
. (95)
From Assumption C.1, the second part in (91) is bounded by
ENX
n=1τ−1X
i=0gt,i
s,n−τ−1X
i=0∇xsf 
xt,i
c,xt,i
s	2
≤ττ−1X
i=0ENX
n=1gt,i
s,n− ∇xsFn 
xt,i
c,xt,i
s	2
≤NNX
n=1σ2
nτ2. (96)
Thus, (91) becomes
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
+ 
ηt2τ2NNX
n=1 
σ2
n+G2
32−2ηtτE
f 
xt
−f(x∗)
−µNτηt
2xt
s−x∗
s2+ 2ηt 
12NX
n=1Sτ3 
ηt2 
2σ2
n+G2!
+NNX
n=1 
ηt2σ2
nτ2
≤
1−ηtNτµ
2
Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
. (97)
Using the above lemma, we can prove the convergence error. Let ∆t+1≜Ehxt+1
s−x∗
s2i
. We
can rewrite (97) as:
∆t+1≤
1−ηtNτµ
2
∆t−2ηtτE
f 
xt
−f(x∗)
,
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
,
≤
1−ηtNτµ
2
∆t+(ηt)2τ2
4B1+(ηt)3τ3
8B2. (98)
where B1:= 4NPN
n=1 
2σ2
n+G2
andB:= 192 SPN
n=1 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
Nτ(γs+t), i.e,Nηtτ
2=β
γs+t, where β=2
µ, γs=8S
Nµ−1.
It is easy to show that ηt≤1
2Sτfor all t. Next, we will prove that ∆t+1≤v
γs+t+1, where
v= maxn
4B1
µ2+8B2
µ3(γs+1),(γs+ 1)∆0o
. We prove this by induction. First, the definition of v
ensures that it holds for t=−1. Assume the conclusion holds for some t, it follows that
∆t+1≤
1−Nηtτµ
2
∆t+(ηt)2τ2
4B1+(ηt)3τ3
8B2 (99)
≤
1−µβ
γs+tv
γs+t+(ηt)2τ2
4B1+(ηt)3τ3
8B2 (100)
=γs+t−1
(γs+t)2v+β2B1
(γs+t)2+β3B2
(γs+t)3−βµ−1
(γs+t)2v
(101)
=γs+t−1
(γs+t)2v+β2B1
(γs+t)2+β3B2
(γs+t)3−βµ−1
(γs+t)2max4B1
µ2+8B2
µ3(γs+ 1),(γs+ 1)∆0
(102)
=γs+t−1
(γs+t)2v+β2B1
(γs+t)2+β3B2
(γs+t)3−βµ−1
(γs+t)2maxβ2B1
βµ−1+β3B2
(βµ−1)(γs+1),(γs+1)∆0
(103)
≤γs+t−1
(γs+t)2v (104)
≤v
γs+t+ 1. (105)
33Hence, we have proven that ∆t≤v
γs+t,∀t. Therefore, we have
Ehxt
s−x∗
s2i
= ∆t≤v
γs+t=maxn
4B1
µ2+8B2
µ3(γs+1),(γs+ 1)Ehx0
s−x∗
s2io
γs+t
≤16NPN
n=1 
2σ2
n+G2
µ2(γs+t)+1536SPN
n=1 
2σ2
n+G2
µ3(γs+t) (γs+ 1)+(γs+ 1)Ehx0
s−x∗
s2i
γs+t.(106)
E.1.2 One-round Parallel Update for Client-Side Models
Under Assumptions C.1 and C.2, if ηt≤1
2Sτ, in round t, Lemma D.1 gives
Ehxt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (107)
Let∆t+1≜Ehxt+1
c−x∗
c2i
. We can rewrite (107) as:
∆t+1≤
1−ηtτµ
2
∆t+(ηt)2τ2
4B1+(ηt)3τ3
8B2. (108)
where B1:= 4NPN
n=1a2
n 
2σ2
n+G2
andB2:= 192 SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
τ(γc+t), i.e,ηtτ
2=β
γc+t, where β=2
µ, γc=8S
µ−1. It is
easy to show that ηt≤1
2Sτfor all t. For v= maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)∆0o
, we can prove
that∆t≤v
γc+t,∀t. Therefore, we have
Ehxt
c−x∗
c2i
= ∆t≤v
γc+t=maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)Ehx0
c−x∗
c2io
γc+t
≤16NPN
n=1a2
n 
2σ2
n+G2
µ2(γc+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γc+t) (γc+ 1)+(γc+ 1)Ehx0
c−x∗
c2i
γc+t.
(109)
E.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (106) and(109) using Proposition 3.5. For
ηt≤1
2Sτandγ=8S
µ−1, we have
E
f(xT)
−f(x∗)
≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
≤8SNPN
n=1(a2
n+1 ) 
2σ2
n+G2
µ2(γ+T)+768S2PN
n=1(an+1 ) 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+1 )Ehx0−x∗2i
2(γ+T)
(110)
34E.2 General convex case for SFL-V2
E.2.1 One-round Sequential Update for M-Server-Side Model
By Lemma E.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
. (111)
E.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (112)
E.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (111) and (112) as follows
Ehxt+1−x∗2i
≤Ehxt+1
s−x∗
s2i
+Ehxt+1
c−x∗
c2i
,
≤Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1(a2
n+ 1) 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1(an+ 1) 
2σ2
n+G2
=Ehxt−x∗2i
−4ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1(a2
n+ 1) 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1(an+ 1) 
2σ2
n+G2
. (113)
Then, we can obtain the relation between Ehxt+1−x∗2i
andEh
∥xt−x∗∥2i
, which is related to
E[f(xt)−f(x∗)]. Applying Lemma 8 in [17], we obtain the performance bound as
E
f 
xT
−f(x∗)
≤1
2 
NNX
n=1(a2
n+ 1) 
2σ2
n+G2!1
2 x0−x∗2
T+ 1!1
2
+1
2 
24SNX
n=1(an+ 1) 
2σ2
n+G2!1
3 x0−x∗2
T+ 1!1
3
+Sx0−x∗2
2(T+ 1). (114)
35E.3 Non-convex case for SFL-V2
E.3.1 One-round Sequential Update for M-Server-Side Model
For the server, we have
E
∇xsf 
xt
,xt+1
s−xt
s
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηtτ∇xsf 
xt
−ηtτ∇xsf 
xt
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηtτ∇xsf 
xt
−
∇xsf 
xt
s
, ηtτ∇xsf 
xt
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0gt,i
s,n#
+ηtτ∇xsf 
xt+
−ηtτ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0∇xsFn 
xt,i
c,n,xt,i
s,n	#
+ηtτ∇xsf 
xt+
−ηtτ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0∇xsFn 
xt,i
c,n,xt,i
s,n	
+ηtNX
n=1τ−1X
i=0∇xsFn 
xt#+
−ηtτ∇xsf 
xt2
≤ηtτ*
∇xsf 
xt
,E"
−1
τNX
n=1τ−1X
i=0∇xsFn 
xt,i
c,n,xt,i
s,n	
+1
τNX
n=1τ−1X
i=0∇xsFn 
xt#+
−ηtτ∇xsf 
xt2
≤ηtτ
2∇xsf 
xt2+ηt
2τE
NX
n=1τ−1X
i=0∇xsFn 
xt,i
c,n,xt,i
s,n	
−NX
n=1τ−1X
i=0∇xsFn 
xt2

−ηtτ∇xsf 
xt2
≤ −ηtτ
2∇xsf 
xt2+ηt
2τE
NX
n=1τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηtτ
2∇xsf 
xt2+Nηt
2τNX
n=1E
τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηtτ
2∇xsf 
xt2+NηtS2
2NX
n=1τ−1X
i=0Ehxt,i
s,n−xt
s2i
, (115)
where we apply Assumption C.1, ∇xsf(xt) =PN
n=1∇xsFn(xt), and⟨a, b⟩ ≤a2+b2
2.
By Lemma C.6 with ηt≤1√
8Sτ, we have
τ−1X
i=0Ehxt,i
s,n−xt
s2i
≤2τ2
8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xsf 
xt
s2
.(116)
Thus, (115) becomes
E
∇xsf 
xt
,xt+1
s−xt
s
≤−ηtτ
2∇xsf 
xt2+NηtS2
2NX
n=12τ2
8τ 
ηt2σ2
n+8τ 
ηt2ϵ2+8τ 
ηt2∇xsf 
xt
s2
≤
−ηtτ
2+ 8N2 
ηt3τ3S2∇xsf 
xt2+ 8NηtS2τ3NX
n=1 
ηt2 
σ2
n+ϵ2
. (117)
36Furthermore, we have
S
2Ehxt+1
s−xt
s2i
=SN(ηt)2
2NX
n=1E
τ−1X
i=0gt,i
s,n2

≤SN(ηt)2
2NX
n=1E
τ−1X
i=0gt,i
s,n2

≤SN(ηt)2τ
2NX
n=1τ−1X
i=0Ehgt,i
s,n2i
≤SN(ηt)2τ
2NX
n=1τ−1X
i=0Ehgt,i
s,n−gt
s,n+gt
s,n2i
≤SN(ηt)2τ
2NX
n=1τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Ehgt
s,n2i
≤SN(ηt)2τ
2NX
n=1τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Eh∇xsFn 
xt2+σ2
ni
, (118)
where the last line uses Assumption C.1 and E
∥z∥2
=∥E[z]∥2+E[∥z−E[z]∥2
for any random
variable z.
By Lemma C.7 with ηt≤1
2Sτ, we have
τ−1X
i=0Ehgt,i
s,n−gt
s,n2i
≤8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
. (119)
Thus, (118) becomes
S
2Ehxt+1
s−xt
s2i
≤SN(ηt)2τ
2NX
n=1
8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
+τEh∇xsFn 
xt2+σ2
ni
≤SN(ηt)2τ
2NX
n=1
τ+ 8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
≤SN(ηt)2τ
2NX
n=1
τ+ 8τ3 
ηt2S2∇xsFn 
xt
− ∇xsf 
xt
+∇xsf 
xt2+σ2
n
≤SN(ηt)2τ
2NX
n=1
τ+ 8τ3 
ηt2S2
2∇xsf 
xt2+ 2ϵ2+σ2
n
. (120)
E.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is the same as the client’s model update in version 1.
Thus, we have
E
∇xcf 
xt
,xt+1
c−xt
c
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=1a2
n!
∇xcf 
xt2+ 8NηtS2τ3NX
n=1a2
n 
ηt2 
σ2
n+ϵ2
.
(121)
37Forηt≤1
2Sτ,
S
2Ehxt+1
c−xt
c2i
≤SN(ηt)2τ
2NX
n=1a2
n
τ+ 8τ3 
ηt2S2
2∇xcf 
xt2+ 2ϵ2+σ2
n
. (122)
E.3.3 Superposition of M-Server and Clients
Applying (117), (120), (122) and (121) into (36) in Proposition C.4, we have
E
f 
xt+1
−f 
xt
≤E
∇xcf 
xt
,xt+1
c−xt
c
+S
2Ehxt+1
c−xt
c2i
+E
∇xsf 
xt
,xt+1
s−xt
s
+S
2Ehxt+1
s−xt
s2i
≤
−ηtτ
2+ 8N2 
ηt3τ3S2∇xf 
xt2
+ 8NηtS2τ3NX
n=1 
ηt2(a2
n+ 1) 
σ2
n+ϵ2
+SN(ηt)2τ
2NX
n=1
τ+ 8τ3 
ηt2S2
2∇xf 
xt2
+SN(ηt)2τ
2NX
n=1(a2
n+ 1)
τ+ 8τ3 
ηt2S2 
2ϵ2+σ2
n
≤ 
−ηtτ
2+ 8N2 
ηt3S2τ3+SN 
ηt2τNX
n=1
τ+ 8τ3 
ηt2S2!
∇xf 
xt2
+ 8NηtS2τ3NX
n=1 
ηt2(a2
n+ 1) 
σ2
n+ϵ2
+1
2SN 
ηt2τ
τ+ 8τ3 
ηt2S2NX
n=1(a2
n+ 1) 
2ϵ2+σ2
n
≤
−ηtτ
2+SN2 
ηt2τ2+ 8N2 
ηt3S2τ3+ 8S3N2 
ηt4τ4∇xf 
xt2
+ 8N 
ηt3S2τ3NX
n=1(a2
n+ 1)σ2
n+ 8N 
ηt3S2τ3ϵ2NX
n=1(a2
n+ 1)
+SN 
ηt2τ2ϵ2NX
n=1(a2
n+ 1) +1
2SN 
ηt2τ2NX
n=1(a2
n+ 1)σ2
n
+ 8NS3 
ηt4τ4ϵ2NX
n=1(a2
n+ 1) + 4 NS3 
ηt4τ4NX
n=1(a2
n+ 1)σ2
n
≤ −ηtτ
2
1−2SN2ηtτ2
τ
1 + 8 Sηtτ+ 8S2 
ηt2τ2∇xf 
xt2
+1
2NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 4NS3 
ηt4τ4NX
n=1(a2
n+ 1)σ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 8NSL3 
ηt4τ4NX
n=1(a2
n+ 1)ϵ2
≤ −ηtτ
2
1−2N2Sηtτ2
τ
1 +1
2+1
32∇xf 
xt2
38+NS 
ηt2τ21
2+1
2+1
64NX
n=1(a2
n+ 1)σ2
n+ 2SN 
ηt2τ21
2+1
4+1
64NX
n=1(a2
n+ 1)ϵ2
≤ −ηtτ
2
1−4N2Sηtτ2
τ∇xf 
xt2+ 2NS 
ηt2NX
n=1 
τ2a2
n+τ2 
σ2
n+ϵ2
≤ −ηtτ
4∇xf 
xt2+ 2NS 
ηt2τ2NX
n=1 
a2
n+ 1 
σ2
n+ϵ2
, (123)
where we first let ηt≤1
16Sτand then let ηt≤1
8SN2τ. We have appliedPN
n=1a2
n≤N.
Rearranging the above we have
ηt∇xf 
xt2≤4
τ 
f 
xt
−E
f 
xt+1
s
+ 8NS 
ηt2τNX
n=1a2
n+ 1
τ 
σ2
n+ϵ2
.(124)
Taking expectation and averaging over all t, we have
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτ(f(x0)−f∗) +8NSτ
TNX
n=1(a2
n+ 1) 
σ2
n+ϵ2T−1X
t=0 
ηt2.
(125)
39F Proof of Theorem 3.8
• In Sec. F.1, we prove the strongly convex case.
• In Sec. F.2, we prove the general convex case.
• In Sec. F.3, we prove the non-convex case.
F.1 Strongly convex case for SFL-V1
F.1.1 One-round Parallel Update for M-Server-Side Model
We first bound the M-server-side model update in one round for full participation ( qn= 1for all n),
and then compute the difference between full participation and partial participation ( qn<1for some
n). We denote It
nas a binary variable, taking 1 if client nparticipates in model training in round t,
and 0 otherwise. Practically, It
nfollows a Bernoulli distribution with an expectation of qn.
For full participation, Lemma D.1 gives
Ehxt+1
s−x∗
s2i
≤
1−ηt˜τµ
2
Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2(˜τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(˜τ)3 
ηt3NX
n=1an 
2σ2
n+G2
. (126)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
s−xt+1
s2i
=Ehxt+1
s−xt
s+xt
s−xt+1
s2i
≤Ehxt+1
s−xt
s2i
≤E
NX
n=1ηtanIn
t
qn˜τ−1X
i=0gt,i
s,n 
xt,i
c,n,xt,i
s,n	2

≤N˜τNX
n=1 
ηt2a2
n
qn˜τ−1X
i=0Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
≤N(˜τ)2 
ηt2G2NX
n=1a2
n
qn, (127)
where we use E∥X−EX∥2≤E∥X∥2,E[It
n] = qn, and xt+1
s =xt
s−
ηtP
n∈Pt(q)P˜τ−1
i=0a2
n
qngt,i
s,n 
xt,i
c,n,xt,i
s,n	
.
Combining the above gives
Ehxt+1
s−x∗
s2i
=Ehxt+1
s−xt+1
s+xt+1
s−x∗
s2i
≤
1−ηt˜τµ
2
Ehxt
s−x∗
s2i
+ 
ηt2(˜τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(˜τ)3 
ηt3NX
n=1an 
2σ2
n+G2
+N(˜τ)2 
ηt2G2NX
n=1a2
n
qn. (128)
40Let∆t+1≜Ehxt+1
s−x∗
s2i
. We can rewrite (128) as:
∆t+1≤
1−ηt˜τµ
2
∆t+(ηt)2(˜τ)2
4B1+(ηt)3(˜τ)3
8B2. (129)
where B1:= 4NPN
n=1a2
n 
2σ2
n+G2
+4NG2PN
n=1a2
n
qnandB:= 192 SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
˜τ(γs+t), i.e,ηt˜τ
2=β
γs+t, where β=2
µ, γs=8S
µ−1. It is
easy to show that ηt≤1
2S˜τfor all t. We can prove that ∆t≤v
γs+t,∀t. Therefore, we have
Ehxt
s−x∗
s2i
= ∆t≤v
γs+t=maxn
4B1
µ2+8B2
µ3(γs+1),(γs+ 1)Ehx0
s−x∗
s2io
γs+t
≤16NPN
n=1a2
n 
2σ2
n+G2
+ 16NG2PN
n=1a2
n
qn
µ2(γs+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γs+t) (γs+ 1)
+(γs+ 1)Ehx0
s−x∗
s2i
γs+t. (130)
F.1.2 One-round Parallel Update for Client-Side Models
Define xc
t=PN
n=1anxt
c,n, which represents the aggregating weights in round tfor full par-
ticipation. Using a similar derivation as the M-server side, we first bound the client-side
model update in one round for full participation Ehxt+1
c−x∗
c2i
and then bound the dif-
ference of client-side model parameters between full participation and partial participation
Ehxt+1
c−x∗
c2i
. The overall gradient update rule of clients in each training round is xt+1
c=
xt
c−ηtP
n∈Pt(q)Pτ−1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
Under Assumptions C.1 and C.2, if ηt≤1
2Sτ, in round t, Lemma D.1 gives
Ehxt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2(τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(τ)3 
ηt3NX
n=1an 
2σ2
n+G2
. (131)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
c−xt+1
c2i
=Ehxt+1
c−xt
c+xt
c−xt+1
c2i
≤Ehxt+1
c−xt
c2i
≤E
NX
n=1ηtanIn
t
qnτ−1X
i=0gt,i
c,n 
xt,i
c,n,xt,i
s,n	2

≤NτNX
n=1 
ηt2a2
n
qnτ−1X
i=0Ehgt,i
c,n 
xt,i
c,n,xt,i
s,n	2i
≤N(τ)2 
ηt2G2NX
n=1a2
n
qn, (132)
41where we use E∥X−EX∥2≤E∥X∥2,E[It
n] = qn, and xt+1
c =xt
c−
ηtP
n∈Pt(q)Pτ−1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
We obtain the client-side model parameter update in one round for partial participation by combining
the two terms and we have
Ehxt+1
c−x∗
c2i
=Ehxt+1
c−xt+1
c+xt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
+ 
ηt2(τ)2NNX
n=1a2
n 
2σ2
n+G2
+ 24S(τ)3 
ηt3NX
n=1an 
2σ2
n+G2
+N(τ)2 
ηt2G2NX
n=1a2
n
qn, (133)
where we consider E[f(xt)−f(x∗)]≥0.
Let∆t+1≜Ehxt+1
c−x∗
c2i
. We can rewrite (163) as:
∆t+1≤
1−ηtτµ
2
∆t+(ηt)2(τ)2
4B1+(ηt)3(τ)3
8B2. (134)
where B1 := 4 NPN
n=1a2
n 
2σ2
n+G2
+ 4 NG2PN
n=1a2
n
qnand B2 :=
192SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
τ(γc+t), i.e,ηtτ
2=β
γc+t, where β=2
µ, γc=8S
µ−1. It is
easy to show that ηt≤1
2Sτfor all t. For v= maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)∆0o
, we can prove
that∆t≤v
γc+t,∀t. Therefore, we have
Ehxt
c−x∗
c2i
= ∆t≤v
γc+t=maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)Ehx0
c−x∗
c2io
γc+t
≤16NPN
n=1a2
n 
2σ2
n+G2
+ 16NG2PN
n=1a2
n
qn
µ2(γc+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γc+t) (γc+ 1)
+(γc+ 1)Ehx0
c−x∗
c2i
γc+t. (135)
F.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (130) and(135) using Proposition 3.5. For
ηt≤1
2Smax{τ,˜τ}andγ=8S
µ−1, we have
E
f(xT)
−f(x∗)
≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
≤8SNPN
n=1a2
n
2σ2
n+G2+G2
qn
µ2(γ+T)+768S2PN
n=1an 
2σ2
n+G2
µ3(γ+T) (γ+ 1)+S(γ+ 1)Ehx0−x∗2i
2(γ+T).
(136)
42F.2 General convex case for SFL-V1
F.2.1 One-round Parallel Update for M-Server-Side Model
By Lemma D.1 with µ= 0andηt≤1
2S˜τ, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2˜τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24S˜τ3 
ηt3NX
n=1an 
2σ2
n+G2
. (137)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
s−xt+1
s2i
≤N˜τ2 
ηt2G2NX
n=1a2
n
qn. (138)
Thus, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2˜τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24S˜τ3 
ηt3NX
n=1an 
2σ2
n+G2
+N˜τ2 
ηt2G2NX
n=1a2
n
qn.
(139)
F.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (140)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
c−xt+1
c2i
≤Nτ2 
ηt2G2NX
n=1a2
n
qn. (141)
Thus, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n
qn.
(142)
F.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (139) and (142) as follows
43Ehxt+1−x∗2i
≤Ehxt+1
s−x∗
s2i
+Ehxt+1
c−x∗
c2i
,
≤Ehxt
s−x∗
s2i
−2ηt˜τE
f 
xt
−f(x∗)
+ 
ηt2˜τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24S˜τ3 
ηt3NX
n=1an 
2σ2
n+G2
+N˜τ2 
ηt2G2NX
n=1a2
n
qn
+Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n
qn
=Ehxt−x∗2i
−4ηtmin{τ,˜τ}E
f 
xt
−f(x∗)
+ 
ηt2NNX
n=1a2
n(˜τ2+τ2) 
2σ2
n+G2
+24S 
ηt3NX
n=1an(˜τ3+τ3) 
2σ2
n+G2
+N 
τ2+˜τ2 
ηt2G2NX
n=1a2
n
qn.
(143)
Then, we can obtain the relation between Ehxt+1−x∗2i
andEh
∥xt−x∗∥2i
, which is related
toE[f(xt)−f(x∗)]. Applying Lemma 8 in [ 17] and let τmin:= min {˜τ, τ}, we obtain the
performance bound as
E
f 
xT
−f(x∗)
≤1
2 
˜τ2+τ2
τ2
minNNX
n=1a2
n
2σ2
n+G2+G2
n
qn!1
2 x0−x∗2
T+ 1!1
2
+1
2 
˜τ2+τ2
τ2
min24SNX
n=1an 
2σ2
n+G2!1
3 x0−x∗2
T+ 1!1
3
+Sx0−x∗2
2(T+ 1). (144)
44F.3 Non-convex case for SFL-V1
F.3.1 One-round Parallel Update for M-Server-Side Model
For the server, we have
E
∇xsf 
xt
,xt+1
s−xt
s
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηt˜τ∇xsf 
xt
−ηt˜τ∇xsf 
xt
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηt˜τ∇xsf 
xt
−
∇xsf 
xt
s
, ηt˜τ∇xsf 
xt
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0anIt
n
qngt,i
s,n#
+ηt˜τ∇xsf 
xt+
−ηt˜τ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
v
xt,i
c,n,xt,i
s,n	#
+ηt˜τ∇xsf 
xt+
−ηt˜τ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
+ηtNX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt#+
−ηt˜τ∇xsf 
xt2
≤ηt˜τ*
∇xsf 
xt
,E"
−1
˜τNX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
+1
˜τNX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt#+
−ηt˜τ∇xsf 
xt2
≤ηt˜τ
2∇xsf 
xt2+ηt
2˜τE
NX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
−NX
n=1˜τ−1X
i=0anIt
n
qn∇xsFn 
xt2

−ηt˜τ∇xsf 
xt2
≤ −ηt˜τ
2∇xsf 
xt2+ηt
2˜τE
NX
n=1anIt
n
qn˜τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηt˜τ
2∇xsf 
xt2+Nηt
2˜τNX
n=1a2
n
qnE
˜τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηt˜τ
2∇xsf 
xt2+NηtS2
2NX
n=1a2
n
qn˜τ−1X
i=0Ehxt,i
s,n−xt
s2i
, (145)
where we apply Assumption C.1, ∇xsf(xt) =PN
n=1an∇xsFn(xt),⟨a, b⟩ ≤a2+b2
2, andE[It
n] =
qn.
By Lemma C.6 with ηt≤1√
8S˜τ, we have
˜τ−1X
i=0Ehxt,i
s,n−xt
s2i
≤2˜τ2
8˜τ 
ηt2σ2
n+ 8˜τ 
ηt2ϵ2+ 8˜τ 
ηt2∇xsf 
xt
s2
.(146)
Thus, (145) becomes
E
∇xsf 
xt
,xt+1
s−xt
s
≤−ηt˜τ
2∇xsf 
xt2+NηtS2
2NX
n=1a2
n
qn2˜τ2
8˜τ 
ηt2σ2
n+8˜τ 
ηt2ϵ2+8˜τ 
ηt2∇xsf 
xt
s2
≤ 
−ηt˜τ
2+ 8N 
ηt3˜τ3S2NX
n=1a2
n
qn!
∇xsf 
xt2+ 8NηtS2˜τ3NX
n=1a2
n
qn 
ηt2 
σ2
n+ϵ2
.
(147)
45Furthermore, we have
S
2Ehxt+1
s−xt
s2i
=SN(ηt)2
2NX
n=1E
˜τ−1X
i=0anIt
n
qngt,i
s,n2

≤SN(ηt)2
2NX
n=1a2
n
qnE
˜τ−1X
i=0gt,i
s,n2

≤SN(ηt)2˜τ
2NX
n=1a2
n
qn˜τ−1X
i=0Ehgt,i
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn˜τ−1X
i=0Ehgt,i
s,n−gt
s,n+gt
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn˜τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Ehgt
s,n2i
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn˜τ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Eh∇xsFn 
xt2+σ2
ni
, (148)
where the last line uses Assumption C.1 and E
∥z∥2
=∥E[z]∥2+E[∥z−E[z]∥2
for any random
variable z.
By Lemma C.7 with ηt≤1
2S˜τ, we have
˜τ−1X
i=0Ehgt,i
s,n−gt
s,n2i
≤8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
. (149)
Thus, (148) becomes
S
2Ehxt+1
s−xt
s2i
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn
8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
+ ˜τEh∇xsFn 
xt2+σ2
ni
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn
˜τ+ 8˜τ3 
ηt2S2∇xsFn 
xt2+σ2
n
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn
˜τ+ 8˜τ3 
ηt2S2∇xsFn 
xt
− ∇xsf 
xt
+∇xsf 
xt2+σ2
n
≤SN(ηt)2˜τ
2NX
n=1a2
n
qn
˜τ+ 8˜τ3 
ηt2S2
2∇xsf 
xt2+ 2ϵ2+σ2
n
, (150)
F.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is similar to the server. Thus, we have
E
∇xcf 
xt
,xt+1
c−xt
c
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=1a2
n
qn!
∇xcf 
xt2+ 8NηtS2τ3NX
n=1a2
n
qn 
ηt2 
σ2
n+ϵ2
.
(151)
46Forηt≤1
2Sτ,
S
2Ehxt+1
c−xt
c2i
≤SN(ηt)2τ
2NX
n=1a2
n
qn
τ+ 8τ3 
ηt2S2
2∇xcf 
xt2+ 2ϵ2+σ2
n
. (152)
F.3.3 Superposition of M-Server and Clients
Applying (147) ,(150) ,(152) and(151) into(36) in Proposition C.4 and define τmin≜min{τ,˜τ},
τmax≜max{τ,˜τ}we have
E
f 
xt+1
−f 
xt
≤E
∇xcf 
xt
,xt+1
c−xt
c
+S
2Ehxt+1
c−xt
c2i
+E
∇xsf 
xt
,xt+1
s−xt
s
+S
2Ehxt+1
s−xt
s2i
≤ 
−ηtmin{τ,˜τ}
2+ 8N 
ηt3(max{τ,˜τ})3S2NX
n=1a2
n
qn!
∇xf 
xt2
+ 8NηtS2 
τ3+ ˜τ3NX
n=1 
ηt2a2
n
qn 
σ2
n+ϵ2
+SN(ηt)2max{τ,˜τ}
2NX
n=1a2
n
qn
max{τ,˜τ}+ 8 (max {τ,˜τ})3 
ηt2S2
2∇xf 
xt2
+SN(ηt)2τ
2NX
n=1a2
n
qn
τ+ 8τ3 
ηt2S2 
2ϵ2+σ2
n
+SN(ηt)2˜τ
2NX
n=1a2
n
qn
˜τ+8˜τ3 
ηt2S2 
2ϵ2+σ2
n
≤ 
−ηtτmin
2+8N 
ηt3S2τ3
maxNX
n=1a2
n
qn+SN 
ηt2τmaxNX
n=1a2
n
qn
τmax+8τ3
max 
ηt2S2!
∇xf 
xt2
+ 8NηtS2 
τ3+ ˜τ3NX
n=1a2
n
qn 
ηt2 
σ2
n+ϵ2
+1
2SN 
ηt2τ
τ+ 8τ3 
ηt2S2NX
n=1a2
n
qn 
2ϵ2+σ2
n
+1
2SN 
ηt2˜τ
˜τ+ 8˜τ3 
ηt2S2NX
n=1a2
n
qn 
2ϵ2+σ2
n
≤ 
−ηtτmin
2+SN 
ηt2τ2
maxNX
n=1a2
n
qn+8N 
ηt3S2τ3
maxNX
n=1a2
n
qn+8S3N 
ηt4τ4
maxNX
n=1a2
n
qn!
∇xf 
xt2
+ 8N 
ηt3S2τ3NX
n=1a2
n
qnσ2
n+ 8N 
ηt3S2τ3ϵ2NX
n=1a2
n
qn
+SN 
ηt2τ2ϵ2NX
n=1a2
n
qn+1
2SN 
ηt2˜τ2NX
n=1a2
n
qnσ2
n
+ 8NS3 
ηt4τ4ϵ2NX
n=1a2
n
qn+ 4NS3 
ηt4τ4NX
n=1a2
n
qnσ2
n
+ 8N 
ηt3S2˜τ3NX
n=1a2
n
qnσ2
n+ 8N 
ηt3S2˜τ3ϵ2NX
n=1a2
n
qn
+SN 
ηt2˜τ2ϵ2NX
n=1a2
n
qn+1
2SN 
ηt2˜τ2NX
n=1a2
n
qnσ2
n
47+8NS3 
ηt4˜τ4ϵ2NX
n=1a2
n
qn+ 4NS3 
ηt4˜τ4NX
n=1a2
n
qnσ2
n
≤ −ηtτmin
2 
1−2SNηtτ2
max
τminNX
n=1a2
n
qn
1 + 8 Sηtτ+ 8S2 
ηt2τ2
max!
∇xf 
xt2
+1
2NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 4NS3 
ηt4τ4NX
n=1a2
n
qnσ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 8NSL3 
ηt4τ4NX
n=1a2
n
qnϵ2
+1
2NS 
ηt2˜τ2+ 8N 
ηt3S2˜τ3+ 4NS3 
ηt4˜τ4NX
n=1a2
n
qnσ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2˜τ3+ 8NSL3 
ηt4˜τ4NX
n=1a2
n
qnϵ2
≤ −ηtτmin
2 
1−2NSηtτ2
max
τminNX
n=1a2
n
qn
1 +1
2+1
32!
∇xf 
xt2
+NS 
ηt2τ21
2+1
2+1
64NX
n=1a2
n
qnσ2
n+ 2SN 
ηt2τ21
2+1
4+1
64NX
n=1a2
n
qnϵ2
+NS 
ηt2˜τ21
2+1
2+1
64NX
n=1a2
n
qnσ2
n+ 2SN 
ηt2˜τ21
2+1
4+1
64NX
n=1a2
n
qnϵ2
≤ −ηtτmin
2 
1−4NSηtτ2
max
τminNX
n=1a2
n
qn!
∇xf 
xt2+2NS 
ηt2 
τ2+˜τ2NX
n=1a2
n
qn 
σ2
n+ϵ2
≤ −ηtτmin
4∇xf 
xt2+ 2NS 
ηt2 
τ2+ ˜τ2NX
n=1a2
n
qn 
σ2
n+ϵ2
, (153)
where we first let ηt≤1
16Sτmaxand then let ηt≤1
8SNτ2max
τminPN
n=1a2n
qn. We also use ∥∇xf(xt)∥2=
∥∇xcf(xt)∥2+∥∇xsf(xt)∥2.
Rearranging the above we have
ηt∇xf 
xt2≤4
τmin 
f 
xt
−E
f 
xt+1
s
+ 8NS 
ηt2τ2+ ˜τ2
τminNX
n=1a2
n
qn 
σ2
n+ϵ2
(154)
Taking expectation and averaging over all t, we have
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτmin(f(x0)−f∗) +8NSτ2+˜τ2
τmin
TNX
n=1a2
n
qn 
σ2
n+ϵ2T−1X
t=0 
ηt2.
(155)
48G Proof of Theorem 3.9
• In Sec. G.1, we prove the strongly convex case.
• In Sec. G.2, we prove the general convex case.
• In Sec. G.3, we prove the non-convex case.
G.1 Strongly convex case for SFL-V2
G.1.1 One-round Sequential Update for M-Server-Side Model
We first bound the M-server-side model update in one round for full participation ( qn= 1for all n),
and then compute the difference between full participation and partial participation ( qn<1for some
n). We denote It
nas a binary variable, taking 1 if client nparticipates in model training in round t,
and 0 otherwise.
For full participation, Lemma E.1 gives
Ehxt+1
s−x∗
s2i
≤
1−Nηtτµ
2
Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
. (156)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
s−xt+1
s2i
=Ehxt+1
s−xt
s+xt
s−xt+1
s2i
≤Ehxt+1
s−xt
s2i
≤E
NX
n=1ηtIn
t
qnτ−1X
i=0gt,i
s,n 
xt,i
c,n,xt,i
s,n	2

≤NτNX
n=1 
ηt21
qnτ−1X
i=0Ehgt,i
s,n 
xt,i
c,n,xt,i
s,n	2i
≤Nτ2 
ηt2G2NX
n=11
qn, (157)
where we use E∥X−EX∥2≤E∥X∥2,E[It
n] = qn, and xt+1
s =xt
s−
ηtP
n∈Pt(q)Pτ−1
i=01
qngt,i
s,n 
xt,i
c,n,xt,i
s,n	
.
Combining the above gives
Ehxt+1
s−x∗
s2i
=Ehxt+1
s−xt+1
s+xt+1
s−x∗
s2i
≤
1−Nηtτµ
2
Ehxt
s−x∗
s2i
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=11
qn. (158)
49Let∆t+1≜Ehxt+1
s−x∗
s2i
. We can rewrite (158) as:
∆t+1≤
1−ηtNτµ
2
∆t+(ηt)2τ2
4B1+(ηt)3τ3
8B2. (159)
where B1:= 4NPN
n=1 
2σ2
n+G2
+ 4NG2PN
n=11
qnandB:= 192 SPN
n=1 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
Nτ(γs+t), i.e,Nηtτ
2=β
γs+t, where β=2
µ, γs=8S
Nµ−1. It is
easy to show that ηt≤1
2Sτfor all t. We can prove that ∆t≤v
γs+t,∀t. Therefore, we have
Ehxt
s−x∗
s2i
= ∆t≤v
γs+t=maxn
4B1
µ2+8B2
µ3(γs+1),(γs+ 1)Ehx0
s−x∗
s2io
γs+t
≤16NPN
n=1 
2σ2
n+G2
+ 16NG2PN
n=11
qn
µ2(γs+t)+1536SPN
n=1 
2σ2
n+G2
µ3(γs+t) (γs+ 1)
+(γs+ 1)Ehx0
s−x∗
s2i
γs+t. (160)
G.1.2 One-round Parallel Update for Client-Side Models
Define xc
t=PN
n=1anxt
c,n, which represents the aggregating weights in round tfor full par-
ticipation. Using a similar derivation as the M-server side, we first bound the client-side
model update in one round for full participation Ehxt+1
c−x∗
c2i
and then bound the dif-
ference of client-side model parameters between full participation and partial participation
Ehxt+1
c−x∗
c2i
. The overall gradient update rule of clients in each training round is xt+1
c=
xt
c−ηtP
n∈Pt(q)Pτ−1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
Under Assumptions C.1 and C.2, if ηt≤1
2Sτ, in round t, Lemma D.1 gives
Ehxt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (161)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
c−xt+1
c2i
=Ehxt+1
c−xt
c+xt
c−xt+1
c2i
≤Ehxt+1
c−xt
c2i
≤E
NX
n=1ηtanIn
t
qnτ−1X
i=0gt,i
c,n 
xt,i
c,n,xt,i
s,n	2

≤NτNX
n=1 
ηt2a2
n
qnτ−1X
i=0Ehgt,i
c,n 
xt,i
c,n,xt,i
s,n	2i
≤Nτ2 
ηt2G2NX
n=1a2
n
qn, (162)
50where we use E∥X−EX∥2≤E∥X∥2,E[It
n] = qn, and xt+1
c =xt
c−
ηtP
n∈Pt(q)Pτ−1
i=0an
qngt,i
c,n 
xt,i
c,n,xt,i
s,n	
.
We obtain the client-side model parameter update in one round for partial participation by combining
the two terms and we have
Ehxt+1
c−x∗
c2i
=Ehxt+1
c−xt+1
c+xt+1
c−x∗
c2i
≤
1−ηtτµ
2
Ehxt
c−x∗
c2i
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n
qn. (163)
Let∆t+1≜Ehxt+1
c−x∗
c2i
. We can rewrite (163) as:
∆t+1≤
1−ηtτµ
2
∆t+(ηt)2τ2
4B1+(ηt)3τ3
8B2. (164)
where B1 := 4 NPN
n=1a2
n 
2σ2
n+G2
+ 4 NG2PN
n=1a2
n
qnand B2 :=
192SPN
n=1an 
2σ2
n+G2
.
Consider a diminishing stepsize ηt=2β
τ(γc+t), i.e,ηtτ
2=β
γc+t, where β=2
µ, γc=8S
µ−1. It is
easy to show that ηt≤1
2Sτfor all t. For v= maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)∆0o
, we can prove
that∆t≤v
γc+t,∀t. Therefore, we have
Ehxt
c−x∗
c2i
= ∆t≤v
γc+t=maxn
4B1
µ2+8B2
µ3(γc+1),(γc+ 1)Ehx0
c−x∗
c2io
γc+t
≤16NPN
n=1a2
n 
2σ2
n+G2
+ 16NG2PN
n=1a2
n
qn
µ2(γc+t)+1536SPN
n=1an 
2σ2
n+G2
µ3(γc+t) (γc+ 1)
+(γc+ 1)Ehx0
c−x∗
c2i
γc+t. (165)
G.1.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (160) and(165) using Proposition 3.5. For
ηt≤1
2Sτandγ=8S
µ−1, we have
E
f(xT)
−f(x∗)
≤S
2 
E||xT
s−x∗
s||2+E||xT
c−x∗
c||2
≤8SNPN
n=1(a2
n+ 1)
2σ2
n+G2+G2
qn
µ2(γ+T)+768S2PN
n=1(an+ 1) 
2σ2
n+G2
µ3(γ+T) (γ+ 1)
+S(γ+ 1)Ehx0
c−x∗
c2i
2(γ+T)(166)
51G.2 General convex case for SFL-V2
G.2.1 One-round Sequential Update for M-Server-Side Model
By Lemma E.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
. (167)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
s−xt+1
s2i
≤Nτ2 
ηt2G2NX
n=11
qn. (168)
Thus, we have
Ehxt+1
s−x∗
s2i
≤Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=11
qn.(169)
G.2.2 One-round Parallel Update for Client-Side Models
By Lemma D.1 with µ= 0andηt≤1
2Sτ, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
. (170)
Considering that each client nparticipates in model training with a probability qn, we have
Ehxt+1
c−xt+1
c2i
≤Nτ2 
ηt2G2NX
n=1a2
n
qn. (171)
Thus, we have
Ehxt+1
c−x∗
c2i
≤Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1a2
n 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1an 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n
qn.
(172)
G.2.3 Superposition of M-Server and Clients
We merge the M-server-side and client-side models in (169) and (172) as follows
Ehxt+1−x∗2i
≤Ehxt+1
s−x∗
s2i
+Ehxt+1
c−x∗
c2i
,
52≤Ehxt
s−x∗
s2i
−2ηtτE
f 
xt
−f(x∗)
+Ehxt
c−x∗
c2i
−2ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1(a2
n+ 1) 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1(an+ 1) 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n+ 1
qn
=Ehxt−x∗2i
−4ηtτE
f 
xt
−f(x∗)
+ 
ηt2τ2NNX
n=1(a2
n+ 1) 
2σ2
n+G2
+ 24Sτ3 
ηt3NX
n=1(an+ 1) 
2σ2
n+G2
+Nτ2 
ηt2G2NX
n=1a2
n+ 1
qn. (173)
Then, we can obtain the relation between Ehxt+1−x∗2i
andEh
∥xt−x∗∥2i
, which is related to
E[f(xt)−f(x∗)]. Applying Lemma 8 in [17], we obtain the performance bound as
E
f 
xT
−f(x∗)
≤1
2 
NNX
n=1(a2
n+ 1)
2σ2
n+G2+G2
n
qn!1
2 x0−x∗2
T+ 1!1
2
+1
2 
24SNX
n=1(an+ 1) 
2σ2
n+G2!1
3 x0−x∗2
T+ 1!1
3
+Sx0−x∗2
2(T+ 1). (174)
53G.3 Non-convex case for SFL-V2
G.3.1 One-round Sequential Update for M-Server-Side Model
For the server, we have
E
∇xsf 
xt
,xt+1
s−xt
s
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηtτ∇xsf 
xt
−ηtτ∇xsf 
xt
≤E
∇xsf 
xt
,xt+1
s−xt
s+ηtτ∇xsf 
xt
−
∇xsf 
xt
s
, ηtτ∇xsf 
xt
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0It
n
qngt,i
s,n#
+ηtτ∇xsf 
xt+
−ηtτ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	#
+ηtτ∇xsf 
xt+
−ηtτ∇xsf 
xt2
≤*
∇xsf 
xt
,E"
−ηtNX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
+ηtNX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt#+
−ηtτ∇xsf 
xt2
≤ηtτ*
∇xsf 
xt
,E"
−1
τNX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
+1
τNX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt#+
−ηtτ∇xsf 
xt2
≤ηtτ
2∇xsf 
xt2+ηt
2τE
NX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt,i
c,n,xt,i
s,n	
−NX
n=1τ−1X
i=0It
n
qn∇xsFn 
xt2

−ηtτ∇xsf 
xt2
≤ −ηtτ
2∇xsf 
xt2+ηt
2τE
NX
n=1τ−1X
i=0It
n
qn 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηtτ
2∇xsf 
xt2+Nηt
2τNX
n=11
qnE
τ−1X
i=0 
∇xsFn 
xt,i
c,n,xt,i
s,n	
− ∇xsFn 
xt2

≤ −ηtτ
2∇xsf 
xt2+NηtS2
2NX
n=11
qnτ−1X
i=0Ehxt,i
s,n−xt
s2i
, (175)
where we apply Assumption C.1, ∇xsf(xt) =PN
n=1∇xsFn(xt),⟨a, b⟩ ≤a2+b2
2, andE[It
n] =
qn.
By Lemma C.6 with ηt≤1√
8Sτ, we have
τ−1X
i=0Ehxt,i
s,n−xt
s2i
≤2τ2
8τ 
ηt2σ2
n+ 8τ 
ηt2ϵ2+ 8τ 
ηt2∇xsf 
xt
s2
(176)
Thus, (175) becomes
E
∇xsf 
xt
,xt+1
s−xt
s
≤−ηtτ
2∇xsf 
xt2+NηtS2
2NX
n=11
qn2τ2
8τ 
ηt2σ2
n+8τ 
ηt2ϵ2+8τ 
ηt2∇xsf 
xt
s2
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=11
qn!
∇xsf 
xt2+ 8NηtS2τ3NX
n=11
qn 
ηt2 
σ2
n+ϵ2
.
(177)
54Furthermore, we have
S
2Ehxt+1
s−xt
s2i
=SN(ηt)2
2NX
n=1E
τ−1X
i=0It
n
qngt,i
s,n2

≤SN(ηt)2
2NX
n=11
qnE
τ−1X
i=0gt,i
s,n2

≤SN(ηt)2τ
2NX
n=11
qnτ−1X
i=0Ehgt,i
s,n2i
≤SN(ηt)2τ
2NX
n=11
qnτ−1X
i=0Ehgt,i
s,n−gt
s,n+gt
s,n2i
≤SN(ηt)2τ
2NX
n=11
qnτ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Ehgt
s,n2i
≤SN(ηt)2τ
2NX
n=11
qnτ−1X
i=0
Ehgt,i
s,n−gt
s,n2i
+Eh∇xsFn 
xt2+σ2
ni
, (178)
where the last line uses Assumption C.1 and E
∥z∥2
=∥E[z]∥2+E[∥z−E[z]∥2
for any random
variable z.
By Lemma C.7 with ηt≤1
2Sτ, we have
τ−1X
i=0Ehgt,i
s,n−gt
s,n2i
≤8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
. (179)
Thus, (178) becomes
S
2Ehxt+1
s−xt
s2i
≤SN(ηt)2τ
2NX
n=11
qn
8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
+τEh∇xsFn 
xt2+σ2
ni
≤SN(ηt)2τ
2NX
n=11
qn
τ+ 8τ3 
ηt2S2∇xsFn 
xt2+σ2
n
≤SN(ηt)2τ
2NX
n=11
qn
τ+ 8τ3 
ηt2S2∇xsFn 
xt
− ∇xsf 
xt
+∇xsf 
xt2+σ2
n
≤SN(ηt)2τ
2NX
n=11
qn
τ+ 8τ3 
ηt2S2
2∇xsf 
xt2+ 2ϵ2+σ2
n
. (180)
G.3.2 One-round Parallel Update for Client-Side Models
The analysis of the client-side model update is the same as the client’s model update in version 1.
Thus, we have
E
∇xcf 
xt
,xt+1
c−xt
c
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=1a2
n
qn!
∇xcf 
xt2+ 8NηtS2τ3NX
n=1a2
n
qn 
ηt2 
σ2
n+ϵ2
.
(181)
55Forηt≤1
2Sτ,
S
2Ehxt+1
c−xt
c2i
≤SN(ηt)2τ
2NX
n=1a2
n
qn
τ+ 8τ3 
ηt2S2
2∇xcf 
xt2+ 2ϵ2+σ2
n
. (182)
G.3.3 Superposition of M-Server and Clients
Applying (177), (180), (182) and (181) into (36) in Proposition C.4, we have
E
f 
xt+1
−f 
xt
≤E
∇xcf 
xt
,xt+1
c−xt
c
+S
2Ehxt+1
c−xt
c2i
+E
∇xsf 
xt
,xt+1
s−xt
s
+S
2Ehxt+1
s−xt
s2i
≤ 
−ηtτ
2+ 8N 
ηt3τ3S2NX
n=11
qn!
∇xf 
xt2
+ 8NηtS2τ3NX
n=1a2
n+ 1
qn 
ηt2 
σ2
n+ϵ2
+SN(ηt)2τ
2NX
n=11
qn
τ+ 8τ3 
ηt2S2
2∇xf 
xt2
+SN(ηt)2τ
2NX
n=1a2
n+ 1
qn
τ+ 8τ3 
ηt2S2 
2ϵ2+σ2
n
≤ 
−ηtτ
2+ 8N 
ηt3S2τ3NX
n=11
qn+SN 
ηt2τNX
n=11
qn
τ+ 8τ3 
ηt2S2!
∇xf 
xt2
+ 8NηtS2τ3NX
n=1a2
n+ 1
qn 
ηt2 
σ2
n+ϵ2
+1
2SN 
ηt2τ
τ+ 8τ3 
ηt2S2NX
n=1a2
n+ 1
qn 
2ϵ2+σ2
n
≤ 
−ηtτ
2+SN 
ηt2τ2NX
n=11
qn+ 8N 
ηt3S2τ3NX
n=11
qn+ 8S3N 
ηt4τ4NX
n=11
qn!
∇xf 
xt2
+ 8N 
ηt3S2τ3NX
n=1a2
n+ 1
qnσ2
n+ 8N 
ηt3S2τ3ϵ2NX
n=1a2
n+ 1
qn
+SN 
ηt2τ2ϵ2NX
n=1a2
n+ 1
qn+1
2SN 
ηt2τ2NX
n=1a2
n+ 1
qnσ2
n
+ 8NS3 
ηt4τ4ϵ2NX
n=1a2
n+ 1
qn+ 4NS3 
ηt4τ4NX
n=1a2
n+ 1
qnσ2
n
≤ −ηtτ
2 
1−2SNηtτ2
τNX
n=11
qn
1 + 8 Sηtτ+ 8S2 
ηt2τ2!
∇xf 
xt2
+1
2NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 4NS3 
ηt4τ4NX
n=1a2
n+ 1
qnσ2
n
+
NS 
ηt2τ2+ 8N 
ηt3S2τ3+ 8NSL3 
ηt4τ4NX
n=1a2
n+ 1
qnϵ2
56≤ −ηtτ
2 
1−2NSηtτ2
τNX
n=11
qn
1 +1
2+1
32!
∇xf 
xt2
+NS 
ηt2τ21
2+1
2+1
64NX
n=1a2
n+ 1
qnσ2
n+ 2SN 
ηt2τ21
2+1
4+1
64NX
n=1a2
n+ 1
qnϵ2
≤ −ηtτ
2 
1−4N2Sηtτ2
τNX
n=11
qn!
∇xf 
xt2+ 2NS 
ηt2τ2NX
n=1a2
n+ 1
qn 
σ2
n+ϵ2
≤ −ηtτ
4∇xf 
xt2+ 2NS 
ηt2τ2NX
n=1a2
n+ 1
qn 
σ2
n+ϵ2
, (183)
where we first let ηt≤1
16Sτand then let ηt≤1
8SN2τPN
n=11
qn. We have appliedPN
n=1a2
n≤N.
Rearranging the above we have
ηt∇xf 
xt2≤4
τ 
f 
xt
−E
f 
xt+1
s
+ 8NS 
ηt2τNX
n=1a2
n+ 1
qn 
σ2
n+ϵ2
.(184)
Taking expectation and averaging over all t, we have
1
TT−1X
t=0ηtEh∇xf 
xt2i
≤4
Tτ(f(x0)−f∗) +8NSτ
TNX
n=1a2
n+ 1
qn 
σ2
n+ϵ2T−1X
t=0 
ηt2.
(185)
57H Comparative Analysis
H.1 Main technical results
We conclude the convergence results in our paper in Table 1.
Table 1: Performance upper bounds for different objectives (let Q:=PN
n=11
qn).
Scenario Case Method Convergence result
Full participationStrongly convexSFL-V1S
µ(S+µT)(N(σ2+G2) +µSIerr)
SFL-V2S
µ(S+µT)(N2(σ2+G2) +µSIerr)
General convexSFL-V1 (N(σ2+G2)
T)1
2+ (N(σ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(σ2+G2)
T)1
2+ (N2(σ2+G2)
T)1
3+S
TIerr
Non-convexSFL-V1NS(σ2+ϵ2)
T+Ferr
T
SFL-V2N2S(σ2+ϵ2)
T+Ferr
T
Partial participationStrongly convexSFL-V1S
µ(S+µT)(N(σ2+G2(1 +Q)) +µSIerr)
SFL-V2S
µ(S+µT)(N2(σ2+G2(1 +Q)) +µSIerr)
General convexSFL-V1 (N(σ2+G2(1+Q))
T)1
2+ (N(σ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(σ2+G2(1+Q))
T)1
2+ (N2(σ2+G2)
T)1
3+S
TIerr
Non-convexSFL-V1NS(σ2+ϵ2)Q
T+Ferr
T
SFL-V2N2S(σ2+ϵ2)Q
T+Ferr
T
H.2 Comparison of Bounds
We compare our derived bounds for SFL to other distributed approaches. For simplicity, we let
an= 1/Nin (1) and σn=σfor all nin (6). The result are summarized in Table 2. Since different
convergence theories make slightly different assumptions, we clarify them below.
In [ 33],σ2
∗is the variance of the stochastic gradient at the optimum:
Eζn∼Dnh
∥gn(x∗, ζn)− ∇Fn(x∗)∥2i
≤σ2
∗.In [16],Γ = f∗−PN
n=1F∗
n/Ncharacterizes
the client heterogeneity. In [ 17],ϵ2
∗characterizes the client heterogeneity at the optimum, similar to
[12], i.e.,1
NPN
n=1||∇Fn(x∗)||2=ϵ2
∗.
Table 2: Performance upper bounds for strongly convex objectives with full client participation. Here,
absolute constants and polylogarithmic factors are omitted. We further relax the upper bounds of
SFL-V2 for an easier comparison.
Method Performance upper bound
Mini-Batch SGD [33]σ2
∗
µNτT+S(f(x0)−f∗)
µexp
−µT
S
FL
[16]S
µτ+T
σ2+SΓN+Nτ2G2
µN+SIerr
[10]σ2
µNτT+Sσ2
µ2τT2+Sϵ2
µ2T2+µIerrexp
−µT
S
SL [17]σ2
µNτT+Sσ2
µ2NτT2+Sϵ2
∗
µ2NT2+µIerrexp
−µT
S
SFL
SFL-V1 (Theorem 3.6)S
µ(S+µT) 
N(σ2+G2) +µSIerr
SFL-V2 (Theorem 3.7)S
µ(S+µT) 
N2(σ2+G2) +µSIerr
The key observation is that our derived bounds match the other distributed approaches in the order of
Tand they all achieve O(1/T).
58Furthermore, we will compare the convergence upper bounds of SFL to those of distributed SGD in
[12] (with parameters p= 1and¯ζ2= 0) as follows:
Table 3: Performance upper bounds for different objectives with full client participation.
Case Method Convergence results
Strongly convexDistributed SGDσ2
µNT+SIerrexp
−µT
S
SFL-V1S
µ(S+µT)(N(σ2+G2) +µSIerr)
SFL-V2S
µ(S+µT)(N2(σ2+G2) +µSIerr)
General convexDistributed SGD (σ2
NT2+S
T)Ierr
SFL-V1 (N(σ2+G2)
T)1
2+ (N(σ2+G2)
T)1
3+S
TIerr
SFL-V2 (N2(σ2+G2)
T)1
2+ (N2(σ2+G2)
T)1
3+S
TIerr
Non-convexDistributed SGD (σ2
NT2+1
T)SFerr
SFL-V1NS(σ2+ϵ2)
T+Ferr
T
SFL-V2N2S(σ2+ϵ2)
T+Ferr
T
In the aforementioned table, we denote σn=σ, define Ierr≜||x0−x∗||2, and represent Ferr≜
f(x0)−f∗. The absolute constants and polylogarithmic factors are omitted for brevity. Our SFL
algorithms show the same convergence rate as the distributed SGD.
H.3 Comparison of Communication and Computation Overheads
There have been are some papers discussing the overhead of SFL, e.g., [ 27,4]. We mainly use the
analysis from [27].
We start with the definitions. Let Krepresent the total number of clients involved, Ddenote the
aggregate size of the data, and vindicate the size of the smashed layer. The rate of communication is
given by R, while Tfbsignifies the duration required for a complete forward and backward propagation
cycle on the entire model for a dataset of size D, applicable across various architectures. The time
needed to aggregate the full model is expressed as Tfedavg . The full model’s size is denoted by |W|,
andrreflects the proportion of the full model’s size that is accessible to a client in SFL, specifically,
|WC|=r|W|. The factor 2r|W|in the communication per client arises from the necessity for clients
to download and upload their model updates before and after the training process. These findings are
encapsulated in Table 4. It is observed that as Kescalates, the cumulative cost of training time tends
to rise following the sequence: SFL-V2 being less than SFL-V1.
Table 4: Communication and computation comparison between FL, SL, and SFL.
Method Communication per client Total communication Total model training time
FL 2|W| 2K|W| Tfb+2|W|
R+Tfedavg
SL (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
R+2r|W|K
R
SFL-V1 (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
RK+2r|W|
R+Tfedavg
SFL-V2 (2D
K)v+ 2r|W| 2Dv+ 2rK|W| Tfb+2Dv
RK+2r|W|
R+Tfedavg
2
590 50 100 150 200
Training Round020406080100 AccuracySFL-V1
SFL-V2
FLSL
FedProx
FedOpt(a)β= 0.1, N= 10 .
0 50 100 150 200
Training Round020406080100 AccuracySFL-V1
SFL-V2
FLSL
FedProx
FedOpt (b)β= 0.1, N= 100 .
Figure 6: Performance comparison on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round020406080100Accuracy
E=2
E=5E=10 (d) SFL-V2 on CIFAR-100.
Figure 7: Impact of local iteration on SFL performance.
I Additional Experiments
I.1 More comparing methods
We compare the SFL methods with the benchmarks, i.e., FedProx [ 15] and FedOpt [ 19]. We have
used the same hyperparameters, and trained the models on CIFAR-10. The results are provided in
Figure 6. From the figures, we observe that SFL-V2 continues to be the best-performing algorithm.
This is consistent with our observations in the main paper.
I.2 Impact of local iteration
We further study the impact of local epoch number Eon the SFL performance. The results are
reported in Fig. 7. We observe that SFL generally converges faster with a larger τ, demonstrating the
benefit of SFL in practical distributed systems.
I.3 Results using loss metric
We further report the results using the loss metric. More specifically:
•Impact of cut layer : The results are reported in Figs. 8 and 9.
•Impact of data heterogeneity : The results are reported in Fig. 10.
•Impact of partial participation : The results are reported in Fig. 11.
In general, we see similar (but opposite) trends with the observations in the main paper. That is, a
higher accuracy is associated with a smaller loss. These results are again consistent with our theories.
I.4 Results on the impact of the position of cut layer.
We can observe from the results that the performance of SFL-V1 and SFL-V2 increases in Lc. We
look at the impact of the position of cut layer from the gradient perspective. We plot the gradient
divergence in Fig. 12:
600 50 100 150 200
Training Round0.00.10.20.30.40.5LossLc=1
Lc=2Lc=3
Lc=4(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.5LossLc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.20.40.60.81.0LossLc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0LossLc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 8: Impact of the choice of cut layer on SFL training loss.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0246810LossLc=1
Lc=2Lc=3
Lc=4 (d) SFL-V2 on CIFAR-100.
Figure 9: Impact of the choice of cut layer on SFL test loss.
We see for SFL-V1 and SFL-V2, the gradient divergence decreases as we choose a latter cut layer (a
larger Lc). This means that the client drift issue is less severe and hence the performance increases.
In addition, from a theoretical perspective, if we write ϵ2(i.e., upper bound of gradient divergence
defined in Assumption 3.3) as a function of Lc, we can see that the upper bounds of performance
loss decrease in Lc. This provides a theoretical angle that the performance of SFL-V1 and SFL-V2
increases in Lc.
I.5 Results on FEMNIST dataset
We have conducted more simulations on a larger dataset FEMNIST. In particular, we consider
N= 100 and train FL, SFL-V1, SFL-V2. Note that the data come from different sources and are
heterogeneous across clients. The results are reported in Fig. 13.
We note that our key observation continues to hold. That is, SFL-V2 outperforms FL and SFL-V1
under-performs FL under heterogeneous data and a large number of clients.
610 50 100 150 200
Training Round0.00.10.20.30.40.50.6Loss=0.1
=0.5
=1
=
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Loss=0.1
=0.5
=1
=
 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Loss=0.1
=0.5
=1
=
 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Loss=0.1
=0.5
=1
=
 (d) SFL-V2 on CIFAR-100.
Figure 10: Impact of data heterogeneity on SFL training loss.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1
(a) SFL-V1 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1 (b) SFL-V2 on CIFAR-10.
0 50 100 150 200
Training Round0.00.10.20.30.40.50.6Lossq=0.2
q=0.5q=1 (c) SFL-V1 on CIFAR-100.
0 50 100 150 200
Training Round0.00.20.40.60.81.0Lossq=0.2
q=0.5q=1 (d) SFL-V2 on CIFAR-100.
Figure 11: Impact of client participation on SFL training loss.
Figure 12: Results on the impact of the position
of cut layer.
0 100 200 300 400 500
Training Round020406080100Accuracy
V1
V2FLFigure 13: Results on FEMNIST.
62NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: We claim that we provide convergence analysis of split-federated learning
(SFL) for strongly convex, general convex, and non-convex objectives on heterogeneous
data in the abstract and introduction.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: In Section 5, we claim that it is also important to theoretically analyze how the
choice of the cut layer affects the SFL performance.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
63Answer: [Yes]
Justification: Section 3 presents the theoretical results with full set of assumptions. The
proof of Proposition 3.5 is given in Appendix C.4. The complete proofs of Theorems
3.6-3.7 are given in Appendices D-E, respectively. Proofs of Theorems 3.6-3.7 are given in
Appendices D-E, respectively.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Section 4.1 presents the setup of our experiments to reproduce the experimental
results. We further provide our codes in the supplementary material.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
645.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide our codes in the supplementary material. We will provide open
access to the data and code if the paper is accepted.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We present the setup of our experiments, including the datasets and hyperpa-
rameters, in Section 4.1 and provide our codes in the supplementary material.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [No]
Justification: This is a theory paper. Due to limit of computation resources and time, we
were not able to run more experiments.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
65•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: We have used one CPU and one GPU. Specifically, the CPU is Intel(R)
Xeon(R) Gold 5320 CPU with 2.20GHz, and the GPU is A100-PCIE-80GB. Memory:
256GB Storage: 10TB. Each experiment curve takes about 10 hours to train.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We have conformed to all aspects of code of ethics with this submission.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: The goal of this work is to provide a comprehensive analysis on the convergence
of SFL. Our theoretical results have two potential impacts. First, we provide a thorough
understanding on the performance of SFL, which potentially guides the implementation of
SFL (e.g., the choice between FL and SFL, the choice of hyper-parameters and cut layers).
66Second, the convergence results can be used for modeling the training performance of SFL.
Together with an effective modeling of communication and computation overheads of clients,
researchers will be able to perform SFL system optimization. Due to the reduced clients’
training loads in SFL, such a system optimization can potentially minimize the burden
at clients (e.g., human mobile devices) while maintaining client privacy and satisfactory
training performance.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: The paper poses no such risks. We use open-access datasets and models.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: Our codes are based on the codes provided in [ 27], which was cited in the
main paper.
67Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
68Justification: The paper does not involve crowdsourcing nor research with human subjects
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
69