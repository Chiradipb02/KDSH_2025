SPARKLE: A Unified Single-Loop Primal-Dual
Framework for Decentralized Bilevel Optimization
Shuchen Zhu∗
Peking University
shuchenzhu@stu.pku.edu.cnBoao Kong∗
Peking University
kongboao@stu.pku.edu.cnSongtao Lu
IBM Research
songtao@ibm.com
Xinmeng Huang
University of Pennsylvania
xinmengh@sas.upenn.eduKun Yuan†
Peking University
kunyuan@pku.edu.cn
Abstract
This paper studies decentralized bilevel optimization, in which multiple agents col-
laborate to solve problems involving nested optimization structures with neighbor-
hood communications. Most existing literature primarily utilizes gradient tracking
to mitigate the influence of data heterogeneity, without exploring other well-known
heterogeneity-correction techniques such as EXTRA or Exact Diffusion. Addi-
tionally, these studies often employ identical decentralized strategies for both
upper- and lower-level problems, neglecting to leverage distinct mechanisms across
different levels. To address these limitations, this paper proposes SPARKLE , a
unified Single-loop Primal-dual AlgoRithm framewor Kfor decentra Lized bil Evel
optimization. SPARKLE offers the flexibility to incorporate various heterogeneity-
correction strategies into the algorithm. Moreover, SPARKLE allows for different
strategies to solve upper- and lower-level problems. We present a unified conver-
gence analysis for SPARKLE , applicable to all its variants, with state-of-the-art
convergence rates compared to existing decentralized bilevel algorithms. Our
results further reveal that EXTRA and Exact Diffusion are more suitable for de-
centralized bilevel optimization, and using mixed strategies in bilevel algorithms
brings more benefits than relying solely on gradient tracking.
1 Introduction
Numerous modern machine learning tasks, such as reinforcement learning [ 25], meta-learning [ 4],
adversarial learning [ 36], hyper-parameter optimization [ 19], and imitation learning [ 3], entail nested
optimization formulations that extend beyond the traditional single-level paradigm. For instance,
hyper-parameter optimization aims to identify the optimal hyper-parameters for a specific learning
task in the upper level by minimizing the validation loss, achieved through training models in the
lower-level process. This nested optimization structure has spurred significant attention towards
Stochastic Bilevel Optimization (SBO). Since the size of data samples involved in bilevel problems
has become increasingly large, this paper investigates decentralized algorithms over a network of n
agents (nodes) that collaborate to solve the following distributed bilevel optimization problem:
min
x∈RpΦ(x) =f(x, y⋆(x)):=1
nnX
i=1fi(x, y⋆(x)), (upper-level) (1a)
∗Equal Contribution
†Corresponding Author: Kun Yuan. Kun Yuan is also affiliated with National Engineering Labratory for Big
Data Analytics and Applications, and AI for Science Institute, Beijing, China.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).s.t. y⋆(x) = argmin
y∈Rqn
g(x, y):=1
nnX
i=1gi(x, y)o
. (lower-level) (1b)
In this formulation, each agent iholds a private upper-level objective function fi:Rp×Rq→R
and a strongly convex lower-level objective function gi:Rp×Rq→Rdefined as:
fi(x, y) =Eϕ∼Dfi[Fi(x, y;ϕ)], g i(x, y) =Eξ∼Dgi[Gi(x, y;ξ)], (2)
where DfiandDgirepresent the local data distributions at agent i. This paper does not make any
assumptions about these data distributions, implying there might be data heterogeneity across agents.
Linear speedup and transient iteration complexity. A decentralized stochastic algorithm achieves
linear speedup if its iteration complexity decreases linearly with the network size n. Additionally, the
transient iteration complexity refers to the number of transient iterations a decentralized algorithm
must undergo to achieve the asymptotic linear speedup stage. The fewer the transient iterations, the
faster the algorithm can achieve linear speedup. This paper aims to develop decentralized stochastic
bilevel algorithms that can achieve linear speedup with as few transient iterations as possible.
Limitations in previous works. A significant challenge in decentralized bilevel optimization lies
in accurately estimating the hyper-gradient ∇Φ(x)through neighborhood communications. Several
studies have emerged to effectively address this challenge, such as those by [ 9,33,52,16,21,40,57,
29]. However, existing works suffer from several critical limitations:
•Stringent assumptions and inadequate convergence analysis. Many existing studies rely on
stringent assumptions to ensure convergence. For instance, references [ 9,10,33,21,52] assume
bounded gradients, while reference [ 29] assumes bounded data heterogeneity (also known as
bounded gradient dissimilarity). These restrictive assumptions do not arise in centralized bilevel
optimization, implying their potential unnecessity. Moreover, some of these works suffer from
inadequate convergence analysis, unable to clarify the transient iteration complexity [ 9,33,10] or
provide a sharp estimation of the influence of network topologies [52, 21].
•Limited exploration of various heterogeneity-correction techniques. Several concurrent stud-
ies [16,57,40] have utilized Gradient Tracking (GT) [50,13,38] to remove the assumption
of bounded data heterogeneity. However, it remains uncertain whether GTis the most suitable
mechanism for decentralized bilevel optimization. Many other techniques are also useful for
addressing data heterogeneity in single-level decentralized optimization, such as EXTRA [ 45]
and Exact-Diffusion (ED) [ 56,30,54] (which is also known as D2[46]). Even within GT, there
are variants including Adapt-Then-Combine GT (ATC-GT) [ 50], non-ATC-GT [ 38], and semi-
ATC-GT [ 13]. It remains unexplored whether these techniques for mitigating data heterogeneity
converge and even outperform GT when employed in decentralized bilevel algorithms.
•Unknown effects of employing different upper- and lower-level update strategies. In bilevel
optimization, the challenges in solving the upper- and lower-level problems differ substantially.
For instance, the upper-level problem (1a)is non-convex, whereas the lower-level problem (1b)
is strongly convex. Moreover, estimating the gradient at the lower level is considerably simpler
compared to estimating the hyper-gradient at the upper level. Understanding the roles of updates
at each level is crucial to develop more efficient algorithms. However, most existing algorithms
employ the same decentralized methods to solve both the upper- and lower-level problems. For
example, references [ 9,52,29] utilize decentralized gradient descent (DGD) for updates at both
levels while [57, 40, 16] leverage GT, overlooking the potential advantages of mixed strategies.
To address these limitations, several critical questions naturally arise: Should each heterogeneity-
correction mechanism listed in [ 50,13,38,56,30,54,46] be explored one-by-one? Should we
consider combining any two of these techniques to update the upper and lower-level problems,
respectively? It is evident that examining each individual heterogeneity-correction technique, and
even exploring their combinations, would involve an unbearable amount of effort.
Main results and contributions. This paper addresses all the aforementioned limitations without
exhaustively exploring all heterogeneity-correction techniques. Our main results are as follows.
•A unified decentralized bilevel framework. To avoid examining each single heterogeneity-
correction technique, we propose SPARKLE , a unified Single-loop Primal-dual AlgoRithm
2Table 1: Comparison between different decentralized stochastic bilevel algorithms. Kdenotes the number of
(upper-level) iterations; 1−ρdenotes the spectral gap of the mixing matrix (see Assumption 2); b2bounds
the gradient dissimilarity; εis the target stationarity such thatPK−1
k=0E[∥∇Φ(¯xk)∥2]/K < ε ;pandqare the
dimensions of the upper- and lower-level variables, reflecting per-round communication costs. Assumptions
of bounded gradient, Lipschitz continuity, and bounded gradient dissimilarity are abbreviated as BG, LC, and
BGD, respectively. We also list the best-known results of single-level GT, EXTRA, and ED at the bottom.
Algorithms Assumption▷A. Rate.♢A. Comp.†A. Comm.‡Tran. Iter.◁Loopless
DSBO [9] LC1√
K1
ε3 
pqlog(1
ε) +q
ε1
ε2 N.A. No
MA-DSBO [10] LC1√
K1
ε2log(1
ε)q
ε2log(1
ε) +p
ε2 N.A. No
SLAM [33] LC1√
nK1
nε2log(1
ε)p+q
nε2 N.A. No
MDBO [21] BG1√
nK1
nε2log(1
ε)p+q
nε2n3
(1−ρ)8 No
Gossip DSBO [52] BG1√
nK1
nε2log(1
ε)q2
nε2log(1
ε) +pq
nε2n3
(1−ρ)4 No
LoPA [40]∗BGD1√
K1
ε2p+q
ε2 N.A. Yes
D-SOBA [29] BGD1√
nK1
nε2p+q
nε2 maxn
n3
(1−ρ)2,n3b2
(1−ρ)4o
Yes
SPARKLE-GT (ours) None1√
nK1
nε2ap+q
nε2♯maxn
n3
(1−ρ)2,n
(1−ρ)8/3o
Yes
SPARKLE-EXTRA (ours) None1√
nK1
nε2ap+q
nε2♯ n3
(1−ρ)2 Yes
SPARKLE-ED (ours) None1√
nK1
nε2ap+q
nε2♯ n3
(1−ρ)2 Yes
Single-level GT [2, 28] None1√
nK1
nε2p
nε2 maxn
n3
(1−ρ)2,n
(1−ρ)8/3o
Yes
Single-level EXTRA [2] None1√
nK1
nε2p
nε2n3
(1−ρ)2 Yes
Single-level ED [2] None1√
nK1
nε2p
nε2n3
(1−ρ)2 Yes
♢The convergence rate when K→ ∞ (smaller is better).
†The number of gradient/Jacobian/Hessian evaluations per agent to achieve ε-accuracy when ϵ→0(smaller is better).
‡The communication costs per agent to achieve ε-stationarity when ϵ→0(smaller is better).
◁The transient iteration complexity to achieve linear speedup (smaller is better). “N.A.” means that the algorithm cannot
achieve linear speedup or the transient time cannot be accessed from existing convergence analysis.
▷Additional assumptions beyond Assumption 1.
∗LoPA solves the personalized problem, where the lower-level objectives are local to agents.
♯a >0measures the relative sparsity of the mixing weights Wx,Wy,Wz, which can be very small in certain cases. Here
1−ρinTran. Iter. denotes the smallest spectral gap of Wx,Wy,Wz. See more discussions in Appendix C.2.3.
framewor Kfor decentra Lized bil Evel optimization. By specifying certain hyper-parameters,
SPARKLE can be tailored to SPARKLE -EXTRA, SPARKLE -ED, and SPARKLE -GT, which
employ EXTRA [ 45], ED [ 56,30], or multiple GT variants [ 50,13,38], respectively, to facilitate
the upper and lower-level problems. Additionally, SPARKLE is the first algorithm enabling
distinct updating strategies across different levels; for example, one can utilize GT in the upper-
level but ED in the lower-level, resulting in a brand new SPARKLE-GT-ED algorithm.
•A unified and sharp analysis of various heterogeneity-correction schemes. We provide a unified
convergence analysis for SPARKLE, which immediately applies to all SPARKLE variants with
distinct heterogeneity-correction techniques. The analysis does not require restrictive assumptions
such as gradient boundedness used in [ 9,10,33,21,52] or data-heterogeneity bounded used
in [29]. Moreover, our analysis demonstrates the provable superiority of SPARKLE compared to
existing algorithms, as evidenced by the convergence rates listed in Table 1. Most importantly, our
analysis shows that both SPARKLE -EXTRA and SPARKLE -ED outperform SPARKLE -GT
(see Table 1), implying that GT is not the best scheme for decentralized bilevel optimization.
•Mixing strategies outperform employing GT alone. We demonstrate how optimization at
different levels affects convergence rates. Our theoretical analysis suggests that the updating
strategy at the lower level is crucial in determining the overall performance in decentralized bilevel
algorithms. Building upon this insight, we establish that incorporating the ED or EXTRA strategy
in the lower-level update phase leads to better transient iteration complexity than relying solely on
the GT mechanism in both levels as proposed in [10, 16, 40], see Table 2 for more details.
•Comparable performance with single-level algorithms. We elucidate the comparison between
bilevel and single-level stochastic decentralized optimization. On one hand, we demonstrate that
the convergence performance of all our proposed algorithms is not inferior to their single-level
counterparts (see the bottom part in Table 1). On the other hand, by considering specific lower-level
loss functions, our bilevel results directly yield the non-asymptotic convergence of corresponding
3Table 2: The transient iteration complexity of SPARKLE with mixed updating strategies at various levels. The
smaller the transient iteration complexity is, the faster the algorithm will achieve its linear speedup stage. The
first row and column respectively indicate the updating strategy for the upper- and lower-level problems. Please
refer to Appendix B.3 for more implementation details and Appendix C.2.4 for proofs .
lowerupperED EXTRA GT
EDn3
(1−ρ)2n3
(1−ρ)2n3
(1−ρ)2
EXTRAn3
(1−ρ)2n3
(1−ρ)2n3
(1−ρ)2
GT maxn
n3
(1−ρ)2,n
(1−ρ)8/3o
maxn
n3
(1−ρ)2,n
(1−ρ)8/3o
maxn
n3
(1−ρ)2,n
(1−ρ)8/3o
single-level algorithms. This is the first result demonstrating bilevel optimization essentially
subsumes the convergence of the single-level optimization.
Our main results are listed in Table 1. All SPARKLE variants achieve the state-of-the-art asymp-
totic rate, asymptotic gradient complexity, asymptotic communication cost, and transient iteration
complexity under more relaxed assumptions compared to existing methods.
Related works. A significant challenge in decentralized bilevel optimization is accurately estimating
the hyper-gradient ∇Φ(x), necessitating solving global lower-level problems and estimating Hessian
inversion. To this end, various decentralized techniques have been applied in bilevel optimization,
including Neumann series in [ 52], JHIP oracle in [ 9], HIGP oracle in [ 10], and augmented Lagrangian-
based communication in [ 33]. Additionally, reference [ 29] proposes a single-loop algorithm utilizing
decentralized SOBA. To enhance algorithmic robustness against data heterogeneity, recent studies
have employed Gradient Tracking (GT) in both lower- and upper-level optimization. However,
existing works built upon GT suffer from several limitations. Results of [ 16,9] concentrate solely on
deterministic cases, while reference [ 40] addresses personalized problems in the lower-level, which
do not require achieving global consensus in the lower-level problem. Moreover, [ 9,10] introduce
computationally expensive inner loops for GT steps. None of these works can establish smaller
transient iteration complexity than D-SOBA for decentralized SBO, even though the latter algorithm
employs no heterogeneity-correction technique.
The unified framework for single-level decentralized optimization has been extensively studied in the
literature. References [ 1,49,26] propose frameworks for decentralized composite optimization in
deterministic settings, while [ 2] investigates a framework under stochastic settings. However, none
of these works can be directly applied to decentralized bilevel algorithms. Several studies [ 21,57]
utilize variance reduction techniques to accelerate the convergence of stochastic decentralized bilevel
algorithms. Our proposed SPARKLE framework is orthogonal to variance reduction; it can also
incorporate variance-reduced gradient estimation to achieve improved convergence rates. More
relevant works on decentralized optimization and bilevel optimization are discussed in Appendix A.
Notations. We use lowercase letters to represent vectors and uppercase letters to represent matrices.
We introduce col{x1, ..., x n}:= [x⊤
1, ..., x⊤
n]⊤∈Rpnfor brevity. Variables with overbar denote the
average over all agents. For example, ¯xk=Pn
i=1xk
i/n. We denote A=A−1
n1n1⊤
nfor matrix
A∈Rn×n, where 1n∈Rndenotes the n-dimensional vector with all entries being one. For a
function f(x, y) :Rp×Rq→R, we use ∇1f(x, y)∈Rp,∇2f(x, y)∈Rqto represent its partial
gradients with respect to xandy, respectively. Similarly, ∇12f(x, y)∈Rp×q,∇22f(x, y)∈Rq×q
represent the corresponding Jacobian and Hessian matrix. We use the notation ≲to denote inequalities
that hold up to constants related to the initialization of algorithms and smoothness constants.
2SPARKLE : A unified framework for decentralized bilevel optimization
This section develops SPARKLE , a unified framework for decentralized bilevel optimization, and
discusses its numerous variants by specifying certain hyper-parameters.
2.1 Three pillar subproblems in decentralized bilevel optimization.
When solving the upper-level problem (1a), it is critical to obtain the hyper-gradient ∇Φ(x), which
can be expressed as [22]
∇Φ(x) =∇1f(x, y⋆(x))− ∇2
12g(x, y⋆(x))
∇2
22g(x, y⋆(x))−1∇2f(x, y⋆(x)). (3)
4Evaluating this hyper-gradient is computationally expensive due to the inversion of the Hessian matrix.
This evaluation becomes even more challenging over a decentralized network of collaborative agents.
First, the inverse of the Hessian matrix cannot be obtained by simply averaging the local Hessian
inverses due to [1
nPn
i=1∇2
22gi(x, y⋆(x))]−1̸=1
nPn
i=1[∇2
22gi(x, y⋆(x))]−1. Second, the global
averaging operation cannot be realized through decentralized communication. To overcome these
challenges, one can introduce an auxiliary variable z⋆(x):= [∇2
22g(x, y⋆(x))]−1∇2f(x, y⋆(x))[12],
which is the solution to a quadratic problem
z⋆(x) = argmin
z∈Rq1
2z⊤∇2
22g(x, y⋆(x))z−z⊤∇2f(x, y⋆(x))
. (4)
Once z⋆(x)is derived by solving (4), we can substitute it into (3) to achieve ∇Φ(x).
Following this idea, solving the distributed bilevel optimization problem (1)essentially involves
solving three subproblems, where hi(x, y⋆(x), z) :=1
2z⊤∇2
22gi(x, y⋆(x))z−z⊤∇2fi(x, y⋆(x)),
x⋆= argmin
x∈Rp1
nnX
i=1fi(x, y⋆(x)), (upper-level) (5a)
y⋆(x) = argmin
y∈Rq1
nnX
i=1gi(x, y), (lower-level) (5b)
z⋆(x) = argmin
z∈Rq1
nnX
i=1hi(x, y⋆(x), z). (auxiliary-level) (5c)
Given the variable x, one can achieve y⋆(x)by solving the lower-level problem in (5b). With y⋆(x)
determined, z⋆(x)can be obtained by solving the auxiliary-level problem in (5c). Subsequently, with
z⋆(x)available, one can directly compute the hyper-gradient and solve the upper-level problem in
(5a) using gradient descent. This constitutes the primary methodology to solve problem (1).
A bilevel algorithm essentially solves three subproblems listed in (5), each formulated as a single-level
decentralized optimization problem. Nevertheless, primary approaches may suffer from nested loops
in algorithmic development. A few recent studies [ 12,11,57,29] propose to solve each problem in
(5a)-(5c)approximately with one single iteration, leading to practical single-loop bilevel algorithms.
For example, applying a D-SGD step [ 43] to each of (5a)-(5c)yields the D-SOBA method [ 29], while
further leveraging the GT technique leads to decentralized bilevel methods in [9, 16, 57, 21].
However, it is less explored whether numerous other heterogeneity-correction techniques [ 50,13,
38,56,30,54,46] beyond GT can be incorporated into algorithmic design to achieve even better
performance in bilevel optimization. To avoid exploring each case individually, we next introduce a
general framework that unifies all these techniques for solving single-level problems.
2.2 A unified framework for decentralized single-level optimization.
In this subsection, we consider solving the single-level problem minx∈Rp1
nPn
i=1fi(x)over a
network of nnodes. For each k-th (k≥0) iteration, we let xk
idenote the local x-variable maintained
by the i-th agent. Furthermore, we associate the topology with a weight matrix W= [wij]n
i,j=1∈
Rn×nin which wij∈(0,1)if node jis connected to node iotherwise wij= 0. We use bold symbols
to denote stacked vectors or matrices across agents. For example, xk=col{xk
1, ..., xk
n} ∈Rpnand
W=W⊗Ip, where ⊗denotes the Kronecker product operator.
A unified framework with moving average. Building on the formulation in [ 1,2], we develop a
unified primal-dual framework with moving average for decentralized optimization:
rk+1= (1−θ)rk+θgk,xk+1=Cxk−αArk+1−Bdk,dk+1=dk+Bxk+1. (6)
Herexkdenotes the primal variable, dkdenotes the dual variable introduced to mitigate the influence
of data-heterogeneity, gkstacks all (stochastic) gradients evaluated at xk
ifor1≤i≤n,rkdenotes
the momentum introduced to boost training with coefficient θ∈[0,1], andα >0is the learning rate.
Matrices A,B,C∈Rpn×pnare adapted from the mixing matrix W, which determine how agents
communicate with each other. See Appendix B.1 for more detailed motivations.
Framework (6)unifies various decentralized techniques in the literature. For instance, by letting
θ= 1and specifying A,B,Cdelicately, framework (6)reduces to ED, EXTRA, and numerous GT
5Algorithm 1 SPARKLE: A unified framework for decentralized stochastic bilevel optimization
Require: Initialize x0=y0=z0=r0=0,d0
x=d0
y=d0
z=0, learning rate αk, βk, γk, θk.
fork= 0,1,···, K−1do
yk+1=Cyyk−βkAyvk−Bydk
y,dk+1
y=dk
y+Byyk+1; ▷lower-level update
zk+1=Czzk−γkAzpk−Bzdk
z,dk+1
z=dk
z+Bzzk+1; ▷auxiliary-level update
rk+1= (1−θk)rk+θkuk; ▷momentum update
xk+1=Cxxk−αkAxrk+1−Bxdk
x,dk+1
x=dk
x+Bxxk+1; ▷upper-level update
end for
variants, see Table 3 and Appendix B.1 for more details. Framework (6)is closely related to the
unified decentralized method developed in [ 1,2]. The primary difference lies in the incorporation
of the momentum variable rk, which can help improve the transient iteration complexity of the
framework (6)and relax the smoothness condition for bilevel algorithms [ 11]. A detailed comparison
between framework (6) and that proposed in [1, 2] is provided in Appendix B.2.
2.3 A unified framework for decentralized bilevel optimization.
By utilizing the unified framework (6)to approximately solve each subproblem in (5)with only
one iteration , we achieve SPARKLE, a unified single-loop framework for decentralized bilevel
optimization. In particular, we independently sample data ξk
i∼ D fi,ζk
i∼ D giwithin each node at
iteration k, and evaluate stochastic gradients/Jacobians/Hessians as follows
lk
i=∇1Fi(xk
i, yk
i;ξk
i), bk
i=∇2Fi(xk
i, yk
i;ξk
i), vk
i=∇2Gi(xk
i, yk
i;ζk
i),
Jk
i=∇2
12Gi(xk
i, yk
i;ζk
i), Hk
i=∇2
22Gi(xk
i, yk
i;ζk
i).
Next we stack the descent directions for variables of each level as follows
lower-level stochstic gradient: vk=col{vk
1, ..., vk
n},
auxilliary-level stochstic gradient: pk=col{Hk
1zk
1−bk
1, ..., Hk
nzk
n−bk
n},
upper-level stochstic gradient: uk=col{lk
1−Jk
1zk+1
1, ..., lk
n−Jk
nzk+1
n}.
The SPARKLE algorithm is detailed in Algorithm 1. In this algorithm, we utilize different dual
variables dsand communication matrices As,Bs,Csfor each variable s∈ {x, y, z}to optimize
their respective objective functions. We use momentum rkonly for updating the upper-level variable,
which is sufficient to enhance convergence of bilevel algorithms and relax the smoothness condition.
Versatility in decentralized strategies. SPARKLE is highly versatile, supporting various decentral-
ized strategies by allowing the specification of different communication matrices As,Bs, andCs.
For example, by setting As=I,Bs= (I−W)1/2, andCs=Wfor any s∈ {x, y, z}, SPARKLE
will utilize EXTRA to update variables x,y, andz, resulting in the SPARKLE-EXTRA variant. Other
variants can be achieved by setting As,Bs, andCsaccording to Table 3. These variants can be
implemented more efficiently than listed in Algorithm 1, see Appendix B.3.
Flexibility across optimization levels. SPARKLE supports different optimization and communi-
cation mechanisms for each level of (5), which can be directly achieved by choosing different As,
Bs, andCsmatrices for each level s∈ {x, y, z}. For example, SPARKLE can utilize GT to update
the upper-level variable xwhile employing ED to update the auxiliary- and lower-level variables y
andz. Throughout this paper, we denote SPARKLE using the decentralized mechanism Lfor the
lower-level and auxiliary variables, and Ufor the upper-level in Algorithm 1, by SPARKLE- L-U,
or simply SPARKLE- LifL=U. In addition, SPARKLE even supports utilizing different mixing
matrices Wx,Wy,Wzacross levels.
3 Convergence analysis
In this section, we establish the convergence properties of the SPARKLE framework and examine
the influence of different decentralized techniques utilized across optimization levels.
6Table 3: SPARKLE facilitates different decentralized techniques by specifying As,Bs,Csfors∈{x, y, z}.
We denote the stacked local variables and the associate gradients estimates by s∈{x,y,z}andg(s), respectively.
The update rule refers to the specific algorithmic recursion for each level. See derivations in Appendix B.2.
Algorithms As Bs CsThe specific update rule at the k-th iteration.
ED Ws(I−Ws)1
2Wssk+2=Ws 
2sk+1−sk−α 
g(sk+1)−g(sk)
EXTRA I (I−Ws)1
2Wssk+2=Ws 
2sk+1−sk
−α 
g(sk+1)−g(sk)
ATC-GT W2
sI−WsW2
ssk+1=Ws 
sk−αhk
s
,hk+1
s=Ws 
hk
s+g(sk+1)−g(sk)
Semi-ATC-GT WsI−WsW2
ssk+1=Wssk−αhk
s,hk+1
s=Ws 
hk
s+g(sk+1)−g(sk)
Non-ATC-GT I I −WsW2
ssk+1=Wssk−αhk
s,hk+1
s=Wshk
s+g(sk+1)−g(sk)
3.1 Assumptions
Before presenting the theoretical guarantees, we first introduce the following assumptions used
throughout this paper.
Assumption 1. There exist constants µg, Lf,0, Lf,1, Lg,1, Lg,2such that for any 1≤i≤n,
1.∇fi,∇gi,∇2giareLf,1, Lg,1, Lg,2Lipschitz continuous, respectively;
2.∥∇2fi(x, y⋆(x))∥ ≤Lf,0for any x∈Rp;3
3.gi(x, y)isµg-strongly convex with respect to yfor any fixed x∈Rp.
Moreover, we define L:= max {Lf,0, Lf,1, Lg,1, Lg,2}andκ:=L/µ g.
Assumption 2. For each s∈ {x, y, z}, the corresponding mixing matrix Ws∈Rn×nis non-negative,
symmetric and doubly stochastic, i.e.,
Ws=W⊤
s, W s1n=1n,(Ws)ij≥0,∀1≤i, j≤n,
and the corresponding communication graph is strongly-connected, i.e., its eigenvalues satisfy
1 =λ1(Ws)> λ2(Ws)≥. . .≥λn(Ws)andρ(Ws):= max {|λ2(Ws)|,|λn(Ws)|}<1.
The value 1−ρ(Ws)is referred to as the spectral gap in the literature [ 34,53,31] ofWs, which
measures the connectivity of the communication graph. It would approach 0for sparse networks. For
example, it holds that 1−ρ(Ws) = Θ(1 /n2)for the matrix Wsinduced by a ring graph.
Assumption 3. For any s∈ {x, y, z}, we assume the communication matrices As, Bs, Csused in
SPARKLE are polynomial functions of Ws. Furthermore, we assume As, Csare doubly stochastic,
andNull( Bs) = Span {1n}. In addition, we assume all eigenvalues of the augmented matrix
Ls:=
Cs−B2
sBs
−Bs In
are strictly less than one in magnitude, where Cs≜Cs−1
n1n1⊤
nandIn≜In−1
n1n1⊤
n.
We remark that Assumption 3 is mild and is satisfied by all choices listed in Table 3. See more
discussions in Appendix C.2.2.
Assumption 4. We assume ∇Fi(x, y;ξ),∇Gi(x, y;ξ), and∇2Gi(x, y;ξ)to be unbiased estimates
of∇fi(x, y),∇gi(x, y), and∇2gi(x, y)with bounded variances σ2
f,1, σ2
g,1, σ2
g,2, respectively.
3.2 Convergence theorem
Under the above assumptions, we establish the convergence properties as follows. Proof details can
be found in Appendix C.
3This is more relaxed than Lipschitz continuous fi, or bounded ∇2fiin [21, 57, 33, 11].
7Theorem 1. Under Assumptions 1 – 4, there exist proper constant step-sizes α, β, γ and momentum
coefficient θ, such that the SPARKLE framework listed in Algorithm 1 will converge as follow:
1
K+ 1KX
k=0E[∥∇Φ(¯xk)∥2]≲κ5σ√
nK+κ16
3(δy,1+δz,1)σ2
3
K2
3+κ7
2δx,1σ1
2
K3
4
+
κ26
5δy,2+κ6δz,2σ2
5
K4
5+
κ16
3δy,3+κ14
3δz,3+κ8
3δx,31
K+ 
κCα+κ4Cθ1
K,
where σ≜max{σf,1, σg,1, σg,2},{δs,i}3
i=1are constants depending only on Ws,As,Bs,Csfor
s∈ {x, y, z}, and Cα, Cθare constants independent of K. See Lemma 17 for their detailed values.
In the deterministic scenario with σ= 0,SPARKLE converges at the rate O(1/K), see the formal
theorem and derivation in Appendix C.3. This recovers the rate in [ 15] under even milder assumptions.
Unlike reference [ 15], which only considers GT in the deterministic setting, SPARKLE is a unified
bilevel framework for the more general stochastic setting.
Linear speedup. According to Theorem 1, SPARKLE achieves an asymptotic linear speedup
asKapproaches infinity, which applies to all SPARKLE variants regardless of the decentralized
strategies employed and whether they are utilized at different optimization levels. Furthermore, the
asymptotically dominant term κ5σ/(√
nK)matches exactly with the single-node bilevel algorithm
SOBA [12] when n= 1, implying the tightness of Theorem 1 in terms of the asymptotic rate.
Remark 1. We establish an upper bound for the consensus error1
KKP
k=0Eh
∥xk−¯xk∥2
n+∥yk−¯yk∥2
ni
.
Please refer to Lemma 19 in Appendix C.2.1 for more details.
3.3 Transient iteration complexity
With the non-asymptotic rate established in Theorem 1, we can derive the transient iteration complex-
ity of SPARKLE as follows. The proof is in Lemma 18.
Corollary 1. Under the same assumptions as in Theorem 1, the transient iteration complexity of
SPARKLE —with the influence of κandσ2omitted for brevity—is on the order of
maxn
n2δx, n3δy, n3δz, nˆδx, nˆδy, nˆδzo
, (8)
where δs,ˆδsonly depend Ws,As,Bs,Csfors∈ {x, y, z}. Their values are in Lemma 18.
We obtain the transient iteration complexity of each variant of SPARKLE by applying Corollary 1.
Corollary 2. ForSPARKLE-ED andSPARKLE-EXTRA , if we choose Wy=Wz, it holds that
δx=O 
(1−ρ(Wx))−2
, δ y=δz=O 
(1−ρ(Wy))−2
,
ˆδx=O
(1−ρ(Wx))−3
2
, ˆδy=ˆδz=O 
(1−ρ(Wy))−2
.(9)
Furthermore, if we choose Wx=Wy=Wzand denote ρ≜ρ(Wx), the transient iteration
complexity derived in (8)can be simplified as n3/(1−ρ)2.
Corollary 3. ForSPARKLE-GT and its variants with semi/non-ATC-GT, if we let Wy=Wz,
δx=O 
(1−ρ(Wx))−2
, δ y=δz=O 
(1−ρ(Wy))−2
,
ˆδx=O 
(1−ρ(Wx))−2
, ˆδy=ˆδz=O
(1−ρ(Wy))−8
3
.
Furthermore, if we let Wx=Wy=Wzand denote ρ≜ρ(Wx), the transient iteration complexity
derived in (8)can be simplified as max{n3/(1−ρ)2, n/(1−ρ)8/3}.
Remark 2 (SOTA transient iterations) .Comparing with algorithms listed in Table 1, all SPARKLE
variants achieve smaller transient iteration complexity, implying that they can achieve linear speedup
much faster than the other algorithms, especially over sparse network topologies with 1−ρ→0.
Remark 3 (GT is not the best technique for decentralized SBO) .While GT is widely adopted in the
literature [ 16,21,57] to facilitate decentralized SBO, a comparison of Corollary 2 and 3 reveals that
both SPARKLE-EXTRA andSPARKLE-ED outperform SPARKLE-GT in terms of transient
iteration complexity. This implies that EXTRA and ED are better than GT for decentralized SBO.
83.4 Different strategies across optimization levels
Corollary 1 clarifies how different update strategies for x,y, and zimpact the transient iterations
through constants {δs,ˆδs}fors∈ {x, y, z}. Since δy=δzandˆδy=ˆδzwhen Wy=Wz
(Lemma 18), we naturally employ the same strategy to update yandz. The following corollary
studies the utilization of both ED and GT in SPARKLE . See the transient iterations complexity of
other mixed strategies in Appendix C.2.4 and Table 2.
Corollary 4. ForSPARKLE-ED-GT which uses ED to update yandzand GT to update x, if
Wx=Wy=Wzand we denote ρ=ρ(Wx), it then holds that
δx=δy=δz=O 
(1−ρ)−2
, ˆδx=ˆδy=ˆδz=O 
(1−ρ)−2
,
which implies that the transient iteration complexity in (8)can be simplified as n3/(1−ρ)2.
Remark 4 (Mixed strategies outperform employing GT only) .Comparing Corollary 3 and 4, we find
that using ED to update yandzwill lead to smaller ˆδyandˆδz, which improves the transient iteration
complexity compared to employing GT only in all optimization levels (see Corollary 3) .
3.5 Different topologies across optimization levels
In SPARKLE, we can utilize different topologies across levels. Theorem 1 and Corollary 1 have
clarified the influence of using different topologies across levels through the constants {δs,ˆδs}for
s∈ {x, y, z}. For instance, when substituting {δs,ˆδs}established in (9)into(8), SPARKLE-ED has
the following transient iteration complexity:
max{n2(1−ρ(Wx))−2, n3(1−ρ(Wy))−2}
where Wxis the mixing matrix for updating x, while Wyis for updating yandz. As long as
(1−ρ(Wx))−1≲√n(1−ρ(Wy))−1holds, SPARKLE-ED retains the transient iteration complexity
ofn3(1−ρ(Wy))−2, which allows for the utilization of a sparser network topology when updating
x, thereby reducing communication overheads. Consequently, the ratio aof the communication
volume per round for the variables xandycan be significantly less than one. See Appendix C.2.3 for
discussion on how to use different topologies across levels in other SPARKLE variants.
3.6 Recovering single-level decentralized optimization
Previous works typically study single-level and bilevel optimization separately. By taking
Gi(x, y, ξ )≡ |y|2/2andFi(x, y, ϕ ) =Fi(x, ϕ)into (2), the decentralized SBO problem (1)re-
duces to stochastic single-level optimization. By setting zk≡0,yk≡0,uk
i=∇1fi(xk
i, ξk
i),
SPARKLE reduces to the single-level framework (6), whose convergence can be naturally guaranteed
by Theorem 1. Please refer to Appendix C.4 for the detailed proof and results. This is the first
result demonstrating that bilevel optimization essentially subsumes the convergence of single-level
optimization.
4 Numerical experiments
In this section, we present experiments to validate our theoretical findings. We first explore how
update strategies and network structures influence the convergence of SPARKLE . Then we com-
pare SPARKLE to the existing decentralized SBO algorithms. Additional experiments about a
decentralized SBO problem with synthetic data are in Appendix D.1.
Hyper-cleaning on FashionMNIST dataset. We consider a data hyper-cleaning problem [ 44] on
a corrupted FashionMNIST dataset [ 48]. Problem formulations and experimental setups can be
found in Appendix D.2. Firstly, we equip SPARKLE with different decentralized strategies in
different optimization levels and then compare them with D-SOBA [ 29], MA-DSBO-GT [ 10], and
MDBO [ 21] using the corruption rate p= 0.1,0.2,0.3, respectively. As is shown in Figure 1, all
theSPARKLE -based algorithms generally achieve higher test accuracy than D-SOBA, while ED
and EXTRA especially outperform GT. Meanwhile, using mixed strategies ( i.e.,SPARKLE -ED-GT
andSPARKLE -EXTRA-GT) achieves similar test accuracy with SPARKLE -ED and SPARKLE -
EXTRA and outperform SPARKLE -GT, respectively. These observations match with the theoretical
results in Corollary 2-4 and Remark 3, 4.
90 250 500 750 1000 1250 1500 1750 2000
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SPARKLE/uni00ADED/uni00ADGTSPARKLE/uni00ADEXTRA/uni00ADGT
D/uni00ADSOBA
MA/uni00ADDSBO/uni00ADGT
MDBO
0 500 1000 1500 2000 2500 3000
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SPARKLE/uni00ADED/uni00ADGTSPARKLE/uni00ADEXTRA/uni00ADGT
D/uni00ADSOBA
MA/uni00ADDSBO/uni00ADGT
MDBO
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SPARKLE/uni00ADED/uni00ADGTSPARKLE/uni00ADEXTRA/uni00ADGT
D/uni00ADSOBA
MA/uni00ADDSBO/uni00ADGT
MDBOFigure 1: The test accuracy on hyper-cleaning with various SPARKLE -based algorithms using different
corruption rates p. (Left: p= 0.1, Middle: p= 0.2, Right: p= 0.3.)
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(a)SPARKLE-EXTRA; Fixed topo x; Varied topo of y,z
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(b)SPARKLE-EXTRA; Fixed topo y,z; Varied topo of x
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
Figure 2: Test accuracy of SPARKLE-EXTRA on
hyper-cleaning. (Left: fixed graph for xand varying
graph for y, z; Right: fixed for y, zand varying for x)
0 250 500 750 1000 1250 1500 1750 2000
sample size0.00.51.01.52.02.53.03.54.0upper level loss1600 1700 1800 19000.270.280.29SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRASLDBO
MDBO
0 250 500 750 1000 1250 1500 1750 2000
sample size0.00.51.01.52.02.53.03.54.0upper level loss1600 1700 1800 19000.320.33SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRASLDBO
MDBOFigure 3: The upper-level loss against samples gener-
ated by one agent of different algorithms in the policy
evaluation. (Left: n= 10 , Right: n= 20 .)
Next, we test SPARKLE -EXTRA with two communication strategies including fixed topology for
updating xand varying topology for y, z, and fixed topology for updating y, zand varying topology
forx. As illustrated in Figure 2, maintaining a fixed topology for xwhile reducing the connectivity
of the topology for yandzwill deteriorate the algorithmic performance. Conversely, preserving the
topology for yandzwhile decreasing the connectivity for xhas little impact on the performance.
This suggests that the influence of the network topology for yandzon the algorithm dominates
over the topology for x, which is consistent with our discussion in Section 3.5. We also numerically
examine the influence of moving average on convergence, see discussions in Appendix D.2.
Distributed policy evaluation in reinforcement learning. We consider a multi-agent MDP problem
in reinforcement learning on a distributed setting with n∈ {10,20}agents respectively, which can
be formulated as a decentralized SBO problems [ 52]. Here, we compare SPARKLE with existing
decentralized SBO approaches including MDBO [ 21] and the stochastic extension of SLDBO [ 16]
over a Ring graph. Figure 3 illustrates that SPARKLE converges faster and achieves a lower sample
complexity than the other baselines, especially when n= 20 , which shows the empirical benefits of
SPARKLE in decentralized SBO algorithms with a large number of agents and sparse communication
modes. More experimental details are in Appendix D.3.
Decentralized meta-learning. We investigate decentralized meta-learning on miniImageNet [ 47]
with multiple tasks [ 18], formulating it as a decentralized bilevel optimization problem. This approach
minimizes the validation loss with respect to shared parameters as the upper-level loss, while the
training loss is managed by task-specific parameters at the lower level. Additional details about
the experiment can be found in Appendix D.4. Our method, SPARKLE , is benchmarked against
D-SOBA [29] and MAML [18], demonstrating a significant improvement in training accuracy.
5 Conclusions and limitations
This paper proposes SPARKLE, a unified single-loop primal-dual framework for decentralized
stochastic bilevel optimization. Being highly versatile, SPARKLE can support different decentralized
mechanisms and topologies across optimization levels. Moreover, all SPARKLE variants have been
demonstrated to achieve state-of-the-art convergence rate compared to existing algorithms. However,
SPARKLE currently supports only strongly-convex problems in the lower-level optimization. Its
compatibility with generally-convex lower-level problems remains unknown. Additionally, the
condition number of the lower-level problem significantly impacts the performance, as is the case
with existing bilevel algorithms. We aim to address these limitations in future work.
106 Acknowledgment
The work of Shuchen Zhu, Boao Kong, and Kun Yuan is supported by Natural Science Foundation
of China under Grants 92370121, 12301392, and W2441021. This work is also supported by Open
Project of Key Laboratory of Mathematics and Information Networks, Ministry of Education, China.
No. KF202302.
References
[1]S. A. Alghunaim, E. K. Ryu, K. Yuan, and A. H. Sayed. Decentralized proximal gradient algorithms with
linear convergence rates. IEEE Transactions on Automatic Control , 66(6):2787–2794, 2020.
[2]S. A. Alghunaim and K. Yuan. A unified and refined convergence analysis for non-convex decentralized
learning. IEEE Transactions on Signal Processing , 2022.
[3]S. Arora, S. Du, S. Kakade, Y . Luo, and N. Saunshi. Provable representation learning for imitation learning
via bi-level optimization. In International Conference on Machine Learning , pages 367–376. PMLR, 2020.
[4]L. Bertinetto, J. Henriques, P. Torr, and A. Vedaldi. Meta-learning with differentiable closed-form solvers.
InInternational Conference on Learning Representations (ICLR), 2019 . International Conference on
Learning Representations, 2019.
[5]T.-H. Chang, M. Hong, and X. Wang. Multi-agent distributed optimization via inexact consensus admm.
IEEE Transactions on Signal Processing , 63(2):482–497, 2014.
[6]J. Chen and A. H. Sayed. Diffusion adaptation strategies for distributed optimization and learning over
networks. IEEE Transactions on Signal Processing , 60(8):4289–4305, 2012.
[7]T. Chen, Y . Sun, Q. Xiao, and W. Yin. A single-timescale method for stochastic bilevel optimization. In
International Conference on Artificial Intelligence and Statistics , pages 2466–2488. PMLR, 2022.
[8]T. Chen, Y . Sun, and W. Yin. Closing the gap: Tighter analysis of alternating stochastic gradient methods
for bilevel problems. Advances in Neural Information Processing Systems , 34:25294–25307, 2021.
[9]X. Chen, M. Huang, and S. Ma. Decentralized bilevel optimization. arXiv preprint arXiv:2206.05670 ,
2022.
[10] X. Chen, M. Huang, S. Ma, and K. Balasubramanian. Decentralized stochastic bilevel optimization with
improved per-iteration complexity. In International Conference on Machine Learning , pages 4641–4671.
PMLR, 2023.
[11] X. Chen, T. Xiao, and K. Balasubramanian. Optimal algorithms for stochastic bilevel optimization under
relaxed smoothness conditions. arXiv preprint arXiv:2306.12067 , 2023.
[12] M. Dagréou, P. Ablin, S. Vaiter, and T. Moreau. A framework for bilevel optimization that enables
stochastic and global variance reduction algorithms. Advances in Neural Information Processing Systems ,
35:26698–26710, 2022.
[13] P. Di Lorenzo and G. Scutari. Next: In-network nonconvex optimization. IEEE Transactions on Signal
and Information Processing over Networks , 2(2):120–136, 2016.
[14] J. Domke. Generic methods for optimization-based modeling. In Artificial Intelligence and Statistics ,
pages 318–326. PMLR, 2012.
[15] J. Dong, Z. Cao, T. Zhang, J. Ye, S. Wang, F. Feng, L. Zhao, et al. Eflops: Algorithm and system co-design
for a high performance distributed training platform. In 2020 IEEE International Symposium on High
Performance Computer Architecture (HPCA) , pages 610–622, 2020.
[16] Y . Dong, S. Ma, J. Yang, and C. Yin. A single-loop algorithm for decentralized bilevel optimization. arXiv
preprint arXiv:2311.08945 , 2023.
[17] J. C. Duchi, A. Agarwal, and M. J. Wainwright. Dual averaging for distributed optimization: Convergence
analysis and network scaling. IEEE Transactions on Automatic control , 57(3):592–606, 2011.
[18] C. Finn, P. Abbeel, and S. Levine. Model-agnostic meta-learning for fast adaptation of deep networks.
International Conference on Machine Learning , pages 1126–1135, 2017.
11[19] L. Franceschi, P. Frasconi, S. Salzo, R. Grazzi, and M. Pontil. Bilevel programming for hyperparameter
optimization and meta-learning. In International Conference on Machine Learning , pages 1568–1577.
PMLR, 2018.
[20] B. Gao, Y . Yang, and Y . xiang Yuan. Lancbio: dynamic lanczos-aided bilevel optimization via krylov
subspace. arXiv preprint arXiv:2404.03331 , 2024.
[21] H. Gao, B. Gu, and M. T. Thai. On the convergence of distributed stochastic bilevel optimization algorithms
over a network. In International Conference on Artificial Intelligence and Statistics , pages 9238–9281.
PMLR, 2023.
[22] S. Ghadimi and M. Wang. Approximation methods for bilevel programming. arXiv preprint
arXiv:1802.02246 , 2018.
[23] R. Grazzi, L. Franceschi, M. Pontil, and S. Salzo. On the iteration complexity of hypergradient computation.
InInternational Conference on Machine Learning , pages 3748–3758. PMLR, 2020.
[24] Z. Guo, Q. Hu, L. Zhang, and T. Yang. Randomized stochastic variance-reduced methods for multi-task
stochastic bilevel optimization. arXiv preprint arXiv:2105.02266 , 2021.
[25] M. Hong, H.-T. Wai, Z. Wang, and Z. Yang. A two-timescale stochastic algorithm framework for
bilevel optimization: Complexity analysis and application to actor-critic. SIAM Journal on Optimization ,
33(1):147–180, 2023.
[26] D. Jakoveti ´c. A unification and generalization of exact distributed first-order methods. IEEE Transactions
on Signal and Information Processing over Networks , 5(1):31–46, 2018.
[27] K. Ji, J. Yang, and Y . Liang. Bilevel optimization: Convergence analysis and enhanced design. In
International Conference on Machine Learning , pages 4882–4892. PMLR, 2021.
[28] A. Koloskova, T. Lin, and S. U. Stich. An improved analysis of gradient tracking for decentralized machine
learning. Advances in Neural Information Processing Systems , 34:11422–11435, 2021.
[29] B. Kong, S. Zhu, S. Lu, X. Huang, and K. Yuan. Decentralized bilevel optimization over graphs: Loopless
algorithmic update and transient iteration complexity. arXiv preprint arXiv:2402.03167 , 2024.
[30] Z. Li, W. Shi, and M. Yan. A decentralized proximal-gradient method with network independent step-sizes
and separated convergence rates. IEEE Transactions on Signal Processing , July 2019. early acces. Also
available on arXiv:1704.07807.
[31] X. Lian, C. Zhang, H. Zhang, C.-J. Hsieh, W. Zhang, and J. Liu. Can decentralized algorithms outperform
centralized algorithms? A case study for decentralized parallel stochastic gradient descent. In Advances in
Neural Information Processing Systems , pages 5330–5340, 2017.
[32] T. Lin, S. P. Karimireddy, S. U. Stich, and M. Jaggi. Quasi-global momentum: Accelerating decentralized
deep learning on heterogeneous data. In International Conference on Machine Learning , 2021.
[33] S. Lu, S. Zeng, X. Cui, M. Squillante, L. Horesh, B. Kingsbury, J. Liu, and M. Hong. A stochastic linearized
augmented lagrangian method for decentralized bilevel optimization. Advances in Neural Information
Processing Systems , 35:30638–30650, 2022.
[34] Y . Lu and C. De Sa. Optimal complexity in decentralized training. In International Conference on Machine
Learning , pages 7111–7123. PMLR, 2021.
[35] D. Maclaurin, D. Duvenaud, and R. Adams. Gradient-based hyperparameter optimization through reversible
learning. In International Conference on Machine Learning , pages 2113–2122. PMLR, 2015.
[36] A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to
adversarial attacks. In International Conference on Learning Representations , 2018.
[37] A. Nedi ´c, A. Olshevsky, and M. G. Rabbat. Network topology and communication-computation tradeoffs
in decentralized optimization. Proceedings of the IEEE , 106(5):953–976, 2018.
[38] A. Nedic, A. Olshevsky, and W. Shi. Achieving geometric convergence for distributed optimization over
time-varying graphs. SIAM Journal on Optimization , 27(4):2597–2633, 2017.
[39] A. Nedic and A. Ozdaglar. Distributed subgradient methods for multi-agent optimization. IEEE Transac-
tions on Automatic Control , 54(1):48–61, 2009.
12[40] Y . Niu, J. Xu, Y . Sun, Y . Huang, and L. Chai. Distributed stochastic bilevel optimization: Improved
complexity and heterogeneity analysis. arXiv preprint arXiv:2312.14690 , 2023.
[41] G. Qu and N. Li. Harnessing smoothness to accelerate distributed optimization. IEEE Transactions on
Control of Network Systems , 5(3):1245–1260, 2018.
[42] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla,
M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer
Vision , 115:211–252, 2015.
[43] A. H. Sayed. Adaptive networks. Proceedings of the IEEE , 102(4):460–497, 2014.
[44] A. Shaban, C.-A. Cheng, N. Hatch, and B. Boots. Truncated back-propagation for bilevel optimization.
InThe 22nd International Conference on Artificial Intelligence and Statistics , pages 1723–1732. PMLR,
2019.
[45] W. Shi, Q. Ling, G. Wu, and W. Yin. EXTRA: An exact first-order algorithm for decentralized consensus
optimization. SIAM Journal on Optimization , 25(2):944–966, 2015.
[46] H. Tang, X. Lian, M. Yan, C. Zhang, and J. Liu. D2: Decentralized training over decentralized data. In
International Conference on Machine Learning , pages 4848–4856, 2018.
[47] O. Vinyals, C. Blundell, T. Lillicrap, D. Wierstra, et al. Matching networks for one shot learning. Advances
in Neural Information Processing Systems , 29, 2016.
[48] H. Xiao, K. Rasul, and R. V ollgraf. Fashion-mnist: a novel image dataset for benchmarking machine
learning algorithms. arXiv preprint arXiv:1708.07747 , 2017.
[49] J. Xu, Y . Tian, Y . Sun, and G. Scutari. Distributed algorithms for composite optimization: Unified
framework and convergence analysis. IEEE Transactions on Signal Processing , 69:3555–3570, 2021.
[50] J. Xu, S. Zhu, Y . C. Soh, and L. Xie. Augmented distributed gradient methods for multi-agent optimization
under uncoordinated constant stepsizes. In IEEE Conference on Decision and Control (CDC) , pages
2055–2060, Osaka, Japan, 2015.
[51] J. Yang, K. Ji, and Y . Liang. Provably faster algorithms for bilevel optimization. Advances in Neural
Information Processing Systems , 34:13670–13682, 2021.
[52] S. Yang, X. Zhang, and M. Wang. Decentralized gossip-based stochastic bilevel optimization over
communication networks. Advances in Neural Information Processing Systems , 35:238–252, 2022.
[53] K. Yuan, S. A. Alghunaim, and X. Huang. Removing data heterogeneity influence enhances network
topology dependence of decentralized SGD. Journal of Machine Learning Research , 24(280):1–53, 2023.
[54] K. Yuan, S. A. Alghunaim, B. Ying, and A. H. Sayed. On the influence of bias-correction on distributed
stochastic optimization. IEEE Transactions on Signal Processing , 2020.
[55] K. Yuan, Q. Ling, and W. Yin. On the convergence of decentralized gradient descent. SIAM Journal on
Optimization , 26(3):1835–1854, 2016.
[56] K. Yuan, B. Ying, X. Zhao, and A. H. Sayed. Exact dffusion for distributed optimization and learning –
Part I: Algorithm development. IEEE Transactions on Signal Processing , 67(3):708 – 723, 2018.
[57] Y . Zhang, M. T. Thai, J. Wu, and H. Gao. On the communication complexity of decentralized bilevel
optimization. arXiv preprint arXiv:2311.11342 , 2023.
13Appendix for “SPARKLE: A Unified Single-Loop
Primal-Dual Framework for Decentralized Bilevel
Optimization”
Contents
A More related works 15
B More details of SPARKLE 15
B.1 Primal-dual deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
B.2 Specific instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
B.3 Implementation details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
C Convergence analysis 18
C.1 Proof of Theorem 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
C.1.1 Notations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18
C.1.2 Basic transformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
C.1.3 Proof sketch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
C.1.4 Technical lemmas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
C.1.5 Descent lemmas for the upper-level . . . . . . . . . . . . . . . . . . . . . 23
C.1.6 Descent lemmas for the lower- and auxiliary-level . . . . . . . . . . . . . 30
C.1.7 Consensus error analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
C.1.8 Proof of the main theorem . . . . . . . . . . . . . . . . . . . . . . . . . . 47
C.2 Analysis of consensus error and transient iteration complexity . . . . . . . . . . . 54
C.2.1 Consensus Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
C.2.2 Essential matrix norms for analysis . . . . . . . . . . . . . . . . . . . . . 59
C.2.3 Theoretical gap between upper-level and lower-level . . . . . . . . . . . . 59
C.2.4 The transient iteration complexities of some specific examples in SPARKLE. 60
C.3 Convergence analysis in deterministic scenarios . . . . . . . . . . . . . . . . . . . 61
C.4 Degenerating to single-level algorithms . . . . . . . . . . . . . . . . . . . . . . . 62
D Experimental details 64
D.1 Synthetic bilevel optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
D.2 Hyper-cleaning on FashionMNIST dataset . . . . . . . . . . . . . . . . . . . . . . 65
D.3 Distributed policy evaluation in reinforcement learning . . . . . . . . . . . . . . . 68
D.4 Decentralized meta-learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
14A More related works
Bilevel optimization. Bilevel optimization presents substantial difficulties compared to single-level
optimization due to its nested structure. Estimating hyper-gradient ∇Φ(x)of the upper level involves
solving lower-level problems and estimating the Hessian inverse, which requires additional calcu-
lations. Many algorithms and techniques have been proposed to solve the challenge. Approximate
Implicit Differentiation (AID)-based algorithms [ 14,22,23,27] leverage the implicit gradient form of
∇Φ(x), which entails solving a linear system to obtain the Hessian-inverse-vector product. Similarly,
[8,25] utilize the Neumann series to handle the Hessian inverse. Iterative Differentiation (ITD)-based
algorithms [ 19,35,14,23,27] use iterative methods solving the lower-level problem and then es-
timate the hyper-gradient through automatic differentiation. However, these approaches introduce
inner steps, leading to extra computational overhead and memory spaces. [ 12] proposes a single-
level algorithm called SOBA, which approximating the Hessian-inverse-vector product by solving
a quadratic programming problem. A recent work [ 20] utilizes the Krylov subspace technique and
the Lanczos process to approximate it in deterministic scenarios. For stochastic bilevel optimization,
various methods have been employed to improve the convergence rate, such as momentum [ 7,11]
and variance reduction [51, 27, 24].
Decentralized optimization. Decentralized optimization is developed to deal with large-scale
optimization problems, where datasets are distributed among multiple agents. Without a central
server, each agent only gets access to its own local data and communications are limited to its
neighbors in a network. Compared with centralized algorithms, decentralized ones preserve data
privacy, and are more robust to contingencies in the communication network. However, due to the
absence of a central server, decentralized optimization requires communication among agents, posing
greater challenges for convergence, especially in the presence of severe data heterogeneity. To tackle
this issue, various algorithms have emerged, such as decentralized gradient descent [ 39,55], diffusion
strategies [ 6], dual averaging [ 17], EXTRA [ 45], Exact Diffusion (a.k.a. D2) [56,30,46], gradient
tracking [50, 13, 38], and decentralized ADMM [5]. In stochastic scenarios, a common method for
decentralized optimization is the decentralized stochastic gradient descent (DSGD), which has gained
a lot of attentions recently. It has been proved to achieve linear speedup asymptotically and shares
the same asymptotic rate with centralized stochastic gradient descent [31].
B More details of SPARKLE
B.1 Primal-dual deviation
Here we provide a detailed motivation of the update framework (6)for decentralized single-level
algorithms. First, we rewrite the single-level distributed optimization problem in the following
equivalent form:
min
xi∈Rdf(x1, ..., x n) =1
nnX
i=1fi(xi),s.t.x1=...=xn, (10)
where each fiis smooth and possibly non-convex. To simplify the notation, we assume that d= 1
without loss of generality. Now we introduce three symmetric matrices A, B, D such that Ais a
doubly stochastic communication matrix with ρ(A)<1, and B, D satisfy NullB= Null D=
Span{1n}. In general, B(D) determines the topology of a connected graph GB(GD) over agents.
The constraint Bx= 0(Dx= 0) is equivalent to:
xi=xjifxi, xjare adjacent in GB(GD).
To simplify the derivation, we additionally assume that A, B, D are pairwise commutative. Then for
x= (x1, ..., x n), we have:
x1=...=xn⇔Bx= 0⇔Dx= 0⇔Ax=x.
Therefore, (10) can be equivalently reformulated as
min
x∈Rnf(Ax),s.t.Bx= 0. (11)
15We construct the augmented Lagrangian function of the problem (11) as follows:
Lρ(x, d) =f(Ax) +⟨d, Bx⟩+ρ
2∥Dx∥2,
where xdenotes the primal variable, ddenotes the dual variable or Lagrangian multiplier associated
with the consensus constraint, ∥Dx∥2serves as the penalty term measuring the deviation from
Dx= 0, or equivalently Bx= 0;ρ >0is the penalty coefficient. Though the introduction of
matrices A, D is essentially a matter of equivalent substitution, it enhances the universality of the
algorithm framework we get.
Following classical primal-dual methods, we alternately perform gradient descent on xand gradient
ascent on din the k-th iteration:
xk+1=xk−α(A∇f(Axk) +Bdk+ρD2xk), dk+1=dk+βBxk+1,
where α, β denote the step-sizes. By making the change of variables
ˆxk=Axk,ˆdk=rα
βAdk,bB=p
αβB,bC=I−αρD2,bA=A2,
we obtain
ˆxk+1=bCˆxk−αbA∇f(ˆxk)−bBˆdk,ˆdk+1=ˆdk+bBˆxk+1. (12)
One should note that the definition implies that bA,bCare doubly stochastic communication matrices
under appropriate selections of α, ρ. Finally, thanks to the introduction of moving-average iteration
of(12), we can obtain the framework (6)which serves as the foundation for our algorithm design.
See more details in Section 2.3.
B.2 Specific instances
Relation to some existing single-level algorithm frameworks According to (12), our framework
at single-level is
xk+1=Cxk−αAgk−Bdk,dk+1=dk+Bxk+1, k= 0,1, ... (13)
where αis the step-size, gkdenotes the estimated gradient at the k-th iteration, dserves as the dual
variable.
Replacing CwithCA, we get UDA[1] , and equivalently, SUDA [2]:
xk+1=CAxk−αAgk−Bdk,dk+1=dk+Bxk+1, k= 0,1, ...
Therefore, following SUDA, we can also recover some common state-of-the-art heterogeneity
methods as follows by selecting specific A,B,C. First, from (13) we get
xk+2−xk+1=C(xk+1−xk)−αA 
gk+1−gk
−B 
dk+1−dk
=C 
xk+1−xk
−αA 
gk+1−gk
−B2xk+1.
Thus, for k≥0we have
xk+2= 
I−B2+C
xk+1−Cxk−αA 
gk+1−gk
,
withx1=Cx0−αAg0.
Some specific instances We next show that how to choose A,B,Cto get some common hetero-
geneity methods.
• ED: Taking A=W,B= (I−W)1/2andC=W, we get ED:
xk+2=W 
2xk+1−xk−α 
gk+1−gk
,
withx1=W 
x0−αg0
.
16• EXTRA: Taking A=I,B= (I−W)1/2withC=W, we get EXTRA:
xk+2=W 
2xk+1−xk
−α 
gk+1−gk
,
andx1=Wx0−αg0.
• Adapt-then-combine gradient tracking (ATC-GT): The iteration of ATC-GT is
xk+1=W 
xk−αhk
,hk+1=W 
hk+gk+1−gk
withh0=Wg0,x0=Wx0(x0
1=...=x0
n). It follows that for k≥0
xk+2−Wxk+1=Wxk+1−W2xk−αW 
hk+1−Whk
.
Then we obtain
xk+2= 2Wxk+1−W2xk−αW2 
gk+1−gk
,
withx1=W2x0−αW2g0. Thus, we can take A=W2,B= (I−W)2,C=W2to
implement ATC-GT.
• Semi-ATC-GT: The iteration of Semi-ATC-GT is
xk+1=W 
xk−αhk
,hk+1=Whk+gk+1−gk
withh0=Wg0,x0=Wx0(x0
1=...=x0
n). Like ATC-GT, we have
xk+2= 2Wxk+1−W2xk−αW 
gk+1−gk
,
withx1=W2x0−αWg0. Thus, we can take A=W,B= (I−W)2,C=W2to
implement semi-ATC-GT.
• Non-ATC-GT: The iteration of Non-ATC-GT is
xk+1=Wxk−αhk,hk+1=Whk+gk+1−gk
withh0=Wg0,x0=Wx0(x0
1=...=x0
n). We have
xk+2= 2Wxk+1−W2xk−α 
gk+1−gk
,
withx1=W2x0−αg0. Thus, we can take A=I,B= (I−W)2,C=W2to implement
Non-ATC-GT.
B.3 Implementation details
Given the update method L, we update the lower-level variable yat the k-th (k≥0) iteration as
follows. For brevity, we define y−1
i=y0
i, v−1
i= 0, o0
i=Pn
j=1(Wy)ijv0
j.


yk+1
i=Pn
j=1(Wy)ij 
2yk
j−yk−1
j−βk 
vk
i−vk−1
i
ifL=ED
yk+1
i=Pn
j=1(Wy)ij 
2yk
j−yk−1
j
−βk 
vk
i−vk−1
i
ifL=EXTRA
yk+1
i=Pn
j=1(Wy)ij 
yk
j−βkok
j
, ok+1
i=Pn
j=1(Wy)ij 
ok
j+vk+1
i−vk
i
ifL=GT
··· others
(14)
Similarly, we update the auxiliary variable zat the k-th (k≥0) iteration as follows. For brevity, we
define z−1
i=z0
i, p−1
i= 0, h0
i=Pn
j=1(Wz)ijp0
j. Note that we use the same method Lto update z
as we do for the lower-level variable y.


zk+1
i=Pn
j=1(Wz)ij 
2zk
j−zk−1
j−γk 
pk
i−pk−1
i
ifL=ED
zk+1
i=Pn
j=1(Wz)ij 
2zk
j−zk−1
j
−γk 
pk
i−pk−1
i
ifL=EXTRA
zk+1
i=Pn
j=1(Wz)ij 
zk
j−γkhk
j
, hk+1
i=Pn
j=1(Wz)ij 
hk
j+pk+1
i−pk
i
ifL=GT
··· others
(15)
Given the update method U, we update the upper-level variable xat the k-th (k≥0) iteration as
follows. For brevity, we define x−1
i=x0
i, t0
i=Pn
j=1(Wy)ijr1
j.
17

xk+1
i=Pn
j=1(Wx)ij 
2xk
j−xk−1
j−αk 
rk+1
i−rk
i
ifU=ED
xk+1
i=Pn
j=1(Wx)ij 
2xk
j−xk−1
j
−αk 
rk+1
i−rk
i
ifU=EXTRA
xk+1
i=Pn
j=1(Wx)ij 
xk
j−αktk
j
, tk+1
i=Pn
j=1(Wx)ij 
tk
j+rk+2
i−rk+1
i
ifU=GT
··· others
(16)
Then the practical implementation of SPARKLE with mixed strategies is
Algorithm 2 SPARKLE- L-U
Require: Initialize x0
i=y0
i=z0
i=r0
i= 0, step-sizes αk, βk, γk, θk.
fork= 0,1,···, K−1, each agent i(in parallel) do
Update yk+1
iaccording to (14);
Update zk+1
iaccording to (15);
rk+1
i= (1−θk)rk
i+θkuk
i;
Update xk+1
iaccording to (16).
end for
C Convergence analysis
C.1 Proof of Theorem 1
C.1.1 Notations
We use lowercase letters to represent vectors and uppercase letters to represent matrices. Stacked
vectors [x⊤
1, ..., x⊤
n]⊤is denoted by col{x1, ..., x n}for brevity. We denote a block diagonal matrix
with diagonal block Mi(1≤i≤l)byblkdiag {M1, ..., M l}, and a diagonal matrix with diagonal
elements di(1≤i≤k)bydiag{d1, ..., d k}. The Kronecker product operator is denoted by ⊗. For a
variable v, we use vk
ito represent its components at k-th iteration and i-th agent.
Moreover, we use an overbar above an iterator to denote the average over all agents. For example,
¯xk=Pn
i=1xk
i/n. Upright bold symbols are used to denote stacked vectors or matrices across
agents. For example, xk:=col{xk
1, ..., xk
n},¯xk:=col{¯xk, ...,¯xk}(ntimes ),Wx:=Wx⊗Idim(x).
Denote the 2-norm of a matrix by ∥ · ∥.
Next, we define following σ-fields which will be used in our convergence analysis:
Fk=σ 
y0, . . . ,yk+1,z0, . . . ,zk+1,x0, . . . ,xk,r0, . . . ,rk
,
Uk=σ 
y0, . . . ,yk+1,z0, . . . ,zk,x0, . . . ,xk,r0, . . . ,rk
,
Gk=σ 
y0, . . . ,yk,z0, . . . ,zk,x0, . . . ,xk,r0, . . . ,rk
,
and denote E[·|Fk]byEk,E[·|Uk]byeEk,E[·|Gk]bybEkfor brevity.
Define
z⋆(x) = nX
i=1∇2
22gi(x, y⋆(x))!−1 nX
i=1∇2fi(x, y⋆(x))!
,
Then, for k= 0,1,···, define:
zk+1
⋆= nX
i=1∇2
22gi 
¯xk, y⋆(¯xk)!−1 nX
i=1∇2fi 
¯xk, y⋆(¯xk)!
.
For convenience, we define x−1=x0,y−1=y0, y⋆(¯x−1) =y⋆(¯x0), z0
⋆=z1
⋆.
18C.1.2 Basic transformations
We begin with conducting SUDA-like [ 2] transformations, which is fundamental of the following
proofs.
Firstly, we define tkto track the averaged stochastic gradients among agents as follows
tk
y=By(dk
y−Byyk) +βAy∇2g(¯xk,¯yk),
tk
z=Bz(dk
z−Bzzk) +γAzpk(¯xk,¯yk+1),
tk
x=Bx(dk
x−Bxxk) +αAxe∇Φ(¯xk),(17)
where
pk(¯xk,¯yk+1) =col
∇2
22gi(¯xk,¯yk+1)zk
⋆− ∇ 2fi(¯xk,¯yk+1)	n
i=1,
e∇Φ(¯xk) =col
∇1fi(¯xk, y⋆(¯xk))− ∇ 12gi(¯xk, y⋆(¯xk))zk+1
⋆	n
i=1.
Then the iteration of y,z,xin Algorithm 1 can be written as:
iteration of y:(
yk+1= (Cy−B2
y)yk−tk
y−βAy
vk− ∇ 2g(¯xk,¯yk)
,
tk+1
y=tk
y+B2
yyk+βAy
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)
,(18)
iteration of z:(
zk+1= (Cz−B2
z)zk−tk
z−γAz
pk−pk(¯xk,¯yk+1)
,
tk+1
z=tk
z+B2
zzk+γAz
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
,(19)
iteration of x:

xk+1= (Cx−B2
x)xk−tk
x−αAxh
rk+1−e∇Φ(¯xk)i
,
tk+1
x=tk
x+B2
xxk+αAxh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
.(20)
Next, we present the transformation of the matrices A, B, C . For a communication matrix Wsfor the
variable s∈ {x, y, z}satisfying Assumption 2, there exists an orthogonal matrix Usuch that:
W=UsˆΛsU⊤
s=1√n1ˆUs
1 0
0 Λ s
1√n1⊤
ˆU⊤
s
,
where Λs=diag{λsi}n
i=2,ˆU⊤
s∈Rn×(n−1)satisfies ˆUsˆU⊤
s=In−1
n1n1⊤
nand1⊤
nˆUs= 0. Then
it follows that:
Ws=UsˆΛsU⊤
s=1√n1⊗Idim(s)ˆUs
Idim(s)0
0 Λs
1√n1⊤⊗Idim(s)
ˆU⊤
s
,
where dim(s)denotes the dimension of the corresponding variable, Λs= Λ s⊗Idim(s)∈
Rd(n−1)×[dim(s)·(n−1)],Us∈R[dim(s)·n]×[dim(s)·n]is an orthogonal matrix, and ˆUs=ˆUs⊗
Idim(s)∈R[dim(s)·n]×[dim(s)·(n−1)]satisfies:
ˆU⊤
sˆUs=Idim(s)·(n−1),ˆUsˆU⊤
s=
In−1
n11⊤
⊗Idim(s),(1⊤⊗Idim(s))ˆUs=0.
Now we add subscript sforWs. Then, as As,B2
s,Cscan be expressed as a polynomial of Wsfor
s∈ {x, y, z}according to Assumption 2, we have the orthogonal decomposition:
As=UsˆΛsaU⊤
s=1√n1⊗Idim(s)ˆUs
Idim(s) 0
0 Λsa
1√n1⊤⊗Idim(s)
ˆU⊤
s
,
B2
s=UsˆΛ2
sbU⊤
s=1√n1⊗Idim(s)ˆUs
0 0
0Λ2
sb
1√n1⊤⊗Idim(s)
ˆU⊤
s
,
Cs=UsˆΛscU⊤
s=1√n1⊗Idim(s)ˆUs
Idim(s) 0
0 Λsc
1√n1⊤⊗Idim(s)
ˆU⊤
s
,(21)
19where
Λsa=diag{λsa,i}n
i=2|{z }
Λsa⊗Idim(s),Λsb=diag{λsb,i}n
i=2|{z }
Λsb⊗Idim(s),Λsc=diag{λsc,i}n
i=2|{z }
Λsc⊗Idim(s).
Moreover, each Λsbis positive definite because of the null space condition in Assumption 2. Then,
multiplying both sides of (18), (19) and (20) by U⊤
y,U⊤
z,U⊤
xrespectively, we get:
iter. of y:(
U⊤
yyk+1= (ˆΛyc−ˆΛ2
yb)U⊤
yyk−U⊤
ytk
y−βˆΛyaU⊤
y
vk− ∇ 2g(¯xk,¯yk)
,
U⊤
ytk+1
y=U⊤
ytk
y+ˆΛ2
ybU⊤
yyk+βˆΛyaU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)
,
(22)
iter. of z:(
U⊤
zzk+1= (ˆΛzc−ˆΛ2
zb)U⊤
zzk−U⊤
ztk
z−γˆΛzaU⊤
z
pk−pk(¯xk,¯yk+1)
,
U⊤
ztk+1
z=U⊤
ztk
z+ˆΛ2
zbU⊤
zzk+γˆΛzaU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
.
(23)
iter. of x:

U⊤
xxk+1= (ˆΛxc−ˆΛ2
xb)U⊤
xxk−U⊤
xtk
x−αˆΛxaU⊤h
rk+1−e∇Φ(¯xk)i
,
U⊤
xtk+1
x=U⊤
xtk
x+ˆΛ2
xbU⊤
xxk+αˆΛxaU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
.(24)
Then, due to Eq. (17), we have:
(1⊤⊗Id)tk
y= (1⊤⊗Id) 
By(dk
y−Byyk) +βAy∇2g(¯xk,¯yk)
=nβ∇2g(¯xk,¯yk).(25)
(1⊤⊗Id)tk
z= (1⊤⊗Id) 
Bz(dk
z−Bzzk) +γAzpk(¯xk,¯yk+1)
=γnX
i=1
∇2
22gi(¯xk,¯yk+1)zk
⋆− ∇ 2fi(¯xk,¯yk+1)
.(26)
(1⊤⊗Id)tk
x= (1⊤⊗Id)
Bx(dk
x−Bxxk) +αAxe∇Φ(¯xk)
=αnX
i=1
∇1fi(¯xk, y⋆(¯xk))− ∇ 12gi(¯xk, y⋆(¯xk))zk+1
⋆
.(27)
Substituting (25),(26),(27) into (22),(23),(24), respectively. Then use (21) and the structure of
ˆUy,ˆUz,ˆUx, we have
iter. of y:

¯yk+1= ¯yk−β¯vk,
ˆU⊤
yyk+1= (Λyc−Λ2
yb)ˆU⊤
yyk−ˆU⊤
ytk
y−βΛyaˆU⊤
y
vk− ∇ 2g(¯xk,¯yk)
,
ˆU⊤
ytk+1
y=ˆU⊤
ytk
y+Λ2
ybˆU⊤
yyk+βΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)
,
iter. of z:

¯zk+1= ¯zk−γ¯pk,
ˆU⊤
zzk+1= (Λzc−Λ2
zb)ˆU⊤
zzk−ˆU⊤
ztk
z−γΛzaˆU⊤
z
pk−pk(¯xk,¯yk+1)
,
ˆU⊤
ztk+1
z=ˆU⊤
ztk
z+Λ2
zbˆU⊤
zzk+γΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
,
iter. of x:

¯xk+1= ¯xk−α¯rk+1,
ˆU⊤
xxk+1= (ˆΛxc−ˆΛ2
xb)ˆU⊤
xxk−ˆU⊤
xtk
x−αˆΛxaˆU⊤
xh
rk+1−e∇Φ(¯xk)i
,
ˆU⊤
xtk+1
x=ˆU⊤
xtk
x+ˆΛ2
xbˆU⊤
xxk+αˆΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
.
20The above three equations are equivalent to:
"ˆU⊤
yyk+1
Λ−1
ybˆU⊤
ytk+1
y#
=
Λyc−Λ2
yb−Λyb
Λyb I"ˆU⊤
yyk
Λ−1
ybˆU⊤
yty
k#
−β"
ΛyaˆU⊤
y
vk− ∇ 2g(¯xk,¯yk)
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#
,(28)
ˆU⊤
zzk+1
Λ−1
zbˆU⊤
ztk+1
z
=
Λzc−Λ2
zb−Λzb
Λzb IˆU⊤
zzk
Λ−1
zbˆU⊤
ztz
k
−γ
ΛzaˆU⊤
z
pk−pk(¯xk,¯yk+1)
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
,(29)
ˆU⊤
xxk+1
Λ−1
xbˆU⊤
xtk+1
x
=
Λxc−Λ2
xb−Λxb
Λxb IˆU⊤
xxk
Λ−1
xbˆU⊤
xtx
k
−α
ΛxaˆU⊤
xh
rk+1−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
.(30)
Fors∈ {x,y,z}, define:
ek
s=ˆU⊤
ssk
Λ−1
sbˆU⊤
stk
s
,Ms=
Λsc−Λ2
sb−Λsb
Λsb I
.
Then (28), (29), (30) are respectively equivalent to:
ek+1
y=Myek
y−β"
ΛyaˆU⊤
y
vk− ∇ 2g(¯xk,¯yk)
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#
,
ek+1
z=Mzek
z−γ
ΛzaˆU⊤
z
pk−pk(¯xk,¯yk+1)
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
,
ek+1
x=Mxex
k−α
ΛxaˆU⊤
xh
rk+1−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
.
Assumption 2, 3 imply that all eigenvalues of

diag{0,Λsc−Λ2
sb} − diag{0,Λsb}
diag{0,Λsb} diag{0,1, ...,1}
=
U⊤
s
U⊤
s
Cs−1
n1n1⊤
n−B2
s −Bs
Bs In−1
n1n1⊤
n
Us
Us (31)
are strictly less than one in magnitude. Thus by symmetrically exchanging columns and rows of the
matrix, we know that equivalently, all eigenvalues of

Λsc−Λ2
sb−Λsb
Λsb In−1
andMs=
Λsc−Λ2
sb −Λsb
Λsb In−1⊗Idim(s)
(32)
are strictly less than one in magnitude,.
Then according to Lemma 3, for s∈ {x, y, z},Mshas the similarity transformation:
Ms=OsΓsO−1
s,
where Osis invertible and ∥Γs∥<1. Moreover, we define ˆek
s=O−1
sek
s. It yields
ˆek+1
y=Γyˆek
y−βO−1
y"
ΛyaˆU⊤
y
vk− ∇ 2g(¯xk,¯yk)
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#
, (33)
21ˆek+1
z=Γyˆek
z−γO−1
z
ΛzaˆU⊤
z
pk−pk(¯xk,¯yk+1)
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)
, (34)
ˆek+1
x=Γxˆek
x−αO−1
x
ΛxaˆU⊤
xh
rk+1−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
. (35)
Then, for s∈ {x,y,z}, the consensus errors between different agents have the upper bound of:
sk−¯sk2=∥ˆU⊤
ssk∥2≤ ∥ek
s∥2≤ ∥Os∥2∥ˆek
s∥2. (36)
Thus, we can define:
∆k=κ2∥Ox∥2∥ˆek
x∥2+κ2∥Oy∥2∥ˆek+1
y∥2+∥Oz∥2∥ˆek+1
z∥2
to measure the consensus error during the iteration.
We also define
Ik=∥¯zk+1−zk+1
⋆∥2+κ2∥¯yk+1−y⋆(¯xk)∥2,
to measure the estimation accuracy of the lower- and auxiliary-level problems.
C.1.3 Proof sketch
Before proceeding with the formal proof, we first present the structure of the proof in Appendix C.
Bounded by each other
Descent of xPE∥¯rk∥2
Descent of yPE∥¯yk+1−y⋆(¯xk)∥2PE[∆k]PE[Ik]
Descent of zPE∥¯zk+1−zk+1
⋆∥2
Consensus of yPE∥ˆek
y∥2PE∆k
n+Ik
Consensus of zPE∥ˆek
z∥2
Consensus of xPE∥ˆek
x∥2PE∥Φ(¯xk)∥2
Hyper-gradient estimationPE∥Ekuk−e∇Φ(¯xk)∥2
Hyper-gradient estimationPE∥Ekrk+1−e∇Φ(¯xk)∥2Lemma 17
VariancePE∥Ekuk−uk∥2


22C.1.4 Technical lemmas
Lemma 1. Suppose Assumptions 1 hold, we know ∇Φ(x),e∇Φ(x),z⋆(x)andy⋆(x)defined above
areL∇Φ,eL,Lz⋆,Ly⋆- Lipschitz continuous respectively with the constants satisfying:
L∇Φ≤Lf,1+2Lf,1Lg,1+Lg,2Lf,0
µg+2Lg,1Lf,0Lg,2+L2
g,1Lf,1
µ2g+Lg,2L2
g,1Lf,0
µ3g,
eL≤Lf,1+2Lf,1Lg,1+Lg,2Lf,0
µg+2Lg,1Lf,0Lg,2+L2
g,1Lf,1
µ2g+Lg,2L2
g,1Lf,0
µ3g,
Ly⋆≤Lg,1
µg,
Lz⋆≤q
1 +L2
y⋆Lf,1
µg+Lf,0Lg,2
µ2g
.
And we also have:
∥z⋆(x)∥ ≤Lf,0
µg,∀x∈Rp.
Proof. See Lemma 2.2 in [22] and Lemma B.2 in [11].
Lemma 2. Suppose that g(x)isµ-strongly convex and L-smooth. Then for any xand0< α <2
µ+L,
we have
∥x−α∇g(x)−x⋆∥ ≤(1−αµ)∥x−x⋆∥,
where x⋆= argmin g(x).
Proof. See Lemma 10 in [41].
Lemma 3. Given diagonal matrices A, B, C, D ∈R(n−1)×(n−1), and
M=
A⊗IdB⊗Id
C⊗IdD⊗Id
.
Suppose that the eigenvalues of Mare strictly less than one in magnitude. Then there exist an
invertible matrix Oand a matrix Γwith∥Γ∥<1, such that Mhas the similarity transformation:
M=OΓO−1.
Proof. See Lemma 1 in [2].
Remark 5. Asserting the existence of Γwith∥Γ∥<1, Lemma 3 only guarantees the convergence
ofSPARKLE . However, to obtain a precise non-asymptotic convergence rate, one must construct
appropriate OandΓ. See more details in Appendix C.2.2.
C.1.5 Descent lemmas for the upper-level
In this subsection, we estimate the upper bound of the errors induced by the moving average in
hyper-gradient estimation, as well as the upper bound of ∥∇Φ(x)∥2based on Ik,∆k.
Lemma 4. Suppose Assumptions 1- 4 hold. We have:
Ek¯uk− ∇Φ(¯xk)2≤20
nL2(∆k+nIk),
Ekuk−e∇Φ(¯xk)2
≤20L2(∆k+nIk).(38)
23Proof. Cauchy Schwartz inequality implies that:
Ekuk−e∇Φ ¯xk2
≤5nX
i=1∇1fi 
xk
i, yk+1
i
− ∇ 1fi 
¯xk,¯yk+12+ 5nX
i=1∇1fi 
¯xk,¯yk+1
− ∇ 1fi 
¯xk, y⋆(¯xk)2
+ 5nX
i=1∇2
12gi 
xk
i, yk+1
i 
zk+1
i−zk+1
⋆2
+ 5nX
i=1 
∇2
12gi 
xk
i, yk+1
i
− ∇2
12gi 
¯xk,¯yk+1
zk+1
⋆2
+ 5nX
i=1 
∇2
12gi 
¯xk,¯yk+1
− ∇2
12gi 
¯xk, y⋆(¯xk)
zk+1
⋆2
≤10 
L2
f,1+κ2L2
f,0xk−¯xk2+yk+1−¯yk+12+¯yk+1−y⋆(¯xk)2
+ 10L2
g,1zk+1−¯zk+12+¯zk+1−zk+1
⋆2
≤20L2(∆k+nIk).
For the termEk¯uk− ∇Φ 
¯xk2, we have:
Ek¯uk− ∇Φ(¯xk)2≤1
nEkuk−e∇Φ ¯xk2
≤20L2∆k
n+Ik
.
Lemma 5. Suppose that Assumptions 1- 4 hold. We have
n2KX
k=0E
∥¯uk−Ek[¯uk]∥2
=KX
k=0E
∥uk−Ek[uk]∥2
≤9σ2
g,2KX
k=0 
E∥zk+1−¯zk+1∥2+E∥¯zk+1−zk+1
⋆∥2
+ 3(K+ 1)n 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
.(39)
Proof. Fork≥0, Cauchy Schwartz inequality implies that
1
3Ek
∥uk−Ek[uk]∥2
≤Ek"nX
i=1∥∇1fi(xk
i, yk+1
i, ξk
i)− ∇ 1fi(xk
i, yk+1
i)∥2#
+Ek"nX
i=1 
∇12gi(xk
i, yk+1
i, ζk
i)− ∇ 12gi(xk
i, yk+1
i)
zk+1
i2#
≤nσ2
f,1+σ2
g,2∥zk+1∥2
≤nσ2
f,1+ 3σ2
g,2 
∥zk+1−¯zk+1∥2+∥¯zk+1−zk+1
⋆∥2+∥zk+1
⋆∥2
≤nσ2
f,1+ 3σ2
g,2 
∥zk+1−¯zk+1∥2+∥¯zk+1−zk+1
⋆∥2+nL2
f,0
µ2g!
.
Then taking expectation and summation on both sides, we get
KX
k=0E
∥uk−Ek[uk]∥2
≤9σ2
g,2KX
k=0 
E∥zk+1−¯zk+1∥2+E∥¯zk+1−zk+1
⋆∥2
+ 3(K+ 1)n 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
.
24Since samples among agents are independent, it follows that
KX
k=0Ek
∥¯uk−Ek[¯uk]∥2
=1
n2KX
k=0Ek
∥uk−Ek[uk]∥2
.
Taking expectations, we get the conclusion.
Lemma 6. Suppose that Assumptions 1- 4, and Lemmas 4, 5 hold. If
α≤1
2L∇Φ, (40)
we have
1
4KX
k=0E¯rk+12
≤Φ(¯x0)−inf Φ
α+ 10 
L2+θσ2
g,2
n!KX
k=0E∆k
n+Ik
+3θ
n(K+ 1) 
σ2
f,1+ 2σ2
g,2L2
f,0
µ2g!
.
(41)
Proof. TheL∇Φ-smoothness of Φindicates that
Ek[Φ 
¯xk+1
]−Φ(¯xk)
≤
∇Φ(¯xk), 
−αEk[¯rk+1]
+L∇Φα2
2Ek∥¯rk+1∥2
=
∇Φ(¯xk)−Ek[¯uk],−αEk[¯rk+1]
+L∇Φ
2α2Ek∥¯rk+1∥2−α
Ek[¯uk],Ek[¯rk+1]
.
Then, due to Ek[¯uk] =θ−1(Ek[¯rk+1]−(1−θ)¯rk), we have:
Ek[Φ 
¯xk+1
]−Φ(¯xk)
≤α
2∥∇Φ(¯xk)−Ek[¯uk]∥2+α
2∥Ek[¯rk+1]∥2
+L∇Φ
2α2Ek∥¯rk+1∥2−α
Ek[¯uk],Ek[¯rk+1]
=α
2∥∇Φ(¯xk)−Ek[¯uk]∥2+ (−α
2+L∇Φ
2α2)Ek∥¯rk+1∥2−α(1−θ)
2θ∥Ek[¯rk+1]−¯rk∥2
+α(1−θ)
2θ 
∥¯rk∥2−Ek∥¯rk+1∥2
+α
2θEk∥¯rk+1−Ek[¯rk+1]∥2
≤α
2∥∇Φ(¯xk)−Ek[¯uk]∥2+ (−α
2+L∇Φ
2α2)Ek∥¯rk+1∥2+αθ
2Ek∥¯uk−Ek[¯uk]∥2
+α(1−θ)
2θ 
∥¯rk∥2−Ek∥¯rk+1∥2
,
where the first equality uses 2
¯rk,Ek[¯rk+1]
=∥¯rk∥2+∥Ek[¯rk+1]∥2− ∥¯rk−Ek[¯rk+1]∥2and
Ek∥¯rk+1∥2=∥Ek[¯rk+1]∥2+Ek∥¯rk+1−Ek[¯rk+1]∥2.
Taking expectation and summation, and using α≤1
2L∇Ψ, we get
inf Φ−Φ(¯x0)
≤α
2KX
k=0E∥∇Φ(¯xk)−Ek[¯uk]∥2−α
4KX
k=0E∥¯rk+1∥2+αθ
2KX
k=0E
Ek∥¯uk−Ek[¯uk]∥2
.(42)
Since samples of different agents are independent, we have
Ek∥¯uk−Ek[¯uk]∥2=1
n2Ek∥uk−Ek[uk]∥2.
25Combining it with the conclusion of Lemma 4 and 5, we get from (42) that
α
4KX
k=0E¯rk+12
≤Φ(¯x0)−inf Φ +α
2KX
k=0E∥∇Φ(¯xk)−Ek[¯uk]∥2+αθ
2KX
k=0E
Ek∥¯uk−Ek[¯uk]∥2
≤Φ(¯x0)−inf Φ + 10 α 
L2+θσ2
g,2
n!KX
k=0E∆k
n+Ik
+3αθ
n(K+ 1) 
σ2
f,1+ 2σ2
g,2L2
f,0
µ2g!
.
Lemma 7. Suppose that Assumptions 1- 4 hold, then we have
KX
k=0EEk[rk+1]−e∇Φ(¯xk)2
≤1−θ
θe∇Φ(¯x0)2
+ 2KX
k=0EEk[uk]−e∇Φ(¯xk)2
+2eL2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
+ (1−θ)θKX
k=0Ehuk−Ek[uk]2i
.
Proof. We define u−1=0for brevity. From the definition of Ek, we have :
Ek−1rk−e∇Φ(¯xk−1)2
=Ek−1Ek−1[rk]−e∇Φ(¯xk−1)2
+Ek−1hrk−Ek−1[rk]2i
=Ek−1Ek−1[rk]−e∇Φ(¯xk−1)2
+θ2Ek−1huk−1−Ek−1[uk−1]2i
.(43)
Jensen’s inequality implies that
Ekh
∥Ek[rk+1]−e∇Φ(¯xk)∥2i
≤(1−θ)Ekrk−e∇Φ(¯xk−1)2
+θEk
Ek[uk]−e∇Φ(¯xk)
+θ−1(1−θ)
e∇Φ(¯xk−1)−e∇Φ(¯xk)2
≤(1−θ)Ekrk−e∇Φ(¯xk−1)2
+ 2θEkEk[uk]−e∇Φ(¯xk)2
+2(1−θ)2
θEke∇Φ(¯xk−1)−e∇Φ(¯xk)2
.(44)
Substituting (43) into (44) , and taking expectation and summation on both sides, we get:
θKX
k=0EEk−1[rk]−e∇Φ(¯xk−1)2
≤Er0−e∇Φ(¯x−1)2
−EEK[rK+1]−e∇Φ(¯xk)2
+ 2θKX
k=0EEk[uk]−e∇Φ(¯xk)2
+2(1−θ)2
θKX
k=0Ee∇Φ(¯xk−1)−e∇Φ(¯xk)2
+ (1−θ)θ2KX
k=0Ehuk−Ek[uk]2i
.
26Finally, note that x−1=x0,r0=0, andE−1=E0. Subtracting θEE−1[r0]−e∇Φ(¯x−1)2
=
θe∇Φ(¯x0)2
from both sides of this equation, we get:
KX
k=0EEk[rk+1]−e∇Φ(¯xk)2
≤1−θ
θe∇Φ(¯x0)2
+ 2KX
k=0EEk[uk]−e∇Φ(¯xk)2
+2eL2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
+ (1−θ)θKX
k=0Ehuk−Ek[uk]2i
.
Lemma 8 (Descent lemma) .Suppose that Assumptions 1- 4 and Lemmas 4, 5 hold. If
α2
θ2(1−θ)≤1
32L2
∇Φ, α≤1
10L∇Φ, (45)
then we have
KX
k=0E∥∇Φ(¯xk)∥2≲Φ(¯x0)−inf Φ
α+ 
L2+ 
θ(1−θ) +L∇Φαθ2
σ2
g,2KX
k=0E∆k
n+Ik
+ (K+ 1) 
θ(1−θ) +L∇Φαθ2
(σ2
f,1+κ2σ2
g,2) +(1−θ)2
θ∥∇Φ(¯x0)∥2.
Proof. TheL∇Φ-smoothness of Φindicates that
Ek[Φ(¯xk+1)]−Φ(¯xk)
≤
∇Φ(¯xk),−αEk[¯rk+1]
+L∇Φα2
2Ek¯rk+12
=−α
∇Φ(¯xk),Ek[¯rk+1]− ∇Φ(¯xk)
−α∥∇Φ(¯xk)∥2+L∇Φ
2α2Ek¯rk+12
≤ −α
2∥∇Φ(¯xk)∥2+α
2∥Ek[¯rk+1]− ∇Φ(¯xk)∥2+L∇Φ
2α2Ek¯rk+12.
Taking expectation and summation on both sides, we get:
KX
k=0αE∥∇Φ(¯xk)∥2
≤2(Φ(¯x0)−inf Φ) +KX
k=0αE∥Ek[¯rk+1]− ∇Φ(¯xk)∥2+KX
k=0L∇Φα2E¯rk+12.(46)
Define auxiliary series mkas:
m0= ¯r0= 0, mk+1= (1−θ)mk+θ∇Φ(¯xk).
Note that
Ek¯rk+12=Ek¯rk+12+Ek¯rk+1−Ek¯rk+12
≤2∥Ek[¯rk+1]− ∇Φ(¯xk)∥2+ 2∥∇Φ(¯xk)∥2+θ2Ek∥¯uk−Ek¯uk∥2.(47)
Then using the Jenson’s Inequality, we get:
∥Ek¯rk+1−mk+1∥2=∥(1−θ)(¯rk−mk) +θ(Ek¯uk− ∇Φ(¯xk))∥2
≤(1−θ)∥¯rk−mk∥2+θ∥Ek¯uk− ∇Φ(¯xk)∥2.
27It follows that for k≥0
E∥Ek¯rk+1−mk+1∥2
≤(1−θ)E∥Ek−1[¯rk]−mk∥2+ (1−θ)θ2E∥¯uk−1−Ek−1¯uk−1∥2+θE∥Ek¯uk− ∇Φ(¯xk)∥2,
where for brevity we define ¯u−1= 0.
Taking the summation on both sides from k= 0toK, we get
KX
k=0θE∥Ek¯rk+1−mk+1∥2≤K−1X
k=0θE∥Ek¯rk+1−mk+1∥2+E∥EK¯rK+1−mK+1∥2
≤KX
k=0θE∥Ek¯uk− ∇Φ(¯xk)∥2+K−1X
k=0(1−θ)θ2E∥¯uk−Ek¯uk∥2.
(48)
On the other hand, due to the definition of mkand Jenson’s Inequality, we have:
∥mk+1− ∇Φ(¯xk)∥2=∥(1−θ)(mk− ∇Φ(¯xk))∥2
= (1−θ)2∥mk− ∇Φ(¯xk−1) +∇Φ(¯xk−1)− ∇Φ(¯xk)∥2
≤(1−θ)∥mk− ∇Φ(¯xk−1)∥2+(1−θ)2
θL2
∇Φα2∥¯rk∥2.
Taking the summation, we get
KX
k=0θ∥mk+1− ∇Φ(¯xk)∥2≤ ∥m0− ∇Φ(¯x−1)∥2+KX
k=0(1−θ)2
θL2
∇Φα2∥¯rk∥2
= (1−θ)2∥∇Φ(¯x0)∥2+KX
k=0(1−θ)2
θL2
∇Φα2∥¯rk∥2.(49)
Combining (48) and (49), we obtain:
KX
k=0θE∥Ek¯rk+1− ∇Φ(¯xk)∥2
≤2KX
k=0θE∥Ek¯rk+1−mk+1∥2+ 2KX
k=0θ∥mk+1− ∇Φ(¯xk)∥2
≤2KX
k=0θE∥Ek¯uk− ∇Φ(¯xk)∥2+ 2K−1X
k=0(1−θ)θ2E∥¯uk−Ek¯uk∥2
+ 2KX
k=0(1−θ)2
θL2
∇Φα2E∥¯rk∥2+ 2(1−θ)2∥∇Φ 
¯x0
∥2
≤2KX
k=0θE∥Ek¯uk− ∇Φ(¯xk)∥2+ 2K−1X
k=0
1 + 21−θ
θL2
∇Φα2
(1−θ)θ2E∥¯uk−Ek¯uk∥2
+ 2(1−θ)2∥∇Φ 
¯x0
∥2+ 2K−1X
k=0(1−θ)2
θL2
∇Φα2
2E∥Ek[¯rk+1]− ∇Φ(¯xk)∥2+ 2E∥∇Φ(¯xk)∥2
,
(50)
where the last inequality uses (47).
(45) indicates that 41−θ
θL2
∇Φα2≤θ
8. Subtracting
2K−1X
k=0(1−θ)2
θL2
∇Φα2·2E∥Ek[¯rk+1]− ∇Φ(¯xk)∥2
28from both sides of (50), we have:
KX
k=0θE∥Ek¯rk+1− ∇Φ(¯xk)∥2
≤4KX
k=0θE∥Ek¯uk− ∇Φ(¯xk)∥2+ 8K−1X
k=0(1−θ)θ2E∥¯uk−Ek¯uk∥2+ 4(1−θ)2∥∇Φ(¯x0)∥2
+θ
4K−1X
k=0E∥∇Φ(¯xk)∥2.(51)
Substituting (47), (51) into (46), we get:
KX
k=0αE∥∇Φ(¯xk)∥2
≤2(Φ(¯x0)−inf Φ) +KX
k=0(α+ 2L∇Φα2)E∥Ek[¯rk+1]− ∇Φ(¯xk)∥2+KX
k=02L∇Φα2E∥∇Φ(¯xk)∥2
+KX
k=02L∇Φα2θ2Ek∥¯uk−Ek¯uk∥2
≤2(Φ(¯x0)−inf Φ) + 5 αKX
k=0E∥Ek¯uk− ∇Φ(¯xk)∥2+ 5α
θ(1−θ)2∥∇Φ 
¯x0
∥2
+KX
k=0
10α
θ(1−θ) + 2L∇Φα2
θ2E∥¯uk−Ek¯uk∥2+α
2K−1X
k=0E∥∇Φ(¯xk)∥2,
(52)
where the last inequality uses α≤1
10L∇Φ.
Subtractingα
2PK−1
k=0E∥∇Φ(¯xk)∥2from both sides of (52), and substituting (38),(39) into it, we
get:
1
2KX
k=0αE∥∇Φ(¯xk)∥2
≤2(Φ(¯x0)−inf Φ) + 100 αL2KX
k=0E∆k
n+Ik
+ 5α
θ(1−θ)2∥∇Φ 
¯x0
∥2
+ 
10α
θ(1−θ) + 2L∇Φα2
n2θ2·9σ2
g,2KX
k=0 
E∥zk+1−¯zk+1∥2+E∥¯zk+1−zk+1
⋆∥2
+ 
10α
θ(1−θ) + 2L∇Φα2
n2θ2·3(K+ 1)n 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
≤2(Φ(¯x0)−inf Φ) + 
100αL2+ 9 
10αθ(1−θ) + 2L∇Φα2θ2σ2
g,2
n!KX
k=0E∆k
n+Ik
+ 3(K+ 1) 
10α(1−θ) + 2L∇Φα2θθ
n 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
+ 5α
θ(1−θ)2∥∇Φ 
¯x0
∥2.
29Finally, multiplying2
αon both sides, we get:
KX
k=0E∥∇Φ(¯xk)∥2≲Φ(¯x0)−inf Φ
α+ 
L2+ 
θ(1−θ) +L∇Φαθ2σ2
g,2
n!KX
k=0E∆k
n+Ik
+K+ 1
n 
θ(1−θ) +L∇Φαθ2
(σ2
f,1+κ2σ2
g,2) +(1−θ)2
θ∥∇Φ(¯x0)∥2.
C.1.6 Descent lemmas for the lower- and auxiliary-level
The following lemmas present the error analysis of the estimation of y⋆(¯xk)andzk
⋆, i.e., the term Ik:
Lemma 9 (Estimation error of y⋆(x)).Suppose Assumptions 1- 4hold, and:
β≤µg
32L2
g,1. (53)
Then we have the estimation error of y⋆:
∥¯y0−y⋆(¯x0)∥2+KX
k=0E[∥¯yk+1−y⋆(¯xk)∥2]
≤4
βµg∥¯y0−y⋆(¯x0)∥2+KX
k=16α2L2
y⋆
β2µ2gE∥¯rk∥2+KX
k=16
µ2gL2
g,1E"
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
n#
+4Kβσ2
g,1
nµg,
and
KX
k=0E
∥¯yk+1−¯yk∥2
≤β2L2
g,1
n 
4 +48L2
g,1
µ2g!KX
k=1E 
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
+48α2L2
g,1
µ2gL2
y⋆KX
k=1E∥¯rk∥2
+3(K+ 1)β2
nσ2
g,1+32βL2
g,1
µg∥¯y0−y⋆(¯x0)∥2.
(54)
Proof. For each k≥0, due to the independence of samples, we have:
bEk[∥¯yk+1−y⋆(¯xk)∥2] =bEk[∥¯yk−β¯vk−y⋆(¯xk)∥2]
=bEk
¯yk−β1
nnX
i=1∇2gi(xk
i, yk
i)−y⋆(¯xk) +β1
nnX
i=1 
∇2gi(xk
i, yk
i)−vk
i2

≤¯yk−β1
nnX
i=1∇2gi(¯xk,¯yk)−y⋆(¯xk) +β1
nnX
i=1(∇2gi(¯xk,¯yk)− ∇ 2gi(xk
i, yk
i))2
+β2σ2
g,1
n.
30Then,
bEk[∥¯yk+1−y⋆(¯xk)∥2]
≤
1 +βµg
2¯yk−β1
nnX
i=1∇2gi(¯xk,¯yk)−y⋆(¯xk)2
+β2
1 +2
βµg1
nnX
i=1(∇2gi(¯xk,¯yk)− ∇ 2gi(xk
i, yk
i))2
+β2σ2
g,1
n
≤
1 +βµg
2
(1−βµg)2∥¯yk−y⋆(¯xk)∥2
+β2
1 +2
βµg
L2
g,1∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
+β2σ2
g,1
n
≤(1−βµg)
1 +βµg
2
∥¯yk−y⋆(¯xk−1)∥2+
1 +2
βµg
∥y⋆(¯xk)−y⋆(¯xk−1)∥2
+β2
1 +2
βµg
L2
g,1∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
+β2σ2
g,1
n
≤
1−βµg
2
∥¯yk−y⋆(¯xk−1)∥2+3
βµgL2
y⋆∥¯xk−¯xk−1∥2
+3β
µgL2
g,1∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
+β2σ2
g,1
n,
where the first and the third inequality is due to the Jenson’s inequality, the second inequality holds
according to Lemma 2 and the fact that β≤µg
32L2
g,1≤1
3(µg+Lg,1), and the last inequality uses
βµg≤1
3. Taking the summation and expectation on the both sides, we get:
KX
k=0βµg
2E[∥¯yk−y⋆(¯xk−1)∥2] +E[∥¯yk+1−y⋆(¯xk)∥2]
≤E∥¯y0−y⋆(¯x0)∥2+KX
k=0E"
3α2
βµgL2
y⋆∥¯rk∥2+3β
µgL2
g,1∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
+β2σ2
g,1
n#
.
Using (36) and the fact that x0,y0is consensual, it follows that:
K+1X
k=0βµg
2E[∥¯yk−y⋆(¯xk−1)∥2]≤2∥¯y0−y⋆(¯x0)∥2+KX
k=13α2
βµgL2
y⋆E∥¯rk∥2
+KX
k=13β
µgL2
g,1E"
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
n#
+2Kβ2σ2
g,1
n.
(55)
On the other hand,
bEk
∥¯yk+1−¯yk∥2
≤β21
nnX
i=1∇2gi(xk
i, yk
i)2
+β2
nσ2
g,1
≤2β2
1
nnX
i=1 
∇2gi(xk
i, yk
i)− ∇ 2gi(¯xk,¯yk)2
+∇2g(¯xk,¯yk)− ∇ 2g(¯xk, y⋆(¯xk))2

+β2
nσ2
g,1
≤2β2L2
g,1
n 
∥xk−¯xk∥2+∥yk−¯yk∥2+ 2∥¯yk+1−y⋆(¯xk)∥2+ 2∥¯yk+1−¯yk∥2
+β2
nσ2
g,1,
31where the second inequality uses ∇2g(¯xk, y⋆(¯xk)) = 0 .
Note that β2≤µ2
g
32L4
g,1≤1
8L2
g,1. Subtracting 2β2L2
g,1∥¯yk+1−¯yk∥on both sides, and taking
expectation and summation, we get:
KX
k=0E
∥¯yk+1−¯yk∥2
≤KX
k=0"
4β2L2
g,1
nE 
∥xk−¯xk∥2+∥yk−¯yk∥2
+8β2L2
g,1
nE∥¯yk+1−y⋆(¯xk)∥2+2β2
nσ2
g,1#
≤4β2L2
g,1
nKX
k=1E 
∥Ox∥2∥ˆex
k∥2+∥Oy∥2∥ˆey
k∥2
+8β2L2
g,1
nKX
k=0E∥¯yk+1−y⋆(¯xk)∥2
+2(K+ 1)β2
nσ2
g,1
≤4β2L2
g,1
nKX
k=1E 
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
+2(K+ 1)β2
nσ2
g,1
+ 8β2L2
g,1 
4
βµg∥¯y0−y⋆(¯x0)∥2+KX
k=16α2
β2µ2gL2
y⋆E∥¯rk∥2!
+ 8β2L2
g,1 KX
k=16
µ2gL2
g,1E"
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
n#
+4Kβσ2
g,1
nµg!
≤β2L2
g,1
n 
4 +48L2
g,1
µ2g!KX
k=1E 
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
+48α2L2
g,1
µ2gL2
y⋆KX
k=1E∥¯rk∥2
+3(K+ 1)β2
nσ2
g,1+32βL2
g,1
µg∥¯y0−y⋆(¯x0)∥2.
where the second inequality holds since x0,y0are consensual, the third inequality uses (55), and the
last inequality holds since β≤µg
32L2
g,1.
Lemma 10 (Estimation error of z⋆(x)).Suppose that Assumptions 1- 4hold, and
γ <min(
1
µg,nL2
g,1
µ2gσ2
g,2,nµg
36σ2
g,2)
. (56)
We have:
K+1X
k=0E∥¯zk−zk
⋆∥2
≤KX
k=09α2L2
z⋆
γ2µ2gE∥¯rk∥2
+ 72κ2KX
k=1Eκ2∥Ox∥2∥ˆek
x∥2+∥Oz∥2∥ˆek
z∥2
n
+ 72κ2KX
k=0E"
κ2∥Oy∥2∥ˆek+1
y∥2
n#
+KX
k=072κ4E
∥¯yk+1−y⋆(¯xk)∥2
+3∥z1
⋆∥2
µgγ+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
.
Proof. For each k≥0, note that zk
⋆=∇2
22g(¯xk, y⋆(¯xk))−1∇2f2(¯xk, y⋆(¯xk)), we have:
eEk[¯zk+1]−zk+1
⋆= ¯zk−γ
nnX
i=1 
∇2
22gi(xk
i, yk+1
i)zk
i− ∇ 2fi(xk
i, yk+1
i)
−zk+1
⋆
32="
I−γ
nnX
i=1∇2
22gi(xk
i, yk+1
i)#
(¯zk−zk+1
⋆) +γ
nnX
i=1
∇2fi(xk
i, yk+1
i)− ∇ 2fi(¯xk, y⋆(¯xk))
+γ
nnX
i=1∇2
22gi(xk
i, yk+1
i)(¯zk−zk
i) +γ
nnX
i=1
∇2
22gi(¯xk, y⋆(¯xk))− ∇2
22gi(xk
i, yk+1
i)
zk+1
⋆.
Then we have:
eEk[¯zk+1]−zk+1
⋆2
≤(1 +γµg)"
I−γ
nnX
i=1∇2
22gi(xk
i, yk+1
i)#
(¯zk−zk+1
⋆)2
+ 3γ2
1 +1
γµg1
nnX
i=1
∇2fi(xk
i, yk+1
i)− ∇ 2fi(¯xk, y⋆(¯xk))2
+ 3γ2
1 +1
γµg1
nnX
i=1
∇2
22gi(¯xk, y⋆(¯xk))− ∇2
22gi(xk
i, yk+1
i)
zk+1
⋆2
+ 3γ2
1 +1
γµg1
nnX
i=1∇2
22gi(xk
i, yk+1
i)(¯zk−zk
i)2
≤(1 +γµg)(1−γµg)2∥¯zk−zk+1
⋆∥2
+6γ
µg 
L2
g,1∥zk−¯zk∥
n+ 
L2
g,2L2
f,0
µ2g+L2
f,1!∥xk−¯xk∥2
n+∥yk+1−y⋆(¯xk)∥2
n!
≤(1−γµg)
1 +γµg
2
∥¯zk−zk
⋆∥2+
1 +2
γµg
∥zk
⋆−zk+1
⋆∥2+6γ
µgL2
g,1∥zk−¯zk∥
n
+12γ
µg 
L2
g,2L2
f,0
µ2g+L2
f,1!∥xk−¯xk∥2
n+∥yk+1−¯yk+1∥2
n+∥¯yk+1−y⋆(¯xk)∥2
≤(1−γµg
2)∥¯zk−zk
⋆∥2+3α2L2
z⋆
γµg∥¯rk∥2+6γ
µgL2
g,1∥zk−¯zk∥
n
+12γ
µg 
L2
g,2L2
f,0
µ2g+L2
f,1!∥xk−¯xk∥2
n+∥yk+1−¯yk+1∥2
n+∥¯yk+1−y⋆(¯xk)∥2
where the first and third inequality uses Jensen’s inequality and Cauchy Schwartz inequality, the
second inequality holds due to Assumption 1 and γµg<1, the last inequality holds since z⋆(x)is
Lz⋆Lipschitz continuous.
Moreover, the independence of samples implies that
eEk¯zk+1−eEk[¯zk+1]2
=γ2eEk1
nnX
i=1(Hk
i−eEk[Hk
i])zk
i+1
nX
i(bk
i−eEk[bk
i])2
≤2γ2
n
σ2
g,2∥zk∥2
n+σ2
f,1
≤2γ2
n 
3σ2
g,2 
∥zk−¯zk∥2
n+∥¯zk−zk
⋆∥2+L2
f,0
µ2g!
+σ2
f,1!
.
Asγsatisfies
6σ2
g,2γ2
n≤6γL2
g,1
µ2g,6σ2
g,2γ2
n≤γµg
6,
33we get:
eEk[∥¯zk+1−zk+1
⋆∥2] =eEk∥eEk[¯zk+1]−zk+1
⋆∥2+eEk∥¯zk+1−eEk[¯zk+1]∥2
≤
1−γµg
3
∥¯zk−zk
⋆∥2+3α2L2
z⋆
γµg∥¯rk∥2+12γ
µgL2
g,1∥zk−¯zk∥2
n+2γ2
n 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+12γ
µg 
L2
g,2L2
f,0
µ2g+L2
f,1!∥xk−¯xk∥2
n+∥yk+1−¯yk+1∥2
n+∥¯yk+1−y⋆(¯xk)∥2
.
Taking expectation and summation on both sides, we get
KX
k=0γµg
3E∥¯zk−zk
⋆∥2+E∥¯zK+1−zK+1
⋆∥2
≤E∥¯z0−z0
⋆∥2+KX
k=0"
3α2L2
z⋆
γµgE∥¯rk∥2+12γ
µgL2
g,1E∥zk−¯zk∥2
n+2γ2
n 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!#
+KX
k=012γ
µg 
L2
g,2L2
f,0
µ2g+L2
f,1!
E∥xk−¯xk∥2
n+∥yk+1−¯yk+1∥2
n+∥¯yk+1−y⋆(¯xk)∥2
.
It follows that
K+1X
k=0E∥¯zk−zk
⋆∥2
≤KX
k=09α2L2
z⋆
γ2µ2gE∥¯rk∥2
+ 72κ2KX
k=1Eκ2∥Ox∥2∥ˆek
x∥2+∥Oz∥2∥ˆek
z∥2
n
+ 72κ2KX
k=0E"
κ2∥Oy∥2∥ˆek+1
y∥2
n#
+KX
k=072κ4E
∥¯yk+1−y⋆(¯xk)∥2
+3∥z1
⋆∥2
µgγ+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
,
since z0
⋆=z1
⋆andz0is consensual.
Then, we combine the results in Lemmas 9, 10 and give an upper bound of E[Ik]:
Lemma 11. Suppose that Lemmas 9 and 10 hold. Then we have:
KX
k=−1E[Ik]≤9α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆KX
k=0E∥¯rk∥2+ 510 κ4KX
k=0E∆k
n
+3∥z1
⋆∥2
µgγ
+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+ 73κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
nµgβ!
.
(57)
Remark 6. Here I−1=∥¯z0−z0
⋆∥2+κ2∥¯y0−y⋆(¯x−1)∥2. The aim of introducing this term is to
simplify the subsequent proofs of other lemmas.
34Proof. Lemma 10 implies that:
K+1X
k=0E∥¯zk−zk
⋆∥2
≤KX
k=09α2L2
z⋆
γ2µ2gE∥¯rk∥2
+ 72κ2KX
k=1Eκ2∥Ox∥2∥ˆek
x∥2+∥Oz∥2∥ˆek
z∥2
n
+ 72κ2KX
k=0E"
κ2∥Oy∥2∥ˆek+1
y∥2
n#
+KX
k=072κ4E
∥¯yk+1−y⋆(¯xk)∥2
+3∥z1
⋆∥2
µgγ+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
Then, using Lemma 9, we have:
KX
k=−1E[Ik] =K+1X
k=0E∥¯zk−zk
⋆∥2+κ2K+1X
k=0E∥¯yk−y⋆(¯xk−1)∥2
≤KX
k=09α2L2
z⋆
γ2µ2gE∥¯rk∥2
+ 72κ2KX
k=1Eκ2∥Ox∥2∥ˆek
x∥2+∥Oz∥2∥ˆek
z∥2
n
+ 72κ2KX
k=0E"
κ2∥Oy∥2∥ˆek+1
y∥2
n#
+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+ 73κ4"
4
βµg∥¯y0−y⋆(¯x0)∥2+KX
k=16α2
β2µ2gL2
y⋆E∥¯rk∥2#
+3∥z1
⋆∥2
µgγ+ 73κ4"KX
k=16
µ2gL2
g,1E"
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
n#
+4Kσ2
g,1
nµgβ#
≤KX
k=09α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆
E∥¯rk∥2+KX
k=0510κ4E∆k
n
+3∥z1
⋆∥2
µgγ
+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+ 73κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
nµgβ!
.
C.1.7 Consensus error analysis
In this subsection we aim to bound the consensus errors of y, z, x (i.e. the terms ∥ˆek
y∥2,∥ˆek
z∥2, and
∥ˆek
x∥2).
Lemma 12 (Consensus error of y).Suppose that Assumptions 1- 4 hold, and
β2≤(1− ∥Γy∥)2
8L2
g,1∥O−1y∥2∥Oy∥2∥Λya∥2. (58)
We have
K+1X
k=0E∥ˆek
y∥2≤3KX
k=0β2∥O−1
y∥2
(1− ∥Γy∥)2∥Λ−1
yb∥2∥Λya∥2L2
g,1E
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
+∥Ox∥2
3∥Oy∥2KX
k=0E∥ˆek
x∥2+3(K+ 1)β2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2E∥ˆe0
y∥2
1− ∥Γy∥.(59)
35Proof. Firstly, the term ∥ˆek+1
y∥2can be deformed as
∥ˆek+1
y∥2
=Γyˆek
y−βO−1
y
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
yh
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)i
−βO−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#2
=Γyˆek
y−βO−1
y
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
yh
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)i
2
+β2O−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#2
−2*
Γyˆek
y, βO−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#+
+ 2β2*
O−1
y
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
yh
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)i
,O−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#+
(60)
due to Eq.(33). Then, for the first term in the right-hand side of (60), we have:
bEk
Γyˆek
y−βO−1
y"
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#2

≤∥Γy∥∥ˆek
y∥2+β2∥O−1
y∥2
1− ∥Γy∥bEk
"
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#2

≤∥Γy∥∥ˆek
y∥2+β2∥O−1
y∥2
1− ∥Γy∥· ∥Λya∥2∥∇2g(xk,yk)− ∇ 2g(¯xk,¯yk)∥2
+β2∥O−1
y∥2
1− ∥Γy∥∥Λ−1
yb∥2∥Λya∥2bEk
∥∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)∥2
≤∥Γy∥∥ˆek
y∥2+β2∥O−1
y∥2
1− ∥Γy∥· ∥Λya∥2L2
g,1 
∥xk−¯xk∥2+∥yk−¯yk∥2
+β2∥O−1
y∥2
1− ∥Γy∥∥Λ−1
yb∥2∥Λya∥2L2
g,1bEk
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
,
(61)
where the first inequality uses the Jenson’s inequality, the second inequality hold since ∥ˆU⊤
y∥ ≤1.
For the second term, we have:
bEk
O−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#2
≤ ∥O−1
y∥2∥Λya∥2nσ2
g,1. (62)
For the third them, we have:
bEk"*
Γyˆek
y, βO−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#+#
= 0. (63)
36Next, for the last term, we have:
bEk*
O−1
y"
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#
,O−1
y"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#+
≤1
2∥O−1
y∥2bEk"
ΛyaˆU⊤
yh
bEk[vk]− ∇ 2g(¯xk,¯yk)i
Λ−1
ybΛyaˆU⊤
y
∇2g(¯xk+1,¯yk+1)− ∇ 2g(¯xk,¯yk)#2
+1
2∥O−1
y∥2bEk"
ΛyaˆU⊤
yh
vk−bEk[vk]i
0#2
≤1
2β2∥O−1
y∥2∥Λya∥2L2
g,1bEkh
∥xk−¯xk∥2+∥yk−¯yk∥2i
+1
2β2∥O−1
y∥2∥Λ−1
yb∥2∥Λya∥2L2
g,1bEkh
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2i
+1
2β2∥O−1
y∥2∥Λya∥2nσ2
g,1.
(64)
Taking expectations on both sides of (60), and plugging (61), (62), (63), (64) into it, we obtain:
E
∥ˆek+1
y∥2
≤2β2∥O−1
y∥2
1− ∥Γy∥∥Λ−1
yb∥2∥Λya∥2L2
g,1E
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
+∥Γy∥E∥ˆek
y∥2
+ 2β2∥O−1
y∥2
1− ∥Γy∥∥∥Λya∥2L2
g,1E
∥xk−¯xk∥2+∥yk−¯yk∥2
+ 2β2∥O−1
y∥2∥Λya∥2nσ2
g,1.
Taking summation over kand using ∥xk−¯xk∥2≤ ∥Ox∥2∥ˆek
x∥2,∥yk−¯yk∥2≤ ∥Oy∥2∥ˆek
y∥2, we
get:
(1− ∥Γy∥)KX
k=0E
∥ˆek
y∥2
≤2KX
k=0β2∥O−1
y∥2
1− ∥Γy∥∥Λ−1
yb∥2∥Λya∥2L2
g,1E
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
+E∥ˆe0
y∥2−E∥ˆek+1
y∥2+ 2KX
k=0β2∥O−1
y∥2
1− ∥Γy∥∥∥Λya∥2L2
g,1E
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
+ 2(K+ 1)β2∥O−1
y∥2∥Λya∥2nσ2
g,1
≤2KX
k=0β2∥O−1
y∥2
1− ∥Γy∥∥Λ−1
yb∥2∥Λya∥2L2
g,1E
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
+E∥ˆe0
y∥2−E∥ˆek+1
y∥2+1− ∥Γy∥
4∥Oy∥2KX
k=0E
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek
y∥2
+ 2(K+ 1)β2∥O−1
y∥2∥Λya∥2nσ2
g,1,
where the last inequality uses β2≤(1− ∥Γy∥)2
8L2
g,1∥O−1y∥2∥Oy∥2∥Λya∥2.
It follows that
K+1X
k=0E
∥ˆek
y∥2
≤3KX
k=0β2∥O−1
y∥2
(1− ∥Γy∥)2∥Λ−1
yb∥2∥Λya∥2L2
g,1E
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2
+∥Ox∥2
3∥Oy∥2KX
k=0E
∥ˆek
x∥2
+3(K+ 1)β2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2E∥ˆe0
y∥2
1− ∥Γy∥.
37Lemma 13 (Consensus error of z).Suppose that Assumptions 1- 4 hold, and γsatisfies
6γ2∥O−1
z∥2∥Oz∥2∥Λza∥2
1− ∥Γz∥·(2L2+ 2(1− ∥Γz∥)σ2
g,2)≤1− ∥Γz∥
4. (65)
We have
K+1X
k=0E
∥ˆek
z∥2
≤16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)∥O−1
z∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E
∥¯zk−zk
⋆∥2
+2E[∥ˆe0
z∥2]
1− ∥Γz∥
+8γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g+L2
g,1L2
z⋆!
∥¯xk+1−¯xk∥2#
+8γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g!
∥¯yk+2−¯yk+1∥2#
+ 16( K+ 1)nγ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+κ2
3∥Oz∥2KX
k=0E(∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2).(66)
Proof. Firstly, Eq. (34) implies that:
ˆek+1
z=Γzˆek
z−γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)#
+γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#
.
Then using Cauchy Schwartz inequality, we get
∥ˆek+1
z∥2
≤Γzˆek
z−γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)#2
+γ2O−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#2
−2*
Γzˆek
z, γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#+
+γ2O−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)#2
+γ2O−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#2(67)
38To obtain the upper bound of the right-hand side of the above equation, we first estimate some
individual terms in it as follows. Note that:
eEk∥eEk[pk]−pk(¯xk,¯yk+1)∥2
=nX
i=1eEk∇2
22gi(xk
i, yk+1
i)zk
i− ∇ 2fi(xk
i, yk+1
i)− 
∇2
22gi(¯xk,¯yk+1)z⋆
k− ∇ 2fi(¯xk,¯yk+1)2
≤3nX
i=1eEk∇2
22gi(xk
i, yk+1
i)(zk
i−zk
⋆)2+ 3nX
i=1eEk(∇2
22gi(xk
i, yk+1
i)− ∇2
22gi(¯xk,¯yk+1))zk
⋆2
+ 3nX
i=1eEk∇2fi(¯xk,¯yk+1)− ∇ 2fi(xk
i, yk+1
i)2
≤6L2
g,1(∥zk−¯zk∥2+∥¯zk−zk
⋆∥2) + 3 
L2
g,2L2
f,0
µ2g+L2
f,1!
 
∥xk−¯xk∥2+∥yk+1−¯yk+1∥2
(68)
and
eEk∥pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)∥2
=nX
i=1eEk∥∇2
22gi(¯xk+1,¯yk+2)zk+1
⋆− ∇ 2fi(¯xk+1,¯yk+2)− ∇2
22gi(¯xk,¯yk+1)zk
⋆+∇2fi(¯xk,¯yk+1)∥2
≤3nX
i=1eEk∥(∇2
22gi(¯xk+1,¯yk+2)− ∇2
22gi(¯xk,¯yk+1))zk+1
⋆∥2
+ 3nX
i=1eEk∥∇2
22gi(¯xk,¯yk+1)(zk+1
⋆−zk
⋆)∥2+ 3nX
i=1eEk∥∇2fi(¯xk+1,¯yk+2)− ∇ 2fi(¯xk,¯yk+1)∥2
≤3eEk" 
L2
f,1+L2
g,2L2
f,0
µ2g!
(∥¯xk+1−¯xk∥2+∥¯yk+2−¯yk+1∥2) +L2
g,1L2
z⋆∥¯xk−¯xk−1∥2#
.
(69)
Then we present the bound of the right-hand side of (67). For the first term, we have the following
evaluations:
eEk"Γzˆek
z−γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)##
≤∥Γz∥∥ˆek
z∥2+γ2∥O−1
z∥2
1− ∥Γz∥eEk
"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)#2

≤∥Γz∥∥ˆek
z∥2+γ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥eEkh
∥eEk[pk]−pk(¯xk,¯yk+1)∥2i
+γ2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
1− ∥Γz∥eEk
∥pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)∥2
(70)
where the first inequality use Jensen’s inequality and the second inequality use ∥ˆU⊤
z∥ ≤1.
39For the second term, since zk,yk+1∈ Uk, we have:
eEkO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#2
≤∥O−1
z∥2∥Λza∥2eEkh
∥eEk[pk]−pk2
]
≤2∥O−1
z∥2∥Λza∥2(∥zk∥2σ2
g,2+nσ2
f,1)
≤6∥O−1
z∥2∥Λza∥2  
∥zk−¯zk∥2+∥¯zk−zk
⋆∥2+nL2
f,1
µ2g!
σ2
g,2+nσ2
f,1!
.(71)
For the third term, we have:
2eEk*
Γzˆek
z, γO−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#+
= 0, (72)
since ˆek
z∈ Uk.
Next, for the last two terms, we have:
eEk
O−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pk(¯xk,¯yk+1)i
Λ−1
zbΛzaˆU⊤
z
pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)#2

≤∥O−1
z∥2∥Λza∥2eEkh
∥eEk[pk]−pk(¯xk,¯yk+1)∥2i
+∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2eEk
∥pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)∥2
.(73)
eEk
O−1
z"
ΛzaˆU⊤
zh
eEk[pk]−pki
0#2
≤ ∥O−1
z∥2∥Λza∥2eEkh
∥eEk[pk]−pk∥2i
. (74)
Taking the expectation eEkon both sides of (67) and plugging (70),(71),(72),(73) and(74) into it,
we obtain:
eEk
∥ˆek+1
z∥2
≤∥Γz∥∥ˆek
z∥2+2γ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥eEkh
∥eEk[pk]−pk(¯xk,¯yk+1)∥2i
+2γ2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
1− ∥Γz∥eEk
∥pk+1(¯xk+1,¯yk+2)−pk(¯xk,¯yk+1)∥2
+ 2γ2∥O−1
z∥2∥Λza∥2eEk∥eEk[pk]−pk∥2
≤∥Γz∥∥ˆek
z∥2+ 12nγ2∥O−1
z∥2∥Λza∥2 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+12γ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥(L2
g,1+ (1− ∥Γz∥)σ2
g,2)eEk
∥Oz∥2∥ˆek
z∥2+∥¯zk−zk
⋆∥2
+6γ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
g,2L2
f,0
µ2g+L2
f,1!
eEk
∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,1+L2
g,2L2
f,0
µ2g!
eEk
∥¯xk+1−¯xk∥2+∥¯yk+2−¯yk+1∥2
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥L2
g,1L2
z⋆eEk
∥¯xk−¯xk−1∥2
,
40where the second inequality uses (36), (68), (69), and (71).
Thanks to
6γ2∥O−1
z∥2∥Oz∥2∥Λza∥2
1− ∥Γz∥·(2L2+ 2(1− ∥Γz∥)σ2
g,2)≤1− ∥Γz∥
4,
we have:
eEk
∥ˆek+1
z∥2
≤1 + 3∥Γz∥
4∥ˆek
z∥2+12γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)∥O−1
z∥2∥Λza∥2
1− ∥Γz∥eEk
∥¯zk−zk
⋆∥2
+ 12nγ2∥O−1
z∥2∥Λza∥2 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+1− ∥Γz∥
4∥Oz∥2κ2(∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2)
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,1+L2
g,2L2
f,0
µ2g!
eEk
∥¯xk+1−¯xk∥2+∥¯yk+2−¯yk+1∥2
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥L2
g,1L2
z⋆eEk
∥¯xk−¯xk−1∥2
.
Taking summation and expectation on both sides, we get:
3
4(1− ∥Γz∥)KX
k=0E
∥ˆek
z∥2
≤E∥ˆe0
z∥2−E
∥ˆek+1
z∥2
+12γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)∥O−1
z∥2∥Λza∥2
1− ∥Γz∥KX
k=0E
∥¯zk−zk
⋆∥2
+1− ∥Γz∥
4∥Oz∥2κ2KX
k=0E(∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2)
+ 12nγ2∥O−1
z∥2∥Λza∥2 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g+L2
g,1L2
z⋆!
∥¯xk+1−¯xk∥2#
+6γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
1− ∥Γz∥KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g!
∥¯yk+2−¯yk+1∥2#
.
Thus,
K+1X
k=0E
∥ˆek
z∥2
≤16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)∥O−1
z∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E
∥¯zk−zk
⋆∥2
+2E[∥ˆe0
z∥2]
1− ∥Γz∥
+8γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g+L2
g,1L2
z⋆!
∥¯xk+1−¯xk∥2#
+8γ2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0E" 
L2
f,1+L2
g,2L2
f,0
µ2g!
∥¯yk+2−¯yk+1∥2#
41+ 16( K+ 1)nγ2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+κ2
3∥Oz∥2KX
k=0E(∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2).
Lemma 14 (Consensus error of x).Suppose that Assumptions 1- 4 and Lemmas 4, 5, and 7 hold. We
have
K+1X
k=0E∥ˆek
x∥2
≤E∥ˆe0
x∥2
1− ∥Γx∥+2α2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+6nα2θ(K+ 1)∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥
θ+1−θ
1− ∥Γx∥ 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
+α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[∆k+nIk]
+2eL2α2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2
∥Λ−1
xb∥2+2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
.(75)
Proof. Firstly, the term ∥ˆek+1
x∥2can be deformed as
∥ˆek+1
x∥2
=Γxˆek
x−αO−1
x
ΛxaˆU⊤
xh
rk+1−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
2
=Γxˆek
x−αO−1
x
ΛxaˆU⊤
xh
Ek[rk+1]−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
2
+α2Ek"O−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
02#
−2
Γxˆek
x, αO−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
0
+ 2α2*
O−1
x
ΛxaˆU⊤
xh
Ek[rk+1]−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
,O−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
0+
(76)
due to Eq. (35).
42Then, for the first term of the right-hand side of (76), we use Jensen’s Inequality and get:
Ek
Γˆek
x−αO−1
x
ΛxaˆU⊤
xh
Ek[rk+1]−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
2

≤∥Γx∥∥ˆek
x∥2+α2∥O−1
x∥2
1− ∥Γx∥Ek

ΛxaˆU⊤
xh
Ek[rk+1]−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
2

≤∥Γx∥∥ˆek
x∥2+α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥EkEk[rk+1]−e∇Φ(¯xk)2
,
+α2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
1− ∥Γx∥Eke∇Φ(¯xk+1)−e∇Φ(¯xk)2
.(77)
For the second term in the right-hand side of (76), we have:
EkO−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
02
≤∥O−1
x∥2∥Λxa∥2Ek∥Ek[rk+1]−rk+1∥2
=θ2∥O−1
x∥2∥Λxa∥2Ek∥Ek[uk]−uk∥2.(78)
Like (72), we have:
Ek
Γxˆek
x, αO−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
0
= 0. (79)
Next, for the last term, we have:
2α2Ek*
O−1
x
ΛxaˆU⊤
xh
Ek[rk+1]−e∇Φ(¯xk)i
Λ−1
xbΛxaˆU⊤
xh
e∇Φ(¯xk+1)−e∇Φ(¯xk)i
,O−1
x
ΛxaˆU⊤
x
Ek[rk+1]−rk+1
0+
≤α2∥O−1
x∥2∥Λxa∥2Ekh
∥Ek[rk+1]−e∇Φ(¯xk)∥2+∥Ek[rk+1]−rk+1∥2i
+α2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2Ekh
∥e∇Φ(¯xk+1)−e∇Φ(¯xk)∥2i
.
(80)
Taking the expectation on both sides of (76), and plugging (77), (78), (79), (80) into it, we obtain:
Ek∥ˆek+1
x∥2
≤∥Γx∥∥ˆek
x∥2+ 2α2θ2∥O−1
x∥2∥Λxa∥2Ek∥Ek[uk]−uk∥2
+2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥Ekh
∥Ek[rk+1]−e∇Φ(¯xk)∥2+∥Λ−1
xb∥2∥e∇Φ(¯xk+1)−e∇Φ(¯xk)∥2i
.
43Taking expectation and summation on both sides, we obtain:
(1− ∥Γx∥)KX
k=0E∥ˆek
x∥2
≤E∥ˆe0
x∥2−E∥ˆek+1
x∥2+2eL2α2∥O−1
x∥2∥Λ−1
xb∥2∥Λxa∥2
1− ∥Γx∥KX
k=0E∥¯xk+1−¯xk∥2
+2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
1−θ
θe∇Φ(¯x0)2
+ 2KX
k=0EEk[uk]−e∇Φ(¯xk)2!
+2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥·2eL2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
+
2α2θ2∥O−1
x∥2∥Λxa∥2+2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥θ(1−θ)KX
k=0E∥Ek[uk]−uk∥2
≤E∥ˆe0
x∥2−E∥ˆek+1
x∥2+2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥1−θ
θe∇Φ(¯x0)2
+ 6(K+ 1)nα2θ∥O−1
x∥2∥Λxa∥2
θ+1−θ
1− ∥Γx∥ 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
+α2∥O−1
x∥2∥Λxa∥280L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[∆k+nIk]
+2eL2α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥
∥Λ−1
xb∥2+2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
.
where the first inequality uses eL- Lipschitz continuity of e∇Φ, Lemma 7, and the second inequality
uses Lemma 4 , Lemma 5 and
∥zk+1−¯zk+1∥2≤∆k,∥¯zk+1−zk+1
⋆∥2≤nIk.
Hence we get
K+1X
k=0E∥ˆek
x∥2
≤E∥ˆe0
x∥2
1− ∥Γx∥+2α2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+6nα2θ(K+ 1)∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥
θ+1−θ
1− ∥Γx∥ 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
+α2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[∆k+nIk]
+2eL2α2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2
∥Λ−1
xb∥2+2(1−θ)2
θ2K−1X
k=0Eh¯xk+1−¯xk2i
.
The following lemma gather the consensus analysis of x, y, z together:
Lemma 15. Take
η1=3κ2β2∥Oy∥2∥O−1
y∥2
(1− ∥Γy∥)2∥Λ−1
yb∥2∥Λya∥2L2
g,1+ 16γ2L2 
2κ2+L2
z⋆∥Oz∥2∥∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
(1− ∥Γz∥)2
44+ 4κ2eL2
1 +(1−θ)2
θ2∥Λ−1
xb∥2
α2∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
(1− ∥Γx∥)2,
η2=3κ2L2
g,1β2∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
(1− ∥Γy∥)2+ 16L2 
2κ2+L2
z⋆
γ2∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
(1− ∥Γz∥)2.
Suppose that Assumptions 1- 4 and Lemmas 12, 13, 14 hold, and α, β satisfy
α2≤(1− ∥Γx∥)2
24κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2h
80L2+ 18θ(1− ∥Γx∥)
θ+1−θ
1−∥Γx∥
σ2
g,2i,
η2β2≤1
1248L2
g,1.(82)
We have:
1
4KX
k=0E[∆k] (83)
≤(η1+ 48κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+32L2
g,1η2β
µg∥¯y0−y⋆(¯x0)∥2+ 3(K+ 1)η2β2σ2
g,1
+κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[nIk]
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥·16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥KX
k=−1E[nIk]
+3κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+2∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+2κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 16( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 24( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
.
Proof. Adding (59), (66) and (75) together, we get:
κ2∥Ox∥2K+1X
k=0E[∥ˆek
x∥2] +κ2∥Oy∥2K+1X
k=0E[∥ˆek
y∥2] +∥Oz∥2K+1X
k=0E[∥ˆek
z∥2]
≤3κ2KX
k=0β2∥Oy∥2∥O−1
y∥2
(1− ∥Γy∥)2∥Λ−1
yb∥2∥Λya∥2L2
g,1Eh
∥¯xk+1−¯xk∥2+∥¯yk+1−¯yk∥2i
+κ2∥Ox∥2
3KX
k=0Eh
∥ˆek
x∥2i
+3κ2(K+ 1)β2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥
+16γ2(L2
g,1+ (1− ∥Γ∥)σ2
g,2)∥O−1
z∥2∥Oz∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0Eh
∥¯zk−zk
⋆∥2i
+κ2
3KX
k=0E(∥Ox∥2∥ˆek
x∥2+∥Oy∥2∥ˆek+1
y∥2)
+8γ2(2κ2+L2
z⋆)L2∥Oz∥2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0Eh
∥¯xk+1−¯xk∥2i
+16γ2κ2L2∥Oz∥2∥O−1
z∥2∥Λ−1
zb∥2∥Λza∥2
(1− ∥Γz∥)2KX
k=0Eh
∥¯yk+2−¯yk+1∥2i
45+ 16( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+2∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+2κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+6nκ2α2θ(K+ 1)∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥
θ+1−θ
1− ∥Γx∥ 
σ2
f,1+ 3σ2
g,2L2
f,0
µ2g!
+κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0[∆k+nIk]
+2κ2eL2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2
∥Λ−1
xb∥2+2(1−θ)2
θ2K−1X
k=0E¯xk+1−¯xk2
≤3
4K+1X
k=0E
κ2∥Ox∥2∥ˆ ek
x∥2+κ2∥Oy∥2∥∥ˆ ek
y∥2+∥Oz∥2∥∥ˆ ek
z∥2
+ (η1+ 48κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+η232L2
g,1β
µg∥¯y0−y⋆(¯x0)∥2+ 3(K+ 1)β2σ2
g,1
+κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[nIk]
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥·16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥KX
k=−1E[nIk]
+3κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+2∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+2κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 16( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 24( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
.
where the second inequality uses (54) and
η2L2
g,1β2·52 +κ2α2∥O−1
x∥2∥Ox∥2∥Λxa∥2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2
≤1
12.
Hence:
1
4KX
k=0E[∆k]
≤(η1+ 48κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+32L2
g,1η2β
µg∥¯y0−y⋆(¯x0)∥2+ 3(K+ 1)η2β2σ2
g,1
+κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[nIk]
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥·16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥KX
k=−1E[nIk]
+3κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+2κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+2∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+2κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
46+ 16( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 24( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
.
C.1.8 Proof of the main theorem
Before giving the final result of the convergence analysis, we present the following Lemma that
combines the results in the analysis of Ikand∆k:
Lemma 16. Suppose that Assumptions 1- 4 and Lemmas 6, 11, 15 hold. If α, β, γ, θ satisfy
α2≤(1− ∥Γx∥)2
16∥Ox∥2∥O−1x∥2∥Λxa∥2h
80L2+ 18θ
θ+1−θ
1−∥Γx∥
(1− ∥Γx∥)σ2
g,2i
·2040κ6,
β2η2≤1
1024L2
g,1,
γ2≤(1− ∥Γz∥)2
256∥Oz∥2∥O−1z∥2∥Λza∥2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)·2040κ4,(84)
and
40
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆ 
L2+θσ2
g,2
n!
≤1
4080κ4,
(85)
then we have:
KX
k=0E[∆k+nIk]≲κ4(η1+κ2L2
y⋆η2)α2n(Φ(¯x0)−inf Φ)
α+θ(K+ 1)( σ2
f,1+κ2σ2
g,2)
+α2L2
z⋆
γ2µ2g+κ4α2
β2µ2gL2
y⋆n(Φ(¯x0)−inf Φ)
α+θ(K+ 1)( σ2
f,1+κ2σ2
g,2)
+κ6β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+κ4η2β2(K+ 1)σ2
g,1
+κ6∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+κ4∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥+κ6∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥
+κ6α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2·1−θ
θe∇Φ(¯x0)2
+ (K+ 1)κ4γ2∥Oz∥2∥O−1
z∥2∥Λza∥2n
1− ∥Γz∥(σ2
f,1+κ2σ2
g,2)
+ (K+ 1)κ6α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2n
1− ∥Γx∥(σ2
f,1+κ2σ2
g,2)
+(K+ 1)γ
µg(σ2
f,1+κ2σ2
g,2) +n∥z1
⋆∥2
µgγ+κ4 
∥¯y0−y⋆(¯x0)∥2
βµg+Kσ2
g,1
µgβ!
.
47Proof. Combining (57) and (83), we obtain
KX
k=0E[∆k] +1
1020κ4KX
k=−1E[nIk]
≤4(η1+ 48κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+128L2
g,1η2β
µg∥¯y0−y⋆(¯x0)∥2+ 12( K+ 1)η2β2σ2
g,1
+ 4κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[nIk]
+4∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥·16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥KX
k=−1E[nIk]
+12κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+8κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+8∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+4κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+8κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 64( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 96( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆KX
k=0E∥¯rk∥2+1
2KX
k=0E[∆k] +1
1020κ4·3n∥z1
⋆∥2
µgγ
+(K+ 1)
1020κ46γ
µg 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+73κ4
1020κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
µgβ!
.
(86)
Subtracting the term
4κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
1− ∥Γx∥80L2
1− ∥Γx∥+ 18θ
θ+1−θ
1− ∥Γx∥
σ2
g,2KX
k=0E[nIk]
+4∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥16γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥KX
k=−1E[nIk] +1
2KX
k=0E[∆k]
from both sides of (86) and using the restriction of α, γ in (84), we can get:
1
2040κ4 KX
k=0E[∆k] +KX
k=−1E[nIk]!
≤4(η1+ 48κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+128L2
g,1η2β
µg∥¯y0−y⋆(¯x0)∥2+ 12( K+ 1)η2β2σ2
g,1
+12κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+8κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+8∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+4κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+8κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 64( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 96( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
48+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆KX
k=0E∥¯rk∥2+(K+ 1)
1020κ4·6γ
µg 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+1
1020κ4·3n∥z1
⋆∥2
µgγ+1
1020κ4·73κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
µgβ!
≤
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆ KX
k=0E∥¯rk+1∥2
+ 12( K+ 1)η2β2σ2
g,1+12κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+8κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥
+8∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥+4κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+8κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 64( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 96( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ (K+ 1)18γ
µg·1020κ4 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+1
1020κ4·3n∥z1
⋆∥2
µgγ+1
1020κ4·73κ4 
8
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
µgβ!
,
where the second inequality holds since
128L2
g,1η2β
µg≤1
8βµg.
Then taking (41) into the concern, we know:
1
2040κ4 KX
k=0E[∆k] +KX
k=−1E[nIk]!
≤40
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆
L2+θσ2
g,2
nKX
k=0E[∆k+nIk]
+ 4
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆n(Φ(¯x0)−inf Φ)
α
+ 12θ(K+ 1)
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆ 
σ2
f,1+ 2σ2
g,2L2
f,0
µ2g!
+ 12( K+ 1)η2β2σ2
g,1+12κ2β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+8κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥
+8∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥+4κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+8κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+ 64( K+ 1)nγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ 96( K+ 1)nκ2α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥ 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+ (K+ 1)18γ
µg·1020κ4 
L2
f,0
µ2gσ2
g,2+σ2
f,1!
+1
1020κ4·3n∥z1
⋆∥2
µgγ+1
1020κ4·73κ48
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
µgβ
,
49Since
40
4(η1+ 48κ2L2
y⋆η2)α2+1
1020κ49α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆ 
L2+θσ2
g,2
n!
≤1
4080κ4,
it follows that
KX
k=0E[∆k+nIk]
≲
κ4(η1+κ2L2
y⋆η2)α2+α2L2
z⋆
γ2µ2g+κ4α2
β2µ2gL2
y⋆n(Φ(¯x0)−inf Φ)
α
+θ(K+ 1)
κ4(η1+κ2L2
y⋆η2)α2+α2L2
z⋆
γ2µ2g+κ4α2
β2µ2gL2
y⋆
(σ2
f,1+κ2σ2
g,2)
+κ6β2(K+ 1)∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+κ4η2β2(K+ 1)σ2
g,1+κ6∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥
+κ4∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥+κ6∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+κ6α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)21−θ
θe∇Φ(¯x0)2
+
κ4γ2∥Oz∥2∥O−1
z∥2∥Λza∥2n
1− ∥Γz∥+γ
µg
(K+ 1)( σ2
f,1+κ2σ2
g,2)
+ (K+ 1)κ6α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2n
1− ∥Γx∥(σ2
f,1+κ2σ2
g,2)
+n∥z1
⋆∥2
µgγ+κ4 
1
βµg∥¯y0−y⋆(¯x0)∥2+Kσ2
g,1
µgβ!
.
Then, we finish the proof of this lemma.
Finally, we can give the proof of Lemma 17, which is a detailed version of Theorem 1:
Lemma 17 (Detailed version of Theorem 1) .Suppose that Assumptions 1- 4 hold. Then there exist
constant step-sizes α, β, γ, θ , such that
1
K+ 1KX
k=0E∥∇Φ(¯xk)∥2
≲κ5σ√
nK+κ16
3"∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥1
3
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥1
3#
σ2
3
K2
3
+κ7
2∥Ox∥∥O−1
x∥∥Λxa∥
1− ∥Γy∥1
2σ1
2
K3
4
+
κ26
5 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
n(1− ∥Γy∥)2!1
5
+κ6∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
n(1− ∥Γz∥)21
5
σ2
5
K4
5
+
κ16
3 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
3
+κ14
3∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
3
+κ8
3∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
3#
1
K+ 
κCα+κ4Cθ1
K,
where σ= max {σf,1, σg,1, σg,2},Cα, Cθare defined as:
Cα=L∇Φ+κ3∥Ox∥∥O−1
x∥∥Λxa∥L
1− ∥Γx∥+κ3L∥Ox∥∥O−1
x∥∥Λxa∥∥Λ−1
xb∥
1− ∥Γx∥1
2
+κ4L2
g,1
µg+σ2
g,1
nµg
+κ4∥Oy∥∥O−1
y∥∥Λya∥Lg,1
1− ∥Γy∥+κ9
2Lg,1 
∥Oy∥∥O−1
y∥∥Λya∥∥Λ−1
yb∥
1− ∥Γy∥!1
2
+κ4
µg+µ2
gσ2
g,1
nL2
g,1
50+κ6∥Oz∥∥O−1
z∥∥Λza∥q
L2+ (1− ∥Γz∥)σ2
g,2
1− ∥Γz∥+κ11
2L∥Oz∥∥O−1
z∥∥Λza∥∥Λ−1
zb∥
1− ∥Γz∥1
2
,
Cθ=σ2
g,2
nL2
g,1+σ2
g,2
L2+ 1
Proof. Take L1=L2+ 
θ(1−θ) +L∇Φαθ2σ2
g,2
nand use the conclusion of Lemmas 8 and 16,
we get:
1
K+ 1KX
k=0E∥∇Φ(¯xk)∥2
≲Φ(¯x0)−inf Φ
α(K+ 1)+1
n 
θ(1−θ) +L∇Φαθ2
(σ2
f,1+κ2σ2
g,2) +(1−θ)2
θ(K+ 1)∥∇Φ 
¯x0
∥2
+L1
κ4(η1+κ2L2
y⋆η2)α2+α2L2
z⋆
γ2µ2g+κ4α2
β2µ2gL2
y⋆Φ(¯x0)−inf Φ
α(K+ 1)+θ
n(σ2
f,1+κ2σ2
g,2)
+L1κ6β2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1+L1κ4η2β2σ2
g,1
n
+L1
K+ 1κ6∥Oy∥2E∥ˆe0
y∥2
n(1− ∥Γy∥)+κ4∥Oz∥2E∥ˆe0
z∥2
n(1− ∥Γz∥)+κ6∥Ox∥2E∥ˆe0
x∥2
n(1− ∥Γx∥)
+L1κ6α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(K+ 1)(1 − ∥Γx∥)2·1−θ
θ·e∇Φ(¯x0)2
n
+L1
κ4γ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+γ
nµg
(σ2
f,1+κ2σ2
g,2)
+L1κ6α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥(σ2
f,1+κ2σ2
g,2)
+L1∥z1
⋆∥2
(K+ 1)µgγ+L1κ41
βµg(K+ 1)∥¯y0−y⋆(¯x0)∥2+σ2
g,1
nµgβ
.(87)
Define:
ζy
0=1
nnX
i=1∥∇2gi(¯x0,¯y0)− ∇ 2g(¯x0,¯y0)∥2,
ζz
0=1
nnX
i=1E
∥∇2
22gi(¯x0,¯y1)− ∇2
22g(¯x0,¯y1)∥2∥z1
⋆∥2+∥∇2gi(¯x0,¯y1)− ∇ 2g(¯x0,¯y1)∥2
,
ζx
0=1
nnX
i=1∥∇1fi(¯x0, y⋆(¯x0))− ∇ 1f(¯x0, y⋆(¯x0))∥2
+1
nnX
i=1∥∇2
12gi(¯x0, y⋆(¯x0))− ∇2
12g(¯x0, y⋆(¯x0))∥2∥z1
⋆∥2,
ˆζ0=1
ne∇Φ(¯x0)2
.
Then we take:
α1=κ−4rn
Kσ2, (88)
αx,2=(1− ∥Γx∥)2
κ10K∥Ox∥2∥O−1x∥2∥Λxa∥2σ21
4
αy,2= 
1− ∥Γy∥
κ13K∥Oy∥2∥O−1y∥2∥Λya∥2σ2
g,1!1
3
,
51αy,3= 
n(1− ∥Γy∥)2
κ21K∥Oy∥2∥O−1y∥2∥Λya∥2∥Λ−1
yb∥2σ2
g,1!1
5
,
αz,2=1− ∥Γz∥
κ13K∥Oz∥2∥O−1z∥2∥Λza∥2σ21
3
,
αz,3= 
n(1− ∥Γz∥)2
κ25K∥Oz∥2∥O−1z∥2∥Λza∥2∥Λ−1
zb∥2σ2
g,1!1
5
,
αyb,2= 
1− ∥Γy∥
κ13∥Oy∥2∥O−1y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0!1
3
,
αzb,2=1− ∥Γz∥
κ11∥Oz∥2∥O−1z∥2∥Λza∥2∥Λ−1
zb∥2ζz
01
3
,
αxb,2=1− ∥Γx∥
κ5∥Ox∥2∥O−1x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
01
3
,
θ1= 
nκ2ˆζ0
Kσ2!1
2
,
θ2=κ3αx,2,
and
θ=
Cθ+1
θ1+1
θ2−1
,
α=Θ
Cα+√
1−θ
θκ3+1
α1+1
αy,2+1
αy,3+1
αz,3+1
αyb,2+1
αzb,2+1
αxb,2+1
αz,2+1
αx,2−1
,
β=Θ 
κ4α
,
γ=Θ 
κ4α
,
(89)
52It yields L1= Θ( L2), and (45),(53),(56),(40),(58),(65),(82),(84), and (85) hold. It implies that
the restrictions on the step-sizes α, β, γ, θ in all previous lemma conditions hold. Thus all previous
lemmas hold. We obtain:
1
K+ 1KX
k=0E∥∇Φ(¯xk)∥2
≲Φ(¯x0)−inf Φ
αK+θ
n(σ2
f,1+κ2σ2
g,2) +ˆζ0
θK+κ6β2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1+η2κ4β2σ2
g,1
n
+1
K"
κ6∥Oy∥2E∥ˆe0
y∥2
n(1− ∥Γy∥)+κ4∥Oz∥2E∥ˆe0
z∥2
n(1− ∥Γz∥)+κ6∥Ox∥2E∥ˆe0
x∥2
n(1− ∥Γx∥)#
+
κ4γ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+γ
nµg
(σ2
f,1+κ2σ2
g,2)
+κ6α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥(σ2
f,1+κ2σ2
g,2)
+∥z1
⋆∥2
(K+ 1)µgγ+κ4 
1
βµg(K+ 1)∥¯y0−y⋆(¯x0)∥2+σ2
g,1
nµgβ!
≲θ
n(σ2
f,1+κ2σ2
g,2) +1
θK+κ
αK+κ9σ2
g,1
nα+κ14α2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1
+ 
κ10∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
(1− ∥Γy∥)2+κ14∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
(1− ∥Γz∥)2!
κ12α4σ2
g,1
n
+α2κ14∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
K(1− ∥Γy∥)+α2κ12∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
K(1− ∥Γz∥)
+α2κ6∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
K(1− ∥Γx∥)
+
κ12α2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+κ6α2θ∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2+κ5α
n
(σ2
f,1+κ2σ2
g,2)
≲θ1
n(σ2
f,1+κ2σ2
g,2) +κ4
θ1K+Cθκ4
K+κ
α1K+κ9σ2
g,1
nα1+κ5α1
n(σ2
f,1+κ2σ2
g,2)
+κ14α2
y,2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1+κ
αy,2K
+κ10∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
(1− ∥Γy∥)2κ12α4
y,3σ2
g,1
n+κ
αy,3K
+κ14∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
(1− ∥Γz∥)2κ12α4
z,3σ2
g,1
n+κ
αz,3K
+α2
yb,2κ14∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
K(1− ∥Γy∥)+κ
αyb,2K
+α2
zb,2κ12∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
K(1− ∥Γz∥)+κ
αzb,2K
+α2
xb,2κ6∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
K(1− ∥Γx∥)+κ
αxb,2K
+κ12α2
z,2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥(σ2
f,1+κ2σ2
g,2) +κ
αz,2K
+κ6α2
x,2θ2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2(σ2
f,1+κ2σ2
g,2) +κ
αx,2K+κ4
θ2K,
53where the last inequality uses (89).
Finally, substituting (88) and (89) into the last inequality, we can get:
1
K+ 1KX
k=0E∥∇Φ(¯xk)∥2
≲κ5σ√
nK+κ16
3
 
∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!1
3
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥1
3
σ2
3
K2
3
+κ7
2∥Ox∥∥O−1
x∥∥Λxa∥
1− ∥Γy∥1
2σ1
2
K3
4
+
κ26
5 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
n(1− ∥Γy∥)2!1
5
+κ6∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
n(1− ∥Γz∥)21
5
σ2
5
K4
5
+
κ16
3 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
3
+κ14
3∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
3
+κ8
3∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
3#
1
K+ 
κCα+κ4Cθ1
K,
where σ= max {σf,1, σg,1, σg,2}.
Remark 7. From the proof of Lemma 17, the impact of the moving average technique on variance
reduction becomes evident. The termθ
nσ2absorb α2η1σ2, which includes the high order term α4σ2.
Additionally, compared to y, z, the quadratic term related to σ2ofxhas an extra term θmultiplied in
the numerator ( α2θσ2). These details reduce the impacts of noise to terms related to x, confirming
the conclusion that terms related to y, zdominate the rate in precious sections. Notably, taking θ <1
is indispensable our proof. If we take θ= 1, there would be a constant term1
nσ2in the convergence
rate (see the first inequality of (87)), since the coefficient α2/β2+α2/γ2=O(1). This would not
guarantee the convergence of SPARKLE .
C.2 Analysis of consensus error and transient iteration complexity
From Lemma 17, we can immediately obtain the transient time complexity of Algorithm 1. Here we
omit the impacts of the condition number κ.
Lemma 18. The transient time complexity of Algorithm 1 has an upper bound of:
max

n3 
∥Oy∥2∥O−1
y∥2
1− ∥Γy∥!2
∥Λya∥2, n3∥Oz∥2∥O−1
z∥2
1− ∥Γz∥2
∥Λza∥2,
n2∥Ox∥∥O−1
x∥
1− ∥Γx∥2
∥Λxa∥2, n 
∥Oy∥∥O−1
y∥∥Λ−1
yb∥
1− ∥Γy∥!4
3
∥Λya∥,
n∥Oz∥∥O−1
z∥∥Λ−1
zb∥
1− ∥Γz∥4
3
∥Λza∥, n∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
1− ∥Γx∥2
3
,
n∥Ox∥∥O−1
x∥∥Λxa∥∥Λ−1
xb∥
1− ∥Γx∥, n
.(90)
Proof. According to lemma 17, SPARKLE achieves linear speedup if:
1√
nK≳
 
∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!1
3
+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥1
3
1
K2
3
54+∥Ox∥∥O−1
x∥∥Λxa∥
1− ∥Γy∥1
21
K3
4
+
 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
n(1− ∥Γy∥)2!1
5
+∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
n(1− ∥Γz∥)21
5
1
K4
5
+
 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
3
+∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
3
+∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
3#
1
K+ (Cα+Cθ)1
K.
It holds when Ksatisfies:
 
∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!1
31
K2
3≲1√
nK,
∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥1
31
K2
3≲1√
nK,
 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
n(1− ∥Γy∥)2!1
51
K4
5≲1√
nK,
∥Ox∥∥O−1
x∥∥Λxa∥
1− ∥Γy∥1
21
K3
4≲1√
nK,
∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
n(1− ∥Γz∥)21
51
K4
5≲1√
nK,
 
∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
31
K≲1√
nK,
∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
31
K≲1√
nK,
∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
31
K≲1√
nK,
(Cα+Cθ)1
K≲1√
nK.
Then we get:
K≳max(
n3∥Oy∥2∥O−1
y∥2
1− ∥Γy∥2
∥Λya∥2, n3∥Oz∥2∥O−1
z∥2
1− ∥Γz∥2
∥Λza∥2,
n2∥Ox∥∥O−1
x∥
1− ∥Γx∥2
∥Λxa∥2, n 
∥Oy∥∥O−1
y∥∥Λ−1
yb∥
1− ∥Γy∥!4
3
∥Λya∥,
n∥Oz∥∥O−1
z∥∥Λ−1
zb∥
1− ∥Γz∥4
3
∥Λza∥, n∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
1− ∥Γx∥2
3
,
n∥Ox∥∥O−1
x∥∥Λxa∥∥Λ−1
xb∥
1− ∥Γx∥, n
.
55C.2.1 Consensus Error
Lemma 19. Suppose that Assumptions 1- 4 hold. Then there exist constant step-sizes α, β, γ, θ , such
that Lemma 17 holds and
1
KKX
k=0E∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
≲Kn
K 
∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!
,
where≲Kdenotes the the asymptotic rate when K→ ∞ .
Proof. Suppose α,β,γ, and θsatisfy the constraints given in (88) and(89), which ensures that
Theorem 1 (Lemma 17) holds.
For clarity, we define the constants:
c1=9α2L2
z⋆
γ2µ2g+438κ4α2
β2µ2gL2
y⋆, c 2= 10 
L2+θσ2
g,2
n!
.
Then there exist α,β,γ, and θthat satisfy the constraints in (88) and (89), and also:
c1≤0.01L−2, c 2≤11L2. (91)
We take such values for step-sizes in the following proof.
We proceed by substituting (41) into (57), yielding:
KX
k=−1E[Ik]≤4c1 
Φ(¯x0)−inf Φ
α+c2K−1X
k=0E∆k
n+Ik
+3θ
nK 
σ2
f,1+ 2σ2
g,2L2
f,0
µ2g!!
+ 510 κ4KX
k=0E∆k
n
+3∥z1
⋆∥2
µgγ
+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+ 73κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
nµgβ!
.
Subtracting 4c1c2PK−1
k=0E[Ik]from both sides, we get:
KX
k=−1E[Ik]≲Φ(¯x0)−inf Φ
α+θ
nK 
σ2
f,1+σ2
g,2L2
f,0
µ2g!
+κ4KX
k=0E∆k
n
+∥z1
⋆∥2
µgγ
+Kγ
µgn 
σ2
g,2L2
f,0
µ2g+σ2
f,1!
+κ4 
1
βµg∥¯y0−y⋆(¯x0)∥2+Kσ2
g,1
nµgβ!
.
Substituting (57) into (41), we obtain:
1
4KX
k=0E¯rk+12
≤Φ(¯x0)−inf Φ
α+c2KX
k=0E∆k
n
+c2c1KX
k=0E∥¯rk∥2
+c2"
510κ4KX
k=0E∆k
n
+3∥z1
⋆∥2
µgγ+6(K+ 1)γ
µgn 
3σ2
g,2L2
f,0
µ2g+σ2
f,1!
+73κ4 
4
βµg∥¯y0−y⋆(¯x0)∥2+4Kσ2
g,1
nµgβ!#
+3θ
n(K+ 1) 
σ2
f,1+ 2σ2
g,2L2
f,0
µ2g!
.
56Subtracting c2c1PK
k=0E∥¯rk∥2from both sides, we get
KX
k=0E¯rk+12
≲Φ(¯x0)−inf Φ
α+κ4KX
k=0E∆k
n
+θ
nK 
σ2
f,1+σ2
g,2L2
f,0
µ2g!
+∥z1
⋆∥2
µgγ+Kγ
µgn 
σ2
g,2L2
f,0
µ2g+σ2
f,1!
+κ4 
1
βµg∥¯y0−y⋆(¯x0)∥2+Kσ2
g,1
nµgβ!
.
Taking
η3= 
κ2∥O−1
x∥2∥Ox∥2∥Λxa∥2α2
(1− ∥Γx∥)2+∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥·γ2(L2
g,1+ (1− ∥Γz∥)σ2
g,2)
1− ∥Γz∥!
,
and combining previous results with (83), we obtain
KX
k=0E[∆k]
≲(η1+κ2L2
y⋆η2)α2KX
k=0E∥¯rk+1∥2+κη2β∥¯y0−y⋆(¯x0)∥2+Kη2β2σ2
g,1+η3KX
k=−1E[nIk]
+κ2β2K∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1+κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥
+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥+κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
θ(1− ∥Γx∥)2e∇Φ(¯x0)2
+Knγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
κ2σ2
g,2+σ2
f,1
+Knκ2α2θ∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2 
κ2σ2
g,2+σ2
f,1
≲
(η1+κ2L2
y⋆η2)α2+η3
·κ4KX
k=0E[∆k] +κη2β∥¯y0−y⋆(¯x0)∥2+Kη2β2σ2
g,1
+n
(η1+κ2L2
y⋆η2)α2+η31
α+θ
nK 
σ2
f,1+κ2σ2
g,2
+1
µgγ+Kγ
µgn 
κ2σ2
g,2+σ2
f,1
+κ4 
1
βµg+Kσ2
g,1
nµgβ!#
+κ2β2K∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥nσ2
g,1
+κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
θ(1− ∥Γx∥)2e∇Φ(¯x0)2
+κ2∥Oy∥2E∥ˆe0
y∥2
1− ∥Γy∥+∥Oz∥2E∥ˆe0
z∥2
1− ∥Γz∥+κ2∥Ox∥2E∥ˆe0
x∥2
1− ∥Γx∥
+Knγ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
κ2σ2
g,2+σ2
f,1
+Knκ2α2θ∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2 
κ2σ2
g,2+σ2
f,1
.
(88) and (89) imply that
η1≲κ2+κ2∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2, η 2≲κ2,
(η1+κ2L2
y⋆η2)α2≲κ−4, η 3≲κ−4
57where η1, η2are defined in Lemma 15.
Then taking α, β, γ, θ such that (88),(89),(91) hold and κ4[(η1+κ2L2
y⋆η2)α2+η3]is a sufficiently
small constant, we can derive the following result:
1
KKX
k=0E∆k
n
≲κη2β
K+η2β2σ2
g,1
n
+
(η1+κ2L2
y⋆η2)α2+η31
αK+θ
n 
σ2
f,1+κ2σ2
g,2
+1
µgγK+γ
µgn 
κ2σ2
g,2+σ2
f,1
+
(η1+κ2L2
y⋆η2)α2+η3
κ4 
1
βµgK+σ2
g,1
nµgβ!
+κ2β2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1
+κ2α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
θK(1− ∥Γx∥)2+κ2∥Oy∥2E∥ˆe0
y∥2
(1− ∥Γy∥)Kn+∥Oz∥2E∥ˆe0
z∥2
(1− ∥Γz∥)Kn+κ2∥Ox∥2E∥ˆe0
x∥2
(1− ∥Γx∥)Kn
+γ2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
κ2σ2
g,2+σ2
f,1
+κ2α2θ∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2 
κ2σ2
g,2+σ2
f,1
≲κ5η2α
K+κ10α2σ2
g,1
n+κ
Kh
(η1+κ2L2
y⋆η2)α+η3
αi
+
(η1+κ2L2
y⋆η2)α2+η3"
θ
n 
σ2
f,1+κ2σ2
g,2
+κ5α
n 
κ2σ2
g,2+σ2
f,1
+κ9σ2
g,1
nα#
+κ2∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥σ2
g,1κ8α2+κ−1α∥Ox∥2∥O−1
x∥2∥Λxa∥2
K(1− ∥Γx∥)2
+α2κ10∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
K(1− ∥Γy∥)+α2κ8∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
K(1− ∥Γz∥)
+α2κ2∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
K(1− ∥Γx∥)
+κ8α2∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥ 
κ2σ2
g,2+σ2
f,1
+κ2α2θ∥Ox∥2∥O−1
x∥2∥Λxa∥2
(1− ∥Γx∥)2 
κ2σ2
g,2+σ2
f,1
.
From (88) and (89), we can determine the asymptotic orders for α, β, γ andθwhen K→ ∞
α=O
κ−4rn
Kσ2
, β =Orn
Kσ2
, γ =Orn
Kσ2
, θ =O
κrn
Kσ2
.
Then we get
1
KKX
k=0E∆k
n
≲Kκ2n
K 
∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!
,
where≲Kdenotes the the asymptotic rate when K→ ∞ .
Then using (36) and the definition of ∆k, we get
1
KKX
k=0E∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
≲Kn
K 
∥Oz∥2∥O−1
z∥2∥Λza∥2
1− ∥Γz∥+∥Oy∥2∥O−1
y∥2∥Λya∥2
1− ∥Γy∥!
.
58In particular, the corresponding result of SPARKLE variants that using EXTRA, ED or GT is
1
KKX
k=0E∥xk−¯xk∥2
n+∥yk−¯yk∥2
n
≲Kn
K1
1−ρy+1
1−ρz
,
where ρy, ρzare spectrum gaps of relevant mixing matrices.
C.2.2 Essential matrix norms for analysis
Common heterogeneity-correction algorithms, including ED, EXTRA and GT, satisfy Assumption
3, according to transformations (31),(32) and discussions in [ 2, Appendix B.2]. Then Lemma 3
ensures that ∥Γ∥<1. From Lemma 18, the transient time complexity depends on the coefficients
∥O∥2,∥O−1∥2,∥Λa∥2,∥Λ−1
b∥2, and∥Γ∥2. The solution of these matrices is constructive. Table 4
presents the upper bounds of these coefficients with different communication modes. Please refer
to [2, Appendix B.2] for more details about the construction of these matrices and the computation
of relevant norms. It is required that Wis positive definite for ED, EXTRA, and we denote the
smallest nonzero eigenvalue of Wbyρ.ρcan view as a constant. Otherwise we replace Wwith
tI+ (1−t)Wfor some constant t∈(0,1)(e.g.t= 1/2).
Substituting values of ∥Os∥,∥O−1
s∥,∥Λsa∥,∥Λ−1
sb∥,∥Γs∥into(90) , we obtain the explicit transient
iteration complexity for some specific examples of Algorithm 1, which are listed in Table 2. Note
that all GT variants exhibit the same transient iteration complexity.
Table 4: Upper bounds of coefficients for different heterogeneity-correction modes in Lemma 18,
where notation Ois omitted for ∥O∥and∥O−1∥.
Mode A B C ∥O∥ ∥O−1∥ ∥Λa∥ ∥ Λ−1
b∥ ∥ Γ∥
ED W (I−W)1
2W 1 ρ−1
2 ρ (1−ρ)−1
2√ρ
EXTRA I (I−W)1
2W 1 ρ−1
2 1 (1 −ρ)−1
2√ρ
ATC-GT W2I−W W21 1 ρ2(1−ρ)−1 1+ρ
2
Semi-ATC-GT W I −W W21 1 ρ (1−ρ)−1 1+ρ
2
Non-ATC-GT I I −W W21 1 1 (1 −ρ)−1 1+ρ
2
C.2.3 Theoretical gap between upper-level and lower-level
Note that ∥Λsa∥ ≤1. We rewrite the upper bound of the transient iteration complexity in Lemma 18
as
max{n3δy, n3δz, n2δx, nˆδy, nˆδz, nˆδx} (92)
where
δy=∥Oy∥2∥O−1
y∥2
1− ∥Γy∥2
∥Λya∥2, δz=∥Oz∥2∥O−1
z∥2
1− ∥Γz∥2
∥Λza∥2, δx=∥Ox∥∥O−1
x∥
1− ∥Γz∥∥Λza∥2
,
ˆδy= 
∥Oy∥∥O−1
y∥∥Λ−1
yb∥
1− ∥Γy∥!4
3
,ˆδz=∥Oz∥∥O−1
z∥∥Λ−1
zb∥
1− ∥Γz∥4
3
,
ˆδx=∥Ox∥2∥O−1
x∥2∥Λ−1
xb∥2
1− ∥Γx∥2
3
+∥Ox∥∥O−1
x∥∥Λ−1
xb∥
1− ∥Γx∥.
(93)
Suppose that we use the same communication matrices and heterogeneity-correction methods for
updating x, y, z ,i.e.
∥Ox∥=∥Oy∥=∥Oz∥,∥O−1
x∥=∥O−1
y∥=∥O−1
z∥,∥Γx∥=∥Γy∥=∥Γz∥,
∥Λxa∥=∥Λya∥=∥Λza∥,∥Λ−1
xb∥=∥Λ−1
yb∥=∥Λ−1
zb∥.
59Then we have
δx≲δy=δz,ˆδx≲ˆδy=ˆδz, (94)
Now we fix the update strategies for y, z.(94) implies that we can appropriately increase δx,ˆδxwhile
keeping the transient iteration complexity (92) unchanged (at most scaled by a constant factor). For
example, we can use a moderately sparser communication network for updating xthany, z. We
illustrate this point with three examples: SPARKLE -ED, SPARKLE -EXTRA and SPARKLE -GT
(variants), where y, zshare the same communication matrix Wy.
• SPARKLE-ED, SPARKLE-EXTRA: From Table 4, we have
δx=O 
(1−ρ(Wx))−2
, δy=δz=O 
(1−ρ(Wy))−2
,
ˆδx=O
(1−ρ(Wx))−3
2
,ˆδy=ˆδz=O 
(1−ρ(Wy))−2
.
Substituting these values into (92), we get the transient iteration complexity is bounded by
max
n2(1−ρ(Wx))−2, n3(1−ρ(Wy))−2	
SPARKLE-ED will keep the transient iteration complexity n3(1−ρ(Wy))−2(the dominated
term) if
(1−ρ(Wx))−1≲√n(1−ρ(Wy))−1. (95)
• SPARKLE-GT variants: Results in Table 4 imply that
δx=O 
(1−ρ(Wx))−2
, δy=δz=O 
(1−ρ(Wy))−2
,
ˆδx=O 
(1−ρ(Wx))−2
,ˆδy=ˆδz=O
(1−ρ(Wy))−8
3
.
Following the same argument as before, we have the following upper bound of the transient
iteration complexity of SPARKLE-GT
maxn
n2(1−ρ(Wx))−2, n3(1−ρ(Wy))−2, n(1−ρ(Wy))−8
3o
.
we get the constraints of the spectral gap 1−ρ(Wx)that maintains the transient iteration
complexity maxn
n3(1−ρ(Wy))−2, n(1−ρ(Wy))−8
3o
:
(1−ρ(Wx))−1≲maxn√n(1−ρ(Wy))−1, n−1/2(1−ρ(Wy))−4
3o
. (96)
Denote the communication times per agent of Wx,Wybycx, cyrespectively. For example, we have
cx= 2,cy=n−1when taking Ring Graph for x(i.e.[Wx]ij̸= 0iff|i−j| ∈ {0,1, n−1}), and
Complete Graph for y(i.e.Wy=1
n1n1⊤
n).
Then for each agent, the communication cost per round is O(cxp+cyq). If we take a=cx/cyto
measure the relative sparsity of the two communication matrices, and consider cy=O(1), then for
each agent, the communication cost per round is O(ap+q).(95) and(96) theoretically provide the
range of the sparsity (connectivity) degree of Wxrelative to Wy. From (95) and(96), we can set
a≪1, while maintaining the transient iteration complexity for SPARKLE -GT, SPARKLE -ED,
SPARKLE-EXTRA.
C.2.4 The transient iteration complexities of some specific examples in SPARKLE.
Now we compute the transient iteration complexities of each SPARKLE- L-Ualgorithm, where
L,U∈ {GT (variants) ,ED,EXTRA }. For brevity, here we assume that Wx=Wy=Wz, use the
same heterogeneity-correction method to y, z, and denote the spectral gap 1−ρ(Wx)by1−ρ.
Substituting the results in Table 4 into (92) and (93), we get
δx=O1
(1−ρ)2
, δy=δz=O1
(1−ρ)2
for any L,U∈ {GT (variants) ,ED,EXTRA },
ˆδx=O1
(1−ρ)2
,O1
(1−ρ)3/2
,O1
(1−ρ)3/2
60forU={GT (variants) ,ED,EXTRA }respectively, and
ˆδy=ˆδz=O1
(1−ρ)8/3
,O1
(1−ρ)2
,O1
(1−ρ)2
forL={GT (variants) ,ED,EXTRA }respectively.
Combining the above results, we can directly obtain Table 2, the transient iteration complexities of
SPARKLE with mixed heterogeneity-correction techniques in different levels.
C.3 Convergence analysis in deterministic scenarios
The following lemma gives the convergence rate of Algorithm 1 without a moving average when
there is no sample noise:
Lemma 20. Suppose that Assumptions 1- 4 hold. If σ2= 0, then there exist α, β, γ andθ= 1such
that
1
K+ 1KX
k=0E∥Φ(¯xk)∥2
≲ 
κ16∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
31
K+κ14∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
31
K
+κ8∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
31
K+eCα1
K.
whereeCαis a series of overheads which is defined below.
Proof. Note that σ2= 0implies that L1= Θ( L2)when α=O(L−1
∇Φ). Thus (87) implies that:
1
K+ 1KX
k=0E∥Φ(¯xk)∥2
≲Φ(¯x0)−inf Φ
α(K+ 1)
+L2
κ4(η1+κ2L2
y⋆η2)α2+α2L2
z⋆
γ2µ2g+κ4α2
β2µ2gL2
y⋆Φ(¯x0)−inf Φ
α(K+ 1)
+L2κ6∥Oy∥2E∥ˆe0
y∥2
n(K+ 1)(1 − ∥Γy∥)+L2κ4∥Oz∥2E∥ˆe0
z∥2
n(K+ 1)(1 − ∥Γz∥)+L2κ6∥Ox∥2E∥ˆe0
x∥2
n(K+ 1)(1 − ∥Γx∥)
+L2∥z1
⋆∥2
µgγ(K+ 1)+L2κ4
K+ 11
βµg∥¯y0−y⋆(¯x0)∥2.(97)
61Then we aim to choose the stepsize α, β, γ . Define:
eCα=L∇Φ+κ3∥Ox∥∥O−1
x∥∥Λxa∥L
1− ∥Γx∥+κ3L∥Ox∥∥O−1
x∥∥Λxa∥∥Λ−1
xb∥
1− ∥Γx∥1
2
+κ4L2
g,1
µg+κ4∥Oy∥∥O−1
y∥∥Λya∥Lg,1
1− ∥Γy∥+κ4Lg,1 
κ∥Oy∥∥O−1
y∥∥Λya∥∥Λ−1
yb∥
1− ∥Γy∥!1
2
+κ6L∥Oz∥∥O−1
z∥∥Λza∥
1− ∥Γz∥+κ11
2L∥Oz∥∥O−1
z∥∥Λza∥∥Λ−1
zb∥
1− ∥Γz∥1
2
,
eαyb,2= 
1− ∥Γy∥
κ13∥Oy∥2∥O−1y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0!1
3
,
eαzb,2=1− ∥Γz∥
κ11∥Oz∥2∥O−1z∥2∥Λza∥2∥Λ−1
zb∥2ζz
01
3
,
eαxb,2=1− ∥Γx∥
κ5∥Ox∥2∥O−1x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
01
3
.
Then there exist
α= Θ
eCα+eα−1
xb,2+eα−1
yb,2+eα−1
zb,2−1
, β= Θ 
κ4α
, γ= Θ 
κ4α
such that (45), (53), (56), (40), (58), (65), (82), and (84) hold. Then all previous lemmas hold.
Then from (97) we have:
1
K+ 1KX
k=0E∥Φ(¯xk)∥2
≲κ
αK+α2κ14∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
K(1− ∥Γy∥)
+α2κ12∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
K(1− ∥Γz∥)+α2κ6∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
K(1− ∥Γx∥)
≲ 
κ16∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2ζy
0
1− ∥Γy∥!1
31
K+κ14∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2ζz
0
1− ∥Γz∥1
31
K
+κ8∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
1− ∥Γx∥1
31
K+eCα1
K.
C.4 Degenerating to single-level algorithms
We consider the bilevel problem with the following upper- and lower-level loss function on the i-th
agent:
Fi(x, y, ϕ ) =Fi(x, ϕ), G i(x, y, ξ )≡∥y∥2
2.
Actually, this optimization problem with respect to xis single-level, since we have zk≡0,yk≡0,
uk
i=∇1fi(xk
i, ξk
i)by induction. By taking θ= 1, we get the following single-level algorithm
framework for decentralized stochastic single-level algorithm. As we discuss in previous sections, it
can recover various heterogeneity-correction algorithms, including GT, EXTRA and ED, by selecting
specific Ax,Bx,Cx.
62Algorithm 3 SPARKLE: degenerating to single-level decentralized stochastic algorithms
Require: Initialize x0=0,d0
x=0, learning rate αk.
fork= 0,1,···, K−1do
xk+1=Cxxk−αkAxuk−Bxdk
x,dk+1
x=dk
x+Bxxk+1;
end for
In this case, we have z⋆
k≡0,y⋆
k≡0. Notice that Ly⋆= 0,Lz⋆= 0. It gives
η2=O 
β2∥Oy∥2∥O−1
y∥2∥Λya∥2∥Λ−1
yb∥2
(1− ∥Γy∥)2+γ2∥Oz∥2∥O−1
z∥2∥Λza∥2∥Λ−1
zb∥2
(1− ∥Γz∥)2!
,
η1=O
η2+α2
1 +(1−θ)2
θ2∥Λ−1
xb∥2∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
(1− ∥Γx∥)2
.
If we take
α≲min(
1,1− ∥Γx∥
∥Ox∥∥O−1x∥∥Λxa∥,1− ∥Γx∥
∥Ox∥∥O−1x∥∥Λxa∥∥Λ−1
xb∥1
2)
andθ= 1,β→0,γ→0, then (45),(53),(56),(40),(58),(65),(82), and (84) hold. Thus all
previous lemmas hold. Then (87) transforms into
1
K+ 1KX
k=0E∥Φ(¯xk)∥2
≲f(¯x0)−inff
α(K+ 1)+1
n 
θ(1−θ) +αθ2
σ2
f,1+(1−θ)2
θ(K+ 1)∥∇f 
¯x0
∥2
+η1α2f(¯x0)−inff
α(K+ 1)+θ
nσ2
f,1
+∥Ox∥2E∥ˆe0
x∥2
n(K+ 1)(1 − ∥Γx∥)
+α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
n(1− ∥Γx∥)2(K+ 1)"
1−θ
θnX
i=1∇fi(¯x0)2#
+1
n
α2θ
θ+1−θ
1− ∥Γx∥∥Ox∥2∥O−1
x∥2∥Λxa∥2n
1− ∥Γx∥
σ2
f,1.
It follows that
1
K+ 1KX
k=0E∥Φ(¯xk)∥2
≲f(¯x0)−inff
α(K+ 1)+ασ2
f,1
n+
α4∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2
(1− ∥Γx∥)2f(¯x0)−inff
α(K+ 1)+1
nσ2
f,1
+∥Ox∥2E∥ˆe0
x∥2
n(K+ 1)(1 − ∥Γx∥)+α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥σ2
f,1
≲f(¯x0)−inff
α(K+ 1)+ασ2
f,1
n+α2∥Ox∥2∥O−1
x∥2∥Λxa∥2
1− ∥Γx∥σ2
f,1
+α2∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
(K+ 1)(1 − ∥Γx∥)+α4∥O∥2
x∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2σ2
f,1
n(1− ∥Γx∥)2.
(98)
63Like (88), we take
C0= 1 +∥Ox∥∥O−1
x∥∥Λxa∥
1− ∥Γx∥+∥Ox∥∥O−1
x∥∥Λxa∥∥Λ−1
xb∥
1− ∥Γx∥1
2
,
α1=s
n
Kσ2
f,1, α 2= 
1− ∥Γx∥
K∥Ox∥2∥O−1x∥2∥Λxa∥2σ2
f,1!1
3
,
α3=1− ∥Γx∥
∥Ox∥2∥O−1x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
01
3
,
α4= 
n(1− ∥Γx∥)2
K∥O∥2x∥O−1x∥2∥Λxa∥2∥Λ−1
xb∥2σ2
f,1!1
5
,
α= Θ
C0+1
α1+1
α2+1
α3+1
α4−1
.
Substituting these values into (98), we get
1
K+ 1KX
k=0E∥Φ(¯xk)∥2≲σf,1√
nK+ 
∥Ox∥2∥O−1
x∥2∥Λxa∥2σ2
f,1
1− ∥Γx∥!1
3
K−2/3+C0
K
+∥Ox∥2∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2ζx
0
(1− ∥Γx∥)1
31
K+ 
∥O∥2
x∥O−1
x∥2∥Λxa∥2∥Λ−1
xb∥2σ2
f,1
n(1− ∥Γx∥)2!1
5
K−4/5.
Like Lemma 18, we get the transient iterating complexity for Algorithm 3 is
(
n3∥Ox∥2∥O−1
x∥2
1− ∥Γx∥2
∥Λxa∥2, n∥Ox∥∥O−1
x∥∥Λ−1
xb∥
1− ∥Γx∥4
3
∥Λxa∥, n)
.
Substituting the value of relevant norms in Table 4, we get the transient iteration complexity for GT,
EXTRA, ED are
O
maxn3
(1−ρ)2,n
(1−ρ)8/3
,On3
(1−ρ)2
,On3
(1−ρ)2
respectively, where ρ:=ρ(Wx). These upper bounds are the same as the state-of-the-art results
shown in Table 1. It indicates that our analysis accurately captures the impacts of updates at each
level on the convergence results.
D Experimental details
In this section, we provide the details of our numerical experiments discussed in Section 4. We also
provide addition experimental results which are not mentioned in the main text due to the space
limitation. For all GT variants, we focus on one typical representative, ATC-GT, in our experiments,
which we denote as GT for brevity. All experiments described in this section were run on an NVIDIA
A100 server.
D.1 Synthetic bilevel optimization
Here, we consider problem (1)whose upper- and lower level loss functions on the i-th agents
(1≤i≤N) are denoted as:
fi(x, y) =EAi,bih
∥Aiy−bi∥2i
,
gi(x, y) =EAi,bih
∥Aiy−x∥2+Cr∥y∥2i
,
640 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(a) Fully connceted, severe heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
0 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(b) 2D Torus, severe heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
0 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(c) Adjusted ring, severe heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
0 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(d) Fully connceted, mild heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
0 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(e) 2D Torus, mild heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
0 1000 2000 3000 4000 5000
number of gradient evaluations103
102
101
100101102||x(i)x*||2
(f) Adjusted ring, mild heterogeneity
D/uni00ADSOBA
SPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRAFigure 4: The estimation error of D-SOBA, SPARKLE -GT, SPARKLE -ED, and SPARKLE -
EXTRA under different networks and data heterogeneity.
where x∈RD, y∈RKandCrdenotes a fixed regularization parameter. For each agent i, we
firstly generate the local solution y∗
i, x∗
iasy∗
i=y∗+ζiandx∗
i=A∗b∗+ξi, where x∗∼ N(0, IK)
is a randomly generated vector, each element of A∗is independently sampled from N(0,9). The
observation (Ai, bi)on agent iis generated in a streaming manner by Ai=A∗+ϕi,bi=x∗
i+ψi,
in which each element of ϕi∈RK×Dandψi∈RDare independently generated by N(0, σ2
g). The
terms ξi∼ N(0, σ2
hIK)andζi∼ N(0, σ2
hID)control the heterogeneity of data distributions across
different agents.
We set D= 20 , K= 10 , σg= 0.001, Cr= 0.001. Then we set σh= 0.5to represent severe
heterogeneity across agents and σh= 0.1for mild heterogeneity. We run D-SOBA, SPARKLE -GT,
SPARKLE -ED, and SPARKLE -EXTRA over Ring, 2D-Torus [ 37], and fully connected networks
withN= 64 agents. The moving-average term θ= 0.1and the step-size at the t-th iteration are
αt=βt=γt= 1/(500 + 0 .01t). The batch size is 10.
Fig. 4 illustrates the averaged estimation errorPN
i=1x(t)
i−x∗2
of the mentioned algorithms with
different communication topology and data heterogeneity. It is observed that SPARKLE with ED,
EXTRA, GT achieve better convergence performances with decentralized communication networks.
Meanwhile, SPARKLE -ED and SPARKLE -EXTRA are more robust to data heterogeneity and the
sparsity of network topology than SPARKLE -GT. All the results are consistent with our theoretical
results.
D.2 Hyper-cleaning on FashionMNIST dataset
Here, we consider a data hyper-clean problem [ 44] on FashionMNIST dataset [ 48]. The FashionM-
NIST dataset consists of 60000 images for training and 10000 images for testing and we randomly
split 50000 training images into a training set and the other 10000 images into a validation set.
The data hyper-cleaning problem aims to train a classifier from a corrupted dataset, in which the label
of each training data is replaced by a random class number with a probability p(i.e. the corruption
rate). It can be considered as a stochastic bilevel problem (1)whose upper- and lower-level loss
functions on the i-th agents ( 1≤i≤n) are formulated as:
fi(x, y) =1D(i)
valX
(ξe,ζe)∈D(i)
valL(ϕ(ξe;y), ζe),
gi(x, y) =1D(i)
trX
(ξe,ζe)∈D(i)
trσ(xe)L(ϕ(ξe;y), ζe) +C∥y∥2,
650.50 0.55 0.60 0.65 0.70
test accuracy050010001500200025003000number of gradient evaluationsSPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SPARKLE/uni00ADED/uni00ADGTSPARKLE/uni00ADEXTRA/uni00ADGT
D/uni00ADSOBA
MA/uni00ADDSBO/uni00ADGT
0.50 0.55 0.60 0.65 0.70
test accuracy05001000150020002500number of gradient evaluationsSPARKLE/uni00ADGT
SPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SPARKLE/uni00ADED/uni00ADGTSPARKLE/uni00ADEXTRA/uni00ADGT
D/uni00ADSOBA
MA/uni00ADDSBO/uni00ADGTFigure 5: Hypergradient evaluation times for required test accuracy in hyper-cleaning problem. (Left:
p= 0.2; Right: p= 0.3)
where ϕdenotes a training model while ydenotes its parameters, Ldenotes the cross-entropy loss
function and σ(x) = (1 + e−x)−1is the sigmoid function. D(i)
trandD(i)
valdenotes the training and
validation set of the i-th agent, respectively. C >0is a fixed regularization parameter.
Data generation and experiment settings. In this experiment, we let ϕbe a two-layer MLP network
with a 300-dim hidden layer and ReLU activation while ydenotes its parameters. For 1≤i≤10,
we sample a probability distribution Pirandomly by Dirichlet distribution with parameters α= 0.1.
The training and validation images with label iare sent to different agents according the probability
distribution Pi. Then D(i)
trandD(i)
valare generated sufficiently heterogeneous [ 32]. We set C= 0.001.
The batch size is set to 50.
Convergence performances with different corruption rates. We set the moving-average term
θk= 0.2and run D-SOBA [ 29], MA-DSBO-GT [ 10], MDBO [ 21]SPARKLE -GT, SPARKLE -ED,
SPARKLE -EXTRA, SPARKLE -ED-GT, and SPARKLE -EXTRA-GT on an Adjusted Ring graph
withn= 10 agents and p= 0.1,0.2,0.3separately. The step-sizes for all the algorithms are set to
αk=βk=γk= 0.03and the term ηin MDBO is set to 0.5. The weight matrix of Adjust Ring
W= [wij]n×nsatisfies:
wij=

a, ifj=i,
1−a
2,if(j−i)%n=±1,
0, else.
Moreover, we run SPARKLE with ED in the lower level and auxiliary variable and gradient tracking
in the upper level (i.e. SPARKLE -ED-GT) as well as SPARKLE with EXTRA in the lower level
and auxiliary variable and gradient tracking in the upper level (i.e. SPARKLE -EXTRA-GT) and
compare their test accuracy with the other four algorithms.
Figure 1 shows that SPARKLE -ED and SPARKLE -EXTRA outperforms in different cases than
SPARKLE -GT. Meanwhile, SPARKLE -EXTRA, SPARKLE -EXTRA-GT achieve similar test
accuracy, as do those for SPARKLE -ED and SPARKLE -ED-GT, which matches our theoretical
results in transient iteration analysis. Figure 5 presents the times of gradient evaluation for different
test accuracies of these algorithms at p= 0.2,0.3, demonstrating similar results.
Influence of network topology. We set the corruption rate p= 0.3, the step sizes αk=βk=γk=
0.02, and the moving-average term θk= 0.2. Then we run SPARKLE-EXTRA and SPARKLE-
EXTRA-GT on a network containing n= 10 nodes with different topologies in the following two
cases:
•Fixed upper, varied lower :xcommunicates through a five-peer graph; y, zcommunicate through
different adjusted rings with ρ= 0.647,0.828,0.924,0.990.
•Fixed lower, varied upper :y, zcommunicate through a five-peer graph; xcommunicates through
different adjusted rings with ρ= 0.647,0.828,0.924,0.990.
660 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(a)SPARKLE-EXTRA; Fixed topo x; Varied topo of y,z
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(b)SPARKLE-EXTRA; Fixed topo y,z; Varied topo of x
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(c)SPARKLE-EXTRA-GT; Fixed topo x; Varied topo of y,z
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
0 500 1000 1500 2000 2500 3000 3500
number of gradient evaluations0.00.10.20.30.40.50.60.70.8test accuracy(d)SPARKLE-EXTRA-GT; Fixed topo y,z; Varied topo of x
2200 2400 2600 2800 3000 3200 34000.650.700.750.80
=0.647
=0.828
=0.924
=0.990
Figure 6: The average test accuracy of SPARKLE-EXTRA and SPARKLE-EXTRA-GT on hyper-
cleaning with different communicating strategy of x, y, z .
Table 5: Mean and standard deviation of the average test accuracy of last 40 iterations during 10 trials
with different moving-average terms
Algorithm θ= 0.05 θ= 0.2 θ= 0.3
SPARKLE -GT 0.7080±0.0215 0.7045±0.0126 0 .7064±0.0113
SPARKLE -ED 0.7096±0.0074 0.7113±0.0047 0.7110±0.0081
SPARKLE -EXTRA 0.7190±0.0103 0.7277±0.0090 0.7243±0.0028
SPARKLE -ED-GT 0.7064±0.0063 0.7178±0.0037 0.7162±0.0041
SPARKLE -EXTRA-GT 0.7198±0.0051 0.7262±0.0058 0.7247±0.0048
The weight matrix of five-peer graph W= [wij]n×nsatisfies:
wij=0.2,if(j−i)%n= 0,±1,±2,
0, else.
Figure 6 shows the average test accuracy of both SPARKLE -EXTRA and SPARKLE -EXTRA-GT
over 10 trials. It indicates that the test accuracy decays with increasing spectral gap of topologies
related to y, zwhile the topology of xis fixed during the whole iterations. However, such convergence
gap becomes milder when the topologies of y, zare fixed and that of xvaries. This phenomenon
supports our theoretical findings, which suggest that the transient iteration complexity is more
sensitive to the network topologies of y, zthan to that of x.
Influence of moving-average iteration on convergence. Moreover, for θt= 0.05,0.2,0.3, we
runSPARKLE -GT, SPARKLE -ED, SPARKLE -EXTRA, SPARKLE -ED-GT, and SPARKLE -
EXTRA-GT on an Adjusted Ring graph with n= 10 agents, αk=βk=γk= 0.03andp= 0.3
for 3000 iterations. We obtain the average test accuracy of the last 40 iterations over 10 trials, and
present the mean and standard deviation during the different trials in Table 5. We can observe that
most algorithms achieve the highest test accuracy when θ= 0.2, which may prove that a suitable θ
can benefit the test accuracy in hyper-cleaning problems.
670 250 500 750 1000 1250 1500 1750 2000
sample size0.00.51.01.52.02.53.03.54.0test lossSPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SLDBOMDBO
Single/uni00ADlevel
0 250 500 750 1000 1250 1500 1750 2000
sample size0.51.01.52.02.53.0test lossSPARKLE/uni00ADED
SPARKLE/uni00ADEXTRA
SLDBOMDBO
Single/uni00ADlevelFigure 7: The test loss against samples generated by one agent of different algorithms in the policy
evaluation. (Left: n= 20 , Right: n= 10 .)
Table 6: The average training loss of the last 500 iterations for 10 independent trials in the distributed
policy evaluation.
Algorithm N= 10 N= 20
SPARKLE -ED 0.2781±1.09×10−30.3198±3.21×10−3
SPARKLE -EXTRA 0.2743±0.88×10−30.3207±2.94×10−3
MDBO 1.0408±4.51×10−31.3293±8.38×10−3
SLDBO 0.4132±1.18×10−30.8374±2.47×10−3
Single-level ED 0.2948±0.92×10−30.3164±3.12×10−3
D.3 Distributed policy evaluation in reinforcement learning
Following the result of [ 52], we consider a multi-agent MDP problem in reinforcement learning on a
distributed setting with nagents. Denote Sas the state space. Suppose that the value function in each
states∈ S is a linear function V(s) =ϕ⊤
sx, where ϕs∈Rmis a feature and x∈Rmis a parameter.
To obtain the optimal solution x∗, we consider the following Bellman minimization problem:
min
x∈RmF(x) =1
nnX
i=1"
1
2|S|X
s∈S 
ϕ⊤
sx−Es′
ri(s, s′) +γϕ⊤
s′xs2#
where ri(s, s′)denotes the reward incurred from transition stos′on the i-th agent, γ∈(0,1)denotes
the discount factor. The expectation is taken over all random transitions from state stos′. It can be
viewed as a bilevel optimization problem with the following upper- and lower-level loss:
fi(x, y) =1
2|S|X
s∈S(ϕ⊤
sx−ys)2,
gi(x, y) =X
s∈S 
ys−Es′
ri(s, s′) +γϕ⊤
s′xs2,
where y= (y1,···, y|S|)⊤∈R|S|. In our experiment, we set the number of states |S|= 200 and
m= 10 . For each s∈ S, we generate its feature ϕs∼U[0,1]m. The non-negative transition
probabilities are generated randomly and standardized to satisfyP
s′∈Sps,s′= 1. The mean reward
¯ri(s, s′)are independently generated from the uniform distribution U[0,1]. In each iteration, the
stochastic reward ri(s, s′)∼ N(¯ri(s, s′),0.022).
Forn= 10,20, we run SPARKLE -ED and SPARKLE -EXTRA as well as existing decentralized
SBO algorithms MDBO [ 21] and SLDBO [ 16] (here we use the stochastic gradient instead of
deterministic gradient) over a Ring graph. For MDBO, the number of Hessian-inverse estimation
iterations is set to 5. The step sizes are 0.03 for all methods. Figure 3 illustrates the upper-level loss
against samples generated by one agent for 10 independent trials. Table 6 shows the average training
loss of the last 500 iterations for 10 independent trials of the four decentralized SBO algorithms as
well as single-level ED [ 56] (For bilevel algorithms, training loss means the upper-level loss here).
680 2000 4000 6000 8000 10000 12000 14000
time(s)0.00.10.20.30.40.50.60.7training/uni00A0accuracy
SPARKLE/uni00ADED
D/uni00ADSOBA
Decentralized/uni00A0MAML
0 2000 4000 6000 8000 10000 12000 14000
time(s)0.00.10.20.30.40.50.60.7test/uni00A0accuracySPARKLE/uni00ADED
D/uni00ADSOBA
Decentralized/uni00A0MAMLFigure 8: The accuracy on training and testing set of different algorithms for the meta-learning
problem.
Both Figure 3 and Table 6 demonstrate that SPARKLE -ED and SPARKLE -EXTRA converge faster
than other methods.
Finally, we create a fixed "test set" with 10000 sample generated from S. Figure 7 shows the
loss on the test set of SPARKLE-ED, SPARKLE-EXTRA, SLDBO, MDBO and single-level ED
algorithm, demonstrating the superior performance of SPARKLE compared to other decentralized
SBO algorithms.
D.4 Decentralized meta-learning
We consider a meta-learning problem as described in [ 18]. There are Rtasks{Ts, s= 1,···, R}.
Each task Tshas its own loss function L(x, ys, ξ), where ξsrepresents a stochastic sample drawn from
the data distribution Ds,ysdenotes the task-specific parameters and xdenotes the global parameters
shared by all the tasks. In meta-learning problem, we aim to find the parameters (x∗, y∗
1,···, y∗
R)
that minimizes the loss function across all Rtasks, i.e.,
min
x,y1,···,yRl(x, y1,···, yR) =1
RRX
s=1Eξ∼Ds[L(x, ys, ξ)]. (102)
The problem (102) can be formulated as a decentralized SBO problem with heterogeneous data
distributions across Nnodes. For i= 1,2,···, N, letDtrain
s,iandDval
s,idenote the training and
validation datasets for the s-th task Tsreceived by node irespectively. We can then address the
meta-learning problem by minimizing (1), with the upper- and lower-level loss functions defined as:
fi(x, y) =1
RRX
s=1Eξ∼Dval
s,i[L(x, ys, ξ)],
gi(x, y) =1
RRX
s=1h
Eξ∼Dtrain
s,i[L(x, ys, ξ)] +R(ys)i
,
where Ldenotes the cross-entropy loss and R(ys) =Cr∥ys∥2is a strongly convex regularization
function.
In this experiment, we compare SPARKLE-ED with D-SOBA [ 29] and MAML [ 18] in a decentralized
communication setting over a 5-way 5-shot task across a network of N= 8 nodes connected by
Ring graph. The dataset used is miniImageNet [ 47], derived from ImageNet [ 42], which comprises
100 classes, each containing 600 images of size 84×84. We set R= 2000 and partition these
classes into 64 for training, 16 for validation, and 20 for testing. For the training and validation
classes, the data is split according to a Dirichlet distribution with parameter α= 0.1[32]. We utilize
a four-layer CNN with four convolution blocks, where each block sequentially consists of a 3×3
convolution with 32 filters, batch normalizationm, ReLU activation, and 2×2max pooling. The batch
size is 32 , and Cr= 0.001. The parameters of the last linear layer are designated as task-specific,
while the other parameters are shared globally. For SPARKLE and D-SOBA, the step-sizes are
69β=γ= 0.1andα= 0.01. For MAML, the inner step-size is 0.1 and the outer step-size is 0.001,
and the number of inner-loop steps as 3. For all algorithms, the task number is set to 32. And we only
repeat the experiment only once due to the time limitation. Figure 8 shows the average accuracy on
the training dataset for all nodes, as well as the test accuracy of the three algorithms. We observe
that SPARKLE-ED outperforms other algorithms, demonstrating the efficiency of SPARKLE in
decentralized meta-learning problems.
70NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Refer to Abstract and Introduction.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Refer to Section Conclusions.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
71Justification: Refer to Section Assumptions for our assumptions, and Appendix for detailed
proof.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Refer to Appendix.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
72Answer: [No]
Justification: We may consider making data and code openly accessible when it is deemed
necessary.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/
guides/CodeSubmissionPolicy) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run
to reproduce the results. See the NeurIPS code and data submission guidelines (https:
//nips.cc/public/guides/CodeSubmissionPolicy) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Refer to Appendix.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We show error bars in experiments where we consider them essential.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
73•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Refer to Appendix.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?
Answer: [Yes]
Justification:Our research conforms, in every respect, with the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: There is no societal impact of our work.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
74•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: There is no such risk in the paper.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We comply with the licenses of existing assets used in the paper and provide
necessary references.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has curated
licenses for some datasets. Their licensing guide can help determine the license of a
dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
75•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: The paper does not release new assets.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: The paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
76