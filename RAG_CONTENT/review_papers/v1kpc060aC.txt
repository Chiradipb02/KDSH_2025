Weight for Robustness: A Comprehensive Approach
towards Optimal Fault-Tolerant Asynchronous ML
Tehila Dahan
Department of Electrical Engineering
Technion
Haifa, Israel
t.dahan@campus.technion.ac.ilKfir Y. Levy
Department of Electrical Engineering
Technion
Haifa, Israel
kfirylevy@technion.ac.il
Abstract
We address the challenges of Byzantine-robust training in asynchronous distributed
machine learning systems, aiming to enhance efficiency amid massive paralleliza-
tion and heterogeneous computing resources. Asynchronous systems, marked by
independently operating workers and intermittent updates, uniquely struggle with
maintaining integrity against Byzantine failures, which encompass malicious or
erroneous actions that disrupt learning. The inherent delays in such settings not
only introduce additional bias to the system but also obscure the disruptions caused
by Byzantine faults. To tackle these issues, we adapt the Byzantine framework
to asynchronous dynamics by introducing a novel weighted robust aggregation
framework. This allows for the extension of robust aggregators and a recent meta-
aggregator to their weighted versions, mitigating the effects of delayed updates. By
further incorporating a recent variance-reduction technique, we achieve an optimal
convergence rate for the first time in an asynchronous Byzantine environment.
Our methodology is rigorously validated through empirical and theoretical anal-
ysis, demonstrating its effectiveness in enhancing fault tolerance and optimizing
performance in asynchronous ML systems.
1 Introduction
In recent years, there has been significant growth in the development of large-scale machine learning
(ML) models and the volume of data they require [Zhao et al., 2023]. To efficiently accelerate large-
scale training processes, Distributed ML has emerged as a crucial approach that can be categorized
into synchronous and asynchronous paradigms. In synchronous learning, workers update the model
simultaneously using the average of their outputs, similar to the Minibatch approach [Dekel et al.,
2012]. Asynchronous learning, however, allows workers to operate independently, sending updates
as they are ready without waiting for others [Arjevani et al., 2020]. This prevents slow workers from
hindering the process, making it especially practical as the number of workers increases.
A major challenge of distributed ML is fault-tolerance, and Byzantine ML [Alistarh et al., 2018,
Lamport et al., 2019, Guerraoui et al., 2023] is a powerful framework for tackling this aspect.
Byzantine ML captures a broad spectrum of failures within distributed environments, including
random malfunctions or even malicious workers aiming to disrupt the training process. This makes
Byzantine ML widely applicable across various domains to ensure robust performance.
Addressing the Byzantine problem in synchronous distributed learning is well-established [Karim-
ireddy et al., 2020, 2021, Allouah et al., 2023, Farhadkhani et al., 2022, Alistarh et al., 2018, Dahan
and Levy, 2024]. Two primary ingredients were found to be crucial towards tackling Byzantine ML
in synchronous settings: (i)Robust Aggregators [Yin et al., 2018, Blanchard et al., 2017, Chen et al.,
2017]: such aggregators combine the gradient estimates sent by the workers to a single estimate
38th Conference on Neural Information Processing Systems (NeurIPS 2024).while filtering out the outliers which may hinder the training process. While the use of robust
aggregators is crucial, it was found to be insufficient, and an additional ingredient of (ii)learning
from history was shown to be vital in mitigating Byzantine faults [Karimireddy et al., 2021]. And, the
performance of robust aggregators was systematically explored within a powerful generic framework
[Karimireddy et al., 2020, 2021, Allouah et al., 2023, Farhadkhani et al., 2022, Dahan and Levy,
2024]. Moreover, due to the diversity of Byzantine scenarios [Xie et al., 2020a, Allen-Zhu et al.,
2020, Baruch et al., 2019], it was found that relying on a single aggregator is insufficient, making the
variety of robust aggregators essential. Unfortunately, many existing aggregators have sub-optimal
performance. This drawback was elegantly resolved by the design of meta-aggregators [Karimireddy
et al., 2020, Allouah et al., 2023, Dahan and Levy, 2024], that enable to boost the performance
of baseline aggregators. Unfortunately, in the asynchronous case, the use of robust aggregators is
not straightforward, as updates are typically applied individually per-worker, rather than averaging
outputs from all workers at once [Arjevani et al., 2020].
Despite its advantages, asynchronous distributed learning presents unique challenges, particularly
when dealing with Byzantine faults. The delays inherent in asynchronous settings introduce additional
bias to the system and obscure the disruptions caused by Byzantine faults. In fact, in contrast to
the synchronous Byzantine setting, all existing approaches towards the asynchronous Byzantine
case do not ensure a generalization error (excess loss) that diminishes with the number of honest
data-samples and updates. This applies to works for both convex [Fang et al., 2022] as well as
non-convex scenarios [Xie et al., 2020b, Yang and Li, 2023]; as well as to works that further assume
the availability of a trusted dataset possessed by the central-server [Xie et al., 2020b, Fang et al.,
2022]. Furthermore, the performance guarantees of all existing approaches towards that setting
include an explicit dependence on the dimension of the problem — a drawback that does not exist for
SOTA synchronous Byzantine approaches.
Contributions. We explore the asynchronous Byzantine setting under the fundamental framework
of Stochastic Convex Optimization (SCO) [Hazan et al., 2016]. Our work is the first to achieve
a convergence rate that diminishes with the number of honest data samples and updates and does
not explicitly depend on the problem’s dimension. In the absence of Byzantine workers, our rate
matches the optimal performance of Byzantine-free asynchronous settings. This stands in contrast to
previous efforts on Byzantine, which did not attain diminishing rates or dimensionality independence,
even without Byzantine workers. We also show the effectiveness of our approaches in practice. Our
contributions:
•We quantify the difficulty in asynchronous scenarios by considering the number of Byzantine
updates , which is more natural than the standard measure of number of Byzantine workers .
•We identify the need to utilize weighted aggregators rather than standard ones in favor of asyn-
chronous Byzantine problems. Towards doing so, we extend the robust aggregation framework to
allow and include weights and develop appropriate (weighted) rules and a meta-aggregator.
•Achieving Optimal Convergence : We incorporate our weighted robust framework with a recent
double momentum mechanism, leveraging its unique features to achieve an optimal convergence
rate for the first time in asynchronous Byzantine ML.
Related Work. A long line of studies has explored the synchronous Byzantine setting (see e.g., Al-
istarh et al. [2018], Karimireddy et al. [2020, 2021], Allouah et al. [2023], Farhadkhani et al. [2022],
Allen-Zhu et al. [2020], El Mhamdi et al. [2021], Dahan and Levy [2024]). Alistarh et al. [2018],
Karimireddy et al. [2021] demonstrated that historical information is crucial for optimal performance
in Byzantine scenarios; and Karimireddy et al. [2021] introduced the idea of combining generic
aggregation rules, together with standard momentum with a parameter of 1/√
Tto effectively incor-
porates√
Titerations of historical gradients. Additionally, Dahan and Levy [2024] showed that a
double momentum approach is effective by taking a momentum parameter of 1/T, capturing the
entire gradient history.
Robust aggregators such as Coordinate-wise Trimmed Mean (CWTM) [Yin et al., 2018], Krum
[Blanchard et al., 2017], Geometric Median (GM) [Chen et al., 2017], CWMed [Yin et al., 2018],
and Minimum Diameter Averaging [Guerraoui et al., 2018] have also proven to be highly beneficial
in synchronous settings and have been evaluated within robust frameworks [Allouah et al., 2023,
Karimireddy et al., 2020, Farhadkhani et al., 2022, Dahan and Levy, 2024]. However, not all
robust aggregators achieve optimal performance, leading to the development of meta-aggregators
2[Karimireddy et al., 2020, Allouah et al., 2023, Dahan and Levy, 2024] to enhance their effectiveness.
While standard aggregation works well in synchronous settings, where outputs are averaged across
all workers, it is less suitable for asynchronous settings, where updates are processed individually as
they arrive [Arjevani et al., 2020].
To adapt these approaches to asynchronous settings, Yang and Li [2023] devised BASGDm, an
extension of BASGD [Yang and Li, 2021], that groups worker momentums into buckets that are
then aggregated using a robust aggregator. Other methods, like Zeno++ [Xie et al., 2020b] and
AFLGuard [Fang et al., 2022], rely on a trusted dataset on the central server, which hinders their
practicality. Kardam [Damaskinos et al., 2018] uses the Lipschitzness of gradients to filter out outliers.
Unfortunately, none of these approaches ensure a generalization error (excess loss) that diminishes
with the number of honest data-samples and updates, and suffers from an explicit dependence on the
problem’s dimension. And this applies even in the absence of Byzantine faults.
Asynchronous Byzantine ML faces unique challenges as inherent delays add bias that obscures
Byzantine disruptions. To mitigate this delay-bias in asynchronous, non-Byzantine scenarios, Cohen
et al. [2021], Aviv et al. [2021] propose methods to keep model weights relatively close during
iterations. Other approaches [Stich and Karimireddy, 2019, Arjevani et al., 2020, Mishchenko et al.,
2022] suggest adjusting the step size proportionally to the delay. These strategies have proven useful
in reducing the negative impact of delays, and achieve optimal performance.
Our work extends several concepts from Dahan and Levy [2024] to the asynchronous scenario.
We devise a novel generalization of their Centered Trimmed Meta Aggregator (CTMA) towards
weighted meta-aggregation, making it amenable to asynchronous scenarios. In the spirit of Dahan
and Levy [2024], we also adopt a recent variance reduction technique called µ2-SGD [Levy, 2023].
Nevertheless, while Dahan and Levy [2024] used this technique in a straightforward manner, we
found it crucial to appropriately incorporate individual per-worker weights to overcome the challenge
of asynchronicity in Byzantine ML.
2 Setting
Our discussion focuses on the minimization of a smooth convex objective f:K →R:
f(x) :=Ez∼D[f(x;z)],
where K ⊆Rdis a compact convex set and Ddenotes an unknown distribution from which we can
draw i.i.d samples {zt∼ D} t. Our work considers first-order methods that iteratively utilize gradient
information to approach an optimal point. Such methods output a solution xT, which is evaluated by
the expected excess loss:
ExcessLoss :=E[f(xT)−f(x∗)],
where x∗is a solution that minimizes foverKandxT∈ K approximates this optimal solution.
Asynchronous Training. We explore these methods within a distributed environment involving
multiple workers. Our discussion focuses on a centralized distributed framework characterized by a
central Parameter Server ( PS) that may communicate with mworkers. Each of these workers may
draw i.i.d. samples z∼ D; and based on these samples, compute unbiased gradient estimate g∈Rd
at a point x∈ K. Concretely, a worker may compute g:=∇f(x;z); implying that E[g|x] =∇f(x).
Specifically, our main focus is on Asynchronous systems, where the PSdoes not wait to receive the
stochastic gradient computations from all machines; instead, it updates its model whenever a worker
completes a (stochastic) gradient computation. That worker then proceeds to compute a gradient
estimate for the updated model, while the other workers continue to compute gradients based on
‘stale’ models. This staleness leads to the use of staled (and therefore biased) gradient estimates,
which is a major challenge in designing and analyzing asynchronous training methods.
Asynchronous Byzantine Framework. We assume that an unknown subset of the mworkers are
Byzantine , implying that these workers may transmit arbitrary or malicious information during the
training process, and these "Byzantine" workers may even collaborate to disrupt the training. We
assume that the fraction of updates that arrive from Byzantine workers during the asynchronous
training process is bounded and strictly smaller than 1/2and denote this fraction by λ.
Remark 2.1 (Fraction of Byzantine Updates vs. Byzantine Workers) .In both synchronous and
asynchronous settings, it is common to consider a bound on the fraction of Byzantine workers (up
3to1/2) [Allouah et al., 2023, Farhadkhani et al., 2022, Karimireddy et al., 2020, 2021, Yang and Li,
2023, 2021, Damaskinos et al., 2018]. In synchronous scenarios this is meaningful since the server
equally treats the information from all workers; which is done by equally averaging gradients of all
workers in each iteration in a mini-batch fashion [Dekel et al., 2012]. Conversely, in asynchronous
scenarios, faster workers contribute to more updates than slower workers, leading to an unequal
influence on the training process. In such scenarios, the fraction of Byzantine workers is less relevant;
and it is therefore much more natural to consider the fraction of Byzantine updates . Interestingly,
our definition aligns with the standard one (for the synchronous case), which considers the number of
Byzantine workers.
Notation. For each worker i∈[m]and iteration t,s(i)
trepresents the total number of updates by
worker iup to t, and τ(i)
tis the delay compared to the current model. t(i)is the last update before
t, making τ(i)
tthe time since the second last update (Figure 1). τtdenotes the delay for the worker
arriving at iteration t, i.e., if worker jarrives at iteration tthenτt=τ(j)
t.
t t(i) t−τ(i)
t
τ(i)
t
Figure 1: Illustration of the delay interval τ(i)
tfor worker iat iteration t, marking t(current iteration),
t(i)(most recent update from worker i), and t−τ(i)
t(previous update from worker i).
For a given time (iteration) t, lett(i)be the last iteration when worker imade an update. We denote
d(i)
t:=dt(i),g(i)
t:=gt(i),˜g(i)
t:=˜gt(i), and x(i)
t=xt(i), where the latter are individual vectors
that we will later define for any worker i. Throughout, ∥·∥represents the L2-norm. For any natural
N,[N] ={1, . . . , N }. We use the compressed sum notation α1:t=Pt
k=1αk. For every x∈Rd,
the orthogonal projection of xonto a set Kis denoted by ΠK(x) = arg min y∈K∥y−x∥2. We
denote BandGas the subsets of Byzantine workers and honest workers, respectively, such that
|m|=|G|+|B|.
Assumptions. We use the following conventional assumptions:
Bounded Diameter : we assume there exists D > 0such that max
x,y∈K∥x−y∥ ≤D. (1)
Bounded Variance : there exists σ >0such that ∀x∈ K,z∈Support {D},
E∥∇f(x;z)− ∇f(x)∥2≤σ2. (2)
Expectation over Smooth Functions : we assume that f(·)is an expectation of smooth functions,
i.e.∀x,y∈ K,z∈Support {D} there exist L >0such that,
∥∇f(x;z)− ∇f(y;z)∥ ≤L∥x−y∥, (3)
The above assumption also implies that the expected loss f(·)isLsmooth.
Bounded Smoothness Variance [Levy, 2023]: in Appendix A we show that Eq. (3)implies that,
∀x,y∈ K,z∈Support {D} there exists σ2
L∈[0, L2]such,
E∥(∇f(x;z)− ∇f(x))−(∇f(y;z)− ∇f(y))∥2≤σ2
L∥x−y∥2(4)
Bounded Delay :∃K > 0such that for each worker i∈[m],τ(i)
min≤τ(i)
t≤Kτ(i)
min (5)
where τ(i)
minis the minimum delay of worker i.Kbounds the variance of the delay for each worker.
Bounded Byzantine Iterations : there exists 0≤λ < 1/2such that t∈[T]:tB≤λt (6)
where tBis the total number of iterations made by Byzantine workers up to iteration t.
Sample-Arrival Independence : we assume that the delays in the system (i.e. τ(i)
t’s) are indepen-
dent of the data samples. This is a standard assumption in asynchronous training scenarios, see
e.g., Arjevani et al. [2020], Aviv et al. [2021].
43 Weighted Robust Aggregation Rules
As we have mentioned, robust aggregation rules have played a major role in designing fault-tolerant
ML training methods for synchronous settings (see, e.g., Allouah et al. [2023], Karimireddy et al.
[2020, 2021], Dahan and Levy [2024]). These existing aggregation rules treat inputs from all workers
equally, which makes sense in synchronous cases where all workers contribute the same number of
updates and data samples. Conversely, this symmetry breaks down in asynchronous settings, where
faster (honest) workers contribute more updates and samples compared to slower workers.
Inspired by this asymmetry, we have identified the need to define a notion of weighted robust
aggregators that generalizes the standard definition of robust aggregators. In this section, we provide
such a definition, derive weighted variants of standard aggregators that satisfy our new definition, and
design a generic meta-approach to derive optimal weighted aggregation rules. Later, in Section 4, we
demonstrate the benefits of using weighted robust aggregators as a crucial building block in designing
asynchronous fault-tolerant training methods (see Alg. 2).
3.1 Robust Weighted Aggregation Framework
Below, we generalize the definition introduced by Dahan and Levy [2024], Karimireddy et al. [2020,
2021] to allow and associate weights to the inputs of the robust aggregation rule, therefore allowing
the aggregator to unequally treat its inputs.
Definition 3.1. (cλ, λ)-weighted robust . Assume we have mrandom vectors x1, . . . , xm∈Rd
and corresponding weights s1, . . . , s m>0. Also assume we have an "honest" subset G ⊆ [m],
implying {xi}∈ Gare independent of each other. Finally, assume that there exists λ∈[0,1/2)such
thatP
i∈Gsi≥(1−λ)s1:m. Moreover, assume that for any i∈ Gthere exist ρi≥0such that,
E∥xi−¯xG∥2≤ρ2
i,∀i∈ G.
Then an aggregation rule Aωis called (cλ, λ)-weighted robust if for any such mrandom vectors and
weights and λ≥0, it outputs ˆx← A ω(x1, . . . , xm;s1, . . . , s m)such that,
E∥ˆx−¯xG∥ ≤cλρ2
for some cλ≥0. Above, ¯xG:=1P
i∈GsiP
i∈Gsixi,ρ2:=1P
i∈GsiP
i∈Gsiρ2
i, and the expectation
is w.r.t. {xi}m
i=1and (possible) randomization in the Aω.
Here, λrepresents the fraction of the sum of the non-honest vectors’ weights, unlike the unweighted
definition (in synchronous cases) [Karimireddy et al., 2020, 2021, Allouah et al., 2023, Farhadkhani
et al., 2022] where it indicates the fraction of non-honest vectors. These definitions align when all
weights are equal [Dahan and Levy, 2024]. Similarly to the unweighted version, the optimal cλ
should be cλ≤O(λ)[Dahan and Levy, 2024].
Remark 3.1. Note that our definition is generic and may be applied in both convex and non-convex
scenarios. Moreover, it is natural to consider such weighted aggregators beyond asynchronous
settings. For example, in synchronous settings where workers have varying batch sizes, weighted
aggregation based on batch sizes may be more effective than uniform aggregation.
Next, we present two weighted variants of standard (non-weighted) aggregators that satisfy the above
definition (we defer the proof into Appendix C). Table 1 summarizes their cλvalues.
3.2 Weighted Variant of Geometric Median and Coordinate-Wise
Weighted Geometric Median (WeightedGM) The Weighted Geometric Median (WeightedGM)
minimizes the weighted sum of Euclidean distances to a set of points. Formally, for points {xi}m
i=1
and corresponding weights {si}m
i=1, WeightedGM ∈arg min y∈RdP
i∈[m]si∥y−xi∥.
Weighted Coordinate-Wise Median (WeightedCWMed) The Weighted Coordinate-Wise Median
(WeightedCWMed) aggregates multi-dimensional data by finding the weighted median of each
coordinate separately. Thus, for given coordinate if {xi}m
i=1are sorted and weights {si}m
i=1, the
weighted median xj∗is the element where: j∗= arg min j∈[m]nP
i∈[j]si>1
2P
i∈[m]sio
.If
Pj
i=1si=1
2Pm
i=1sifor some j, then: WeightedMedian =xj+xj+1
2.
5Aggregation ω-GM ω-CWMed ω-GM + ω-CTMA ω-CWMed + ω-CTMA
cλ
1 +λ
1−2λ2
1 +λ
1−2λ2
λ
1 +λ
1−2λ2
λ
1 +λ
1−2λ2
Table 1: Summary of weighted aggregation rules and their respective cλvalues.
Algorithm 1 Weighted Centered Trimmed Meta Aggregator ( ω-CTMA)
1:Input: Set of vectors {xi}m
i=1, weights {si}m
i=1, threshold parameter λ∈[0,1/2),
2: (cλ, λ)-weighted robust aggregated vector x0← A ω({xi}m
i=1;{si}m
i=1).
3:Sort the sequence {∥xi−x0∥}m
i=1in non-decreasing order, and then reindex {xi}i∈[m]and their
corresponding weights {si}i∈[m]according to this new order.
4:Define S←set of indices corresponding to the first j∗elements in the sorted sequence, where
j∗is the smallest j∈[m]for whichP
i∈[j]si≥(1−λ)P
i∈[m]si.
5:Setsm+1←(1−λ)P
i∈[m]si−P
i∈[j∗−1]si,xm+1←xj∗,S←(S\{j∗})∪ {m+ 1}.
6:Compute the weighted sum: ˆx←(1/P
i∈Ssi)P
i∈Ssixi.
7:Output: ˆx
3.3 Weighted Centered Trimmed Meta Aggregator ( ω-CTMA)
Table 1 illustrates that ω-GM and ω-CWMed fail to achieve the desired optimal cλ=O(λ); typically
forλ≤1/3, their cλremains ≤O(1). To address this suboptimality, we propose ω-CTMA, a
weighted extension of the Centered Trimmed Meta Aggregator (CTMA) [Dahan and Levy, 2024].
This extension enables us to achieve the optimal bound cλ≤O(λ)forλ≤1/3(see Table 1).
Theω-CTMA algorithm (Algorithm 1) operates on a set of vectors along with their associated
weights, a threshold λ∈[0,1/2), and a (cλ, λ)-weighted robust aggregator. It sorts the distances
between each vector and the weighted robust aggregator, trims the set based on the threshold to satisfyP
i∈Ssi= (1−λ)s1:m, and calculates a weighted average of the vectors, excluding outliers based
on their proximity to an anchor point—the weighted robust aggregator.
Lemma 3.1. Under the assumptions outlined in Definition 3.1, if ω-CTMA receives a (cλ, λ)-
weighted robust aggregator, Aω; then the output of ω-CTMA, ˆx, is(60λ(1 +cλ), λ)-robust.
For the complete analysis, please refer to Appendix C.2. Like CTMA [Dahan and Levy, 2024],
ω-CTMA is highly efficient, with a computational complexity of O(dm+mlogm), similar to ω-GM,
ω-CWMed, and weighted averaging, differing by at most an additional logarithmic factor.
4 Asynchronous Robust Training
We leverage the µ2-SGD algorithm [Levy, 2023], a double momentum mechanism that enhances
variance reduction. By seamlessly incorporating our weighted robust framework as a black box into
theµ2-SGD, we derive an optimal asynchronous Byzantine convergence rate.
µ2-SGD: Theµ2-SGD is a variant of standard SGD, incorporating several key modifications in its
update rule:
wt+1= ΠK(wt−ηαtdt),xt+1=1
α1:t+1X
k∈[t+1]αkwk;w1=x1∈ K,∀t >1.
Here,{αt>0}tare importance weights that emphasize different update steps, with αt∝tto place
more weight on recent updates. The sequence {xt}trepresents weighted averages of the iterates
{wt}t, and dtis an estimate of the gradient at the average point, ∇f(xt), differing from standard
SGD, which estimates gradients at the iterates, ∇f(wt).
This approach relates to Anytime-GD [Cutkosky, 2019], which is strongly connected to momentum
and acceleration concepts [Cutkosky, 2019, Kavis et al., 2019]. While the stochastic version of
Anytime-GD typically uses the estimate ∇f(xt;zt),µ2-SGD employs a variance reduction mech-
anism to produce a corrected momentum estimate dt[Cutkosky and Orabona, 2019]. Specifically,
d1=∇f(x1;z1), and for t >2:
dt=∇f(xt;zt) + (1 −βt)(dt−1− ∇f(xt−1;zt)).
6Algorithm 2 Asynchronous Robust µ2-SGD
1:Input: learning rate ηt>0, starting point x1∈ K, number of steps T, importance weights
{αt}t, momentum correction weights {βt}t,(cλ, λ)-robust weighted aggregation function Aω.
2:Initialize: ∀i∈[m], sets(i)
0= 0. Setw1=x1. Each honest worker i∈ Gdraws z(i)∼ D and
setd(i)
1=∇f(x1;z(i)).
3:fort= 1toTdo ▷Server update
4: Receive dt−τtfrom worker i∈[m]and update:
5: d(i)
t=dt−τt,s(i)
t=s(i)
t−1+ 1;∀j̸=i: sets(j)
t=s(j)
t−1, and for t >1:d(j)
t=d(j)
t−1;
6: Update server model:
7: wt+1= ΠK
wt−ηtαtAω({d(j)
t, s(j)
t}m
j=1)
, & xt+1=1Pt+1
k=1αkPt+1
k=1αkwk
8: Send xtto worker i. Ifiis an honest worker, it performs the following update:
9: Worker idraws zt∼ D, computes gt=∇f(xt;zt), &˜gt−τt=∇f(xt−τt;zt),
10: and updates: dt=gt+ (1−βt)(dt−τt−˜gt−τt) ▷Worker update
11:end for
12:Output: xT
Here, βt∈[0,1]arecorrected momentum weights. It can be shown by induction that E[dt] =
E[∇f(xt)]; however, in general, E[dt|xt]̸=∇f(xt), unlike standard SGD estimators. Nevertheless,
[Levy, 2023] demonstrates that choosing corrected momentum weights βt:= 1/tresults in significant
error reduction, with E∥εt∥2:=E∥dt−∇f(xt)∥2≤O(˜σ2/t)at step t, where ˜σ2≤O(σ2+D2σ2
L).
This indicates that variance decreases with t, contrasting with standard SGD where the variance
E∥εSGD
t∥2:=E∥gt− ∇f(xt)∥2remains uniformly bounded.
4.1 Asynchronous Robust µ2-SGD
Building upon these, we integrate the µ2-SGD with a (cλ, λ)-weighted robust aggregator Aω, as
described in Alg. 2. At each iteration t∈[T], the global PSreceives an output from a certain
worker and aggregates all workers’ recent updatesn
d(i)
tom
i=1by employing weights accordingly to
the number of updates of each workern
s(i)
tom
i=1. An honest worker iarriving at iteration treturns
its corrected momentum d(i)
tto thePS, computed as:
d(i)
t=dt−τt=gt−τt+ (1−βt−τt)(dt−τt−τt−τt−˜gt−τt−τt−τt),
where gt:=∇f(xt;zt), and ˜gt−τt:=∇f(xt−τt;zt). Afterwards, the PSperforms the AnyTime
update step as follows:
wt+1= ΠK
wt−ηαtAω({d(i)
t, s(i)
t}m
i=1)
,xt+1=1
α1:t+1X
k∈[t+1]αkwk.
In the spirit of Levy [2023], Dahan and Levy [2024], we suggest employing βt:= 1/st, which
effectively considers the entire individual gradient’s history of each worker; this translates to a
stochastic error bound of ∥ε(i)
t∥ ≤O(˜σ/st)for an honest worker iarriving at iteration t. To achieve
an error corresponding to the total number of honest iterations tG, specifically ∥εt∥ ≤O(˜σ/tG), as
in the non-distributed setting [Levy, 2023], a weighted collective error across all honest workers
should be considered with weights determined by the number of honest worker arrivals, as detailed
in Theorem 4.1. The unique characteristics of µ2-SGD make it well-suited for the asynchronous
Byzantine setting, where λ < 1/2relates to the fraction of Byzantine iterations. The total iteration
number tmatches the sum of the workers’ frequencies (P
i∈[G]s(i)
t=tG), aligning with the weighted
robust definition in Definition 3.1. Using other approaches like momentum [Karimireddy et al.,
2020, 2021, Allouah et al., 2023] is less straightforward in the asynchronous Byzantine setting
with the weighted robust definition. This complexity arises because an individual honest error
∥ε(i)
t∥≲O(˜σ/√st)implies that weights should be√stinstead of st, which can be more challenging.
Remark 4.1 (Memory and Computational Overhead of Algorithm 2) .Algorithm 2 incurs additional
memory and computational costs compared to the asynchronous Byzantine-free setting [Arjevani
7et al., 2020], where the server stores only one worker’s output and the global model. For robust
performance, Algorithm 2 stores the latest outputs from all workers, increasing memory usage to
O(dm). Robust aggregation methods like ω-CWMed [Yin et al., 2018] and ω-GM [Chen et al., 2017,
Acharya et al., 2022] add a computational cost of O(dmlogm)per round, unlike asynchronous
Byzantine-free settings where worker outputs are used without aggregation. Comparable overheads
are observed in synchronous Byzantine-resilient methods, which similarly aggregate outputs from
all workers. This reflects a necessary trade-off: achieving robustness inherently requires leveraging
information from all workers to counteract the influence of potentially faulty ones.
Theorem 4.1. For a convex set Kwith bounded diameter Dand a function f:K 7→R, and assume
the assumptions in Equations (2),(3),(4). Then Alg. 2 with parameters {αt=t}tand{βt= 1/st}t
ensures the following for every t∈[T]and each honest worker i∈ G:
Eε(i)
t2
≤˜σ2
s(i)
t,E1
P
i∈Gs(i)
tX
i∈Gs(i)
tε(i)
t2
≤˜σ2
tG,
where ε(i)
t=d(i)
t− ∇f(x(i)
t),˜σ2= 2σ2+ 32D2K2σ2
L, and tGis the total number of honest
iterations up to the tthiteration.
Proof Sketch of Thm. 4.1. The complete analysis is provided in App. B.1. It involves several key
steps for an honest iworker who arrives at iteration t:
1. Following Lemma B.1, the distance between successive query points: ∥x(i)
t−x(i)
t−τt∥ ≤4K
s(i)
t−1D
2. We analyze the recursive dynamics of the error term ε(i)
tby setting βt=1
s(i)
tand obtain:
s(i)
tε(i)
t= (g(i)
t− ∇f(x(i)
t)) + ( s(i)
t−1)Z(i)
t+ (s(i)
t−1)ε(i)
t−τt,
where Z(i)
t:=g(i)
t− ∇f(x(i)
t)−(˜g(i)
t−τt− ∇f(x(i)
t−τt)). Unrolling this recursion provides an
explicit expression: s(i)
tε(i)
t=P
k∈[s(i)
t]M(i)
k,whereM(i)
s(i)
t:=g(i)
t− ∇f(x(i)
t) + (st−1)Z(i)
t;
thus,{M(i)
k}k∈[s(i)
t]is a martingale difference sequence.
3. Employing the above with Eq. (2) and (4), we have: E∥M(i)
k∥2≤2σ2+ 32D2K2σ2
L= ˜σ2.
4. Leveraging the properties of a martingale difference sequence, we have:
Es(i)
tε(i)
t2
=EX
k∈h
s(i)
tiM(i)
k2
=X
k∈h
s(i)
tiEM(i)
k2
≤˜σ2s(i)
t,
EX
i∈Gs(i)
tε(i)
t2
=EX
i∈GX
k∈h
s(i)
tiM(i)
k2
=X
i∈GX
k∈h
s(i)
tiEM(i)
k2
≤˜σ2X
i∈Gs(i)
t= ˜σ2tG.
Remark 4.2. Compared to synchronous scenarios [Levy, 2023, Dahan and Levy, 2024], the variance
˜σin Thm. 2 additionally includes the variance in the delay, denoted as K(Eq. (5)). In balanced
scheduling methods, like Round Robin [Langford et al., 2009], the impact of Kon the error becomes
minor, as the delay τ(i)
t=mis constant. In the case of constant delays, the factor Kequals 1.
Lemma 4.1. LetAωbe(cλ, λ)-weighted robust aggregation rule and let f:K 7→R, where Kis a
convex set with bounded diameter D, and presume that the assumption in Equations (2),(3),(4)hold.
Then invoking Alg. 2 with {αt=t}tand{βt= 1/st}t, ensures the following for any t∈[T],
Eˆdt− ∇f(xt)2
≤O
˜σ2
t+cλm˜σ2
t|{z}
Variance+(τmax
tDL)2
t2+cλ(τmax
tDL)2
t2| {z }
Bias

8where ˆdt=Aω({d(i)
t, s(i)
t}m
i=1),τmax
t= max i∈[m]{τ(i)
t}, and ˜σ2= 2σ2+ 32D2K2σ2
L.
Lemma 4.1 shows that the error between our gradient estimator ˆdtand the true gradient includes a
bias term arising from the aggregation of delayed momentums. This is in contrast to the synchronous
scenario [Dahan and Levy, 2024] where the error is solely variance-dependent without any bias
component. However, this bias does not affect the overall excess loss (Theorem 4.2), which remains
comparable to the optimal rate achieved in synchronous Byzantine settings (see Remark 4.5).
By integrating the weighted robust aggregator with the double momentum mechanism, we achieve
the optimal convergence rate for the first time in an asynchronous Byzantine setting—a significant
advancement over previous efforts.
Theorem 4.2 (Asynchronous Byzantine µ2-SGD Guarantees) .LetAωbe(cλ, λ)-weighted robust
aggregation rule and let fbe a convex function. Also, let us make the same assumptions as in
Thm. 4.1, and let us denote G∗:=∥∇f(x∗)∥, where x∗∈arg min x∈Kf(x). Then invoking Alg. 2
with{αt=t}tand{βt= 1/st}t, and using a learning rate η≤1/4LTguarantees,
E[f(xT)−f(w∗)]≤OG∗D+LD2µmax(√1 +cλ)
T+D˜σ(√1 +cλm)√
T
where ˜σ2= 2σ2+ 32D2K2σ2
L,µmax=1
TP
t∈[T]τmax
t, and τmax
t= max i∈[m]{τ(i)
t}.
Remark 4.3. In the absence of Byzantine iterations ( λ= 0), the parameter cλof a(cλ, λ)-weighted
robust aggregator can diminish to 0 when we use ω-CTMA (see Table 1). This aligns with the
asynchronous SGD analysis [Arjevani et al., 2020] and represents the first work to achieve optimal
convergence without Byzantine workers compared to previous efforts [Yang and Li, 2021, 2023, Fang
et al., 2022, Zhu et al., 2023, Damaskinos et al., 2018, Xie et al., 2020b, Zhu et al., 2024].
Remark 4.4. Unlike previous works [Yang and Li, 2021, 2023, Fang et al., 2022, Zhu et al., 2023,
Damaskinos et al., 2018, Xie et al., 2020b, Zhu et al., 2024], our convergence rate is independent of
data dimensionality dand is sublinear at T, even in the presence of Byzantine workers.
Remark 4.5. This result is consistent with the synchronous scenario [Dahan and Levy, 2024], where
the delay is constant τt=mas in Round Robin [Langford et al., 2009]. In this case, the proportion of
Byzantine workers is λ, and the asynchronous excess loss is ≤O
LD2m
T+D˜σ√1+cλm√
T
. In compari-
son to the synchronous case, where mworkers perform Rrounds, here we make Rquery point updates
andT=Rm data-samples, resulting in synchronous excess loss ≤O
LD2
R+D˜σ√
1/m+cλ√
R
=
O
LD2m
T+D˜σ√1+mcλ√
T
[Dahan and Levy, 2024].
5 Experiments
To evaluate the effectiveness of our proposed approach, we conducted experiments on MNIST
[LeCun et al., 2010] and CIFAR-10 [Krizhevsky et al., 2014] datasets—two recognized benchmarks
in image classification tasks. We employed a two-layer convolutional neural network architecture
for both datasets, implemented using the PyTorch framework. The training was performed using the
cross-entropy loss function, and all computations were executed on an NVIDIA RTX 3090 GPU.
To ensure the robustness of our findings, each experiment was repeated with three different random
seeds, and the results were averaged accordingly. Our experimental results demonstrate consistent
performance across both datasets. Further details about the experimental setup and the complete
results are provided in Appendix D.
Weighted vs. Non-Weighted Robust Aggregators . We evaluated the test accuracy of weighted
and non-weighted robust aggregators in imbalanced asynchronous Byzantine environments. Our
experiments show that weighted robust aggregators consistently achieved higher test accuracy than
the non-weighted ones (see Figure 2 and Figure 5). This highlights the benefit of prioritizing workers
who contribute more updates in asynchronous setups.
9Figure 2: CIFAR-10 .Test Accuracy of Weighted vs. Non-Weighted Robust Aggregators . This scenario involves 17
workers, including 8 Byzantine workers, with workers’ arrival probabilities proportional to the square of their IDs. We
used the µ2-SGD in this scenario. Left: label flipping ,λ= 0.3. Right: sign flipping ,λ= 0.4.
Effectiveness of ω-CTMA . We evaluated the test accuracy of weighted robust aggregators with and
without the integration of ω-CTMA, as shown in Figure 3 and Figure 6. The results demonstrate
thatω-CTMA can enhance the performance of weighted robust aggregators in various Byzantine
scenarios. Notably, ω-CTMA may maintain high accuracy even when other robust aggregators fail,
as seen with the Empire attack result for both datasets.
Figure 3: CIFAR-10 .Test Accuracy Comparison of Weighted Robust Aggregators With and Without ω-CTMA .
This scenario involves 9 workers with 1 or 3 Byzantine workers. Workers’ arrival probabilities are proportional to their
IDs, and we used µ2-SGD. On the left, we have the label flipping andlittle attacks with λ= 0.1andλ= 0.2for 1 and 3
Byzantine workers, respectively. On the right , the empire attack, each with λ= 0.4and 3 Byzantine workers.
Performance of µ2-SGD vs. Standard Momentum and SGD . We evaluated the test accuracy of
µ2-SGD in comparison to standard momentum [Polyak, 1964] and SGD [eon Bottou, 1998] within
an asynchronous Byzantine setup. Figure 4 and Figure 7 show that µ2-SGD performs on par with
standard momentum, while SGD generally exhibits poorer performance relative to both. These results
underscore the importance of utilizing historical information when addressing Byzantine scenarios.
Figure 4: CIFAR-10 .Test Accuracy Comparison Among Different Optimizers . This scenario involves 9 workers (4
Byzantine) with λ= 0.4for the first three from lefttoright , andλ= 0.3for the label flipping attack on the left. Workers’
arrival probabilities are proportional to their IDs.
Conclusions and Future Work
This paper shows that using a double momentum approach, which incorporates the entire history
of each honest worker, improves the error bound to be proportional to the total number of updates
when considering their weighted average in asynchronous settings. By integrating this method with a
weighted robust framework, µ2-SGD achieves an optimal convergence rate, making it particularly
effective for asynchronous Byzantine environments. However, integrating other optimization algo-
rithms, like momentum, into this weighted robust framework can be challenging, as they do not
achieve an error bound proportional to the total number of updates and may complicate the adjustment
of weights based on the update count. This highlights the need for further research to adapt different
methods to the spirit of this framework in non-convex and convex settings.
10Acknowledgement
This research was partially supported by Israel PBC-V ATAT, the Technion Artificial Intelligent Hub
(Tech.AI), and the Israel Science Foundation (grant No. 3109/24).
References
Anish Acharya, Abolfazl Hashemi, Prateek Jain, Sujay Sanghavi, Inderjit S Dhillon, and Ufuk
Topcu. Robust training in high dimensions via block coordinate geometric median descent. In
International Conference on Artificial Intelligence and Statistics , pages 11145–11168. PMLR,
2022.
Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li. Byzantine stochastic gradient descent. Advances in
Neural Information Processing Systems , 31, 2018.
Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, and Dan Alistarh. Byzantine-resilient non-convex
stochastic gradient descent. arXiv preprint arXiv:2012.14368 , 2020.
Youssef Allouah, Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, Rafaël Pinot, and John
Stephan. Fixing by mixing: A recipe for optimal byzantine ml under heterogeneity. In International
Conference on Artificial Intelligence and Statistics , pages 1232–1300. PMLR, 2023.
Yossi Arjevani, Ohad Shamir, and Nathan Srebro. A tight convergence analysis for stochastic gradient
descent with delayed updates. In Algorithmic Learning Theory , pages 111–132. PMLR, 2020.
Rotem Zamir Aviv, Ido Hakimi, Assaf Schuster, and Kfir Yehuda Levy. Asynchronous distributed
learning: Adapting to gradient delays without prior knowledge. In International Conference on
Machine Learning , pages 436–445. PMLR, 2021.
Gilad Baruch, Moran Baruch, and Yoav Goldberg. A little is enough: Circumventing defenses for
distributed learning. Advances in Neural Information Processing Systems , 32, 2019.
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine learning
with adversaries: Byzantine tolerant gradient descent. Advances in neural information processing
systems , 30, 2017.
Yudong Chen, Lili Su, and Jiaming Xu. Distributed statistical machine learning in adversarial settings:
Byzantine gradient descent. Proceedings of the ACM on Measurement and Analysis of Computing
Systems , 1(2):1–25, 2017.
Alon Cohen, Amit Daniely, Yoel Drori, Tomer Koren, and Mariano Schain. Asynchronous stochastic
optimization robust to arbitrary delays. Advances in Neural Information Processing Systems , 34:
9024–9035, 2021.
Ashok Cutkosky. Anytime online-to-batch, optimism and acceleration. In International conference
on machine learning , pages 1446–1454. PMLR, 2019.
Ashok Cutkosky and Francesco Orabona. Momentum-based variance reduction in non-convex sgd.
Advances in neural information processing systems , 32, 2019.
Tehila Dahan and Kfir Yehuda Levy. Fault tolerant ml: Efficient meta-aggregation and synchronous
training. In Forty-first International Conference on Machine Learning , 2024.
Georgios Damaskinos, Rachid Guerraoui, Rhicheek Patra, Mahsa Taziki, et al. Asynchronous
byzantine machine learning (the case of sgd). In International Conference on Machine Learning ,
pages 1145–1154. PMLR, 2018.
Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction
using mini-batches. Journal of Machine Learning Research , 13(1), 2012.
El Mahdi El Mhamdi, Rachid Guerraoui, and Sébastien Louis Alexandre Rouault. Distributed
momentum for byzantine-resilient stochastic gradient descent. In 9th International Conference on
Learning Representations (ICLR) , number CONF, 2021.
11L eon Bottou. Online learning and stochastic approximations. Online learning in neural networks ,
17(9):142, 1998.
Minghong Fang, Jia Liu, Neil Zhenqiang Gong, and Elizabeth S Bentley. Aflguard: Byzantine-
robust asynchronous federated learning. In Proceedings of the 38th Annual Computer Security
Applications Conference , pages 632–646, 2022.
Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, Rafael Pinot, and John Stephan. Byzantine
machine learning made easy by resilient averaging of momentums. In International Conference on
Machine Learning , pages 6246–6283. PMLR, 2022.
Rachid Guerraoui, Sébastien Rouault, et al. The hidden vulnerability of distributed learning in
byzantium. In International Conference on Machine Learning , pages 3521–3530. PMLR, 2018.
Rachid Guerraoui, Nirupam Gupta, and Rafael Pinot. Byzantine machine learning: A primer. ACM
Computing Surveys , 2023.
Elad Hazan et al. Introduction to online convex optimization. Foundations and Trends ®in Optimiza-
tion, 2(3-4):157–325, 2016.
Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Byzantine-robust learning on heterogeneous
datasets via bucketing. arXiv preprint arXiv:2006.09365 , 2020.
Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Learning from history for byzantine robust
optimization. In International Conference on Machine Learning , pages 5311–5319. PMLR, 2021.
Ali Kavis, Kfir Y Levy, Francis Bach, and V olkan Cevher. Unixgrad: A universal, adaptive algorithm
with optimal guarantees for constrained optimization. Advances in neural information processing
systems , 32, 2019.
Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The cifar-10 dataset. online: https: // www.
cs. toronto. edu/ ~kriz/ cifar. html , 55(5), 2014.
Leslie Lamport, Robert Shostak, and Marshall Pease. The byzantine generals problem. In Concur-
rency: the works of leslie lamport , pages 203–226. 2019.
John Langford, Alexander Smola, and Martin Zinkevich. Slow learners are fast. arXiv preprint
arXiv:0911.0491 , 2009.
Yann LeCun, Corinna Cortes, Chris Burges, et al. Mnist handwritten digit database, 2010. URL
http://yann.lecun.com/exdb/mnist/ . Licensed under CC BY-SA 3.0, available at https:
//creativecommons.org/licenses/by-sa/3.0/ .
Kfir Y Levy. µ2-sgd: Stable stochastic optimization via a double momentum mechanism. arXiv
preprint arXiv:2304.04172 , 2023.
Konstantin Mishchenko, Francis Bach, Mathieu Even, and Blake E Woodworth. Asynchronous sgd
beats minibatch sgd under arbitrary delays. Advances in Neural Information Processing Systems ,
35:420–433, 2022.
Boris T Polyak. Some methods of speeding up the convergence of iteration methods. Ussr computa-
tional mathematics and mathematical physics , 4(5):1–17, 1964.
Sebastian U Stich and Sai Praneeth Karimireddy. The error-feedback framework: Better rates for sgd
with delayed gradients and compressed communication. arXiv preprint arXiv:1909.05350 , 2019.
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Fall of empires: Breaking byzantine-tolerant sgd
by inner product manipulation. In Uncertainty in Artificial Intelligence , pages 261–270. PMLR,
2020a.
Cong Xie, Sanmi Koyejo, and Indranil Gupta. Zeno++: Robust fully asynchronous sgd. In Interna-
tional Conference on Machine Learning , pages 10495–10503. PMLR, 2020b.
Yi-Rui Yang and Wu-Jun Li. Basgd: Buffered asynchronous sgd for byzantine learning. In Interna-
tional Conference on Machine Learning , pages 11751–11761. PMLR, 2021.
12Yi-Rui Yang and Wu-Jun Li. Buffered asynchronous sgd for byzantine learning. Journal of Machine
Learning Research , 24(204):1–62, 2023.
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed
learning: Towards optimal statistical rates. In International Conference on Machine Learning ,
pages 5650–5659. PMLR, 2018.
Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,
Beichen Zhang, Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv
preprint arXiv:2303.18223 , 2023.
Zehan Zhu, Yan Huang, Chengcheng Zhao, and Jinming Xu. Asynchronous byzantine-robust
stochastic aggregation with variance reduction for distributed learning. In 2023 62nd IEEE
Conference on Decision and Control (CDC) , pages 151–158. IEEE, 2023.
Zehan Zhu, Yan Huang, Chengcheng Zhao, and Jinming Xu. Asynchronous byzantine-robust
stochastic aggregation with variance reduction for distributed learning. 2024.
13A Bounded Smoothness Variance Assumption
We show that Eq. (3) implies that Eq. (4) holds for some σ2
L∈[0, L2].
E∥(∇f(x;z)− ∇f(x))−(∇f(y;z)− ∇f(y))∥2=E∥∇f(x;z)− ∇f(y;z)∥2− ∥∇ f(x)− ∇f(y))∥2
≤L2∥x−y∥2.
Here, we also used E[∇f(x;z)− ∇f(y;z)] = (∇f(x)− ∇f(y)), and followed Eq. (3). Therefore,
we establish that σ2
L∈[0, L2].
B Asynchronous Robust Convex Analysis
B.1 Proof of Thm. 4.1
Proof of Thm. 4.1. To simplify the discussion, let’s introduce some notations for a worker i∈ G,
who arrives at time t:
˜xst:=xt−τt=x(i)
t,˜xst−1:=xt−τt−τt−τt=x(i)
t−τt
˜εst:=εt−τt=ε(i)
t,˜εst−1:=εt−τt−τt−τt=ε(i)
t−τt
hst:=gt−τt=g(i)
t,˜hst−1:=˜gt−τt−τt−τt=˜g(i)
t−τt
Next, we will employ the following lemma that bounds the distance between the averages xt,xt−τt.
Recall that xtandxt−τtare consecutive query points for the worker ithat arrives at time t.
Lemma B.1 (Aviv et al. [2021]) .Letf:K 7→R, where Kis a convex set with bounded diameter D.
Then invoking Alg. 2 with {αt=t}tensures the following for any t∈[T],
∥xt−xt−τt∥ ≤4Dτt
t.
For completeness, we provide a proof in Section B.1.1.
Next, we define µtbe the average delay of the worker ithat arrives at iteration t, i.e.,
st=t
µt, s t−1 =st−τt=t−τt
µt−τt.
From Equation (5), we infer that,
τ(i)
min≤µt≤Kτ(i)
min. (7)
Following this, we analyze the upper bound on the distance between two successive query points for
an honest worker ithat arrives at time t:
∥˜xst−˜xst−1∥=∥xt−τt−xt−τt−τt−τt∥ ≤4τt−τt
t−τtD=4τt−τt
(µt−τt)(st−1)D≤4K
st−1D , (8)
where the first inequality follows Lemma B.1. The second equality utilizes the relation st−1 =t−τt
µt−τt.
The final inequality stems from the assumptions in Eq. (5) and Eq. (7).
Remark: Before proceeding with the analysis, we shall condition the (possible randomization) in
the delays of all workers; and recall that the data-samples are independent of the delays. Thus, the
expectations that we take are only with respect to the randomization in the data-samples and are
conditioned on the delays. Thus, this conditioning allows us to treat the delays τ(i)
t’s and number of
updates s(i)
t’s as fixed and predefined.
We proceed to analyze the recursive dynamics of ˜εstfor each i∈ G. Based on the definitions of dt
andεt, we can present the recursive relationship in the following way:
˜εst=βt(hst− ∇f(˜xst)) + (1 −βt)Zst+ (1−βt)˜εst−1,
14where Zst:=hst−∇f(˜xst)−(˜hst−1−∇f(˜xst−1)). Upon choosing βt=1
st, we can reformulate
the above equation as follows:
st˜εst= (hst− ∇f(˜xst)) + ( st−1)Zst+ (st−1)˜εst−1.
Unrolling this recursion yields an explicit expression for any st≥1:
st˜εst=X
k∈[st]M(i)
k, (9)
where we have defined,
M(i)
k:=hk− ∇f(˜xk) + (k−1)Zk, (10)
andkis a counter for the iterations where worker imakes an update.
Following this, we derive an upper bound for the expected square norm of M(i)
kas follows:
E∥M(i)
k∥2≤2E∥hk− ∇f(˜xk)∥2+ 2(k−1)2E∥(hk− ∇f(˜xk))−(˜hk−1− ∇f(˜xk−1))∥2
≤2σ2+ 2σ2
L(k−1)2E∥xk−xk−1∥2
≤2σ2+ 32D2K2σ2
L= ˜σ2, (11)
where the first inequality uses ∥a+b∥2≤2∥a∥2+ 2∥b∥2, which holds ∀a,b∈Rd. The second
inequality aligns with the assumptions outlined in Equations (2)and(4). The third inequality uses
Eq. (8).
Establishing the First Part of the Theorem: Before continuing, it is natural to define an ordered
set of samples {z1,z2, . . . , ztG}such that these samples are associated with honest and consecutive
updates (or iterates) of the PS, andtGis the total number of honest updates up to time t. Concretely,
theτthhonest update of the PSis based on an honest worker that utilizes a fresh sample zτ.
Now, for a given worker iwe shall define the filtration associated with his updates. Concretely, let
k∈ {1, . . . s(i)
T}. Then we define F(i)
kto be the sigma-algebra induces by the sequence of samples
{z1,z2, . . . , ztG}up to the kthupdate of worker i. And it is easy to see that {F(i)
k}k∈[s(i)
t]is a
filtration. Moreover, it can be directly shown that for a given worker i, then the above defined sequence
{M(i)
k}k∈[s(i)
t](see Eq. (10)) is a martingale difference sequence with respect to {F(i)
k}k∈[s(i)
t]. This
allows us to directly employ Lemma B.2 below, which yields,
Es(i)
tε(i)
t2
=EX
k∈h
s(i)
tiM(i)
k2
=X
k∈h
s(i)
tiEM(i)
k2
≤˜σ2s(i)
t,
where we have also used Equations (9)and(11). Thus, the above bounds establish the first part of the
theorem.
Lemma B.2 (See e.g. Lemma B.1 in Levy [2023]) .Let{Mt}tbe a martingale difference sequence
with respect to a filtration {Ft}t, then the following holds for any t,
EX
τ∈[t]Mτ2
=X
τ∈[t]E∥Mτ∥2.
Establishing the Second Part of the Theorem: As before, we define an ordered set of samples
{z1,z2, . . . , ztG}such that these samples are associated with honest and consecutive updates (or
iterates) of the PS, and tGis the total number of honest updates up to time t. Concretely, the τth
honest update of the PSis based on an honest worker that utilizes a fresh sample zτ. We shall also
define {Fτ}τ∈[tG]be the natural filtration induced by the ordered sequence of data samples.
Moreover, for a given sample zτ∈ {z1,z2, . . . , ztG}, letiτ∈[m]be the worker that is associated
with the τthhonest update of the PS, with a fresh sample zτ. In this case, we shall define:
Mτ:=M(iτ)
s(iτ)
τ.
15whereM(i)
kis defined in Eq. (10). It is immediate to show that {Mτ}τ∈[tG]is a martingale difference
sequence with respect to {Fτ}τ∈[tG]. Moreover, the following holds directly be the definition of Mτ:
X
i∈GX
k∈h
s(i)
tiM(i)
k=tGX
τ=1Mτ. (12)
Now using Eq. (9) the following holds,
X
i∈Gs(i)
tε(i)
t=X
i∈GX
k∈h
s(i)
tiM(i)
k. (13)
Combining Equations (12) and(13) together with Lemma B.2 establishes the second part of the
theorem,
EX
i∈Gs(i)
tε(i)
t2
=EX
i∈GX
k∈h
s(i)
tiM(i)
k2
=EtGX
τ=1Mτ2
=tGX
τ=1E∥Mτ∥2≤˜σ2tG.
where the inequality uses the bound in Eq. (11).
B.1.1 Proof of Lemma B.1
Proof. We borrowed the following steps from Aviv et al. [2021]. Let’s define y∈ K as the average
ofxtover the interval [t−τt, t], i.e.,
y:=1
αt−τt+1:ttX
i=t−τt+1αiwi.
Then we have the following relationship:
α1:txt=tX
i=1αiwi=t−τtX
i=1αiwi+tX
i=t−τt+1αiwi=α1:t−τtxt−τt+αt−τt+1:ty.
Hence,
α1:t−τt(xt−xt−τt) =αt−τt+1:t(y−xt).
By setting αt=t, we have that,
∥xt−xt−τt∥=αt−τt+1:t
α1:t−τt∥y−xt∥
=τt(t−τt+ 1 + t)
(t−τt)(t−τt+ 1)∥y−xt∥
≤τt(t−τt+ 1)
(t−τt)(t−τt+ 1)∥y−xt∥+tτt
(t−τt)2∥y−xt∥
=τt
t−τt∥y−xt∥+tτt
(t−τt)2∥y−xt∥.
Fort≥3τt, we have that,
∥xt−xt−τt∥ ≤3τtD
2t+9τtD
4t≤4τtD
t.
Given that the domain is bounded, ∥xt−xt−τt∥ ≤D∀t, fort <3τt, we have D <4τtD
t. Combining
these results, we conclude:
∥xt−xt−τt∥ ≤4τtD
t.
16B.2 Proof of Lemma 4.1
Proof of Lemma 4.1.
Lemma B.3. Letf:K 7→R, where Kis a convex set with bounded diameter D. Then invoking
Alg. 2 with {αt=t}tensures the following for any t∈[T], and every i, j∈[m],
x(i)
t−x(j)
t≤4D
τ(i)
t+τ(j)
t
t.
Proof.
x(i)
t−x(j)
t≤x(i)
t−xt+xt−x(j)
t≤4Dτ(i)
t
t+4Dτ(j)
t
t,
where the first inequality is a result of the triangle inequality, and the second follows Lemma B.1.
Bias Bounds. Here’s a refined version:
We begin by analyzing the upper bound of the bias in the collective gradients of honest workers
up to time tin relation to the gradient at that time, denoted as B1
t. Following this, we derive the
upper bound for the bias between the collective gradients of these honest workers and the gradient
of an individual honest worker, also up to time t, which we denote as B2
t. For clarity, we define
¯∇G,t:=1P
i∈Gs(i)
tP
i∈Gs(i)
t∇f(x(i)
t).
B1
t:=E¯∇G,t− ∇f(xt)
=E1
P
i∈Gs(i)
tX
i∈Gs(i)
t∇f(x(i)
t)− ∇f(xt)
≤E"
1
P
i∈Gs(i)
tX
i∈Gs(i)
t∇f(x(i)
t)− ∇f(xt)#
≤L
P
i∈Gs(i)
tE"X
i∈Gs(i)
tx(i)
t−xt#
≤4DL
P
i∈Gs(i)
tE"X
i∈Gs(i)
tτ(i)
t
t#
≤4τmax
tDL
t. (14)
Here, the first inequality leverages Jensen’s inequality, and the second follows the smoothness
assumption in Eq. (3). The third follows Lemma B.1, and the last inequality follows that τmax
t:=
max i∈[m]{τ(i)
t}.
17For the second bias B2
t, we have:
EB2
t:=E∇f(x(i)
t)−¯∇G,t
=E∇f(x(i)
t)−1
P
j∈Gs(j)
tX
j∈Gs(j)
t∇f(x(j)
t)
≤1
P
j∈Gs(j)
tE
X
j∈Gs(j)
t∇f(x(i)
t)− ∇f(x(j)
t)

≤L
P
j∈Gs(j)
tE
X
j∈Gs(j)
tx(i)
t−x(j)
t

≤4DL
P
j∈Gs(j)
tE
X
j∈Gs(j)
t 
τ(i)
t+τ(j)
t
t!

≤8τmax
tDL
t. (15)
Like before, the first inequality leverages Jensen’s inequality, and the second follows the smoothness
assumption in Eq. (3), the third inequality follows Lemma B.3, and the last one follows that
τmax
t:= max i∈[m]{τ(i)
t}.
Variance Bound. We start by determining ρias outlined in Definition 3.1:
E∥d(i)
t−¯dG,t∥2≤3E∥d(i)
t− ∇f(x(i)
t)∥2+ 3E∥¯∇G,t−¯dG,t∥2+ 3EB2
t2
= 3Eε(i)
t2
+ 3E1
P
i∈Gs(i)
tX
i∈Gs(i)
tε(i)
t2
+ 3EB2
t2
≤3˜σ2
s(i)
t+3˜σ2
tG+192(τmax
tDL)2
t2
≤6˜σ2
s(i)
t+192(τmax
tDL)2
t2,
where ¯dG,t:=1P
i∈Gs(i)
tP
i∈Gs(i)
td(i)
t. The first and inequality uses ∥a+b+c∥2≤3∥a∥2+
3∥b∥2+3∥c∥2, which holds ∀a,b,c∈Rd. The second inequality follows Theorem 4.1 and employs
the second bias bound in Eq. (15). The third uses the fact that s(i)
t≤tG,∀i∈ G. Accordingly, we set
ρ2
i:=6˜σ2
s(i)
t+192(τmax
tDL)2
t2 .
Following this, we derive ρas outlined in Definition 3.1:
ρ2=1
P
i∈Gs(i)
tX
i∈Gs(i)
tρ2
i=1
tGX
i∈Gs(i)
t 
6˜σ2
s(i)
t+192(τmax
tDL)2
t2!
=6m˜σ2
tG+192(τmax
tDL)2
t2.
(16)
18Next, we establish an upper bound for E∥Et∥2:
E∥Et∥2=Eˆdt− ∇f(xt)2
≤2Eˆdt−¯dG,t2
+ 2E¯dG,t− ∇f(xt)2
≤2cλ6m˜σ2
tG+192(τmax
tDL)2
t2
+ 4E¯dG,t−¯∇G,t2+ 4EB1
t2
= 2cλ6m˜σ2
tG+192(τmax
tDL)2
t2
+ 4E1
P
i∈Gs(i)
tX
i∈Gs(i)
tε(i)
t2
+ 4EB1
t2
≤12cλm˜σ2
tG+4˜σ2
tG+(τmax
tDL)2(384cλ+ 64)
t2
≤8˜σ2
t+24cλm˜σ2
t+64(τmax
tDL)2
t2+384cλ(τmax
tDL)2
t2,
where the first inequality uses ∥a+b∥2≤2∥a∥2+ 2∥b∥2, which holds ∀a,b∈Rd. The second
inequality utilizes the same inequality and is further supported by Definition 3.1 and Equation (16).
The third aligns with Theorem 4.1, and employs the first bias bound in Eq. (14). The last one utilizes
the fact that tG≥(1−λ)t≥t/2, given λ < 1/2.
B.3 Proof of Thm. 4.2
Proof of Thm. 4.2. Following Lemma 4.1 and applying Jensen’s inequality, we derive the following
bound:
E∥Et∥=Ep
∥Et∥2≤p
E∥Et∥2≤O˜σ√1 +mcλ√
t+τmax
tDL√1 +cλ
t
, (17)
where the third inequality uses√
a+b≤√a+√
bfor non-negative a, b∈R. The explanation
behind this can be seen through the following steps:
√a+√
b2
=a+ 2√
ab+b≥a+b ,
whereby taking the square root of both sides of this equation, we obtain the desired inequality.
Next, let’s revisit the AnyTime guarantee as outlined in Cutkosky [2019] and proceed to delve into
the regret analysis of the update rule.
Theorem B.1 (Rephrased from Theorem 1 in Cutkosky [2019]) .Letf:K →Rbe a convex function
with a minimum x∗∈arg min w∈Kf(w). Also let {αt≥0}t, and{wt∈ K} t,{xt∈ K} t, such that
{xt}tis an{αt}tweighted averaged of {wt}t, i.e. such that x1=w1, and for any t≥1,
xt+1=1
α1:t+1X
τ∈[t+1]ατwτ.
Then the following holds for any t≥1:
α1:t(f(xt)−f(x∗))≤X
τ∈[t]ατ∇f(xτ)(wτ−x∗).
Lemma B.4. Letf:K →Rbe a convex function with a minimum x∗∈arg min w∈Kf(w), and
assume that the assumption in Eq. (1)holds. Also let {αt≥0}t, and{wt∈ K} t. Then, for any
t≥1, an arbitrary vector ˆdt∈Rd, and the update rule:
wt+1= ΠK
wt−ηαtˆdt
,
we have,
tX
τ=1ατ⟨ˆdτ,wτ+1−x∗⟩ ≤D2
2η−1
2ηtX
τ=1∥wτ−wτ+1∥2.
19Lemma B.5. letf:K →Rbe an L-smooth and convex function, and let x∗∈arg min x∈Kf(x),
then for any x∈Rdwe have,
∥∇f(x)− ∇f(x∗)∥2≤2L(f(x)−f(x∗)).
Next, for every iteration t≤T, we define:
ˆdt:=Aω({d(i)
t, s(i)
t}m
i=1)
Et:=ˆdt− ∇f(xt)
Thus, combining Theorem B.1 with Lemma B.4, we have that,
α1:t(f(xt)−f(x∗))≤X
τ∈[t]ατ⟨∇f(xτ),wτ−x∗⟩
=X
τ∈[t]ατ⟨ˆdτ,wτ+1−x∗⟩+X
τ∈[t]ατ⟨ˆdτ,wτ−wτ+1⟩ −X
τ∈[t]ατ⟨Eτ,wτ−x∗⟩
≤D2
2η−1
2ηX
τ∈[t]∥wτ−wτ+1∥2+X
τ∈[t]ατ⟨ˆdτ,wτ−wτ+1⟩ −X
τ∈[t]ατ⟨Eτ,wτ−x∗⟩
=D2
2η−1
2ηX
τ∈[t]∥wτ−wτ+1∥2+X
τ∈[t]ατ⟨∇f(xτ),wτ−wτ+1⟩ −X
τ∈[t]ατ⟨Eτ,wτ+1−x∗⟩
≤D2
2η−1
2ηX
τ∈[t]∥wτ−wτ+1∥2+X
τ∈[t]ατ⟨∇f(xτ),wτ−wτ+1⟩
| {z }
(A)+DX
τ∈[t]ατ∥Eτ∥,
(18)
where the first inequality is derived from the Anytime guarantee, as outlined in Theorem B.1. The
second inequality follows Lemma B.4. The third inequality is a result of applying the Cauchy-Schwarz
inequality and the assumption in Eq. (1).
(A):=−1
2ηX
τ∈[t]∥wτ−wτ+1∥2+X
τ∈[t]ατ⟨∇f(xτ),wτ−wτ+1⟩
=−1
2ηX
τ∈[t]∥wτ−wτ+1∥2+X
τ∈[t]ατ⟨∇f(xτ)− ∇f(x∗),wτ−wτ+1⟩+X
τ∈[t]ατ⟨∇f(x∗),wτ−wτ+1⟩
≤η
2X
τ∈[t]α2
τ∥∇f(xτ)− ∇f(x∗)∥2+X
τ∈[t]ατ⟨∇f(x∗),wτ−wτ+1⟩
≤2ηLX
τ∈[t]α1:τ∆τ+X
τ∈[t](ατ−ατ−1)⟨∇f(x∗),wτ⟩ −αt⟨∇f(x∗),wt+1⟩
= 2ηLX
τ∈[t]α1:τ∆τ+X
τ∈[t](ατ−ατ−1)⟨∇f(x∗),wτ−wt+1⟩
≤2ηLX
τ∈[t]α1:τ∆τ+X
τ∈[t](ατ−ατ−1)∥∇f(x∗)∥∥wτ−wt+1∥
≤1
2TX
τ∈[T]α1:τ∆τ+αtG∗D .
Here, the first inequality employs the Young’s inequality. For the second inequality, we introduce the
notation ∆t:=f(xt)−f(x∗), and we follow Lemma B.5, which relates to the smoothness of the
function f. In this step, we also set α0= 0and utilizes the property α2
τ≤2α1:τ, given that ατ=τ.
The third inequality uses the Cauchy-Schwarz inequality. The last inequality follows the assumption
in Eq. (1). It uses the fact that t≤Tand∆t≥0,∀t. This step also incorporates the choice of an
appropriate learning rate parameter η≤1/4LT.
20Plugging (A) into Eq. (18), gives us,
α1:t∆t≤1
2TX
τ∈[T]α1:τ∆τ+D2
2η+αtG∗D+DX
τ∈[t]ατ∥Eτ∥. (19)
Lemma B.6 (Lemma C.2 in Levy [2023]) .let{At}t∈[T],{Bt}t∈[T]be sequences of non-negative
elements, and assume that for any t≤T,
At≤BT+1
2TX
t∈[T]At.
Then the following bound holds,
AT≤2BT.
In the next step, let us define two terms: At:=α1:tE[f(xt)−f(x∗)]andBt:=D2
2η+αtG∗D+
DP
τ∈[t]ατE∥Eτ∥. Note that the series {Bt}tforms a non-decreasing series of non-negative values,
implying Bt≤BTfor any t∈[T]. As a result of Eq. (19), we have that At≤BT+1
2TP
τ∈[T]Aτ.
Leveraging Lemma B.6, Eq. (17), and acknowledging that α1:T= Θ( T2), asαt=t, it follows that:
E[f(xT)−f(x∗)]≤2
T2BT
=D2
T2η+2G∗D
T+2D
T2X
t∈[T]αtE∥E∥
≤O
D2
T2η+G∗D
T+D
T2X
t∈[T]√
t˜σ√
1 +mcλ+τmax
tDL√
1 +cλ

≤OD2
T2η+G∗D
T+D˜σ√1 +mcλ√
T+µmaxD2L√1 +cλ
T
,
where µmax:=1
TP
t∈[T]τmax
t. Finally, choosing the optimal η≤1
4TLgives us:
E[f(xT)−f(x∗)]≤OLD2µmax√1 +cλ
T+G∗D
T+D˜σ√1 +mcλ√
T
.
B.3.1 Proof of Lemma B.4
Proof of Lemma B.4. The update rule wτ+1= ΠK(wτ−ηατˆdτ)can be expressed as a convex
optimization problem within the set K:
wτ+1= ΠK
wτ−ηατˆdτ
= arg min
w∈K∥wτ−ηατˆdτ−w∥2
= arg min
w∈K{ατ⟨ˆdτ,w−wτ⟩+1
2η∥w−wτ∥2}.
Here, the first equality is derived from the definition of the update rule, the second stems from the
property of projection, and the final equality is obtained by reformulating the optimization problem
in a way that does not affect the minimum value.
Given that wτ+1is the optimal solution of the above convex problem, by the optimality conditions,
we have that:

ατˆdτ+1
η(wτ+1−wτ),w−wτ+1
≥0,∀w∈ K.
21Rearranging this, summing over t≥1iterations, and taking w=x∗, we derive:
X
τ∈[t]ατ⟨ˆdτ,wτ+1−x∗⟩ ≤1
ηX
τ∈[t]⟨wτ−wτ+1,wτ+1−x∗⟩
=1
2ηX
τ∈[t] 
∥wτ−x∗∥2− ∥wτ+1−x∗∥2− ∥wτ−wτ+1∥2
=1
2η
∥w1−x∗∥2− ∥wt+1−x∗∥2−X
τ∈[t]∥wτ−wτ+1∥2

≤D2
2η−1
2ηX
τ∈[t]∥wτ−wτ+1∥2.
The first equality equality is achieved through algebraic manipulation, and the last inequality follows
the assumption in Eq. (1).
B.3.2 Proof of Lemma B.5
Proof of Lemma B.5.
Lemma B.7 (Lemma C.1 in Levy [2023]) .letf:Rd→Rbe an L-smooth function with a global
minimum x∗, then for any x∈Rdwe have,
∥∇f(x)∥2≤2L(f(x)−f(x∗)).
Let us define the function h(x) =f(x)−f(x∗)− ⟨∇ f(x∗),x−x∗⟩. Due to the convexity of f(x),
we have the gradient inequality f(x)−f(x∗)≥ ⟨∇ f(x∗),x−x∗⟩, which implies h(x)≥0. As
h(x∗) = 0 , this implies that x∗is the global minimum of h. Applying Lemma B.7, gives us,
∥∇f(x)− ∇f(x∗)∥2=∥∇h(x)∥2≤2L(f(x)−f(x∗)− ⟨∇ f(x∗),x−x∗⟩)≤2L(f(x)−f(x∗)),
where last inequality holds due to the convexity of f, which implies that ⟨∇f(x∗),x−x∗⟩ ≥0.
C Robust Aggregators Analysis
C.1 Weighted Robust Aggregators
C.1.1 Weighted Geometric Median (WeightedGM)
The Weighted Geometric Median (WeightedGM) is an aggregation method that seeks a point mini-
mizing the weighted sum of Euclidean distances to a set of points. Formally, for a given set of points
{xi}m
i=1and corresponding weights {si}m
i=1, the WeightedGM aggregator is defined as follows:
WeightedGM ∈arg min
y∈RdX
i∈[m]si∥y−xi∥
Lemma C.1. Letˆxbe a WeightedGM aggregator then ˆxis(cλ, λ)-weighted robust with cλ=
1 +λ
1−2λ2
.
22Proof.
∥ˆx−¯xG∥=ˆx−1P
i∈GsiX
i∈Gsixi
≤1P
i∈GsiX
i∈Gsi∥ˆx−xi∥
=1P
i∈GsiX
i∈[m]si∥ˆx−xi∥ −1P
i∈GsiX
i∈Bsi∥ˆx−xi∥
≤1P
i∈GsiX
i∈[m]si∥¯xG−xi∥ −1P
i∈GsiX
i∈Bsi∥ˆx−xi∥
=1P
i∈GsiX
i∈Gsi∥¯xG−xi∥+1P
i∈GsiX
i∈Bsi∥¯xG−xi∥ −1P
i∈GsiX
i∈Bsi∥ˆx−xi∥
≤1P
i∈GsiX
i∈Gsi∥¯xG−xi∥+1P
i∈GsiX
i∈Bsi∥¯xG−ˆx∥
≤1P
i∈GsiX
i∈Gsi∥¯xG−xi∥+λ
1−λ∥¯xG−ˆx∥.
The first inequality leverages Jensen’s inequality. The second inequality follows the WeightedGM
definition. The third is derived using the following triangle inequality: ∥¯xG−xi∥ ≤ ∥ ¯xG−
ˆx∥+∥ˆx−xi∥. The final inequality is based on the assumptions thatP
i∈Bsi≤λs1:mandP
i∈Gsi≥(1−λ)s1:m.
By rearranging, we obtain:
∥ˆx−¯xG∥ ≤
1 +λ
1−2λ1P
i∈GsiX
i∈Gsi∥¯xG−xi∥.
Taking the square of both sides and applying Jensen’s inequality gives us:
∥ˆx−¯xG∥2≤
1 +λ
1−2λ21P
i∈GsiX
i∈Gsi∥¯xG−xi∥2.
Taking the exception of both sides gives us the following:
E∥ˆx−¯xG∥2≤
1 +λ
1−2λ2
ρ2.
C.1.2 Weighted Coordinate-Wise Median (WeightedCWMed)
The Weighted Coordinate-Wise Median (WeightedCWMed) is an aggregation technique that operates
on a per-coordinate basis. For a given set of multi-dimensional data points {xi}m
i=1and corresponding
weights {si}m
i=1, the WeightedCWMed is computed by independently finding the weighted median of
each coordinate across all points. Formally, for the kthdimension, the WeightedCWMed aggregator
is defined as:
[WeightedCWMed ]k:=WeightedMedian ({[xi]k}m
i=1;{[si]k}m
i=1)
where [x]kis the kthelement of a vector xand the WeightedMedian is defined as follows: given
the elements {x1, . . . , xm}of each dimension are sorted in ascending order and their corresponds
weights {s1, . . . , s m}, the weighted median is the element xj∗, where j∗is determined by the
condition:
j∗∈arg min
j∈[m]

X
i∈[j]si>1
2X
i∈[m]si


23If there exists a value jsuch that:
X
i∈[j]si=1
2X
i∈[m]si
Then, the WeightedMedian is the average of the j-th and (j+ 1) -th elements:
WeightedMedian =xj+xj+1
2
Here, we extend the theoretical guarantee of the Coordinate-Wise Median (CWMed) to its weighted
version, following the procedure in Allouah et al. [2023].
Lemma C.2. LetAω:Rd×m→Rdbe a weighted coordinate-wise aggregation function. Given
set of points {xi}m
i=1and corresponding weights {si}m
i=1, this function incorporates dreal-valued
functions A1
ω, . . . , Ad
ω, where each [Aω({xi}m
i=1;{si}m
i=1)]k=Ak
ω({[xi]k}m
i=1;{[si]k}m
i=1). If for
eachk∈[d],Ak
ωis(cλ, λ)-weighted robust that satisfies:
EAk
ω({[xi]k}m
i=1;{[si]k}m
i=1)−[¯xG]k2≤cλP
i∈GsiX
i∈GsiE|[xi]k−[¯xG]k|2.
Then Aωis(cλ, λ)-weighted robust.
Proof. Since Aωis a coordinate-wise aggregator, it applies the same aggregation rule across each
dimension. Therefore,
∥Aω({xi}m
i=1;{si}m
i=1)−¯xG∥2=X
k∈[d]Ak
ω({[xi]k}m
i=1;{[si]k}m
i=1)−[¯xG]k2.
Given that each Ak
ω, fork∈[d], is(cλ, λ)-weighted robust that satisfies:
EAk
ω({[xi]k}m
i=1;{[si]k}m
i=1)−[¯xG]k2≤cλP
i∈GsiX
i∈GsiE|[xi]k−[¯xG]k|2.
We can express the overall aggregation function Aωas follows:
X
k∈[d]EAk
ω({[xi]k}m
i=1;{[si]k}m
i=1)−[¯xG]k2≤X
k∈[d]cλP
i∈GsiX
i∈GsiE|[xi]k−[¯xG]k|2
=cλP
i∈GsiX
i∈GsiEX
k∈[d]|[xi]k−[¯xG]k|2
=cλP
i∈GsiX
i∈GsiE∥xi−¯xG∥2
≤cλρ2,
where the first inequality is derived from the assumption stated in this lemma. The second aligns with
the definition of (cλ, λ)-weighted robust as detailed in Definition 3.1.
Lemma C.3. Letˆxbe a WeightedCWMed aggregator then ˆxis(cλ, λ)-weighted robust with cλ=
1 +λ
1−2λ2
.
Proof. In the context of the kthcoordinate, [WeightedCWMed ]kfunctions equivalently to Weight-
edGM for a one-dimensional case. Consequently, each coordinate of the WeightedCWMed aggregator
is(cλ, λ)-weighted robust with cλ=
1 +λ
1−2λ2
as established in Lemma C.1. Furthermore, since
the WeightedCWMed functions on a coordinate-wise basis, it follows from Lemma C.2 that the entire
WeightedCWMed aggregator is (cλ, λ)-weighted robust with cλ=
1 +λ
1−2λ2
.
24C.2 Proof of Lemma 3.1
Proof of Lemma 3.1. We denote yi:=xi−x0,ΣG:=P
i∈Gsi,ΣS:=P
i∈Ssi,ΣB:=P
i∈Bsi,
andΣm:=P
i∈[m]si. Recall that ΣG≥(1−λ)Σm, and ΣS= (1−λ)Σm(Alg. 1).
ˆx−¯xG=1
ΣSX
i∈Ssixi−¯xG
=x0−¯xG+1
ΣSX
i∈Ssi(xi−x0)
=−1
ΣGX
i∈Gsi(xi−x0) +1
ΣSX
i∈Ssi(xi−x0)
=−1
ΣGX
i∈Gsiyi+1
ΣSX
i∈Ssiyi
=1
ΣS−1
ΣGX
i∈Gsiyi−1
ΣSX
i∈Gsiyi+1
ΣSX
i∈Ssiyi
=1
ΣS−1
ΣGX
i∈Gsiyi−1
ΣSX
i∈G\Ssiyi+1
ΣSX
i∈S\Gsiyi
=ΣG−ΣS
ΣSΣGX
i∈Gsiyi−1
ΣSX
i∈G\Ssiyi+1
ΣSX
i∈S\Gsiyi.
Taking the squared norm of both sides, we obtain:
∥ˆx−¯xG∥2=ΣG−ΣS
ΣSΣGX
i∈Gsiyi−1
ΣSX
i∈G\Ssiyi+1
ΣSX
i∈S\Gsiyi2
≤3ΣG−ΣS
ΣSΣGX
i∈Gsiyi2
+ 31
ΣSX
i∈G\Ssiyi2
+ 31
ΣSX
i∈S\Gsiyi2
≤3ΣGΣG−ΣS
ΣSΣG2X
i∈Gsi∥yi∥2+3P
i∈S\Gsi
Σ2
SX
i∈S\Gsi∥yi∥2+3P
i∈G\Ssi
Σ2
SX
i∈G\Ssi∥yi∥2,
(20)
where the first inequality follows the inequality ∥a+b+c∥2≤3∥a∥2+3∥b∥2+3∥c∥2,∀a,b,c∈R2
and the second follow Jensen’s inequality.
Note that,
ΣG−ΣS
ΣSΣG2
=Σm−ΣB−(1−λ)Σm
ΣSΣG2
=λΣm−ΣB
ΣSΣG2
≤λΣm
(1−λ)ΣmΣG2
≤2λ
ΣG2
<2λ
Σ2
G, (21)
where the first inequality holds because ΣB≤λΣmandΣS= (1−λ)Σm. The second inequality
follows from the fact that 1−λ≥1/2, and the last since λ < 1/2.
25In addition, we have that,
P
i∈S\Gsi
Σ2
S=P
i∈S∪Gsi−P
i∈Gsi
Σ2
S
≤Σm−(1−λ)Σm
Σ2
S
=λΣm
Σ2
S
=λΣm
(1−λ)2Σ2m
≤4λ
Σm
≤4λ
ΣG, (22)
where the first inequality follows the facts that S∪ G ⊆ [m],{si≥0}i∈[m]andΣG≥(1−λ)Σm.
The second inequality is based on that 1−λ≥1/2, and the last since ΣG≤Σm. And in a similar
way,
P
i∈G\Ssi
Σ2
S≤4λ
ΣG(23)
Applying Eq. (21), Eq. (22) and Eq. (23) into Eq. (20), gives us,
∥ˆx−¯xG∥2≤6λ
ΣGX
i∈Gsi∥yi∥2+12λ
ΣGX
i∈S\Gsi∥yi∥2+12λ
ΣGX
i∈G\Ssi∥yi∥2
≤12λ
ΣGX
i∈S\Gsi∥xi−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2,
where the latter holds sinceP
i∈G\Ssi∥yi∥2≤P
i∈Gsi∥yi∥2.
Next, we define:
S∗:=[
i∈S{i}si
j=1,G∗:=[
i∈G{i}si
j=1.
Note thatP
i∈S\Gsi∥xi−x0∥2=P
i∈S∗\G∗∥xi−x0∥2. We’ll show that there exists an injective
function Φ :S∗\G∗→ G∗\S∗such that, ∀i∈S∗\ G∗,∥xΦ(i)−x0∥ ≥ ∥ xi−x0∥is satisfied. This
follows from our selection of S, which consists of the closest elements {xi}i∈Stox0(see Alg. 1),
and from:
|S∗\G∗|=X
i∈S\Gsi=X
i∈Ssi+X
i∈G\Ssi−X
i∈Gsi≤X
i∈G\Ssi=|G∗\S∗|,
where the last inequality follows thatP
i∈Ssi−P
i∈Gsi= (1−λ)Σm−ΣG≤0.
26Thus,
∥ˆx−¯xG∥2≤12λ
ΣGX
i∈S\Gsi∥xi−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2
=12λ
ΣGX
i∈S∗\G∗∥xi−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2
≤12λ
ΣGX
i∈S∗\G∗∥xΦ(i)−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2
≤12λ
ΣGX
i∈G∗∥xi−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2
=12λ
ΣGX
i∈Gsi∥xi−x0∥2+18λ
ΣGX
i∈Gsi∥xi−x0∥2
=30λ
ΣGX
i∈Gsi∥xi−x0∥2
≤60λ
ΣGX
i∈Gsi∥xi−¯xG∥2+60λ
ΣGX
i∈Gsi∥¯xG−x0∥2,
where the second inequality follows from the definition of the injective function Φ. The third
inequality is justified by the fact thatP
i∈G∗\S∗∥yi∥2≤P
i∈G∗∥yi∥2. Finally, the last inequality
leverages the property ∥a+b∥2≤2∥a∥2+ 2∥b∥2, which holds ∀a,b∈Rd.
Taking the expectations of both sides gives us the following:
E∥ˆx−¯xG∥2≤60λ
ΣGX
i∈GsiE∥xi−¯xG∥2+60λ
ΣGX
i∈GsiE∥¯xG−x0∥2
≤60λρ2+ 60λcλρ2
= 60λ(1 +cλ)ρ2,
where the last inequaility stems from Def. 3.1.
D Experiments
D.1 Technical Details
Datasets. We simulated over the MNIST [LeCun et al., 2010] and CIFAR-10 [Krizhevsky et al.,
2014] datasets. The datasets were accessed through torchvision (version 0.16.2).
•MNIST Dataset . MNIST is a widely used benchmark dataset in the machine learning community,
consisting of 70,000 grayscale images of handwritten digits (0-9) with a resolution of 28x28 pixels.
The dataset is split into 60,000 training images and 10,000 test images.
•CIFAR-10 Dataset . CIFAR-10 is a widely recognized benchmark dataset in the machine learning
community, containing 60,000 color images categorized into 10 different classes. Each image has
a resolution of 32x32 pixels and represents objects such as airplanes, automobiles, birds, cats, and
more. The dataset is evenly split into 50,000 training images and 10,000 test images.
Imbalanced Arrival Scenarios. We simulated two types of imbalanced arrival scenarios:
•Proportional Arrival Probability : The probability of arrival for the i-th worker in the honest
group was set proportionally to i/P
j∈Gj, ensuring that workers with higher indices had a higher
chance of arriving. The same distribution method was applied to Byzantine workers.
•Squared ID Arrival Probability : In a more skewed scenario, the arrival probability was pro-
portional to the square of the worker’s ID, i.e., i2/P
j∈Gj2. This setup further accentuated the
imbalance by favoring workers with larger IDs.
27Parameter MNIST CIFAR-10
Model Architecture Conv(1,20,5), ReLU,
MaxPool(2x2), Conv(20,50,5),
ReLU, MaxPool(2x2),
FC(800 →50), BatchNorm,
ReLU, FC(50 →10)Conv(3,20,5), ReLU,
MaxPool(2x2), Conv(20,50,5),
ReLU, MaxPool(2x2),
FC(1250 →50), BatchNorm,
ReLU, FC(50 →10)
Learning Rate 0.01 0.01
Batch Size 64 64
Data Processing &
AugmentationNormalize(mean=(0.1307),
std=(0.3081))RandomCrop(size=32,
padding=2),
RandomHorizontalFlip(p=0.5),
Normalize(mean=(0.4914,
0.4822, 0.4465), std=(0.2023,
0.1994, 0.2010))
Table 2: Experimental Setup for MNIST and CIFAR-10
For simplicity, Byzantine workers were introduced after a fixed number of iterations, controlled by a
parameter λ. However, it is worth noting that when Byzantine iterations are concentrated, they can
cause significant performance degradation. Such patterns can lead to increased delays for honest
updates, ultimately affecting the overall convergence of the algorithm.
Optimization Setup. We optimized the cross-entropy loss across all experiments. For comparisons,
we configured µ2-SGD with fixed parameters γ= 0.1andβ= 0.25. This was tested against
Standard SGD, and Momentum-based SGD, where the momentum parameter was set to β= 0.9as
recommended by Karimireddy et al. [2021], and also fine-tuning βto 0.8.
Attack Simulations. We simulated four types of attacks to evaluate the robustness of our approach:
1.Label Flipping [Allen-Zhu et al., 2020]: The labels of the data were flipped to incorrect
values, by subtracting the original labels from 9.
2.Sign Flipping [Allen-Zhu et al., 2020]: The signs of the workers’ output were flipped.
3.Little [Baruch et al., 2019]: Adapted from the synchronous case. It computes the maximum
allowable deviation zmaxbased on iterations count rather than the number of workers. Then,
it perturbs the honest updates by subtracting the product of the weighted standard deviation
andzmaxfrom the weighted mean of the honest updates.
Byzantine_update =weighted_mean (honest_momentums )−weighted_std (honest_momentums )·zmax.
4.Empire [Xie et al., 2020a]: Adapted from the synchronous case. This attack scales the
weighted mean of the honest momentums by a factor ϵin the negative direction,
Byzantine_update =−ϵ·weighted_mean (honest_momentums ).
In the two latter attacks, the mean and standard deviation are calculated coordinate-wise with respect
to weights, setting ϵ= 0.1.
AnyTime Update Formulation. Regarding the AnyTime update, defined as xt:=
αtwt+α1:t−1xt−1
α1:t, we employed a momentum-based formulation that equivalent to the standard
AnyTime update. Specifically, we updated the model parameters according to the formula:
xt=γtwt+ (1−γt)xt−1
where γtis difined as γt:=αt
α1:t. By setting αt=Cα1:t−1withC >0being a constant, we derived
thatγt=C
C+1and remains consistent across all time steps t≥1.
For more details, please visit our GitHub repository.1
1https://github.com/dahan198/asynchronous-fault-tolerant-ml
28D.2 Experimental Results on MNIST
Figure 5: MNIST .Test Accuracy of Weighted vs. Non-Weighted Robust Aggregators . This scenario
involves 17 workers, including 8 Byzantine workers, with workers’ arrival probabilities proportional to the
square of their IDs. We used the µ2-SGD in this scenario. Left: label flipping ,λ= 0.3. Right: sign flipping ,
λ= 0.4.
Figure 6: MNIST .Test Accuracy Comparison of Weighted Robust Aggregators With and Without ω-
CTMA . This scenario involves 9 workers, with a very fast Byzantine worker, and workers’ arrival probabilities
proportional to their IDs. On the left, we have a sign flipping attack with standard momentum (β= 0.9,λ= 0.4),
and on the right , we have little (λ= 0.2) and empire (λ= 0.4) attacks with µ2-SGD.
Figure 7: MNIST .Test Accuracy Comparison Among Different Optimizers . This scenario involves 9
workers, with λ= 0.4, 4 Byzantine workers, and workers’ arrival probabilities proportional to their IDs. We
also compared between momentum with the standard parameter β= 0.9suggested by Karimireddy et al. [2021]
and a fine-tuned parameter β= 0.8.
29NeurIPS paper checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the abstract and introduction do not include the claims made
in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or NA
answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how much
the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification:
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings, model
well-specification, asymptotic approximations only holding locally). The authors should
reflect on how these assumptions might be violated in practice and what the implications
would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was only
tested on a few datasets or with a few runs. In general, empirical results often depend on
implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution is
low or images are taken in low lighting. Or a speech-to-text system might not be used
reliably to provide closed captions for online lectures because it fails to handle technical
jargon.
•The authors should discuss the computational efficiency of the proposed algorithms and
how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to address
problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an important
role in developing norms that preserve the integrity of the community. Reviewers will be
specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
30Justification:
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
• All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if they
appear in the supplemental material, the authors are encouraged to provide a short proof
sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived well
by the reviewers: Making the paper reproducible is important, regardless of whether the
code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may be
necessary to either make it possible for others to replicate the model with the same dataset,
or provide access to the model. In general. releasing code and data is often one good
way to accomplish this, but reproducibility can also be provided via detailed instructions
for how to replicate the results, access to a hosted model (e.g., in the case of a large
language model), releasing of a model checkpoint, or other means that are appropriate to
the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how to
reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct the
dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case authors
are welcome to describe the particular way they provide for reproducibility. In the
case of closed-source models, it may be that access to the model is limited in some
way (e.g., to registered users), but it should be possible for other researchers to have
some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
31Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not
be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how to
access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confidence
intervals, or statistical significance tests, at least for the experiments that support the main
claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall run
with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula, call
to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error of
the mean.
32•It is OK to report 1-sigma error bars, but one should state it. The authors should preferably
report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality
of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or figures
symmetric error bars that would yield results that are out of range (e.g. negative error
rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster, or
cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute than
the experiments reported in the paper (e.g., preliminary or failed experiments that didn’t
make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: we ensured that our paper conforms with the NeurIPS Code of Ethics
Guidelines:
• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special considera-
tion due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: we do not foresee any special societal impact that arise due to our work
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g.,
deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied to
particular applications, let alone deployments. However, if there is a direct path to any
negative applications, the authors should point it out. For example, it is legitimate to point
out that an improvement in the quality of generative models could be used to generate
33deepfakes for disinformation. On the other hand, it is not needed to point out that a
generic algorithm for optimizing neural networks could enable people to train models that
generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is being
used as intended and functioning correctly, harms that could arise when the technology is
being used as intended but gives incorrect results, and harms following from (intentional
or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks, mecha-
nisms for monitoring misuse, mechanisms to monitor how a system learns from feedback
over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification:
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do not
require this, but we encourage authors to take this into account and make a best faith
effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has curated
licenses for some datasets. Their licensing guide can help determine the license of a
dataset.
•For existing datasets that are re-packaged, both the original license and the license of the
derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to the
asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
34Answer: [Yes]
Justification:
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their sub-
missions via structured templates. This includes details about training, license, limitations,
etc.
•The paper should discuss whether and how consent was obtained from people whose asset
is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: our work does not involve crowdsourcing nor research with human subjects
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribution
of the paper involves human subjects, then as much detail as possible should be included
in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or
other labor should be paid at least the minimum wage in the country of the data collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: our paper does not involve crowdsourcing nor research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
35