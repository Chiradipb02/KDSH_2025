Published in Transactions on Machine Learning Research (10/2024)
Undetectable Steganography for Language Models
Or Zamir orzamir@tauex.tau.ac.il
School of Computer Science
Tel Aviv University
Reviewed on OpenReview: https: // openreview. net/ forum? id= fq6aQoMSHz
Abstract
We introduce a cryptographic method to hide an arbitrary secret payload in the response of
a Large Language Model (LLM). A secret key is required to extract the payload from the
model’s response, and without the key it is provably impossible to distinguish between the
responses of the original LLM and the LLM that hides a payload. In particular, the quality
of generated text is not affected by the payload. Our approach extends a recent result of
Christ, Gunn and Zamir (2023) who introduced an undetectable watermarking scheme for
LLMs.
Prompt: Write an email asking my professor Prof. Hannity to not make the final exam in Machine
Learning 101 too difficult.
Response: Dear Professor Hannity,
I hope this email finds you well. I am writing to respectfully request that you consider the level of difficulty
for the final exam in Machine Learning 101. While I am confident in my understanding of the course
materials and have put in a significant amount of effort throughout the semester, I do have concerns about
the potential difficulty of the final exam.
As you may recall, several students in my previous sections of Machine Learning have found the final exam
to be very challenging, leading to frustration and disappointment. While I understand that the course is
intended to push students to their limits and beyond, I believe that some relaxation of the latter may be
in order.
I would kindly ask that you consider reducing the difficulty of the final exam or offering some additional
supports or resources to help students prepare. I believe that this could enhance the learning experience
Hidden Payload: OZ(Encoded as 10bits.)
Figure 1: We asked Llama 2 to write an email urging a professor for an easy exam, intended to be sent
anonymously. Nevertheless, the part of the response shown above secretly encodes the initials of the user
who used the LLM. This secret payload was encoded without modifying the response distribution at all.
1 Introduction
As the applications of machine learning models generating human-like text become widespread, concerns
for misuse proportionally rise. As detection of text generated by Large Language Models (LLMs) seemingly
approachesinfeasibility( JAML20 ;KSK+23;SKB+23;CBZ+23), theabilityto intentionally plant awatermark
in LLM-generated text becomes the most viable approach to differentiate LLM-generated from human-
generated text.
A long line of works showed that a watermark can be planted in LLMs by altering the output texts ( AF21;
QZL+23;YAJK23;MZ23;KGW+23a). Recently, Christ, Gunn and Zamir ( CGZ23) showed that a watermark
can be planted in LLM-outputs without altering the distribution of responses. Informally, CGZ show that any
LLM can be modified such that: 1) It is computationally infeasible to distinguish between the original and
1Published in Transactions on Machine Learning Research (10/2024)
the modified LLMs unless you hold a secret key, even when you are allowed to make many adaptive queries,
2) With the secret key, outputs of the modified LLM can be detected as watermarked. The importance of this
notion of undetectibility is that it formally guarantees that the quality of text does not degrade (or change at
all) in the process of planting the watermark.
In this work, we extend the watermarking scheme of CGZ to plant an arbitrary payload into the LLM
response, while still maintaining the same property of undetectability. This implies, for example, that an
LLM may secretly hide session-metadata (such as the user’s name, the time, or the prompt used) in the
response it gives. In particular, it can extend the ability of detecting text generated by the LLM to the
ability of also knowing whoused the LLM or whenthey did so. It also means that even an LLM running
off-line may use the responses it gives to covertly leak internal information to those who will later be exposed
to the seemingly-clean LLM responses. The main technical tool we use to transform the CGZ scheme from
watermarking to embedding a message, is incorporating a dynamic variant of Error Correcting Codes with
feedback.
The process of encoding a hidden message into a given channel (e.g., a picture or natural language) is called
Steganography and was extensively studied in many domains ( HvAL08;DIRR09;KJGR21 ;dWSK+22). The
unique property of our setting, though, is that in the case of LLM responses the distribution of the channel is
unknown. The hidden message should be recovered from the response of the LLM, without knowing what
the prompt used to generate the response was. In particular, the process of decoding the message must be
agnostic to the distribution of responses. Recent manuscripts ( FCT+23;WYC+23;YAK23) embed messages
in LLM responses, but do so by altering the distribution of responses, similar to the non-undetectable
watermarking schemes. In particular, those methods affect the response distribution and may degrade the
quality of generated text.
Under realistic assumptions which we verify empirically, the amount of hidden bits our scheme can encode in
an LLM output is linear in the length of the response, which is asymptotically optimal. Our scheme only
negligibly affects the complexity of the generation process and is thus easy and efficient to deploy. While
this paper is theoretical in nature and the properties of the suggested scheme are proven rigorously, we also
implemented the scheme and provide empirical examples. An open problem not addressed in this paper is
that our encoding scheme is not very robust to edits of the generated text, we discuss this in length in later
sections.
1.1 Organization of the paper
In Section 2 we give the formal definitions of the problem’s setting, and state the main theorems of this
paper rigorously. We also give the necessary preliminaries. In Section 3 we give a quick overview of the CGZ
watermark. In Section 4 we give an high-level overview of our scheme. Then, in Section 5 we introduce
a simple dynamic error correcting code with feedback, which we later use as a building block. Finally, in
Section 6 we give and analyze the full scheme. In Section 7 we discuss our implementation of the scheme
and some empirical evaluation of it. In Section 8 we discuss limitations of our scheme, and in particular
robustness to editing. We follow with open problems and conclusions.
2 Model and Preliminaries
Many of the notions in this section are adapted from ( CGZ23), the last subsection contains our new definitions
and theorems for Steganography in LLMs.
2.1 Preliminaries
Letλbethesecurityparameter, wedenoteby negl(λ)anyfunctionthatisin O/parenleftig
1
p(λ)/parenrightig
foreverypolynomial p(·).
As is standard in Cryptography research, we think of λas the “key size", and of running times that are
super-polynomial in λas “infeasible". We denote by logandlnthe logarithm with base two and the natural
logarithm, respectively. For a sequence s= (...,si,...)we denote by s[i:j]the sub-sequence (si,...,sj).
The Hamming distance between two vectors is defined as the number of indices on which they differ, that
2Published in Transactions on Machine Learning Research (10/2024)
is∆(z,z′) :=|{i|zi̸=z′
i}|. We denote by x||ythe concatenation of the vectors x,y, and by len(v)the
dimension of the vector v.
Pseudorandom function (PRF). LetF={Fk:{0,1}ℓ1(λ)→{0,1}ℓ2(λ)|k∈{0,1}λ}be a family of
functions.Fis a PRF if Fkis efficiently computable and for all probabilistic polynomial-time distinguishers
D,
/vextendsingle/vextendsingle/vextendsingle/vextendsinglePr
k←{0,1}λ/bracketleftig
DFk(·)(1λ) = 1/bracketrightig
−Pr
f/bracketleftig
Df(·)(1λ) = 1/bracketrightig/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤negl(λ)
wherefdenotes a random function from {0,1}ℓ1(λ)to{0,1}ℓ2(λ). PRFs are a standard cryptographic primitive
equivalent to one-way functions and can be constructed from standard assumptions ( GGM86;HILL99).
Intuitively, a PRF is simply a function that is indistinguishable from a totally random function without
knowledge of the secret key kthat parameterizes it.
2.2 Language Models
We adapt the definition of ( CGZ23) for language models, which in turns follows that of ( KGW+23b). We
will often refer to language models simply as models.
Definition 2.1. A language model Modelover token setTis a deterministic algorithm that takes as input a
prompt prompt and tokens previously output by the model x= (x1,...,xi−1), and outputs a probability
distribution pi=Model (prompt,x)overT.
A language model Modelis used to generate text as a response to a prompt by iteratively sampling from the
returned distribution until a special terminating token done∈Tis drawn.
Definition 2.2. A language model’s response toprompt is a random variable Model (prompt )∈T⋆that is
defined algorithmically as follows. We begin with an empty list of tokens x= (). As long as the last token
inxis not done, we draw a token xifrom the distribution Model (prompt,x)and append it to x. Finally,
we set Model (prompt ) =x.
We assume that our model never outputs text of length super-polynomial in λ.
2.3 Entropy and Empirical Entropy
For a probability distribution Dover elements of a finite set X, the Shannon entropyofDis
H(D) =E
x∼D[−logD(x)],
whereD(x)is the probability of xin the distribution D. Theempirical entropy (also known as Shannon
information) of xinDis simply−logD(x). The expected empirical entropy of x∼DisH(D).
The following definition of empirical entropy of a model’s response is taken from (CGZ23).
Definition 2.3. For a language model Model, a prompt prompt, and a possible response x∈T⋆, we define
theempirical entropy ofModelresponding with xtoprompt, denoted by He(Model,prompt,x), as
−log Pr/bracketleftig
Model (prompt ) =x/bracketrightig
.
Note that in expectation, Definition 2.3 simply captures the entropy in the response generation. That is, we
have
E
x[He(Model,prompt,x)] =H/parenleftbig
Model (prompt )/parenrightbig
,
wherex∼Model (prompt ).
The following definition naturally generalizes empirical entropy from whole outputs to substrings out of a
model’s output.
3Published in Transactions on Machine Learning Research (10/2024)
Definition 2.4. For a language model Model, a prompt prompt, a possible response x∈T⋆, and indices
i,j∈[|x|]withi≤jwe define the empirical entropy on substring [i,j]ofModelresponding with xtoprompt
as
H[i,j]
e(Model,prompt,x) :=
−log Pr/bracketleftig
Model (prompt ) [i:j] =x[i:j]|
Model (prompt ) [1 : (i−1)] =x[1 : (i−1)]/bracketrightig
.
2.3.1 Empirical Entropy in Natural Language
Studies in linguistics ( GC02;CLA17;SL22) conclude that in natural language the entropy per unit of text
(e.g., a word) is usually constant throughout the text. In particular, the empirical entropy of a LLM response
is expected to be linear in the length of the text, and roughly uniformly distributed among the different
tokens that assemble the response. This intuition was empirically verified by ( CGZ23). We reaffirm the above
in Section 7 in which we also run empirical evaluations.
2.4 Steganography for LLMs
In this section we finally define rigorously steganography for language models. We first explain the definition
intuitively. During the setup of the scheme, we generate a secret key kof sizeλ. To generate a response, we
use a method Stegkthat together with the key k, receives a prompt prompt and a secret message payload .
A retrieval method Retrkshould be able to retrieve the hidden payload from an output generated using Stegk,
while also using the secret key k.
Definition 2.5 (Steganography Scheme) .Asteganography scheme for a model ModeloverTis a tuple of
algorithmsW= (Setup,Steg,Retr)where:
•Setup (1λ)→koutputs a secret key, with respect to a security parameter λ.
•Stegk(prompt,payload )is a randomized algorithm that takes as input a prompt prompt and a
payload payload , and generates a response in T⋆.
•Retrk(x)→T⋆is an algorithm that takes as input and returns as an output sequences in T⋆.
The most important property of the steganography scheme we present in this paper is undetectability .
Intuitively, we require that without knowledge of the secret key, Stegk(prompt,⋆)andModel (prompt )are
indistinguishable even to a user allowed to make many adaptive queries. The payloads used in Stegkdo not
affect this property.
Definition 2.6 (Undetectability) .A steganography scheme W= (Setup,Steg,Retr)isundetectable if for
every security parameter λand all polynomial-time distinguishers D,
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglePr[DModel,Model(1λ)→1]−
Pr
k←Setup (1λ)[DModel,Stegk(1λ)→1]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤negl(λ),
where the notation DO1,O2means that Dis allowed to adaptively query both O1andO2with arbitrary
prompts.
Another important desired property is that Retrkshould succeed in retrieving the payload from the output
ofStegk(prompt,payload ). Such a successful retrieval inherently requires making assumptions on the length
of the payload and the entropy of the model. It is for example impossible to encode an arbitrary payload
4Published in Transactions on Machine Learning Research (10/2024)
longer than the output in the output, or to plant any payload at all in a deterministic model (thus, without
any entropy) while remaining undetectable. The best possible result is thus encoding He(Model,prompt,x)
bits of payload in an output x←Stegk(prompt,payload ), this is because the empirical entropy of an
output exactly quantifies the number of entropy bits used for its generation.
We achieve the above best-possible bound asymptotically yet we require two additional technical conditions.
First, we can plant payloads only when He(Model,prompt,x) = Ω(λ). Intuitively, this is because outputs
with a very low empirical entropy (with respect to the security parameter) show up too frequently and thus
can’t be modified while maintaining undetectability. The necessity of this condition, that also appeared in
the CGZ result, is proven in ( CGZ23). Second, we require that the empirical entropy is spread somewhat
uniformly throughout the output x. This appears to be necessary for technical reasons (e.g., avoiding a
scenario in which the empirical entropy is high solely due to a single very-low-probability token in the
response), yet could potentially be relaxed in future works. As discussed in Section 2.3.1 and empirically
reaffirmed in Section 7, this condition is satisfied by natural language in which the entropy is roughly constant
per each unit of text.
A semi-formal version of the theorem follows, the formal one appears in Section 6.
Theorem (Informal version of Theorem 6.3) .Fix a model Model. Let prompt,payload be strings. Condi-
tioned on the empirical entropy of a response ygenerated by Stegk(prompt,payload )being high enough ,
the expected length of the prefixes of payload andRetrk(y)that identify is at least Θ(len(y)).
The definition of high enough , formally stated in Section 6, roughly means that for any consecutive part of
the response consisting of a large enough number rof tokens, the empirical entropy in that part is at least
the square root ˜Ω (√r)of the length. As discussed in Section 2.3.1 and verified empirically in Section 7, in
natural language we actually expect the entropy to grow linearlywith the length of the text, much higher
than the required square root. Under this condition, the theorem guarantees that a response of length Lwill
allow retrieving the first Θ(L)bits of the payload , which is (up to constants) the best possible.
3 Overview of the CGZ Watermark
This section is adapted in its entirety from CGZ ( CGZ23), and contains a high-level description of their
watermarking scheme.
We first simplify the definition of a language model (Definition 2.1) by assuming that the token set is
binary,T={0,1}. We may assume this without loss of generality due to a straightforward reduction that
appears in Section 4.1 of CGZ. We will implicitly use this reduction throughout our work as well.
The intuitive idea behind the CGZ watermark is planting a watermark not by changing the model’s
distribution, but by correlating the randomness used by the model with the secret key. We begin by describing
a simplified approach that works only for generating a single response, of length bounded by some parameter L.
Letk= (k1,k2,...,kL)be the secret key, chosen by drawing each kiuniformly and independently from [0,1].
To generate a response to a prompt prompt, we run the model as intended yet use kito determine the
random choice in the i-th response token generation. Let pidenote the probability, according to the real model
with the previously chosen tokens as prefix, of the i-th token being 1. The watermarked model outputs xi= 1
ifki≤piandxi= 0otherwise. Crucially, as kiwas chosen uniformly, the probability of xi= 1is exactlypi
and hence the output distribution of the model is not affected at all. On the other hand, we now expect some
correlation between xiandki.
For each response bit xi, the detection algorithm may compute the following score, that depends on the key
and on the response but not on the prompt, the model, or the distributions pi,
s(xi,ki) =/braceleftigg
ln1
kiifxi= 1
ln1
1−kiifxi= 0.
5Published in Transactions on Machine Learning Research (10/2024)
Given a string x= (x1,...,xℓ), the detection algorithm sums the score of all bits
c(x) =ℓ/summationdisplay
i=1s(xi,ki).
The main observation is that the score is higher in responses generated by the above procedure than
it is for unrelated strings. In non-watermarked text, the value of kiis independent of the value of xi.
Therefore,s(xi,ki)is simply an exponential random variable with mean 1:
E
ki[s(xi,ki)] =/integraldisplay1
0ln(1/x)dx= 1,
and we have Ek[c(x)−|x|] = 0. For watermarked responses, on the other hand,
E
ki[s(xi,ki)] =/integraldisplaypi
0ln1
xdx+/integraldisplay1
piln1
1−xdx
=/integraldisplaypi
0ln1
xdx+/integraldisplay1−pi
0ln1
xdx
= 1 +−pi·lnpi−(1−pi)·ln(1−pi)
= 1 + ln(2)·H(pi),
and the total expected score is
E
k[c(x)−|x|] = ln 2·H(Model (prompt )).
We thus observed that at least in expectation, the score of watermarked texts is larger than that of arbitrary
texts, and that the difference between those quantities is roughly the entropy in the response. To make this
observation algorithmically useful, considering expectations is not sufficient, as we need to set some score
threshold for detection and analyze the probability of the score passing this threshold in each of the two cases.
This analysis will not be repeated in this short overview and appears in CGZ.
To avoid having an upper bound Lon the length of the response, and to reduce the length of the key k, we
use a Pseudo-Random Function F(PRF, as defined in Section 2). The key will now simply be a random
string of length λ, and we would implicitly set ki:=Fk(i). By the definition of a PRF, those values are
indistinguishable from independently chosen random values.
The final obstacle is remaining undetectable even when many queries are allowed. In the above sketch the
choice of the key kfully determines all randomness, and thus for example the same prompt will always get the
same response. To overcome this hurdle, we begin the generation of each response with using real randomness
(and not the key) to sample tokens, while counting the empirical entropy of the response prefix generated
so far. When the response prefix passes a threshold of empirical entropy λ, we denote the response’s prefix
asrand start running the previous scheme with ras an additional input to the PRF. That is, after we set
the prefixrwe use the value Fk(r,i)to generate the i-th token. In the detection, we will enumerate over all
possible prefixes of the response as r. In CGZ, it is shown that because the prefix ris set only after enough
entropy was used, it has negligible probability to ever repeat itself in different queries. Thus the inputs to the
PRF calls are each unique and the scheme becomes undetectable even with many queries being made.
The pseudo-codes for generation (Algorithm 1) and detection (Algorithm 2) of the watermark appear in the
Appendix. In CGZ, those algorithms are then generalized to also support the detection of the watermark
from a substring out of the response and not only from the response in its entirety as is sketched above.
4 High-Level Overview of Our Scheme
In this section we give an overview of our construction, with the rigorous details appearing in Sections 5
and 6. As in the CGZ overview in Section 3, we again assume without loss of generality that the token space
is binary.
6Published in Transactions on Machine Learning Research (10/2024)
Algorithm 1: Watermarking algorithm Watk
Data:A prompt ( prompt) and a secret key k
Result: Watermarked text x1,...,xL
i←1;
H←0;
while done/∈(x1,...,xi−1)do
pi←Model (prompt,x1,...,xi−1);
ifH <λthen
// Collect more internal entropy
Sample (xi,p)←(1,pi)with probability pi, otherwise (0,1−pi);
H←H−logp;
ifH≥λthen
r←(x1,...,xi);
end
else
// Embed the watermark
xi←1[Fk(r,i)≤pi];
end
i←i+ 1;
end
Algorithm 2: Detector Detectk
Data:Textx1,...,xLand a secret key k
Result: True or False
fori∈[L]do
r(i)←(x1,...,xi);
Definev(i)
j:=xj·Fk(r(i),j) + (1−xj)·(1−Fk(r(i),j))forj∈[L];
if/summationtextL
j=i+1ln(1/v(i)
j)>(L−i) +λ√
L−ithen
returnTrue;
end
end
returnFalse;
As a first attempt, we notice that one may generalize any watermark into a steganography scheme by using
several keys. Let k1,...,kmbemdifferent secret keys, and setup a watermarking scheme with each of them.
To encode a message i∈[m]within a response, simply use the watermarking instance corresponding to kito
generate said response. In the retrieval step, we will use the detection algorithm with everykeykjto find
which of them was used. While undetectability is trivially preserved, as we only use undetectable watermarks
to generate responses, the scheme becomes infeasible as soon as misn’t very small. This is because both the
rate of “false-positives" and the detection time grow by a multiplicative factor of m. In particular, encoding ℓ
bits of information will cause a multiplicative factor of 2ℓin the running time of the retrieval algorithm, and
will also require that the false-positive rate of the watermarking scheme be much smaller than 2−ℓ.
A reasonable next step then, is breaking up the payload into smaller parts (say, characters or bits), and
encoding each of those parts separately in a similar fashion to the previous suggestion. One subtle issue to
overcome while implementing this idea is that partitioning the response into those smaller chunks is not
straightforward. This is because we know a successful watermarking requires high empirical entropy, and it
is not known in advance what parts of the response would contain high empirical entropy. Moreover, the
retriever needs to be able to use the same partition as the steganography algorithm. We solve this problem
by implicitly defining the partition to chunks using the detection score itself: Let tbe some score threshold
to be decided later. Denote the first bit of the payload by b∈{0,1}. We start planting the payload in
the same way as the CGZ watermark is embedded, but with bas an additional input to the PRF. That is,
7Published in Transactions on Machine Learning Research (10/2024)
the randomness used in the i-th token is Fk(i,b). The retriever would compute the scores for both options
ofbover more and more tokens until one of the two scores passes a certain threshold determined by t. For
example, we can consider the minimal prefix of the response x[:i]for which (c(x[:i])−i)/√
i>twith respect
to the score computed with either b= 0orb= 1. Crucially, both StegkandRetrkcan compute those scores,
so both can compute the index iin which one of the scores passed the threshold for the first time. Thus,
both are able to agree on the end of the chunk encoding the first bit of the payload, and thus can iteratively
restart this process with the next bit of the payload and so on. Following the CGZ analysis, a threshold of
roughlyt≈λis required to make sure the correct bit is always the first one to pass the score threshold, as
otherwise the false-positive rate of passing the score threshold is non-negligible. This means that whilst the
decoding time and general error rate are now low enough, we still can’t encode payloads that are too long.
Even if every token contains constant entropy, only Θ(L/λ)bits of the payload can be encoded in a response
of lengthL. Sinceλis rather large, we should desire to get this quantity down to the optimal Θ(L).
Finally, we use Error Correcting Codes (ECC) to lower the threshold tand in turn increase the number of
hidden payload bits. Intuitively, if instead of setting t≈λwe settto be a large constant, then false-positives
do happen, but only with a small constant probability. Thus, if instead of encoding the bits of the payload
itself, we would encode the bits of an ECC applied to the payload, we should be able to recover the payload
even if a constant fraction of the bits were transmitted incorrectly. This would reduce tfromλtoO(1)as
desired. A problem that remains is that applying a standard ECC “scrambles" the message and thus if only a
prefix of the code is successfully hidden then it would be impossible to decode anything out of the payload.
For this reason, in Section 5 we define and construct a Dynamic ECC, this is a code in which for every i, the
firstibits of the code can be used to retrieve the first Θ(i)bits of the message. Thus, a response of size L
would hide the first Θ(L)bits of the payload. To significantly simplify the construction of the ECC, we use
the fact our construction provides noiseless feedback . As mentioned before, during the encoding process, Stegk
can also simulate Retrkand thus knows what bit will be detected by the retriever at each step. Thus, the
ECC can depend on whether or not each previously sent bit was transmitted correctly. In the construction of
Section 5 we actually use a ternary code alphabet rather than binary, which doesn’t affect the sketch of the
construction much.
We finally note that to support multiple queries, we use the same idea of CGZ sketched in Section 3, and
begin by observing enough real entropy to set a unique prefix r, the following random choices will be made
usingFk(r,i,b). For the detector to find the correct prefix to use as r, we need to use the first λbits of
entropy after setting the prefix to place a normal watermark, which the detector would use to verify the
choice ofr. This means that to be undetectable with many queries, we start encoding the payload only after
the first Θ(λ)tokens (or bits of entropy). As long as L= Ω(λ)this does not matter asymptotically.
5 Dynamic Error Correcting Code
Error Correcting Codes (ECCs) are the means to compensate for errors in the transmission of messages. An
ECCencodingisafunction Enc: Σk→Γnfrommessagesoflength koveralphabet Σ, tocodewordsoflength n
over alphabet Γ. Therateof a code is R(Enc) :=k
n, which signifies how efficient the code is. The (relative)
distance of a code is δ(Enc) :=1
nminz̸=z′Enc(z)∆Enc(z′), which is twice the fraction of corrupt indices in a
codeword that still allows decoding it to the original message. A code (or a family of codes) is considered
goodif both its rate and distance are constant, which means that the length of messages is only expanded by
a constant factor, yet a constant fraction of errors can be corrected. ECCs are extensively studied and it is
long known that good ECCs can be constructed, even when Σ = Γ = F2. (Ham50;Gil52;Var57;Jus72;SS96)
An ECC with feedback is an ECC in which we transmit the symbols of the codeword Enc(x)one-by-one, and
immediately receive feedback with regards to whether an error occurred in transmitting this symbol. The
following symbols we submit may adaptively depend on the feedback received so far. We say that the feedback
isnoiseless if the feedback received is always reliable. If the errors in transmission occur randomly (i.e.,
each transmitted symbol has the same probability of becoming corrupted), then it turns out that noiseless
feedback does not improve the parameters of the best possible ECC. On the other hand, if the small fraction
of corrupted symbols is chosen adversarially, then noiseless feedback does improve the best possible distance.
Feedback also appears to allow simpler and more efficient encoding and decoding schemes. (Ber64; Cov88)
8Published in Transactions on Machine Learning Research (10/2024)
We define a natural generalization of ECCs, in which the length of the message (and hence also of the code)
is not known in advance. We call those Dynamic ECCs. We would require that for anyk′≤k, the firstk′
symbols of the message can be decoded from the first O(k′)symbols of the codeword, even if a small fraction
of those codeword symbols are corrupted. This definition is similar yet weaker than the definition of Tree
Codes (Sch93; Sch96).
Definition 5.1. For alphabets Σ,Γa family{Enck}k∈Nof functions Enck: Σk→Γ⋆is called a Dynamic
ECC if for every k∈N, the function Enck: Σk→Γnkis an ECC, where
Enck(x) :=Enc1(x[: 1])||Enc2(x[: 2])||...||Enck(x),
nk:= max
x∈Σklen(Enck(x)).
In simple words, a Dynamic ECC is a family of standard ECCs where the codeword corresponding to the a
prefix of a message, is always a prefix of the codeword corresponding to the entire message.
Definition 5.2. The rate of a Dynamic ECC is R(Enc) :=infk∈NR(Enck) =infk∈Nk
nk. The distance of it
isδ(Enc) := infk∈Nδ(Enck).
In a similar manner, we also define a Dynamic ECC with (noiseless) feedback to be a Dynamic ECC in which
after each symbol transmitted we receive a feedback as to which symbol was received. We next present a
simple construction of a Dynamic ECC with feedback where |Σ|= 2,|Γ|= 3, and both the rate and distance
are constant. This construction is rather straightforward and is similar to constructions used in slightly
different settings (EGH15).
Theorem 5.3. For anyε∈(0,1
2)there exists a Dynamic ECC with noiseless feedback with |Σ|= 2,|Γ|= 3,
in whichεfraction of errors can be corrected and nk=⌈k
1−2ε⌉. Both encoding and correction take linear time.
We think of the message alphabet as binary Σ ={0,1}, and to the codeword alphabet we add an additional
symbol Γ ={0,1,←}. We would think of the symbol ’ ←’ as a “backspace". Intuitively, we will always
compute the message that is the decoding of what the receiver saw so far, and if it is consistent with the
input we simply send the next bit of the input. If it is not consistent with input, we will send a “backspace"
to indicate that the last symbol is incorrect. We will do so iteratively.
For a sequence y= (y1,...,yn)∈Γ⋆, we recursively define decode (y)to bedecode (y[: (n−1)])||(yn)
ifyn∈{0,1}, anddecode (y[: (n−1)])[:−1]ifyn=′←′, wherev[:−1]means removing the last symbol from
the vectorv(unless its empty). As the base case, we have decode (()) = ().
For a message x= (x1,...,xk)∈Σ⋆and a previously transmitted (partial) codeword y= (y1,...,yn)∈Γ⋆
we define the longest agreeing prefix of xand the decoding of yas
last(x,y) := max
i{i|x[:i] =decode (y)[:i]}.
We then define the length of the wrong suffix of the decoding of yassuff(x,y) :=len(decode (y))−last(x,y).
Given a message xand partial codeword y, we define the next symbol to be sent as next(x,y) =′←′
ifsuff(x,y)>0, and as next(x,y) =x[last(x,y) + 1]otherwise. Our protocol is thus simple, if xis the
message and yis the codeword received by the receiver so far (which we know using the noiseless feedback),
then the next symbol we send is next (x,y).
Lemma 5.4. Letx∈Σ⋆be a message and y∈Γnbe a partial codeword received by the receiver according to
the described protocol, and assume that at most εnof the symbols in ywere received differently than sent by
the protocol. Then, last (x,y)≥(1−2ε)n.
Proof.For any partial received codeword y′we define the potential function Φ(x,y′) :=last(x,y′)−suff(x,y′).
We first show that if the next token is received correctly then the potential increases by one, that
is,Φ(x,y′||next(x,y′)) = Φ(x,y′) + 1. We show this by considering two cases. If suff(x,y′) = 0
thendecode (y′) =x[:last(x,y′)]andnext(x,y′) =x[last(x,y′) + 1], thusdecode (x,y′||next(x,y′)) =
9Published in Transactions on Machine Learning Research (10/2024)
x[:last(x,y′) + 1]. Otherwise, suff(x,y′)>0andnext(x,y′) =′←′, and hence suff(x,y′||next(x,y′)) =
suff(x,y′)−1.
Next, we show that if the next token is received incorrectly then the potential decreases by one, that
isΦ(x,y′||s) =max(0,Φ(x,y′)−1)whenevers̸=next(x,y′). We again consider two cases. If suff(x,y′)>0
then we have s∈{0,1}and in turn suff(x,y′||s) =suff(x,y′) + 1. Otherwise suff(x,y′) = 0and we either
have suff (x,y′||s) = 1ifs̸=′←′or have last (x,y′||s) = max(0,last(x,y′)−1)ifs=′←′.
We conclude that if eout of thensymbols in ywere received incorrectly, then
Φ(x,y)≥1·(n−e)−1·e=n−2e≥n−2·εn.
On the other hand, as suff (x,y)≥0we also have last (x,y′)≥Φ(x,y′).
Proof of Theorem 5.3. Denote by nk=⌈k
1−2ε⌉. Letxbe a message and ythe firstnktokens received by
running the protocol. Assume that at most εnkout of those tokens were received incorrectly. By Lemma 5.4,
we have
last(x,y)≥(1−2ε)nk≥k.
Hence, decode (y)[:k]correctly retrieves x[:k].
6 Our Scheme
As in the overview of Section 3, we begin by analysing a scheme in which only a single query is undetectable.
Then, in Section 6.1 we apply the same idea of CGZ to go from undetectability for one query to complete
undetectability. An intuitive explanation of our scheme is covered in Section 4.
Algorithm 3: One-query steganography algorithm Stegk
Data:A prompt ( prompt), a payload ( payload ), and a secret key k
Result: Responsex1,...,xL
i←1;
code←();
scoreσ←0forσ∈{0,1,←};
score_len←0;
next←next(payload,code);
while done/∈(x1,...,xi−1)do
pi←Model (prompt,x1,...,xi−1);
xi←1[Fk(i,next)≤pi];
score_len←score_len + 1;
forσ∈{0,1,←}do
scoreσ←scoreσ+s(xi,Fk(i,σ));
if(scoreσ−score_len )/√score_len>tthen
code←code||(σ);
scoreσ←0forσ∈{0,1,←};
score_len←0;
next←next(payload,code);
break;
end
end
i←i+ 1;
end
Algorithm 3 naturally follows the sketch of Section 4, while using the ECC (and notation) of Section 5.
Let’s informally describe the algorithm in words. The algorithm depends on a score threshold tto be set
10Published in Transactions on Machine Learning Research (10/2024)
later. We apply the Dynamic ECC to the message payload , and denote by nextthe next symbol we are
supposed to transmit according to the ECC. We start generating response tokens following the CGZ scheme,
by comparing the actual distribution pito the PRF value Fk(i,next). As the PRF value depends on next, a
correlation between the randomness we use and the token we are attempting to transmit is created. After
each generated response token, we also emulate the retriever: Ignoring our knowledge of next, for every code
symbolσ∈{0,1,←}we compute the score (as defined in Section 3) of the response tokens we saw so far.
We wait until the score of a some symbol σ, normalized with respect to the number of tokens involved in the
score computation, passes a threshold t. That is, until
scoreσ−score_len√score_len>t.
When this happens, we view σas the symbol received by the ECC receiver. While σ=nextis supposed
to be more likely, the symbol could be incorrect. Whenever we add a symbol to the code, we restart our
computation of the score and start transmitting the next code symbol. Algorithm 4 shows the retrieval
process, which is identical to what is emulated within the steganography algorithm. Note that both algorithms
have a linear running time.
Algorithm 4: One-query retriever Retrk
Data:Responsex1,...,xL, and a secret key k
Result: Retrieved payload payload
code←();
scoreσ←0forσ∈{0,1,←};
score_len←0;
fori= 1,2,...,Ldo
score_len←score_len + 1;
forσ∈{0,1,←}do
scoreσ←scoreσ+s(xi,Fk(i,σ));
if(scoreσ−score_len )/√score_len>tthen
code←code||(σ);
scoreσ←0forσ∈{0,1,←};
score_len←0;
break;
end
end
end
returndecode (code);
We first observe that the distribution of the response is indistinguishable from the distribution of the original
model (when a single query is made).
Lemma 6.1. For any Modeland any prompt,payload,t, the distribution of Stegk(prompt,payload )
over a random choice of key kis indistinguishable from the distribution of Model (prompt ).
Proof.The proof is rather straightforward and follows CGZ and its overview in Section 3. If we replace each
timeFk(i,next)is used (to determine xi) with a new uniformly chosen value in [0,1], then the distribution
ofModelis completely unaffected. Using a PRF instead of “fresh" random values is indisitinguishable as
long as we don’t use the PRF on the same input more than once. As each input to the PRF consists of the
(unique) index i, we never call it on the same input.
We should next show that Retrk(Stegk(prompt,payload ))successfully retrieves payload . As discussed in
Section 2.4, doing so requires making assumptions on the empirical entropy of the generated response. We
prove that a relatively weak assumption (which in particular covers the case of natural languages) is sufficient,
11Published in Transactions on Machine Learning Research (10/2024)
yet it is very likely that the proof can be adapted for other conditions as well - as the algorithm itself is quite
flexible. We also note that in the proof we don’t optimize for constants but for simplicity (of proof), the
empirical evaluation in Section 7 implies that the actual constants are far better than in the following proof.
Definition 6.2. Leth= (h1,...,hL)be a sequence of empirical entropies (i.e., non-negative numbers). We
say thathisr0-saturated if for every consecutive subsequence of hof lengthr≥r0, the sum of entropies is
at least 10√rlnr. That is, for every r≥r0and1≤i≤L−(r−1), we have/summationtexti+r−1
j=ihj≥10√rlnr.
For example, if the empirical entropy in each consecutive block of btokens is at least some constant α>0,
then the empirical entropies are ˜O/parenleftig
b2
α2/parenrightig
-saturated. This is because a consecutive block of bktokens contains
at leastαkentropy, which is larger than 10√
bkln(bk)ifk=˜Ω/parenleftbigb
α2/parenrightbig
. Hence, natural language which has this
property (as discussed in Section 2.3.1) is O(1)-saturated. In fact, the entropy of natural language grows
linearly with the length of the text, while our condition is merely for it to grow faster than the square root of
the length of the text. We verify these claims empirically in Section 7.
Finally, we prove that if the empirical entropy of a response is O(1)-saturated, and the response is of length L,
then in expectation at least the first Θ(L)bits of the payload are retrieved correctly.
Theorem 6.3. Fix a model Modeland an integer r0, there exists a choice of threshold tfor which the
following holds. Let prompt,payload be strings. Conditioned on the empirical entropy of a response y
generated by Stegk(prompt,payload )beingr0-saturated, the expected length of the prefixes of payload
andRetrk(y)that identify is at least Θ(len(y)/r0).
The proof of Theorem 6.3 is deferred to Appendix A.
6.1 Complete Undetectability
To move from undetectability of a single response to the general undetectability defined in Definition 2.6, we
simply repeat the “trick" of CGZ as overviewed in Section 3. The complete details are deferred to Appendix B.
7 Empirical Evaluation
We implemented1Algorithms 3 and 4 from Section 6, that provide undetectability for a single query. We did
so for simplicity and as we only aim to evaluate the new contributions of this paper.
In Figure 2, we estimate the number of message bits we can hide in a response of a certain length. For
each length of response, we ran our scheme for 100times using the LLM model GPT-2 ( RWC+19) on a
randomly chosen prompt from the list of example prompts provided by OpenAI on their GPT-2 webpage.2
We ran it with threshold parameter t= 2, which we didn’t optimize. As expected, it is evident that the
number of hidden bits grows linearly with the length of the response. In Figure 3, we detail the decoding
process of the example shown in Figure 1, generated using the 7B parameters Instruct version of the Llama 2
model developed by Meta ( TMS+23). We did not optimize for constants. The takeaways from this section
are twofold; First, we show that the implementation of our scheme is simple and the run-time overhead is
minimal; Second, we empirically support the claim from Section 2.3.1 that the empirical entropy in LLMs
grows linearly with the length of the response.
8 Limitations and Open Problems
The main issue we did not discuss so far is robustness to editing. That is, can the payload be recovered even
if the model’s response is somehow edited? We mainly leave dealing with robustness to future work, yet next
list a couple of observations regarding robustness. In CGZ ( CGZ23), the watermarking scheme is adapted to
“restart" once-in-a-while so that the watermark will be detectable from any long enough consecutive substring
of the response (and not only from the entire response). The same modification can easily be applied to
1Code available at: https://github.com/OrZamir/steg
2https://openai.com/research/better-language-models
12Published in Transactions on Machine Learning Research (10/2024)
20 40 60 80 10005101520
4.198.0111.6514.7517.87
Response length, in tokens.Hidden payload length, in bits.
Figure 2: Plot of the number of successfully hidden payload bits, by length of response. Experiments ran on
GPT-2 with a random choice of an example prompt taken from the OpenAI website. The experiment was
performed 100 times for each response length.
Prompt: Write an email asking my professor Prof. Hannity to not make the final exam in Machine
Learning 101 too difficult.
Response: DearProfessorHannity,
Ihopethisemailfindsyouwell.Iamwritingtorespectfullyrequestthatyouconsiderthelevelofdifficulty
forthefinalexaminMachineLearning101.WhileIamconfidentinmyunderstandingofthecourse
materialsandhaveputinasignificant 0 amountofeffortthroughoutthesemester, Ido 1have 1
concerns 0 aboutthepotential 1difficulty←ofthefinalexam.
Asyoumayrecall,severalstudentsinmyprevioussectionsof←Machine 1 Learninghavefoundthe
finalexamtobeverychallenging 1,leadingtofrustration 1and←disappointment 0 .WhileI←
understandthatthecourseisintendedtopushstudentstotheirlimitsandbeyond,Ibelievethatsome
relaxationofthelatter 1maybeinorder.
Iwouldkindlyaskthatyouconsiderreducingthedifficultyofthefinalexamorofferingsomeadditional
supportsor 1resourcestohelpstudentsprepare.I 0believethatthiscould 1 enhance 0
Error Correcting Code: 01101←←111←0←11010
Hidden Payload: “OZ", encoded as 01111 11010.
Figure 3: A breakdown of the decoding algorithm for the example in Figure 1.
our scheme as well, making the payload retrievable from any long enough substring out of the model’s
response. At the other end of the spectrum, it is known that under certain conditions powerful users can
edit any watermark out of a model’s response ( ZEF+23;CGZ23). Intuitively, a complete rephrasing of the
response, for example, is supposed to remove any watermark. The previous empirical works on watermarks
and steganography, that do not guarantee undetectability, showcase some robustness to certain types of edits.
References
[AF21]Sahar Abdelnabi and Mario Fritz. Adversarial watermarking transformer: Towards tracing text
provenance with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP) , pages
121–140. IEEE, 2021.
[Ber64]Elwyn R Berlekamp. Block coding with noiseless feedback . PhD thesis, Massachusetts Institute
of Technology, 1964.
13Published in Transactions on Machine Learning Research (10/2024)
[CBZ+23]Souradip Chakraborty, Amrit Singh Bedi, Sicheng Zhu, Bang An, Dinesh Manocha, and Furong
Huang. On the possibilities of AI-generated text detection. arXiv preprint arXiv:2304.04736 ,
2023.
[CGZ23] Miranda Christ, Sam Gunn, and Or Zamir. Undetectable watermarks for language models.
arXiv preprint arXiv:2306.09194 , 2023.
[CLA17] Ruina Chen, Haitao Liu, and Gabriel Altmann. Entropy in different text types. Digital
Scholarship in the Humanities , 32(3):528–542, 2017.
[Cov88] Thomas M Cover. The role of feedback in communication. In Performance Limits in Commu-
nication Theory and Practice , pages 225–235. Springer, 1988.
[DIRR09] Nenad Dedić, Gene Itkis, Leonid Reyzin, and Scott Russell. Upper and lower bounds on
black-box steganography. Journal of Cryptology , 22:365–394, 2009.
[dWSK+22]Christian Schroeder de Witt, Samuel Sokota, J Zico Kolter, Jakob Foerster, and Martin
Strohmeier. Perfectly secure steganography using minimum entropy coupling. arXiv preprint
arXiv:2210.14889 , 2022.
[EGH15] Klim Efremenko, Ran Gelles, and Bernhard Haeupler. Maximal noise in interactive communica-
tion over erasure channels and channels with feedback. In Proceedings of the 2015 Conference
on Innovations in Theoretical Computer Science , pages 11–20, 2015.
[FCT+23]Pierre Fernandez, Antoine Chaffin, Karim Tit, Vivien Chappelier, and Teddy Furon. Three
bricks to consolidate watermarks for large language models. arXiv preprint arXiv:2308.00113 ,
2023.
[GC02]Dmitriy Genzel and Eugene Charniak. Entropy rate constancy in text. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics , pages 199–206, 2002.
[GGM86] Oded Goldreich, Shafi Goldwasser, and Silvio Micali. How to construct random functions.
Journal of the ACM (JACM) , 33(4):792–807, 1986.
[Gil52]Edgar N Gilbert. A comparison of signalling alphabets. The Bell system technical journal ,
31(3):504–522, 1952.
[Ham50] Richard W Hamming. Error detecting and error correcting codes. The Bell system technical
journal, 29(2):147–160, 1950.
[HILL99] Johan Håstad, Russell Impagliazzo, Leonid A Levin, and Michael Luby. A pseudorandom
generator from any one-way function. SIAM Journal on Computing , 28(4):1364–1396, 1999.
[HvAL08] Nicholas Hopper, Luis von Ahn, and John Langford. Provably secure steganography. IEEE
Transactions on Computers , 58(5):662–676, 2008.
[JAML20] Ganesh Jawahar, Muhammad Abdul-Mageed, and Laks VS Lakshmanan. Automatic detection
of machine generated text: A critical survey. arXiv preprint arXiv:2011.01314 , 2020.
[Jus72]Jørn Justesen. Class of constructive asymptotically good algebraic codes. IEEE Transactions
on information theory , 18(5):652–656, 1972.
[KGW+23a]John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.
A watermark for large language models. arXiv preprint arXiv:2301.10226 , 2023.
[KGW+23b]John Kirchenbauer, Jonas Geiping, Yuxin Wen, Jonathan Katz, Ian Miers, and Tom Goldstein.
A watermark for large language models. CoRR, abs/2301.10226, 2023.
[KJGR21] Gabriel Kaptchuk, Tushar M Jois, Matthew Green, and Aviel D Rubin. Meteor: Cryptographi-
cally secure steganography for realistic distributions. In Proceedings of the 2021 ACM SIGSAC
Conference on Computer and Communications Security , pages 1529–1548, 2021.
14Published in Transactions on Machine Learning Research (10/2024)
[KSK+23]Kalpesh Krishna, Yixiao Song, Marzena Karpinska, John Wieting, and Mohit Iyyer. Paraphras-
ing evades detectors of AI-generated text, but retrieval is an effective defense. arXiv preprint
arXiv:2303.13408 , 2023.
[MZ23]Travis Munyer and Xin Zhong. Deeptextmark: Deep learning based text watermarking for
detection of large language model generated text. arXiv preprint arXiv:2305.05773 , 2023.
[QZL+23]Jipeng Qiang, Shiyu Zhu, Yun Li, Yi Zhu, Yunhao Yuan, and Xindong Wu. Natural language
watermarking via paraphraser-based lexical substitution. Artificial Intelligence , page 103859,
2023.
[RWC+19]Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al.
Language models are unsupervised multitask learners. OpenAI blog , 1(8):9, 2019.
[Sch93]Leonard J Schulman. Deterministic coding for interactive communication. In Proceedings of the
twenty-fifth annual ACM symposium on Theory of computing , pages 747–756, 1993.
[Sch96]Leonard J Schulman. Coding for interactive communication. IEEE transactions on information
theory, 42(6):1745–1756, 1996.
[SKB+23]Vinu Sankar Sadasivan, Aounon Kumar, Sriram Balasubramanian, Wenxiao Wang, and Soheil
Feizi. Can AI-generated text be reliably detected? arXiv preprint arXiv:2303.11156 , 2023.
[SL22]Yaqian Shi and Lei Lei. Lexical richness and text length: An entropy-based perspective. Journal
of Quantitative Linguistics , 29(1):62–79, 2022.
[SS96]Michael Sipser and Daniel A Spielman. Expander codes. IEEE transactions on Information
Theory, 42(6):1710–1722, 1996.
[TMS+23]Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,
Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open
foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 , 2023.
[Var57]Rom Rubenovich Varshamov. Estimate of the number of signals in error correcting codes.
Docklady Akad. Nauk, SSSR , 117:739–741, 1957.
[WYC+23]Lean Wang, Wenkai Yang, Deli Chen, Hao Zhou, Yankai Lin, Fandong Meng, Jie Zhou,
and Xu Sun. Towards codable text watermarking for large language models. arXiv preprint
arXiv:2307.15992 , 2023.
[YAJK23] KiYoonYoo, WonhyukAhn, JihoJang, andNojunKwak. Robustnaturallanguagewatermarking
through invariant features. arXiv preprint arXiv:2305.01904 , 2023.
[YAK23] KiYoon Yoo, Wonhyuk Ahn, and Nojun Kwak. Advancing beyond identification: Multi-bit
watermark for language models. arXiv preprint arXiv:2308.00221 , 2023.
[ZEF+23]Hanlin Zhang, Benjamin L Edelman, Danilo Francati, Daniele Venturi, Giuseppe Ateniese, and
Boaz Barak. Watermarks in the sand: Impossibility of strong watermarking for generative
models.arXiv preprint arXiv:2311.04378 , 2023.
15Published in Transactions on Machine Learning Research (10/2024)
Appendix
A Proof of Theorem 6.3
We need to analyze two quantities. First, when Stegkadds a symbol to the code, what is the probability it is
incorrect (i.e., different than the intended nextsymbol)?; Second, how many symbols do we manage to add to
thecode? Or equivalently, how many response tokens do we usually see before adding a symbol to the code?
To answer both questions, we analyze the evolution of the correct score (i.e., the one corresponding to the
nextsymbol) and incorrect scores from the time we start computing them and until one of them passes the
threshold.
While computing the score with respect to an incorrect symbol, every token’s score is simply an exponential
random variable with mean 1. Denote by s1,s2,...the scores of each individual token (i.e., independent Exp(1)
random variables), and by Si:=/summationtexti
j=1sjtheir accumulative sums. By Lemma 5 in CGZ we have that for
anyℓ,τ > 0,
Pr[Sℓ≥ℓ+τ√
ℓ]≤/parenleftbigg4
5/parenrightbiggτ
.
Letb≥r0be an integer to be chosen later. By a union bound, the probability of the score passing the
thresholdtat any time within the bfirst steps is bounded by b/parenleftbig4
5/parenrightbigt.
For the score with respect to the correct symbol, the first btokens contain at least 10√
blnbempirical entropy,
asb≥r0and as we conditioned on our response being r0-saturated. In CGZ it is shown that Sℓis still
distributed as the sum of ℓindependent Exp(1)variables, but it is now additively shifted by the empirical
entropy of those ℓvariables. In particular, by Theorem 7 and Lemma 5 in CGZ, it follows that for any τ >0
we have
Pr[Sb<b+ 10√
blnb−√
τb]≤e−τ/2.
Equivalently,
Pr/bracketleftbiggSb−b√
b<10 lnb−√τ/bracketrightbigg
≤e−τ/2.
We chooset= 5lnbandτ= (5lnb)2and deduce from the above statements that: I) The probability that an
incorrect (normalized) score passed the threshold twithin the first bsteps is at most b/parenleftbig4
5/parenrightbigt=b/parenleftbig4
5/parenrightbig5 lnb=
e(1−5 ln(5/4)) lnb<e−(lnb)/10. II) The probability that the correct (normalized) score passed the threshold t
within the first bsteps, which is at least the probability it was above the threshold at the end of the b-th
step, is at least 1−e−τ/2= 1−e−25(lnb)2/2. By combining (I) and (II) we conclude that the probability that
the correct score passed the threshold within the first bsteps, yet the two incorrect scores did not, is at least
1−e−25(lnb)2/2−2e−(lnb)/10,
denote this number by (1−ε(b)). As limb→∞ε(b) = 0, there exists a constant b0such that for every b≥b0
it holds that ε(b)≤1
3. We setb=max(r0,b0). Note that b0is a universal constant independent of r0and
other parameters. We conclude that with probability at least2
3the correct symbol is transmitted within the
firstbtokens, and in particular the symbol is transmitted correctly with probability at least2
3.
As the probability of incorrectly transmitting a symbol is at most1
3<1
2, we can use Theorem 5.3 to conclude
that ifncode symbols are transmitted overall, then the first Θ(n)bits of the payload are retrieved correctly.
It is thus only left to analyze the number of transmitted code symbols.
We again consider the same inequality from before, that holds for any b′≥r0,τ > 0,
Pr/bracketleftig
Sb′−b′
√
b′<10 lnb′−√τ/bracketrightig
≤e−τ/2. By choosing τ=(5 lnb′)2we observe that for any b′> bwe
have 10lnb′−√τ= 5lnb′>5lnb=t. And thus, Pr/bracketleftig
Sb′−b′
√
b′<t/bracketrightig
≤e−25(lnb′)2/2. Denote by ℓthe
random variable which is the first step in which the score (w.r.t. the correct symbol) passed the threshold t,
16Published in Transactions on Machine Learning Research (10/2024)
by the above inequality we have
E[ℓ] =∞/summationdisplay
i=1Pr [ℓ≥i]
=b/summationdisplay
i=1Pr [ℓ≥i] +∞/summationdisplay
i=b+1Pr [ℓ≥i]
<b/summationdisplay
i=11 +∞/summationdisplay
i=b+1e−25
2(lni)2
=b+O(1).
As the correct symbol is expected to pass the score threshold after b+O(1)response tokens, in particular a
symbol is expected to be transmitted in the protocol at least once every b+O(1)response tokens.
B Complete Undetectability
Our revised algorithm partitions the generation of response tokens into three parts:
1.We use real randomness to generate tokens and count the amount of empirical entropy used in the
process, until enough (at least λ) empirical entropy was seen, we call the prefix of tokens generated
in this step r.
2.We begin generating tokens using the PRF, with both rand the index as inputs. We don’t yet submit
code symbols and wait until the score passes λ. We do this step to leave a signal to the detector
with regards to what prefix rwas chosen by the generation algorithm.
3. We now run the one-query scheme, while adding ras an additional input to the PRF calls.
We remark that the second part can be avoided, as the correct rcan be detected implicitly during the third
part, but for simplicity of presentation we include it. With this structure, the proofs are rather straightforward.
The pseudo-code for Stegkappears in Algorithm 5, and for Retrkin Algorithm 6.
Theorem B.1. Algorithm 5 is undetectable as defined in Definition 2.6.
Proof.This follows from Theorem 11 in CGZ, as the inputs to the PRF in the generation process are all
unique within a single query, and all contain rwhich ever repeats within different queries only with negligible
probability.
Theorem 6.3 also remains correct as-is, besides that we “lose" O(λ)empirical entropy to Parts 1 and 2.
As long as L= Ω(λ)then, the same theorem statement still holds. While the running time of Stegkis
unaffected, the running time of Retrkis now quadratic instead of linear. This can be avoided by truncating
the verification of r, but we do not do so for the sake of simplicity.
17Published in Transactions on Machine Learning Research (10/2024)
Algorithm 5: Steganography algorithm Stegk
Data:A prompt ( prompt), a payload ( payload ), and a secret key k
Result: Responsex1,...,xL
i←1;
H←0;
r_score←0;
r_score_len←0;
code←();
scoreσ←0forσ∈{0,1,←};
score_len←0;
next←next(payload,code);
while done/∈(x1,...,xi−1)do
pi←Model (prompt,x1,...,xi−1);
ifH <λthen
// Part 1
Sample (xi,p)←(1,pi)with probability pi, otherwise (0,1−pi);
H←H−logp;
ifH≥λthen
r←(x1,...,xi);
end
else if (r_score−r_score_len )≤λ√r_score_len then
// Part 2
xi←1[Fk(r,i,None )≤pi];
r_score←r_score +s(xi,Fk(r,i,None ));
r_score_len←r_score_len + 1;
else
// Part 3
xi←1[Fk(r,i,next)≤pi];
score_len←score_len + 1;
forσ∈{0,1,←}do
scoreσ←scoreσ+s(xi,Fk(r,i,σ ));
if(scoreσ−score_len )/√score_len>tthen
code←code||(σ);
scoreσ←0forσ∈{0,1,←};
score_len←0;
next←next(payload,code);
break;
end
end
end
i←i+ 1;
end
18Published in Transactions on Machine Learning Research (10/2024)
Algorithm 6: Retriever algorithm Retrk
Data:Responsex1,...,xL, and a secret key k
Result: Retrieved payload payload
code←();
scoreσ←0forσ∈{0,1,←};
score_len←0;
forj= 1,2,...,Ldo
r←(x1,...,xj);
r_score←0;
r_score_len←0;
fori=j+ 1,j+ 2,...,Ldo
if(r_score−r_score_len )≤λ√r_score_len then
// Verify r
r_score←r_score +s(xi,Fk(r,i,None ));
r_score_len←r_score_len + 1;
else
// Correct rfound
score_len←score_len + 1;
forσ∈{0,1,←}do
scoreσ←scoreσ+s(r,xi,Fk(r,i,σ ));
if(scoreσ−score_len )/√score_len>tthen
code←code||(σ);
scoreσ←0forσ∈{0,1,←};
score_len←0;
break;
end
end
end
end
ifcode̸= ()then
returndecode (code);
end
end
returnFalse;
19