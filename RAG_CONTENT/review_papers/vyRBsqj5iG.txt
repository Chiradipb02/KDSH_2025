Published in Transactions on Machine Learning Research (12/2023)
Proximal Mean Field Learning in Shallow Neural Networks
Alexis M.H. Teter amteter@ucsc.edu
Department of Applied Mathematics
University of California, Santa Cruz
Iman Nodozi inodozi@ucsc.edu
Department of Electrical and Computer Engineering
University of California, Santa Cruz
Abhishek Halder ahalder@iastate.edu
Department of Aerospace Engineering
Iowa State University
Reviewed on OpenReview: https: // openreview. net/ forum? id= vyRBsqj5iG
Abstract
We propose a custom learning algorithm for shallow over-parameterized neural networks,
i.e., networks with single hidden layer having infinite width. The infinite width of the hidden
layer serves as an abstraction for the over-parameterization. Building on the recent mean
field interpretations of learning dynamics in shallow neural networks, we realize mean field
learning as a computational algorithm, rather than as an analytical tool. Specifically, we
design a Sinkhorn regularized proximal algorithm to approximate the distributional flow for
the learning dynamics over weighted point clouds. In this setting, a contractive fixed point
recursion computes the time-varying weights, numerically realizing the interacting Wasser-
stein gradient flow of the parameter distribution supported over the neuronal ensemble.
An appealing aspect of the proposed algorithm is that the measure-valued recursions allow
meshless computation. We demonstrate the proposed computational framework of inter-
acting weighted particle evolution on binary and multi-class classification. Our algorithm
performs gradient descent of the free energy associated with the risk functional.
1 Introduction
While universal function approximation theorems for neural networks have long been known (Cybenko, 1989;
Barron,1993;Horniketal.,1989),suchguaranteesdonotaccountforthedynamicsofthelearningalgorithms.
Starting in 2018, several works (Mei et al., 2018; Chizat & Bach, 2018; Rotskoff & Vanden-Eijnden, 2018;
Sirignano & Spiliopoulos, 2020; Rotskoff & Vanden-Eijnden, 2022; Boursier et al., 2022) pointed out that
the first order learning dynamics for shallow (i.e., single hidden layer) neural networks in the infinite width
(i.e., over-parameterization) limit leads to a nonlinear partial differential equation (PDE) that depends on a
pair of advection and interaction potentials.
The Cauchy initial value problem associated with the PDE describes the evolution of neuronal parameter
ensemble induced by the learning dynamics. This result can be interpreted as a dynamical version of the
universal approximation theorem. In particular, the potentials depend on both the loss function as well as
the activation functions of the neural network.
The advection potential in this nonlinear PDE induces a drift, while the interaction potential induces a
nonlocal force. Remarkably, this PDE can be interpreted as an infinite dimensional gradient flow of the
population risk w.r.t. the Wasserstein metric arising from the theory of optimal mass transport (Villani,
2009; 2021).
1Published in Transactions on Machine Learning Research (12/2023)
The nonlocal nonlinear PDE interpretation makes connection with the so-called “propagation of chaos”–a
term due to Kac (Kac, 1956) that has grown into a substantial literature in statistical physics (McKean Jr,
1966; Sznitman, 1991; Carmona & Delarue, 2018). From this viewpoint, the first order algorithmic dynamics
makes the individual neurons in the hidden layer behave as interacting particles. These particle-level or
microscopic interactions manifest as a population-level or macroscopic gradient flow.
As an analytic tool, the mean field Wasserstein gradient flow interpretation helps shed light on the conver-
gence of first order learning dynamics in over-parameterized networks. In this work, we propose Wasserstein
proximal recursions to realize the mean field learning dynamics as a meshless computational algorithm.
1.1 Computational challenges
Transcribing the mean field Wasserstein gradient flow PDE from an analytical tool to a computational
algorithmisparticularlychallengingintheneuralnetworkcontext. ThisisbecausethederivationofthePDE
in (Mei et al., 2018; Chizat & Bach, 2018; Rotskoff & Vanden-Eijnden, 2018; Sirignano & Spiliopoulos, 2020),
and the corresponding infinite dimensional gradient descent interpretation, is an asymptotic consistency
result. Specifically, the PDE describes the time evolution of the joint population density (or population
measure in general) for the hidden layer neuronal ensemble. By definition, this interpretation is valid in the
mean field (infinite width) limit of the single hidden layer. In other words, to leverage the gradient flow PDE
perspective in computation, the number of neurons in the hidden layer must be large.
However, from a numerical perspective, explicitly evolving the joint population in the large width regime
is problematic. This is because the large width implies that the time-varying joint neuronal population
distributions have high dimensional supports. Even though existing software tools routinely deploy stochas-
tic gradient descent (SGD) algorithms at the microscopic (i.e., particle) level, it is practically infeasible to
estimate the time-varying population distributions using Monte Carlo or other a posteriori function approx-
imation algorithms near this limit. One also cannot resort to standard finite difference-type discretization
approach for solving this gradient flow PDE because the large width limit brings the curse of dimensionality.
Therefore, it is not obvious whether the mean field dynamics can lead to a learning algorithm in practice.
1.2 Related works
Beyondmeanfieldlearning, Wassersteingradientflowsappearinmanyotherscientific(Ambrosioetal.,2005;
Santambrogio, 2017) and engineering (Halder & Georgiou, 2017; Caluya & Halder, 2021b; Halder et al., 2022)
contexts. Thus, there exists a substantial literature on numerically implementing the Wasserstein gradient
flows – both with grid (Peyré, 2015; Benamou et al., 2016; Carlier et al., 2017; Carrillo et al., 2022) and
without grid (Liu et al., 2019; Caluya & Halder, 2019a; Halder et al., 2020). The latter class of algorithms
are more relevant for the mean field learning context since the underlying parameter space (i.e., the support)
is high dimensional. The proximal recursion we consider is closely related to the forward or backward
discretization (Salim et al., 2020; Frogner & Poggio, 2020) of the Jordan-Kinderlehrer-Otto (JKO) scheme
(Jordan et al., 1998).
To bypass numerical optimization over the manifold of measures or densities, recent works (Mokrov et al.,
2021; Alvarez-Melis et al., 2021; Bunne et al., 2022) propose using input convex neural networks (Amos
et al., 2017) to perform the Wasserstein proximal time-stepping by learning the convex potentials (Brenier,
1991) associated with the respective pushforward maps. To alleviate the computational difficulties in high
dimensions, Bonet et al. (2021) proposes replacing the Wasserstein distance with the sliced-Wasserstein
distance (Rabin et al., 2011) scaled by the ambient dimension.
We note here that there exists extensive literature on the mean field limit of learning in neural networks from
other perspectives, including the Neural Tangent Kernel (NTK) and the Gaussian process viewpoints, see
e.g., (Jacot et al., 2018; Lee et al., 2019; Novak et al., 2019; Xiao et al., 2018; Li & Nguyen, 2018; Matthews
et al., 2018). Roughly speaking, the key observation is that in the infinite width limit, the learning evolves
as a suitably defined Gaussian process with network architecture-dependent kernel. We mention this in the
passing since in this work, we will only focus on the Wasserstein gradient flow viewpoint. We point out that
2Published in Transactions on Machine Learning Research (12/2023)
unlike the NTK, the mean field limit in Wasserstein gradient flow viewpoint does not approximate dynamical
nonlinearity. In particular, the associated initial value problem involves a nonlinear PDE (see (14)).
1.3 Contributions
With respect to the related works referenced above, the main contribution of the present work is that
we propose a meshless Wasserstein proximal algorithm that directly implements the macroscopic learning
dynamics in a fully connected shallow network. We do so by evolving population densities as weighted
scattered particles.
Different from Monte Carlo-type algorithms, the weight updates in our setting are done explicitly by solving
a regularized dual ascent. This computation occurs within the dashed box highlighted in Fig. 1. The
particles’ location updates are done via nonlocal Euler-Maruyama. These two updates interact with each
other (see Fig. 1), and together set up a discrete time-stepping scheme.
The discrete time-stepping procedure we propose, is a novel interacting particle system in the form of a
meshless algorithm. Our contribution advances the state-of-the-art as it allows for evolving the neuronal
population distribution in an online manner, as needed in mean field learning. This is in contrast to a
posteriori function approximation in existing Monte Carlo methods (cf. Sec. 1.1). Explicit proximal weight
updates allows us to bypass offline high dimensional function approximation, thereby realizing mean field
learning at an algorithm level.
With respect to the computational challenges mentioned in Sec. 1.1, it is perhaps surprising that we are able
to design an algorithm for explicitly evolving the population densities without directly discretizing the spatial
domain of the underlying PDE. Our main idea to circumvent the computational difficulty is to solve the
gradient flow PDE notas a PDE, but to instead direct the algorithmic development for a proximal recursion
associated with the gradient flow PDE. This allows us to implement the associated proximal recursion over
a suitably discrete time without directly discretizing the parameter space (the latter is what makes the
computation otherwise problematic in the mean field regime).
For specificity, we illustrate the proposed framework on two numerical experiments involving binary and
multi-class classification with quadratic risk. The proposed methodology should be of broad interest to
other problems such as the policy optimization (Zhang et al., 2018; Chu et al., 2019; Zhang et al., 2020) and
the adversarial learning (Domingo-Enrich et al., 2020; Mroueh & Nguyen, 2021; Lu, 2023).
We emphasize that the perspective taken in this work is somewhat non-standard w.r.t. the existing literature
in that our main intent is to explore the possibility of designing a new class of algorithms by leveraging the
connection between the mean field PDE and the Wasserstein proximal operator. This is a new line of idea
for learning algorithm design that we show is feasible. As such, we do not aim to immediately surpass the
carefully engineered existing state-of-the-art in experiments. Instead, this study demonstrates a proof-of-
concept which should inspire follow up works.
1.4 Notations and preliminaries
We use the standard convention where the boldfaced lowercase letters denote vectors, boldfaced uppercase
letters denote matrices, and non-boldfaced letters denote scalars. We use the symbols ∇and∆to denote the
Euclidean gradient and Laplacian operators, respectively. In case of potential confusion, we attach subscripts
to these symbols to clarify the differential operator is taken w.r.t. which variable. The symbols ⊙,⊘,exp,
and tanhdenoteelementwise multiplication, division, exponential, and hyperbolic tangent, respectively.
Furthermore, randandrandndenote draw of the uniform and standard normal distributed random vector
of appropriate dimension. In addition, 111represents a vector of ones of appropriate dimension.
LetZ1,Z2⊆Rd. The squared 2-Wasserstein metric W2(with standard Euclidean ground cost) between two
probability measures π1(dzzz1)andπ2(dzzz2)(or between the corresponding densities when the measures are
3Published in Transactions on Machine Learning Research (12/2023)
absolutely continuous), where zzz1∈Z1,zzz2∈Z2, is defined as
W2
2(π1,π2) := inf
π∈Π(π1,π2)/integraldisplay
Z1×Z2∥zzz1−zzz2∥2
2dπ(zzz1,zzz2). (1)
In (1), the symbol Π (π1,π2)denotes the collection of joint measures (couplings) with finite second moments,
whose first marginal is π1, and the second marginal is π2.
1.5 Organization
The remainder of this paper is organized as follows. In Sec. 2, we provide the necessary background for the
empirical risk minimization and for the corresponding mean field limit. The proposed proximal algorithm
(including its derivation, convergence guarantee and implementation) is detailed in Sec. 3. We then report
numerical case studies in Sec. 4 and Sec. 5 for binary and multi-class classifications, respectively. Sec. 6
concludes the paper. Supporting proofs and derivations are provided in Appendices A, B and C. Numerical
resultsforasyntheticonedimensionalcasestudyoflearningasinusoidusingtheproposedproximalalgorithm
is provided in Appendix D.
2 From empirical risk minimization to proximal mean field learning
To motivate the mean field learning formulation, we start by discussing the more familiar empirical risk
minimization set up. We then explain the infinite width limit for the same.
2.1 Empirical risk minimization
We consider a supervised learning problem where the dataset comprises of the features xxx∈X⊆ Rnx, and
the labelsy∈Y⊆ R, i.e., the samples of the dataset are tuples of the form
(xxx,y)∈X×Y⊆ Rnx×R.
The objective of the supervised learning problem is to find the parameter vector θθθ∈Rpsuch thaty≈f(xxx,θθθ)
wherefis some function class parameterized by θθθ. In other words, fmaps from the feature space Xto
the label spaceY. To this end, we consider a shallow neural network with a single hidden layer having nH
neurons. Then, the parameterized function fadmits representation
f(xxx,θθθ) :=1
nHnH/summationdisplay
i=1Φ (xxx,θθθi), (2)
where Φ (xxx,θθθi) :=aiσ(⟨wwwi,xxx⟩+bi)for alli∈[nH] :={1,2,...,n H}, andσ(·)is a smooth activation function.
The parameters ai,wwwiandbiare the scaling, weights, and bias of the ithhidden neuron, respectively, and
together comprise the specific parameter realization θθθi∈Rp,i∈[nH].
We stack the parameter vectors of all hidden neurons as
θθθ:=/parenleftbigθθθ1,θθθ2,...,θθθnH/parenrightbig⊤∈RpnH
and consider minimizing the following quadratic loss:
l(y,xxx,θθθ)≡l(y,f(xxx,θθθ)) :=/parenleftig
y−f(xxx,θθθ)/parenrightig2
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
quadratic loss. (3)
We suppose that the training data follows the joint probability distribution γ, i.e., (xxx,y)∼γ. Define the
population risk Ras the expected loss given by
R(f) :=E(xxx,y)∼γ[l(y,xxx,θθθ)]. (4)
4Published in Transactions on Machine Learning Research (12/2023)
In practice, γis unknown, so we approximate the population risk with the empirical risk
R(f)≈1
ndatandata/summationdisplay
j=1l/parenleftig
yj,xxxj,θθθ/parenrightig
(5)
wherendatais the number of data samples. Then, the supervised learning problem reduces to the empirical
risk minimization problem
min
θθθ∈RpnHR(f).(6)
Problem (6) is a large but finite dimensional optimization problem that is nonconvex in the decision variable
θθθ. The standard approach is to employ first or second order search algorithms such as the variants of SGD
or ADAM (Kingma & Ba, 2014).
2.2 Mean field limit
The mean field limit concerns with a continuum of hidden layer neuronal population by letting nH→∞.
Then, we view (2) as the empirical average associated with the ensemble average
fMeanField :=/integraldisplay
RpΦ(xxx,θθθ) dµ(θθθ)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
hidden neuronal population mass=Eθθθ[Φ(xxx,θθθ)], (7)
whereµdenotes the joint population measure supported on the hidden neuronal parameter space in Rp.
Assuming the absolute continuity of µfor all times, we write dµ(θθθ) =ρ(θθθ)dθθθwhereρdenotes the joint
population density function (PDF).
Thus, the risk functional R, now viewed as a function of the joint PDF ρ, takes the form
F(ρ) :=R(fMeanField (xxx,ρ)) =E(xxx,y)/parenleftbigg
y−/integraldisplay
RpΦ(xxx,θθθ)ρ(θθθ)dθθθ/parenrightbigg2
=F0+/integraldisplay
RpV(θθθ)ρ(θθθ)dθθθ+/integraldisplay
R2pU(θθθ,˜θθθ)ρ(θθθ)ρ(˜θθθ)dθθθd˜θθθ, (8)
where
F0:=E(xxx,y)/bracketleftbig
y2/bracketrightbig
, V (θθθ) :=E(xxx,y)[−2yΦ(xxx,θθθ)], U (θθθ,˜θθθ) :=E(xxx,y)[Φ(xxx,θθθ)Φ(xxx,˜θθθ)]. (9)
Therefore, the supervised learning problem, in this mean field limit, becomes an infinite dimensional varia-
tional problem:
min
ρF(ρ) (10)
whereFis a sum of three functionals. The first summand F0is independent of ρ. The second summand is
a potential energy given by expected value of “drift potential” Vand is linear in ρ. The last summand is a
bilinear interaction energy involving an “interaction potential” Uand is nonlinear in ρ.
The main result in Mei et al. (2018) was that using first order SGD learning dynamics induces a gradient
flow of the functional Fw.r.t. the 2-Wasserstein metric W2, i.e., the mean field learning dynamics results
in a joint PDF trajectory ρ(t,θθθ). Then, the minimizer in (10) can be obtained from the large tlimit of the
following nonlinear PDE:
∂ρ
∂t=−∇W2F(ρ), (11)
where the 2-Wasserstein gradient (Villani, 2021, Ch. 9.1) (Ambrosio et al., 2005, Ch. 8) of Fis
∇W2F(ρ) :=−∇·/parenleftbigg
ρ∇δF
∂ρ/parenrightbigg
,
andδ
δρdenotes the functional derivative w.r.t. ρ.
5Published in Transactions on Machine Learning Research (12/2023)
In particular, Mei et al. (2018) considered the regularized risk functional1
Fβ(ρ) :=F(ρ) +β−1/integraldisplay
Rpρlogρdθθθ, β > 0, (12)
by adding a strictly convex regularizer (scaled negative entropy) to the unregularized risk F. In that case, the
sample path dynamics corresponding to the macroscopic dynamics (11) precisely becomes the noisy SGD:
dθθθ=−∇θθθ/parenleftbigg
V(θθθ) +/integraldisplay
RpU(θθθ,˜θθθ)ρ(˜θθθ)d˜θθθ/parenrightbigg
dt+/radicalbig
2β−1dηηη, θθθ(t= 0)∼ρ0, (13)
whereηηηis the standard Wiener process in Rp, and the random initial condition θθθ(t= 0)follows the law of
a suitable PDF ρ0supported over Rp.
In this regularized case, (11) results in the following nonlinear PDE initial value problem (IVP):
∂ρ
∂t=∇θθθ·/parenleftbigg
ρ/parenleftbigg
V(θθθ) +/integraldisplay
RpU(θθθ,˜θθθ)ρ(˜θθθ)d˜θθθ/parenrightbigg/parenrightbigg
+β−1∆θθθρ, ρ (t= 0,θθθ) =ρ0. (14)
In other words, the noisy SGD induces evolution of a PDF-valued trajectory governed by the advection,
nonlocal interaction, and diffusion–the latter originating from regularization. Notice that a large value of
β > 0implies a small entropic regularization in (12), hence a small additive process noise in (13), and
consequently, a small diffusion term in the PDE (14).
The regularized risk functional Fβin (12) can be interpreted as a free energy wherein Fcontributes a sum
of the advection potential energy and interaction energy. The term β−1/integraltext
Rpρlogρdθθθcontributes an internal
energy due to the noisy fluctuations induced by the additive Wiener process noise/radicalbig
2β−1dηηηin (13).
InMeietal.(2018), asymptoticguaranteeswereobtainedforthesolutionof(14)toconvergetotheminimizer
ofFβ. Our idea, outlined next, is to solve the minimization of Fβusing measure-valued proximal recursions.
2.3 Proximal mean field learning
For numerically computing the solution of the PDE IVP (14), we propose proximal recursions over P2(Rp),
defined as the manifold of joint PDFs supported over Rphaving finite second moments. Symbolically,
P2(Rp) :=/braceleftbigg
Lebesgue integrable ρoverRp|ρ≥0,/integraldisplay
Rpρdθθθ= 1,/integraldisplay
Rpθθθ⊤θθθρdθθθ<∞/bracerightbigg
.
Proximal updates generalize the concept of gradient steps, and are of significant interest in both finite and
infinite dimensional optimization (Rockafellar, 1976a;b; Bauschke et al., 2011; Teboulle, 1992; Bertsekas
et al., 2011; Parikh et al., 2014). For a given input, these updates take the form of a structured optimization
problem:
proximal update
= arg inf
decision variable/braceleftbigg1
2dist2(decision variable ,input ) +time step×functional (decision variable )/bracerightbigg
,(15)
for some suitable notion of distance dist (·,·)on the space of decision variables, and some associated func-
tional. It is usual to view (15) as an operator mapping input∝⇕⊣√∫⊔≀→proximal update, thus motivating the term
proximal operator .
The connection between (15) and the gradient flow comes from recursively evaluating (15) with some initial
choice for the input. For suitably designed pair (dist (·,·),functional ), in the small time step limit, the
sequence of proximal updates generated by (15) converge to the infimum of the functional. In other words,
the gradient descent of the functional w.r.t. distmay be computed as the fixed point of the proximal operator
1The parameter β> 0is referred to as the inverse temperature.
6Published in Transactions on Machine Learning Research (12/2023)
(15). For a parallel between gradient descent and proximal recursions in finite and infinite dimensional
gradient descent, see e.g., (Halder & Georgiou, 2017, Sec. I). Infinite dimensional proximal recursions over
the manifold of PDFs have recently appeared in uncertainty propagation (Caluya & Halder, 2019b; Halder
et al., 2022), stochastic filtering (Halder & Georgiou, 2017; 2018; 2019), and stochastic optimal control
(Caluya & Halder, 2021b;a).
In our context, the decision variable ρ∈P2(Rp)and the distance metric dist≡W2. Specifically, we propose
recursions over discrete time tk−1:= (k−1)hwhere the index k∈N, andh >0is a constant time step-
size. Leveraging that (14) describes gradient flow of the functional Fβw.r.t. theW2distance metric, the
associated proximal recursion is of the form
ϱk=proxW2
hFβ(ϱk−1) := arg inf
ϱ∈P2(Rp)/braceleftbigg1
2(W2(ϱ,ϱk−1))2+hFβ(ϱ)/bracerightbigg
(16)
whereϱk−1(·) :=ϱ(·,tk−1), andϱ0≡ρ0. The notation proxW2
hFβ(ϱk−1)can be parsed as “the proximal
operator of the scaled functional hFβw.r.t. the distance W2, acting on the input ϱk−1∈P2(Rp)”. Our idea
is to evaluate the recursion in the small hlimit, i.e., for h↓0.
To account for the nonconvex bilinear term appearing in (12), following (Benamou et al., 2016, Sec. 4), we
employ the approximation:
/integraldisplay
R2pU(θθθ,˜θθθ)ϱ(θθθ)ϱ(˜θθθ)dθθθd˜θθθ≈/integraldisplay
R2pU(θθθ,˜θθθ)ϱ(θθθ)ϱk−1(˜θθθ)dθθθd˜θθθ∀k∈N.
We refer to the resulting approximation of FβasˆFβ, i.e.,
ˆFβ(ϱ,ϱk−1) :=/integraldisplay
Rp/parenleftbigg
F0+V(θθθ) +/parenleftbigg/integraldisplay
RpU(θθθ,˜θθθ)ϱk−1(˜θθθ)d˜θθθ/parenrightbigg
+β−1logϱ(θθθ)/parenrightbigg
ϱ(θθθ)dθθθ.
Notice in particular that ˆFβdepends on both ϱ,ϱk−1,k∈N. Consequently, this approximation results in a
semi-implicit variant of (16), given by
ϱk:= arg inf
ϱ∈P2(Rp)/braceleftbigg1
2(W2(ϱ,ϱk−1))2+hˆFβ(ϱ,ϱk−1)/bracerightbigg
. (17)
We have the following consistency guarantee, stated informally, among the solution of the PDE IVP (14)
and that of the variational recursions (17). The rigorous statement and proof are provided in Appendix A.
Theorem 1. (Informal ) Consider the regularized risk functional (12) wherein Fis given by (8)-(9). In
the small time step ( h↓0) limit, the proximal updates (17) with ϱ0≡ρ0converge to the solution for the
PDE IVP (14).
We next detail the proposed algorithmic approach to numerically solve (17).
3 ProxLearn: proposed proximal algorithm
TheoverallworkflowofourproposedproximalmeanfieldlearningframeworkisshowninFig. 1. Wegenerate
Nsamples from the known initial joint PDF ϱ0and store them as a weighted point cloud/braceleftbig
θθθi
0,ϱi
0/bracerightbigN
i=1. Here,
ϱi
0:=ϱ0/parenleftbig
θθθi
0/parenrightbig
for alli∈[N]. In other words, the weights of the samples are the joint PDF values evaluated
at those samples.
For eachk∈N, the weighted point clouds/braceleftbig
θθθi
k,ϱi
k/bracerightbigN
i=1are updated through the two-step process outlined in
our proposed Algorithm 1, referred to as ProxLearn . At a high level, lines 9–18 in Algorithm 1 perform
nonlinear block co-ordinate recursion on internally defined vectors zzz,qqqwhose converged values yield the
proximal update (line 19). We next explain where these recursions come from detailing both the derivation
ofProxLearn and its convergence guarantee.
7Published in Transactions on Machine Learning Research (12/2023)
3.1 Derivation of ProxLearn
The main idea behind our derivation that follows, is to regularize and dualize the discrete version of the
optimizationproblemin(17). Thisallowsustoleveragecertainstructureoftheoptimalsolutionthatemerges
from the first order conditions for optimality, which in turn helps design a custom numerical recursion.
Specifically, to derive the recursion given in ProxLearn , we first write the discrete version of (17) as
ϱϱϱk= arg min
ϱϱϱ/braceleftbigg
min
MMM∈Π(ϱϱϱk−1,ϱϱϱ)1
2⟨CCCk,MMM⟩+h/angbracketleftbig
vvvk−1+UUUk−1ϱϱϱk−1+β−1logϱϱϱ,ϱϱϱ/angbracketrightbig/bracerightbigg
, k∈N,(18)
where
Π (ϱϱϱk−1,ϱϱϱ) :={MMM∈RN×N|MMM≥000(elementwise) ,MMM111 =ϱϱϱk−1, MMM⊤111 =ϱϱϱ}, (19)
vvvk−1≡V(θθθk−1), (20)
UUUk−1≡U/parenleftig
θθθk−1,˜θθθk−1/parenrightig
, (21)
andCCCk∈RN×Ndenotes the squared Euclidean distance matrix, i.e.,
CCCk(i,j) :=∥θθθi
k−θθθj
k−1∥2
2∀(i,j)∈[N]×[N].
We next follow a “regularize-then-dualize” approach. In particular, we regularize (18) by adding the entropic
regularization H(MMM) :=⟨MMM,logMMM⟩, and write
ϱϱϱk= arg min
ϱϱϱ/braceleftbigg
min
MMM∈Π(ϱϱϱk−1,ϱϱϱ)1
2⟨CCCk,MMM⟩+ϵH(MMM) +h/angbracketleftbig
vvvk−1+UUUk−1ϱϱϱk−1+β−1logϱϱϱ,ϱϱϱ/angbracketrightbig/bracerightbigg
, k∈N(22)
whereϵ>0is a regularization parameter.
Following Karlsson & Ringh (2017, Lemma 3.5), Caluya & Halder (2019a, Sec. III), the Lagrange dual
problem associated with (22) is
/parenleftig
λλλopt
0,λλλopt
1/parenrightig
= arg max
λλλ0,λλλ1∈RN/braceleftigg
⟨λλλ0,ϱϱϱk−1⟩−ˆF⋆
β(−λλλ1)−ϵ
h/parenleftbig
exp/parenleftbig
λλλ⊤
0h/ϵ/parenrightbig
exp (−CCCk/2ϵ) exp (λλλ1h/ϵ)/parenrightbig/bracerightigg
(23)
where
ˆF⋆
β(·) := sup
ϑ{⟨·,ϑ⟩−ˆFβ(ϑ)} (24)
is the Legendre-Fenchel conjugate of the free energy ˆFβin (17), and the optimal coupling matrix MMMopt:=
[mopt(i,j)]N
i,j=1in (22) has the Sinkhorn form
mopt(i,j) = exp (λλλ0(i)h/ϵ) exp (−CCCk(i,j)/(2ϵ)) exp (λλλ1(j)h/ϵ). (25)
To solve (23), considering (12), we write the “discrete free energy” as
ˆFβ(ϱϱϱ) =/angbracketleftbig
vvvk−1+UUUk−1ϱϱϱk−1+β−1logϱϱϱ,ϱϱϱ/angbracketrightbig
. (26)
Its Legendre-Fenchel conjugate, by (24), is
ˆF⋆
β(λ) := sup
ϑ{λλλ⊤ϱϱϱ−vvv⊤
k−1ϱϱϱ−ϱϱϱ⊤UUUk−1ϱϱϱk−1−β−1ϱϱϱ⊤logϱϱϱ}. (27)
Setting the gradient of the objective in (27) w.r.t. ϱϱϱto zero, and solving for ϱϱϱgives the maximizer
ϱϱϱmax= exp/parenleftbig
β/parenleftbig
λλλ−vvvk−1−β−1111−UUUk−1ϱϱϱk−1/parenrightbig/parenrightbig
. (28)
8Published in Transactions on Machine Learning Research (12/2023)
Substituting (28) back into (27), we obtain
ˆF⋆
β(λ) =β−1111 exp (β(λλλ−vvvk−1−UUUk−1ϱϱϱk−1)−111). (29)
Fixingλλλ0, and taking the gradient of the objective in (23) w.r.t. λλλ1gives
exp (λλλ1h/ϵ)⊙/parenleftig
exp (−CCCk/2ϵ)⊤exp (λλλ0h/ϵ)/parenrightig
= exp(−βvvvk−1−βUUUk−1ϱϱϱk−1−111)⊙(exp (λλλ1h/ϵ))−βϵ
h.(30)
Likewise, fixing λλλ1, and taking the gradient of the objective in (23) w.r.t. λλλ0, gives
exp (λλλ0h/ϵ)⊙(exp (−CCCk/2ϵ) exp (λλλ1h/ϵ)) =ϱϱϱk−1. (31)
Next, letting ΓΓΓk:= exp (−CCCk/2ϵ),qqq:= exp (λλλ0h/ϵ),zzz:= exp (λλλ1h/ϵ), andξξξk−1:= exp(−βvvvk−1−
βUUUk−1ϱϱϱk−1−111), we express (30) as
zzz⊙/parenleftbig
ΓΓΓ⊤
kqqq/parenrightbig
=ξξξk−1⊙zzz−βϵ
h, (32)
and (31) as
qqq⊙(ΓΓΓkzzz) =ϱϱϱk−1. (33)
Finally using (19), we obtain
ϱϱϱk=/parenleftbig
MMMopt/parenrightbig⊤1=N/summationdisplay
j=1mopt(j,i) =zzz(i)N/summationdisplay
j=1ΓΓΓk(j,i)qqq(j) =zzz⊙ΓΓΓ⊤
kqqq. (34)
In summary, (34) allows us to numerically perform the proximal update.
Remark 1. Note that in Algorithm 1 (i.e., ProxLearn ) presented in Sec. 3, the lines 11, 12, and 19
correspond to (32), (33) and (34), respectively.
3.2 Convergence of ProxLearn
Our next result provides the convergence guarantee for our proposed ProxLearn algorithm derived in Sec.
3.1.
Proposition 1. The recursions given in lines 7–18 in Algorithm 1 ProxLearn , converge to a unique fixed
point (qqqopt,zzzopt)∈RN
>0×RN
>0. Consequently, the proximal update (34) (i.e., the evaluation at line 19 in
Algorithm 1) is unique.
Proof.Notice that the mappings (qqq(:,ℓ),zzz(:,ℓ))∝⇕⊣√∫⊔≀→(qqq(:,ℓ+1),zzz(:,ℓ+1))given in lines 11 and 12 in Algorithm
1, are cone preserving since these mappings preserve the product orthant RN
>0×RN
>0. This is a direct
consequence of the definition of qqq,zzzin terms of λλλ0,λ1λ1λ1.
Now the idea is to show that the recursions in lines 11 and 12 in Algorithm 1, as composite nonlinear maps,
are in fact contractive w.r.t. a suitable metric on this cone. Following Caluya & Halder (2019a, Theorem
3), thezzziteration given in line 11 in Algorithm 1, ProxLearn , forℓ= 1,2,..., is strictly contractive in
the Thompson’s part metric (Thompson, 1963) and thanks to the Banach contraction mapping theorem,
converges to a unique fixed point zzzopt∈RN
>0.
We note that our definition of ξξξk−1is slightly different compared to the same in Caluya & Halder (2019a,
Theorem 3), but this does not affect the proof. From definition of CCCk, we haveCCCk∈[0,∞)which implies
ΓΓΓk(i,j)∈(0,1]. Therefore, ΓΓΓkis a positive linear map for each k∈N. Thus, by (linear) Perron-Frobenius
theorem, the linear maps ΓΓΓkare contractive. Consequently the qqqiterates also converge to unique fixed point
qqqopt∈RN
>0.
Since converged pair (qqqopt,zzzopt)∈RN
>0×RN
>0is unique, so is the proximal update (34), i.e., the evaluation
at line 19 in Algorithm 1.
We next discuss the implementation details for the proposed ProxLearn algorithm.
9Published in Transactions on Machine Learning Research (12/2023)
Figure 1: Schematic of the proposed proximal algorithm for mean field learning, updating scattered point
cloud/braceleftbig
θθθi
k−1,ϱi
k−1/bracerightbigN
i=1fork∈N. The location of the points/braceleftbig
θθθi
k−1/bracerightbigN
i=1are updated via the Euler-Maruyama
scheme; the corresponding probability weights are computed via proximal updates highlighted within the
dashed box. Explicitly performing the proximal updates via the proposed algorithm, and thereby enabling
mean filed learning as an interacting weighted particle system, is our novel contribution
.
3.3 Implementation of ProxLearn
We start by emphasizing that ProxLearn updates both the parameter sample locations θθθi
kand the joint
PDF values ϱi
kevaluated at those locations, without gridding the parameter space. In particular, the PDF
values are updated online, not as an offline a posteriori function approximation as in traditional Monte Carlo
algorithms.
We will apply ProxLearn , as outlined here, in Sec. 4. In Sec. 5, we will detail additional modifications of
ProxLearn to showcase its flexibility.
Required inputs of ProxLearn are the inverse temperature β, the time step-size h, a regularization
parameter ε, and the number of samples N. Additional required inputs are the training feature data
XXX:= [xxx1...xxxndata]⊤∈Rndata×nxand the corresponding training labels yyy:= [y1...yndata]⊤∈Rndata, as
well the weighted point cloud {θθθi
k−1,ϱi
k−1}N
i=1for eachk∈N. Furthermore, ProxLearn requires two
internal parameters as user input: the numerical tolerance δ, and the maximum number of iterations L.
Fork∈N, let
ΘΘΘk−1:=
(θθθ1
k−1)⊤
(θθθ2
k−1)⊤
...
(θθθN
k−1)⊤
∈RN×p, ϱϱϱk−1:=
ϱ1
k−1
ϱ2
k−1...
ϱN
k−1
∈RN
>0.
In line 2 of Algorithm 1, ProxLearn updates the locations of the parameter vector samples θθθi
kinRpvia
Algorithm 2, EulerMaruyama . This location update takes the form:
θθθi
k=θθθi
k−1−h∇/parenleftbig
V/parenleftbig
θθθi
k−1/parenrightbig
+ω/parenleftbig
θθθi
k−1/parenrightbig/parenrightbig
+/radicalbig
2β−1/parenleftbig
ηηηi
k−ηηηi
k−1/parenrightbig
, (35)
10Published in Transactions on Machine Learning Research (12/2023)
Algorithm 1 Proximal Algorithm
1:procedure ProxLearn (ϱϱϱk−1,ΘΘΘk−1,β,h,ε,N,XXX,yyy,δ,L)
2:vvvk−1, UUUk−1,ΘΘΘk←EulerMaruyama (h,β,ΘΘΘk−1,XXX,yyy,ϱϱϱk−1)▷Update the location of the samples
3:CCCk(i,j)←/vextenddouble/vextenddouble/vextenddoubleθθθki−θθθj
k−1/vextenddouble/vextenddouble/vextenddouble2
2
4: ΓΓΓk←exp(−CCCk/2ε) ▷Lines 4-8 define the terms needed in re-expressing (30) as (32)
5:ξξξk−1←exp(−βvvvk−1−βUUUk−1ϱϱϱk−1−111)
6:zzz0←randN×1
7:zzz←[zzz0,000N×(L−1)]
8:qqq←[ϱϱϱk−1⊘(ΓkΓkΓkz0z0z0),000N×(L−1)]
9:ℓ= 1
10: whileℓ≤Ldo
11:zzz(:,ℓ+ 1)←(ξξξk−1⊘(ΓΓΓ⊤
kqqq(:,ℓ))1
1+βε/h ▷Following (32)
12:qqq(:,ℓ+ 1)←ϱϱϱk−1⊘(ΓΓΓkzzz(:,ℓ+ 1)) ▷Following (33)
13: if||qqq(:,ℓ+ 1)−qqq(:,ℓ)||<δand||zzz(:,ℓ+ 1)−zzz(:,ℓ)||<δthen
14: Break
15: else
16: ℓ←ℓ+ 1
17: end if
18: end while
19: returnϱϱϱk←zzz(:,ℓ)⊙(ΓΓΓ⊤
kqqq(:,ℓ)) ▷Use (34) to map ϱϱϱk−1toϱϱϱk
20:end procedure
Algorithm 2 Euler-Maruyama Algorithm
1:procedure EulerMaruyama (h,β,ΘΘΘk−1,XXX,yyy,ϱϱϱk−1)
2:PPPk−1←ΦΦΦ(ΘΘΘk−1,XXX) ▷Lines 2-4 construct the argument of the gradient in (35)
3:UUUk−1←1/ndataPPPk−1PPP⊤
k−1
4:uuuk−1←UUUk−1ϱϱϱk−1
5:vvvk−1←−2/ndataPPPk−1yyy
6:DDD←Backward (uuuk−1+vvvk−1) ▷Approximate the gradient of (35) using PyTorch library
Backward (Paszke et al., 2017)
7:GGG←/radicalbig
2h/β×randnN×p
8: ΘΘΘk←ΘΘΘk−1+h×DDD+GGG ▷ Complete the location update via (35)
9:end procedure
whereω(·) :=/integraltext
U(·,˜θθθ)ϱ(˜θθθ)d˜θθθ, andηηηi
k−1:=ηηηi(t= (k−1)h),∀k∈N.
To perform this update, EulerMaruyama constructs a matrix PPPk−1whose (i,j)th element is PPPk−1(i,j) =
Φ(xxxj,θθθi
k−1). FromPPPk−1, we construct vvvk−1andUUUk−1as in lines 3 and 5. In line 6 of Algorithm 2,
EulerMaruyama uses the automatic differentiation module of PyTorch Library, Backward (Paszke et al.,
2017), to calculate the gradients needed to update ΘΘΘk−1toΘΘΘk∀k∈N.
Once ΘΘΘk,vvvk−1, andUUUk−1have been constructed via EulerMaruyama ,ProxLearn maps theN×1vector
ϱϱϱk−1to the proximal update ϱϱϱk.
We next illustrate the implementation of ProxLearn for binary and multi-class classification case studies.
A GitHub repository containing our code for the implementation of these applications can be found at
https://github.com/zalexis12/Proximal-Mean-Field-Learning.git . Please refer to the Readme file
therein for an outline of the structure of our code.
11Published in Transactions on Machine Learning Research (12/2023)
4 Case study: binary classification
InthisSection, wereportnumericalresultsforourfirstcasestudy, whereweapplytheproposed ProxLearn
algorithm for binary classification.
For this case study, we perform two implementations on different computing platforms. Our first implemen-
tation is on a PC with 3.4 GHz 6-Core Intel Core i5 processor, and 8 GB RAM. For runtime improvement,
we then use a Jetson TX2 with a NVIDIA Pascal GPU with 256 CUDA cores, 64-bit NVIDIA Denver and
ARM Cortex-A57 CPUs.
4.1 WDBC data set
We apply the proposed algorithm to perform a binary classification on the Wisconsin Diagnostic Breast
Cancer (henceforth, WDBC) data set available at the UC Irvine machine learning repository (Dua & Graff,
2017). This data set consists of the data of scans from 569patients. There are nx= 30features from each
scan. Scans are classified as “benign” (which we label as −1) or “malignant” (labeled as +1).
In (2), we define Φ/parenleftbig
xxx,θθθi
k−1/parenrightbig
:=ai
k−1tanh(⟨wwwi
k−1,xxx⟩+bi
k−1)∀i∈[N]after (k−1)updates. The parameters
ai
k−1,wwwi
k−1andbi
k−1are the scaling, weight and bias of the ithsample after (k−1)updates, respectively.
Lettingp:=nx+ 2, the parameter vector of the ithsample after (k−1)updates is
θθθi
k−1:=
ai
k−1
bi
k−1
wwwi
k−1
∈Rp,∀i∈[N].
We setϱ0≡Unif([0.9,1.1]×[−0.1,0.1]×[−1,1]nx), a uniform joint PDF supported over np=nx+ 2 = 32
dimensional mean field parameter space.
We use 70% of the entire data set as training data. As discussed in Sec. 3, we learn the mean field parameter
distribution via weighted scattered point cloud evolution using ProxLearn . We then use the confusion
matrix method (Visa et al., 2011) to evaluate the accuracy of the obtained model over the test data, which
is the remaining 30%of the full data set, containing ntestpoints.
For each test point xxxtest∈Rnx, we construct
φφφ(xxxtest) :=
Φ(xxxtest,θθθ1
k−1)
Φ(xxxtest,θθθ2
k−1)
...
Φ(xxxtest,θθθN
k−1)
∈RN
whereθθθi
k−1is obtained from the training process. We estimate fMeanField in (7) in two ways. First, we
estimatefMeanField as a sample average of the elements of φφφ. Second, we estimate fMeanField by numerically
approximating the integral in (7) using the propagated samples {θθθi
k−1,ϱi
k−1}N
i=1fork∈N. We refer to
these as the “unweighted estimate” and “weighted estimate,” respectively. While the first estimate is an
empirical average, the second uses the weights {ϱi
k−1}N
i=1obtained from the proposed proximal algorithm.
ThefMeanField “unweighted estimate” and “weighted estimate” are then passed through the softmax and
argmax functions respectively, to produce the predicted labels.
4.2 Numerical experiments
We set the number of samples N= 1000, numerical tolerance δ= 10−3, the maximum number of iterations
L= 300, and the regularizing parameter ε= 1. Additionally, we set the time step to h= 10−3. We run
the simulation for different values of the inverse temperature β, and list the corresponding classification
accuracy in Table 1. The “weighted estimate,” the ensemble average using proximal updates, produces more
accurate results, whereas the “unweighted estimate,” the empirical average, is found to be more sensitive to
the inverse temperature β.
12Published in Transactions on Machine Learning Research (12/2023)
UnweightedWeighted
(a) Regularized risk calculated via CPU.
UnweightedWeighted (b) Regularized risk calculated via GPU.
Figure 2: The solid line shows the regularized risk functional Fβversus the number of proximal recursions
shown for the WDBC dataset with β= 0.05. The shadow shows the Fβvariation range for different values
ofβ∈{0.03,0.05,0.07}.
Table 1: Classification accuracy of the proposed computational framework for the WDBC Dataset
βUnweighted Weighted
0.03 91.17% 92.35%
0.05 92.94% 92.94%
0.07 78.23% 92.94%
For each fixed β, we perform 106proximal recursions incurring approx. 33 hours of computational time.
Fig. 2a shows the risk functional, computed as the averaged loss over the test data using each of the two
estimates described above.
To improve the runtime of our algorithm, we run our code on a Jetson TX2 module, converting data and
variables to PyTorch variables.
We begin calculations in Float32, switching to Float64 only when needed to avoid not-a-number (NaN)
errors. This switch typically occurs after 2×105to3×105iterations. As shown in Table 2, we train the
neural network to a comparable accuracy in only 2.5×105iterations. The new runtime is around 6% of
the original runtime for the CPU-based computation. Fig. 2b shows the risk functional calculated via this
updated code. We parallelize these calculations, taking advantage of the GPU capacity of the Jetson TX2.
We utilize these improvements in runtime to additionally experiment with our choice of ε. Table 3 reports
the final values of the regularized risk functional ˆFβand corresponding runtimes for varying ε. As expected,
largerεentails more smoothing and lowers runtime. The corresponding final regularized risk values show
no significant variations, suggesting numerical stability.
4.3 Computational complexity
In this case study, we determine the computational complexity of ProxLearn as follows. Letting aaak−1:=/parenleftbiga1
k−1... aN
k−1/parenrightbig⊤,bbbk−1:=/parenleftbigb1
k−1... bN
k−1/parenrightbig⊤,WWWk−1:=/parenleftbigwww1
k−1... wwwN
k−1/parenrightbig⊤, we create the N×ndata
matrix
PPPk−1:=/parenleftbig
aaak−1111⊤/parenrightbig
⊙tanh(WWWk−1XXX⊤+bbbk−1111⊤), (36)
which has complexity O(ndataNnx). The subsequent creation of matrix UUUk−1in line 3 of Algorithm 2 has
complexity O(ndataN2), and creating vvvk−1anduuuk−1takes complexity O(Nndata)andO(N2)respectively.
13Published in Transactions on Machine Learning Research (12/2023)
Table 2: Classification accuracy on Jetson Tx2, after 2.5×105iterations
βUnweighted Weighted Runtime (hr)
0.03 91.18% 91.18% 1.415
0.05 91.18% 92.94% 1.533
0.07 90.59% 91.76% 1.704
Table 3: Comparing final ˆFβand runtimes for various ε
εUnweighted Final ˆFβRuntime (s)
0.1 1.4348×10−232863
0.5 1.3740×10−211026
1 1.0412×10−25022
5 1.1293×10−24731
10 9.8849×10−34766
Thecomplexityincalculatingtherelevantderivativesof vvvk−1anduuuk−1isO(N2ndatanx)(thesederivativesare
calculated in Appendices B and C). Updating ΘΘΘk−1using these results has complexity of O(Np) =O(Nnx).
Therefore, the process of updating ΘΘΘk−1viaEulerMaruyama isO(N2ndatanx).
The significant complexity in the remainder of ProxLearn arises in the construction of matrix CCCkin line
3 and the matrix-vector multiplications within the while loop in lines 11, 12.
The creation of the N×NmatrixCCCk, in which each element is the vector norm of a nx×1vector, is
O(nxN2). In a worst-case scenario, the while loop runs Ltimes. The operations of leading complexity
within the while loop are the multiplications of the ΓΓΓkmatrix of size N×Nwith theN×1vectors, which
have a complexity of O(N2). Therefore, the while loop has a complexity of O(LN2).
Updatingϱϱϱk−1thus has a complexity of O((nx+L)N2). In practice, the while loop typically ends far before
reaching the maximum number of iterations L.
Fromthisanalysis, wefindthattheoverallcomplexityof ProxLearn isO(N2(ndatanx+L)). Incomparison,
the per iteration complexity for JKO-ICNN is O/parenleftbig
Ninner(N+ 1)Nbatch +N3/parenrightbig
whereNinnerdenotes the
number of inner optimization steps, and Nbatchdenotes the batch size. The per iteration complexity for
SWGF isO(NinnerNprojNbatch logNbatch)whereNprojdenotes the number of projections to approximate the
sliced Wasserstein distance.
4.4 Comparisons to existing results
From Fig. 2, we observe that there is a significant burn in period for the risk functional curves. These trends
in learning curves agree with those reported in (Mei et al., 2018). In particular, (Mei et al., 2018, Fig. 3)
and Fig. 7.3 in that reference’s Supporting Information , show convergence trends very similar to our Fig.
2: slow decay until approx. 105iterations and then a significant speed up. The unusual convergence trend
was explicitly noted in (Mei et al., 2018): “We observe that SGD converges to a network with very small
risk, but this convergence has a nontrivial structure and presents long flat regions”. It is interesting to note
that (Mei et al., 2018) considered an experiment that allowed rotational symmetry and simulated the radial
(i.e., with one spatial dimension) discretized PDE, while we used the proposed proximal recursion directly
in the neuron population ensemble to solve the PDE IVP, i.e., similar convergence trends were observed
using different numerical methods applied to the same mean field PDE IVP. This makes us speculate that
the convergence trend is specific to the mean field PDE dynamics itself, and is less about the particular
numerical algorithm. This observation is consistent with recent works such as (Wojtowytsch & Weinan,
2020) which investigate the mean field learning dynamics in two layer ReLU networks and in that setting,
show that the learning can indeed be slow depending on the target function.
14Published in Transactions on Machine Learning Research (12/2023)
Table 4: Comparison of average classification accuracy from Bonet et al. (2022, Table 1) to our algorithm,
ProxLearn
Dataset JKO-ICNN SWGF + RealNVP ProxLearn, Weighted ProxLearn, Unweighted
Banana 0.550±10−20.559±10−20.551±10−20.535±5·10−2
Diabetes 0.777±7·10−30.778±2·10−30.736±2·10−20.731±10−2
Twonorm 0.981±2·10−40.981±6·10−40.972±2·10−30.972±2·10−3
As a first study, our numerical results achieve reasonable classification accuracy compared to the state-of-art,
even though our proposed meshless proximal algorithm is very different from the existing implementations.
We next compare the numerical performance with existing methods as in Mokrov et al. (2021) and Bonet
et al. (2022). We apply our proximal algorithm for binary classification to three datasets also considered in
Mokrov et al. (2021) and Bonet et al. (2022): the banana, diabetes, and twonorm datasets.
The banana dataset consists of 5300 data points, each with nx= 2features, which we rescale to lie between
0 and 8. We set β= 0.05, draw our initial weights wwwfrom Unif ([−2,2]nx)and biasbfrom Unif ([−0.3,0.3]),
and setϱϱϱ0≡Unif(0,1000). We run our code for 3500iterations, splitting the data evenly between test and
training data.
The diabetes dataset consists of nx= 8features from each of 768patients. Based on our experimental
results, we make the following adjustments to our algorithm: we redefine β= 0.65,ϱϱϱ0≡Unif(0,1000), and
draw our initial weights wwwfrom Unif ([−2,2]nx). We rescale the data to lie between 0 and 1, and use half of
the dataset for training purposes, and the remainder as test data. In this case, we run our code for 4.99×105
iterations.
The twonorm dataset consists of 7,400 samples drawn from two different normal distributions, with nx= 20
features. We again consider 50% of the same as training data and used the remaining 50% as test data, and
rescale the given data by a factor of 8. Based on our empirical observations, we redefine β= 1.95, and once
more draw our initial weights wwwfrom Unif ([−2,2]nx)and setϱϱϱ0≡Unif(0,1000). In this case, we perform
104proximal recursions in each separate run.
We run our code five times for each of the three datasets under consideration and compute “unweighted
estimates” and “weighted estimates” in each case, as described above. These estimates assign each data
point a value: negative values predict the label as 0, while positive values predict the label as 1. From these
results, we calculate the weighted and unweighted accuracy by finding the percentage of predicted test labels
that match the actual test labels. The average accuracy over all five runs is reported in Table 4, alongside
the results reported in Bonet et al. (2022, Table 1). We achieve comparable accuracy to these recent results.
5 Case study: multi-class classification
We next apply the proposed proximal algorithm to a ten-class classification problem using the Semeion
Handwritten Digit (hereafter SHD) Data Set (Dua & Graff, 2017). This numerical experiment is performed
on the aforementioned Jetson TX2.
5.1 SHD data set
The SHD Data Set consists of 1593 handwritten digits. By viewing each digit as 16×16pixel image, each
image is represented by nx= 162= 256features. Each feature is a boolean value indicating whether a
particular pixel is filled. We subsequently re-scale these features such that xxxi∈{− 1,1}nx.
15Published in Transactions on Machine Learning Research (12/2023)
5.2 Adaptations to ProxLearn for multi-class case
To apply ProxLearn for a multi-class case, we make several adaptations. For instance, rather than at-
tempting to determine f(xxx)≈y, we redefine f(xxx)to represent a mapping of input data to the predicted
likelihood of the correct label. We therefore redefine the variables, parameters, and risk function as follows.
Each label is represented by a 1×10vector of booleans, stored in a ndata×10matrixYYYwhereYi,j= 1if
theithdata pointxxxihas labelj, andYi,j= 0otherwise.
We construct the N×ndatamatrixPPPk−1by defining the (j,i)element ofPPPk−1as
PPPk−1(j,i) := ΦΦΦ(θθθj
k−1,XXX(i,:),YYY(i,:))
:=/angbracketleftbigg
softmax (XXX(i,:)(θθθj
k−1)⊤),(YYY(i,:))⊤/angbracketrightbigg
(37)
where⟨·,·⟩denotes the standard Euclidean inner product. The softmax function in (37) produces a 10×1
vector of non-negative entries that sum to 1. By taking the inner product of this vector with the Boolean
vectorYYY(i,:), we definePPPk−1(j,i) = ΦΦΦ(θθθj
k−1,XXX(i,:),YYY(i,:))as the perceived likelihood that the data point i
islabeledcorrectlybysample j. Asourmodelimproves, thisvalueapproaches 1, whichcausestheprobability
of an incorrect label to drop.
As this newly defined PPPk−1does not call for bias or scaling, the weights alone are stored in the N×pmatrix
ΘΘΘk−1. In this case, p:= 10nx, as each of the nxfeatures requires a distinct weight for each of the ten labels.
For convenience, we reshape ΘΘΘk−1= (θθθ1
k−1,...,θθθN
k−1), where each θθθi
k−1is a10×nxmatrix. Therefore, ΘΘΘk−1
is a10×nx×Ntensor.
We redefine the unregularized risk to reflect our new ΦΦΦas follows:
F(ρ) :=E(xxx,yyy)/parenleftbigg
1−/integraldisplay
RpΦ(xxx,yyy,θθθ)ρ(θθθ)dθθθ/parenrightbigg2
. (38)
Expanding the above, we arrive at a form that resembles (8), now with the following adjusted definitions:
F0:= 1, (39)
V(θθθ) :=E(xxx,yyy)[−2Φ(θθθ,xxx,yyy)], (40)
U(θθθ,˜θθθ) :=E(xxx,yyy)[Φ(θθθ,xxx,yyy)Φ(˜θθθ,xxx,yyy)]. (41)
We use the regularized risk functional Fβas in (12) where Fnow is given by (38). Due to the described
changes in the structure of ΘΘΘk−1, the creation of CCCkin line 3 of ProxLearn results in a 10×N×Ntensor,
which we then sum along the ten element axis, returning an N×Nmatrix.
Finally, we add a scaling in line 7 of EulerMaruyama , scaling the noise by a factor of 1/100.
5.3 Numerical experiments
With the adaptations mentioned above, we set the inverse temperature β= 0.5,ϵ= 10, the step size
h= 10−3, andN= 100. We draw the initial weights from Unif/parenleftbig
[−1,1]10nx/parenrightbig
. We take the first ndata= 1000
images as training data, reserving the remaining ntest= 593images as test data, and execute 30 independent
runs of our code, each for 106proximal recursions.
To evaluate the training process, we create a matrix PPPtest
k−1∈RN×ntest, using test data rather than training
data, but otherwise defined as in (37). We then calculate a weighted approximation of Fβ:
Fβ≈1
ntest/vextenddouble/vextenddouble/vextenddouble/vextenddouble111−(PPPtest
k−1)⊤ϱϱϱ/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2, (42)
and an unweighted approximation:
Fβ≈1
ntest/vextenddouble/vextenddouble/vextenddouble/vextenddouble111−1
N(PPPtest
k−1)⊤111/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
2, (43)
16Published in Transactions on Machine Learning Research (12/2023)
Figure 3: The solid line shows the average regularized risk functional Fβversus the number of proximal
recursions shown for the Semeion dataset with β= 0.5. The narrow shadow shows the Fβvariation range
with the same βusing the results of 30 independent runs, each starting from the same initial point cloud/braceleftbig
θθθi
0,ϱi
0/bracerightbigN
i=1.
which we use to produce the risk and weighted risk log-log plots shown in Fig. 3.
Notably, despite the new activation function and the adaptations described above, our algorithm produces
similar risk plots in the binary and multi-class cases. The run time for 106iterations is approximately 5.3
hours.
To evaluate our multi-class model, we calculate the percentage of accurately labeled test data by first taking
argmax (XXXtestΘΘΘk−1)along the ten dimensional axis, to determine the predicted labels for each test data
pointusingeachsampleof ΘΘΘk−1. Wethencomparethesepredictedlabelswiththeactuallabels. Weachieved
61.079%accuracy for the test data, and 75.330%accuracy for the training data.
5.4 Updated computational complexity of ProxLearn
In the binary case, the creation of matrix CCCkrequiresO(nxN2)flops. In the case of multi-class classification
concerning mclasses,CCCkis redefined as the sum of msuch matrices. Therefore, creating the updated matrix
CCCktakesO(mnxN2)flops. Thus, updating ϱϱϱk−1is of complexity O((mnx+L)N2). The complexity of
EulerMaruyama can be generalized from the discussion in Sec. 4.
6 Conclusions
6.1 Summary
This work presents a proximal mean field learning algorithm to train a shallow neural network in the over-
parameterized regime. The proposed algorithm is meshless, non-parametric and implements the Wasserstein
proximal recursions realizing the gradient descent of entropic-regularized risk. Numerical case studies in
binary and multi-class classification demonstrate that the ideas of mean field learning can be attractive as
computational framework, beyond purely theoretical interests. Our contribution should be of interest to
other learning and variational inference tasks such as the policy optimization and adversarial learning.
17Published in Transactions on Machine Learning Research (12/2023)
We clarify that the proposed algorithm is specifically designed for a neural network with single hidden layer
in large width regime. For multi-hidden layer neural networks, the mean field limit in the sense of width
as pursued here, is relatively less explored for the training dynamics. In the multiple hidden layer setting,
theoretical understanding of the limits is a frontier of current research; see e.g., Fang et al. (2021); Sirignano
& Spiliopoulos (2022). Extending these ideas to design variants of proximal algorithms requires new lines
of thought, and as such, is out-of-scope of this paper. In the following, we outline the scope for such future
work.
6.2 Scope for future work
Existing efforts to generalize the theoretical results for the mean field limit as in this work, from single to
multi-hidden layer networks, have been pursued in two different limiting sense. One line of investigations
(Sirignano & Spiliopoulos, 2020; 2022; Yu & Spiliopoulos, 2023) take the infinite width limit one hidden layer
at a time while holding the (variable) widths of other hidden layers fixed. More precisely, if the ith hidden
layer hasNineurons, then the limit is taken by first normalizing that layer’s output by Nγi
ifor some fixed
γi∈[1/2,1]and then letting Ni→∞for an index iwhile holding other Nj’s fixed and finite, j̸=i.
A different line of investigations (Araújo et al., 2019; Nguyen, 2019) consider the limit where the widths of all
hidden layers simultaneously go to infinity. In this setting, the population distribution over the joint (across
hidden layers) parameter space is shown to evolve under SGD as per a McKean-Vlasov type nonlinear IVP;
see (Araújo et al., 2019, Def. 4.4 and Sec. 5). We anticipate that the proximal recursions proposed herein can
be extended to this setting by effectively lifting the Wasserstein gradient flow to the space of measure-valued
paths. Though not quite the same, but this is similar in spirit to how classical bi-mariginal Schrödinger
bridge problems (Léonard, 2012; Chen et al., 2021) have been generalized to multi-marginal settings over
the path space and have led to significant algorithmic advances in recent years (Haasler et al., 2021; Carlier,
2022; Chen et al., 2023). Pursuing such ideas for designing proximal algorithms in the multiple hidden layer
case will comprise our future work.
Acknowledgment
This work was supported by NSF award 2112755. The authors acknowledge the reviewers’ perceptive feed-
back to help improve this paper.
References
David Alvarez-Melis, Yair Schiff, and Youssef Mroueh. Optimizing functionals on the space of probabilities
with input convex neural network. In Annual Conference on Neural Information Processing Systems , 2021.
Luigi Ambrosio, Nicola Gigli, and Giuseppe Savaré. Gradient flows: in metric spaces and in the space of
probability measures . Springer Science & Business Media, 2005.
Brandon Amos, Lei Xu, and J Zico Kolter. Input convex neural networks. In International Conference on
Machine Learning , pp. 146–155. PMLR, 2017.
Dyego Araújo, Roberto I Oliveira, and Daniel Yukimura. A mean-field limit for certain deep neural networks.
arXiv preprint arXiv:1906.00193 , 2019.
Andrew R Barron. Universal approximation bounds for superpositions of a sigmoidal function. IEEE
Transactions on Information theory , 39(3):930–945, 1993.
Heinz H Bauschke, Patrick L Combettes, et al. Convex analysis and monotone operator theory in Hilbert
spaces, volume 408. Springer, 2011.
Jean-David Benamou, Guillaume Carlier, and Maxime Laborde. An augmented Lagrangian approach to
Wasserstein gradient flows and applications. ESAIM: Proceedings and surveys , 54:1–17, 2016.
18Published in Transactions on Machine Learning Research (12/2023)
Dimitri P Bertsekas et al. Incremental gradient, subgradient, and proximal methods for convex optimization:
A survey. Optimization for Machine Learning , 2010(1-38):3, 2011.
Clément Bonet, Nicolas Courty, François Septier, and Lucas Drumetz. Sliced-Wasserstein gradient flows.
arXiv preprint arXiv:2110.10972 , 2021.
Clément Bonet, Nicolas Courty, François Septier, and Lucas Drumetz. Efficient gradient flows in sliced-
wasserstein space. arXiv preprint arxiv:2110.10972 , 2022.
Etienne Boursier, Loucas Pillaud-Vivien, and Nicolas Flammarion. Gradient flow dynamics of shallow relu
networks for square loss and orthogonal inputs. Advances in Neural Information Processing Systems , 35:
20105–20118, 2022.
Yann Brenier. Polar factorization and monotone rearrangement of vector-valued functions. Communications
on pure and applied mathematics , 44(4):375–417, 1991.
Charlotte Bunne, Laetitia Papaxanthos, Andreas Krause, and Marco Cuturi. Proximal optimal transport
modeling of population dynamics. In International Conference on Artificial Intelligence and Statistics ,
pp. 6511–6528. PMLR, 2022.
Kenneth F Caluya and Abhishek Halder. Gradient flow algorithms for density propagation in stochastic
systems. IEEE Transactions on Automatic Control , 65(10):3991–4004, 2019a.
Kenneth F Caluya and Abhishek Halder. Proximal recursion for solving the Fokker-Planck equation. In
2019 American Control Conference (ACC) , pp. 4098–4103. IEEE, 2019b.
KennethFCaluyaandAbhishekHalder. ReflectedSchrödingerbridge: Densitycontrolwithpathconstraints.
In2021 American Control Conference (ACC) , pp. 1137–1142. IEEE, 2021a.
Kenneth F Caluya and Abhishek Halder. Wasserstein proximal algorithms for the Schrödinger bridge prob-
lem: Density control with nonlinear drift. IEEE Transactions on Automatic Control , 67(3):1163–1178,
2021b.
Guillaume Carlier. On the linear convergence of the multimarginal sinkhorn algorithm. SIAM Journal on
Optimization , 32(2):786–794, 2022.
Guillaume Carlier, Vincent Duval, Gabriel Peyré, and BeSchrnhard SchmitzeSchr. Convergence of entropic
schemes for optimal transport and gradient flows. SIAM Journal on Mathematical Analysis , 49(2):1385–
1418, 2017.
RenéCarmonaandFrançoisDelarue. Probabilistic theory of mean field games with applications I-II . Springer,
2018.
José A Carrillo, Katy Craig, Li Wang, and Chaozhen Wei. Primal dual methods for Wasserstein gradient
flows.Foundations of Computational Mathematics , 22(2):389–443, 2022.
Tianrong Chen, Guan-Horng Liu, Molei Tao, and Evangelos A Theodorou. Deep momentum multi-marginal
schr\" odinger bridge. arXiv preprint arXiv:2303.01751 , 2023.
Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. Stochastic control liaisons: Richard sinkhorn meets
gaspard monge on a schrodinger bridge. Siam Review , 63(2):249–313, 2021.
Lenaic Chizat and Francis Bach. On the global convergence of gradient descent for over-parameterized
models using optimal transport. Advances in neural information processing systems , 31, 2018.
Casey Chu, Jose Blanchet, and Peter Glynn. Probability functional descent: A unifying perspective on
GANS, variational inference, and reinforcement learning. In International Conference on Machine Learn-
ing, pp. 1213–1222. PMLR, 2019.
George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of control, signals
and systems , 2(4):303–314, 1989.
19Published in Transactions on Machine Learning Research (12/2023)
Carles Domingo-Enrich, Samy Jelassi, Arthur Mensch, Grant Rotskoff, and Joan Bruna. A mean-field
analysis of two-player zero-sum games. Advances in neural information processing systems , 33:20215–
20226, 2020.
Dheeru Dua and Casey Graff. UCI machine learning machine learning repository. 2017. URL "http:
//archive.ics.uci.edu/ml" .
Cong Fang, Jason Lee, Pengkun Yang, and Tong Zhang. Modeling from features: a mean-field framework
for over-parameterized deep neural networks. In Conference on learning theory , pp. 1887–1936. PMLR,
2021.
CharlieFrognerandTomasoPoggio. ApproximateinferencewithWassersteingradientflows. In International
Conference on Artificial Intelligence and Statistics , pp. 2581–2590. PMLR, 2020.
Isabel Haasler, Axel Ringh, Yongxin Chen, and Johan Karlsson. Multimarginal optimal transport with a
tree-structured cost and the schrodinger bridge problem. SIAM Journal on Control and Optimization , 59
(4):2428–2453, 2021.
Abhishek Halder and Tryphon T Georgiou. Gradient flows in uncertainty propagation and filtering of linear
gaussian systems. In 2017 IEEE 56th Annual Conference on Decision and Control (CDC) , pp. 3081–3088.
IEEE, 2017.
Abhishek Halder and Tryphon T Georgiou. Gradient flows in filtering and Fisher-Rao geometry. In 2018
Annual American Control Conference (ACC) , pp. 4281–4286. IEEE, 2018.
Abhishek Halder and Tryphon T Georgiou. Proximal recursion for the Wonham filter. In 2019 IEEE 58th
Conference on Decision and Control (CDC) , pp. 660–665. IEEE, 2019.
Abhishek Halder, Kenneth F Caluya, Bertrand Travacca, and Scott J Moura. Hopfield neural network flow:
A geometric viewpoint. IEEE Transactions on Neural Networks and Learning Systems , 31(11):4869–4880,
2020.
Abhishek Halder, Kenneth F Caluya, Pegah Ojaghi, and Xinbo Geng. Stochastic uncertainty propagation in
power system dynamics using measure-valued proximal recursions. IEEE Transactions on Power Systems ,
2022.
Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are universal
approximators. Neural networks , 2(5):359–366, 1989.
Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural tangent kernel: Convergence and generalization
in neural networks. Advances in neural information processing systems , 31, 2018.
Richard Jordan, David Kinderlehrer, and Felix Otto. The variational formulation of the Fokker–Planck
equation. SIAM journal on mathematical analysis , 29(1):1–17, 1998.
Mark Kac. Foundations of kinetic theory. In Proceedings of The third Berkeley symposium on mathematical
statistics and probability , volume 3, pp. 171–197, 1956.
Johan Karlsson and Axel Ringh. Generalized Sinkhorn iterations for regularizing inverse problems using
optimal mass transport. SIAM Journal on Imaging Sciences , 10(4):1935–1962, 2017.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980 , 2014.
Maxime Laborde. On some nonlinear evolution systems which are perturbations of Wasserstein gradient
flows.Topological Optimization and Optimal Transport: In the Applied Sciences , 17:304–332, 2017.
Jaehoon Lee, Lechao Xiao, Samuel Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-Dickstein, and
Jeffrey Pennington. Wide neural networks of any depth evolve as linear models under gradient descent.
Advances in neural information processing systems , 32, 2019.
20Published in Transactions on Machine Learning Research (12/2023)
Christian Léonard. From the schrödinger problem to the monge–kantorovich problem. Journal of Functional
Analysis, 262(4):1879–1920, 2012.
Ping Li and Phan-Minh Nguyen. On random deep weight-tied autoencoders: Exact asymptotic analysis,
phase transitions, and implications to training. In International Conference on Learning Representations ,
2018.
Chang Liu, Jingwei Zhuo, Pengyu Cheng, Ruiyi Zhang, and Jun Zhu. Understanding and accelerating
particle-based variational inference. In International Conference on Machine Learning , pp. 4082–4092.
PMLR, 2019.
Yulong Lu. Two-scale gradient descent ascent dynamics finds mixed nash equilibria of continuous games: A
mean-field perspective. In International Conference on Machine Learning , pp. 22790–22811. PMLR, 2023.
Alexander G de G Matthews, Jiri Hron, Mark Rowland, Richard E Turner, and Zoubin Ghahramani. Gaus-
sian process behaviour in wide deep neural networks. In International Conference on Learning Represen-
tations, 2018.
Henry P McKean Jr. A class of Markov processes associated with nonlinear parabolic equations. Proceedings
of the National Academy of Sciences , 56(6):1907–1911, 1966.
Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape of two-layer
neural networks. Proceedings of the National Academy of Sciences , 115(33):E7665–E7671, 2018.
Petr Mokrov, Alexander Korotin, Lingxiao Li, Aude Genevay, Justin M Solomon, and Evgeny Burnaev.
Large-scale Wasserstein gradient flows. Advances in Neural Information Processing Systems , 34:15243–
15256, 2021.
Youssef Mroueh and Truyen Nguyen. On the convergence of gradient descent in GANs: MMD GAN as a
gradient flow. In International Conference on Artificial Intelligence and Statistics , pp. 1720–1728. PMLR,
2021.
Phan-Minh Nguyen. Mean field limit of the learning dynamics of multilayer neural networks. arXiv preprint
arXiv:1902.02880 , 2019.
Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander A Alemi, Jascha Sohl-Dickstein, and
Samuel S Schoenholz. Neural tangents: Fast and easy infinite neural networks in python. In Interna-
tional Conference on Learning Representations , 2019.
Neal Parikh, Stephen Boyd, et al. Proximal algorithms. Foundations and trends ®in Optimization , 1(3):
127–239, 2014.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin,
Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.
Gabriel Peyré. Entropic approximation of Wasserstein gradient flows. SIAM Journal on Imaging Sciences ,
8(4):2323–2351, 2015.
Julien Rabin, Gabriel Peyré, Julie Delon, and Marc Bernot. Wasserstein barycenter and its application to
texture mixing. In International Conference on Scale Space and Variational Methods in Computer Vision ,
pp. 435–446. Springer, 2011.
R. Tyrrell Rockafellar. Augmented Lagrangians and applications of the proximal point algorithm in convex
programming. Mathematics of operations research , 1(2):97–116, 1976a.
R Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. SIAM journal on control and
optimization , 14(5):877–898, 1976b.
Grant Rotskoff and Eric Vanden-Eijnden. Trainability and accuracy of artificial neural networks: An inter-
acting particle system approach. Communications on Pure and Applied Mathematics , 75(9):1889–1935,
2022.
21Published in Transactions on Machine Learning Research (12/2023)
Grant M Rotskoff and Eric Vanden-Eijnden. Neural networks as interacting particle systems: Asymptotic
convexity of the loss landscape and universal scaling of the approximation error. stat, 1050:22, 2018.
Adil Salim, Anna Korba, and Giulia Luise. The Wasserstein proximal gradient algorithm. Advances in
Neural Information Processing Systems , 33:12356–12366, 2020.
Filippo Santambrogio. {Euclidean, metric, and Wasserstein }gradient flows: an overview. Bulletin of Math-
ematical Sciences , 7(1):87–154, 2017.
Justin Sirignano and Konstantinos Spiliopoulos. Mean field analysis of neural networks: A central limit
theorem. Stochastic Processes and their Applications , 130(3):1820–1852, 2020.
Justin Sirignano and Konstantinos Spiliopoulos. Mean field analysis of deep neural networks. Mathematics
of Operations Research , 47(1):120–152, 2022.
Alain-Sol Sznitman. Topics in propagation of chaos. In Ecole d’été de probabilités de Saint-Flour XIX—1989 ,
pp. 165–251. Springer, 1991.
Marc Teboulle. Entropic proximal mappings with applications to nonlinear programming. Mathematics of
Operations Research , 17(3):670–690, 1992.
Anthony C Thompson. On certain contraction mappings in a partially ordered vector space. Proceedings of
the American Mathematical Society , 14(3):438–443, 1963.
Cédric Villani. Optimal transport: old and new , volume 338. Springer, 2009.
Cédric Villani. Topics in optimal transportation , volume 58. American Mathematical Soc., 2021.
Sofia Visa, Brian Ramsay, Anca L Ralescu, and Esther Van Der Knaap. Confusion matrix-based feature
selection. MAICS, 710:120–127, 2011.
Stephan Wojtowytsch and E Weinan. Can shallow neural networks beat the curse of dimensionality? a mean
field training perspective. IEEE Transactions on Artificial Intelligence , 1(2):121–129, 2020.
LechaoXiao, YasamanBahri, JaschaSohl-Dickstein, SamuelSchoenholz, andJeffreyPennington. Dynamical
isometryandameanfieldtheoryofCNNs: Howtotrain10,000-layervanillaconvolutionalneuralnetworks.
InInternational Conference on Machine Learning , pp. 5393–5402. PMLR, 2018.
Jiahui Yu and Konstantinos Spiliopoulos. Normalization effects on deep neural networks. Foundations of
Data Science , 5(3):389–465, 2023.
Junyu Zhang, Alec Koppel, Amrit Singh Bedi, Csaba Szepesvari, and Mengdi Wang. Variational policy gra-
dient method for reinforcement learning with general utilities. Advances in Neural Information Processing
Systems, 33:4572–4583, 2020.
Ruiyi Zhang, Changyou Chen, Chunyuan Li, and Lawrence Carin. Policy optimization as Wasserstein
gradient flows. In International Conference on Machine Learning , pp. 5737–5746. PMLR, 2018.
A Proof of Theorem 1
We provide the formal statement followed by the proof.
Theorem 1. Consider the regularized risk functional (12) wherein Fis given by (8)-(9). Let ρ(t,θθθ)solve
the IVP (14), and let {ϱk−1}k∈Nbe the sequence generated by (17) with ϱ0≡ρ0. Define the interpolation
ϱh: [0,∞)×Rp∝⇕⊣√∫⊔≀→[0,∞)as
ϱh(t,θθθ) :=ϱk−1(h,θθθ)∀t∈[(k−1)h,kh ), k∈N.
Thenϱh(t,θθθ)h↓0−−→ρ(t,θθθ)inL1(Rp).
22Published in Transactions on Machine Learning Research (12/2023)
Proof.Our proof follows the general development in Laborde (2017, Sec. 12.3). In the following, we sketch
the main ideas.
We have the semi-implicit free energy
ˆFβ(ϱ,ϱk−1) =Eϱ/bracketleftbigg
F0+V(θθθ) +/integraldisplay
RpU(θθθ,˜θθθ)ϱk−1(˜θθθ)d˜θθθ/bracketrightbigg
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
=:Vadvec (ϱ)+β−1Eϱ[logϱ], k∈N,
wherein the summand
Vadvec(ϱ) :=Eϱ/bracketleftbigg
F0+V(θθθ) +/integraldisplay
RpU(θθθ,˜θθθ)ϱk−1(˜θθθ)d˜θθθ/bracketrightbigg
is linear in ϱ, and contributes as an effective advection potential energy. The remaining summand
β−1Eϱ[logϱ]results in from diffusion regularization and contributes as an internal energy term.
We note from equation 9 that the functional Vadvec(ϱ)is lower bounded for all ϱ∈P 2(Rp). Furthermore,
Vadvec(ϱ)and∇Vadvec(ϱ)are uniformly Lipschitz continuous, i.e., there exists C1>0such that
∥∇V advec(ϱ)∥L∞(Rp)+∥∇2Vadvec(ϱ)∥L∞(Rp)≤C1
for allϱ∈P 2(Rp)where the constant C1>0is independent of ϱ, and∇2denotes the Euclidean Hessian
operator.
Moreover, there exists C2>0such that for all ϱ,˜ϱ∈P2(Rp), we have
∥∇V advec(ϱ)−∇V advec(˜ϱ)∥L∞(Rp)≤C2W2(ϱ,˜ϱ).
Thus,Vadvec(ϱ)satisfy the hypotheses in Laborde (2017, Sec. 12.2).
Fort∈[0,T], we say that ρ(t,θθθ)∈C([0,T],P2(Rp))is a weak solution of the IVP equation 14 if for any
smooth compactly supported test function φ∈C∞
c([0,∞)×Rp), we have
/integraldisplay∞
0/integraldisplay
Rp/parenleftbigg/parenleftbigg∂φ
∂t−⟨∇φ,∇Vadvec(ϱ)⟩/parenrightbigg
ρ+β−1ρ∆φ/parenrightbigg
dθθθdt=−/integraldisplay
Rpφ(t= 0,θθθ)ρ0(θθθ). (44)
Following Laborde (2017, Sec. 12.2), under the stated hypotheses on Vadvec(ϱ), there exists weak solution of
the IVP equation 14 that is continuous w.r.t. the W2metric.
The remaining of the proof follows the outline below.
•Using the Dunford-Pettis’ theorem, establish that the sequence of functions {ϱk(h,θθθ)}k∈Nsolving
equation 17 is unique.
•Define the interpolation ϱh(t) :=ϱk(h,θθθ)ift∈((k−1)h,kh ]for allk∈N. Then establish that ϱh(t)
solves a discrete approximation of equation 44.
•Finally combine the gradient estimates and pass to the limit h↓0, to conclude that ρh(t)in this
limit solves converges to the weak solution of equation 44 in strong L1(Rp)sense.
Forthedetailedcalculationsonthepassagetothelimit, wereferthereaderstoLaborde(2017, Sec. 12.5).
B Expressions involving the derivatives of vvv
We define matrices
TTT:= tanh/parenleftbig
WXWXWX⊤+bbb111⊤/parenrightbig
,
SSS:= sech2/parenleftbig
WXWXWX⊤+bbb111⊤/parenrightbig
,
23Published in Transactions on Machine Learning Research (12/2023)
where 111is a vector of all ones of size ndata×1, and the functions tanh(·)andsech2(·)are elementwise. Notice
thatTTT,SSS∈RN×ndata. Then
vvv=−2
ndataaaa⊙/parenleftbig
tanh(WWWXXX⊤+bbb111⊤)yyy/parenrightbig
=−2
ndataaaa⊙(TyTyTy).
Proposition 2. With the above notations in place, we have
∂vvv
∂aaa111 =N/summationdisplay
k=1∂vvvk
∂aaa=−2
ndataTyTyTy, (45)
and
∂vvv
∂bbb111 =N/summationdisplay
k=1∂vvvk
∂bbb=−2
ndataaaa⊙SySySy. (46)
Furthermore,
N/summationdisplay
k=1∂vvvk
∂WWW=−2
ndata/bracketleftbig/parenleftbig
aaa111⊤/parenrightbig
⊙/parenleftbig
SSS/parenleftbig
XXX⊙yyy111⊤/parenrightbig/parenrightbig/bracketrightbig
. (47)
Proof.Thekthelement ofvvvisvvvk=−2
ndataaaak/summationtextndata
i=1[TTTk,iyyyi]. Thus,
∂vvvk
∂aaaj=/braceleftigg
0 fork̸=j,
−2
ndata/summationtextndata
i=1[TTTk,iyyyi]fork=j.
So the matrix∂vvv
∂aaais diagonal, and
/bracketleftbigg∂vvv
∂aaa111/bracketrightbigg
k=−2
ndatandata/summationdisplay
i=1[TTTk,iyyyi] =−2
ndata[TyTyTy]k.
Hence, we obtain
∂vvv
∂aaa111 =−2
ndataTyTyTy,
which is (45).
On the other hand,
∂vvvk
∂bbbk=∂
∂bbbk/bracketleftigg
−2
ndataaaakndata/summationdisplay
i=1[TTTk,iyyyi]/bracketrightigg
=−2
ndataaaakndata/summationdisplay
i=1∂
∂bbbk[TTTk,iyyyi].
Note that
∂
∂bbbk[TTTk,iyyyi] =∂
∂bbbktanh
nx/summationdisplay
j=1(WWWk,jXXXi,j) +bbbk
yyyi
= sech2
nx/summationdisplay
j=1(WWWk,jXXXi,j) +bbbk
yyyi=SSSk,iyyyi.
24Published in Transactions on Machine Learning Research (12/2023)
Therefore,
∂vvvk
∂bbbj=/braceleftigg
0 fork̸=j,
−2
ndataaaak/summationtextndata
i=1[SSSk,iyyyi]fork=j.
As the matrix∂vvv
∂bbbis diagonal, we get
/bracketleftbigg∂vvv
∂bbb111/bracketrightbigg
k=−2
ndataaaakndata/summationdisplay
i=1[SSSk,iyyyi] =−2
ndataaaak[SSSyyy]k,
and so
∂vvv
∂bbb111 =−2
ndataaaa⊙SySySy,
which is indeed (46).
Likewise, we take an element-wise approach to the derivatives with respect to weights WWWk,m. Note that such
a weightWWWk,mwill only appear in the kth element of vvv, and so we only need to compute
∂vvvk
∂WWWk,m=−2
ndataaaakndata/summationdisplay
i=1∂
∂WWWk,m[TTTk,iyyyi].
Since
∂
∂WWWk,m[TTTk,iyyyi] =∂
∂WWWk,mtanh
nx/summationdisplay
j=1(WWWk,jXXXj,i) +bbbk
yyyi
= sech2
nx/summationdisplay
j=1(WWWk,jXXXi,j) +bbbk
XXXi,myyyi=SSSk,iXXXi,myyyi,
we have
∂vvvk
∂WWWm,j=/braceleftigg
0 fork̸=m,
−2
ndataaaak/summationtextndata
i=1[SSSk,iXXXi,myyyi]fork=m.
Thus,
N/summationdisplay
k=1∂vvvk
∂WWWm,j=−2
ndataaaamndata/summationdisplay
i=1[SSSm,iXXXi,myyyi]
=−2
ndataaaam/bracketleftbig
SSS/parenleftbig
XXX⊙/parenleftbig
yyy111⊤/parenrightbig/parenrightbig/bracketrightbig
m,j.
Therefore, considering 111∈Rnx, we write
N/summationdisplay
k=1∂vvvk
∂WWW=−2
ndata/bracketleftbig/parenleftbig
aaa111⊤/parenrightbig
⊙/parenleftbig
SSS/parenleftbig
XXX⊙yyy111⊤/parenrightbig/parenrightbig/bracketrightbig
,
thus arriving at (47). This completes the proof.
C Expressions involving the derivatives of uuu
Expressions involving the derivatives of uuu, are summarized in the Proposition next. These results find use
in Sec. 4. We start by noting that
uuu=1
ndata(111⊤aaa⊙TTT)(111⊤aaa⊙TTT)⊤ρρρ
=1
ndata(111⊤aaa⊙TTT)(aaa⊤111⊙TTT⊤)ρρρ.
25Published in Transactions on Machine Learning Research (12/2023)
Proposition 3. With the above notations in place, we have
∂uuu
∂aaa/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
N×N111
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
N×1=1
ndata/bracketleftig/parenleftbig/parenleftbig
ϱϱϱaaa⊤/parenrightbig
⊙/parenleftbig
TTTTTT⊤/parenrightbig/parenrightbig
111 + 111 (aaa⊙ϱϱϱ)⊤TTTTTT⊤111/bracketrightig
, (48)
and
∂uuu
∂bbb/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
N×N111
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
N×1=1
ndata/bracketleftig/parenleftig/parenleftbig
a1a1a1⊤/parenrightbig
⊙/parenleftbig
STSTST⊤/parenrightbig
⊙/parenleftig
111 (aaa⊙ϱϱϱ)⊤/parenrightig/parenrightig
111
+/parenleftbig/parenleftbig
1a1a1a⊤/parenrightbig
⊙/parenleftbig
STSTST⊤/parenrightbig
⊙/parenleftbig
(aaa⊙ϱϱϱ)111⊤/parenrightbig/parenrightbig
111/bracketrightbig
. (49)
Furthermore,
N/summationdisplay
k=1∂uuu
∂WWWi,j=1
ndataN/summationdisplay
k=1ndata/summationdisplay
m=1aiak(ϱi+ϱk)Tk,mSi,mXm,j. (50)
Proof.Lettingttt⊤
idenote the ith row ofTTT, we rewrite uuuas follows:
uuu=1
ndata
a1ttt⊤
1
...
aNttt⊤
N
/bracketleftbigρ1a1ttt1+...+ρNaNtttN/bracketrightbig
=1
ndata
a1ttt⊤
1(ρ1a1ttt1+...+ρNaNtttN)
...
aNttt⊤
N(ρ1a1ttt1+...+ρNaNtttN)
.
Fori̸=k, we thus have
∂uuui
∂aaak=1
ndataaittt⊤
i(ρktttk) =1
ndataaiρkttt⊤
itttk.
Likewise, for i=k, we have
∂uuuk
∂aaak=1
ndataakρkttt⊤
ktttk+1
ndatattt⊤
k(ρ1a1ttt1+...+ρNaNtttN).
Combining the above, we obtain∂uuu
∂aaa, and hence (48) follows.
On the other hand, for i̸=k, we have
∂uuui
∂bbbk=1
ndataaittt⊤
iρkak∂tttk
∂bbbk=1
ndataaittt⊤
iρkaksssk,
and fori=k, we obtain
∂uuui
∂bbbk=1
ndataai/parenleftbigg∂tttk
∂bbbk/parenrightbigg⊤
(ρ1a1ttt1+...+ρNaNtttN)
+1
ndataakttt⊤
kρkak∂tttk
∂bbbk
=1
ndataai(sssk)⊤(ρ1a1ttt1+...+ρNaNtttN)
+1
ndataakttt⊤
kρkaksssk.
Combining the above, we obtain∂uuu
∂bbb, and hence (49) follows.
26Published in Transactions on Machine Learning Research (12/2023)
Iteration#1Iteration#1000Iteration#5000
Figure 4: The evolution of the regularized risk ˆFβversus iteration index kfor the proposed ProxLearn .
Inset plots compare the ground truth (sinusoid) with the output from the network at three specific iterations.
Finally, noting that WWWi,jis in theith row ofTTT, fori̸=k, we obtain
∂uuuk
∂WWWi,j=1
ndataakttt⊤
kρiai∂ttti
∂WWWi,j=1
ndataakttt⊤
kρiai(sssi⊙xxxj),
wherexxxjis thejth column of XXX. Likewise, for i=k, we get
∂uuuk
∂WWWi,j=1
ndataak/parenleftbigg∂tttk
∂WWWi,j/parenrightbigg⊤
(ρ1a1ttt1+...+ρNaNtttN)
+1
ndataakttt⊤
kρkak∂tttk
∂WWWi,j
=1
ndataak(sssi⊙xxxj)⊤(ρ1a1ttt1+...+ρNaNtttN)
+1
ndataakttt⊤
kρkak(sssi⊙xxxj).
Combining the above, we obtain∂uuu
∂WWWi,j, thereby arriving at (50).
D Learning sinusoid
To better visualize the functionality of the proposed algorithm, we perform a synthetic case study of
learning a sinusoid following the set up as in (Novak et al., 2019, Sec. 2.1). We performed 5000 itera-
tions of ProxLearn withN= 1000samples (no mini-batch) from the initial PDF ϱ0(θ≡(a,b,w )) =
Unif([−1,1]×[−1,1]×[−1.5,1.5]), and used algorithm parameters β= 0.3,h= 10−4,δ= 10−3,ε= 10−3,
L= 10. The evolution of the associated regularized risk functional and the learnt functions are shown in Fig.
4. Fig. 5 shows the function approximations learnt by our proposed algorithm at the end of 3200 iterations
for 20 randomized runs with the same initial PDF and parameters as reported here.
27Published in Transactions on Machine Learning Research (12/2023)
Figure 5: Comparison of the ground truth (here sin(x)) with the learnt approximants obtained from the
proposed ProxLearn after 3200 iterations for 20 randomized runs. All randomized runs use the same initial
PDF and parameters as reported here.
Table 5: Comparing final ˆFβfor varying N
NFinal ˆFβ
500 0.01241931
700 0.01075817
1000 0.00806645
2000 0.00762518
To illustrate the effect of finite Non the algorithm’s performance, we report the effect of varying Non the
final regularized risk value ˆFβfor a specific synthetic experiment. We observe that increasing Nimproves
the final regularized risk, as expected intuitively.
28