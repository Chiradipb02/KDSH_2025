The Benefits of Balance:
From Information Projections to Variance Reduction
Lang Liu∗Ronak Mehta∗Soumik Pal Zaid Harchaoui
University of Washington
Abstract
Data balancing across multiple modalities and sources appears in various forms in
foundation models in machine learning and AI, e.g.in CLIP and DINO. We show
that data balancing across modalities and sources actually offers an unsuspected
benefit: variance reduction. We present a non-asymptotic statistical bound that
quantifies this variance reduction effect and relates it to the eigenvalue decay of
Markov operators. Furthermore, we describe how various forms of data balancing
in contrastive multimodal learning and self-supervised clustering can be better
understood, and even improved upon, owing to our variance reduction viewpoint.
1 Introduction
Deep neural networks have shown remarkable success at learning task-specific representations of
data when provided supervision from massive amounts of labeled training examples. Recent trends,
however, have shifted toward task-agnostic, universal representations that may be easily fine-tuned or
even have zero-shot capabilities out of the box. Supervised learning, stricto sensu , is too limited a
framework for these billion-parameter, data-hungry models, and a question at the heart of modern
machine learning is learning from unlabeled, partially labeled, or weakly labeled data.
This need has paved the way for the current generation of self-supervised learning (SSL) approaches
that circumvent the need for large amounts of “strong” labels. In SSL, a model is trained on a generic
pseudo-task suited for unlabeled data, such as relating image-caption pairs or augmentations of
the same image. Despite modern foundation models such as DINO [Caron et al., 2021] and CLIP
[Radford et al., 2021] being trained in this fashion, many aspects of SSL remain mysterious.
In particular, the training process of self-supervised models often transcends the rules of the standard
empirical risk minimization (ERM) toolkit. ERM combines two well-understood techniques: mini-
batch sampling and gradient-based optimization using backpropagation. On the other hand, SSL adds
clever, yet less-understood techniques to the training pipeline. To illustrate this, consider a minibatch
of independent and identically distributed (i.i.d.) training examples (X1, Y1), . . . , (Xn, Yn)∼P,
where Pis a joint probability measure on sample spaces X × Y (e.g. feature-label or image-caption
pairs) and let Pn=1
nPn
i=1δ(Xi,Yi)be the empirical distribution. For a model parameterized by
θ∈Rdwith loss function hθ, a stochastic learning algorithm involves computing the minibatch loss
EPn[hθ(X, Y)] =1
nnX
i=1hθ(Xi, Yi) (1)
and backpropagating through it to produce a minibatch stochastic gradient estimate. The algorithm
then proceeds with the stochastic gradient descent (SGD) or a variant thereof (e.g., Adam, SGD with
momentum, etc). Self-supervised methods often modify this recipe by intervening on the optimization
algorithm in a minibatch-specific way.
∗These authors contributed equally to this work.
38th Conference on Neural Information Processing Systems (NeurIPS 2024).For example, SwaV [Caron et al., 2020] passes the minibatch examples through the model’s encoder
and clusters output vectors to generate pseudo-labels for a prediction task. In teacher-student
architectures such as BYOL [Grill et al., 2020] and DINO [Caron et al., 2021], the minibatch is
passed through two networks, where the “student” network is updated via backpropagation and the
“teacher” network is updated by cloning the student’s weights in regular intervals. In CLIP [Radford
et al., 2021], a model optimizes the sum of two cross-entropy losses, where the predicted class
probabilities on example iare generated by comparison to all other elements of the minibatch. While
introducing such interventions into the procedure has clearly proven useful practically, it remains
conceptually unclear what exactly is being optimized by the learning algorithm.
In this work, we aim to gain a better theoretical understanding of the objectives and algorithms
underlying these empirically effective recipes. In particular, we want to shed a theoretical light on
their precise benefits over traditional learning methods. We show that such recipes often enjoy an
unsuspected benefit: reducing the variance of the empirical minibatch objective.
Concretely, we formalize the model updates described above as two phrases. Let Z1, . . . , Z nbe a
minibatch containing data points of arbitrary type (e.g. unlabeled images). In the first phase, this
original data source is mapped (possibly using a model parameterized by θ) to another minibatch
(X1, Y1), . . . , (Xn, Yn)ofderived pairs in X × Y . For example, in SwaV , each Ziis an image,
and we derive (Xi, Yi)by setting Xi=Ziand letting Yibe the pseudo-label based on clustering
the vector representations of the images. In CLIP, each Ziis an image-caption pair, and we derive
(Xi, Yi)by simply letting Xibe the image and Yibe the caption. In either example, Yiisnota label
in the traditional sense. In the second phase, we use the model to compute a probability distribution
Pn,θoverX × Y , and perform a stochastic gradient update for the objective
EPn,θ[hθ(X, Y)]. (2)
This reduces to empirical risk minimization on the minibatch objective (1) when Z= (X, Y)(each
data point is originally observed in X × Y ) and Pn,θ=Pn(the empirical distribution of the data is
used, regardless of the model). Beyond this setting, one specific example of Pn,θhas been applied
across various families of self-supervised learning (as detailed in Sec. 2), which we refer to as data
balancing or simply balancing , the primary subject of this work.
For a probability measure QonX × Y , letQXandQYbe the respective marginals on XandY
and let QX|YandQY|Xdenote the respective conditional distributions. Given fixed target marginal
distributions PXonXandPYonY, balancing refers to repeatedly applying the operations
R7→arg min
Q:QX=PXKL(Q∥R)and R7→arg min
Q:QX=PYKL(Q∥R), (3)
in an alternating fashion. After enough iterations, the resulting probability measure approximately
marginalizes to PXandPYin each variable. When XandYare finite with |X|=mand|Y|=l,
these operations reduce to rescaling the rows of an (m×l)-matrix by PX/QXor its columns by
PY/QY. This algorithm has a decades-old history and is known in other contexts as Sinkhorn-Knopp
matrix scaling [Sinkhorn, 1967], iterative proportional or biproportional fitting [Johnston and Pattie,
1993], and raking-ratio estimation [Thompson, 2000]. The marginals PXandPYcan represent
auxiliary information or inductive bias from users, such as the desire for balanced clusters.
Returning to Pn,θin(2), we show in Sec. 2 that both self-labeling and contrastive approaches in SSL
implicitly define Pn,θby the following steps: 1) constructing a method-specific “initial” measure P(0)
n
onX × Y , then 2) applying kiterations of the operations (3)to generate a sequence P(0)
n, . . . , P(k)
n,
and finally, 3) setting Pn,θ:=P(k)
n. In other words, these methods embed a learnable balancing
operation in their objectives. A natural question to consider is: if the marginals one uses accurately
represent the ones of the true probability measure Pgoverning the data, are balanced quantities
“better behaved” than their unbalanced counterparts? If so, in what way?
Inspired by this question, we fix the model parameter θ(thus dropping the subscript from the
quantities above) and analyze the fluctuations of the unbalanced and balanced objectives. The formal
problem statement is as follows. Let P(0)
n=PnandP(k)
ndenote the output of k≥1iterations of data
balancing (see Sec. 3 for the precise definition). Finally, letting h:X × Y → Rbe a fixed function
of interest, we define the population parameter φand its k-step balanced estimator φ(k)
nby
φ:=EP[h(X, Y)]and φ(k)
n:=EP(k)
n[h(X, Y)]. (4)
2Our goal is to establish theoretical guarantees on the mean squared error (MSE) EP[(φ(k)
n−φ)2]of
estimating φusing φ(k)
n, with an informative dependence on the sample size n, number of iterations k,
target marginals (PX, PY), and test function h. We are particularly interested in its comparison to the
direct estimator based on the empirical measure φ(0)
n=1
nPn
i=1h(Xi, Yi), as to quantify the effect
of the auxiliary information (PX, PY). Our analysis uncovers two surprising facts. Firstly, while
originally proposed for a different purpose, balancing reduces the variance of the empirical estimate.
Secondly, while the balancing iterations are nonlinear operations on the input measure, the variance
reduction can be precisely quantified using the spectral decay of two linear Markov operators: the
conditional means given XandY, respectively.
Contributions. In Sec. 2, we detail the mathematical connection between balancing and the modern
representation learning techniques mentioned above. In Sec. 3, we prove a new upper bound on the
MSE of the balancing estimator φ(k)
n. The bound decomposes into an O(n−1)first-order variance term
and an O(k6n−3/2)second-order term. The first-order term is shown to have a strict improvement
over the empirical measure baseline with a fine-grained dependence on the spectra of two particular
Markov operators. The second-order term can be used to compute the asymptotic variance reduction
for statistical efficient comparisons. Our proof technique relies on a recursion decomposition for
balancing-based estimators, which may be of independent interest. In Sec. 4, we illustrate how
insights from our analysis can be practically applied to CLIP-type objectives and evaluation setups.
2 Data Balancing in Practice
To demonstrate a precise connection to (2), we describe how a collection of training examples
Z1, . . . , Z nobserved in an original data space Z(e.g. grayscale images) is mapped to a probability
measure Pn,θ. Using the framework introduced in Sec. 1, this amounts to specifying four components:
1) the map from the original data into the derived sample spaces XandY, 2) the initial measure P(0)
n,
3) the function h, and 4) the target marginals (PX, PY)for this measure to fit. From that point, the
iterations of (3)produce P(1)
n, . . . , P(k)
n, and we set Pn,θ:=P(k)
n. For ease of presentation, we hide
the dependence of P(k)
n=Pn,θandh≡hθon the model parameter θ. See Fig. 1 for examples of
different choices of the sample spaces XandY.
Example 1: Self-Supervised Clustering. Balancing is used in discriminative clustering and self-
supervised clustering; see [Jones et al., 2022, Asano et al., 2020, Caron et al., 2020] for variations
on this theme. We describe the swapped prediction task of Caron et al. [2020] for concreteness but
emphasize that clustering of this form is used as an intermediate step (or as the task itself) in many
SSL pseudo-tasks. At a high level, this approach involves passing elements of a minibatch through
two encoders to generate vector representations. These representations are then clustered separately,
and the features from one encoder predict the cluster label from the other encoders. Denote the
encoders fθs:Z →Rrandfθt:Z →Rr, colloquially known as the student andteacher networks,
respectively. Here, we let {Zi}n
i=1be a minibatch of nimages, with
X={Z1, . . . , Z n}andY={1, . . . , l},
where m=nand the elements of Yindex learnable cluster representation vectors c1, . . . , c l∈Rr.
Thus, we consider the overall parameter vector to be θ:= (θs, θt, c1, . . . , c l). Given temperature
hyperparameters ϵ, τ > 0, the initial measure and loss function are given by the expressions
P(0)
n(x, y)∝efθs(x)⊤cy/ϵand h(x, y) = logefθt(x)⊤cy/τ
Pl
y′=1efθt(x)⊤cy′/τ.
Directly optimizingP
x,yP(0)
n(x, y)h(x, y)without any constraints would lead to collapse, so it is
balanced before optimization. The target marginals PXandPYare given by the discrete uniform
measures on XandY. This formulation is often derived by solving an optimal transport problem
with the Sinkhorn-Knopp algorithm to assign soft cluster labels, the iterative solution result from this
procedure is precisely P(k)
n. The intuition behind the choice of uniform marginal PXis that each data
point has an equal amount of mass to be allotted, whereas PYcaptures that the cluster sizes are equal.
The number of iterations kis selected based on optimization considerations.
Example 2: Contrastive Learning. Contrastive Language-Image Pre-Training [Radford et al.,
2021], or CLIP, is an architecture with an image encoder and a text encoder that map to a joint
3Figure 1: Data Balancing Examples: Each panel shows a possible distribution Qon different
choices of ( X,Y). The orange histograms are the target marginal PY.Left: Q(x, y)is the affinity of
an image xfor cluster y.Center: Q(x, y)is the similarity of an image xto a text caption y.Right:
Q(x, y)is the proportion of substring matches between a text caption xand a keyword y.
embedding space. Trained using image-caption pairs, the loss promotes representations such that
images and text that are paired in the minibatch are close, whereas those that are not paired are
far. The latter aspect (promoting dissimilarity of unpaired images/text) is what prevents collapse
in this framework. To our knowledge, our interpretation of the CLIP objective as an implicit data
balancing procedure is novel. Under this interpretation, we demonstrate that the objective is in fact a
nonlinear function of Pn,θ, whereas its gradient will have a linear form similar to (2). In this case,
eachZi= (Xi, Yi), where Xiis an image and Yiis an associated caption. We have that
X={X1, . . . , X n}andY={Y1, . . . , Y n},
so that m=n. Consider an image encoder fθI:X 7→Rrand text encoder fθT:Y 7→Rrwith
parameter vector θ= (θI, θT). The initial, unnormalized measure and the (in this case, vector-valued)
function hare chosen based on these encoded representations:
P(0)
n(x, y)∝efθI(x)⊤fθT(y)and h(x, y) =∇θ(fθI(x)⊤fθT(y)). (5)
While we usually interpret has a loss function, we will show below that the CLIP loss depends
nonlinearly on Pn,θ, while the gradient has a linear dependence. If we believe, as in Example 1, that
the target marginals (PX, PY)of the images and the text should be roughly uniform, we can apply
the balancing iterations (3)with the target marginals being the uniform distributions over XandY,
respectively. Because there is no preference for starting the iterations with the XorYdimension
first, we may consider both orderings. Let Q(1)
nbe one iteration of balancing in the Ydimension and
R(1)
nrepresent one such iteration in the Xdimension. Then the original CLIP objective LCLIP
n can be
recovered (up to an additive constant) as
LCLIP
n :=−1
2nX
i=1"
logP(0)
n(Xi, Yi)P
xP(0)
n(x, Yi)+ logP(0)
n(Xi, Yi)P
yP(0)
n(Xi, y)#
=−1
2nX
i=1[logQ(1)
n(Xi, Yi) + log R(1)
n(Xi, Yi)]−logn. (6)
The measure Pn,θ=1
2Q(1)
n+1
2R(1)
nis constructed in this case by averaging the outputs of one iteration
of balancing under each modality. Taking the gradient of (6)with respect to θ(whose dependence is
contained in (Q(1)
n, R(1)
n)) recovers the expression for hin(5). The objective is often interpreted as an
average of cross-entropy loss terms, each representing the prediction of one modality’s original pair
from the other. In our formulation, LCLIP
n can also be viewed as an average negative log-likelihood
under the Q(1)
nandR(1)
n. It is also of interest to study the effect of using Q(k)
nandR(k)
nfork≥0in
general, as we show in Sec. 4.
4Example 3: Metadata Curation. Here, we consider taking Mnto be an entire training set, as
opposed to a particular minibatch. At the billion-parameter scale, dataset design can be the primary
factor that differentiates performance between foundation models [Fang et al., 2013, Xu et al., 2024,
Gadre et al., 2023]. One general approach used in both the original CLIP dataset [Radford et al.,
2021] and an open-source replication [Xu et al., 2024] is metadata curation, wherein a text dataset
Mn(possibly captions for images) is synthesized using a list of keywords {y1, . . . , y l}so that
X={Z1, . . . , Z n},Y={y1, . . . , y l},
meaning that m=n. The keywords are matched to texts within Xvia substring matching. While
the approach of Xu et al. [2024] (dubbed MetaCLIP) pools all matched keywords on every text to
measure the “distribution” of keywords, we consider a version in which each text Zican only be
labeled with a single keyword yj. This allows for a true joint probability measure on X × Y . The
marginal distribution of observed keywords is initially long-tailed (see Fig. 4) (e.g., “the” will match
many more texts than “xylophone”). In both Radford et al. [2021] and Xu et al. [2024], the data are
resampled so that this distribution of keywords over matches is closer to uniformity, i.e. keywords
with many matches have their associated texts downsampled during the dataset creation process.
While the probability measure may not be computed explicitly (due to scale), this adjustment of the
keyword distribution can be viewed as a single iteration of balancing (3)applied to the Ymarginal.
For tasks such as language modeling, we have
P(0)
n(x, y) =Pn(x, y)and h(x, y) =ℓ)θ(x), (7)
where ℓθ(x)denotes the loss of a model evaluated at a single text x∈ X (notice that the keyword is
not used). We elucidate this connection by applying direct balancing on a subset of the ImageNet-
Captions dataset in Sec. 4, observing the effect on downstream model performance.
Motivated by these scenarios, we address the statistical problem outlined in Sec. 1 by analyzing
balancing-based estimators. We then return to examples mentioned above in Sec. 4, illustrating how
the theoretical analysis can be translated to algorithmic variants.
3 Theoretical Analysis of Variance Reduction
We now present theoretical guarantees on the mean squared error (MSE) of the data-balanced
estimator φ(k)
nand highlight relevant points in the proofs. For readers’ convenience, a notation table
(Tab. 1) is in Appx. A. We first give context on the main innovations of the analysis and then outline
its high-level steps. These innovations include relating the nonlinear iterations of balancing over
probability measures to linear operators on a vector space and using a singular value decomposition
of these operators to quantify their effect after a finite number of iterations. Furthermore, by scaling
the number of iterations appropriately, we can characterize the estimator using the limit of balancing
iterations, which is an object of interest in applications including optimal transport.
Preliminaries. Recall the setting introduced in Sec. 1, in which we consider sample spaces (X,Y),
along with true and unknown joint distribution PonX × Y with known marginals (PX, PY). For
ease of presentation, we assume that |X|=|Y|=m, although the arguments do not rely on equal
support sizes. We make the following assumption throughout, which is usually satisfied by the
desired marginals PXandPY, such as in the uniform cases discussed in Sec. 2: the target marginals
PX(x)>0andPY(y)>0for all x∈ X andy∈ Y. We define P(0)
n=Pnas the empirical measure
and for k≥1construct
P(k)
n(x, y) :=

PX(x)
P(k−1)
n,X(x)·P(k−1)
n(x, y)kodd
PY(y)
P(k−1)
n,Y(y)·P(k−1)
n(x, y)keven. (8)
By direct computation, we see that the iterations in (8)are equivalent to applying (3)forkodd
and even, respectively. See Fig. 2 (left) for a visualization of this procedure. The iterations are
well-defined for all kunder the event that Supp(Pn,X) =Supp(PX)andSupp(Pn,Y) =Supp(PY),
i.e., all observed row counts and column counts are non-empty.2
2Due to this technical consideration, we define P(k)
nto be the empirical measure Pnwhen this condition is
not satisfied, which we show occurs with low-probability. See Appx. D.4 for details.
5Figure 2: Data Balancing. Nonlinear and linear operators associated with each iteration of (8).Left:
Visualization of the exact iterations of (8)in the space of probability measures. The blue set contains
joint distributions with X-marginal equal to PX, whereas the orange set contains joint distributions
withY-marginal equal to PY.Right: Visualization of L2(P), the operators defining (11), and the
singular values given in (13).
To provide background, the scheme of alternating the operators (8)is often seen as an iterative
algorithm to solve the problem
min
Q∈Π(PX,PY)KL(Q∥P(0)
n), (9)
where Π(PX, PY)denotes the set of probability measures on X × Y that marginalize to PXandPY
in each variable and KL(·∥·)denotes the Kullback-Leibler divergence. The iterations (8)are based
on the alternating minimization approach of solving
P(k)
n(x, y) :=(
arg min{Q:QX=PX}KL(Q∥P(k−1)
n)kodd
arg min{Q:QY=PY}KL(Q∥P(k−1)
n)keven,
which inspires the viewpoint of balancing as alternating information projections . As we show in
Appx. C, the iterations of (8)can equivalently be defined using the KL, reverse KL, or χ2-divergences.
This viewpoint is relevant as previously, efforts have been made (e.g. in Bickel et al. [1991]) to
analyze the variance reduction afforded by the solution to (9)directly. However, quantifying the
variance reduction (in terms of properties of P) using this approach is challenging, as there is no
closed-form expression for the solution of (9). A key mathematical outcome of our analysis is that the
closed-form expressions of the projections (8)can be used to compute the reduction in mean squared
error at each iteration. Thus, by letting k≡k(n)→ ∞ (scaled appropriately against n), we can
determine the reduction for the solution of (9)for large n. This is the subject of the upcoming Cor. 2.
From Information Projections to Orthogonal Projections. First, we will show that the variance
reduction resulting from each nonlinear iteration of (8)is associated with a linear operator applied to
h. Thus, instead of analyzing the alternating information projections over probability measures, we
may use familiar tools to understand alternating orthogonal projections in a vector space. To define
them, we first let L2(P)to be the set of functions h:X × Y → Rsatisfying EP
h2(X, Y)
<∞.
Even though X × Y is finite, working within L2(P)will be analytically convenient. Let L2(PX)
be the subspace of L2(P)containing functions that only depend on the first argument x∈ X
and define L2(PY)analogously. These are the solid-colored subspaces in Fig. 2 (right). Next, let
µX:L2(P)→L2(PX)andµY:L2(P)→L2(PY)be defined as, for any h∈L2(P),
µXh= arg min
f∈L2(PX)EP
(h(X, Y)−f(X))2
=⇒[µXh](x, y) :=EP[h(X, Y)|X] (x)
The operator µXis an orthogonal projection onto L2(PX). The orthogonal projection operator
µYontoL2(PY)is defined analogously. We may also define the conditional debiasing operators
CX=I−µXandCY=I−µY, which each project onto the orthogonal complements of L2(PX)and
6L2(PY), visualized as subspaces with dotted border in Fig. 2 (right). To understand the importance
of the conditional mean and debiasing operators, we give a recursive formula that forms the backbone
of our analysis. Define µk=µXforkodd and µk=µYforkeven, and define Cksimilarly. Thus,
by using the notation Q(h) :=EQ[h(X, Y)], we have by linearity of expectation that
[P(k)
n−P](h) = [P(k)
n−P](Ckh) +=0z}| {
[P(k)
n−P](µkh)
= [P(k−1)
n−P](Ckh) + [P(k)
n−P(k−1)
n](Ckh)
= [P(0)
n−P](C1. . .Ckh)| {z }
first-order term+Pk
ℓ=1[P(ℓ)
n−P(ℓ−1)
n](Cℓ. . .Ckh)| {z }
higher-order terms. (10)
To justify the first line, we discuss the case when kis odd. Notice that µXhis only a function of X,
so its expectation only depends on PXthat is equal to P(k)
n,X(theX-marginal of P(k)
n) by(8). The last
line follows by unrolling the previous step k−1times. This recursive expansion is proven formally
in Prop. 15 in Appx. D. Given the expansion, the mean squared error can be computed by taking the
expectation of squared (10). We show that the second moment of the first-order term in (10) is equal
toσ2
k/nwhere
σ2
0:=Var(h)andσ2
k:=Var(C1. . .Ckh)fork≥1, (11)
and all other terms are O(k6n−3/2). Thus, by exactly computing the constant in the dominating term,
we may quantify the asymptotic variance reduction. Our first main result concerns the higher-order
terms and shows that it is indeed dominated by the first-order term. Note that the empirical mean
φ(0)
n=1
nPn
i=1h(Xi, Yi)is unbiased, and so its MSE is equal to σ2
0/n. Define in addition
p⋆:= min {min
xPX(x),min
yPY(y)}
which measures the non-uniformity of the target marginals. We have that p⋆is positive because both
PXandPYare positive. We now state the first main result.
Theorem 1. For a sequence of data balancing estimators (φ(k)
n)k≥1as defined in (4), there exists an
absolute constant C >0and distribution dependent constant s∈[0,1)and such the following holds
forσ2
gap=σ2
0−σ2
k: For n≥C[log2(2n/p⋆) +mlog (n+ 1)]/p2
⋆andk≥1, we have
EP
(φ(k)
n−φ)2
≤σ2
0−σ2
gap
n+Osk
n
+˜Ok6
n3/2
. (12)
The quantities σ2
gapandsare quantified toward the end of this section and are dependent on eigende-
cays of the conditional mean operators for each variable under P. Furthermore, σ2
gap>0except for
the pathological case of µXhbeing a constant function. Showing Thm. 1 boils down to showing that
the higher-order term in (10) isO(n−1)with high probability. Using the expression (8)and assuming
thatℓ≥1is odd, we see that
[P(ℓ)
n−P(ℓ−1)
n](Cℓ. . .Ckh) =X
x,y"
PX(x)
P(ℓ−1)
n,X(x)−1#
·[Cℓ. . .Ckh](x, y)P(ℓ−1)
n(x, y).
The first (blue) term in the product quantifies the disagreement between the X-marginal of P(ℓ−1)
n and
the true marginal, which can be bounded in terms of KL(P(0)
n,X∥PX)and is shown to be O(n−1/2)
with high probability via techniques from information theory. The second (orange) term can be
unrolled recursively in a similar fashion to (10) itself, which will consequently be O(n−1/2)as well;
this is the most technical part of the analysis (see Appx. D.3). Our analysis also yields a bound for
the sensitivity of balancing to misspecified marginals; see Appx. D.5.
Given Thm. 1, a natural next step is to quantify the gap between σ2
0andσ2
k, which requires finer-
grained properties of CXandCY. Notably, we show that as k→ ∞ ,σ2
kapproaches a limiting
value. Thus, via (12), by using k=o(n1/12)obtains asymptotic variance of the solution to (9). This
contrasts with Albertus and Berthet [2019], in which the dependence of a quantity similar to (12) is
exponential in k, meaning that k=o(log(n))is required for convergence under this argument.
7From Orthogonal Projections to Variance Reduction. We now clarify what is precisely meant
by the “spectrum” of the conditional mean operators µXandµY. As proven using a singular value
decomposition (Prop. 3) in Appx. B.1, there exists a basis {αj}m
j=1ofL2(PX), a basis {βj}m
j=1of
L2(PY), and real values {sj}m
j=1, that satisfy
µYαj=sjβjandµXβj=sjαjforj∈ {1, . . . , m }. (13)
Furthermore, α1=1Xandβ1=1Yleading to the equality ⟨f, α1⟩L2(PX)=EPX[f(X)]. Finally,
s1= 1andsjis non-negative and non-increasing in j. For a concrete example, consider m= 2, in
which case Pcan be written as a matrix in R2×2and elements of L2(PX)andL2(PX)are vectors in
R2. Then, in the case of uniform marginals, we can verify directly that (13) can be satisfied by setting
α1=β1=
1
1
, α2=β2=
1
−1
,andP=1
4
1 +s1−s
1−s1 +s
(14)
fors=s2(the second largest singular value). Thus, as s→1, the distribution becomes “fully
dependent” as YandXare completely determined by one another. As s→0,Papproaches the
product measure. Geometrically, because α1=β1, we know that the angle abetween the subspaces
L2(PX)andL2(PY)is given by the angle between α2andβ2. By computing their inner product in
L2(P), we have that ⟨α2, β2⟩L2(P)=
P, α 2β⊤
2
=s= cos a. Thus, s= 0indicates orthogonality
of these subspaces, alluding to the independence of XandY(see the right panel of Fig. 2).
Returning to m≥2, we consider the following as a sufficient condition for variance reduction: the
operators µXandµYhave a positive spectral gap, i.e., s2< s1. Note that this assumption is satisfied
when P(x, y)>0for all (x, y)∈ X × Y by the Perron–Frobenius Theorem [Horn and Johnson,
2013, Chapter 8]. Using the intuition from Fig. 2, this rules out pathological cases such as Ybeing
a deterministic function of X. Under the spectral gap condition, the singular values {sj}m
j=2that
are strictly less than 1will determine a geometric rate of decay in variance given in Cor. 2. The left
and right singular functions αj:X →Randβj:Y →Rwill define a useful coordinate system to
represent projections of hwhen analyzing φ(k)
n.
Indeed, let ¯h=P(h)be the centered test function. Because µX¯h∈L2(PX)andµY¯h∈L2(PY),
we may decompose this function on the two bases to write
µX¯h=mX
j=1ujαjand µY¯h=mX
j=1vjβj. (15)
Cor. 2 below relates the (normalized) variance σ2
kof the first-order term to the one of the sample
mean φ(0)
n. In fact, it shows that the variance reduction σ2
0−σ2
kdecays geometrically to the quantity
σ2
gap:=mX
j=2"
u2
j+(vj−sjuj)2
1−s2
j#
.
For simplicity, we only present the result for keven, i.e., σ2
2t.
Corollary 2. The variance reduction achieved by t+ 1iterations of the CYCXoperator can be
quantified as
σ2
0−σ2
2(t+1)=σ2
gap−mX
j=2s2
j(vj−sjuj)2
1−s2
js4t
j=mX
j=2"
u2
j+ (1−s4t+2
j)(vj−sjuj)2
1−s2
j#
.
Intuitively, the operators CXandCYare the main sources of the variance reduction via orthogonality.
Since α1=1X, we can see that the reduction will always be strictly positive as long as µX¯his not a
constant function. Finally, using s:=s2≥sjforj≥2gives the second term in Thm. 1.
4 Numerical Illustrations
We illustrate how data balancing manifests in the motivating examples mentioned in Sec. 2 with
experiments with CLIP-type models. We focus here on zero-shot image classification tasks. Details
on these experiments, and additional ones including linear probing and zero-shot retrieval, as well as
an empirical investigation of the sensitivity to misspecified marginals, are all contained in Appx. E.
Code to reproduce the data and experiments can be found at https://github.com/ronakdm/balancing.
80.20.40.60.8CIFAR-10
m=128
0.20.40.60.8
m=512
0.20.40.60.8
m=128
0.20.40.60.8
m=512
0.100.150.200.250.30
m=128
0.10.20.3
m=512
0.00.20.4CIFAR-100
0.20.4
0.10.20.3
0.00.10.20.3
0.010.020.03
0.010.020.030.040.05
Iterations0.20.40.60.8STL-10
Iterations0.40.60.8
Iterations0.20.40.60.8
Iterations0.20.40.60.8
Iterations0.10.20.3
Iterations0.10.20.3
CLIP Text Embeddings BERT Text Embeddings GPT-2 Text Embeddings
No Balancing CLIP Balancing (k=1) Multi-CLIP (k=2)Figure 3: Zero-Shot Classification Performance across Embeddings, Batch Sizes, and Objectives.
The three vertical panels describe different choices of the text encoder fθTwhich increases in quality
from left to right; that is, pre-trained GPT-2, BERT, and CLIP embeddings, respectively. Within
each vertical panel, examples include batch sizes m= 128 andm= 512 . Rows indicate various
evaluation datasets from CIFAR-10, CIFAR-100, and STL-10. The y-axis of each plot indicates
average per-class recall, whereas the x-axis indicates training iterations at the given batch size.
Model, Datasets, and Evaluation. Throughout, we consider training variants of CLIP models (see
Sec. 2), which require a dataset of image-caption pairs. For the training set, we use the ImageNet-
Captions dataset [Fang et al., 2013], which pairs images from ImageNet [Deng et al., 2009] that
were taken from Flickr with their original captions. In the notation of Sec. 2, the model is specified
by selecting an image encoder fθIand a text encoder fθT. In all cases, we use a fixed image/text
encoder as a base vector representation and compose it with a trainable feed-forward neural network,
i.e.,fθ=fhead
θ◦fbase. We fix the base image encoder as CLIP ViT-B/32 architecture pre-trained on
LAION-2B [Schuhmann et al., 2022], and vary the base text encoder across embedding models of
varying quality: GPT-2 [Radford et al., 2019], BERT [Devlin et al., 2019], and CLIP-based encodings.
When two CLIP encoders are used for the base image/text vector representation, they are taken from
separate CLIP models (i.e. the base representations are not dependent). We evaluate models based on
zero-shot classification performance using the standard CLIP inference procedure: for any image
x, a label c∈ {1, . . . , C }is predicted by associating to each ca natural language prompt yc, and
predicting the scores s(x) = (s1(x), . . . , s C(x)), with
sc(x) =e⟨fθI(x),fθT(yc)⟩/τ
PC
c′=1e⟨fθI(x),fθT(yc′)⟩/τ(16)
for a temperature τ >0. Multiple prompting strategies can be used depending on the evaluation
dataset, for which we average embeddings before applying (16). We use the public CLIP Benchmark
repository, using the datasets CIFAR-10, CIFAR-100, STL-10, with their default caption sets.
Data Balancing Effects. Fig. 3 shows the zero-shot classification performance (in terms of average
per-class recall) of variants depending on whether the contrastive learning objective from Sec. 2
is used or not. One iteration of balancing already leads to improvement in terms of downstream
performance. Multiple balancing iterations lead to further improvements. See Appx. E for more
details on this experiment, and for analogous ones with linear probing and zero-shot retrieval.
Fig. 4 then shows how balancing can be used to adjust an entire pre-training set to given marginals
based on metadata, as described in Sec. 2 in the metadata curation example. After balancing, the
target marginal has less than 2orders of difference. In terms of downstream performance, data
balancing leads to some improvement in the smaller batch regime ( m= 512 ) when curating the
dataset. See Appx. E for more details on this experiment.
9Histogram of Metadata Categories in Pre-T raining Dataset Zero-Shot Accuracy of Models with Dif ferent Pre-T raining Data
Evaluated on CIF AR-100 Evaluated on STL-10 Original Data Rebalanced Data
Training Iterations Training Iterations Metadata Category Meatadata CategoryFigure 4: Balancing and Metadata Curation. Depiction of balancing and metadata curation
(Example 3 in Sec. 2) on ImageNet-Captions dataset, in which Xrepresents image-caption pairs and
Yrepresents keywords. Left: Observed marginal Pn,Y(orange) and PY(blue), which are sorted by
order of increasing probability. Right: Zero-shot evaluation of an embedding model trained using the
standard CLIP loss original versus the balanced training set.
Related Work Self-supervised learning has witnessed a surge of recent interest as datasets and
computing hardware allow for larger, more capable models (see Balestriero et al. [2023] and references
therein). While we highlight in this paper the connections between data balancing and contrastive
learning [Radford et al., 2021], we acknowledge that data balancing can also be related to ”self-
distillation” approaches more broadly [Grill et al., 2020, Chen and He, 2021, Oquab et al., 2024].
Historical motivations for data balancing include census or survey data, in which Pnis a cross-
tabulation of (a limited number of) paired observations and the target marginals were estimated
from large amounts of unpaired observations [Deming and Stephan, 1940, Ireland and Kullback,
1968]. This situation is not unlike the present day—yet at a different scale—in which the amount of
unstructured single-modality data (such as images) still dwarfs the amount of high-quality multimodal
data [Gadre et al., 2023]. Bickel et al. [1991] proved classical asymptotic results on balancing
estimators. Linear operators similar to the ones we use in Sec. 3 also appear in their analysis. More
recently, Albertus and Berthet [2019] studied such estimators from an asymptotic empirical process
viewpoint. Our theoretical results significantly improve on those from Albertus and Berthet [2019]
primarily in the dependence of the number of iterations kon the sample size nto achieve convergence
guarantees (from logarithmic to polynomial).
Matrix scaling is a popular algorithm for solving entropy-regularized optimal transport (EOT). We
refer to Peyr ´e and Cuturi [2019] for a survey. See also Courty et al. [2017], Shen et al. [2018], Peng
et al. [2019] for interesting methods based on EOT in machine learning. Entropy-regularized optimal
transport was one of the original inspirations for SSL techniques such as SwaV (see Sec. 2). While
EOT is itself a deterministic optimization problem, a related statistical problem is the large-sample
limits of EOT solutions when the marginal measures are estimated from data [Mena and Niles-Weed,
2019, Genevay et al., 2019, Klatt et al., 2020]. We emphasize that, while this line of work shares the
matrix scaling algorithm with our setting, the statistical problem is entirely distinct; in statistical EOT,
the target marginal distributions are computed from observations of independent, unpaired data, and
the initial measure can be computed from the cost function. In our setting, the data are dependent,
forming the random initial measure Pn, whereas PXandPYare fixed auxiliary information.
5 Conclusion
We showed how several disparate techniques used towards the training of foundation models are
instances of a data balancing algorithm, which has the unsuspected benefit of reducing the variance
of learning objectives involving multiple sources of data. We proved a new non-asymptotic bound
on the mean-squared error of balanced estimators as they adjust to the given marginals. We also
highlight the key roles of conditional expectation operators in quantifying that variance reduction
effect. Finally, we translated the marginal balancing interpretation of several training practices for
foundation models into algorithmic variants that warrant further investigation. Exploring variants
incorporating prior information on the data sources is also an interesting venue for future work.
10Acknowledgements The authors are grateful to G. Ilharco, M. Wortsman, K. Pillutla, L. Schmidt,
and J. Wellner for fruitful discussions related to this work. This work was supported by NSF
DMS-2023166, CCF-2019844, DMS-2134012, PIMS 20240827-PRN01, NIH, and IARPA 2022-
22072200003. Part of this work was done while L. Liu was with the University of Washington, and
while R. Mehta and Z. Harchaoui were visiting the Simons Institute for the Theory of Computing.
Broader Impact While this paper is of a theoretical nature, the web-scale pre-training sets used to
train foundation models can affect not only the biases of the models themselves but also the behavior
of individuals who interact with them. In the case of representation learning, unrefined Internet
data may lead to non-uniform performance among protected attributes such as gender, age, etc. For
generative models, individuals of all ages may be influenced by harmful images or textual output.
Studying the relationship between the balancing procedures considered in this paper and more holistic
model evaluations presents a valuable direction for follow-up work.
References
M. Albertus and P. Berthet. Auxiliary information: The raking-ratio empirical process. Electronic
Journal of Statistics , 13(1), 2019.
Y . Asano, C. Rupprecht, and A. Vedaldi. Self-labelling via simultaneous clustering and representation
learning. In ICLR , 2020.
R. Balestriero, M. Ibrahim, V . Sobal, A. Morcos, S. Shekhar, T. Goldstein, F. Bordes, A. Bardes,
G. Mialon, Y . Tian, A. Schwarzschild, A. G. Wilson, J. Geiping, Q. Garrido, P. Fernandez, A. Bar,
H. Pirsiavash, Y . LeCun, and M. Goldblum. A cookbook of self-supervised learning. arXiv
preprint , 2023.
P. J. Bickel, Y . Ritov, and J. A. Wellner. Efficient estimation of linear functionals of a probability
measure Pwith known marginal distributions. The Annals of Statistics , 1991.
M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski, and A. Joulin. Unsupervised learning of
visual features by contrasting cluster assignments. In NeurIPS , 2020.
M. Caron, H. Touvron, I. Misra, H. J ´egou, J. Mairal, P. Bojanowski, and A. Joulin. Emerging
properties in self-supervised vision transformers. In ICCV , 2021.
X. Chen and K. He. Exploring simple Siamese representation learning. In CVPR , 2021.
N. Courty, R. Flamary, A. Habrard, and A. Rakotomamonjy. Joint distribution optimal transportation
for domain adaptation. In NeurIPS , 2017.
T. M. Cover. Elements of Information Theory . John Wiley & Sons, 1999.
W. E. Deming and F. F. Stephan. On a least squares adjustment of a sampled frequency table when
the expected marginal totals are known. Annals of Mathematical Statistics , 11, 1940.
J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical
image database. In CVPR , 2009.
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. BERT: Pre-training of deep bidirectional
transformers for language understanding. In ACL, 2019.
M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The PASCAL Visual
Object Classes Challenge 2007 (VOC2007) Results, 2007.
A. Fang, G. Ilharco, M. Wortsman, Y . Wan, V . Shankar, A. Dave, and L. Schmidt. Data determines
distributional robustness in contrastive language-image pre-training (CLIP). In ICML , 2013.
S. Y . Gadre, G. Ilharco, A. Fang, J. Hayase, G. Smyrnis, T. Nguyen, R. Marten, M. Wortsman,
D. Ghosh, J. Zhang, E. Orgad, R. Entezari, G. Daras, S. M. Pratt, V . Ramanujan, Y . Bitton,
K. Marathe, S. Mussmann, R. Vencu, M. Cherti, R. Krishna, P. W. Koh, O. Saukh, A. Ratner,
S. Song, H. Hajishirzi, A. Farhadi, R. Beaumont, S. Oh, A. Dimakis, J. Jitsev, Y . Carmon,
V . Shankar, and L. Schmidt. DataComp: In search of the next generation of multimodal datasets.
InNeurIPS , 2023.
11A. Genevay, L. Chizat, F. Bach, M. Cuturi, and G. Peyr ´e. Sample complexity of Sinkhorn divergences.
InAISTATS , 2019.
I. Gohberg, S. Goldberg, and M. Kaashoek. Classes of Linear Operators Vol. 1 . Springer, 1990.
J.-B. Grill, F. Strub, F. Altch ´e, C. Tallec, P. Richemond, E. Buchatskaya, C. Doersch, B. Avila Pires,
Z. Guo, M. Gheshlaghi Azar, B. Piot, k. kavukcuoglu, R. Munos, and M. Valko. Bootstrap your
own latent: A new approach to self-supervised learning. In NeurIPS , 2020.
M. Hodosh, P. Young, and J. Hockenmaier. Framing image description as a ranking task: Data,
models and evaluation metrics. Journal of Artificial Intelligence Research , 2013.
R. A. Horn and C. R. Johnson. Matrix Analysis . Cambridge University Press, 2013.
C. T. Ireland and S. Kullback. Contingency tables with given marginals. Biometrika , 1968.
R. J. Johnston and C. J. Pattie. Entropy-maximizing and the iterative proportional fitting procedure.
The Professional Geographer , 45, 1993.
C. Jones, V . Roulet, and Z. Harchaoui. Discriminative clustering with representation learning with
any ratio of labeled to unlabeled data. Statistics and Computing , 2022.
D. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR , 2015.
M. Klatt, C. Tameling, and A. Munk. Empirical regularized optimal transport: Statistical theory and
applications. SIAM Journal on Mathematics of Data Science , 2020.
T.-Y . Lin, M. Maire, S. Belongie, L. Bourdev, R. Girshick, J. Hays, P. Perona, D. Ramanan, C. L.
Zitnick, and P. Doll ´ar. Microsoft COCO: Common Objects in Context, 2015.
S. Maji, J. Kannala, E. Rahtu, M. Blaschko, and A. Vedaldi. Fine-Grained Visual Classification of
Aircraft. Technical report, University of Oxford, 2013.
G. Mena and J. Niles-Weed. Statistical bounds for entropic optimal transport: Sample complexity
and the central limit theorem. In NeurIPS , 2019.
M. Nutz. Introduction to Entropic Optimal Transport. Lecture notes, Columbia University , 2021.
M. Oquab, T. Darcet, T. Moutakanni, H. V . V o, M. Szafraniec, V . Khalidov, P. Fernandez, D. HAZIZA,
F. Massa, A. El-Nouby, M. Assran, N. Ballas, W. Galuba, R. Howes, P.-Y . Huang, S.-W. Li,
I. Misra, M. Rabbat, V . Sharma, G. Synnaeve, H. Xu, H. Jegou, J. Mairal, P. Labatut, A. Joulin,
and P. Bojanowski. DINOv2: Learning robust visual features without supervision. Transactions
on Machine Learning Research , 2024.
X. Peng, Q. Bai, X. Xia, Z. Huang, K. Saenko, and B. Wang. Moment matching for multi-source
domain adaptation. In ICCV , 2019.
G. Peyr ´e and M. Cuturi. Computational Optimal Transport: With Applications to Data Science.
Foundations and Trends in Machine Learning , 11, 2019.
A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised
multitask learners, 2019.
A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin,
J. Clark, et al. Learning transferable visual models from natural language supervision. In ICML ,
2021.
C. Schuhmann, R. Beaumont, R. Vencu, C. W. Gordon, R. Wightman, M. Cherti, T. Coombes,
A. Katta, C. Mullis, M. Wortsman, P. Schramowski, S. R. Kundurthy, K. Crowson, L. Schmidt,
R. Kaczmarczyk, and J. Jitsev. LAION-5B: An open large-scale dataset for training next generation
image-text models. In NeurIPS , 2022.
J. Shen, Y . Qu, W. Zhang, and Y . Yu. Wasserstein distance guided representation learning for domain
adaptation. In AAAI , 2018.
12R. Sinkhorn. Diagonal equivalence to matrices with prescribed row and column sums. American
Mathematical Monthly , 74(4), 1967.
M. E. Thompson. Theory of Sample Surveys . Chapman & Hall, 2000.
H. Xu, S. Xie, X. Tan, P.-Y . Huang, R. Howes, V . Sharma, S.-W. Li, G. Ghosh, L. Zettlemoyer, and
C. Feichtenhofer. Demystifying CLIP data. In ICLR , 2024.
13Appendix
Table of Contents
A Notation 15
B Linear Operators and Variance Reduction 15
B.1 Singular Value Decomposition . . . . . . . . . . . . . . . . . . . . . . . . . . 15
B.2 Proof of Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
C From Information Projections to Data Balancing 19
C.1 Balancing as Information Projections . . . . . . . . . . . . . . . . . . . . . . . 19
C.2 Proof of Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
D Statistical Analysis of Balancing Estimators 24
D.1 Recursion of Estimation Error . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
D.2 Technical Tools & Intermediate Results . . . . . . . . . . . . . . . . . . . . . . 26
D.3 Analysis of Higher-Order Term . . . . . . . . . . . . . . . . . . . . . . . . . . 27
D.4 Proof of Main Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
D.5 Misspecified Marginal Distributions . . . . . . . . . . . . . . . . . . . . . . . . 35
E Experimental Details 44
E.1 Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
E.2 Model Specification and Hyperparameters . . . . . . . . . . . . . . . . . . . . 44
E.3 Compute Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
E.4 CLIP and Multi-CLIP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
E.5 Metadata Curation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
E.6 Additional Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
F NeurIPS Paper Checklist 50
14A Notation
Symbol Description
X,Y Sample spaces for two data sources.
m,lSupport sizes m=|X|andl=|Y|.
We sometimes assume m=lfor ease of presentation.
P Probability measure on X × Y (the data-generating distribution).
n Sample size.
(X1, Y1), . . . , (Xn, Yn) Independent and identically distributed sample from P.
Pn Empirical measure of {(Xi, Yi)}n
i=1.
QX, QY Marginals of measure QonX × Y , e.g. RX,PY,Pn,X, etc.
Supp(Q) For measure QoverZ, the set of values z∈ Z such that Q(z)>0.
Q(h) The expected value of hunder Q, orEQ[h(X, Y)].
(P(k)
n)k≥1 Sequence of iterations of (8).
k Iteration count of (8).
S The event {Supp(Pn,X) =Supp(PX)and Supp (Pn,Y) =Supp(PY)}.
h Test function h:X × Y → Rof interest.
φ The estimandP
x,yh(x, y)P(x, y).
φ(k)
n The estimatorP
x,yh(x, y)P(k)
n(x, y), when well-defined.
˜φ(k)
n The estimator ˜φ(k)
n:=φ(k)
n1S+φ(0)
n1Sc.
G(k)
n(h) Normalized error√n( ˜φ(k)
n−φ).
V(k)
n(h) Remainder defined in Prop. 15.
¯h Centered function h−EP[h].
σ2
k Variance term EP
(C1, . . .Ckh)2
.
p⋆ min{minxPX(x),minyPY(y)}.
L2(P) Functions h:X × Y → R(asX × Y is finite).
L2(PX),L2(PY) Subspaces of L2(P)containing functions only of x∈ X andy∈ Y, respectively.
µX, µYConditional expectation operators [µXh](x) :=EP[h(X, Y)|X] (x)
and[µYh](y) :=EP[h(X, Y)|Y] (y).
CX,CY Debiasing/centering operators CX=I−µXandCY=I−µY.
µk,Ck (µX,CX)forkodd and (µY,CY)forkeven.
{sj}m
j=1Singular values in Prop. 3.
{αj}m
j=1,{βj}m
j=1Bases for L2(PX)andL2(PY)in Prop. 3.
Table 1: Notation used throughout the paper.
B Linear Operators and Variance Reduction
This section is dedicated to establishing the variance reduction result in Cor. 2 by employing properties
of the Markov operators introduced in Sec. 3. In the first part, we establish Prop. 3, the singular value
decomposition that defines the quantities appearing in Cor. 2. In the second part, we quantify the
difference between σ2
0andσ2
kfor even and odd iterations of k.
B.1 Singular Value Decomposition
Recall the conditional mean operators µXandµYfrom Sec. 3,
[µXh](x) :=E[h(X, Y)|X] (x)and[µYh](y) :=E[h(X, Y)|Y] (y),
with the corresponding debiasing (a.k.a. centering) operators defined by CX=I−µXandCY=
I−µY.
Proposition 3. There exists a basis {αj}m
j=1ofL2(PX), a basis {βj}m
j=1ofL2(PY), and real values
{sj}m
j=1, which satisfy:
µYαj=sjβjandµXβj=sjαjforj∈ {1, . . . , m }, (17)
α1=1X,β1=1Y,s1= 1andsjis non-negative and non-increasing in j.
15Proof. When µXis restricted to L2(PY)andµYis restricted to L2(PX), these operators are in fact
adjoint in L2(P), as by the tower property we have the relation
⟨f, µXg⟩L2(PX)=E[f(X)E[g(Y)|X]] =E[E[f(X)|Y]g(Y)] =⟨µYf, g⟩L2(PY).
Since µY:L2(PX)→L2(PY)is a compact linear operator, by Gohberg et al. [1990, Section IV .1
Theorem 1.1] and Gohberg et al. [1990, Section IV .1 Corollary 1.2], we have that µYadmits a singular
value decomposition satisfying (17). Next, we show that s1≤1and that 1Xis an eigenvector of
µXµY:L2(PX)→L2(PX)with eigenvalue 1, which confirms that s1= 1 andα1=1Xby
the definition of singular values (arguing symmetrically achieves β1=1Y). By the variational
representation of singular values [Gohberg et al., 1990, Section IV .1 Equation (2)], we have that
sup
f:∥f∥L2(PX)=1∥µYf∥L2(PY)=s1.
Consider any f∈L2(PX)such that ∥f∥L2(PX)= 1 . Define the conditional probability
PX|Y(x|y) =P(x, y)/PY(y)which is well-defined by assumption. Then, by the Cauchy-Schwarz
inequality in L2(PX|Y),
∥µYf∥2
L2(PY)=X
y∈Y X
x∈Xf(x)PX|Y(x|y)!2
PY(y)
≤X
y∈YX
x∈Xf2(x)PX|Y(x|y)PY(y)
=X
x∈Xf2(x)X
y∈YP(x, y)
=∥f∥2
L2(PX)= 1.
This proves that s1≤1. For equality, notice that µXµY1X=µX1Y=1X, completing the
proof.
B.2 Proof of Main Results
From Prop. 3, we establish two bases {αj}m
j=1and{βj}m
j=1ofL2(PX)andL2(PY), respectively.
These bases span the range of the operators µXandµY. We will consider the repeated application
of the operator CYCX, a sequence of two centering operations on some function h∈L2(P), and
compare
E
((CYCX)t¯h)2
against E¯h2
for¯h=h−EP[h]. We establish the main result by measuring the reduction in variance from a
single application, in terms of the coordinates of the function of interest on each of the two subspaces.
We will then observe how these coordinates change iteration-to-iteration to give the final result.
Lemma 4. For any h∈L2(P)such that EP[h] = 0 , let
µXh=mX
j=1ujαjandµYh=mX
j=1vjβj.
Then, we have that
E
(CYCXh)2
=E
h2
−mX
j=2u2
j−mX
j=2(vj−sjuj)2.
Proof. By orthogonality, we have that
E
(CYCXh)2
=E
((I−µY)CXh)2
=E
(CXh)2
−2E[(CXh)(µYCXh)] +E
(µYCXh)2
=E
(CXh)2
−2PY((µYCXh)2) +PY((µYCXh)2)
=E
(CXh)2
−PY((µYCXh)2)
=E
h2
−PX((µXh)2)−PY((µYCXh)2).
16Because P(h) = 0 , it holds by the tower property of conditional expectation that PX(µXh) = 0 ,
which implies that
u1=⟨µXh, α1⟩L2(PX)= 0 = ⇒PX((µXh)2) =mX
j=2u2
j.
For the second term, observe that PX(CXh) = 0 , so it holds by the tower property that
PY(µYCXh) = 0 , so
PY((µYCXh)2) =mX
j=2
⟨µYCXh, βj⟩L2(PY)2
.
Next, we compute the term in the square by applying Prop. 3:
⟨µYCXh, βj⟩L2(PY)=⟨µYh, βj⟩L2(PY)− ⟨µYµXh, βj⟩L2(PY)
=vj−*
µYmX
k=1ukαk, βj+
L2(PY)
=vj−*mX
k=1ukskβk, βj+
L2(PY)
=vj−sjuj,
which completes the proof.
Lem. 4 ensures that we have a reduction on each iteration, with a formula that depends on the
coordinates of the function on each subspace. Because these coordinates change every iteration,
we track them in the next lemma. Define h0=¯handht+1= (CYCX)ht, along with the constants
{ut,j}m
j=1and{vt,j}m
j=1given by
µXht=mX
j=1ut,jαjandµYht=mX
j=1vt,jβj.
We have the following.
Lemma 5. For all t≥0, it holds that
ut+1,j=s2
jut,j−sjvt,j,
vt+1,j= 0.
Proof. Fix any j∈[m], and use Prop. 3 to write
ut+1,j=⟨µXCYCXht, αj⟩L2(PX)
=⟨µX(I−µX−µY+µYµX)ht, αj⟩L2(PX)
=⟨µXµYµXht, αj⟩L2(PX)− ⟨µXµYht, αj⟩L2(PX)
=*
µXµYmX
k=1ut,kαk, αj+
L2(PX)−*
µXmX
k=1vt,kβk, αj+
L2(PX)
=s2
jut,j−sjvt,j,
which proves the first part of the claim. For the second part, note that µYCY= 0 , so
⟨µYCYCXht, αj⟩L2(PY)= 0.
Using Lem. 4 and Lem. 5, we can simply accumulate the reduction incurred on every iteration.
17Proposition 6. Define the constants (uj)m
j=1and(vj)m
j=1by
µX¯h=mX
j=1ujαjandµY¯h=mX
j=1vjβj.
Then, we may quantify the variance reduction achieved by t+ 1iterations of the CYCXoperator as
E¯h2
−E
((CYCX)t+1¯h)2
=mX
j=2(
u2
j+ (vj−sjuj)2"
1 +s2
j(1−s4t
j)
1−s2
j#)
→mX
j=2"
u2
j+(vj−sjuj)2
1−s2
j#
ast→ ∞ .
Proof. Apply Lem. 4 (t+ 1) -times so that
E
((CYCX)t+1¯h)2
=E¯h2
−mX
j=2tX
τ=0
(1 +s2
j)u2
τ,j+v2
τ,j−2sjuτ,jvτ,j
=E¯h2
−mX
j=2"
v2
0,j−2sju0,jv0,j+tX
τ=0(1 +s2
j)u2
τ,j#
as by Lem. 5, we have that vτ,j= 0forτ >0. Next, we unroll the definition of uτ,jso that
uτ,j=s2
juτ−1,j−sjvτ−1,j
=s2
j(s2
juτ−2,j−sjvτ−2,j)−sjvτ−1,j
=s2τ−2
j(s2
ju0,j−sjv0,j)
forτ >0, yielding
E¯h2
−E
((CYCX)t+1¯h)2
=mX
j=2"
u2
0,j+ (v0,j−sju0,j)2+ (1 + s2
j)(s2
ju0,j−sjv0,j)2tX
τ=1(s4
j)τ−1#
=mX
j=2"
u2
0,j+ (v0,j−sju0,j)2+ (1 + s2
j)(s2
ju0,j−sjv0,j)2t−1X
τ=0(s4
j)τ#
=mX
j=2"
u2
0,j+ (v0,j−sju0,j)2+s2
j(1 +s2
j)(v0,j−sju0,j)2(1−s4t
j)
1−s4
j#
=mX
j=2"
u2
0,j+ (v0,j−sju0,j)2+s2
j(v0,j−sju0,j)2(1−s4t
j)
1−s2
j#
.
Substitute u0,j=ujandv0,j=vjto complete the proof.
We also present the corresponding result for kodd. The proof follows similarly by repeated application
of the operator CYCX. However, the iterations will be compared to σ2
1=EP
(CX¯h)2
, as we
consider CX¯has the “first” iteration to this process.
Proposition 7. Define the constants (uj)m
j=1by
µYCX¯h=mX
j=1ujβj.
18Then, we may quantify the variance reduction achieved by t+ 1iterations of the CXCYoperator as
E
(CX¯h)2
−E
((CXCY)t+1CX¯h)2
=mX
j=2(
u2
j+ (sjuj)2"
1 +s2
j(1−s4t
j)
1−s2
j#)
→mX
j=2 
1 +s2
j
1−s2
j!
u2
j
ast→ ∞ .
In order to have full monotonicity, we also need that σ2
0≥σ2
1. This follows by orthogonality, as
σ2
0=E¯h2
=E
(CX¯h)2
+E
(µX¯h)2
=σ2
1+E
(µX¯h)2
≥σ2
1. (18)
Thus, we can combine Prop. 7 and (18) to fully quantify the relationship between σ2
0andσ2
kfork
odd.
C From Information Projections to Data Balancing
This section is dedicated to deriving three representations of the balancing procedure as projections
in various statistical divergences, as shown in Fig. 2.
We consider two sets of probability measures denoted by ΠX={Q:QX=PX}andΠY=
{Q:QY=PY}. The marginal matching steps are written as projections in terms of a statistical
divergence D(precisely, an f-divergence) in the form
PX
P(k−1)
n,X⊗P(k−1)
n = arg min
Q∈ΠXD(Q∥P(k−1)
n),PY
P(k−1)
n,Y⊗R= arg min
Q∈ΠYD(Q∥P(k−1)
n).
We provide the derivations for three common choices of D: Kullback-Leibler (KL), reverse KL, and
χ2. Using this viewpoint, and simply assuming the positivity of the marginal measures PXandPY,
we derive an upper bound in Prop. 14 that is constant ink. This is an improvement over the recent
work of Albertus and Berthet [2019], in which they show an upper bound that scales exponentially in
k.
The KL representation will be used in the proof of Prop. 14, which (recalling the sequence (P(k)
n)k≥1
from (8)), controls the error between P(k)
n,YandPYforkodd and P(k)
n,XandPXforkeven.
C.1 Balancing as Information Projections
C.1.1 Projection in KL-Divergence
Proposition 8. Assume that PX≪RXandPY≪RY, and define
Q⋆:= arg min
Q∈ΠXKL(Q∥R), P⋆:= arg min
Q∈ΠYKL(Q∥R). (19)
Then, it holds that
Q⋆(x, y) =PX(x)RY|X(y|x)ifRX(x)>0
0 ifRX(x) = 0(20)
and
P⋆(x, y) =PY(y)RX(x|y)ifRY(y)>0
0 ifRY(y) = 0. (21)
19Proof. In the case that Q(x, y) = 0 , we apply the convention that 0 log 0 = 0 . Consider the case Q⋆,
the projection of RontoΠX. Write
KL(Q∥R) =X
x∈XX
y∈YQ(x, y) logQY|X(y|x)QX(x)
RY|X(y|x)RX(x)
=X
x∈XQX(x)
X
y∈YQY|X(y|x) logQY|X(y|x)QX(x)
RY|X(y|x)RX(x)

=X
x∈XQX(x)
X
y∈YQY|X(y|x) logQY|X(y|x)
RY|X(y|x)+X
y∈YQY|X(y|x) logQX(x)
RX(x)

=X
x∈XQX(x)
X
y∈YQY|X(y|x) logQY|X(y|x)
RY|X(y|x)
+X
x∈XQX(x) logQX(x)
RX(x)
=X
x∈XQX(x) KL( QY|X(·|x)∥RY|X(·|x)) + KL( QX∥RX)
=X
x∈XPX(x) KL( QY|X(·|x)∥RY|X(·|x)) + KL( PX∥RX),
where the last line is due to the marginal constraint Q∈ΠX. For the above to be well defined, we
need that PX≪RXso that KL(PX∥RX)<+∞. The above is minimized when QY|X(y|x) =
RY|X(y|x)for all (x, y)∈ X × Y such that QX(x) =PX(x)>0. The case of P⋆follows
analogously when using that PY≪RY.
C.1.2 Projection in Reverse KL-Divergence
Proposition 9. Assume that PY≪RXandPY≪RY, and define
Q⋆:= arg min
Q∈ΠXKL(R∥Q), P⋆:= arg min
Q∈ΠYKL(R∥Q). (22)
Then, it holds that
Q⋆(x, y) =PX(x)RY|X(y|x)ifRX(x)>0
0 ifRX(x) = 0(23)
and
P⋆(x, y) =PY(y)RX(x|y)ifRY(y)>0
0 ifRY(y) = 0. (24)
Proof. In the case that R(x, y) = 0 , we apply the convention that 0 log 0 = 0 . Note that minimizing
KL(R∥Q)overQis equivalent to minimizing −P
x,yR(x, y) logQ(x, y)(i.e. the cross entropy).
Consider the case Q⋆, the projection of RontoΠX. Because R≪QforKL(R∥Q)<+∞to hold,
we have that R(x)>0 =⇒Q(x)>0, so that QY|X(y|x)is well-defined. Write
−X
x,yR(x, y) logQ(x, y)
=−X
x∈XRX(x) logQX(x)−X
x∈XR(x)X
y∈YRY|X(y|x) logQY|X(y|x)
=−X
x∈XRX(x) logPX(x) +X
x∈XRX(x)
−X
y∈YRY|X(y|x) logQY|X(y|x)
.
The second first term does not depend on Qdue to the marginal constraint Q∈ΠX. The second
term is the expectation of the cross entropy from RY|XtoQY|XoverRX, which is minimized if
RY|X=QY|X. We have specified QY|XandQX, completing the proof.
20C.1.3 Projection in χ2-Divergence
Let1denote the function that is identically equal to 1. Consider the following optimization problem,
which is the subject of the subsequent lemmas:
min
ξ∈AX∥1−ξ∥2
L2(R), (25)
where
AX:=

f:X × Y → RsatisfyingX
y∈Yf(x, y)R(x, y) =PX(x)for any x∈ X

.
Lemma 10. Assume that PX≪RX, and define The problem (25) is feasible, and its solution can
be written as
ξ⋆=CR
X(1−f) +f
for any f∈L2(R), where the linear operator CR
Xis specified by
[CR
Xg](x, y) =g(x, y)−X
y′∈Yg(x, y′)RY|X(y′|x).
Proof. First, we establish feasibility by letting
f(x, y) :=PX(x)/RX(x)ifRX(x)>0
1 otherwise.
This function does not depend on the second input y. Because we assumed that PX≪RX, we have
that the terms of f(x, y)for which RX(x) = 0 do not affect whetherP
y∈Yf(x, y)R(x, y) =PX(x),
because PX(x) = 0 in these cases. In the remainder of this proof, we will show that (25) is an affine
projection problem, and find its solution by converting it to a subspace projection problem. Indeed,
consider f1, . . . , f r∈ AX, and α1, . . . , α r∈Rsuch thatPr
j=1αj= 1. Then,
X
y∈Y
rX
j=1αjfj(x, y)
·R(x, y) =rX
j=1αj
X
y∈Yfj(x, y)R(x, y)
=PX(x),
indicating thatPr
j=1αjfj(x, y)∈ AXandAXis an affine subset of L2(R). Define
SX:=

g:X × Y → RsatisfyingX
y∈Yg(x, y)R(x, y) = 0 for any x∈ X

.
Then, for any f∈ AX, we have that g∈ SXif and only if g+f∈ AX. Taking any f∈ AX, letting
ϕ⋆be the solution of
min
ϕ∈SX∥1−f−ϕ∥2
L2(R), (26)
we will have that ϕ⋆+fwill be the solution of (25). The remainder of the proof is showing that
ϕ⋆=CR
X(1−f).
First, define the operator µR
Xby[µXg](x, y) =P
y′∈Yg(x, y′)RY|X(y′|x), and note (by factoring
outRX(x)) that g∈ SXif and only if µR
Xg= 0. In addition, µR
Xgis linear and idempotent as
µR
XµR
Xg=µR
Xg, so it is a projection operator in L2(R). Thus, SXis the orthogonal complement of
range( µR
X), and the solution of (26) is given by (I−µR
X)(1−f) =CR
X(1−f), because CR
X=I−µR
X.
The claim is proved.
Lemma 11. Assume that PX≪RX. Define
Q⋆:= arg min
Q∈ΠXχ2(Q∥R). (27)
and let ξ⋆be the solution of problem (25). Then,
Q⋆(x, y) =ξ⋆(x, y)R(x, y) =PX(x)RY|X(y|x)ifRX(x)>0
0 ifRX(x) = 0. (28)
21Proof. First, by reparametrizing the problem (27) as finding ξsuch that Q(x, y) =ξ(x, y)R(x, y),
we can compute its solution by solving
min
ξ∈AX,ξ≥0∥1−ξ∥2
L2(R), (29)
Notice that we also have a non-negativity constraint, as opposed to (25). Ifξ⋆solves (25) and
happens to be non-negative, then we have that ξ⋆solves (29) as well and the first equality of (28)
is satisfied by definition. We show the second equality of (28) by direct computation, which also
establishes the non-negativity of ξ⋆simultaneously.
Apply Lem. 10 with
f(x, y) :=PX(x)/RX(x)ifRX(x)>0
1 otherwise.
so that
ξ⋆(x, y) =CR
X(1−f) (x, y) +f(x, y)
="X
z∈Yf(x, z)RY|X(z|x)−f(x, y)#
+f(x, y)
=f(x, y′)
for any y′∈ Y . Thus, the likelihood ratio of Q⋆with respect to Ris a marginal reweighting.
Accordingly,
Q⋆(x, y) =ξ⋆(x, y)R(x, y) =PX(x)RY|X(y|x)ifRX(x)>0
0 ifRX(x) = 0,
completing the proof.
Proposition 12. Assume that PX≪RXandPY≪RY. Define
Q⋆:= arg min
Q∈ΠXχ2(Q∥R), P⋆:= arg min
Q∈ΠYχ2(Q∥R). (30)
Then, it holds that
Q⋆(x, y) =PX(x)RY|X(y|x)ifRX(x)>0
0 ifRX(x) = 0
P⋆(x, y) =PY(y)RX|Y(x|y)ifRY(y)>0
0 ifRY(y) = 0. (31)
Proof. The first equality of (31) follows by the claim of Lem. 11. The second equality follows by
repeating the argument of Lem. 10 and Lem. 11 with (X, x)and(Y, y)swapped.
C.2 Proof of Main Results
We may now control the errors of the ratio of marginals using the projection interpretation established
in the previous sections. Recall the event Sas defined in Tab. 1. The following result, the monotonicity
of the marginal violation terms in terms of KL, will be useful in the bound.
Proposition 13. [Nutz, 2021, Proposition 6.10] Under the event S, it holds that
KL(P(0)
n,X∥PX)≥KL(PY∥P(1)
n,Y)≥KL(P(2)
n,X∥PX)≥. . .
We give the following result for Xand the analogous claim holds on Y.
Proposition 14. Assume that Pn,X(x)>0for all x∈ X. It holds that
max
x∈XPX(x)
P(k−1)
n,X(x)−1≤max{n−1,1} ifk= 1
max{1/p2
⋆−1,1}ifk >1.(32)
22In addition, we have that
max
x∈XPX(x)
P(k−1)
n,X(x)−1≤

nq
1
2KL(Pn,X∥PX)ifk= 1
1
p2⋆q
1
2KL(Pn,X∥PX)ifk >1.
Moreover, when KL(Pn,X∥PX)≤p2
⋆/2, we have
max
x∈XPX(x)
P(k−1)
n,X(x)−1≤2
p⋆r
1
2KL(Pn,X∥PX). (33)
Proof. We first show that P(k−1)
n(x)≥1/nfork= 1 andP(k−1)
n(x)≥p2
⋆fork >1. In the case
thatk= 1, the result follows directly from the event S. For k >1such that kis odd, we have that
forx∈ X,
P(k−1)
n,X(x) =X
y∈YP(k−1)
n(x, y) =X
y∈YPY(y)
P(k−2)
n,Y(y)P(k−2)
n(x, y)
≥p⋆X
y∈YP(k−2)
n(x, y) =p⋆P(k−2)
n,X(x) =p⋆PX(x)≥p2
⋆.
The result for keven can be proven similarly. We now proceed to prove the inequalities given in the
statement, which will rely on the lower bound above.
Proving the first inequality. Then, for any x∈ X,
PX(x)
P(k−1)
n,X(x)−1= max(
PX(x)
P(k−1)
n,X(x)−1,1−PX(x)
P(k−1)
n,X(x))
≤max{n−1,1} ifk= 1
max{1/p2
⋆−1,1}ifk >1,
which is the desired result for the first inequality.
Proving the second and third inequalities. Consider an odd k≥1. By the definition of total
variation distance, it holds that
max
x∈XPX(x)−P(k−1)
n,X(x)≤TV(P(k−1)
n,X, PX).
According to Pinsker’s inequality, we have that TV(P(k−1)
n,X, PX)≤q
1
2KL(P(k−1)
n,X∥PX), and so we
have that
max
x∈XPX(x)−P(k−1)
n,X(x)≤r
1
2KL(P(k−1)
n,X∥PX)≤r
1
2KL(P(0)
n,X∥PX),
where the last inequality follows by the monotonicity of Sinkhorn iterations given in Prop. 13. We
apply the lower bounds to write
max
x∈XPX(x)
P(k−1)
n,X(x)−1≤

nq
1
2KL(Pn,X∥PX)ifk= 1
1
p2⋆q
1
2KL(Pn,X∥PX)ifk >1.
Finally, whenq
1
2KL(Pn,X∥PX)≤p⋆/2, we have that max x∈XPX(x)−P(k−1)
n,X(x)≤p⋆/2and
thus
min
x∈XP(k−1)
n,X(x)≥min
x∈XPX(x)−max
x∈XP(k−1)
n,X(x)−PX(x)≥p⋆
2.
Hence,
max
x∈XPX(x)
P(k−1)
n,X(x)−1≤max x∈XP(k−1)
n,X(x)−PX(x)
minx∈XP(k−1)
n,X(x)≤2
p⋆r
1
2KL(Pn,X∥PX).
23Now, for keven, set k= 2tfort≥0. We have that
max
y∈YP(2t−1)
n,Y (y)−PY(y)≤TV(P(2t−1)
n,Y , PY)≤r
1
2KL(PY∥P(2t−1)
n,Y ).
Invoke Prop. 13 once again to achiever
1
2KL(PY∥P(2t−1)
n,Y )≤r
1
2KL(Pn,X∥PX),
which completes the proof.
D Statistical Analysis of Balancing Estimators
This section contains the proof of the main result, namely Thm. 1. We first consolidate notation and
then give a broad outline of the proof for readability. Let the expectation of a function hunder a
probability measure QonX × Y by denoted by
Q(h) =X
x∈X,y∈Yh(x, y)Q(x, y)
so that
φ(k)
n=P(k)
n(h), φ =P(h),
and
G(k)
n(h) =√n[P(k)
n−P](h) =√n(P(k)
n(h)−P(h)). (34)
Recalling in addition that Ck=CXforkodd and Ck=CYforkeven. The event
S:={Supp(Pn,X) =Supp(PX)and Supp (Pn,Y) =Supp(PY)}, (35)
is used for purely technical reasons in many results.
Proof Outline. We first establish that the recursion formula
[P(k)
n−P](h) = [P(k−1)
n−P](Ckh) +V(k−1)
n(Ckh)
holds in Prop. 15, where
V(k−1)
n(h) =

P
x,y
PX
P(k−1)
n,X(x)−1
h(x, y)P(k−1)
n(x, y)kodd
P
x,y
PY
P(k−1)
n,Y(y)−1
h(x, y)P(k−1)
n(x, y)keven. (36)
The quantity V(k−1)
n(Ckh)describes an error term that accumulates for each iteration of balancing,
which explains why kmust be scaled appropriately against nto ensure the error does not accumulate
too fast. Applying the recursion repeatedly to the balanced sequence (P(k)
n)k≥1and unrolling the
recursion, we see that when kis odd,
[P(k)
n−P](h) = [P(k−1)
n−P](CXh) +V(k−1)
n(CXh)
= [P(k−2)
n−P](CYCXh) +V(k−2)
n(CYCXh) +V(k−1)
n(CXh)
= [P(0)
n−P](C1. . .Ckh)| {z }
first-order term+Pk
ℓ=1V(ℓ−1)
n(Cℓ. . .Ckh)| {z }
higher-order term(37)
Additionally, let hℓ,k:=Cℓ. . .Ckh, so that the first-order term can be written as P(0)
n(h1,k)−P(h1,k)
higher-order term can also be written asPk
ℓ=1V(ℓ−1)
n(hℓ,k). Because our original goal is to upper
bound the mean squared error, we use the expansion above to write
E|P(k)
n(h)−P(h)|2≤E|P(0)
n(h1,k)−P(h1,k)|2
+ 2E|P(0)
n(h1,k)−P(h1,k)|Pk
ℓ=1V(ℓ−1)
n(hℓ,k)+EPk
ℓ=1V(ℓ−1)
n(hℓ,k)2
Regarding the first term, we have that E|P(0)
n(h1,k)−P(h1,k)|2=σ2
k/n, which is the dominant
term in Thm. 1. Thus, the remaining challenge of the proof will be to upper bound the cross term
and squared term and show its dependence on n. The dominant term of these two will be the cross
term, as we will essentially show that |P(0)
n(h1,k)−P(h1,k)|isO(n−1/2)with high probability
and that |Pk
ℓ=1V(ℓ−1)
n(hℓ,k)|is in fact O(n−1)with high probability. As stated in Sec. 3, a key
intermediate result in controlling the higher-order term is Prop. 14, whose proof is given in Appx. C.
The remaining subsections walk through these steps in detail.
24D.1 Recursion of Estimation Error
We first recall that the sequence (P(k)
n)k≥1can be computed with the following formula:
P(0)
n(x, y) :=Pn(x, y)andP(k)
n(x, y) :=

PX
P(k−1)
n,X(x)P(k−1)
n(x, y)kodd
PY
P(k−1)
n,Y(y)P(k−1)
n(x, y)keven. (38)
Prop. 15 establishes the conditions under which these steps are well-defined (i.e. P(k−1)
n,X(x)>0and
P(k−1)
n,Y(y)>0).
Proposition 15. Let(P(k)
n)k≥1, be a sequence computed according to (8). These iterations are
well-defined under the event S, and for G(k)
ndefined in (34) andV(k)
ndefined in (36), it holds that
G(k)
n(h) =G(k−1)
n(h) +√nV(k−1)
n(h). (39)
and
G(k)
n(h) =G(k−1)
n(Ckh) +√nV(k−1)
n(Ckh). (40)
Proof. First, assume that P(k−1)
n,X(x)>0andP(k−1)
n,Y(y)>0for all x∈ X andy∈ Y so that we may
establish the recursion, which we will show by induction toward the end of the proof.
Consider the following steps in the case that kis odd:
P(k)
n(h)
=X
x,yh(x, y)P(k)
n(x, y) =X
x,yh(x, y)PX
P(k−1)
n,X(x)P(k−1)
n(x, y) by (38) for kodd
=X
x,y1·h(x, y)P(k−1)
n(x, y) +X
x,y"
PX
P(k−1)
n,X(x)−1#
·h(x, y)P(k−1)
n(x, y)
=P(k−1)
n(h) +V(k−1)
n(h).
Arguing analogously for keven and subtracting P(h)on both sides, we have that
[P(k)
n−P](h) = [P(k−1)
n−P](h) +V(k−1)
n(h). (41)
We refer to this as the “uncentered” recursion, which proves (39).
We can then establish the following “centered” recursion using the following decomposition in the
case of kodd.
[P(k)
n−P](h)
= [P(k)
n−P](CXh) + [P(k)
n−P](µXh) h=CXh+µXh
= [P(k−1)
n−P](CXh) +V(k−1)
n(CXh) + [P(k)
n−P](µXh) apply (41) to CXh
= [P(k−1)
n−P](CXh) +V(k−1)
n(CXh). P(k)
n(µXh) =P(µXh)
The last line follows because µXhis only a function on X, and due to the definition of the marginal
rebalancing iterations, P(k)
n,X=PX. This gives the desired formula by substituting (34).
We proceed to show that the iterations are well-defined. We will in fact show that P(k−1)
n,X(x)>0
andP(k−1)
n,Y(y)>0for all x∈ X andy∈ Y. For k= 1,P(0)
n,X(x) =Pn,X(x)>0andP(0)
n,Y(y) =
Pn,Y(y)>0for all x∈ X andy∈ Y this holds under the event Sby assumption. We argue by
induction that this holds for all k >1. Assume that the claim is true for {1, . . . , k −1}, and that kis
even. Then,
P(k−1)
n,X(x) =PX(x)>0,
P(k−1)
n,Y(y) =X
x∈XP(k−1)
n(x, y) =X
x∈XPX
P(k−2)
n,X(x)P(k−2)
n(x, y)
≥min
x∈XPX
P(k−2)
n,X(x)·P(k−2)
n,Y(y)>0
asP(k−2)
n,X(x)>0andP(k−2)
n,Y(y)>0by the inductive hypothesis. Arguing analogously for kodd
achieves the claim.
25D.2 Technical Tools & Intermediate Results
Having established the backbone of the argument, we collect in this subsection some useful tools that
are used in the remainder of the proofs.
The following result follows from the method of types in information theory and will be helpful in
deriving the dependence of the higher-order term on n.
Theorem 16. [Cover, 1999, Theorem 11.2.1] Let νbe a discrete probability measure supported on
matoms. Let U1, . . . , U ni.i.d.∼νandνnbe the associated empirical measure. Then, we have for any
ϵ >0that
P(KL(νn∥ν)≥ϵ)≤2−n(ϵ−mlog(n+1)
n).
We then provide a result that counts the number of terms that appear when repeatedly centering via
the operators C1, . . . ,Ck. This formalizes the pattern
CX=I−µX
CYCX=I−µX−µY+µYµX
CXCYCX=I−µX−µY+µYµX+µXµY−µXµYµX,
and so on. This will be useful when bounding hℓ,kuniformly.
Lemma 17. For any k≥1andℓ∈ {1, . . . , k },
Cℓ. . .Ck=I−(k−ℓ−1)/2X
τ=0(µXµY)τµX−(k−ℓ−1)/2X
τ=0(µYµX)τµY
+(k−ℓ)/2X
τ=1(µXµY)τ+(k−ℓ)/2X
τ=1(µYµX)τ+ (−1)k−ℓ+1µℓ. . . µ k,
where the sumPj
τ=iis 0 when i > j and isP⌊j⌋
τ=iwhen jis not an integer by convention.
Proof. We prove the claim by backward induction on ℓ, for the case that kis odd. In the case ℓ=k,
the claim holds because Ck=I−µk. Next, for any ℓ < k , assume that the stated result holds for
{ℓ+ 1, . . . , k }. Then, if ℓis also odd (so that µℓ=µX),
Cℓ. . .Ck=CℓCℓ+1. . .Ck
=I−(k−ℓ−2)/2X
τ=0(µXµY)τµX−(k−ℓ−2)/2X
τ=0(µYµX)τµY
+(k−ℓ−1)/2X
τ=1(µXµY)τ+(k−ℓ−1)/2X
τ=1(µYµX)τ+µY. . .|{z}
k−ℓtermsµX
−µX+(k−ℓ−2)/2X
τ=0(µXµY)τµX+(k−ℓ−2)/2X
τ=0µX(µYµX)τµY
−(k−ℓ−1)/2X
τ=1(µXµY)τ−(k−ℓ−1)/2X
τ=1µX(µYµX)τ−(µXµY)(k−ℓ)/2µX
The red terms and blue terms cancel out to zero. This leaves
Cℓ. . .Ck=I−(k−ℓ−2)/2X
τ=0(µXµY)τµX−(k−ℓ−2)/2X
τ=0(µYµX)τµY
+(k−ℓ−1)/2X
τ=1(µYµX)τ+ (µYµX)(k−ℓ)/2
+(k−ℓ−2)/2X
τ=0µX(µYµX)τµY+ (−1)k−ℓ+1µℓ. . . µ k
26wherein we combine the red terms and re-index the blue terms to get
Cℓ. . .Ck=I−(k−ℓ−2)/2X
τ=0(µXµY)τµX−(k−ℓ−2)/2X
τ=0(µYµX)τµY
+(k−ℓ)/2X
τ=1(µYµX)τ+(k−ℓ)/2X
τ=1(µXµY)τ+ (−1)k−ℓ+1µℓ. . . µ k.
Finally, because k−ℓis even when kis odd and ℓis odd, we can set the upper bound of the first two
sums to (k−ℓ−1)/2without changing the number of terms. This proves the desired result. The
result can be proved similarly when ℓis even. As a result, we have proved the claim for any odd k
andℓ≤k. Similar arguments can be used for the case of keven and ℓ≤k.
D.3 Analysis of Higher-Order Term
Returning to the outline at the start of this section, we may now bound the higher-order remainder
term in (37), namely
kX
ℓ=1V(ℓ−1)
n(hℓ,k) =kX
ℓ=1V(ℓ−1)
n(Cℓ. . .Ckh),
depends on controlling the quantity V(k−1)
n in the summation, which we recall for convenience:
V(k−1)
n(h) =

P
x,y
PX
P(k−1)
n,X(x)−1
h(x, y)P(k−1)
n(x, y)kodd
P
x,y
PY
P(k−1)
n,Y(y)−1
h(x, y)P(k−1)
n(x, y)keven. (42)
Because we have established uniform control over the functions PX/P(k−1)
n,X−1andPY/P(k−1)
n,Y−1,
via Prop. 14 in Appx. C we can now bound the full remainder in Prop. 20.
We also make use of the following intermediate result, which controls how large the ℓ∞-norm of the
function hcan grow after centering.
Lemma 18. ∥hℓ,k∥∞≤2(k−ℓ+ 1)∥h∥∞.
Proof. Apply Lem. 17 and the triangle inequality, so that we only need to count the number of terms
that appear in the sums, adding 2for the first and last term in the expression. We subtract 1from the
total, as one of either (k−ℓ)/2or(k−ℓ+ 1)/2will be a fraction. This yields 2(k−ℓ+ 1) terms
total, the desired result.
We upper bound the sum in Prop. 20. To do so, we introduce some notation. Consider B1andB2
defined by
B1:=M1and B2:= max
2≤ℓ≤kMℓfor Mℓ:=

max x∈XPX(x)
P(ℓ−1)
n,X(x)−1ℓodd
max y∈YPY(y)
P(ℓ−1)
n,Y(y)−1ℓeven
fork≥1. We also enumerate the sample spaces as X={x1, . . . , x m}andY={y1, . . . , y m}, and
define the function
1jk(x, y) :=1{x=xj}kodd
1{y=yj}keven.
This is an indicator function on the j-th element of either XorYdepending on whether kis odd or
even. Finally, for any function h, use (under the event S) recall the empirical process notation
G(k)
n(h) :=√n(P(k)
n(h)−P(h)). (43)
Using this notation, we can rewrite the recursion in terms of the quantity G(k)
n(h)itself. This is
established in the following lemma.
27Lemma 19. Forkodd, it holds that
G(k)
n(h) =G(k−1)
n(CXh) +mX
j=1"
PX(xj)
P(k−1)
n,X(xj)−1#
G(k−1)
n(CXh1jk),
whereas for keven, it holds that
G(k)
n(h) =G(k−1)
n(CYh) +mX
j=1"
PY(yj)
P(k−1)
n,Y(yj)−1#
G(k−1)
n(CYh1jk),
Proof. We give the proof for kodd. By (40) from Prop. 15 and by the definition of G(k)
n(h), we need
only show that P(CXh1jk) = 0 . Indeed,
E[CXh1jk|X] (x) =E[CXh|X] (xj)ifx=xj
0 ifx̸=xj.
ButE[CXh|X] (xj) = 0 by definition of CX. Taking an expectation over PXgives that
P(CXh1jk) = 0 , which implies the desired result. The proof for keven follows symmetrically.
The higher-order term in (37), can be bounded using Prop. 20.
Proposition 20. For any k≥1, the following holds under the event S:
√nkX
ℓ=1|V(ℓ−1)
n(Cℓ. . .Ckh)| ≤mX
j=1 
B1|G(0)
n(h1,k1jℓ)|+B2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+mB2∥h∥∞√nk(k−1)[B1+B2(k+ 1)/3].
Proof. First, for any ℓ∈ {1, . . . , k }, recall the notation hℓ,k:=Cℓ. . .Ckh. By (39) from Prop. 15
and by Lem. 19, we have that for ℓodd,
√nV(ℓ−1)
n(hℓ,k) =mX
j=1"
PX
P(ℓ−1)
n,X(xj)−1#
G(ℓ−1)
n(hℓ,k1jℓ). (44)
Using the statement above, we have that
√n|V(ℓ−1)
n(hℓ,k)| ≤MℓmX
j=1|G(ℓ−1)
n(hℓ,k1jℓ)|.
The bound above holds for ℓeven as well. Then, using the (39) from Prop. 15 again, we have that for
ℓ≥2,
[P(ℓ−1)
n−P](hℓ,k1jℓ) = [P(ℓ−2)
n−P](hℓ,k1jℓ) +V(ℓ−2)
n(hℓ,k1jℓ)
which implies that
|G(ℓ−1)
n(hℓ,k1jℓ)| ≤ |G(ℓ−2)
n(hℓ,k1jℓ)|+√n|V(ℓ−2)
n(hℓ,k1jℓ)|
≤ |G(0)
n(hℓ,k1jℓ)|+√n|V(0)
n(hℓ,k1jℓ)|+. . .+√n|V(ℓ−2)
n(hℓ,k1jℓ)|
≤ |G(0)
n(hℓ,k1jℓ)|+M1√nP(0)
n(|hℓ,k|1jℓ) +. . .+Mℓ√nP(ℓ−2)
n(|hℓ,k|1jℓ)
≤ |G(0)
n(hℓ,k1jℓ)|+ 2∥h∥∞√n[B1+B2(ℓ−1)] (k−ℓ+ 1), (45)
28by Lem. 18 and M1≤B1andMℓ≤B2forℓ≥2. Summing these bounds, we have that
√nkX
ℓ=1|V(ℓ−1)
n(hℓ,k)|
≤M1mX
j=1|G(0)
n(h1,k1jℓ)|+kX
ℓ=2MℓmX
j=1|G(ℓ−1)
n(hℓ,k1jℓ)|
≤B1mX
j=1|G(0)
n(h1,k1jℓ)|+B2kX
ℓ=2mX
j=1|G(ℓ−1)
n(hℓ,k1jℓ)|
≤B1mX
j=1|G(0)
n(h1,k1jℓ)|+
B2kX
ℓ=2mX
j=1 
|G(0)
n(hℓ,k1jℓ)|+ 2∥h∥∞√n[B1+B2(ℓ−1)] (k−ℓ+ 1)
apply (45)
=mX
j=1 
B1|G(0)
n(h1,k1jℓ)|+B2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+
2mB2∥h∥∞√nkX
ℓ=2[B1+B2(ℓ−1)] (k−ℓ+ 1),
because |X|=m. We sum up the last term:
kX
ℓ=2[B1+B2(ℓ−1)] (k−ℓ+ 1) = B1k−1X
ℓ=1(k−ℓ) +B2k−1X
ℓ=1ℓ(k−ℓ)
=k(k−1)
2[B1+B2(k+ 1)/3].
completing the proof.
D.4 Proof of Main Results
We can now show the main result of this section: the bound on the mean squared error of the
rebalanced estimator. Recall the event
S:={Supp(Pn,X) =Supp(PX)and Supp (Pn,Y) =Supp(PY)} (46)
as introduced in (35). To remind the reader of the high-level steps of the proof, we may decompose
the error on the event Swe used the estimator
˜φ(k)
n:=φ(k)
n1S+φ(0)
n1Sc
so we decompose on the event Sto write
EP
˜Pn(k)(h)−P(h)2
=EPh
(Pn(h)−P(h))21Sci
+EPh
(P(k)
n(h)−P(h))21Si
.(47)
Then, we use the upcoming Prop. 21 to bound the first term, which will in turn require showing that
Soccurs with high probability. As for the second term, we will apply Prop. 15 and the derivation (37)
to write
EPh
(P(k)
n(h)−P(h))21Si
=EP
T2
11S
+ 2EP[T1T21S] +EP
T2
21S
(48)
for
T1:= [P(0)
n−P](C1. . .Ckh)andT2:=kX
ℓ=1V(ℓ−1)
n(Cℓ. . .Ckh). (49)
By definition, we have that EP
T2
11S
≤EP
T2
1
=σ2
k/n. It then remains to bound the cross
termEP[T1T21S]and squared term EP
T2
21S
. This is accomplished by Lem. 23 and Lem. 22,
respectively.
29Proposition 21. It holds that P(Sc)≤2m(1−p⋆)n. Moreover, for any δ∈(0,1), we have
EPh
(Pn(h)−P(h))21Sci
≤4∥h∥2
∞min{2m(1−p⋆)n, δ}+2 log(2 /δ)
n∥h∥2
∞2m(1−p⋆)n.
Proof. Define FX:={Supp(Pn,X)̸=Supp(PX)}andFY:={Supp(Pn,Y)̸=Supp(PY)}, so that
Sc=FX∪FY. We first control the probability of FX. LetFj:={Pn,X(xj) = 0}forj∈[m]. We
then obtain FX=∪m
j=1Fj, which implies by the union bound that
P(FX)≤mX
j=1P(Fj) =mX
j=1(1−PX(xj))n≤m(1−p⋆)n.
Similarly, we have that P(FY)≤m(1−p⋆)nand thus P(Sc)≤2m(1−p⋆)n, which gives the first
claim.
To control the expectation, consider any δ >0, and define the event
Eδ:=(P(0)
n(h)−P(h)≤r
2 log (2 /δ)
n∥h∥∞)
.
By Hoeffding’s inequality, it holds that P(Eδ)≥1−δ. Furthermore, we get
E[1Sc(P(0)
n(h)−P(h))2] =E[1Sc1Ec
δ(P(0)
n(h)−P(h))2] +E[1Sc1Eδ(P(0)
n(h)−P(h))2]
≤4∥h∥2
∞E[1Sc1Ec
δ] +2 log (2 /δ)
n∥h∥2
∞E[1Sc1Eδ]
≤4∥h∥2
∞min{P(Sc), P(Ec
δ)}+2 log (2 /δ)
n∥h∥2
∞P(Sc)
≤4∥h∥2
∞min{2m(1−p⋆)n, δ}+2 log (2 /δ)
n∥h∥2
∞2m(1−p⋆)n.
In order to bound the terms appearing in (48), we introduce the events Eδ
1,Eδ
2, andEδ
3, defined by
Eδ
1:=
max{KL(Pn,X∥PX),KL(Pn,Y∥PY)} ≤1
nlog22
δ+mlog(n+ 1)
n
Fδ
ℓ:=n
|G(0)
n(hℓ,k1jℓ)| ≤p
2 log(2 mk/δ )2(k−ℓ+ 1)∥h∥∞o
, ℓ = 1, . . . , k, j = 1, . . . , m
Eδ
2:=k\
ℓ=1Fδ
ℓ
Eδ
3:=n
|G(0)
n(h1,k)| ≤p
2 log(2 /δ)2k∥h∥∞o
.
The events are constructed such that P(Eδ
1)≥1−δ,P(Eδ
2)≥1−δ, andP(Eδ
3)≥1−δ, as we used
in the upcoming proofs of Lem. 23, Lem. 22, and Thm. 24.
Lemma 22 (Squared term bound) .LetT2be defined as in (49). For any δ >0, assuming that
n≥2[log2(2/δ) +mlog(n+ 1)]/p2
⋆, we have that
EP
T2
21S
≤2∥h∥2
∞m2k2
p2⋆[log2(2/δ) +mlog(n+ 1)]2−1{k=1}×


4n+k−1
p2⋆
n+ 2 +k+ 1
p2⋆2
δ+8
n2 r
2 log2mk
δ(k+ 1) +(k−1)(k+ 4)
p2⋆!2
.
Proof. The following computations are done under the event S. First, apply Prop. 20 to write
|T2| ≤1√nmX
j=1 
B1|G(0)
n(h1,k1jℓ)|+B2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+
mB2∥h∥∞k(k−1)[B1+B2(k+ 1)/3]. (50)
30We decompose on the event Eδ
1∩ Eδ
2. Note that by Thm. 16, we have that P(Eδ
1)≥1−δ. It
follows from Hoeffding’s inequality, the union bound, and boundedness of ∥hℓ,k1jℓ∥by Lem. 18
thatP(Eδ
2)≥1−δAs a result, P(Eδ
1∩ Eδ
2)≥1−2δ.
Bound |T2|under the event S\(Eδ
1∩Eδ
2).In this case, we apply (32) from Prop. 14 to get B1≤n
andB2≤1/p2
⋆, along with the universal bounds from Lem. 18:
1√n|G(0)
n(h1,k1jℓ)| ≤2∥h1,k∥∞≤4k∥h∥∞
1√nkX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤2kX
ℓ=2∥hℓ,k∥∞≤kX
ℓ=24(k−ℓ+ 1)∥h∥∞= 2k(k−1)∥h∥∞
so that by plugging into (50),
|T2| ≤ ∥h∥∞mk
4n+k−1
p2⋆
n+ 2 +k+ 1
3p2⋆
,
and in turn,
EPh
T2
21S\(Eδ
1∩Eδ
2)i
≤2∥h∥2
∞m2k2
4n+k−1
p2⋆
n+ 2 +k+ 1
3p2⋆2
δ. (51)
Bound |T2|under the event S ∩ Eδ
1∩ Eδ
2.In this case, we may use that n≥2[log2(2/δ) +
mlog(n+ 1)]/p2
⋆apply (33) from Prop. 14 to get
max{B1, B2} ≤2
p⋆r
1
2KL(Pn,X∥PX)≤1
p⋆√np
2 log2(2/δ) + 2mlog(n+ 1)
and the bounds based on Eδ
2which give
|G(0)
n(h1,k1jℓ)| ≤r
2 log2mk
δ2k∥h∥∞
kX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤kX
ℓ=2r
2 log2mk
δ2(k−ℓ+ 1)∥h∥∞≤r
2 log2mk
δk(k−1)∥h∥∞,
By plugging into (50),
|T2| ≤2m∥h∥∞p
2 log(2 mk/δ ) [2 log2(2/δ) + 2mlog(n+ 1)]
np⋆k(k+ 1) + (52)
m∥h∥∞[2 log2(2/δ) + 2mlog(n+ 1)]
3np2⋆k(k−1)(k+ 4) (53)
≤4mk∥h∥∞[log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
np2⋆× (54)
h
p⋆p
2 log (2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
. (55)
In turn,
EPh
T2
21S\(Eδ
1∩Eδ
2)i
≤16∥h∥2
∞m2k2[log2(2/δ) +mlog(n+ 1)]2−1{k=1}
n2p4⋆×
h
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i2
. (56)
Combining together both (56) and(51) and using that [log2(2/δ) + 2mlog(n+ 1)]≥1, we have
that
EP
T2
21S
≤2∥h∥2
∞m2k2
p2⋆[log2(2/δ) +mlog(n+ 1)]2−1{k=1}×
"
4n+k−1
p2⋆
n+ 2 +k+ 1
p2⋆2
δ+8
n2p
2 log(2 mk/δ )(k+ 1) +(k−1)(k+ 4)
p2⋆2#
,
the result as desired.
31Lemma 23 (Cross term bound) .LetT1andT2be defined as in (49). For any δ >0, assuming that
n≥2[log2(2/δ) +mlog(n+ 1)]/p2
⋆, we have that
EP[T1T21S]
≤2mk2∥h∥2
∞p
2 log(2 /δ) [log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
p2⋆×
"
p⋆p
2 log (2 mk/δ )(k+ 1) + ( k−1)(k+ 4)
n3/2+ 6
4np2
⋆+ (k−1)
n+ 2 +k+ 1
p2⋆
δ#
,
Proof. The following computations are done under the event S. First, apply Prop. 20 to write
|T1T2| ≤1√n|G(0)
n(h1,k)|"
1√nmX
j=1 
B1|G(0)
n(h1,k1jℓ)|+B2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+
mB2∥h∥∞k(k−1)[B1+B2(k+ 1)/3]#
. (57)
We decompose on the event Eδ
1∩Eδ
2∩Eδ
3. Note that by Thm. 16 and that n≥log2(2/δ)+mlog(n+1),
we have that P(Eδ
1)≥1−δ. It follows by Hoeffding’s inequality and the union bound that
P(Eδ
2)≥1−δ. Similarly, we also have by Hoeffding’s inequality that P(Eδ
3)≥1−δ. As a result,
P(Eδ
1∩ Eδ
2∩ Eδ
3)≥1−3δ.
Bound |T1T2|under the event S\(Eδ
1∩ Eδ
2∩ Eδ
3).In this case, we apply (32) from Prop. 14 to get
B1≤nandB2≤1/p2
⋆, along with the universal bounds from Lem. 18:
1√n|G(0)
n(h1,k)| ≤2∥h1,k∥∞≤4k∥h∥∞
1√n|G(0)
n(h1,k1jℓ)| ≤2∥h1,k∥∞≤4k∥h∥∞
1√nkX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤2kX
ℓ=2∥hℓ,k∥∞≤kX
ℓ=24(k−ℓ+ 1)∥h∥∞= 2k(k−1)∥h∥∞,
so that by plugging into (57),
|T1T2| ≤4k2∥h∥2
∞m
4n+k−1
p2⋆
n+ 2 +k+ 1
3p2⋆
,
and in turn,
EPh
T1T21S\(Eδ
1∩Eδ
2∩Eδ
3)i
≤12k2∥h∥2
∞m
p2⋆
4np2
⋆+ (k−1)
n+ 2 +k+ 1
3p2⋆
δ. (58)
Bound |T1T2|under the event S ∩ Eδ
1∩ Eδ
2∩ Eδ
3.In this case, we may use that n≥2[log2(2/δ) +
mlog(n+ 1)]/p2
⋆apply (33) from Prop. 14 to get
max{B1, B2} ≤2
p⋆r
1
2KL(Pn,X∥PX)≤1√n1
p⋆p
2 log2(2/δ) + 2mlog(n+ 1)
and the bounds based on Eδ
2∩ Eδ
2∩ Eδ
3which give
|G(0)
n(h1,k)| ≤p
2 log(2 /δ)2k∥h∥∞
|G(0)
n(h1,k1jℓ)| ≤p
2 log(2 mk/δ )2k∥h∥∞
kX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤kX
ℓ=2r
2 log2mk
δ2(k−ℓ+ 1)∥h∥∞≤r
2 log2mk
δk(k−1)∥h∥∞,
32By plugging into (57),
|T2| ≤m∥h∥∞p
2 log(2 mk/δ ) [2 log2(2/δ) + 2mlog(n+ 1)]
np⋆k(k+ 1) +
m∥h∥∞[2 log2(2/δ) + 2mlog(n+ 1)]
3np2⋆k(k−1)(k+ 4)
≤mk∥h∥∞[log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
np2⋆×
h
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
|T1T2| ≤2mk2∥h∥2
∞p
2 log(2 /δ) [log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
n3/2p2⋆×
h
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
,
In turn,
EPh
T2
21S\(Eδ
1∩Eδ
2∩Eδ
3)i
≤2mk2∥h∥2
∞p
2 log(2 /δ) [log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
n3/2p2⋆×
h
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
, (59)
Combining together both (59) and(58) and using that [log2(2/δ) + 2mlog(n+ 1)]≥1, we have
that
EP[T1T21S]
≤2mk2∥h∥2
∞p
2 log(2 /δ) [log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
p2⋆×
"
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)
n3/2+ 6
4np2
⋆+ (k−1)
n+ 2 +k+ 1
p2⋆
δ#
,
the result as desired.
We now combine the previous results to prove Thm. 24.
Theorem 24. For a sequence of rebalanced distributions (˜Pn(k))k≥1, there exists an absolute constant
C >0such that when n≥C[log2(2n/p⋆) +mlog (n+ 1)]/p2
⋆,
EP[(˜Pn(k)(h)−P(h))2]≤σ2
k
n+CB
n3/2, (60)
where
B=p
log (2 n/p⋆)m2k4∥h∥2
∞
p2⋆
log22n
p⋆+mlog (n+ 1)2−1{k}
log2mkn
p⋆+(k−1)2
p2⋆
.
Proof. We apply the decomposition (47), and subsequently handle the second term using bounds on
the terms in (48). Setδ=p4
⋆/n4. We apply Lem. 22 and Lem. 23 with this choice of δ, so that there
exists an absolute constants ˜C,C1, and C2such that
EP[T1T21S]≤C1∥h∥2
∞m2k3p
log(2n/p⋆)
n3/2p2⋆[log2(2n/p⋆) +mlog(n+ 1)]1−1{k=1}/2×

log2mnk
p⋆+k−1
p2⋆
EP
T2
21S
≤C2∥h∥2
∞m2k4
n2p2⋆[log2(2n/p⋆) +mlog(n+ 1)]2−1{k=1}×

log2mnk
p⋆+(k−1)2
p2⋆
,
33when n≥˜C[log2(2n/p⋆) +mlog (n+ 1)]/p2
⋆. This then implies that there is an absolute constant
C3such that
EP
˜Pn(k)(h)−P(h)2
≤EPh
(P(0)
n(h)−P(h))21Sci
+σ2
k
n+
C3∥h∥2
∞m2k4p
log(2n/p⋆)
n3/2p2⋆
log22n
p⋆+mlog(n+ 1)2−1{k=1}
log2mnk
p⋆+(k−1)2
p2⋆
.
Next, we apply Prop. 21 with the same choice of δ. Because 2[log2(2/δ)+mlog(n+1)]≥log(m/δ)
and−log(1−p⋆)≥p⋆≥p2
⋆, we have that n≥log(δ/m)/log(1−p⋆), which implies that
m(1−p⋆)n≤δ. Combining with the display above, we have that there exists an absolute constant
C >0such that
EP
˜Pn(k)(h)−P(h)2
≤σ2
k
n+C∥h∥2
∞m2k4p
log(2n/p⋆)
n3/2p2⋆
×[log2(2/δ) +mlog(n+ 1)]2−1{k=1}
log2mnk
p⋆+(k−1)2
p2⋆
,
which is the claimed result.
While not shown in the main text, similar techniques to those used above can also control the bias of
˜Pn(k)(h)as in Thm. 25. Interestingly, this bias is of order O(n−2)which confirms the intuition that
even thought ˜Pn(k)(h)may be biased, the dominant term is the variance.
Theorem 25. For a sequence of rebalanced distributions (P(k))k≥1, there exists an absolute constant
C >0such that when n≥C[log2(2n/p⋆) +mlog (n+ 1)]/p2
⋆,
EP[˜Pn(k)(h)−P(h)]2
≤CB
n2, (61)
where Bis as defined in Thm. 24.
Proof. First, apply the decomposition (47) so that
EPh
˜Pn(k)(h)−P(h)i≤ |EP[(Pn(h)−P(h))1Sc]|+|EP[(P(k)
n(h)−P(h))1S]|.
By using the argument of Prop. 21, we have that
|EP[Pn(h)−P(h)]1Sc| ≤2∥h∥∞min{2m(1−p⋆)n, δ}+r
2 log(2 /δ)
n∥h∥∞2m(1−p⋆)n.
Then, by the recursion formula Equation (37), we have that
√n|EP[(P(k)
n(h)−P(h))1S]|
=|EP[G(k)
n(h)1S]|=EP"
(1−1Sc)G(0)
n(C1. . .Ckh) +√n1SkX
ℓ=1V(ℓ−1)
n(Cℓ. . .Ckh)#.
Because G(0)
n(C1. . .Ckh)has zero mean, it follows that
√n|EP[(P(k)
n(h)−P(h))1S]| ≤ |EP[1ScG(0)
n(C1. . .Ckh)]|+√n|EP[1ST2]|
We have by Hoeffding’s inequality that P(Eδ
3)≥1−δ, and that by Lem. 18 that G(0)
n(C1. . .Ckh)≤
4k√n∥h∥∞universally. As a result, applying Prop. 21 once again,
|EP[1ScG(0)
n(C1. . .Ckh)]|
≤EPh
1Sc1Eδ
3G(0)
n(C1. . .Ckh)i+EPh
1Sc1Eδ
3G(0)
n(C1. . .Ckh)i
≤4k√n∥h∥∞min{2m(1−p⋆)n, δ}+p
2 log(2 /δ)2k∥h∥∞2m(1−p⋆)n.
34Using a similar argument to Lem. 22, we have that under S\(Eδ
1∩Eδ
2)(which occurs with probability
no more than 2δ),
|T2| ≤ ∥h∥∞mk
4n+k−1
p2⋆
n+ 2 +k+ 1
3p2⋆
,
and that under S ∩ Eδ
1∩ Eδ
2(which occurs with probability at least 1−2δ),
|T2| ≤4mk∥h∥∞[log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
np2⋆h
p⋆p
2 log(2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
.
Applying the decomposition |EP[1ST2]| ≤EPh
1S\(Eδ
1∩Eδ
2)T2i+EPh
1S∩Eδ
1∩Eδ
2T2iand setting
δ=p2
⋆
n2achieves the desired result.
D.5 Misspecified Marginal Distributions
We now adapt the main results to cases in which the marginal distributions (PX, PY)are misspecified,
in that the user is provided marginal distributions (ˆPX,ϵ,ˆPY,ϵ)which satisfy the following structure.
Assumption 1. There exist fixed probability mass functions ˆPXandˆPYfor some ϵ∈[0,1),
ˆPX,ϵ= (1−ϵ)PX+ϵˆPXandˆPY,ϵ= (1−ϵ)PY+ϵˆPY.
We also have the existence of the positive quantity
ˆp⋆:= min {min
xˆPX(x),min
yˆPY(y)}>0.
Given the existence of ˆp⋆>0, we may also define
ˆp⋆,ϵ= min {min
xˆPX,ϵ(x),min
yˆPY,ϵ(y)} ≥ϵˆp⋆+ (1−ϵ)p⋆>0.
To be precise, the iterations of balancing follow ˆP(0)
n=Pnand
ˆP(k)
n(x, y) :=

ˆPX,ϵ(x)
ˆP(k−1)
n,X(x)·ˆP(k−1)
n(x, y)kodd
ˆPY,ϵ(y)
ˆP(k−1)
n,Y(y)·ˆP(k−1)
n(x, y)keven. (62)
We start by deriving a result similar to Prop. 15. Since ϵ <1, the (possibly misspecified) target
marginals ˆPX,ϵ(x)>0andˆPY,ϵ(y)>0for all x∈ X andy∈ Y. Define
ˆV(k−1)
n(h) :=

P
x,y
ˆPX,ϵ
ˆP(k−1)
n,X(x)−1
h(x, y)ˆP(k−1)
n(x, y)kodd
P
x,y
ˆPY,ϵ
ˆP(k−1)
n,Y(y)−1
h(x, y)ˆP(k−1)
n(x, y)keven(63)
and
ˆG(k)
n(h) :=√n
ˆP(k)
n(h)−P(h)
.
The format of this section will be to derive results analogous to the building blocks of the previous
section. From that point, the computations from Appx. D.4 will achieve the desired result. For the
sake of comparison to Thm. 1 we consider error terms containing ϵonly by their dependence on
(ϵ, k, n, ˆp⋆,ϵ).
35D.5.1 Intermediate Results
Proposition 26. Let(ˆP(k)
n)k≥1be a sequence computed according to (62). Define
c2= maxn
χ2(ˆPX∥PX), χ2(ˆPY∥PY)o
.
These iterations are well-defined under the event S, and for G(k)
ndefined in (43), it holds that
ˆG(k)
n(h) =ˆG(k−1)
n(h) +√nˆV(k−1)
n(h) (64)
and
ˆG(k)
n(h) =ˆG(k−1)
n(Ckh) +√nˆV(k−1)
n(Ckh) +(√n[ˆPX,ϵ−PX](µXh)ifkodd√n[ˆPY,ϵ−PY](µYh)ifkeven. (65)
Furthermore,
ˆG(k)
n(h)≤ˆG(k−1)
n(Ckh)+√nˆV(k−1)
n(Ckh)+c∥h∥L2(P)√nϵ
=ˆG(k−1)
n(Ckh)+√nˆV(k−1)
n(Ckh)+O √nϵ
. (66)
Proof. The proof that ˆP(k−1)
n,X(x)>0andˆP(k−1)
n,Y(y)>0for all x∈ X andy∈ Y follows the exact
same steps as in the proof of Prop. 15. We take this for granted and establish the recursion.
Consider the following steps in the case that kis odd:
ˆP(k)
n(h) =X
x,yh(x, y)ˆP(k)
n(x, y) =X
x,yh(x, y)ˆPX,ϵ
ˆP(k−1)
n,X(x)ˆP(k−1)
n(x, y)
=X
x,y1·h(x, y)ˆP(k−1)
n(x, y) +X
x,y"ˆPX,ϵ
ˆP(k−1)
n,X(x)−1#
·h(x, y)ˆP(k−1)
n(x, y)
=ˆP(k−1)
n(h) +ˆV(k−1)
n(h).
Subtracting P(h)on both sides, we have that
[ˆP(k)
n−P](h) = [ ˆP(k−1)
n−P](h) +ˆV(k−1)
n(h). (67)
This proves the uncentered recursion formula given in (64). We then show the centered version.
[ˆP(k)
n−P](h)
= [ˆP(k)
n−P](CXh) + [ˆP(k)
n−P](µXh)
= [ˆP(k)
n−P](CXh) + [ˆPX,ϵ−PX](µXh)
= [ˆP(k−1)
n−P](CXh) +ˆV(k−1)
n(CXh) + [ˆPX,ϵ−PX](µXh).
Next, we bound the additional error term. By the Cauchy-Schwarz inequality,
[ˆPX,ϵ−PX](µXh)≤ˆPX,ϵ
PX−1
L2(PX)· ∥µXh∥L2(PX)
=q
χ2(ˆPX,ϵ∥PX)· ∥µXh∥L2(PX)
≤q
χ2(ˆPX,ϵ∥PX)· ∥h∥L2(P),
asµXis an orthogonal projection in L2(P). Using convexity of f-divergences, we have that
χ2(ˆPX,ϵ∥PX)≤ϵχ2(ˆPX∥PX) + (1 −ϵ)χ2(PX∥PX) =ϵχ2(ˆPX∥PX).
This achieves the desired result.
Using similar ideas, we then prove an analog of Lem. 19.
36Lemma 27. Forkodd, it holds that
√nˆV(k−1)
n(CXh) =mX
j=1 ˆPX,ϵ
ˆP(k−1)
n,X(xj)−1!
ˆG(k−1)
n(CXh1jk),
whereas for keven, it holds that
√nˆV(k−1)
n(CYh) =mX
j=1 ˆPY,ϵ
ˆP(k−1)
n,Y(xj)−1!
ˆG(k−1)
n(CYh1jk).
Proof. We give the proof for kodd. We claim that we need only show that P(CXh1jk) = 0 . This
would show that
√nˆV(k−1)
n(CXh) =X
x,y ˆPX,ϵ
ˆP(k−1)
n,X(x)−1!
[CXh](x, y)ˆP(k−1)
n(x, y)
=√nmX
j=1X
x,y ˆPX,ϵ
ˆP(k−1)
n,X(x)−1!
[CXh1jk](x, y)ˆP(k−1)
n(x, y)
=√nmX
j=1X
x,y ˆPX,ϵ
ˆP(k−1)
n,X(xj)−1!
[CXh1jk](x, y)ˆP(k−1)
n(x, y)
=mX
j=1 ˆPX,ϵ
ˆP(k−1)
n,X(xj)−1!
√nX
x,y[CXh1jk](x, y)ˆP(k−1)
n(x, y)
=mX
j=1 ˆPX,ϵ
ˆP(k−1)
n,X(xj)−1!
ˆG(k−1)
n(CXh1jk),
where P(CXh1jk) = 0 is employed in the last step. Now the result follows from (65) in Prop. 26
and the definition of ˆG(k)
n(h). To prove the claim, as in Lem. 19, write
E[CXh1jk|X] (x) =E[CXh|X] (xj)ifx=xj
0 ifx̸=xj.
ButE[CXh|X] (xj) = 0 by definition of CX. Taking an expectation over PXgives that
P(CXh1jk) = 0 , which implies the desired result. The proof for keven follows symmetrically.
For the remainder of the argument, we see that (66) can be unrolled so that
ˆG(k)
n(h)≤ |G(0)
n(C1. . .Ckh)|| {z }
first-order term+√nkX
ℓ=1ˆV(ℓ−1)
n(Cℓ. . .Ckh)
| {z }
higher-order term+O(k√nϵ)|{z}
misspecification, (68)
where we use that G(0)
n=ˆG(0)
n.
Next, we need to boundˆV(ℓ−1)
n(Cℓ. . .Ckh), in particular accounting for the marginal violation term.
We follow similar steps as in the analysis of the higher-order term in Appx. D.3.
Proposition 28. Assume that Pn,X(x)>0for all x∈ X. It holds that
max
x∈XˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1≤max{n−1,1} ifk= 1
max{1/ˆp2
⋆,ϵ−1,1}ifk >1.(69)
In addition, we have that
max
x∈XˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1≤

O
nq
log1
1−ϵ
+nq
1
2KL(Pn,X∥PX) ifk= 1
O
1
ˆp2⋆,ϵq
log1
1−ϵ
+1
ˆp2⋆,ϵq
1
2KL(Pn,X∥PX)ifk >1,
37Moreover, when KL(Pn,X∥PX)≤ˆp2
⋆,ϵ
8andϵ≤1−exp
−ˆp2
⋆,ϵ
8
, we have
max
x∈XˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1≤O
1
ˆp⋆,ϵq
log1
1−ϵ
+2
ˆp⋆,ϵr
1
2KL(Pn,X∥PX). (70)
Proof. First, observe that ˆP(0)
n,X(x) =P(0)
n,X(x)≥1/nunder the event S. For k >1such that kis
odd, we have that for x∈ X,
ˆP(k−1)
n,X(x) =X
y∈YˆP(k−1)
n(x, y) =X
y∈YˆPY,ϵ(y)
ˆP(k−2)
n,Y(y)ˆP(k−2)
n(x, y)
≥ˆp⋆,ϵX
y∈YˆP(k−2)
n(x, y) = ˆp⋆,ϵˆP(k−2)
n,X(x) = ˆp⋆,ϵˆPX,ϵ(x)≥ˆp2
⋆,ϵ.
The result for keven can be proven similarly. We now prove the inequalities listed in the statement
using on the lower bounds above.
Proving the first inequality. For any x∈ X,ˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1= max(ˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1,1−ˆPX,ϵ(x)
ˆP(k−1)
n,X(x))
≤max{n−1,1} ifk= 1
max{1/ˆp2
⋆,ϵ−1,1}ifk >1,
which is the desired result.
Proving the second and third inequalities. Consider an odd k≥1. By the definition of total
variation distance, it holds that
max
x∈XˆPX,ϵ(x)−ˆP(k−1)
n,X(x)≤TV(ˆP(k−1)
n,X,ˆPX,ϵ).
According to Pinsker’s inequality, we have that TV(ˆP(k−1)
n,X,ˆPX,ϵ)≤q
1
2KL(ˆP(k−1)
n,X∥ˆPX,ϵ), and so
we have that
max
x∈XˆPX,ϵ(x)−ˆP(k−1)
n,X(x)≤r
1
2KL(ˆP(k−1)
n,X∥ˆPX,ϵ)≤r
1
2KL(P(0)
n,X∥ˆPX,ϵ),
where the last inequality follows by the monotonicity of Sinkhorn iterations given in Prop. 13. Notice
that the remaining term is KL(P(0)
n,X∥ˆPX,ϵ) = KL( Pn,X∥ˆPX,ϵ), which may not decay to zero as
n→ ∞ . Because ϵ <1, write
KL(Pn,X∥ˆPX,ϵ) =X
x∈XPn,X(x) logPn,X(x)
(1−ϵ)PX(x) +ϵˆPX(x)
≤X
x∈XPn,X(x) logPn,X(x)
(1−ϵ)PX(x)
= KL( Pn,X∥PX) + log1
1−ϵ
=⇒r
1
2KL(Pn,X∥ˆPX,ϵ)≤r
1
2KL(Pn,X∥PX) +r
1
2log1
1−ϵ.
We can then apply the lower bounds
max
x∈XˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1≤

nq
1
2KL(Pn,X∥PX) +q
1
2log1
1−ϵ
ifk= 1
1
ˆp2⋆,ϵq
1
2KL(Pn,X∥PX) +q
1
2log1
1−ϵ
ifk >1.
Finally, combining the arguments above, we have that
max
x∈XˆPX,ϵ(x)−ˆP(k−1)
n,X(x)≤r
1
2KL(Pn,X∥PX) +r
1
2log1
1−ϵ
≤ˆp⋆,ϵ
4+ˆp⋆,ϵ
4=ˆp⋆,ϵ
2,
38where the last step invoked the assumption that
KL(Pn,X∥PX)≤ˆp2
⋆,ϵ
8and ϵ≤1−exp
−ˆp2
⋆,ϵ
8
.
This means that
min
x∈XˆP(k−1)
n,X(x)≥min
x∈XˆPX,ϵ(x)−max
x∈XˆP(k−1)
n,X(x)−ˆPX,ϵ(x)≥ˆp⋆,ϵ
2.
Hence,
max
x∈XˆPX,ϵ(x)
ˆP(k−1)
n,X(x)−1≤max x∈XˆP(k−1)
n,X(x)−ˆPX,ϵ(x)
minx∈XˆP(k−1)
n,X(x)≤2
ˆp⋆,ϵr
1
2KL(Pn,X∥ˆPX,ϵ).
Now, for keven, set k= 2tfort≥0. We have that
max
y∈YˆP(2t−1)
n,Y (y)−ˆPY,ϵ(y)≤TV(ˆP(2t−1)
n,Y ,ˆPY,ϵ)≤r
1
2KL(ˆPY,ϵ∥ˆP(2t−1)
n,Y ).
Invoke Prop. 13 once again to achieve
r
1
2KL(ˆPY,ϵ∥ˆP(2t−1)
n,Y )≤r
1
2KL(Pn,X∥ˆPX,ϵ)≤r
1
2KL(Pn,X∥PX) +r
1
2log1
1−ϵ,
which completes the proof.
Proceeding with similar steps, define the quantities
ˆB1:=ˆM1and ˆB2:= max
2≤ℓ≤kˆMℓfor ˆMℓ:=

max x∈XˆPX,ϵ(x)
ˆP(ℓ−1)
n,X(x)−1ℓodd
max y∈YˆPY,ϵ(y)
ˆP(ℓ−1)
n,Y(y)−1ℓeven.
We must now establish an analog of Prop. 20.
Proposition 29. For any k≥1, the following holds under the event S:
√nkX
ℓ=1ˆV(ℓ−1)
n(Cℓ. . .Ckh)≤mX
j=1 
ˆB1|G(0)
n(h1,k1jℓ)|+ˆB2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+mˆB2∥h∥∞√nk(k−1)[ˆB1+ˆB2(k+ 1)/3].
Proof. This proof largely follows the argument of Prop. 20, while accounting for the misspecified
marginal error. Using again the notation hℓ,k:=Cℓ. . .Ckh, it follows from Lem. 27 that, for odd ℓ,
√nˆV(ℓ−1)
n(hℓ,k) =mX
j=1"ˆPX,ϵ
ˆP(ℓ−1)
n,X(xj)−1#
ˆG(ℓ−1)
n(hℓ,k1jℓ)≤ˆMℓmX
j=1ˆG(ℓ−1)
n(hℓ,k1jℓ).
The bound above holds for ℓeven as well. Then, using (64) from Prop. 26 along with the triangle
inequality, we have that for ℓ≥2,[ˆP(ℓ−1)
n−P](hℓ,k1jℓ)≤ˆP(ℓ−2)
n−P](hℓ,k1jℓ)+ˆV(ℓ−2)
n(hℓ,k1jℓ)
which implies thatˆG(ℓ−1)
n(hℓ,k1jℓ) (71)
≤ˆG(ℓ−2)
n(hℓ,k1jℓ)+√nˆV(ℓ−2)
n(hℓ,k1jℓ)
≤ˆG(0)
n(hℓ,k1jℓ)+√nˆV(0)
n(hℓ,k1jℓ)+. . .+√nˆV(ℓ−2)
n(hℓ,k1jℓ)
≤ˆG(0)
n(hℓ,k1jℓ)+ˆM1√nˆP(0)
n(|hℓ,k|1jℓ) +. . .+ˆMℓ√nˆP(ℓ−2)
n(|hℓ,k|1jℓ)
≤ˆG(0)
n(hℓ,k1jℓ)+ 2∥h∥∞√nh
ˆB1+ˆB2(ℓ−1)i
(k−ℓ+ 1), (72)
39by Lem. 18 and ˆM1≤ˆB1and ˆMℓ≤ˆB2forℓ≥2. The bound above holds trivially for ℓ= 1.
Summing these bounds over ℓandj, we have that
√nkX
ℓ=1ˆV(ℓ−1)
n(hℓ,k)
≤ˆM1mX
j=1|G(0)
n(h1,k1jℓ)|+kX
ℓ=2ˆMℓmX
j=1ˆG(ℓ−1)
n(hℓ,k1jℓ)
≤ˆB1mX
j=1|G(0)
n(h1,k1jℓ)|+ˆB2kX
ℓ=2mX
j=1ˆG(ℓ−1)
n(hℓ,k1jℓ)
≤ˆB1mX
j=1|G(0)
n(h1,k1jℓ)|
+ˆB2kX
ℓ=2mX
j=1ˆG(0)
n(hℓ,k1jℓ)+ 2∥h∥∞√nh
ˆB1+ˆB2(ℓ−1)i
(k−ℓ+ 1)
apply (72)
=mX
j=1 
ˆB1|G(0)
n(h1,k1jℓ)|+ˆB2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+ 2mˆB2∥h∥∞√nkX
ℓ=2h
ˆB1+ˆB2(ℓ−1)i
(k−ℓ+ 1),
because |X|=m. We sum up the last term:
kX
ℓ=2h
ˆB1+ˆB2(ℓ−1)i
(k−ℓ+ 1) = ˆB1k−1X
ℓ=1(k−ℓ) +ˆB2k−1X
ℓ=1ℓ(k−ℓ)
=k(k−1)
2h
ˆB1+ˆB2(k+ 1)/3i
,
which completes the proof.
D.5.2 Mean Squared Error Bound
Ultimately, we wish to construct an upper bound for
EP
ˆP(k)
n(h)−P(h)2
1S
+EPh
(Pn(h)−P(h))21Sci
, (73)
as the method returns Pn(h)whenSis not satisfied. The first term will be controlled by intermediate
tools developed above. The second term that includes Scis no different from the one analyzed in
Prop. 21. We handle the second term first. Recall from Prop. 21 that for any δ∈(0,1),
EPh
(Pn(h)−P(h))21Sci
≤
4∥h∥2
∞min{2m(1−p⋆)n, δ}+2 log(2 /δ)
n∥h∥2
∞2m(1−p⋆)n. (74)
Repeat the argument from the proof of Thm. 24: because 2[log2(2/δ) +mlog(n+ 1)]≥log(m/δ)
and−log(1−p⋆)≥p⋆≥p2
⋆, we have that
n≥2[log2(2/δ) +mlog (n+ 1)]/p2
⋆=⇒n≥log(δ/m)/log(1−p⋆). (75)
This in turn implies that m(1−p⋆)n≤δ, and gives as a condition on the sample size n. Further in
the analysis, we will set δ= (ˆp⋆,ϵ/n)4, so right-hand side of (74) can then be upper bounded further,
resulting in
EPh
(Pn(h)−P(h))21Sci
≤4∥h∥2
∞δ
2 +log(2/δ)
n
=˜Oˆp4
⋆,ϵ
n4
,
40a higher-order term compared to other components of the bound.
Next, we must control the left-hand side of (73). We perform the decomposition based on (68):
EP
ˆP(k)
n(h)−P(h)2
1S
≤EP
T2
11S
+ 2EPhT1ˆT21Si
+EPh
ˆT2
21Si
(76)
+O(k√ϵ)·EPh
|T1|+|ˆT2|
1Si
+O(k2ϵ) (77)
for
T1:= [Pn−P](C1. . .Ckh)andˆT2:=kX
ℓ=1ˆV(ℓ−1)
n(Cℓ. . .Ckh). (78)
Recall the events Eδ
1andEδ
2andEδ
3from Appx. D.4. To perform this computation efficiently, we will
split the bounds on each term into two components. In particular, we will show that
• Under the event S ∩ Eδ
1∩ Eδ
2:ˆT2≤ T2+E2,
• Under the event S\(Eδ
1∩ Eδ
2) :ˆT2≤ Tc
2+Ec
2,
• Under the event S ∩ Eδ
3:|T1| ≤ T 1,
• Under the event S\Eδ
3:|T1| ≤ Tc
1,
where any term denoted with “ E” will represent all error terms that include ϵand will be written
in big- Onotation. There are no errors for the bounds on T1, as this term does not depend on the
misspecified marginals. The idea is that for the “ T2” terms we may reuse the bounds derived in
Appx. D.4 by simply replacing p⋆with ˆp⋆,ϵ. This is due to the fact that the dependence of the
analogous terms from Appx. D.4 depend on p⋆only through Prop. 14; similarly, the corresponding
terms in this section depend on ˆp⋆,ϵthrough Prop. 28. We return to the terms in (76) and (77).
Decomposing on Eδ
3will result in a bound of the form
O(k√ϵ)·EP[|T1|1S]≤O(k√ϵ)·(δTc
1+T1).
Decomposing on Eδ
1∩ Eδ
2will result in a bounds of the form
EPh
ˆT2
21Si
≤2δ(Tc
2)2+T2
2+˜O 
δ 
(Ec
2)2+Ec
2Tc
2
+ 
E2
2+E2T2
O(k√ϵ)·EPh
|ˆT2|1Si
≤O(k√ϵ)·(δ(Tc
2+Ec
2) +T2+E2).
Finally, decomposing on Eδ
1∩ Eδ
2∩ Eδ
3will result in a bound of the form
EPhT1ˆT21Si
≤3δTc
1Tc
2+T1T2+˜O(δTc
1Ec
2+T1E2).
The leading terms 2δ(Tc
2)2+T2
2and3δTc
1Tc
2+T1T2from both bounds should have the exact
same form as the terms in Lem. 22 and Lem. 23, with p⋆replaced by ˆp⋆,ϵ, thus retaining the same
dependence on (n, k). By setting δ= ˆp4
⋆,ϵ/n4, we will achieve a similar result to Thm. 24, i.e., that
EP
ˆP(k)
n(h)−P(h)2
1S
≤σ2
k
n+˜Ok6
n3/2
+˜O
(ˆp⋆,ϵ/n)4(Ec
2(Ec
2+Tc
2)) +E2(E2+T2) + (ˆp⋆,ϵ/n)4Tc
1Ec
2+T1E2
. (79)
+˜O 
k√ϵ 
(ˆp⋆,ϵ/n)4Tc
1+T1+ (ˆp⋆,ϵ/n)4(Tc
2+Ec
2) +T2+E2
+k2ϵ
. (80)
It remains to quantify the ˜Oterms by computing the order of the 6 constants (T2, E2,Tc
2, Ec
2,T1,Tc
1).
We follow similar steps to Lem. 22 and Lem. 23 to achieve this.
41Lemma 30. Forδ= (ˆp⋆,ϵ/n)4, assume that n≥8[log2(2/δ) +mlog(n+ 1)] /ˆp2
⋆,ϵandϵ≤
1−exp
−ˆp2
⋆,ϵ
8
. Then, it holds that
Tc
2=˜O
k2
ˆp2⋆,ϵ
n+k
ˆp2⋆,ϵ
, Ec
2= 0
T2=˜Ok3
nˆp2⋆,ϵ
, E 2=˜O
k3
ˆp2⋆,ϵq
1
nlog1
1−ϵ+ log1
1−ϵ
.
Proof. The following computations are done under the event S. First, apply Prop. 29 to write
√nˆT2≤mX
j=1 
ˆB1|G(0)
n(h1,k1jℓ)|+ˆB2kX
ℓ=2|G(0)
n(hℓ,k1jℓ)|!
+mˆB2∥h∥∞k(k−1)[ˆB1+ˆB2(k+ 1)/3]. (81)
We decompose on the event Eδ
1∩ Eδ
2.
Bound |T2|under the event S\(Eδ
1∩Eδ
2).In this case, we apply (69) from Prop. 28 to get ˆB1≤n
andˆB2≤1/ˆp2
⋆,ϵ, along with the universal bounds from Lem. 18:
1√n|G(0)
n(h1,k1jℓ)| ≤2∥h1,k∥∞≤4k∥h∥∞
1√nkX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤2kX
ℓ=2∥hℓ,k∥∞≤kX
ℓ=24(k−ℓ+ 1)∥h∥∞= 2k(k−1)∥h∥∞
so that by plugging into (81),
ˆT2≤ ∥h∥∞mk
4n+k−1
ˆp2⋆,ϵ
n+ 2 +k+ 1
3ˆp2⋆,ϵ
| {z }
Tc
2+ 0|{z}
Ec
2.
Bound |T2|under the event S ∩ Eδ
1∩ Eδ
2.In this case, we may use that n≥8/ˆp2
⋆,ϵ(because
[log2(2/δ) +mlog(n+ 1)]≥1forδ∈(0,1)) and apply (70) from Prop. 28 to get
maxn
ˆB1,ˆB2o
≤O
1
ˆp⋆,ϵq
log1
1−ϵ
+2
ˆp⋆,ϵr
2 log2(2/δ) + 2mlog(n+ 1)
2n
The bounds based on Eδ
2give
|G(0)
n(h1,k1jℓ)| ≤r
2 log2mk
δ2k∥h∥∞
kX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤kX
ℓ=2r
2 log2mk
δ2(k−ℓ+ 1)∥h∥∞≤r
2 log2mk
δk(k−1)∥h∥∞.
By plugging into (81), we can reuse the steps in the bound from (55) (for all terms without ϵ) to write
ˆT2≤4mk∥h∥∞[log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
nˆp2⋆,ϵ×
h
ˆp⋆,ϵp
2 log (2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
+E2,
so that
T2=4mk∥h∥∞[log2(2/δ) + 2mlog(n+ 1)]1−1{k=1}/2
nˆp2⋆,ϵ
×h
ˆp⋆,ϵp
2 log (2 mk/δ )(k+ 1) + ( k−1)(k+ 4)i
.
42We compute E2by using that
maxn
ˆB1,ˆB2o
≤O
1
ˆp⋆,ϵq
log1
1−ϵ
+˜O
1
ˆp⋆,ϵ√n
|G(0)
n(h1,k1jℓ)| ≤˜O(k)
kX
ℓ=2|G(0)
n(hℓ,k1jℓ)| ≤˜O 
k2
,
which gives
E2=˜O
k3
ˆp2⋆,ϵq
1
nlog1
1−ϵ+ log1
1−ϵ
.
We now make the corresponding argument for the term T1.
Lemma 31. Forδ= (ˆp⋆,ϵ/n)4, it holds that
Tc
1=˜O(k),T1=˜Ok√n
.
Proof. The following computations are done under the event S.
Bound |T1|under the event S\Eδ
3.Here we simply apply a universal bound on the empirical
process term:
1√n|G(0)
n(h1,k)| ≤2∥h1,k∥∞≤4k∥h∥∞,
so that Tc
1= 4k∥h∥∞
Bound |T1|under the event S ∩ Eδ
3.Now, we may use the definition of the event Eδ
3to achieve
1√n|G(0)
n(h1,k)| ≤r
2 log(2 /δ)
n2k∥h∥∞=T1.
Knowing that Ec
2= 0, we simplify (79) and (79) to read
˜O
E2(E2+T2+T1)
˜O 
k√ϵ 
(ˆp⋆,ϵ/n)4Tc
1+T1+ (ˆp⋆,ϵ/n)4Tc
2+T2+E2
+k2ϵ
.
We now combine the bounds from the previous two lemmas to compute (79) and(80) to state the
main result.
Theorem 32. Let Asm. 1 be true with error ϵ∈[0,1). For a sequence of rebalanced distribu-
tions (ˆP(k)
n)k≥1, there exists an absolute constant C > 0such that when n≥C[log2(2n/ˆp⋆,ϵ) +
mlog (n+ 1)]/min{p⋆,ˆp⋆,ϵ}2, we have that
EP
ˆP(k)
n(h)−P(h)2
1S
+EPh
(Pn(h)−P(h))21Sci
≤σ2
k
n+˜Ok6
n3/2
+˜O 
k4
ˆp2⋆,ϵ r
1
nlog1
1−ϵ+ log1
1−ϵ!"
k2
ˆp2⋆,ϵ r
1
nlog1
1−ϵ+ log1
1−ϵ+1
n!
+1√n#!
+˜O 
k2"
√ϵ 
ˆp4
⋆,ϵ
n4+1√n+ˆp2
⋆,ϵk
n4
n+k2
ˆp2⋆,ϵ
+k2
ˆp2⋆,ϵ"
1
n+r
1
nlog1
1−ϵ+ log1
1−ϵ#!
+ϵ#!
.
43E Experimental Details
We provide the full experimental details of the experimental results from Sec. 4. We report additional
evaluations on downstream tasks with linear probing and zero-shot retrieval. Finally, we give
illustrations of the sensitivity to misspecified marginals, and of the convergence to the given marginals.
E.1 Datasets
Pre-Training Data. The pre-training data was taken from the public ImageNet-Captions dataset
[Fang et al., 2013]. We subset the dataset by selecting the 250 classes that were most frequent in the
dataset, resulting in 174,594 images and associated Flickr captions. The exact images used and their
associated captions are given in the code supplement.
Evaluation Data. We perform zero-shot classification (as described in Sec. 4), zero-shot retrieval,
and linear probing with various image classification and image-caption datasets. We used the default
class captions (for classification) and default linear probing parameters from the CLIP Benchmark
repo. The datasets (test splits) used were:
•CIFAR-10: 10,000 colored natural images labeled with one of 10 classes.
•CIFAR-100: 10,000 colored natural images labeled with one of 100 classes.
•STL-10: 80,000 colored natural images labeled with one of 10 classes.
•MS-COCO: 41,000 colored natural images with associated captions.
•Flickr8k: 8,000 colored natural images with associated captions.
•Rendered SST2: 1,821 images of typed natural language with sentiment label (2 classes).
•VOC2007: 4,952 colored natural images labeled with one of 20 classes.
•FGVC Aircraft: 34,000 colored natural images labeled with one of 102 classes.
Evaluation scripts using the various embedding models (described below) are provided.
E.2 Model Specification and Hyperparameters
Architecture and Implementation. The models considered CLIP models [Radford et al., 2021], and
are specified by pairs of encoders (fθ, gθ), representing images and text, respectively. The encoders
decompose into fθ=fhead
θ◦fbase
θ(similarly for gθ) where fbase
θdenotes a base image encoder and
fhead
θdenotes a trainable head model. The head models are feed-forward networks with two hidden
layers, 256 hidden units, and 128-dimensional output representations. Their input dimensions may be
512 or 768, depending on whether a CLIP model or BERT/GPT-2 model is used as the base. For the
image base/foundation models, we use the open-source OpenCLIP implementation of the ViT-B/32
model with the laion2b s34b b79k model tag. For the text encoder, we use the encoder of
the variant of the ViT-B/32 with tag datacomp xls13b b90k . For the other text encoders the
Huggingface implementations of GPT-2 and BERT were used.
Optimizer. For optimization, models were trained with stochastic gradient descent (SGD) with the
learning rate tuned along the grid
1−3,3−3,1−2,3−2,1−1	
and a fixed weight decay parameter of
0.01. Momentum-variants such as Adam [Kingma and Ba, 2015] were not used to isolate the effect
of varying losses as described in Sec. 4.
E.3 Compute Environment
Experiments were run on a CPU/GPU workstation with 12 virtual cores, 126G of memory, and four
NVIDIA TITAN Xp GPUs with 12G memory each. The code was written in Python 3 and we use
PyTorch for automatic differentiation. The OpenCLIP and CLIP Benchmark repositories were used
for zero-shot evaluation.
44E.4 CLIP and Multi-CLIP
We considered in the contrastive learning example from Sec. 2 – see (6)in particular – a variant of
the CLIP objective in which either zero, or one, or more than one balancing iterations are performed
(see (6)), via optimizing
L(k)
n=−1
2nX
i=1[logQ(k)
n(Xi, Yi) + log R(k)
n(Xi, Yi)]. (82)
This contrasts the single-iteration variant L(1)
nwhich in fact reduces to the original CLIP loss. Because
these iterations are applied in the objective, backpropagation occurs through each iteration.
In Fig. 3, we plot the zero-shot classification performance (in terms of average per-class recall) of the
variants trained on L(0)
n(the normalized initial measure, No Balancing ),L(1)
n(the original CLIP loss,
CLIP balancing ), and L(2)
n(the two-iteration CLIP loss, Multi-CLIP balancing ). We also vary the
quality of the text encoder fθT, observing an overall accuracy trend of GPT-2 ≺BERT ≺CLIP across
variants, which is to be expected given the base representation quality of each model. Interestingly,
there is an improvement stemming from performing multiple balancing iterations across choices of
the text embedding, the batch size m, and the evaluation dataset.
E.5 Metadata Curation
We considered in the metadata curation example from Sec. 2 how to use balancing to adjust the entire
pre-training set, in the spirit of Xu et al. [2024]. The target marginal PYis selected by choosing a
threshold for which frequent keywords have their probability mass truncated, and the probability
measure is normalized to sum to one. In Fig. 4, we show the observed marginal Pn,Yand the target
marginal PYsorted in increasing order (left). The original marginal on Yhas approximately 5orders
of magnitude of difference between the most and least probable keyword. After balancing, the target
marginal has less than 2orders of difference. To see how this affects downstream performance,
we plot the zero-shot classification accuracy over training iterations in Fig. 4 (right) when using
the original dataset (orange) and using the metadata-balanced dataset (blue). We observe moderate
improvement especially in the small batch regime ( m= 512 ) when curating the dataset.
E.6 Additional Experiments
In this section, we provide 1) a synthetic data example that helps elucidate the role of the spectral
decomposition introduced in Sec. 3, and 2) additional evaluations on downstream tasks such as
zero-shot retrieval and linear probing. For the latter, we maintain the experimental settings as used
in the zero-shot classification example from Sec. 4 (Fig. 3). That is, we train variants of CLIP
models (see Sec. 2) on the ImageNet-Captions dataset [Fang et al., 2013]. As before, we use a fixed
image/text encoder as a base vector representation and compose it with a trainable feed-forward
neural network, i.e., fθ=fhead
θ◦fbase, forθ=θI(images) or θ=θT(text). For the base text
embeddings, we maintain three levels of model quality: GPT-2 [Radford et al., 2019], BERT [Devlin
et al., 2019], and CLIP-based encodings.
Baseline Comparisons. We present a synthetic data example to understand the role of the singular
values s2, . . . , s mand compare our approach to simple baselines that make use of (PX, PY). We
also consider misspecification of these target marginals, in that they are chosen by the user but are
not the marginal distributions of the data-generating distribution P. First, while one can verify by
hand that (14) is a distribution for which s2=s, we construct a more general example for m≥2.
We leave the construction to the end of this example. For controllable misspecification, we define
ϵ∈[0,0.5]to be the misspecification level, so that the corrupted target marginals are set to be
˜PX:= (1−ϵ)PX+ϵˆPXand˜PY:= (1−ϵ)PY+ϵˆPY, (83)
where ˆPXandˆPYare drawn independently and randomly from the Dirichlet( 1m)distribution
(i.e. uniformly over the probability simplex on matoms). Finally, other than the empirical measure
Pn, we define one additional baseline; the importance weighted independently (IPWI) estimator is
defined as
PIPWI
n(x, y) =˜PX(x)
Pn,X(x)˜PY(y)
Pn,Y(y)Pn(x, y). (84)
450.0 0.2 0.4 0.6 0.8
Leading Singular Value s104
103
102
Mean Squared ErrorMarginal Fitting Techniques under Misspecifiation
=0.25 (IPWI)
=0.125 (IPWI)
=0.0 (IPWI)
=0.25 (Bal.)
=0.125 (Bal.)
=0.0 (Bal.)
Emp. MeasureFigure 5: Baseline Comparisons across Dependence and Misspecification Levels. Each line refers
to a combination of an estimation method (the empirical probability measure Pn, the estimator PIPWI
n
from (84), or the balancing estimator P(k)
nfork= 8) and a noise level on the provided marginals
(see (83)). The y-axis shows the mean squared error of estimating a linear functional. The x-axis
represents the dependence level s=s2(i.e. the leading singular value other than s1= 1).
This estimator simply reweighs all cells of the empirical measure by the likelihood ratio from each
observed marginal to the target marginal. Note that the result may not even be a probability measure,
as it may not sum to one. Observe the comparative performance in (see Fig. 5). We notice in particular
that the naive PIPWI
n is outperformed by empirical measure uniformly over s, as by applying both
reweightings simultaneously, the estimator does not satisfy either marginal constraint. On the other
hand, under the maximum amount of target marginal corruption ( ϵ= 0.5), the balancing-based
estimator suffers an approximately half-order of magnitude in MSE. When s≈1, the MSE of the
balancing estimator decreases significantly. We hypothesize that this is because the data sources X
andYare nearly a function of one another, and if this function is estimable to high precision by a
small amount of data, then a single marginal can identify the entire joint distribution via pushforward
calculations. That being said, it is important to note that the quantities ujandvjin(15) also depend
ons, so it is difficult to control the singular values without controlling the respective bases.
As for the construction of the probability mass function and test function, let Imand1m×mdenote
the identity matrix and matrix of ones in Rm×m. For any s∈(0,1)andm≥1, consider the
probability mass matrix Pgiven by
P=1
m1
m1m×m+s
Im−1
m1m×m
.
The eigenvalues of the first matrix in the squared brackets are (1,0, . . . , 0), as it is a rank 1matrix for
which 1mis an eigenvector. The second matrix in the square brackets is the centering matrix (the
projection matrix that subtracts the mean of a vector’s components from the entire vector). Multiplied
bys, it has eigenvalues (0, s, . . . , s )where 0is associated to the eigenvector 1m. Thus, the matrix in
its entirety has eigenvalues (1/m, s/m, . . . , s/m ), where the scaling factor ensures that Psums to
one. The relation (13) holds for this choice of Pand uniform marginals, with s2=. . .=sm=s.
Thus, by tuning s, we may control the level of dependence between XandY. Finally, because Xand
Yare finite, we can also specify the test function hvia an m×mtable indexed by i(meaning xi)
andj(meaning yj). We let h(xi, yj) =|Zij|where the Zijare independently drawn from a standard
normal distribution. The resulting mean squared error is estimated with 200 seeds at n= 300 .
Zero-Shot Retrieval. In this evaluation, we assess the ability of the learned representations to
match queries from one modality to their counterparts in another modality. We are given a test sets
Xtest={x1, . . . , x M}of images and Ytest={y1, . . . , y N}of texts in natural language. We are also
given a matrix of annotations A∈ {0,1}M×Nwhere Aij= 1if and only if yjis a “relevant” caption
460.00.10.20.3MSCOCO (Image)
CLIP Text Embeddings
0.0000.0250.0500.0750.100
BERT Text Embeddings
0.001000.001250.001500.001750.00200
GPT-2 Text Embeddings
0.00.10.20.3MSCOCO (Text)
 0.000.050.10
0.0020.0040.0060.008
0.00.20.4Flickr-8k (Image)
 0.000.050.100.15
0.00450.00500.00550.00600.0065
Training Steps0.00.20.4Flickr-8k (Text)
Training Steps0.000.050.100.150.20
Training Steps0.0050.0100.0150.020
Zeroshot Retrieval Performance (Recall @ 5)
No Balancing CLIP Balancing (k=1) Multi-CLIP (k=2)Figure 6: Zero-Shot Retrieval Performance across Embeddings and Objectives. The three
vertical panels describe different choices of the text encoder fθTwhich increases in quality from left
to right; that is, pre-trained GPT-2, BERT, and CLIP embeddings, respectively. Rows indicate various
datasets, either MS-COCO or Flickr8k. evaluated under recall at K= 5for image and text retrieval,
respectively. The y-axis of each plot indicates the metric (see (85)) for either image or text retrieval,
whereas the x-axis indicates training iterations at batch size 512.
470.600.620.64Rendered SST-2
CLIP Text Embeddings
 BERT Text Embeddings
 GPT-2 Text Embeddings
0.20.40.60.8VOC2007
Training Steps0.20.30.4FGVC Aircraft
Training Steps
 Training Steps
No Balancing CLIP Balancing (k=1) Multi-CLIP (k=2)Figure 7: Linear Probe Performance across Embeddings and Objectives. The three vertical panels
describe different choices of the text encoder fθTwhich increases in quality from left to right; that
is, pre-trained GPT-2, BERT, and CLIP embeddings, respectively. Rows indicate various evaluation
datasets from Rendered SST2, VOC2007, and FGVC Aircraft. The y-axis of each plot indicates the
average per-class recall, whereas the x-axis indicates training iterations at batch size 512.
for image xi(and vice versa). Given a particular query y∈ Y test, we define the top- Kneighborhood
ofyas
NK(y;θ) = arg max
S⊆[M]:|S|=KX
i∈S⟨fθI(xi), fθT(y)⟩,
i.e. the images in the test set that have the closest embeddings under the given model. Then, we may
define the average recall at Kfor image retrieval metric as
AverageRecallK(θ) :=1
NNX
j=1P
i∈NK(yj;θ)AijP
i′∈[M]Ai′j. (85)
In words, the metric evaluates the retrieval system’s ability to detect relevant items in the dataset, in
this case by comparing the closeness of the image-text representations. We can analogously define
theaverage recall at Kfor text retrieval metric by swapping the role of xandyabove. The results
for both retrieval metrics on the MS-COCO [Lin et al., 2015] and Flickr8k [Hodosh et al., 2013]
benchmarks are given in Fig. 6.
Linear Probe. Here, we evaluate the quality of the model’s encoders by fine-tuning a single
linear layer on top of the learned representations for a classification task. In the case of linear
probing via image classification, we use only the image encoder fθI. We are given a training set
{(x1, c1), . . . , (xN, cN)}of image-label pairs, where each ci∈ {1, . . . , C }. We fix the model
48Figure 8: Empirical Marginals of CLIP Contrast Matrix. Depiction of the probability measures
Q(k)
nandR(k)
nas described in (82) from Sec. 2. The orange bars correspond to the observed marginal
after fitting to the target uniform distribution on the given iteration. Left: Q(0)
nandR(0)
n, where
neither marginal is set to uniform. Center: Q(1)
nandR(1)
n, which corresponds to the original CLIP
loss. Right: Q(2)
nandR(2)
n, which correspond to two iterations of the balancing procedure within the
loss. The blue bars are slightly non-uniform.
parameter θIand solve the regularized multinomial cross entropy (MCE) objective
min
W∈RC×r"
LMCE(W) :=−1
NNX
i=1[LogSoftmax( WfθI(xi))]ci+λ
2∥W∥2
F#
,
where λ > 0is a regularization parameter, ∥·∥Fdenotes the Frobenius norm on RC×rand
LogSoftmax : RC→RCis given by LogSoftmax( z) =z−logPC
j=1exp(zj). This results
in a classifier
g(x) := arg max
j∈[C][WfθI(x)]j,
which can then be evaluated using standard accuracy metrics on a held-out test set. The image
classification results for the Rendered SST2 [Radford et al., 2021], VOC2007 [Everingham et al.,
2007], and FGVC Aircraft [Maji et al., 2013] benchmarks are given in Fig. 7.
Empirical Marginals in CLIP Balancing. To further clarify how the iterative balancing procedure
is baked into the CLIP losses, recall from (82) that the objectives decompose into two terms, which
depend on Q(k)
nandR(k)
nwhich differ only based on whether balancing to fit PYor to fit PXis
applied first, respectively. Thus, for any model parameterized by θand any number of iterations k,
there are four marginal distributions of interest: Q(k)
θ,X,Q(k)
θ,Y,R(k)
θ,X, and R(k)
θ,Y. Based on the order
of iterations, we have that Q(1)
θ,Y=R(2)
θ,Y=PY, and R(1)
θ,X=Q(2)
θ,X=PX. This is illustrated in
Fig. 8. We see that after only a few iterations, both marginal distributions converge to the uniform
distribution.
49F NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Theoretical claims, the focus of this paper, are supported with proofs.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We clarify that the setting studied has some dissimilarities with practice in
Sec. 2.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate ”Limitations” section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
50Justification: This is done for all theoretical statements.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Code is provided to reproduce the main results and an extensive experimental
details section is written.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
51Answer: [Yes]
Justification: This is written in the public repo provided in Sec. 4.
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Yes, we even give a list of the specific images of ImageNet used to train the
multimodal models.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Our evaluation metrics are shown with all seeds and their mean plotted in the
corresponding figures.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer ”Yes” if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
• The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
52•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Please see Appx. E.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: NA
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification: The work is primarily theoretical and retrospective.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
53•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [No]
Justification: We do not release general-purpose models, only small-scale illustrative ones.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We site all software and models used in the study in Appx. E.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the package
should be provided. For popular datasets, paperswithcode.com/datasets has
curated licenses for some datasets. Their licensing guide can help determine the license
of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
54•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [Yes]
Justification: We provide a list of notebooks and scripts to illustrate our method and connect
it to existing software repositories such as OpenCLIP.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: NA
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification: NA
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
55