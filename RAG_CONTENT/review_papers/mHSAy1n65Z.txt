Published in Transactions on Machine Learning Research (1/2023)
Optimal Threshold Labeling for Ordinal Regression Methods
Ryoya Yamasaki yamasaki@sys.i.kyoto-u.ac.jp
Department of Systems Science
Graduate School of Informatics, Kyoto University
36-1 Yoshida-Honmachi, Sakyo-ku, Kyoto 606-8501 JAPAN
Reviewed on OpenReview: https: // openreview. net/ forum? id= mHSAy1n65Z
Abstract
For an ordinal regression task, a classiﬁcation task for ordinal data, one-dimensional trans-
formation (1DT)-based methods are often employed since they are considered to capture the
ordinal relation of ordinal data well. They learn a 1DT of the observation of the explanatory
variables so that an observation with a larger class label tends to have a larger value of the
1DT, and classify the observation by labeling that learned 1DT. In this paper, we study
the labeling procedure for 1DT-based methods, which have not been suﬃciently discussed
in existing studies. While regression-based methods and classical threshold methods con-
ventionally use threshold labelings, which label a learned 1DT according to the rank of the
interval to which the 1DT belongs among intervals on the real line separated by threshold
parameters, we prove that likelihood-based labeling used in popular statistical 1DT-based
methods is also a threshold labeling in typical usages. Moreover, we show that these thresh-
old labelings can be sub-optimal ones depending on the learning result of the 1DT and the
task under consideration. On the basis of these ﬁndings, we propose to apply empirical
optimal threshold labeling, which is a threshold labeling that uses threshold parameters
minimizing the empirical task risk for a learned 1DT, to those methods. In experiments
with real-world datasets, changing the labeling procedure of existing 1DT-based methods
to the proposed one improved the classiﬁcation performance in many tried cases.
1 Introduction
Ordinal regression (OR) (or called ordinal classiﬁcation) is the classiﬁcation of ordinal data in which the
underlying target variable is categorical and labeled from a label set (ordinal scale) that is equipped with a
natural ordinal relation for the explanatory variables; see Section 2.1for a detailed formulation. The ordinal
scale is typically formed as a graded (interval) summary of objective indicators like age groups {‘0–9’, ‘10–
19’, . . . , ‘90–99’, ‘100–’} or graded evaluation of subjectivity like human rating {‘excellent’, ‘good’, ‘average’,
‘bad’, ‘terrible’}, and ordinal data appear in various practical applications: age estimation ( Niu et al. ,2016;
Cao et al. ,2020), information retrieval ( Liu,2011), movie rating ( Yu et al. ,2006), and questionnaire survey
in social research ( Bürkner & Vuorre ,2019).
One-dimensional transformation (1DT)-based methods are often applied to the OR problems as
a simple way to capture the ordinal relation of ordinal data: they learn a 1DT of the observation of the
explanatory variables so that an observation with a larger class label tends to have a larger value of the 1DT,
and classify the observation by labeling that learned 1DT, as we will formalize in Section 2.2. For example,
regression-based methods andclassical threshold methods (or called threshold models) conventionally
use a threshold labeling , which labels a learned 1DT according to the rank of the interval to which the 1DT
belongs among intervals on the real line separated by threshold parameters . Regression-based methods
(Kramer et al. ,2001;Agarwal ,2008) learn a 1DT by solving a naïve regression task that infers a class label
by the 1DT in a continuous scale, and often apply nearest-neighbor threshold (NNT) labeling that
rounds the learned 1DT to its nearest label (see Section 3.1). Classical threshold methods ( Shashua & Levin ,
2003;Lin & Li ,2006;Chu & Keerthi ,2007;Lin & Li ,2012;Li & Lin ,2007;Pedregosa et al. ,2017) learn
1Published in Transactions on Machine Learning Research (1/2023)
a 1DT using an objective function diﬀerent from the empirical task risk, and commonly use minimum
threshold (MT) andsummation threshold (ST) labelings that apply parameters obtained incidentally
in that learning procedure as threshold parameters (see Sections 3.2). Also, statistical 1DT-based methods
(statistical methods ) (McCullagh ,1980;Williams ,2006;Cao et al. ,2020;Yamasaki ,2022), in which the
learning procedure of the 1DT can be viewed as statistical modeling of conditional probabilities of the data,
can apply likelihood-based (LB) labeling that is designed to minimize the task risk under the expectation
that the assumed likelihood model is correctly speciﬁed to the data distribution (see Section 3.3).
We, however, have respective concerns on these existing labeling procedures. First, threshold parameters
of NNT, MT, and ST labelings are generally not designed to minimize the task risk. So their threshold
parameters can be sub-optimal for the minimization of the task risk, as we will demonstrate in Example 1.
On the other hand, the LB labeling is designed to minimize the task risk if the assumed likelihood model is
correctly speciﬁed to the distribution of the data (see Theorem 2). However, 1DT-based likelihood models
have a strongly restricted representation ability and can be mis-speciﬁed to the data, and hence the LB
labeling can degrade the classiﬁcation performance depending on the data distribution.
Previous studies have done little theoretical work on the properties of these existing labelings. Therefore,
we ﬁrst study the relationship between these labelings. In particular, we show in Theorem 3that not only
the NNT, MT, and ST labelings but also the LB labeling in typical usages is a threshold labeling. This
ﬁnding motivates us to search for a better labeling function among the class of threshold labelings. Then,
in Section 4, we propose to apply empirical optimal threshold (EOT) labeling , which is a threshold
labeling that uses threshold parameters minimizing the empirical task risk for the learned 1DT, to 1DT-
based methods, under the expectation that the 1DT is learned successfully and the empirical (training) task
risk becomes a good estimate of the (test) task risk. Here, the threshold parameters for the EOT labeling
can be computed with a computational complexity of quasi-linear order O¹𝑛log𝑛ºregarding the training
sample size 𝑛using a dynamic programming-based algorithm (Algorithm 1) mentioned in Lin & Li (2006)
(see Section 5for the relation of our proposal to several previous studies including this reference).
In this study, we further performed numerical experiments of the OR task for real-world ordinal data to
conﬁrm the practical eﬀectiveness of the EOT labeling (see Section 6and Appendix D). The EOT labeling
gave superior generalization performance (more exactly, smaller test task risk) than the NNT, MT, ST, and
LB labelings, in many tried cases. Also, a modiﬁed 1DT-based method with the EOT labeling outperformed
an existing 1DT-based method using the ST labeling that has been declared by Cao et al. (2020) to be
state-of-the-art in 2020 for the age estimation from the facial image.
Therefore, in this paper, we propose to change labeling procedures of (existing) 1DT-based OR methods
to the EOT labeling, on the ground of the fact (see Example 1and Theorem 3) that the NNT, MT, and
ST labelings and LB labeling in typical usages are possibly sub-optimal threshold labelings, and empirical
eﬀectiveness of the EOT labeling.
2 Preliminaries
2.1 Formulation of OR Problem
OR is the classiﬁcation of ordinal data. The ordinal data have an underlying categorical target variable
𝑌2»𝐾¼≔f1,...,𝐾gthat is equipped with an ordinal relation naturally interpretable in the relationship with
explanatory variables X2R𝑑, where𝑑and𝐾are supposed to be integers larger than or equal to 1and
3, respectively.1We here suppose that the target class labels are encoded to 1,...,𝐾 in an order-preserving
manner, like from ‘excellent’ ,..., ‘terrible’ to 1,..., 5.
The task of the OR ( OR task ) is basically the same as that of the standard (including cost-sensitive)
classiﬁcation, to obtain a good classiﬁer 𝑓:R𝑑! »𝐾¼. For a user-speciﬁed task loss function ℓ:
»𝐾¼2! » 0,1º, it is formulated as minimization of the task risk E»ℓ¹𝑓¹Xº,𝑌º¼, where the expectation
1For better modeling of the ordinal data, it would be important to provide a mathematical characterization and further
discussion of the natural ordinal relation. However, it would be related to learning procedure of the 1DT (deﬁned in Section 2.2)
more closely, and its necessity is not so great for the analysis and proposal of this study, so we will not mention it in this paper.
Refer to, for example, OR studies ( da Costa et al. ,2008;Yamasaki ,2022) for the discussion on such characterizations.
2Published in Transactions on Machine Learning Research (1/2023)
value E»¼is taken for all random variables in its argument (here Xand𝑌). Popular task losses for OR
tasks include not only the zero-one task loss ℓzo¹𝑗,𝑘º≔ /x31¹𝑗≠𝑘º, where /x31¹𝑐ºtakes 1 if a condition 𝑐is
true and 0 otherwise, but also V-shaped losses (for cost-sensitive tasks) reﬂecting one’s preference of smaller
prediction errors over larger ones such as the absolute deviation task loss ℓad¹𝑗,𝑘º≔j𝑗 𝑘j,squared
task lossℓsq¹𝑗,𝑘º≔¹𝑗 𝑘º2, andℓzo,𝑐¹𝑗,𝑘º≔ /x31¹j𝑗 𝑘j>𝑐ºwith𝑐0.
For the evaluation in the OR task, one may use criteria that cannot decomposed into a sum of losses for
each sample point: for example, quadratic weighted kappa ( Cohen ,1960;1968). Our discussion in this paper
does not cover such criteria.
2.2 Formulation of One-Dimensional Transformation (1DT)-Based Methods and Threshold Methods
In this paper, we discuss only 1DT-based OR methods. We here provide notations and terminologies common
for all the 1DT-based OR methods.
Suppose that one has the sample D𝑛≔f¹x𝑖,𝑦𝑖ºg𝑛
𝑖=1, each of which is drawn independently from an identical
distribution of¹X,𝑌º. First, 1DT-based methods learn a 1DT𝑎:R𝑑!Rof an observation of the
explanatory variables from a user-speciﬁed class Af𝑎:R𝑑!Rg(1DT class ) (e.g., a neural network
with a ﬁxed network architecture and learnable weight and bias parameters) possibly together with other
objects so that an observation with a larger class label tends to have a larger value of the 1DT; we call
this procedure the learning procedure (of the 1DT). Next, 1DT-based methods build up a classiﬁer as
𝑓=ℎ¯𝑎with a learned 1DT ¯𝑎and a labeling function ℎ:R!»𝐾¼; we call this procedure the labeling
procedure . Most existing 1DT-based methods can be seen as adopting one of the NNT, MT, ST, and LB
labelings, depending on the properties of their learning procedure, as we review later in Section 3.
In particular, we call a labeling function ℎthat can be represented as
ℎ¹𝑢º=ℎthr¹𝑢;tº≔1¸𝐾 1Õ
𝑘=1/x31¹𝑢𝑡𝑘º (1)
with parameters t=¹𝑡1,...,𝑡𝐾 1º2R𝐾 1as the threshold labeling . Also, we call the parameters tas the
threshold parameters , and a 1DT-based method using a threshold labeling as the threshold method ,
in this paper. Note that this formulation of the threshold method is a generalization of the one employed
in most previous studies on conventional threshold methods that we will review latter in Section 3.2. The
threshold labeling ℎthr¹𝑢;tºhas the following properties:
Proposition 1. The threshold labeling ℎthr¹𝑢;tºis non-decreasing and right-continuous in 𝑢2Rand in-
variant regarding the permutation of the threshold parameters 𝑡1,...,𝑡𝐾 1. Conversely, an arbitrary non-
decreasing right-continuous function ℎ:R!»𝐾¼can be represented by a threshold labeling ℎthr¹;tºwith
certain threshold parameters t2R𝐾 1(i.e., there exist t2R𝐾 1such thatℎ¹𝑢º=ℎthr¹𝑢;tºfor any𝑢2R)
or their permutation. Also, if 𝑡1,...,𝑡𝐾 1take only𝐿diﬀerent values, then ℎthr¹𝑢;tºhas𝐿change points
𝑢=𝑢1,...,𝑢𝐿such thatℎthr¹𝑢𝑙 𝜖;tº≠ℎthr¹𝑢𝑙;tºwith a suﬃciently small 𝜖 >0for𝑙=1,...,𝐿 .
The last result implies that the threshold labeling is the simplest as the labeling function in the sense that
the resulting classiﬁer has only ¹𝐾 1ºdecision boundaries for the learned 1DT at most.
Note that, in the learning procedure, since the empirical task risk1
𝑛Í𝑛
𝑖=1ℓ¹ℎ¹𝑎¹x𝑖ºº,𝑦𝑖ºis discontinuous
with respect to the 1DT 𝑎and hence diﬃcult to optimize numerically, many methods depend on another ob-
jective function. In this paper, we call that objective function the empirical surrogate risk , its population
version the surrogate risk , and its data-dependent minimal component the surrogate loss (function) .
2.3 Formulation of Policy of This Study
The goal of this study is to improve the labeling procedure of 1DT-based methods. Thus, regarding the
learning procedure of the 1DT, this paper adopts those by existing studies, and we do not discuss the
goodness of the learning procedure. Assuming that a learned 1DT ¯𝑎and task loss ℓare given, we will
discuss the goodness of the labeling function ℎwith the task risk E»ℓ¹ℎ¹¯𝑎¹Xºº,𝑌º¼or the empirical task risk
1
𝑛Í𝑛
𝑖=1ℓ¹ℎ¹¯𝑎¹x𝑖ºº,𝑦𝑖ºas a criterion, since the aim of the OR task is to minimize the task risk.
3Published in Transactions on Machine Learning Research (1/2023)
3 Review and Analysis of Existing 1DT-Based Methods and Labeling Functions
3.1 Regression-based Method with Nearest-Neighbor Threshold (NNT) Labeling
Regression-based methods ( Kramer et al. ,2001;Agarwal ,2008) learn a 1DT 𝑎by solving a naïve regression
task that infers a class label by the 1DT: for a regression loss function 𝜙:R»𝐾¼!» 0,1º,
min
𝑎2A1
𝑛𝑛Õ
𝑖=1𝜙¹𝑎¹x𝑖º,𝑦𝑖º. (2)
For example, Kramer et al. (2001) used the squared (SQ) loss 𝜙sq¹𝑢,𝑦º≔¹𝑢 𝑦º2, and Agarwal (2008)
used the absolute-deviation (AD) loss 𝜙ad¹𝑢,𝑦º≔j𝑢 𝑦j, as a regression loss function 𝜙.
As a labeling function ℎ, regression-based methods often use the NNT labeling
ℎnnt¹𝑢º≔ℎthr¹𝑢;¹1.5,2.5,...,𝐾 0.5ºº (3)
that is a threshold labeling ℎthr¹;tºwith the threshold parameters 𝑡𝑘=𝑘¸0.5,𝑘=1,...,𝐾 1. The NNT
labeling rounds the learned 1DT to its nearest label.
The regression-based methods using the above two surrogate loss functions and NNT labeling have the
following optimality guarantee for an OR task with a respective speciﬁc task loss:
Theorem 1 (Pedregosa et al. (2017, Theorems 9 and 11)) .Let¹ℓ,𝜙ºbe¹ℓad,𝜙adºor¹ℓsq,𝜙sqº. Then,
for the surrogate risk minimizer ¯𝑎2arg min𝑎:R𝑑!RE»𝜙¹𝑎¹Xº,𝑌º¼based on the surrogate loss 𝜙, the
classiﬁer𝑓nnt=ℎnnt¯𝑎minimizes the task risk E»ℓ¹𝑓¹Xº,𝑌º¼for the task loss ℓ:E»ℓ¹𝑓nnt¹Xº,𝑌º¼=
min𝑓:R𝑑!»𝐾¼E»ℓ¹𝑓¹Xº,𝑌º¼.
According to this theorem, the regression-based methods ( Kramer et al. ,2001;Agarwal ,2008) would be ex-
pectable to work well if the sample size 𝑛and 1DT classAare suﬃciently large. On the other hand, if the 1DT
classAis strongly restricted, a classiﬁer based on the NNT labeling may be sub-optimal for the OR task (be-
cause, generally, E»ℓ¹𝑓nnt¹Xº,𝑌º¼≠E»ℓ¹¯ℎ¹¯𝑎¹Xºº,𝑌º¼for𝑓nnt=ℎnnt¯𝑎with ¯𝑎2arg min𝑎2AE»𝜙¹𝑎¹Xº,𝑌º¼
and ¯ℎ2arg minℎ:R!»𝐾¼E»ℓ¹ℎ¹¯𝑎¹Xºº,𝑌º¼).
3.2 Classical Threshold Method with Minimum and Summation Threshold (MT and ST) Labelings
Classical threshold methods have been studied actively in the machine learning and statistical litera-
ture ( Shashua & Levin ,2003;Chu & Keerthi ,2007;Li & Lin ,2007;Lin & Li ,2012;Pedregosa et al. ,2017;
Cao et al. ,2020). Many of these methods are formulated with a learning procedure that simultaneously
learns¹𝐾 1ºparameters in addition to the 1DT 𝑎:
min
𝑎2A,b2B1
𝑛𝑛Õ
𝑖=1𝜙¹𝑎¹x𝑖º,b,𝑦𝑖º, (4)
where we call b=¹𝑏1,...,𝑏𝐾 1º2R𝐾 1thebias parameters ,BR𝐾 1is a user-speciﬁed class for the
bias parameters ( BPs class ), and𝜙:RR𝐾 1»𝐾¼!» 0,1ºis a surrogate loss function. As the labeling
functionℎ, several early works ( Shashua & Levin ,2003;Chu & Keerthi ,2007) use the MT labeling
ℎmt¹𝑢;¯bº≔minf𝑘2»𝐾¼j𝑢< ¯𝑏𝑘gwith ¯𝑏𝐾≔1 (5)
with learned bias parameters ¯b=¹¯𝑏1,..., ¯𝑏𝐾 1º, and more recent works ( Pedregosa et al. ,2017;Cao et al. ,
2020) use the ST labeling
ℎst¹𝑢;¯bº≔ℎthr¹𝑢;¯bº. (6)
The MT and ST labelings are threshold labelings and have the following relationship:
4Published in Transactions on Machine Learning Research (1/2023)
Proposition 2. Given ¯b2R𝐾 1together with ¯𝑏0≔ 1, let𝑡𝑘be¯𝑏𝑖𝑘with𝑖𝑘≔minf𝑗2f0,...,𝑘gj¯𝑏𝑘¯𝑏𝑗g
for each𝑘=1,...,𝐾 1. Then, one has that ℎmt¹𝑢;¯bº=ℎthr¹𝑢;tºwith t=¹𝑡1,...,𝑡𝐾 1º. Also,ℎmt¹𝑢;¯bº=
ℎthr¹𝑢;¯bºif¯𝑏1 ¯𝑏𝐾 1.
We remark that the MT labeling ℎmt¹𝑢;¯bºand ST labeling ℎst¹𝑢;¯bºare diﬀerent when the learned bias
parameters ¯bare not ordered.
A surrogate loss function 𝜙¹𝑢,b,𝑘ºfor these threshold methods is often built by replacing step functions
/x31¹𝑙ºand /x31¹𝑙¸1ºin the expression of the task loss ℓ¹,𝑘º=ℓ¹𝑘,𝑘º¸Í𝑘 1
𝑙=1fℓ¹𝑙,𝑘º ℓ¹𝑙¸1,𝑘ºg /x31¹𝑙
º¸Í𝐾 1
𝑙=𝑘fℓ¹𝑙¸1,𝑘º ℓ¹𝑙,𝑘ºg /x31¹𝑙¸1ºby convex surrogates widely-used in binary classiﬁcation ( Lin & Li ,
2012;Pedregosa et al. ,2017) such as the hinge, logistic, and exponential losses, so that 𝜙¹,b,𝑘ºbecomes
a continuous convex upper bound of ℓ¹ℎthr¹;bº,𝑘º. For example, in the terminology of Pedregosa et al.
(2017), the immediate threshold (IT) loss function
𝜙¹𝑎¹xº,b,𝑦º=8>>> <
>>>:𝜑¹𝑏1 𝑎¹xºº, if𝑦=1,
𝜑¹𝑎¹xº 𝑏𝐾 1º, if𝑦=𝐾,
𝜑¹𝑎¹xº 𝑏𝑦 1º¸𝜑¹𝑏𝑦 𝑎¹xºº,otherwise(7)
is an upper bound of zero-one task loss ℓzo, and the all threshold (AT) loss function
𝜙¹𝑎¹xº,b,𝑦º=8>>> <
>>>:Í𝐾 1
𝑘=1𝜑¹𝑏𝑘 𝑎¹xºº, if𝑦=1,Í𝐾 1
𝑘=1𝜑¹𝑎¹xº 𝑏𝑘º, if𝑦=𝐾,Í𝑦 1
𝑘=1𝜑¹𝑎¹xº 𝑏𝑘º¸Í𝐾 1
𝑘=𝑦𝜑¹𝑏𝑘 𝑎¹xºº,otherwise(8)
is an upper bound of absolute deviation task loss ℓad. For instance, SVOR-IMC ( Chu & Keerthi ,2007)
uses the IT loss with 𝜑¹𝑢º=minf0,1 𝑢g, ﬁxed margin strategy ( Shashua & Levin ,2003) and SVOR-EXC
(Chu & Keerthi ,2007) use the AT loss with 𝜑¹𝑢º=minf0,1 𝑢g, ORBoost-LR ( Lin & Li ,2006) uses the
IT loss with 𝜑¹𝑢º=𝑒 𝑢, ORBoost-ALL ( Lin & Li ,2006) uses the AT loss with 𝜑¹𝑢º=𝑒 𝑢, and CORAL
(Cao et al. ,2020) uses the AT loss with 𝜑¹𝑢º=log¹1¸𝑒 𝑢º.
As the BPs class B, the non-restricted (non-ordered) class R𝐾 1and ordered class fb2R𝐾 1j𝑏1
𝑏𝐾 1gare often applied. As a simple implementation of the ordered class, Franses & Paap (2001) mentioned
to parametrize the bias parameters bas
𝑏1=𝑏0
1,and𝑏𝑘=𝑏𝑘 1¸𝑏0
𝑘2for𝑘=2,...,𝐾 1, (9)
with other parameters 𝑏0
1,...,𝑏0
𝐾 12R. When the ordered BPs class is applied, the MT and ST labelings
bring the same classiﬁcation results. Also, for many AT loss functions, bias parameters ¯bof the surrogate
risk minimizer¹¯𝑎,¯bº2arg min𝑎2A,b2R𝐾 1E»𝜙¹𝑎¹Xº,b,𝑌º¼are ensured to be ordered ¹¯𝑏1 ¯𝑏𝐾 1º(see
Chu & Keerthi (2005, Lemma 1) and Li & Lin (2007, Theorem 2)), and hence the use of the ordered BPs
class will be justiﬁed.
The use of the surrogate loss 𝜑and the MT or ST labeling ℎ, which make 𝜙¹,¯b,𝑦º(with ordered ¯b) to be an
upper bound of the task loss ℓ¹ℎ¹º,𝑦º, is almost like a convention and may facilitate generalization analysis
(Li & Lin ,2007;Lin & Li ,2012), but the goodness of selecting the MT or ST labeling is not supported
by theoretical discussion. We demonstrate in the following example that the MT or ST labeling may be a
negative factor that degrades the classiﬁcation performance of threshold methods:
Example 1. We here consider the IT loss (7)with𝜑¹𝑢º=minf0,1 𝑢g, which we denote 𝜙hinge -it¹𝑢,b,𝑘º
and call Hinge-IT loss. The Hinge-IT loss is a continuous convex upper bound of the zero-one task loss with
the MT labeling ℓzo¹ℎmt¹;bº,𝑘º(and ST labeling ℓzo¹ℎst¹;bº,𝑘º) when bis ordered (i.e., 𝑏1𝑏𝐾 1):
𝜙hinge -it¹,b,𝑘ºis a convex function and 𝜙hinge -it¹,b,𝑘ºℓzo¹ℎmt¹;bº,𝑘º. So one may think that the Hinge-
IT loss and the task with the zero-one task loss ( Task-Z ) have friendly compatibility, from an analogy of
a well-known result, classiﬁcation calibration ( Bartlett et al. ,2006), in binary classiﬁcation. However, the
following demonstration shows that the MT labeling may be sub-optimal in minimizing the task risk as a
labeling function for the combination of the Hinge-IT loss and Task-Z.
5Published in Transactions on Machine Learning Research (1/2023)
We consider a 4-class OR problem (let 𝐾=4), and suppose that the data appear only on 4 diﬀerent points
x»1¼,..., x»4¼inR𝑑and follow the probability distribution, Pr¹x»𝑖¼º=0.25and¹Pr¹1jx»𝑖¼º,..., Pr¹𝐾jx»𝑖¼ºº=
¹0.5,0.4,0,0.1º,¹0.3,0.5,0,0.2º,¹0.2,0,0.5,0.3º,¹0.1,0,0.4,0.5ºfor𝑖=1,..., 4.2
It can be shown that the surrogate risk minimizer ¹¯𝑎,¯bº2arg min𝑎:R𝑑!R,b2R𝐾 1E»𝜙hinge -it¹𝑎¹Xº,b,𝑌º¼satis-
ﬁes¯𝑏1=¯𝑏2=¯𝑏3=0,¯𝑎¹x»1¼º=¯𝑎¹x»2¼º= 1, and ¯𝑎¹x»3¼º=¯𝑎¹x»4¼º=1(ignore the translation invariance) by
several simple calculations. The MT labeling predicts a label of the data on x»𝑖¼asℎmt¹¯𝑎¹x»𝑖¼º;¯bº=1,1,4,4
for𝑖=1,..., 4(E»ℓzo¹ℎmt¹¯𝑎¹Xº;¯bº,𝑌º¼=0.6), despite that using diﬀerent threshold parameters (say
t=¹ 2,0,2º) one can predict it as ℎmt¹¯𝑎¹x»𝑖¼º;tº=2,2,3,3for𝑖=1,..., 4and yield a smaller value
of the task risk ( E»ℓzo¹ℎmt¹¯𝑎¹Xº;tº,𝑌º¼=0.55). □
3.3 Statistical Methods with Likelihood-Based (LB) Labeling
In the OR research in statistics, several methods have been developed according to the statistical mod-
eling of the conditional probabilities of the data through a 1DT ( McCullagh ,1980;Williams ,2006;
Chu & Ghahramani ,2005;Yamasaki ,2022). For example, the cumulative link model ( McCullagh ,1980),
which is popular in the OR research, models the conditional probabilities Pr¹𝑦jxº,¹x,𝑦º2R𝑑»𝐾¼by
𝑃¹𝑦;𝜎,˜𝑎¹xº,˜bº≔8>>> <
>>>:𝜎¹˜𝑏𝑦 ˜𝑎¹xºº, if𝑦=1,
1 𝜎¹˜𝑏𝑦 1 ˜𝑎¹xºº, if𝑦=𝐾,
𝜎¹˜𝑏𝑦 ˜𝑎¹xºº 𝜎¹˜𝑏𝑦 1 ˜𝑎¹xºº,otherwise,(10)
where𝜎:R!»0,1¼is a link function that is non-decreasing and satisﬁes 𝜎¹ 1º=0and𝜎¹¸1º=1(i.e.,𝜎
is a cumulative distribution (CPD) function), ˜𝑎:R𝑑!Ris an assumed 1DT, and ˜b=¹˜𝑏1,..., ˜𝑏𝐾 1º2R𝐾 1
are assumed bias parameters that satisfy ˜𝑏1 ˜𝑏𝐾 1. As a link function 𝜎, ordinal logistic regression
(OLR) ( McCullagh ,1980) applies the CPD function of the logistic distribution (a.k.a. the sigmoid function)
𝜎logistic¹𝑢º≔1¹1¸𝑒 𝑢º, and cumulative probit model ( Agresti ,2010, Section 5.2) and Gaussian process OR
(GPOR) proposed by Chu & Ghahramani (2005) use the CPD function of the standard Gaussian distribution
(a.k.a. the inverse function of the probit function) 𝜎gauss¹𝑢º≔¯𝑢
 1¹2𝜋º 12𝑒 𝑣22𝑑𝑣.
In the learning procedure of the 1DT, statistical methods apply surrogate loss functions associated with their
statistical modeling. For the cumulative link model, a surrogate loss function 𝜙and the BPs class Bfor the
learning procedure same as ( 4) should satisfy
¹˜𝑢,˜bº=arg min
𝑢2R,b2B𝐾Õ
𝑦=1𝑃¹𝑦;𝜎,˜𝑢,˜bº𝜙¹𝑢,b,𝑦º. (11)
A popular instance of the surrogate loss function is the negative log likelihood (NLL) loss function
𝜙nll¹𝑢,b,𝑦;𝜎º≔ logf𝑃¹𝑦;𝜎,𝑢,bºg, for which the learning procedure amounts to the maximum likelihood
estimation for the model ( 10). Also, Cao et al. (2020) used the AT loss ( 8) with𝜑¹𝑢º= logf𝜎¹𝑢ºg, which we
call the all negative log cumulative likelihoods (ANLCL) loss function and denote 𝜙anlcl¹𝑢,b,𝑦;𝜎º,
for𝜎=𝜎logistic . The learning procedure for this loss function can be characterized as the minimization
of the sum of the NLLs of the models of cumulative conditional probabilities Pr¹𝑌𝑘jX=xºfor binary
classiﬁcation problems, ‘ 𝑘or less’ vs. ‘more than 𝑘’,𝑘=1,...,𝐾 1.
The above interpretation on using the surrogate losses 𝜙nlland𝜙anlcl under the statistical model ( 10) can
be mathematically understood as follows:
Theorem 2. Assume that the random variable ¹X,𝑌ºunderlying the data has conditional probabilities that
can be represented as (10):Pr¹𝑦jxº=𝑃¹𝑦;𝜎,˜𝑎¹xº,˜bºfor every𝑦2»𝐾¼and any x2R𝑑in the support of the
distribution of Xwith𝜎that is non-decreasing and satisﬁes 𝜎¹ 1º=0and𝜎¹¸1º=1(and𝜎¹ º=1 𝜎¹º
for𝜙=𝜙anlcl) such as𝜎logistic and𝜎gauss,˜𝑎:R𝑑!R, and ˜b2R𝐾 1satisfying ˜𝑏1 ˜𝑏𝐾 1. LetA
bef𝑔:R𝑑!Rg, and¹𝜙,Bºbe¹𝜙nll,fb2R𝐾 1j𝑏1𝑏𝐾 1gº,¹𝜙anlcl,R𝐾 1º, or¹𝜙anlcl,fb2R𝐾 1j
𝑏1𝑏𝐾 1gº. Then, any surrogate risk minimizer ¹¯𝑎,¯bº2arg min𝑎2A,b2BE»𝜙¹𝑎¹Xº,b,𝑌º¼satisﬁes
𝑃¹𝑦;𝜎,¯𝑎¹xº,¯bº=Pr¹𝑦jxºfor any x2R𝑑in the support of the distribution of X.
2We abbreviate the marginal probability Pr¹X=xºtoPr¹xºand the conditional probability Pr¹𝑌=𝑦jX=xºtoPr¹𝑦jxº
(this abbreviation applies to an estimate ˆPras well).
6Published in Transactions on Machine Learning Research (1/2023)
For such methods, not only the threshold labelings but also the LB labeling that grounds on the assumed
statistical model is a widely-used option for the labeling function. Considering Theorem 2and the equality
E»ℓ¹𝑓¹xº,𝑌º¼=Í𝐾
𝑦=1Pr¹𝑦jxºℓ¹𝑓¹xº,𝑦º, and aiming to minimize the task risk, min𝑓:R𝑑!»𝐾¼E»ℓ¹𝑓¹𝑋º,𝑌º¼,
these methods can predict a label with the LB labeling
ℎlb¹𝑢;𝜎,¯b,ℓº≔min
arg min
𝑘2»𝐾¼𝐾Õ
𝑦=1𝑃¹𝑦;𝜎,𝑢, ¯bºℓ¹𝑘,𝑦º
(12)
with learned bias parameters ¯b, under the expectation that the assumed statistical model ( 10) correctly
represents the actual statistical behavior of the data and it is learned successfully. Note that there can
be a tie situation where objective functions with diﬀerent 𝑘of (12) take the same value, and arg min𝑘2»𝐾¼
operation outputs multiple labels. The overlaid minoperation in ( 12) avoids such a tie situation.
These methods tend to perform better when their assumed statistical model represents the actual statistical
behavior of the data well. One can, however, ﬁnd that the condition in Theorem 2is very restrictive.
Therefore, in many practical situations, their statistical model would deviate from the actual statistical
behavior of the data, and then their 1DT model may not be learned appropriately, and the LB labeling
ℎlb¹;𝜎,¯b,ℓºmay be sub-optimal for the learned 1DT model ¯𝑎.
One may still consider that the LB labeling is more ﬂexible, in that it is generally not restricted within
the class of non-decreasing threshold labelings, and superior to threshold labelings. However, we found
that the LB labeling takes the form of the threshold labeling, for typical statistical models such as ones
in OLR and GPOR (i.e., the link function 𝜎such as𝜎logistic,𝜎gauss) and for typical task losses such as
ℓ=ℓzo,ℓzo,𝑐,ℓad,ℓsq.
Theorem 3. Suppose that 𝜎is non-decreasing and satisﬁes 𝜎¹ 1º=0and𝜎¹¸1º=1and that ¯𝑏1
¯𝑏𝐾 1. Then, the LB labeling ℎlb¹𝑢;𝜎,¯b,ℓºis
(i)a certain threshold labeling ℎthr¹𝑢;tºfor some t2R𝐾 1, ifℓ¹𝑘,𝑙ºat each ﬁxed 𝑘2 »𝐾¼is non-
increasing in 𝑙for𝑙𝑘and non-decreasing in 𝑙for𝑙𝑘, andℓ𝑘,𝑙¹𝑗º≔ℓ¹𝑘,𝑗º ℓ¹𝑘,𝑗¸1º ℓ¹𝑙,𝑗º¸
ℓ¹𝑙,𝑗¸1ºat each ﬁxed diﬀerent 𝑘,𝑙2»𝐾¼is non-positive (resp. non-negative) for all 𝑗2»𝐾 1¼
respectively when 𝑘 <𝑙 (resp.𝑘 >𝑙 ), for example, ℓ=ℓad,ℓsq,
(ii)a certain threshold labeling ℎthr¹𝑢;tºfor some t2R𝐾 1, ifℓ=ℓzo,ℓzo,𝑐with𝑐2»0,b𝐾2cº,𝜎is
diﬀerentiable, 𝜎0¹𝑣º≔𝑑
𝑑𝑣𝜎¹𝑣ºis even and non-increasing in 𝑣if𝑣 > 0, and𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2ºis non-
increasing in 𝑣1with ﬁxed𝑣2(and in𝑣2with ﬁxed𝑣1) if𝑣1<𝑣2, for example, 𝜎=𝜎logistic,𝜎gauss,
whereb𝑣cis the greatest integer less than or equal to 𝑣,
(iii) the threshold labeling ℎthr¹𝑢;¯bºthat is same as the MT labeling ℎmt¹𝑢;¯bºand ST labeling ℎst¹𝑢;¯bº,
ifℓ=ℓadand𝜎¹0º=0.5.
Here, Theorem 3(i) assumes that the task loss ℓis V-shaped, and the condition on ℓ𝑘,𝑙in Theorem 3(i)
holds under the convexity of ℓdeﬁned below:
Theorem 4. ℓ𝑘,𝑙¹𝑗ºat each ﬁxed diﬀerent 𝑘,𝑙2»𝐾¼is non-positive (resp. non-negative) for all 𝑗2»𝐾 1¼
respectively when 𝑘 <𝑙 (resp.𝑘 >𝑙 ), if the task risk ℓis convex in the diﬀerence of the two arguments:
ℓ¹𝑗3,𝑘3º¹𝑗3 𝑘3º ¹𝑗1 𝑘1º
¹𝑗2 𝑘2º ¹𝑗1 𝑘1ºℓ¹𝑗1,𝑘1º¸¹𝑗2 𝑘2º ¹𝑗3 𝑘3º
¹𝑗2 𝑘2º ¹𝑗1 𝑘1ºℓ¹𝑗2,𝑘2º (13)
for all𝑗1,...,𝑘 32»𝐾¼such that𝑗1 𝑘1≠𝑗2 𝑘2and𝑗1 𝑘1𝑗3 𝑘3𝑗2 𝑘2.
The condition on 𝜎in Theorem 3(ii) comes from the consideration for non-convex task losses.
A result similar to Theorem 3also holds for 1DT-based likelihood models other than the CL model ( 10); refer
to Theorem 5in Section B. For 1DT-based statistical methods, it may be common that their LB labeling is
a threshold labeling.
7Published in Transactions on Machine Learning Research (1/2023)
4 Proposal of 1DT-based Methods with Empirical Optimal Threshold (EOT) Labeling
In typical usages, not only the NNT, MT, and ST labelings, but also the LB labeling is a threshold labeling,
as we conﬁrmed in Theorem 3. Thus, we consider that it would be meaningful to aim for a better threshold
labeling for improving the classiﬁcation performance of existing 1DT-based methods. Recalling that the ﬁnal
goal is to make the task risk E»ℓ¹𝑓¹Xº,𝑌º¼small, and expecting that the 1DT was learned successfully and
the empirical (training) task risk becomes a good estimate of the (test) task risk, we propose to apply the
EOT labeling
ℎ¹𝑢;teotºwith teot2arg min
t2R𝐾 11
𝑛𝑛Õ
𝑖=1ℓ¹ℎthr¹¯𝑎¹x𝑖º;tº,𝑦𝑖º (14)
that uses threshold parameters minimizing the empirical task risk for a given learned 1DT model ¯𝑎.
The threshold parameters for the EOT labeling can be computed with a dynamic programming-based al-
gorithm (Algorithm 1) mentioned in Lin & Li (2006); see also a researchers’ site ( https:// home. work.
caltech. edu/ ~htlin/ program/ orensemble/ ) ofLin & Li (2006), and Section Cof our paper for its opti-
mality guarantee. This algorithm ﬁrst sorts unique elements of f¯𝑎¹x𝑖ºg𝑛
𝑖=1tof¯𝑎𝑗g, and takes advantage of
the recurrence relation ( 46) of the minimizer of the empirical task risk for sample points 𝑖’s s.t. ¯𝑎¹x𝑖º ¯𝑎𝑗
along the ascending order of f¯𝑎𝑗gto calculate threshold parameters minimizing the empirical task risk. It
costs a computational complexity of quasi-linear order O¹𝑛log𝑛ºregarding the training sample size 𝑛, which
stems from the sorting operation in Line 2while the rest operation in Lines 3–15costs a computational
complexity ofO¹𝑛𝐾º.
The NNT labeling for regression-based methods (reviewed in Section 3.1) and LB labeling for statistical
methods (reviewed in Section 3.3) have optimality guarantees for the task risk minimization under ideal
situations; refer to Theorems 1and2. Also, many threshold methods employ ¹𝐾 1ºbias parameters, and
those bias parameters can be directly used in their labeling procedure like MT and ST labelings, as reviewed
in Section 3.2. Presumably, for these reasons, a formulation that allows a threshold labeling with variable
threshold parameters has not been considered for these methods. Our formulation in Section 2.2introduces
the threshold labeling with variable threshold parameters and clearly distinguishes the bias and threshold
parameters. This is also an important contribution of this paper: due to this formulation, it becomes natural
to consider the application of the threshold labeling to 1DT-based methods with a diﬀerent number of bias
parameters than¹𝐾 1ºsuch as PO-VS-SL ( Yamasaki ,2022). Furthermore, this led to the EOT labeling
that has a potential to improve the classiﬁcation performance.
We, however, have to provide a remark on the additional learning of the decision boundaries (here threshold
parameters) after the learning of the learner model (here a 1DT): the additional learning generally has a
risk of enlarging the generalization gap. One can adjust the labeling function ℎso thatℎ¹¯𝑔¹x𝑖ºº=𝑦𝑖for
every training example 𝑖=1,...,𝑛 if allowing arbitrary formats and 𝑦𝑖1=𝑦𝑖2for any𝑖1,𝑖2s.t.x𝑖1=x𝑖2, but
the resulting classiﬁer ℎ¯𝑔would have quite low generalization performance. On the other hand, we here
consider the additional learning of the labeling function among the class of threshold labelings. A threshold
labeling has up to ¹𝐾 1ºdecision boundaries, that is, it is strictly restricted, and we expect that the degree
of the generalization gap will not diﬀer much with any threshold labelings.
5 Relationship to Other Previous Studies
Most existing studies on 1DT-based methods discuss the learning procedure. In Section 3, we reviewed point-
wise 1DT-based methods in which the learning procedure is formulated with a surrogate loss function
deﬁned for each point ¹𝑎¹x𝑖º,𝑦𝑖º, but some 1DT-based methods employ diﬀerent formulations. For example,
pair-wise 1DT-based methods including RankSVM ( Herbrich et al. ,1999) and RankBoost ( Lin & Li ,
2006) are formulated with a surrogate loss function that is deﬁned for each pair of two points ¹𝑎¹x𝑖º,𝑦𝑖ºand
¹𝑎¹x𝑗º,𝑦𝑗º; see also Lin & Li (2012);Gutierrez et al. (2015) for survey of such methods. The EOT labeling
can be applied to those 1DT-based methods as well.
8Published in Transactions on Machine Learning Research (1/2023)
Algorithm 1: Calculation of the threshold parameters for the EOT labeling
Input: Task lossℓ, learned 1DT ¯𝑎, and training data D𝑛=f¹x𝑖,𝑦𝑖ºg𝑛
𝑖=1.
/*Preparation of f¯𝑎𝑗g𝑁
𝑗=1andY𝑗for𝑗=1,...,𝑁 . */
1Letf¯𝑎0
𝑗g𝑁
𝑗=1be unique elements of f¯𝑎¹x𝑖ºg𝑛
𝑖=1:¯𝑎0
𝑗1≠¯𝑎0
𝑗2for all𝑗1,𝑗22»𝑁¼s.t.𝑗1≠𝑗2, and
¯𝑎¹x𝑖º2f ¯𝑎0
𝑗g𝑁
𝑗=1for all𝑖2»𝑛¼.
2Sortf¯𝑎0
𝑗g𝑁
𝑗=1in the ascending order, and represent the result as f¯𝑎𝑗g𝑁
𝑗=1:¯𝑎1 ¯𝑎𝑁.
3Create setsY𝑗=f𝑦𝑖j¯𝑎¹x𝑖º=¯𝑎𝑗g𝑛
𝑖=1,𝑗=1,...,𝑁 .
/*Calculate matrix 𝐿2R𝑁𝐾. */
4 for𝑘=1,...,𝐾 do
5𝐿1,𝑘=Í
𝑦𝑖2Y1ℓ¹𝑘,𝑦𝑖º.
6 for𝑗=2,...,𝑁 do
7 for𝑘=1,...,𝐾 do
/*An efficient implementation of 𝐿𝑗,𝑘=min𝑙2»𝑘¼𝐿𝑗 1,𝑙¸Í
𝑦𝑖2Y𝑗ℓ¹𝑘,𝑦𝑖º. */
8𝐿tmp 𝐿𝑗 1,1(if𝑘=1),minf𝐿tmp,𝐿𝑗 1,𝑘g(otherwise).
9𝐿𝑗,𝑘=𝐿tmp¸Í
𝑦𝑖2Y𝑗ℓ¹𝑘,𝑦𝑖º.
/*Calculate threshold parameters ¯t. */
10𝐼 min¹arg min𝑙2»𝐾¼𝐿𝑁,𝑙º.
11 if𝐼≠𝐾then
Let¯𝑡𝑘be a value larger than ¯𝑎𝑁(e.g.,¸1) for𝑘=𝐼,...,𝐾 1.
12 for𝑗=𝑁 1,..., 1do
13𝐽 min¹arg min𝑙2»𝐼¼𝐿𝑗,𝑙º.
14 if𝐼≠𝐽then
¯𝑡𝑘=¹¯𝑎𝑗¸¯𝑎𝑗¸1º2for𝑘=𝐽,...,𝐼 1, and𝐼 𝐽.
15 if𝐼≠1then
Let¯𝑡𝑘be a value smaller than ¯𝑎1(e.g., 1) for𝑘=1,...,𝐼 1.
Output: Threshold parameters ¯t=¹¯𝑡1,..., ¯𝑡𝐾 1º.
On the other hand, there are several previous works that have studied the labeling procedures diﬀerent from
NNT, MT, ST, LB, and EOT labelings. We review the discussion of those previous works, and describe the
relationship between their methods and the EOT labeling, in the following.
Herbrich et al. (1999) considered a pairwise 1DT-based method based on a hinge-type surrogate loss, for the
task with the zero-one task loss. Their method ( Herbrich et al. ,1999, (12)) adopts a threshold labeling with
threshold parameters determined by minimizing a unique criterion that emphasizes the shape of the used
hinge-type loss and is diﬀerent from the (empirical) surrogate risk, and has no optimality guarantee in the
task risk minimization.
Lin & Li (2006) considered three methods; see RankBoost (4), ORBoost-LR (7), and ORBoost-ALL (8) of
this reference. The third method applies the AT loss with 𝜑¹𝑢º=𝑒 𝑢(ORBoost-ALL), and its labeling
procedure is the same as the MT and ST labelings in this paper. Also, one can understand that the second
method, ORBoost-LR (7), tries to minimize (an upper bound of) the empirical surrogate risk based on the IT
loss function with 𝜑¹𝑢º=𝑒 𝑢and ordered BPs class in its learning procedure, and its labeling procedure also
can be seen to follow the idea of the MT and ST labelings. Finally, the ﬁrst method, RankBoost, is a pair-
wise 1DT-based method, and its objective function (4) for the labeling procedure is deﬁned as the empirical
task risk with the absolute deviation task loss. This labeling procedure is similar to the EOT labeling,
butLin & Li (2006) did not mention the relevance between that objective function and the task under
consideration. Although Lin & Li (2006) presented a description on the threshold parameters determination
based on the zero-one task loss at the part following (4), they tried only the threshold parameters determined
by minimizing the empirical task risk with the absolute deviation task loss even when they considered the
task with the zero-one task loss in their experiments. The main claim of our consideration in Section 4
is that the threshold parameters should be determined via minimizing the (empirical) task risk for the
task under consideration. Therefore, the EOT labeling in Section 4can be interpreted as a variant of
9Published in Transactions on Machine Learning Research (1/2023)
Table 1: Dataset properties, the total sample size 𝑛tot, the dimension 𝑑of the explanatory variables, and
the number 𝐾of classes of the target variable, of the RW datasets used for the experiments in Section 6.
COL PAS SQ1 SQ2 BON TAE AUT NEW TOY ESL
𝑛tot 24 36 52 52 57 151 205 215 300 488
𝑑 6 25 51 52 37 54 71 5 2 4
𝐾 3 3 3 3 5 3 6 3 5 9
BAS EUQ LEV ERA SWD WQR CAR MORPH CACD AFAD
𝑛tot 625 736 1000 1000 1000 1599 1728 55013 159402 164418
𝑑 4 91 4 4 10 11 21 12823 12823 12823
𝐾 3 5 5 9 4 6 4 55 49 26
those for Lin & Li (2006, (4)) with respect to the relevance between the objective function to determine
the threshold parameters and the task under consideration. Our contributions, namely, are to expand the
scope of applicability of the EOT labeling to regression-based, threshold, and statistical methods reviewed
in Section 3, and to modify the EOT labeling to be performed based on the task loss function corresponding
to the task under consideration, not the development of Algorithm 1as a method for the minimization of
the empirical task risk with a given task loss function.
6 Numerical Experiments with Real-World Datasets
Purpose We performed numerical experiments using real-world (RW) datasets to answer the question,
whether a modiﬁed 1DT-based method with the EOT labeling can yield better classiﬁcation performance
(i.e., smaller test task risk) for the OR task than existing 1DT-based methods using other labeling functions.
Datasets and Preprocessing In the experiments, we used the 17 various-domain datasets , COL
(contact-lenses), PAS (pasture), SQ1 (squash-stored), SQ2 (squash-unstored), BON (bondrate), TAE (tae),
AUT (automobile), NEW (newthyroid), TOY ( da Costa et al. ,2008), ESL (employee selection), BAS
(balance-scale), EUQ (eucalyptus), LEV (lectures evaluation), ERA (employee rejection/acceptance), SWD
(social workers decision), WQR (winequality-red), CAR (car evaluation) datasets, and the 3 face-age
datasets , MORPH (MORPH Album2), CACD, and AFAD datasets ( Ricanek & Tesafaye ,2006;Chen et al. ,
2014;Niu et al. ,2016). The main reason why we used the various-domain and face-age datasets is respec-
tively to experiment with many real-world datasets in various domains and to conﬁrm whether the proposed
method achieves the classiﬁcation performance competitive to the state-of-the-art method in a modern ap-
plication. For most of the experimental settings, we referred to those of the previous studies ( Cao et al. ,
2020;Gutierrez et al. ,2015) with few modiﬁcations.3
For the various-domain datasets, we used datasets, which Gutierrez et al. (2015) used as OR datasets, follow-
ing the setting of the explanatory and target variables in Gutierrez et al. (2015). One can obtain the various-
domain datasets from a researchers’ site ( http:// www. uco. es/grupos/ ayrna/ orreview ) ofGutierrez et al.
(2015) or our GitHub repository ( https:// github. com/ yamasakiryoya/ OTL). We purchased the MORPH
dataset at https:// ebill. uncw. edu/ C20231_ ustores/ web/ and preprocessed it so that the face spanned
the whole image with the nose tip, which was located by facial landmark detection ( Sagonas et al. ,2016),
at the center by using EyepadAlign function by Raschka (2018). While this dataset contains 55,134 facial
images with ages from 16 to 77, we used 55,013 images with ages from 16 to 70. The CACD dataset can
be downloaded from https:// bcsiriuschen. github. io/CARC/ . We preprocessed this dataset similarly to
the MORPH dataset. Since the CACD dataset collects images from the Internet using computer vision
techniques, it includes some facial images inappropriate for our consideration. Excluding images, in which
no face or more than two faces were detected in the preprocessing, from the original 163,446 images, we
used 159,402 facial images in the age range of 14–62 years. For the AFAD dataset obtainable at https://
github. com/ afad-dataset/ tarball , because faces in its images were already centered, we took no further
3For the face-age datasets, we used a part of program codes published in https:// github. com/ Raschka-research-group/
coral-cnn byCao et al. (2020), but results of our reproduction of their method diﬀer from theirs mainly because we changed
the learning rate from 510 5to10 2.5. See https:// github. com/ yamasakiryoya/ OTLfor program codes that we used.
10Published in Transactions on Machine Learning Research (1/2023)
preprocessing, and used its 164,418 images with ages 15–40. For these face-age datasets, we treated the age
rank as the target variable. Table 1summarizes basic dataset properties, the total sample size 𝑛tot, the
dimension𝑑of the explanatory variables, and the number 𝐾of classes of the target variable, of all the used
datasets.
For the various-domain datasets, we randomly divided each dataset into 72 % training, 8 % validation, and
20 % test sets. For the face-age datasets, we resized all images to 1281283pixels (3 stems from RGB
channels) and randomly divided each dataset into 72 % training, 8 % validation, and 20 % test sets, and the
training phase used images randomly cropped with the size of 1201203pixels as input to improve the
stability of the model against the diﬀerence of facial positions, and validation and test phases used images
center-cropped to the same size, following procedures by Cao et al. (2020).
Tasks We considered the three popular OR tasks: minimization of the task risk for the zero-one task loss
ℓzo¹𝑗,𝑘º= /x31¹𝑗≠𝑘º(Task-Z ), that for the absolute deviation task loss ℓad¹𝑗,𝑘º=j𝑗 𝑘j(Task-A ), and
that for the squared task loss ℓsq¹𝑗,𝑘º=¹𝑗 𝑘º2(Task-S ).
Methods For the various-domain datasets, we applied a 1DT class based on a 4-layer fully-connected
neural network, in which every hidden layer has 100 nodes activated with the sigmoid function in addition to
bias nodes. Also, for the face-age datasets, we applied a 1DT class based on ResNet-34 ( He et al. ,2016), a
modern CNN architecture, following ( Cao et al. ,2020)’s implementation. It modiﬁes a fully-connected (the
number of classes)-output ﬁnal layer of the conventional ResNet-34 to a fully-connected 1-output layer.
As the surrogate loss function, we tried the AD loss 𝜑ad; the IT loss ( 7) with𝜑¹𝑢º=minf0,1 𝑢g(Hinge-
IT),log¹1¸𝑒 𝑢º(Logistic-IT ); the AT loss ( 8) with𝜑¹𝑢º=minf0,1 𝑢g(Hinge-AT ),log¹1¸𝑒 𝑢º
(Logistic-AT ); the NLL loss 𝜙nllfor the statistical model ( 10) with𝜎=𝜎logistic (OLR-NLL ).4
As the BPs class, we tried the non-ordered class and the ordered class for the IT losses; the ordered class
for the AT and OLR-NLL losses. Note that the AD loss has no bias parameters.
As the labeling procedure, we tried the NNT and EOT labeling for the AD loss; the MT, ST, and EOT
labelings for the Hinge-IT, Hinge-AT and Logistic-IT losses; the MT, ST, LB, and EOT labelings for the
Logistic-AT and OLR-NLL losses. When using the ordered BPs class, the MT and ST labeling yield the
same result (see Proposition 2). Also, for the Logistic-AT and OLR-NLL losses with the ordered BPs class,
MT, ST, and LB labelings yield the same result under the Task-A (see Theorem 3).
Cao et al. (2020) declare that their method, which is a combination of the Logistic-AT loss and ST labeling,
is the state-of-the-art method for the face-age datasets in 2020. Although they used the non-ordered BPs
class, bias parameters of the surrogate risk minimizer are guaranteed to be ordered, and hence using the
ordered BPs class would have made little diﬀerence to the result. Thus, we treated results for the method
with the Logistic-AT loss, ordered BPs class, and ST labeling as their results, in the comparison.
Training and Evaluation During the validation and test phases, models are evaluated based on the
mean zero-one error ( MZE ), the mean absolute deviation error ( MAE ), and the root of the mean squared
error ( RMSE ), which are deﬁned for a classiﬁer 𝑓and𝑚used data points as1
𝑚Í𝑚
𝑖=1ℓzo¹𝑓¹x𝑖º,𝑦𝑖º,
1
𝑚Í𝑚
𝑖=1ℓad¹𝑓¹x𝑖º,𝑦𝑖º, andf1
𝑚Í𝑚
𝑖=1ℓsq¹𝑓¹x𝑖º,𝑦𝑖ºg12, for the Task-Z, Task-A, and Task-S, respectively. Here,
the root operation of the RMSE is only for adjusting the scale of the error and does not aﬀect our discussion
related to the optimality of the EOT labeling.
We ran 50 trials for the various-domain datasets and 10 trials for the face-age datasets, with randomly-set
diﬀerent divisions of training, validation, and test sets and initial parameters of the network. In each trial,
we trained the network using Adam of the learning rate 10 2.5and mini-batch size 256 (or 16 when the
training sample size is less than 256) as an optimization procedure for 500 epochs when 𝑛tot2000 (i.e.,
for the various-domain datasets) or 100 epochs otherwise (i.e., for the face-age datasets). Additionally, for
methods using the EOT labeling, we calculated the threshold parameters according to Algorithm 1at the
end of every training epoch. The above errors were evaluated on the validation set at the end of every
4For numerical stability (to avoid log¹0º), we used an approximation of the NLL loss in which the logarithmic function log¹º
of𝜙nllis replaced to log¹¸10 8ºin the learning procedure.
11Published in Transactions on Machine Learning Research (1/2023)
(a) AD
 (b) Hinge-IT, non-ordered
 (c) Hinge-IT, ordered
(d) Hinge-AT, ordered
 (e) Logistic-IT, non-ordered
 (f) Logistic-IT, ordered
(g) Logistic-AT, ordered
 (h) OLR-NLL, ordered
Figure 1: The learning curves of the training and test errors over 100 training epochs in a certain trial.
These are for a special case for the AFAD dataset and the RMSE for the Task-S. In Figures ( c), (d), and
(f)–(h), the ST and MT labelings yield the same curves.
training epoch, and then we adopted the model at the timing with the smallest error among the obtained
validation error sequences as the test model.
We judge the signiﬁcance on the classiﬁcation performance of the labeling function by the one-sided Wilcoxon
rank sum test with 𝑝-value 0.05 based on errors for all the trials of methods using diﬀerent labeling functions,
in each combination of the dataset, error, surrogate loss function, and BPs class.
Results Figure 1shows the learning curves of the training and test errors. The EOT labeling results in
smaller training errors as its design to do, which appears to in turn result in smaller test errors. Also, we can
ﬁnd that the EOT labeling may stabilize (or smooth) the learning curve from Figures ( e) and ( f). Tables 2,
3, and 4show the mean and standard deviation of the errors, for the test model, evaluated on the test set.
In many tried cases, the EOT labeling outperformed the NNT, MT, ST, and LB labelings regarding the
test task risk. In particular, for the face-age datasets, modiﬁed 1DT-based methods using the EOT labeling
provided better performance than the method (Logistic-AT, Ordered, ST) in Cao et al. (2020) that was the
state-of-the-art in 2020. These results suggest the success of the EOT labeling in the subject (aiming for a
better labeling procedure) of our research.
7 Conclusion and Future Prospect
The NNT, MT, and ST labelings and the LB labeling in typical usages are threshold labelings that may be
sub-optimal depending on the learning result of the 1DT, task under consideration, and data distribution.
In this study we propose to change the labeling procedure of the existing 1DT-based methods to the EOT
labeling that applies the threshold parameters minimizing the empirical task risk for a given 1DT, in order to
obtain higher classiﬁcation performance. Experiments in this paper showed the usefulness of this proposal.
We are also interested in the design of the learning procedure, especially the selection of the surrogate loss
function, for the threshold method. One may be able to undertake systematic discussion on the goodness of
the loss function by ﬁxing components of the threshold method other than the loss function to the optimal
ones. In such discussion, the EOT labeling will serve as the optimal other component. This is a future
prospect.
12Published in Transactions on Machine Learning Research (1/2023)
Table 2: Mean (M) and standard deviation (S) of the test MZE for Task-Z and RW datasets in the form
‘MS’. The smaller the error, the better that method is for that dataset and that task. In each block speciﬁed
with the dataset, error, and learning procedure, we highlighted in bold font the best results that were tied
with each other and superior to all other results with respect to the one-sided Wilcoxon rank sum test with
a signiﬁcance level of 0.05, if they exist. Also, we colored the best results in red for each combination of
dataset and error.
Learning Labeling COL PAS SQ1 SQ2 BON TAE AUT NEW TOY ESL
ADNNT.364.207.345.126.360.162.365.141.497.163.427.085.280.082.035.024.102.045.311.046EOT.380.197.333.134.376.154.353.132.503.159.432.089.290.077.037.024 .085 .042.295 .038
Hinge-ITMT.364.177.385.148.395.161.356.133.512.154.461.096.291.095.039.024.080.038.320.048
non-orderedST.364.177.385.148.395.161.356.133.512.154.461.096.290.093.039.024.080.038.320.048EOT.380.180.335.138.367.137.345.127.477.152.431.087.280.074.034.025 .069 .041.285 .045
Hinge-IT MT,ST .356.185.395.157.420.157.389.135.537.166.451.098.293.082.033.028.065.037.303.042ordered EOT .364.182 .333 .143.384.129.376.140.520.159 .414 .078.287.080.035.030.064.032 .289 .040
Hinge-AT MT,ST .388.206.367.159.396.155.373.133.503.146.448.084.288.091.032.025.074.036.303.037ordered EOT .332.177.320.150.396.158.351.132.485.128 .419 .089.293.082.034.027.072.034 .288 .040
Logistic-ITMT.364.186.398.171.442.154.433.143.560.183.415.093.338.079.038.029.071.033.313.053
non-orderedST.364.186.398.171.442.154.433.143.560.183.415.093.309.072.038.029.071.033.312.053EOT.352.194.355.128.391.143 .356 .128.513.142.404.088 .297 .085.034.028.068.034 .294 .040
Logistic-IT MT,ST .364.207.395.142.444.152.418.141.552.169.410.083.307.092.034.025.064.038.297.039ordered EOT .344.200 .345 .140.413.149.373.139.528.128.397.078.299.084.032.022.061.039.292.037
Logistic-ATMT,ST.360.230.375.125.476.137.427.140.633.167.422.080.281.075.033.024.060.035.303.042
orderedLB.348.203.385.152.451.149.415.134.522.158.420.081.291.097.043.040.060.035.303.043EOT.308.197 .355 .133.389.130 .376 .138.520.143.408.086.284.084.034.026.057.031.298.040
OLR-NLLMT,ST.384.243.390.129.467.132.424.140.577.167.406.079.294.084.043.040.063.034.301.045
orderedLB.372.212.393.170.455.144.418.150.548.146.422.081.281.074.043.036.063.034.299.042EOT.340.193.352.132.393.148.371.132 .490 .149.410.089.291.070.031.025.058.028.294.040
Learning Labeling BAS EUQ LEV ERA SWD WQR CAR MORPH CACD AFAD
ADNNT.089.025.385.044.385.026.754.027.411.028.392.026.014.009.875.005.927.002.882.002EOT .067 .029.388.044.384.027 .733 .032.412.025.395.023.013.008.874.003 .925 .001.878 .002
Hinge-ITMT.031.021.402.042.402.028.739.034.413.031.395.027.009.005.882.003.939.002.902.003
non-orderedST.031.021.402.042.402.028.739.034.413.031.395.027.009.005.881.003.939.002.909.002EOT.027.017 .385 .046.387 .025.732.036.416.027.395.026 .008 .005.882.003.937.003.889 .002
Hinge-IT MT,ST .032.022.389.048.382.024.734.035.417.031.409.023.007.005.882.003.958.002.905.006ordered EOT .025.013 .375 .043.385.025.732.030.414.026 .399 .025.007.005.880.003 .949 .002.886 .003
Hinge-AT MT,ST .055.036.395.047.387.029.750.027.413.032.396.027.007.004.873.005.928.002.882.002ordered EOT .031 .016.386.047.387.026 .728 .029.414.027.402.024.007.005.874.004 .926 .001.878 .002
Logistic-ITMT.024.020.420.051.390.030.744.029.414.036.393.023.017.007.884.003.937.001.887.004
non-orderedST.024.020.420.051.390.030.744.029.414.036.394.021.018.008.885.003.936.002.895.002EOT .015 .014.388 .048.387.026 .734 .033.414.031 .384 .021.010 .006.883.004.936.002 .882 .002
Logistic-IT MT,ST .024.023.407.043.385.029.725.031.416.033.390.024.011.006.893.004.947.002.881.002ordered EOT .016 .013.389.050.386.026.729.031.412.030.389.025.010.006.890.002.946.002.882.002
Logistic-ATMT,ST.019.017.414.039.383.028.731.026 .413 .034.397.022.012.006.874.005.929.004.883.002
orderedLB.018.012.399.047.386.029.758.026.418.031.397.022.011.006.874.006.930.005 .880 .002EOT.016.011.383.046.389.025.732.030 .412 .028.393.020.011.006.872.006.929.004 .879 .003
OLR-NLLMT,ST.018.015.414.051.380.025 .725 .035.411.033.394.025.010.005.871.005.926.002.878.002
orderedLB.017.012.395.045.383.029.747.027.419.030.392.024.010.005.870.005.926.003 .876 .002EOT.015.012 .376 .047.384.026 .733 .032.410.031.394.026.010.005.871.004.925.002 .876 .003
Acknowledgments
This work was supported by Grant-in-Aid for JSPS Fellows, Number 20J23367.
References
Shivani Agarwal. Generalization bounds for some ordinal regression algorithms. In Algorithmic Learning
Theory , pp. 7–21, 2008.
Alan Agresti. Analysis of Ordinal Categorical Data , volume 656. John Wiley & Sons, 2010.
Peter L Bartlett, Michael I Jordan, and Jon D McAuliﬀe. Convexity, classiﬁcation, and risk bounds. Journal
of the American Statistical Association , 101(473):138–156, 2006.
13Published in Transactions on Machine Learning Research (1/2023)
Table 3: A counterpart of Table 2regarding MAE for Task-A and RW datasets.
Learning Labeling COL PAS SQ1 SQ2 BON TAE AUT NEW TOY ESL
ADNNT.492.272.352.141.373.171.382.154.555.176.587.122.365.129.035.024.102.045.321.048EOT.512.272.338.142.391.166.369.145.535.170.550.117.369.105.037.024 .085 .042.303 .037
Hinge-ITMT.500.266.407.195.418.187.371.149.580.189.601.138.406.168.039.024.080.038.333.052
non-orderedST.500.266.407.195.418.187.371.149.580.189.601.138.403.168.039.024.080.038.333.052EOT.464.257.345.153.378.150.360.142.527.211.572.120.391.151.034.025 .069 .041.294 .038
Hinge-IT MT,ST .492.269.400.164.440.184.409.151.593.203.582.137.380.130.033.028.065.037.320.048ordered EOT .468.261.338.146.398.143.387.152.555.165.545.121.384.156.035.030.064.032 .300 .038
Hinge-AT MT,ST .504.281.372.174.407.170.389.143.558.187.567.119.372.130.032.025.074.036.317.040ordered EOT .448.273.338.168.398.168.364.147.520.163.552.131.379.122.034.027.072.034 .304 .040
Logistic-ITMT.516.274.420.215.484.192.456.156.630.244.544.153.420.109.039.029.071.033.322.061
non-orderedST.516.274.420.215.484.192.456.156.627.236.544.153.384.098.039.029.071.033.320.060EOT.468.290.360.151 .409 .165.369 .140.575.195.508.119.380.121.034.028.068.034.303.040
Logistic-IT MT,ST .508.303.403.172.484.188.440.156.600.192.521.129.390.125.034.025.064.038.312.043ordered EOT .464.290.365.171.425.174 .385 .152.565.163.519.126.389.130.032.022.061.039.304.039
Logistic-AT MT,ST,LB .484.291.410.198.484.184.436.144.573.200.538.124.369.110.043.040.060.035.314.044ordered EOT .420.281.360.155 .407 .149.389.151.563.190.521.114.364.117.034.026.057.031.307.042
OLR-NLL MT,ST,LB .516.300.417.210.489.185.440.161.597.184.519.119.366.110.043.036.063.034.310.043ordered EOT .464.284 .352 .149.413 .168.384 .146.555.185.509.111.380.111 .031 .025.058.028.304.037
Learning Labeling BAS EUQ LEV ERA SWD WQR CAR MORPH CACD AFAD
ADNNT.109.039.424.058.413.031 1.236.069.429.035.430.029.014.009 2.931.025 5.243.029 3.352.024EOT .080 .032.423.054.413.030 1.231.072.428.031.432.028.013.009 2.918.033 5.238.029 3.349.020
Hinge-ITMT.035.026.453.051.435.035 1.243.073.432.034.428.031.009.005 3.183.022 5.937.215 4.029.057
non-orderedST.035.026.453.051.435.035 1.243.073.432.034.428.031.009.005 3.173.017 5.939.217 3.979.063EOT.033.023 .424 .061.412 .029 1.232.068.431.031.429.031 .008 .0053.099 .0215.742 .0653.740 .027
Hinge-IT MT,ST .035.024.431.058.414.029 1.245.074.437.037.446.027.007.005 3.349.040 8.052.279 4.694.116ordered EOT .029.019.417.053.413.030 1.229.075.430.027.437.027.007.0053.204 .0326.581 .0573.761 .107
Hinge-AT MT,ST .066.046.435.059.417.031 1.222.062.433.038.433.031.007.004 2.881.033 5.264.030 3.582.090ordered EOT .043 .023.422.062.413.030 1.226.063.431.034.435.029.007.005 2.863.0225.242 .0343.390 .018
Logistic-ITMT.026.024.463.057.425.036 1.262.073.438.037.430.026.017.007 3.189.049 5.758.101 3.796.080
non-orderedST.026.024.463.057.425.036 1.262.073.438.037.429.026.018.009 3.188.049 5.757.103 3.732.038EOT .017 .018.425 .064.414.0311.228 .070.436.034.421.026 .010 .0063.124 .0335.631 .0933.538 .030
Logistic-IT MT,ST .027.027.456.052.416.030 1.239.076.440.033.426.026.011.006 3.742.084 6.685.131 4.082.043ordered EOT .019.016 .432 .062.413.026 1.226.069.436.031.428.027.010.0063.540 .0386.359 .0423.619 .023
Logistic-AT MT,ST,LB .017.015 .409 .056.412.029 1.225.068.433.032.429.027.010.005 2.874.037 5.381.138 3.375.033ordered EOT .020.014.438.052.416.032 1.233.063.437.034.431.023.011.006 2.856.030 5.342.128 3.367.025
OLR-NLL MT,ST,LB .018.015 .407 .055.416.030 1.230.069.434.035.432.025.011.006 2.873.043 5.243.034 3.345.020ordered EOT .019.015.433.057.417.029 1.234.067.436.035.427.026.010.005 2.845.037 5.228.041 3.343.017
Paul-Christian Bürkner and Matti Vuorre. Ordinal regression models in psychology: A tutorial. Advances
in Methods and Practices in Psychological Science , 2(1):77–101, 2019.
Wenzhi Cao, Vahid Mirjalili, and Sebastian Raschka. Rank consistent ordinal regression for neural networks
with application to age estimation. Pattern Recognition Letters , 140:325–331, 2020.
Bor-Chun Chen, Chu-Song Chen, and Winston H Hsu. Cross-age reference coding for age-invariant face
recognition and retrieval. In Proceedings of the European Conference on Computer Vision , pp. 768–783,
2014.
Wei Chu and Zoubin Ghahramani. Gaussian processes for ordinal regression. Journal of Machine Learning
Research , 6(Jul):1019–1041, 2005.
Wei Chu and S Sathiya Keerthi. New approaches to support vector ordinal regression. In Proceedings of the
International Conference on Machine Learning , pp. 145–152, 2005.
Wei Chu and S Sathiya Keerthi. Support vector ordinal regression. Neural Computation , 19(3):792–815,
2007.
Jacob Cohen. A coeﬃcient of agreement for nominal scales. Educational and Psychological Measurement , 20
(1):37–46, 1960.
14Published in Transactions on Machine Learning Research (1/2023)
Table 4: A counterpart of Table 2regarding RMSE for Task-S and RW datasets.
Learning Labeling COL PAS SQ1 SQ2 BON TAE AUT NEW TOY ESL
ADNNT.779.343.593.144.613.193.630.145.821.194.883.116.730.164.167.085.310.075.589.056EOT.827.324.576.161.633.167.617.145.797.171 .828 .109.748.149.173.084 .281 .075.574.045
Hinge-ITMT.799.319.652.194.676.190.609.171.866.214.884.124.767.199.179.084.275.068.604.067
non-orderedST.799.319.652.194.676.190.609.171.866.214.884.124.765.200.179.084.275.068.604.067EOT.760.326.584.171.614.169.601.168 .793 .210.857.110.753.161.160.091 .253 .074.570 .046
Hinge-IT MT,ST .789.331.633.156.694.186.649.156.837.204.885.140.745.164.154.095.243.078.591.060ordered EOT .763.325.571.178.642.149.618.166.791.147.848.105.736.151.159.101.242.071.570.051
Hinge-AT MT,ST .786.307.596.194.646.172.628.164.817.199.866.116.741.171.153.092.264.066.598.052ordered EOT .752.343.569.209.638.165.601.166.757.160.834.097.750.156.157.095.260.064 .569 .043
Logistic-ITMT.812.330.656.222.734.193.695.142.875.242.846.132.789.186.175.094.258.064.589.065
non-orderedST.812.330.656.222.734.193.695.142.870.233.846.132.774.192.175.094.258.064.586.064EOT.754.345.597.169 .650 .173.608 .158.806.194.807.100.745.146.161.091.252.068.566.049
Logistic-IT MT,ST .790.352.644.182.723.188.680.144.842.186.837.124.753.159.159.091.239.082.583.055ordered EOT .779.342.611.199 .663 .173.624 .145.793.160.809.110.742.164.160.082.230.091.572.047
Logistic-ATMT,ST.722.368.614.187.685.176.639.144.797.205.812.112.736.150.182.094.234.080.585.046
orderedLB.757.361.655.202.729.181.680.134.815.197.825.117.726.153.182.098.230.082.582.049EOT.732.346.601.178.651.160.623.163.802.199.813.110.720.141.162.086.224.080 .565 .047
OLR-NLLMT,ST.795.347.634.158.706.177.640.153.800.180.821.118.741.157.166.096.239.071.582.051
orderedLB.795.351.651.221.735.182.680.146.830.168.833.111.736.153.184.097.240.073.578.049EOT.754.351.587.161.655.174.620.159.787.181.812.107.751.156.153.089.231.066.569.048
Learning Labeling BAS EUQ LEV ERA SWD WQR CAR MORPH CACD AFAD
ADNNT.391.075.712.062.697.036 1.623.094.684.035.710.030.113.044 3.962.040 7.395.027 4.571.032EOT .341 .069.719.057.698.036 1.589.077.676.030.721.033.108.044 3.942.039 7.410.0354.534 .027
Hinge-ITMT.187.097.748.058.711.039 1.657.092.689.036.708.028.088.033 4.273.028 8.009.277 5.435.086
non-orderedST.187.097.748.058.711.039 1.657.092.689.036.708.028.088.033 4.272.024 8.003.276 5.301.072EOT.190.097 .711 .068.695 .0351.586 .072.681.031.712.030 .081 .0334.137 .0437.721 .0604.927 .024
Hinge-IT MT,ST .188.088.727.068.697.037 1.644.083.692.037.722.025.078.036 4.529.04110.098.2766.374.183ordered EOT .180.092.713.062.693.0361.588 .075.679 .029.716.029.077.0364.288 .0388.475 .0604.958 .116
Hinge-AT MT,ST .277.118.726.072.698.036 1.607.086.685.034.707.027.079.033 3.874.046 7.443.044 4.902.130ordered EOT .260.101.714.071.693.034 1.591.077.676.027.711.025.077.036 3.867.031 7.442.0484.550 .024
Logistic-ITMT.151.103.756.074.706.041 1.655.085.696.035.713.032.133.032 4.257.070 7.870.109 5.151.078
non-orderedST.151.103.756.074.706.041 1.655.085.696.035.710.039.135.036 4.255.068 7.869.110 5.058.065EOT.119.101 .708 .062.694.0341.585 .079.684.030.702.026 .094 .0344.172 .0457.620 .0874.706 .036
Logistic-IT MT,ST .148.112.748.062.698.037 1.644.090.694.033.707.029.102.032 5.016.100 8.902.182 5.720.062ordered EOT .134.096 .708 .065.693.0361.592 .078.684.027.709.031.095.0364.726 .0648.320 .0554.798 .035
Logistic-ATMT,ST.140.065 .706 .060.696.035 1.585.077.686.031.708.027.102.033 3.859.043 7.520.096 4.589.053
orderedLB.137.071.731.066.696.038 1.604.081.689.034.710.025.102.033 3.858.043 7.497.0804.517 .040EOT.130.095 .693 .067.694.036 1.587.080.682.032.713.029.099.037 3.841.034 7.494.0534.517 .022
OLR-NLLMT,ST.134.067.706.064.697.033 1.592.081.683.024.710.028.100.025 3.870.037 7.437.061 4.574.031
orderedLB.129.074.724.061.696.032 1.616.085.690.034.710.029.099.025 3.869.036 7.423.0604.508 .029EOT.128.091.699.066.693.035 1.588.079.682.026.708.028.096.030 3.852.044 7.417.0594.510 .025
Jacob Cohen. Weighted kappa: nominal scale agreement provision for scaled disagreement or partial credit.
Psychological Bulletin , 70(4):213, 1968.
Joaquim F Pinto da Costa, Hugo Alonso, and Jaime S Cardoso. The unimodal model for the classiﬁcation
of ordinal data. Neural Networks , 21(1):78–91, 2008.
Stephen E Fienberg and William M Mason. Identiﬁcation and estimation of age-period-cohort models in the
analysis of discrete archival data. Sociological Methodology , 10:1–67, 1979.
Eibe Frank and Mark Hall. A simple approach to ordinal classiﬁcation. In Proceedings of the European
Conference on Machine Learning , pp. 145–156, 2001.
Philip Hans Franses and Richard Paap. Quantitative Models in Marketing Research . Cambridge University
Press, 2001.
Pedro Antonio Gutierrez, Maria Perez-Ortiz, Javier Sanchez-Monedero, Francisco Fernandez-Navarro, and
Cesar Hervas-Martinez. Ordinal regression methods: survey and experimental study. IEEE Transactions
on Knowledge and Data Engineering , 28(1):127–146, 2015.
15Published in Transactions on Machine Learning Research (1/2023)
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition , pp. 770–778, 2016.
R Herbrich, T Graepel, and K Obermayer. Support vector learning for ordinal regression. In International
Conference on Artiﬁcial Neural Networks , volume 1, pp. 97–102, 1999.
Stefan Kramer, Gerhard Widmer, Bernhard Pfahringer, and Michael De Groeve. Prediction of ordinal classes
using regression trees. Fundamenta Informaticae , 47(1-2):1–13, 2001.
Ling Li and Hsuan-Tien Lin. Ordinal regression by extended binary classiﬁcation. In Advances in Neural
Information Processing Systems , pp. 865–872, 2007.
Hsuan-Tien Lin and Ling Li. Large-margin thresholded ensembles for ordinal regression: Theory and practice.
InAlgorithmic Learning Theory , pp. 319–333. Springer, 2006.
Hsuan-Tien Lin and Ling Li. Reduction from cost-sensitive ordinal ranking to weighted binary classiﬁcation.
Neural Computation , 24(5):1329–1367, 2012.
Tie-Yan Liu. Learning to Rank for Information Retrieval . Springer Science & Business Media, 2011.
Peter McCullagh. Regression models for ordinal data. Journal of the Royal Statistical Society: Series B
(Methodological) , 42(2):109–127, 1980.
Zhenxing Niu, Mo Zhou, Le Wang, Xinbo Gao, and Gang Hua. Ordinal regression with multiple output cnn
for age estimation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ,
pp. 4920–4928, 2016.
Fabian Pedregosa, Francis Bach, and Alexandre Gramfort. On the consistency of ordinal regression methods.
Journal of Machine Learning Research , 18(Jan):1769–1803, 2017.
Sebastian Raschka. Mlxtend: Providing machine learning and data science utilities and extensions to
python’s scientiﬁc computing stack. Journal of Open Source Software , 3(24):638, 2018.
Karl Ricanek and Tamirat Tesafaye. Morph: A longitudinal image database of normal adult age-progression.
InProceedings of the IEEE International Conference on Automatic Face and Gesture Recognition , pp. 341–
345, 2006.
Christos Sagonas, Epameinondas Antonakos, Georgios Tzimiropoulos, Stefanos Zafeiriou, and Maja Pantic.
300 faces in-the-wild challenge: Database and results. Image and Vision Computing , 47:3–18, 2016.
Amnon Shashua and Anat Levin. Ranking with large margin principle: Two approaches. In Advances in
Neural Information Processing Systems , pp. 961–968, 2003.
WA Thompson Jr. On the treatment of grouped observations in life studies. Biometrics , pp. 463–470, 1977.
Richard Williams. Generalized ordered logit/partial proportional odds models for ordinal dependent vari-
ables. The Stata Journal , 6(1):58–82, 2006.
Ryoya Yamasaki. Unimodal likelihood models for ordinal data. Transactions on Machine Learning Research ,
2022. URL https:// openreview. net/ forum? id=1l0sClLiPc .
Shipeng Yu, Kai Yu, Volker Tresp, and Hans-Peter Kriegel. Collaborative ordinal regression. In Proceedings
of the International Conference on Machine Learning , pp. 1089–1096, 2006.
16Published in Transactions on Machine Learning Research (1/2023)
A Proof of Consistency of Statistical Methods
We here give proof of the theorem on the interpretation of the learning procedure for statistical methods.
Proof of Theorem 2.We can characterize the surrogate risk minimization for the NLL loss as maximum
likelihood estimation for the statistical model ( 10) for multi-class classiﬁcation problem through the equation
min
𝑎2A,b2BE»𝜙nll¹𝑎¹Xº,b,𝑌;𝜎º¼=min
𝑎2A,b2BE𝐾Õ
𝑦=1Pr¹𝑦jXº𝜙nll¹𝑎¹Xº,b,𝑦;𝜎º
=min
𝑎2A,b2BE
 𝐾Õ
𝑦=1Pr¹𝑦jXºlog𝑃¹𝑦;𝜎,𝑎¹xº,bº
.(15)
According to the method of Lagrange multiplier, one solution of a point-wise (at each X=x) minimization
problem
min
fˆPr¹𝑘jxºg𝑘 𝐾Õ
𝑦=1Pr¹𝑦jxºlogˆPr¹𝑦jxº,subject to𝐾Õ
𝑦=1ˆPr¹𝑦jxº=1 (16)
isˆPr¹𝑦jxº=Pr¹𝑦jxº=𝑃¹𝑦;𝜎,˜𝑎¹xº,˜bº,𝑦=1,...,𝐾 , where the existence of such f˜𝑎¹xº,˜bgis assumed in the
statement of the theorem. This solution applies for any x2R𝑑, and one can see that a solution of ( 15) is
f˜𝑎,˜bg, which completes the proof of the statement for the NLL loss.
Also, for the ANLCL loss, we can provide the following characterization:
E»𝜙anlcl¹𝑎¹Xº,b,𝑌º¼
=E
 𝐾Õ
𝑦=1Pr¹𝑦jXº𝑦 1Õ
𝑘=1logf1 𝑄¹𝑘;𝜎,𝑎¹Xº,bºg¸𝐾 1Õ
𝑘=𝑦log𝑄¹𝑘;𝜎,𝑎¹Xº,bº
= 𝐾 1Õ
𝑦=1E
Pr¹𝑌𝑦jXºlog𝑄¹𝑘;𝜎,𝑎¹Xº,bº¸f 1 Pr¹𝑌𝑦jXºglogf1 𝑄¹𝑦;𝜎,𝑎¹Xº,bºg
,(17)
where𝑄¹𝑦;𝜎,𝑎¹xº,bº≔Í𝑦
𝑘=1𝑃¹𝑘;𝜎,𝑎¹xº,bºand the expectation value E»¼is taken for X. On the ground
of the binary version, ‘ 𝑦or less’ vs. ‘more than 𝑦’ (𝑦=1,...,𝐾 1), of ( 16), one can prove the statement
similarly. □
One may consider the IT loss ( 7) with𝜑¹𝑢º= logf𝜎¹𝑢ºg, which we call immediate negative log cu-
mulative likelihoods (INLCL) loss function . However, it is diﬃcult to characterize the surrogate risk
minimization with the INLCL loss as a problem with a known solution unlike those for the NLL and ANLCL
losses, and the optimality condition for the INLCL loss is unknown.
B Proof of Relationships between Labeling Functions
This section provides proofs of Theorems 3and4regarding the relationships between the LB and threshold
labelings. Propositions 1and2would be trivial, so we omit proofs of them.
First, we prove Theorem 3.
Proof of Theorem 3.We introduce the functions
𝑅𝑗¹𝑢º≔𝐾Õ
𝑘=1f𝜎¹¯𝑏𝑘 𝑢º 𝜎¹¯𝑏𝑘 1 𝑢ºgℓ¹𝑗,𝑘º=ℓ¹𝑗,𝐾º¸𝐾 1Õ
𝑘=1𝜎¹¯𝑏𝑘 𝑢ºfℓ¹𝑗,𝑘º ℓ¹𝑗,𝑘¸1ºgfor𝑗=1,...,𝐾,
(18)
17Published in Transactions on Machine Learning Research (1/2023)
with ¯𝑏0= 1 and ¯𝑏𝐾=¸1, where the equation holds, since 𝜎¹ 1º =0and𝜎¹¸1º =1.
The classiﬁer based on the LB labeling, 𝑓¹xº=arg min𝑗2»𝐾¼Í𝐾
𝑘=1𝑃¹𝑘;𝜎,¯𝑎¹xº,¯bºℓ¹𝑗,𝑘º, is equal to
arg min𝑗2»𝐾¼𝑅𝑗¹¯𝑎¹xºº. According to Proposition 1, the LB labeling is a certain threshold labeling if and
only if arg min𝑗2»𝐾¼f𝑅𝑗¹𝑢1ºg𝐾
𝑗=1arg min𝑗2»𝐾¼f𝑅𝑗¹𝑢2ºg𝐾
𝑗=1for any𝑢1,𝑢22Rsuch that𝑢1𝑢2. The latter
condition holds if the situation
𝑅𝑘¹𝑢º> 𝑅𝑙¹𝑢ºfor𝑢2¹𝑠1,𝑠2ºand𝑅𝑘¹𝑢º< 𝑅𝑙¹𝑢ºfor𝑢2¹𝑠2,𝑠3ºwith𝑘 <𝑙, 𝑠 1<𝑠2<𝑠3 (19)
does not occur. In the following we assume 𝑘 <𝑙 for the indices 𝑘,𝑙2»𝐾¼.
Proof of (i). Under the assumption described in the statement of the theorem, the diﬀerence
𝑅𝑘¹𝑢º 𝑅𝑙¹𝑢º=fℓ¹𝑘,𝐾º ℓ¹𝑙,𝐾ºg|                   {z                   }
non-negative
constant¸𝐾 1Õ
𝑗=1𝜎¹¯𝑏𝑗 𝑢º
|      {z      }
non-negative
non-increasingfℓ¹𝑘,𝑗º ℓ¹𝑘,𝑗¸1º ℓ¹𝑙,𝑗º¸ℓ¹𝑙,𝑗¸1ºg|                                                     {z                                                     }
non-positive
constant(20)
is non-decreasing with respect to 𝑢. Thus,𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor𝑢𝑝and𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor𝑢𝑝for some
point𝑝,𝑅𝑘¹𝑢º 𝑅𝑙¹𝑢ºfor any𝑢, or𝑅𝑘¹𝑢º 𝑅𝑙¹𝑢ºfor any𝑢, which implies that the above-mentioned
situation ( 19) does not occur. Note that, for the instances ℓ=ℓad,ℓsq, one has that
ℓ𝑘,𝑙¹𝑗º=ℓ¹𝑘,𝑗º ℓ¹𝑘,𝑗¸1º ℓ¹𝑙,𝑗º¸ℓ¹𝑙,𝑗¸1º=(
 2 /x31¹𝑘𝑗𝑙 1ºforℓ=ℓad,
2¹𝑘 𝑙º, forℓ=ℓsq.(21)
This completes the proof of the statement (i).
Proof of (ii). Forℓ=ℓzo,𝑐with𝑐2»0,b𝐾2cºwhereℓzo=ℓzo,0, the function 𝑅𝑗¹𝑢ºreduces to
𝑅𝑗¹𝑢º=1 f𝜎¹𝑏𝑗 𝑢º 𝜎¹𝑎𝑗 𝑢ºg, (22)
with𝑎𝑗≔¯𝑏maxf0,𝑗 𝑐gand𝑏𝑗≔¯𝑏minf𝑗¸𝑐,𝐾g, where𝑎𝑗< 𝑏𝑗. Lemma 1(described after the proof of
Theorem 3) shows the shape of the function 𝑅𝑗¹𝑢º: Under the assumption of Theorem 3(ii),𝑅𝑗¹𝑢ºis
minimized at 𝑢=¹𝑎𝑗¸𝑏𝑗º2≔𝑐𝑗, symmetric in 𝑢around𝑢=𝑐𝑗, non-increasing in 𝑢for𝑢 < 𝑐𝑗, and
non-decreasing in 𝑢when𝑢 > 𝑐𝑗, from Lemma 1(i) and (ii). Also, assuming that 𝑐𝑗is ﬁxed, then 𝑅𝑗¹𝑢ºis
non-decreasing in 𝑏𝑗 𝑎𝑗, from Lemma 1(iii).
When𝑏𝑘 𝑎𝑘=𝑏𝑙 𝑎𝑙, the translated two curves 𝑅𝑘¹𝑢ºand𝑅𝑙¹𝑢ºhave just one intersection point at
𝑢=¹𝑐𝑘¸𝑐𝑙º2, and it holds that 𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor𝑢¹𝑐𝑘¸𝑐𝑙º2and𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor𝑢¹𝑐𝑘¸𝑐𝑙º2.
Therefore, the situation ( 19) does not occur if 𝑏𝑘 𝑎𝑘=𝑏𝑙 𝑎𝑙.
Then, assume 𝑏𝑘 𝑎𝑘< 𝑏𝑙 𝑎𝑙(the following proof strategy for this setting can be applied to the other
setting𝑏𝑘 𝑎𝑘> 𝑏𝑙 𝑎𝑙). In this setting, 𝑅𝑘¹𝑢º> 𝑅𝑙¹𝑢ºfor𝑢𝑐𝑙due to the shape of the functions 𝑅𝑘
and𝑅𝑙. Also, within»𝑐𝑘,𝑐𝑙¼, they can have one intersection point 𝑝at most such that 𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor
𝑢2»𝑐𝑘,𝑝¼and𝑅𝑘¹𝑢º𝑅𝑙¹𝑢ºfor𝑢2»𝑝,𝑐𝑙¼, since𝑅𝑘¹𝑢ºand𝑅𝑙¹𝑢ºare respectively non-decreasing and
non-increasing in 𝑢. Therefore, the situation ( 19) can be satisﬁed only in such a situation that there exists
a point𝑝satisfying
𝑅𝑘¹𝑝º=𝑅𝑙¹𝑝º, 𝑅0
𝑘¹𝑝º< 𝑅0
𝑙¹𝑝º,and𝑝𝑐𝑘. (23)
The existence of such a point 𝑝implies that
𝜎0¹𝑎𝑘 𝑝º 𝜎0¹𝑏𝑘 𝑝º
𝜎¹𝑎𝑘 𝑝º 𝜎¹𝑏𝑘 𝑝º<𝜎0¹𝑎𝑙 𝑝º 𝜎0¹𝑏𝑙 𝑝º
𝜎¹𝑎𝑙 𝑝º 𝜎¹𝑏𝑙 𝑝ºwith𝑎𝑘𝑎𝑙, 𝑏𝑘𝑏𝑙, 𝑎𝑘𝑏𝑘, 𝑎𝑙𝑏𝑙, 𝑝𝑐𝑘.(24)
However, the assumption that𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2ºis non-increasing in 𝑣1with ﬁxed𝑣2and in𝑣2with ﬁxed𝑣1when
𝑣1<𝑣2shows that
𝜎0¹𝑎𝑘 𝑝º 𝜎0¹𝑏𝑘 𝑝º
𝜎¹𝑎𝑘 𝑝º 𝜎¹𝑏𝑘 𝑝º𝜎0¹𝑎𝑘 𝑝º 𝜎0¹𝑏𝑙 𝑝º
𝜎¹𝑎𝑘 𝑝º 𝜎¹𝑏𝑙 𝑝º𝜎0¹𝑎𝑙 𝑝º 𝜎0¹𝑏𝑙 𝑝º
𝜎¹𝑎𝑙 𝑝º 𝜎¹𝑏𝑙 𝑝º, (25)
18Published in Transactions on Machine Learning Research (1/2023)
which contradicts to equation ( 24). Therefore, the situation ( 19) does not occur also when 𝑏𝑘 𝑎𝑘<𝑏𝑙 𝑎𝑙.
Note that, especially when 𝜎=𝜎logistic , one can show that
𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2º=𝜎logistic¹𝑣1º¹1 𝜎logistic¹𝑣1ºº 𝜎logistic¹𝑣2º¹1 𝜎logistic¹𝑣2ºº
𝜎logistic¹𝑣1º 𝜎logistic¹𝑣2º
=1 f𝜎logistic¹𝑣1º¸𝜎logistic¹𝑣2ºg,(26)
is decreasing in 𝑣1with ﬁxed𝑣2and in𝑣2with ﬁxed𝑣1. Moreover, when 𝜎=𝜎gauss, one has that
𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2º/𝑒 𝑣2
12 𝑒 𝑣2
22
𝜎gauss¹𝑣1º 𝜎gauss¹𝑣2º≔𝑓1¹𝑣1,𝑣2º, (27)
that the derivative of 𝑓1¹𝑣1,𝑣2ºwith respect to 𝑣1,
𝜕
𝜕𝑣1𝑓1¹𝑣1,𝑣2º= 𝑣1𝑒 𝑣2
12f𝜎gauss¹𝑣1º 𝜎gauss¹𝑣2ºg  𝑒 𝑣2
12 𝑒 𝑣2
221p
2𝜋𝑒 𝑣2
12
f𝜎gauss¹𝑣1º 𝜎gauss¹𝑣2ºg2(28)
has the same sign as
𝑓2¹𝑣1,𝑣2º≔ 𝑣1f𝜎gauss¹𝑣1º 𝜎gauss¹𝑣2ºg 1p
2𝜋𝑒 𝑣2
12 1p
2𝜋𝑒 𝑣2
22
, (29)
and that the derivative of 𝑓2¹𝑣1,𝑣2ºwith respect to 𝑣2is
𝜕
𝜕𝑣2𝑓2¹𝑣1,𝑣2º=¹𝑣1 𝑣2º1p
2𝜋𝑒 𝑣2
22. (30)
Since𝜕
𝜕𝑣2𝑓2¹𝑣1,𝑣2º<0when𝑣1< 𝑣2and𝑓2¹𝑣1,𝑣1º=0, it holds that 𝑓2¹𝑣1,𝑣2º, which has the same sign
as𝜕
𝜕𝑣1𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2º, is negative when 𝑣1< 𝑣2, that is,𝜎0¹𝑣1º 𝜎0¹𝑣2º
𝜎¹𝑣1º 𝜎¹𝑣2ºis decreasing in 𝑣1with ﬁxed𝑣2when
𝑣1<𝑣2; monotonicity in 𝑣2with ﬁxed𝑣1can be proved by the same discussion.
Proof of (iii). Regarding the MT and ST labelings, let 𝑦=ℎthr¹𝑢;¯bºunder the assumption ¯𝑏1 ¯𝑏𝐾 1,
which implies that ¯𝑏1 ¯𝑏𝑦 1𝑢¯𝑏𝑦 ¯𝑏𝐾 1. Regarding the LB labeling for the likelihood
model ( 10), one has that, with the abbreviations 𝜎𝑘≔𝜎¹¯𝑏𝑘 𝑢ºfor𝑘=1,...,𝐾 ,
𝑅𝑗¹𝑢º=𝐾Õ
𝑘=1f𝜎𝑘 𝜎𝑘 1gj𝑗 𝑘j,
=j𝑗 1jf𝜎1 𝜎0g¸j𝑗 2jf𝜎2 𝜎1g¸¸ 2f𝜎𝑗 2 𝜎𝑗 3g¸f𝜎𝑗 1 𝜎𝑗 2g
¸f𝜎𝑗¸1 𝜎𝑗g¸2f𝜎𝑗¸2 𝜎𝑗¸1g¸¸j𝑗 𝐾¸1jf𝜎𝐾 1 𝜎𝐾 2g¸j𝑗 𝐾jf𝜎𝐾 𝜎𝐾 1g
= j𝑗 1j𝜎0|{z}
0¸𝑗 1Õ
𝑘=1𝜎𝑘
 𝐾 1Õ
𝑘=𝑗𝜎𝑘
¸j𝑗 𝐾j𝜎𝐾|{z}
1
=𝑗 1Õ
𝑘=1𝜎¹¯𝑏𝑘 𝑢º¸𝐾 1Õ
𝑘=𝑗f1 𝜎¹¯𝑏𝑘 𝑢ºg,(31)
for every𝑗2»𝐾¼. Simple calculations show that 𝜎¹¯𝑏𝑘 𝑢º0.5for𝑘=1,...,𝑦 1andf1 𝜎¹¯𝑏𝑘 𝑢ºg 0.5
for𝑘=𝑦,...,𝐾 1, from ¯𝑏1 ¯𝑏𝑦 1𝑢¯𝑏𝑦 ¯𝑏𝐾 1and the assumption on the shape of 𝜎. One
would see that objective function ( 31) is minimized at 𝑗=𝑦because some summands are replaced by ones
of 0.5 or more if 𝑗deviates from 𝑦, which concludes the proof. □
The following is an auxiliary lemma for the above-described proof of Theorem 3.
Lemma 1. Suppose that 𝜎is non-decreasing and satisﬁes 𝜎¹ 1º=0and𝜎¹¸1º=1. Deﬁne𝑆¹𝑢;𝑎,𝑏º≔
𝜎¹𝑏 𝑢º 𝜎¹𝑎 𝑢ºfor𝑎 <𝑏 . Then, one has that
19Published in Transactions on Machine Learning Research (1/2023)
(i)𝑆¹𝑢;𝑎,𝑏ºwith ﬁxed𝑎and𝑏is symmetric in 𝑢around𝑢=𝑎¸𝑏
2, if𝜎¹ º=1 𝜎¹º, or if𝜎is
diﬀerentiable and 𝜎0is even.
(ii)𝑆¹𝑢;𝑎,𝑏ºwith ﬁxed𝑎and𝑏is maximized with respect to 𝑢at𝑢=𝑎¸𝑏
2, non-decreasing in 𝑢for
𝑢 <𝑎¸𝑏
2, and non-increasing in 𝑢for𝑢 >𝑎¸𝑏
2, if𝜎is diﬀerentiable and 𝜎0¹𝑢ºis even and non-
increasing in 𝑢if𝑢>0.
(iii)𝑆¹𝑢;𝑎,𝑏ºwith ﬁxed𝑢and𝑎¸𝑏
2is increasing with respect to ¹𝑏 𝑎º.
Proof of Lemma 1.Proof of (i). The assumptions that 𝜎¹ 1º=0,𝜎¹¸1º=1, and𝜎0is even imply that
𝜎¹ º=1 𝜎¹º. On the basis of this result, one then has that
𝑆
𝑢¸𝑎¸𝑏
2;𝑎,𝑏
=𝜎
𝑏 
𝑢¸𝑎¸𝑏
2
 𝜎
𝑎 
𝑢¸𝑎¸𝑏
2
=𝜎𝑏 𝑎
2 𝑢
 𝜎
 𝑏 𝑎
2 𝑢
=𝜎𝑏 𝑎
2 𝑢
 1¸𝜎𝑏 𝑎
2¸𝑢
,(32)
which implies that
𝑆
𝑢¸𝑎¸𝑏
2;𝑎,𝑏
=𝑆
 𝑢¸𝑎¸𝑏
2;𝑎,𝑏
. (33)
Proof of (ii). The above equation ( 32) shows that
𝜕
𝜕𝑢𝑆
𝑢¸𝑎¸𝑏
2;𝑎,𝑏
=𝜎0𝑏 𝑎
2¸𝑢
 𝜎0𝑏 𝑎
2 𝑢
=0,at𝑢=0. (34)
Also, one can show that
𝜕
𝜕𝑢𝑆
𝑢¸𝑎¸𝑏
2;𝑎,𝑏
=𝜎0𝑏 𝑎
2¸𝑢
 𝜎0𝑏 𝑎
2 𝑢
=(
𝜎0 j𝑏 𝑎
2¸𝑢j 𝜎0 𝑏 𝑎
2 𝑢0,for𝑢<0,
𝜎0 𝑏 𝑎
2¸𝑢 𝜎0 j𝑏 𝑎
2 𝑢j0,for𝑢>0.(35)
Here, for𝑢<0, we used the fact that 𝜎0is even, which implies that 𝜎0¹𝑏 𝑎
2¸𝑢º=𝜎0¹j𝑏 𝑎
2¸𝑢jº, and𝜎0¹𝑣ºis
non-increasing in 𝑣for𝑣 >0and𝑏 𝑎
2 𝑢 >j𝑏 𝑎
2¸𝑢j>0; for𝑢 >0, we used the fact that 𝜎0is even, which
implies that 𝜎0¹𝑏 𝑎
2 𝑢º=𝜎0¹j𝑏 𝑎
2 𝑢jº, and𝜎0¹𝑣ºis non-increasing in 𝑣for𝑣 >0and𝑏 𝑎
2¸𝑢>j𝑏 𝑎
2 𝑢j>0.
Proof of (iii). With change of variables 𝑡=𝑏 𝑎
2,𝑣=𝑎¸𝑏
2, we introduce a function
𝑇¹𝑡;𝑢,𝑣º=𝑆¹𝑢;𝑣 𝑡,𝑣¸𝑡º=𝜎¹𝑣 𝑢¸𝑡º 𝜎¹𝑣 𝑢 𝑡º. (36)
For this function, one has that
𝜕
𝜕𝑡𝑇¹𝑡;𝑢,𝑣º=𝜎0¹𝑣 𝑢¸𝑡º¸𝜎0¹𝑣 𝑢 𝑡º0, (37)
since𝜎is non-decreasing (i.e., 𝜎0¹𝑢º0for any𝑢). □
Next, we give a proof of Theorem 4.
Proof of Theorem 4.If𝑘 <𝑙 , the convexity shows that
ℓ¹𝑘,𝑗ºf𝑘 𝑗g f𝑘 ¹𝑗¸1ºg
f𝑙 𝑗g f𝑘 ¹𝑗¸1ºgℓ¹𝑘,𝑗¸1º¸f𝑙 𝑗g f𝑘 𝑗g
f𝑙 𝑗g f𝑘 ¹𝑗¸1ºgℓ¹𝑙,𝑗º
=1
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑙,𝑗º,(38)
20Published in Transactions on Machine Learning Research (1/2023)
and that
ℓ¹𝑙,𝑗¸1ºf𝑙 ¹𝑗¸1ºg f𝑘 ¹𝑗¸1ºg
f𝑙 𝑗g f𝑘 ¹𝑗¸1ºgℓ¹𝑘,𝑗¸1º¸f𝑙 𝑗g f𝑙 ¹𝑗¸1ºg
f𝑙 𝑗g f𝑘 ¹𝑗¸1ºgℓ¹𝑙,𝑗º
=𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸1
𝑙 𝑘¸1ℓ¹𝑙,𝑗º.(39)
These inequalities imply that ℓ𝑘,𝑙is non-positive:
ℓ𝑘,𝑙¹𝑗º
=fℓ¹𝑘,𝑗º¸ℓ¹𝑙,𝑗¸1ºg fℓ¹𝑘,𝑗¸1º¸ℓ¹𝑙,𝑗ºg
=fℓ¹𝑘,𝑗º¸ℓ¹𝑙,𝑗¸1ºg 1
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑙,𝑗º
¸𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸1
𝑙 𝑘¸1ℓ¹𝑙,𝑗º
=
ℓ¹𝑘,𝑗º 1
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑙,𝑗º
¸
ℓ¹𝑙,𝑗¸1º 𝑙 𝑘
𝑙 𝑘¸1ℓ¹𝑘,𝑗¸1º¸1
𝑙 𝑘¸1ℓ¹𝑙,𝑗º
0. (40)
Similarly, one can show that ℓ𝑘,𝑙is non-negative if 𝑘 >𝑙 . □
McCullagh (1980, Section 6.1) has proposed the heteroscedastic extension of the cmulative link model ( 10),
𝑃2¹𝑦;𝜎,𝑎¹xº,b,𝑠¹xºº≔𝑃¹𝑦;𝜎,𝑎¹xº𝑠¹xº,b𝑠¹xºº (41)
with the scale model 𝑠:R𝑑!¹0,1º, and statistical OR studies, Thompson Jr (1977);Fienberg & Mason
(1979) and Agresti (2010, Section 4.2), have also considered another model
𝑃3¹𝑦;𝜎,𝑎¹xº,bº≔𝜎¹𝑏𝑦 𝑎¹xºº𝑦 1Ö
𝑘=1f1 𝜎¹𝑏𝑘 1 𝑎¹xººg. (42)
We obtain the following theorem that is similar to Theorem 3and suggests the eﬃciency of the EOT labeling
for statistical methods adopting these other likelihood models:
Theorem 5. Suppose that 𝜎is non-decreasing and satisﬁes 𝜎¹ 1º=0and𝜎¹¸1º=1and that ¯𝑎:R𝑑!R,
¯b2R𝐾 1, and ¯𝑠:R𝑑!¹0,1º.
(i)arg min𝑗2»𝐾¼Í𝐾
𝑘=1𝑃2¹𝑘;𝜎,¯𝑎¹xº,¯b,¯𝑠¹xººℓ¹𝑗,𝑘º=ℎthr¹¯𝑎¹xº;¯bºifℓ=ℓad,𝜎¹0º=0.5, and ¯𝑏1
¯𝑏𝐾 1.
(ii) arg min𝑗2»𝐾¼Í𝐾
𝑘=1𝑃3¹𝑘;𝜎,¯𝑎¹xº,¯bºℓ¹𝑗,𝑘º=ℎthr¹¯𝑎¹xº;tºfor some t2R𝐾 1ifℓ=ℓad.
Proof of Theorem 5.Proof of (i). The statement (i) of Theorem 5is trivial from the statement (iii) of
Theorem 3.
Proof of (ii). Regarding the LB labeling for the likelihood model ( 42), one has that, with the abbreviations
¤𝜎𝑘≔1 𝜎¹¯𝑏𝑘 ¯𝑎¹xººfor𝑘=1,...,𝐾 ,
𝑅𝑗¹¯𝑎¹xºº≔𝐾Õ
𝑘=1𝑃3¹𝑘;𝜎,¯𝑎¹xº,¯bºℓad¹𝑗,𝑘º
=𝐾Õ
𝑘=1
¹1 ¤𝜎𝑘º𝑘 1Ö
𝑙=1¤𝜎𝑙 1
j𝑗 𝑘j,
=j𝑗 1j¹1 ¤𝜎1º¸j𝑗 2j¤𝜎1¹1 ¤𝜎2º¸¸¤𝜎1¤𝜎𝑗 2¹1 ¤𝜎𝑗 1º
¸¤𝜎1¤𝜎𝑗¹1 ¤𝜎𝑗¸1º¸¸j𝑗 𝐾¸1j¤𝜎1¤𝜎𝐾 2¹1 ¤𝜎𝐾 1º¸j𝑗 𝐾j¤𝜎1¤𝜎𝐾 1
=¹𝑗 1º 𝑗 1Õ
𝑘=1𝑘Ö
𝑙=1f1 𝜎¹¯𝑏𝑙 ¯𝑎¹xººg
¸𝐾 1Õ
𝑘=𝑗𝑘Ö
𝑙=1f1 𝜎¹¯𝑏𝑙 ¯𝑎¹xººg
,(43)
21Published in Transactions on Machine Learning Research (1/2023)
for every𝑗2»𝐾¼. One has that
𝑅𝑗¸1¹¯𝑎¹xºº 𝑅𝑗¹¯𝑎¹xºº=1 2𝑗Ö
𝑙=1f1 𝜎¹¯𝑏𝑙 ¯𝑎¹xººg, (44)
is non-decreasing in 𝑗with ﬁxed ¯𝑎¹xº. Therefore, arg min𝑗2»𝐾¼Í𝐾
𝑘=1𝑃3¹𝑘;𝜎,¯𝑎¹xº,¯bºℓad¹𝑗,𝑘ºis the ﬁrst
index𝑙such that𝑅𝑙¸1¹¯𝑎¹xºº 𝑅𝑙¹¯𝑎¹xºº  0, or𝐾if𝑅𝑙¸1¹¯𝑎¹xºº 𝑅𝑙¹¯𝑎¹xºº>0for all𝑙=1,...,𝐾 1.
Also,𝑅𝑙¸1¹¯𝑎¹xºº 𝑅𝑙¹¯𝑎¹xººis non-increasing in ¯𝑎¹xº, for each𝑙=1,...,𝐾 1. These facts show that
arg min𝑗2»𝐾¼Í𝐾
𝑘=1𝑃3¹𝑘;𝜎,¯𝑎¹xº,¯bºℓad¹𝑗,𝑘º=ℎthr¹¯𝑎¹xº;tºwith the threshold parameters 𝑡𝑘,𝑘=1,...,𝐾 1
satisfying𝑅𝑘¸1¹𝑡𝑘º 𝑅𝑘¹𝑡𝑘º=0. □
C Optimality Guarantee of Algorithm for Empirical Optimal Threshold Labeling
Lin & Li (2006) do not describe the optimality guarantee of Algorithm 1in their paper. As a supplement
to their development, we write here the optimality guarantee of Algorithm 1.
Theorem 6. For any task loss ℓ:»𝐾¼2!»0,1º, 1DT ¯𝑎, and training data D𝑛=f¹x𝑖,𝑦𝑖ºg𝑛
𝑖=1, the threshold
parameters ¯tobtained by Algorithm 1minimize the empirical task risk for a classiﬁer based on the threshold
labeling: ¯t2arg mint2R𝐾 11
𝑛Í𝑛
𝑖=1ℓ¹ℎthr¹¯𝑎¹x𝑖º;tº,𝑦𝑖º.
Proof of Theorem 6.First, we prove ‘statement( 𝑗)’ that, for each 𝑘2»𝐾¼,𝐿𝑗,𝑘is the minimum task risk for
a task such that 1DTs f¯𝑎¹x𝑖ºj¯𝑎¹x𝑖º=¯𝑎1g,...,f¯𝑎¹x𝑖ºj¯𝑎¹x𝑖º=¯𝑎𝑗 1gare predicted as any of 1,...,𝑘 in a
non-decreasing manner, and 1DTs f¯𝑎¹x𝑖ºj¯𝑎¹x𝑖º=¯𝑎𝑗gare predicted as 𝑘:
𝐿𝑗,𝑘= min
ℎ1,...,ℎ𝑗2»𝑘¼
s.t.ℎ1ℎ𝑗=𝑘Õ
𝑙2»𝑗¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚º (45)
The statement( 1), which is the starting point for mathematical induction, is trivial. Also, according to the
equation,
𝐿𝑗¸1,𝑘=min
𝑙2»𝑘¼𝐿𝑗,𝑙¸Õ
𝑦𝑖2Y𝑗¸1ℓ¹𝑘,𝑦𝑖º
=min
𝑙2»𝑘¼
min
ℎ1,...,ℎ𝑗2»𝑙¼
s.t.ℎ1ℎ𝑗=𝑙Õ
𝑙2»𝑗¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚º
¸Õ
𝑦𝑖2Y𝑗¸1ℓ¹𝑘,𝑦𝑖º
= min
ℎ1,...,ℎ𝑗¸12»𝑘¼
s.t.ℎ1ℎ𝑗=𝑙ℎ𝑗¸1=𝑘Õ
𝑙2»𝑗¸1¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚ºwith𝑙=arg min
𝑙2»𝑘¼
min
ℎ1,...,ℎ𝑗2»𝑙¼
s.t.ℎ1ℎ𝑗=𝑙Õ
𝑙2»𝑗¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚º
= min
ℎ1,...,ℎ𝑗¸12»𝑘¼
s.t.ℎ1ℎ𝑗¸1=𝑘Õ
𝑙2»𝑗¸1¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚º,(46)
one can ﬁnd that the statement( 𝑗¸1) holds with 𝑗1as well.
The statement( 𝑁) shows that 1DTs f¯𝑎¹x𝑖ºj¯𝑎¹x𝑖º=¯𝑎𝑁gshould be labeled as min¹arg min𝑙2»𝐾¼𝐿𝑁,𝑙º≔𝑀.
Also, for
¹¯ℎ1,..., ¯ℎ𝑁º2 arg min
ℎ1,...,ℎ𝑁2»𝑀¼
s.t.ℎ1ℎ𝑁=𝑀Õ
𝑙2»𝑁¼Õ
𝑦𝑚2Y𝑙ℓ¹ℎ𝑙,𝑦𝑚º, (47)
it will also be clear that 1DTs f¯𝑎¹x𝑖º j ¯𝑎¹x𝑖º=¯𝑎1g,...,f¯𝑎¹x𝑖º j ¯𝑎¹x𝑖º=¯𝑎𝑁 1gshould be labeled as
¯ℎ1,..., ¯ℎ𝑁 1. The index 𝐼or𝐽in Lines 9–15tracks ¯ℎ𝑁¹=𝑀º,¯ℎ𝑁 1,..., ¯ℎ1. Therefore, it can be found that
the obtained threshold parameters are optimal. □
22Published in Transactions on Machine Learning Research (1/2023)
Table 5: Dataset properties, the total sample size 𝑛tot, and the dimension 𝑑of the explanatory variables,
of classes of the target variable, of the benchmark datasets used for the experiments in Appendix D. Note
that AMP originally has 6 missing values and we excluded them.
DIA PYR APR SER TRI WBC CPU AMP BOS STO
𝑛tot 43 74 159 167 186 194 209 392 506 950
𝑑 2 27 15 4 60 32 6 7 13 9
ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
𝑛tot 4177 7129 8192 8192 8192 8912 8912 8192 8192 9517
𝑑 8 5 8 8 8 12 21 32 32 6
POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
𝑛tot 13750 15000 16599 20640 22784 22784 40768 40768 40768
𝑑 40 48 18 8 8 16 10 10 10
D Additional Experiments with Benchmark Datasets
Purpose Many OR studies use datasets, which are generated by discretizing a real-valued target of bench-
mark datasets commonly used for evaluation in a regression task, in their experiments. For example,
Frank & Hall (2001) applied regression benchmark datasets summarized in https:// www. dcc. fc.up.pt/
~ltorgo/ Regression/ DataSets. html , and experimented with datasets generated via the discretization into
3/5/10 equal-frequency bins. Also, Chu & Ghahramani (2005) tried the discretization into 5/10 equal-length
bins in addition to the 5/10 equal-frequency discretization. Therefore, we performed similar experiments
additionally to enforce our claim, and this section describes results of these experiments.
Settings In the experiments, as regression benchmark datasets, we use 29 datasets, DIA (Diabetes),
PYR (Pyrimidines), APR (Auto Price), SER (Servo), TRI (Triazines), WBC (Wisconsin Breast Can-
cer), CPU (Machine CPU), AMP (Auto MPG), BOS (Boston Housing), STO (Stocks Domain), ABA
(Abalone), AI2 (Delta Ailerons), KRA (Kinematics of Robot Arm), CO1 (Computer Activity (1)), PU1
(Pumadyn Domain (1)), BA1 (Bank Domain (1)), CO2 (Computer Activity (2)), PU2 (Pumadyn Do-
main (2)), BA2 (Bank Domain (2)), EL2 (Delta Elevators), POT (Pole Telecomm), AI1 (Ailerons),
EL1 (Elevators), CAL (California Housing), CE1 (Census (1)), CE2 (Census (2)), 2DP (2D Planes),
FRA (Friedman Artiﬁcial), MVA (MV Artiﬁcial), which are obtainable in https:// www. dcc. fc.up.
pt/~ltorgo/ Regression/ DataSets. html , a researchers’ site of Chu & Ghahramani (2005) (http:// www.
gatsby. ucl. ac.uk/~chuwei/ ordinalregression. html ), our GitHub repository ( https:// github. com/
yamasakiryoya/ OTL); see also Table 5. As the discretization manner, we tried 3/5/10 equal-frequency/length
discretization; we denote these generated datasets, for example, as EF3 and EL10 datasets. We adopted
the same neural network model applied for the RW datasets. All other settings are the same as those in
Section 6.
Results Tables 6–23show the mean and standard deviation of the test errors. Table 24summarizes all
the results: the column ‘SUM’ shows that the EOT labeling was superior to existing other labelings for all
learning methods and tasks, and reinforces our claim regarding the usefulness of the EOT labeling.
23Published in Transactions on Machine Learning Research (1/2023)
Table 6: A counterpart of Table 2regarding MZE for Task-Z and EF3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.558.163.388.119.150.060.206.076.513.090.596.082.261.062.204.045.250.034.079.017EOT.576.161.372.129.145.065.198.070.518.076.589.080.260.062 .185 .041.248.038.080.023
Hinge-ITMT.534.161.388.107.159.060.198.070.501.089.580.081.264.063.206.048.245.038.079.018
non-orderedST.534.161.388.107.159.060.198.070.501.089.580.081.264.063.206.048.245.038.079.018EOT.568.135.379.110.154.048.208.067.488.088.579.077.254.055 .184 .041.247.038.075.018
Hinge-IT MT,ST .536.153.391.102.152.052.211.070.511.081.583.090.256.065.197.043.244.039.079.017ordered EOT .544.127.365.116.148.052.199.061.510.083.575.082.256.060.190.037.250.036.076.019
Hinge-AT MT,ST .582.155.388.100.152.060.207.068.497.093.595.086.252.063.201.045.243.037.077.017ordered EOT .554.140.363.108.147.053.212.065.505.089.584.099.265.062.193.040.245.037.077.020
Logistic-ITMT.538.167.384.114.158.066.217.060.483.092.587.094.242.063.196.047.241.036.077.018
non-orderedST.538.167.384.114.158.066.217.060.483.092.587.094.242.063.196.047.241.036.077.018EOT.538.171.385.119.146.047.215.047.481.079.568.088.247.061 .178 .039.234.037.081.022
Logistic-IT MT,ST .536.156.400.099.153.068.229.082.475.081.571.092.255.070.195.044.232.038.073.018ordered EOT .550.158.377.095.134.044.219.060.486.082.559.082.252.065.183.033.229.040.074.019
Logistic-ATMT,ST.542.148.397.106.149.063.221.071.487.079.584.085.249.061.191.045.220.032.074.018
orderedLB.580.159.395.104.148.064.218.064.491.081.575.088.245.063.192.038.221.034.075.019EOT.536.167.385.115.136.046.215.063.503.082.580.088.252.065.181.038.227.040.076.016
OLR-NLLMT,ST.552.175.415.104.155.064.214.063.489.089.576.095.250.067.190.040.228.036.073.020
orderedLB.590.136.388.105.146.064.218.067.487.096.591.095.245.071.197.049.223.035.073.020EOT.560.172.392.105.136.049.212.065.486.088.569.103.253.069.177.037.227.039.076.018
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.351.018.350.012.179.008.171.008.321.012.107.008.200.010.167.008.339.011.350.010EOT.351.016.350.011 .176 .009.171.008.323.013.107.008.199.009.166.008.340.010.348.010
Hinge-ITMT.347.015.353.011.157.010.168.008.318.011.102.008.201.011.163.009.340.010.347.011
non-orderedST.347.015.353.011.157.010.168.008.318.011.102.008.201.011.163.009.340.010.347.011EOT.350.017.350.010.156.009.167.009.318.010.102.008.198.010 .160 .009.339.010.347.010
Hinge-IT MT,ST .349.017.354.011.157.010.169.008.321.011.101.008.200.009.159.009.340.010.348.011ordered EOT .349.016 .350 .011.157.009.168.008.318.010.101.008.198.010.158.009.338.010.348.010
Hinge-AT MT,ST .358.017.352.011.156.010.169.008.322.012.101.008.199.010.160.008.341.011.350.010ordered EOT .350 .017.352.011.158.011.168.008.320.010.100.008.198.009.158.009.339.010.347.011
Logistic-ITMT.347.017.348.010.154.009.166.009.319.011.101.007.195.008.174.009.342.011.348.011
non-orderedST.347.017.348.010.154.009.166.009.319.011.101.007.195.008.174.009.342.011.348.011EOT.347.015.347.010.153.008.166.008.319.009.101.008.195.008 .157 .008.340.011.347.010
Logistic-IT MT,ST .349.017.347.010.153.010.167.009.318.010.101.007.196.009.160.009.342.011.349.012ordered EOT .348.016.348.010.152.008.167.008.319.010.100.008.194.009.159.009.339.011.346.011
Logistic-ATMT,ST.348.017.347.010.154.009.167.009.319.010.101.008.197.007.158.009.342.012.349.010
orderedLB.351.017.348.010.154.010.167.008.319.009.101.008.197.009.158.010.342.013.351.011EOT.350.016.349.010.153.010.168.009.319.009.100.008.196.008.156.009.343.015.348.011
OLR-NLLMT,ST.348.017.348.010.152.010.167.009.318.010.101.007.195.008.158.008.341.012.349.011
orderedLB.351.017.347.010.152.009.166.009.318.010.101.007.196.008.158.009.340.011.350.011EOT.349.015.349.010.153.010.167.008.318.011.100.008.194.007.156.009.341.012.347.011
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.315.006.243.007.300.009.258.006.292.007.267.006.134.003.119.003.010.008EOT.315.008.243.008.299.008.257.006.290.007.266.006.134.003.118.003.009.008
Hinge-ITMT.365.015.239.008.298.007.248.006.325.006.301.008.149.008.121.004.007.001
non-orderedST.365.015.239.008.298.007.248.006.325.006.301.008.149.008.121.004.007.001EOT .359 .012.241.008.297.008.247.006 .321 .006.296 .007.137 .003.120 .004.007 .001
Hinge-IT MT,ST .311.008.239.008.298.008.248.007.288.008.266.006.134.003.120.004.007.001ordered EOT .311.007.240.008.297.007.247.007.287.007.265.006.133.003 .119 .004.007 .001
Hinge-AT MT,ST .314.008.239.008.299.008.252.007.290.007.269.007.134.003.120.004.009.008ordered EOT .314.008.239.007.297.007.252.007.288.007 .267 .007.134.003.119.004.008.007
Logistic-ITMT.313.008.235.007.296.008.238.007.282.006.290.006.133.003.121.004.006.001
non-orderedST.313.008.235.007.296.008.238.007.282.006.290.006.133.003.121.004.006.001EOT.311.007.235.008.296.008.237.007.281.007 .286 .006.133.003 .119 .004.005 .001
Logistic-IT MT,ST .313.008.235.008.297.007.239.007.282.006.263.007.133.004.116.004.009.012ordered EOT .311.007.235.008.296.008.238.007.281.007.262.007.133.003.116.004 .008 .012
Logistic-ATMT,ST.312.007.235.008.298.008.241.008.282.006.297.008.133.003.119.004.021.024
orderedLB.312.007.236.008.298.008.241.007.283.006.297.008.133.003.120.004.021.024EOT.310.007.235.007.298.008.240.007.280.006.295.007.133.003.119.004.020.023
OLR-NLLMT,ST.313.007.235.007.298.008.239.007.281.007.290.007.134.003.119.004.017.022
orderedLB.312.007.235.008.297.008.239.007.282.006.290.007.134.003.119.004.017.022EOT.311.007.236.008.298.008.239.007.281.007.288.006.133.003.118.004 .016 .021
24Published in Transactions on Machine Learning Research (1/2023)
Table 7: A counterpart of Table 2regarding MZE for Task-Z and EF5 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.712.146.568.132.397.089.326.079.677.065.757.061.445.072.319.048.347.043.179.025EOT.688.126.547.152.369.068.322.075.685.062.741.062.445.065.318.044.343.042.176.023
Hinge-ITMT.694.155.597.114.418.087.355.110.675.069.751.080.451.087.311.051.349.047.207.039
non-orderedST.696.154.597.114.418.087.355.110.675.069.751.080.451.087.311.051.349.047.207.039EOT.668.127.587.119 .385 .070.338.085.675.064.760.073.448.076.315.051.353.043 .158 .026
Hinge-IT MT,ST .666.153.588.134.403.077.323.078.685.068.751.079.431.075.307.047.333.042.155.026ordered EOT .658.131.571.133.379.083.328.075.679.074.749.061.447.079.315.051.345.044.154.026
Hinge-AT MT,ST .728.159.569.135.397.091.330.088.676.079.780.063.422.078.310.051.340.046.156.025ordered EOT .662.132.557.129.383.081.325.091.685.083 .750 .073.443.078.320.047.345.042.151.025
Logistic-ITMT.690.157.593.127.417.082.366.117.662.078.765.070.447.070.323.047.353.040.164.028
non-orderedST.692.151.593.127.417.082.366.117.662.078.765.070.447.070.323.047.353.040.164.028EOT.668.138.575.112 .385 .075.320 .078.672.080.751.063.454.077.305.049.352.049 .152 .026
Logistic-IT MT,ST .656.142.581.119.405.082.307.082.683.080.761.076.440.069.308.056.345.049.136.024ordered EOT .664.120.577.118.385.086.311.071.668.071.746.076.451.072.310.046.341.048.136.025
Logistic-ATMT,ST .656 .149.547.137.423.085.309.065.677.070 .737 .075.443.083.298.045.330.044.136.022
orderedLB.730.146.565.150.418.085.304.063.671.074.765.065.422.077.305.048.335.051.136.023EOT .660 .131.557.142.399.072.299.070.687.074 .735 .069.455.085.308.041.342.051.139.025
OLR-NLLMT,ST.664.135.569.116.404.089.329.084.663.072 .743 .075.443.081.299.048.331.043.134.022
orderedLB.718.142.585.106.396.088.308.066.652.067.773.061.439.083.303.046.337.042.136.022EOT.684.125.575.129.382.080.308.078.664.075 .740 .068.448.080.309.044.342.044.134.023
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.533.017.489.014.292.011.277.011.483.010.206.010.331.011.271.009.526.012.555.012EOT .517 .017.479 .011.292.013.277.011.482.008.204.011.331.011.268.012 .522 .009.547 .011
Hinge-ITMT.517.016.484.012.279.012.277.011.495.013.205.009.331.011.274.010.520.013.551.011
non-orderedST.517.016.484.012.279.012.277.011.495.013.205.009.331.011.274.010.520.013.551.011EOT.519.018.481.010.277.011.277.013 .485 .010.203.009.329.011 .262 .010.521.011 .545 .011
Hinge-IT MT,ST .521.017.484.012.279.013.275.010.491.010.203.009.329.011.268.011.524.013.554.014ordered EOT .516.016 .480 .010.279.013.276.011 .485 .009.205.009.328.011.265.010.521.012 .546 .011
Hinge-AT MT,ST .531.017.503.013.279.011.276.011.489.010.204.008.330.011.263.010.526.012.554.013ordered EOT .515 .018.478 .010.277.010.276.011 .486 .010.205.010.328.012.263.010 .523 .012.548 .010
Logistic-ITMT.514.017.494.014.281.013.278.013.486.010.204.010.330.010.300.012.523.014.549.013
non-orderedST.514.017.494.014.281.013.278.013.486.010.204.010.330.010.300.012.523.014.549.013EOT.514.019 .482 .011.274 .012.275.011.486.010.203.010.328.012 .268 .010.520.013.546.011
Logistic-IT MT,ST .515.018.493.011.271.010.275.012.484.009.202.009.327.010.268.012.522.016.551.012ordered EOT .514.018 .483 .012.272.011.274.010.485.009.204.010.326.011.268.010.519.011 .546 .011
Logistic-ATMT,ST .521 .017.486.010.274.011.275.011.488.010.203.009.329.011.259.011.524.012.551.011
orderedLB.532.017.493.013.273.011.275.011.489.010.203.009.328.011.258.009.527.011.554.013EOT .521 .016.482 .013.271.011.275.011.491.011.203.009.326.010.258.009.525.012.549.011
OLR-NLLMT,ST .512 .015.485.013.271.012.275.011.486.008.202.010.327.009.260.011.520.014.548.012
orderedLB.526.016.490.012.272.012.275.010.487.009.202.009.328.010.259.011.527.014.553.014EOT .511 .017.479 .012.271.010.274.011.487.009.202.009.325.011.261.011 .521 .012.547.011
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.513.011.397.009.486.010.389.009.502.007.485.008.242.005.220.005.021.004EOT .486 .013.398.008 .479 .008.388.009 .497 .007.479 .007.241 .004.219.005 .017 .005
Hinge-ITMT.474.010.412.009.476.009.448.008.496.007.476.008.245.005.217.005.089.018
non-orderedST.474.010.412.009.476.009.448.008.496.007.476.008.245.005.217.005.089.018EOT.471.013.412.007 .472 .009.448.008 .492 .007.473 .009.241 .005.214 .004.083 .014
Hinge-IT MT,ST .469.008.397.009.474.007.447.008.494.007.474.008.246.004.214.004.015.003ordered EOT .466.011.395.009 .471 .008.447.009.492.008.472.008 .241 .004.213 .004.013 .003
Hinge-AT MT,ST .488.011.412.009.482.010.451.009.505.008.484.008.245.005.216.004.072.022ordered EOT .482 .012.410.008 .476 .009.450.008 .497 .007.477 .007.240 .004.214 .004.065 .020
Logistic-ITMT.469.009.414.008.479.010.449.009.497.008.473.010.244.005.218.006.076.007
non-orderedST.470.010.414.008.479.010.449.009.497.008.473.010.244.005.218.006.076.007EOT .465 .009.412.007.477.010.448.007.496.007 .470 .007.241 .004.211 .005.066 .005
Logistic-IT MT,ST .465.007.395.009.478.009.447.008.497.008.472.009.244.004.212.004.015.003ordered EOT .462 .010.395.008.475.009.447.008.496.007.469.008 .241 .004.211.004 .013 .003
Logistic-ATMT,ST.468.008.412.009 .480 .010.451 .009.501 .007.484 .009.245.004.211.005.086.044
orderedLB.470.011.412.008.483.010.454.008.505.008.488.009.244.005.212.006.087.045EOT .460 .010.412.008 .478 .010.450 .007.499 .007.482 .007.242 .005.210.005 .081 .044
OLR-NLLMT,ST.463.009.411.009.475.010.449.010 .496 .006.472 .008.245.005.212.005.071.036
orderedLB.465.011.410.009.477.008.450.008.501.007.478.008.245.005.211.005.071.036EOT .460 .009.410.008.474.009.448.009 .495 .007.471 .007.241 .004.211.005 .066 .035
25Published in Transactions on Machine Learning Research (1/2023)
Table 8: A counterpart of Table 2regarding MZE for Task-Z and EF10 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.892.096.728.110.647.069.508.119.843.057.875.058.647.072.581.066.537.043.340.035EOT.868.095.713.115 .622 .073.506.081.838.063.859.049.660.068.596.051.543.048.337.036
Hinge-ITMT.920.077.756.103.649.070.568.070.841.059.884.057.673.074.594.067.549.048.372.044
non-orderedST.912.084.756.103.641.076.551.082.841.059.879.050.665.064.594.067.549.048.368.044EOT .866 .091.731.131.639.073.546.084.851.058.876.058.666.062.598.056.561.045 .349 .034
Hinge-IT MT,ST .860.094.727.103.636.074.538.098.837.047.868.053.676.065.597.058.553.040.335.041ordered EOT .868.076.731.129.641.082 .504 .086.839.063.860.045.656.067.597.058.563.047.329.040
Hinge-AT MT,ST .894.114.725.118.632.073.506.104.823.065.877.053.643.073.574.072.557.051.319.033ordered EOT .872.106.727.122.637.072.495.095.831.061.868.055.656.077.586.066.561.044.316.035
Logistic-ITMT.906.099.737.122.653.086.559.104.828.059.882.041.661.083.601.063.565.046.355.048
non-orderedST.908.093.732.119.647.079.555.100.824.057.880.038.658.081.601.063.565.046.353.045EOT .868 .101.752.106.641.082.536.099.827.059.871.045.656.069.594.062.564.044.343.039
Logistic-IT MT,ST .856.098.727.130.635.073.552.103.826.060.869.048.659.071.593.065 .556 .043.315.032ordered EOT .872.083.720.145.636.076.535.095.823.068.863.068.658.069.595.057.573.043.320.038
Logistic-ATMT,ST.866.099.739.119.626.089.505.080.836.063.867.053.669.076.585.055.574.052.301.031
orderedLB.878.090.719.110.655.077.491.088.821.078.888.046.636.074.585.070 .552 .045.301.037EOT.862.106.732.128.639.080.492.073.831.056.868.054.651.063.590.065.575.050.311.038
OLR-NLLMT,ST.878.106.751.105.631.071.495.082.827.060.869.058.680.069.577.059.567.046.309.037
orderedLB.910.078.717.122.637.077.492.084.826.057.884.048.651.071.573.061.553.048.308.035EOT.866.097.736.118.635.078.476.071.829.069.867.052.659.076.585.057.558.053.303.031
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.736.014.701.013.494.013.468.013.721.010.403.014.528.011.465.017.743.011.764.011EOT .722 .017.686 .012.493.015.464.011 .711 .008.405.013.527.012 .458 .016.741.010 .736 .010
Hinge-ITMT.720.016.702.013.492.014.475.012.713.009.404.014.534.011.457.011.742.010.751.012
non-orderedST.719.016.702.013.492.014.475.012.713.009.404.014.534.011.457.011.742.010.751.012EOT.721.015 .690 .013.486 .014.471.012 .711 .009.400.011.533.013.456.010.742.010.736.008
Hinge-IT MT,ST .719.017.695.011.490.015.467.010.719.011.399.013.529.011.458.015.741.009.742.011ordered EOT .724.019 .691 .012.490.013.467.012 .709 .009.401.011.531.013.458.012.741.011 .734 .008
Hinge-AT MT,ST .732.013.716.013.487.015.476.013.725.011.401.015.532.013.449.014.748.011.782.012ordered EOT .722 .015.686 .013.488.013.473.012 .715 .009.400.012.530.011.446.013 .743 .010.739 .010
Logistic-ITMT.722.014.711.011.487.012.478.012.714.009.404.012.536.012.459.016.743.011.752.013
non-orderedST.722.014.711.011.487.012.478.012.714.009.404.012.536.012.459.016.743.011.752.013EOT.721.016 .686 .012.485.015 .472 .011.710 .010.400 .011.535.011.456.013 .740 .011.738 .009
Logistic-IT MT,ST .717 .016.701.011.494.014.471.013.709.009.397.013.532.012.464.013.742.012.744.009ordered EOT .725.016 .692 .012.490.014.467.012.708.009.399.013.535.011.464.012.741.010 .735 .010
Logistic-ATMT,ST .720 .014.696.011.489.014.477.012 .711 .008.397.011 .531 .009.451.014 .743 .014.743.009
orderedLB.734.015.712.013.492.014.480.012.720.008.398.011.538.013.450.014.750.013.767.010EOT .723 .015.687 .012.489.015.473.011.715.010.399.011 .532 .011.447.014 .743 .010.738 .009
OLR-NLLMT,ST .718 .016.699.013.482.015.465.011 .709 .008.398.013.527.012.450.012 .737 .010.739 .009
orderedLB.734.015.708.012.486.014.469.012.717.011.397.013.527.010.449.014.747.012.764.011EOT .721 .017.687 .012.483.013.466.014 .710 .010.398.012.524.010.447.012 .742 .011.738 .009
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.662.010.612.010.676.008.598.009.685.007.665.008.447.006.423.007.189.069EOT .652 .007.609 .009.655 .008.596.009 .678 .008.659 .007.446.005.420.006 .155 .059
Hinge-ITMT.682.010.629.008.661.008.656.009.719.007.705.007.451.005.420.005.300.072
non-orderedST.682.010.629.008.661.008.656.009.719.007.705.007.451.005.420.005.300.072EOT .675 .010.627.007 .647 .009.652.008 .711 .006.698 .006.447 .005.416 .006.220 .068
Hinge-IT MT,ST .643.007.612.010.650.009.655.008.721.007.710.009.452.006.418.006.140.059ordered EOT .643.009.614.009.649.009.654.008 .715 .007.703 .005.447 .005.416 .006.115 .040
Hinge-AT MT,ST .650.009.637.009.675.008.667.008.721.007.711.008.450.006.417.006.179.069ordered EOT .646.009 .629 .009.656 .008.655 .008.717 .007.704 .008.446 .005.414 .005.138 .033
Logistic-ITMT.689.010.631.008.670.009.664.008.720.006.709.010.448.006.424.007.222.070
non-orderedST.688.010.631.008.670.009.664.008.720.006.709.010.448.006.424.007.222.070EOT .673 .010.627 .006.648 .008.653 .008.712 .006.700 .006.447 .005.417 .006.182 .058
Logistic-IT MT,ST .647.008.614.009.656.010.607.008.687.008.661.008.448.006.418.007.128.032ordered EOT .644 .009.614.009.654.010.604.009.686.007.660.007.447.005 .415 .006.114 .030
Logistic-ATMT,ST.655.009.634.008.660.010 .658 .008.720 .007.707 .010.449.006.418.006.187.056
orderedLB.654.009.638.011.676.009.668.008.723.007.714.007.449.006.417.006.194.064EOT .649 .009.629 .008.657 .008.656 .007.719 .006.706 .007.446 .005.415.005 .156 .045
OLR-NLLMT,ST.675.009 .628 .008.647 .009.651 .008.714 .007.695 .007.448.006.416.005.164.068
orderedLB.688.009.634.009.670.008.664.009.719.007.703.007.448.006.416.005.166.069EOT .666 .009.628 .008.648 .007.652 .008.714 .006.695 .006.447.005.415.005 .145 .059
26Published in Transactions on Machine Learning Research (1/2023)
Table 9: A counterpart of Table 2regarding MZE for Task-Z and EL3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT .330 .140.183.121.139.065.070.038.326.076.527.076.046.033.199.041.222.053.041.017EOT.386.144.175.101.122.060.067.042.319.074.523.085.045.033 .177 .042.200 .039.043.016
Hinge-ITMT.346.147.185.123.147.057.067.048.312.071.510.062.047.034.190.047.197.041.032.012
non-orderedST.346.147.185.123.147.057.067.048.312.071.510.062.047.034.190.047.197.041.032.012EOT.380.144.181.094 .122 .048.068.042.336.082.523.068.042.032 .167 .043.189.034.036.012
Hinge-IT MT,ST .324 .156.180.105.144.051.070.040.311.066.516.063.048.034.195.040.198.041 .031 .012ordered EOT .382.149.176.110 .119 .055.071.044.330.078.527.074.045.031 .165 .040.192.036.036.013
Hinge-AT MT,ST .340.156.172.098.147.059.077.043.305.072.526.085.048.034.191.043.207.051 .030 .014ordered EOT .376.148.179.094 .119 .048.074.040.318.065.541.094.044.034 .163 .042.201.044.034.011
Logistic-ITMT.390.145.209.112.142.065.065.042.319.071.547.065.052.029.168.041.185.046.029.011
non-orderedST.390.145.209.112.142.065.065.042.319.071.547.065.052.029.168.041.185.046.029.011EOT.404.152.187.106 .120 .059.069.043.319.073.544.083.048.031.160.043.182.045.030.011
Logistic-IT MT,ST .392.140.215.128.142.055.063.041.313.055.522.078.053.029.166.038.162.034.029.011ordered EOT .426.137.203.114 .119 .054.073.045.311.071.548.070.052.029.165.042.173.042.031.012
Logistic-ATMT,ST.438.143.211.121.148.052.069.040.308.083.525.081.055.029.162.034.167.039.030.009
orderedLB.408.128.205.115.143.056.069.039.304.084.540.082.055.030.167.043.171.039.030.009EOT.408.141.184.106 .119 .044.068.041.307.075.544.070.052.030.160.040.178.039.030.010
OLR-NLLMT,ST.426.148.204.128.140.059.067.044.320.073.528.076.054.029.166.037.166.033.031.013
orderedLB.396.134.200.119.135.057.068.044.319.071.537.074.054.030.166.038.174.046.031.012EOT.418.134.195.112.115.044.072.045.317.080.535.080.051.030.164.039.182.044.030.010
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.237.013.030.004.198.011.012.004.276.010.065.010.015.003.126.008.088.007.062.004EOT.236.012.030.005 .193 .014.011.003.276.010 .055 .005.015.003 .120 .007.082 .005.061.004
Hinge-ITMT.236.014.030.004.150.010.010.002.270.010.056.007.013.003 .110 .009.085.006.062.004
non-orderedST.236.014.030.004.150.010.010.002.270.010.056.007.013.003 .110 .009.085.006.062.004EOT.235.013.030.004.149.011.011.003.269.011.055.006.013.003.113.010.083.005.061.004
Hinge-IT MT,ST .236.014.030.004.147.012.011.002.269.009.054.006.013.002 .110 .008.085.005.062.004ordered EOT .235.012.030.004.145.011.011.002.269.010.054.006.013.003.114.008.084.006.061.004
Hinge-AT MT,ST .235.014.030.004.144.009.010.003.269.010.055.006.013.002.115.010.084.005.062.004ordered EOT .235.012.030.004.143.010.010.003.268.011.054.005.013.003.117.010 .083 .006.061.004
Logistic-ITMT.232.016.029.004.138.008.011.002.265.009.053.005.014.003.098.008.083.007.061.004
non-orderedST.232.016.029.004.138.008.011.002.265.009.053.005.014.003.098.008.083.007.061.004EOT.230.013.030.004.138.009.011.003.267.010.054.005.013.002.098.008.083.006.061.004
Logistic-IT MT,ST .230.012.029.004.133.008.011.002.267.009.053.004.013.003.092.007.083.006.061.004ordered EOT .229.012.030.005.131.009.010.002.265.009.054.005.013.002.091.007.083.006.061.004
Logistic-ATMT,ST.232.016.029.004.133.009.011.002.265.010.053.005.014.003.092.006.084.007.061.004
orderedLB.230.014.029.004.133.009.011.002.265.010.053.005.014.003.092.006.084.006.061.004EOT.229.014.030.004.131.008.010.002.264.010.054.005.014.003.092.006.083.007.061.004
OLR-NLLMT,ST.230.013.029.004.132.007.010.002.267.009.053.005.013.002.093.007.084.006.061.004
orderedLB.230.013.029.004.132.007.011.003.267.010.054.005.013.002.093.007.084.007.061.004EOT.230.014.030.004.132.008.011.002.265.010.053.005.013.003.093.007.083.007.061.004
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.061.004.068.005.019.002.224.005.033.002.039.003.094.003.125.011.002.001EOT.060.004.069.004 .018 .002.224.006.033.002.039.003.095.003.123.008.001.000
Hinge-ITMT.070.004.068.005.019.002.214.006.031.002.039.002.095.003.094.007.002.001
non-orderedST.070.004.068.005.019.002.214.006.031.002.039.002.095.003.094.007.002.001EOT .061 .004.068.005.018.002.213.006.031.002.039.003.095.003 .092 .006.001 .000
Hinge-IT MT,ST .071.003.069.005.019.002.214.006.032.003.038.003.095.003.091.005.002.001ordered EOT .062 .004.068.005 .018 .002.212.006.031.002 .035 .002.095.003.090.006.002.001
Hinge-AT MT,ST .068.003.068.005.019.002.218.007.032.002.034.002.094.003.091.005.002.001ordered EOT .062.004.069.004 .018 .002.217.007.032.002.035.003.095.003.090.005 .001 .000
Logistic-ITMT.049.004.071.004.019.002.200.006.031.002.038.003.095.003.084.003.002.001
non-orderedST.049.004.071.004.019.002.200.006.031.002.038.003.095.003.084.003.002.001EOT .036 .004.069.005 .018 .002.199.006.032.002.038.003.095.003.083.003 .001 .000
Logistic-IT MT,ST .050.004.070.005.018.002.200.006.032.002.035.003.094.003.081.004.002.000ordered EOT .035 .004.069.005.017.002.199.006.032.002.035.003.095.003.081.003 .001 .000
Logistic-ATMT,ST.041.004.070.005.019.002.200.005.031.002.035.003.095.003.082.003.002.000
orderedLB.038.004.069.005.019.002.201.005.032.002.035.002.095.003.082.003.002.000EOT .034 .003.069.004 .018 .002.199.005.032.002.035.002.095.003.081.004 .001 .000
OLR-NLLMT,ST.038.004.069.005.019.002.201.006.032.002.038.003.095.003.082.003.002.000
orderedLB.037.004.070.005.019.002.200.005.032.002.037.003.095.003.082.003.002.000EOT .034 .004.069.005 .018 .002.199.006.031.002.037.003.095.003.081.003 .001 .000
27Published in Transactions on Machine Learning Research (1/2023)
Table 10: A counterpart of Table 2regarding MZE for Task-Z and EL5 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.582.113.463.137.172.066.114.055.528.071.714.070.087.040.265.050.268.046.169.025EOT.566.138.483.128.191.070.118.060.549.083.694.073.090.044.261.052.264.049.167.031
Hinge-ITMT.518.179.468.171.183.072.119.056.529.073.707.069.092.046.279.051.288.040.209.034
non-orderedST.518.179.468.171.185.074.119.055.530.073.706.069.099.050.279.051.288.040.209.034EOT.554.142.476.142.195.064.124.050.532.069.702.074.097.047 .252 .043.268 .040.164 .024
Hinge-IT MT,ST .542.170.471.130.176.077.130.050.530.079.704.070.098.049.266.044.260.040.147.024ordered EOT .548.143.489.124.179.067.129.052.547.078.699.075.095.053 .253 .049.260.041.146.026
Hinge-AT MT,ST .588.142.452.152.168.075.121.050.536.083.740.067.094.048.266.045.285.052.153.030ordered EOT .538.148.481.121.181.070.128.050.553.076 .705 .081.100.048.262.057.272.042.148.024
Logistic-ITMT.532.142.469.133.201.071.126.052.546.079.715.078.105.044.258.045.283.045.145.023
non-orderedST.532.148.469.133.204.074.125.049.546.077.715.078.107.046.258.045.283.045.145.023EOT.532.163.467.119.196.066.124.044.545.079.713.067.106.043.257.054 .264 .039.140.027
Logistic-IT MT,ST .556.151.463.127.193.067.122.052.532.077.706.081.105.041.245.043.255.039.128.021ordered EOT .538.159.471.131.192.068.128.052.537.076.701.076.110.041.247.056.265.044.127.023
Logistic-ATMT,ST .536 .128.457.147.187.065.121.053.551.086.708.065.108.041.248.044.265.033.131.018
orderedLB.592.135.484.131.195.071.120.058.549.073.722.061.107.044.250.052.261.038.130.019EOT .538 .157.472.107.205.071.124.042.557.083.701.076.106.045.253.057.274.040.130.020
OLR-NLLMT,ST.562.135.485.133.189.064.124.051.544.077.714.077.108.043.249.040.257.039.129.021
orderedLB.560.128.481.120.194.074.122.053.547.080.728.077.108.041.250.044.255.039.129.021EOT.534.152.471.120.191.072.121.054.548.080.708.088.110.042.250.054.265.044.129.019
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.249.026.154.009.223.013.052.006.470.011.113.009.069.006.164.009.176.008.174.008EOT .223 .015.140 .009.220.012 .049 .006.469.012 .110 .007.068.006 .160 .010.175.008 .166 .008
Hinge-ITMT.232.012.152.009.233.016.053.005.496.015.111.008.068.007.202.011.178.009.174.008
non-orderedST.232.012.152.009.233.016.053.005.496.015.111.008.068.007.202.011.178.009.174.008EOT .223 .015.138 .009.229.014 .050 .005.471 .012.108 .008.066.006 .164 .011.177.008 .166 .008
Hinge-IT MT,ST .233.014.145.010.220.014.052.006.483.011.111.008.068.006.169.009.179.009.174.008ordered EOT .221 .014.137 .009.217.014.050.006 .470 .012.108 .009.067.006 .161 .009.177.008 .166 .008
Hinge-AT MT,ST .230.014.146.010.228.013.052.005.476.011.111.008.068.007.164.010.177.008.173.008ordered EOT .223 .013.137 .008.223 .012.050 .006.469 .012.109.008 .066 .006.158 .009.177.009 .166 .008
Logistic-ITMT.217.013.148.008.216.013.054.006.474.011.106.008.068.006.209.010.176.009.168.008
non-orderedST.217.013.137.009.216.013.054.005.474.011.106.008.067.006.209.010.176.009.166.008EOT.218.014.138.009.212.012 .049 .005.470 .010.107.007 .064 .006.160 .011.178.010.166.008
Logistic-IT MT,ST .216.013.137.010.212.014.053.005.473.011.107.007.065.006.161.012.176.009.167.008ordered EOT .218.014.136.008.210.013 .050 .005.472.012.107.007.063.006.157.010.179.009.166.008
Logistic-ATMT,ST.215.014.136.008.217.014.053.005.474.012.108.007.064.007.159.012.176.008.166.009
orderedLB.216.013.137.008.218.014.052.006.474.012.108.007.064.006.160.011.178.008.166.008EOT.216.012.136.009.215.013 .049 .005.474.012.107.008.063.007.157.011.177.007.165.008
OLR-NLLMT,ST.215.014.137.008.212.014.052.005.471.012.106.007.065.006.160.010.178.010.166.008
orderedLB.215.013.137.010.212.014.051.005.471.010.106.007.064.006.160.010.179.010.166.009EOT.217.012.136.008.208.013.050.005.473.012.106.007.063.006.158.011.179.008.165.008
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.043.004.173.006.045.003.349.008.090.004.104.004.172.006.142.006.004.001EOT .041 .003.170 .006.046.004.347.009.090.004.105.004 .167 .005.140.004 .003 .001
Hinge-ITMT.108.006.173.006.061.007.386.009.092.005.104.004.177.003.163.009.032.005
non-orderedST.107.006.173.006.061.007.386.009.093.005.104.004.177.003.163.009.032.005EOT .095 .007.170 .007.051 .004.375 .007.089 .004.102 .004.177.004 .152 .009.006 .001
Hinge-IT MT,ST .035.003.172.006.050.004.379.008.101.007.104.004.172.006.143.007.004.001ordered EOT .034 .003.169 .006.047 .004.375 .007.089 .004.103 .004.165 .005.137 .004.003 .001
Hinge-AT MT,ST .030.003.172.006.054.005.376.008.091.004.104.004.175.005.146.006.004.001ordered EOT .029.003 .169 .006.049 .004.375.008 .090 .004.098 .004.167 .005.138 .004.003 .001
Logistic-ITMT.083.004.175.007.056.005.382.009.089.004.092.004.172.005.144.005.043.008
non-orderedST.083.004.173.006.056.005.382.009.088.004.093.004.172.005.144.005.043.008EOT .064 .006.169 .007.050 .004.378 .006.088.004.092.004 .163 .003.136 .004.007 .002
Logistic-IT MT,ST .029.003.167.006.046.003.380.007.089.004.092.004.163.004.137.004.003.001ordered EOT .028 .003.166.006.046.003 .377 .008.088.004.092.004.163.004 .135 .004.003 .001
Logistic-ATMT,ST.028.003.172.006.052.004.380.008.089.004.094.004.163.004.137.004.004.001
orderedLB.028.003 .169 .006.052.004.379.009.089.004.094.004.163.004.137.004.004.001EOT.028.002 .169 .008.049 .003.378.008.089.004.094.004.162.003 .135 .003.003 .001
OLR-NLLMT,ST.028.003.172.007.050.003.376.007.088.004.092.004.163.004.136.004.010.002
orderedLB.028.003 .170 .006.049.004.376.008.088.004.091.004.163.004.136.004.010.003EOT.028.004 .168 .007.048 .003.376.008.088.004.091.004.162.004.136.004 .007 .001
28Published in Transactions on Machine Learning Research (1/2023)
Table 11: A counterpart of Table 2regarding MZE for Task-Z and EL10 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.756.146.617.101.387.069.272.064.711.067.853.059.189.058.473.073 .442 .048.284.029EOT.768.117.632.113.404.071.274.089.707.071 .833 .059.182.056.470.064.460.054.286.025
Hinge-ITMT.712.144.620.113.393.076.315.069.708.074.843.050.190.059.486.066.463.049.376.027
non-orderedST.712.144.623.110.387.076.345.070.708.070.850.050.194.058.490.067.462.050.376.027EOT.738.131.633.103.397.084 .257 .087.720.070.829.065.183.050 .454 .063.447.049 .289 .029
Hinge-IT MT,ST .698.146.599.116.392.082.244.065.713.086.826.064.188.059.488.064.441.044.281.029ordered EOT .744.130.608.113.398.074.263.082.716.074.826.071.184.055 .447 .061.443.053.279.028
Hinge-AT MT,ST .750.143.616.118.395.077.291.079.725.063.852.058.197.058.471.060.435.049.284.028ordered EOT .730.157.612.112.390.075.284.082.710.063.837.067.186.057.461.062.444.042 .273 .026
Logistic-ITMT.742.137.631.111.405.078.296.073.707.066.848.061.197.054.483.069.441.043.306.031
non-orderedST.742.137.629.103.403.075.358.096.706.072.849.055.206.062.485.067.441.042.306.031EOT.752.145.607.098.384.077 .269 .074.711.070.829.066.194.054 .456 .053.441.044 .279 .027
Logistic-IT MT,ST .740.147.616.122.396.069.232.067.705.077.829.048.189.058.465.062.446.051.273.027ordered EOT .744.120.612.117.395.086.239.081.722.069.838.068.188.062.456.053.443.049.273.027
Logistic-ATMT,ST.718.149.593.115.387.079.248.076.704.075 .822 .060.187.053.477.073.444.047.266.024
orderedLB.748.149.611.130.393.072.259.075.703.082.852.061.193.055.465.071.446.056.266.026EOT.718.138.601.105.396.084.245.069.713.078 .823 .069.184.060.456.055.455.046.263.024
OLR-NLLMT,ST.716.141.604.132.378.080.235.070.700.061.835.058.191.055.468.068.436.044.266.027
orderedLB.770.124.615.111.396.091.229.077.701.067.853.050.188.050.466.066.444.043.262.024EOT.748.146.617.101.392.086.229.082.717.064.837.056.189.059.453.055.454.050.264.025
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.434.017.212.011.399.013.166.009.652.011.248.010.212.011.325.014.313.011.294.009EOT.433.015 .205 .011.400.014.166.009.649.013.250.012.209.009.321.013 .307 .011.294.008
Hinge-ITMT.470.016.212.011.407.015.164.007.662.014.249.013.208.011.347.016.305.012.294.009
non-orderedST.471.016.212.011.407.015.164.008.662.014.249.013.208.011.348.014.305.012.294.009EOT .437 .015.203 .011.396 .016.161 .008.655 .011.245.011 .204 .010.327 .014.306.011.295.009
Hinge-IT MT,ST .432.017.212.010.410.016.160.009.670.012.245.011.205.010.340.012.308.011.293.008ordered EOT .432.016 .202 .011.404 .012.159.009 .656 .010.245.011.204.010.338.014 .304 .010.294.009
Hinge-AT MT,ST .431.016.209.012.406.015.162.008.655.012.246.011.206.012.324.013.311.011.294.008ordered EOT .432.014 .201 .011.403.014.162.009.654.012.246.011.205.011.321.011.308.014.294.009
Logistic-ITMT.444.018.202.012.408.014.163.007.652.011.245.012.204.009.351.017.310.012.291.008
non-orderedST.453.020.206.010.397.015.163.007.652.011.245.012.204.010.351.016.310.012.291.008EOT .430 .017.199 .011.391 .016.158 .010.653.011.243.011 .196 .010.325 .014.308.012.293.009
Logistic-IT MT,ST .426 .013.198.011.398.013.158.009.654.013.243.011.196.010.337.013.306.012.291.008ordered EOT .433.016.199.012.396.013.156.007.652.012.242.010.196.011.333.013.309.013.292.009
Logistic-ATMT,ST.429.013.198.010.398.017.161.006.655.011.244.011.200.010.322.012 .306 .011.293.010
orderedLB.433.013.199.011.396.017.160.007.653.012.244.011.198.010.320.012.315.013.294.010EOT.437.016.199.011.394.015 .157 .008.654.012.245.013.197.010.317.013 .308 .012.293.009
OLR-NLLMT,ST.426.013.198.010.392.015.157.007.652.011.242.011.197.011.321.013.307.012.292.009
orderedLB.430.015.199.011.389.015.157.008.652.011.242.011.197.012.320.012.315.012.293.009EOT.434.016.199.013.389.014.157.008.654.012.243.011.197.010.320.011.308.012.293.010
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.141.008.286.007.267.005.539.013.218.007.211.006.318.005.263.005.050.004EOT .130 .006.283 .007.268.005 .528 .009.216.006.210.005 .315 .005.262.005 .041 .004
Hinge-ITMT.119.009.305.011.310.010.587.008.226.007.226.005.344.005.303.007.074.006
non-orderedST.119.009.305.011.310.010.588.008.226.007.226.005.330.006.288.005.066.006EOT .114 .008.286 .007.289 .008.583 .008.222 .006.227.006 .316 .005.269 .005.039 .003
Hinge-IT MT,ST .151.005.285.007.260.005.521.010.227.006.239.018.323.005.269.004.047.005ordered EOT .129 .005.283.007.260.006 .517 .008.225.006 .229 .006.315 .005.268.005 .038 .004
Hinge-AT MT,ST .120.008.284.007.259.006.535.011.235.005.237.007.324.006.270.005.051.006ordered EOT .106 .008.283.007.260.007 .526 .008.223 .006.230 .006.315 .004.268 .005.043 .004
Logistic-ITMT.104.007.292.008.303.009.586.008.225.006.225.006.342.006.304.009.077.005
non-orderedST.104.007.291.008.303.009.586.008.225.006.225.006.329.006.293.008.071.006EOT .097 .008.283 .008.285 .006.582 .008.222 .006.224.006 .315 .004.268 .005.038 .003
Logistic-IT MT,ST .135.007.278.007.258.007.515.008.207.007.226.006.318.004.260.004.038.004ordered EOT .115 .007.277.006.258.007.514.007.207.006.225.006 .316 .005.260.004 .033 .003
Logistic-ATMT,ST.137.006.287.007.281.007.591.007.229.007.234.006.321.004.269.005.052.004
orderedLB.124.007.285.008.277.006.594.008.231.006.232.006.320.005.268.005.043.004EOT.107.007.283.007.272.006.587.007.225.006.231.006.315.005.266.005.037.003
OLR-NLLMT,ST.126.007.285.007.275.007 .584 .007.223 .007.225.006.319.004.268.006.042.004
orderedLB.110.007.285.008.275.007.589.008.226.007.225.007.319.005.267.005.040.003EOT .100 .008.282 .007.272 .006.582 .008.222 .006.223.006 .315 .005.266 .005.034 .003
29Published in Transactions on Machine Learning Research (1/2023)
Table 12: A counterpart of Table 2regarding MAE for Task-A and EF3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.658.183.404.125.150.060.214.075.631.115.721.105.271.066.209.048.263.037.080.019EOT.668.189.373.135.145.065.226.091.637.109.748.102.268.065 .183 .039.256.037.079.021
Hinge-ITMT.670.219.396.115.159.060.211.079.644.123.730.104.271.067.209.051.255.041.080.018
non-orderedST.670.219.396.115.159.060.211.079.644.123.730.104.271.067.209.051.255.041.080.018EOT.654.184.392.123.154.048.215.077.616.125.711.112.267.057 .184 .041.254.039.075.018
Hinge-IT MT,ST .666.204.401.114.152.052.218.071.648.109.710.109.262.066.199.045.250.041.079.018ordered EOT .656.171.375.135.148.052.204.061.618.109.706.111.264.063.190.037.256.036.076.019
Hinge-AT MT,ST .696.178.396.104.152.060.218.075.621.124.706.113.256.065.203.046.251.039.077.018ordered EOT .666.194.365.109.147.053.210.057.629.119.717.122.267.066.194.040.248.038.077.020
Logistic-ITMT.622.194.416.134.158.066.228.066.625.099.725.123.249.065.197.047.251.040.077.019
non-orderedST.622.194.416.134.158.066.228.066.625.099.725.123.249.065.197.047.251.040.077.019EOT.666.181.391.115.146.047.226.052.604.094.714.112.250.066 .179 .038.241.038.081.022
Logistic-IT MT,ST .636.199.423.114.153.068.237.083.606.108.721.131.263.070.194.043.239.040.074.018ordered EOT .672.180.385.096.134.044.224.059.611.106.721.119.260.066.182.033.238.046.074.018
Logistic-ATMT,ST.638.208.411.115.148.064.223.067.616.102.715.122.256.066.193.040.230.037.075.019
orderedLB.638.208.411.115.148.064.223.067.616.102.715.122.256.066.193.040.230.037.075.019EOT.690.192.381.111.136.046.221.065.616.110.715.122.261.070.182.038.233.042.076.016
OLR-NLLMT,ST.658.188.409.120.146.064.234.083.611.112.713.137.251.071.196.050.230.037.074.021
orderedLB.658.188.409.120.146.064.234.083.611.112.713.137.251.071.196.050.230.037.074.021EOT.678.186.393.101.136.049.217.058.605.104.733.118.264.073 .177 .039.234.042.076.017
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.375.020.360.012.180.008.173.008.332.012.107.008.202.009.167.009.361.013.365.012EOT.378.019.358.010.177.010.173.008.335.013.107.008.202.010.166.008.360.013.365.012
Hinge-ITMT.375.020.369.012.157.010.170.009.330.012.102.008.203.011.163.009.364.013.364.011
non-orderedST.375.020.369.012.157.010.170.009.330.012.102.008.203.011.163.009.364.013.364.011EOT.374.015 .359 .011.157.010.169.009.332.011.102.008.201.010 .160 .009.359 .014.365.011
Hinge-IT MT,ST .376.020.370.013.158.010.170.008.332.012.101.008.202.009.159.009.364.012.363.011ordered EOT .373.017 .358 .011.157.009.170.008.332.011.101.008.200.009.158.009.359.012.363.010
Hinge-AT MT,ST .376.018.364.015.157.010.170.008.332.012.101.008.201.009.160.008.361.013.365.009ordered EOT .376.021 .359 .011.158.011.170.009.332.011.100.008.200.009.158.009.359.013.365.011
Logistic-ITMT.368.019.355.011.154.009.167.009.329.010.101.007.197.008.174.009.364.013.363.012
non-orderedST.368.019.355.011.154.009.167.009.329.010.101.007.197.008.174.009.364.013.363.012EOT.368.018.352.012.153.008.167.009.329.009.101.008.197.008 .157 .008.359.014.364.011
Logistic-IT MT,ST .369.019.355.011.153.010.168.009.329.011.101.007.198.008.160.009.363.014.363.011ordered EOT .371.017.352.011.152.008.168.009.330.010.100.008.196.009.159.009.361.015.364.011
Logistic-ATMT,ST.368.019.353.010.154.010.168.008.328.011.101.008.199.009.158.009.361.014.364.012
orderedLB.368.019.353.010.154.010.168.008.328.011.101.008.199.009.158.009.361.014.364.012EOT.370.018.353.010.153.010.168.009.329.010.100.008.197.008.156.009.360.014.363.011
OLR-NLLMT,ST.367.017.353.012.152.009.167.008.329.011.101.007.197.008.158.009.361.013.363.012
orderedLB.367.017.353.012.152.009.167.008.329.011.101.007.197.008.158.009.361.013.363.012EOT.369.018.353.010.153.010.169.009.330.009.100.008.197.008.157.009.360.015.363.011
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.316.007.246.007.311.008.268.006.308.008.283.007.134.003.119.003.010.008EOT.316.009.246.008.311.009.268.007.308.008.282.006.134.003.118.003.009.008
Hinge-ITMT.393.026.242.009.311.008.258.007.350.008.324.009.149.008.121.004.007.001
non-orderedST.393.026.242.009.311.008.258.007.350.008.324.009.149.008.121.004.007.001EOT .363 .014.243.008.311.008.257.008 .338 .007.314 .008.137 .003.120 .004.007 .001
Hinge-IT MT,ST .312.007.242.008.311.008.258.008.303.008.282.006.134.003.120.004.007.001ordered EOT .312.008.242.008.310.008.256.007.303.008.280.006.133.003 .119 .004.007 .001
Hinge-AT MT,ST .314.008.242.008.311.008.260.007.302.007.282.007.134.003.120.004.009.008ordered EOT .314.008.241.008.309.008.259.007.301.008.280.007.134.003.119.004.008.007
Logistic-ITMT.313.009.238.007.307.008.245.007.293.007.306.007.133.003.121.004.006.001
non-orderedST.313.009.238.007.307.008.245.007.293.007.306.007.133.003.121.004.006.001EOT.312.009.239.008.307.009.244.008.292.007 .299 .007.133.003 .119 .004.005 .001
Logistic-IT MT,ST .313.008.238.008.308.008.246.007.294.007.275.007.133.004.116.004.009.012ordered EOT .312.007.238.008.306.009.244.007.292.007.274.006.133.003.116.004 .008 .012
Logistic-AT MT,ST,LB .313.008.239.008.310.008.247.008.292.007.310.009.133.003.120.004.021.024ordered EOT .311.007.238.009.309.010.246.007.292.006.308.008.133.003.119.004.020.023
OLR-NLL MT,ST,LB .313.007.238.008.309.009.246.008.293.007.304.007.134.003.119.004.017.022ordered EOT .312.008.238.009.308.009.245.007.291.007 .301 .007.133.003.118.004 .016 .021
30Published in Transactions on Machine Learning Research (1/2023)
Table 13: A counterpart of Table 2regarding MAE for Task-A and EF5 datasets
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 1.146.279.755.246.414.100.423.107 1.049.147 1.225.189.496.093.328.048.394.055.180.024EOT 1.204.251.740.239.401.081.438.152 1.038.166 1.220.195.468 .073.328.044.390.055.176.023
Hinge-ITMT 1.104.321.781.242.437.098.471.156 1.084.171 1.263.219.507.106.320.052.394.057.207.039
non-orderedST 1.090.316.781.242.437.098.471.156 1.084.171 1.259.216.507.106.320.052.394.057.207.039EOT 1.126.278.795.242 .399 .085.424 .133 1.042.176 1.243.192.459 .074.320.049.390.058 .158 .026
Hinge-IT MT,ST 1.092.292.805.252.430.085.425.126 1.095.158 1.287.221.504.113.317.050.379.054.155.026ordered EOT 1.154.298.792.266 .396 .088.415.122 1.045.151 1.238.196.480.086.325.055.385.053.154.027
Hinge-AT MT,ST 1.170.310.749.231.427.103.411.124 1.075.144 1.217.169.471.098.318.052.377.057.157.025ordered EOT 1.152.251.764.264.398.084.406.131 1.035.131 1.178.186.451.085.331.052.387.054.152.027
Logistic-ITMT 1.114.310.813.253.452.097.459.159 1.087.157 1.230.232.495.109.333.050.405.056.165.030
non-orderedST 1.108.301.813.253.452.097.459.159 1.087.157 1.230.232.495.109.333.050.405.056.165.030EOT 1.110.266.759.239 .408 .082.422 .147 1.052.175 1.240.195.478.082.316.053.392.056 .151 .024
Logistic-IT MT,ST 1.092.293.816.235.432.099.379.119 1.084.153 1.240.200.493.094.310.055.378.061.136.025ordered EOT 1.136.256.763.245.404.097.392.156 1.049.144 1.259.213.485.085.314.050.385.053.137.026
Logistic-AT MT,ST,LB 1.118.270.768.257.453.101.361.088 1.075.150 1.188.189.467.087.308.048.365.059.137.024ordered EOT 1.154.265.757.256.420.088.368.118 1.046.148 1.196.180.459.081.318.048.367.053.139.025
OLR-NLL MT,ST,LB 1.092.275.772.210.435.110.380.115 1.073.137 1.205.193.479.088.310.049.367.046.136.022ordered EOT 1.140.262.739.230.407.095.381.149 1.058.148 1.211.179.467.070.318.048.373.054.136.024
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.668.021.559.017.302.012.297.013.589.013.206.010.361.013.274.010.659.017.666.017EOT.662.024.560.014.300.013.296.011.592.014.204.011.362.013.274.013.658.016.665.016
Hinge-ITMT.688.028.560.016.287.012.296.012.623.019.205.009.361.012.280.011.672.018.709.020
non-orderedST.688.028.560.016.287.012.296.012.623.019.205.009.361.012.280.011.672.018.709.020EOT .661 .024.560.016.284.013.292.013 .589 .012.204.010.356.012 .266 .010.656 .018.660 .015
Hinge-IT MT,ST .688.029.559.015.286.014.294.011.617.018.203.009.357.012.273.011.673.020.722.020ordered EOT .662 .024.560.015.286.013.293.012 .590 .014.205.008.354.012.270.011 .658 .017.662 .015
Hinge-AT MT,ST .659.023.565.017.284.010.292.011.591.013.205.009.355.013.267.011.658.018.668.015ordered EOT .658.023 .559 .015.285.011.291.009.588.014.204.009.355.012.267.010.656.018 .660 .016
Logistic-ITMT.678.024.584.017.290.014.294.012.594.013.204.010.357.013.309.013.665.017.683.016
non-orderedST.678.024.584.017.290.014.294.012.594.013.204.010.357.013.309.013.665.017.683.016EOT .659 .024.559 .013.281 .012.293.011.589.014.203.009.354.012 .273 .011.657 .017.661 .016
Logistic-IT MT,ST .679.027.582.015.278.011.291.013.595.013.202.010.353.012.273.014.667.020.686.015ordered EOT .660 .024.561 .013.278.011.290.011 .589 .012.204.010.351.012.273.011 .657 .019.662 .016
Logistic-AT MT,ST,LB .658.023.565.015.278.012.291.012.590.015.203.009.353.012.261.010.656.019.663.016ordered EOT .658.021 .558 .013.279.012.290.010.589.013.204.008.351.011.261.011.656.016.663.015
OLR-NLL MT,ST,LB .655.021.562.016.277.013.291.010.589.013.202.009.353.012.264.013.655.019.662.015ordered EOT .657.021.558.013.278.012.290.010.588.016.202.009 .349 .011.264.012.656.018.663.016
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.577.014.441.012.581.013.450.011.617.010.592.013.243.005.221.005.022.005EOT .549 .013.439.011.582.013.448.011.616.011.592.009.241.005 .219 .005.019 .005
Hinge-ITMT.606.024.464.011.616.015.539.012.634.015.596.012.246.005.217.005.097.018
non-orderedST.606.024.464.011.616.015.539.012.634.015.596.012.246.005.217.005.097.018EOT .528 .015.454 .010.572 .012.527 .009.612 .011.575 .011.242 .004.214 .004.091 .014
Hinge-IT MT,ST .664.025.441.011.617.013.535.010.632.013.589.013.247.004.214.004.015.004ordered EOT .518 .012.437.011.571.012.527.010.610.011.575.011 .241 .004.213.004 .014 .003
Hinge-AT MT,ST .557.019.456.012.577.012.530.010.615.010.579.012.246.005.216.004.073.023ordered EOT .549 .018.454.011.576.012.529.009.613.010.577.011 .241 .004.215.004 .067 .021
Logistic-ITMT.662.020.464.012.617.015.536.012.630.011.583.014.245.005.219.006.078.008
non-orderedST.662.020.464.012.617.015.536.012.630.011.583.014.245.005.219.006.078.008EOT .519 .012.454 .009.576 .013.527 .009.614 .011.568 .011.242 .004.211 .005.068 .005
Logistic-IT MT,ST .660.030.437.011.616.014.533.010.630.012.578.012.244.004.212.004.015.003ordered EOT .515 .013.434.010 .577 .012.526 .010.614 .010.566 .009.242 .004.211.004 .014 .003
Logistic-AT MT,ST,LB .523.013.455.009.581.011.531.009.614.011.581.013.245.005.212.005.088.046ordered EOT .509.011.453.010 .577 .012.531.009.613.011.579.011 .242 .005.211.005 .082 .045
OLR-NLL MT,ST,LB .520.012.454.010.575.012.527.010.612.011.570.011.245.005.212.005.072.037ordered EOT .506 .011.452.010.573.013.526.010.611.010.567.009 .241 .004.211.005 .068 .036
31Published in Transactions on Machine Learning Research (1/2023)
Table 14: A counterpart of Table 2regarding MAE for Task-A and EF10 datasets
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 2.466.569 1.397.353.852.134.783.216 2.297.347 2.524.323.995.157.721.094.791.097.362.035EOT 2.554.527 1.396.379.820.130.778.187 2.278.356 2.533.311 1.000.149.746.089.805.093.361.038
Hinge-ITMT 2.436.551 1.413.404.875.132.911.232 2.314.351 2.479.315 1.046.173.742.110.826.091.414.055
non-orderedST 2.444.561 1.424.402.872.132.874.238 2.304.354 2.498.316 1.040.165.742.110.826.091.406.049EOT 2.448.537 1.433.394.817 .123.819.195 2.277.325 2.492.329 1.008.148.733.087.814.096 .374 .043
Hinge-IT MT,ST 2.426.534 1.456.346.874.145.830.186 2.328.307 2.566.358 1.085.165.731.089.812.084.353.043ordered EOT 2.542.489 1.468.375.823.133.798.178 2.259.303 2.505.2721.025 .149.739.075.813.087.347.038
Hinge-AT MT,ST 2.406.499 1.427.384.844.149.742.162 2.240.314 2.541.309.989.152 .702 .094.802.097.330.039ordered EOT 2.476.507 1.504.380.827.142.721.161 2.219.320 2.499.336.992.140.731.082.807.092.329.035
Logistic-ITMT 2.356.496 1.456.411.873.152.825.208 2.303.285 2.531.408 1.042.160.737.092.824.092.384.059
non-orderedST 2.368.476 1.451.407.865.149.817.211 2.295.287 2.536.397 1.033.150.737.092.824.092.383.058EOT 2.522.543 1.447.379.818.116.783.190 2.239.319 2.489.377.995.141.743.082.810.099.365.043
Logistic-IT MT,ST 2.330 .5431.453.365.838.151.841.210 2.302.294 2.606.430 1.069.182.732.084.811.088.331.032ordered EOT 2.530.551 1.487.405.827.124.783.198 2.234.239 2.607.381 1.026.146.735.088.813.087.335.041
Logistic-AT MT,ST,LB 2.324 .4731.465.419.837.130.733.171 2.288.270 2.520.350.995.149.719.093.796.106.312.034ordered EOT 2.526.544 1.471.412.838.131.732.187 2.233.275 2.511.323 1.002.139.727.092.799.096.315.037
OLR-NLL MT,ST,LB 2.362.465 1.465.435.842.118.744.195 2.252.290 2.508.318 1.008.145.695.087.797.088.317.034ordered EOT 2.474.621 1.465.408.812.129.720.185 2.206.283 2.548.381 1.004.131.717.095.805.086.314.030
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT 1.375.040 1.149.026.599.025.606.017 1.249.027.424.014.732.022.542.026 1.379.030 1.335.025EOT 1.373.037 1.148.025.598.021.604.015 1.251.028.425.012.730.022 .532 .023 1.380.029 1.333.024
Hinge-ITMT 1.404.044 1.200.032.595.020.615.017 1.272.026.426.013.746.018.541.019 1.384.031 1.377.027
non-orderedST 1.403.045 1.200.032.595.020.615.017 1.272.026.426.013.746.018.541.019 1.384.031 1.377.027EOT 1.382 .0411.152 .024.581 .018.611.0171.248 .024.419 .011.736 .019.532 .017 1.382.0271.334 .023
Hinge-IT MT,ST 1.463.053 1.218.032.593.023.606.016 1.395.041.420.012.741.021.543.020 1.415.034 1.366.026ordered EOT 1.394 .0391.163 .024.590.023.607.0181.253 .025.423.014 .733 .018.539.0201.391 .0301.339 .026
Hinge-AT MT,ST 1.366.038 1.177.026.586.018.596.015 1.258.025.420.013.720.018.521.019 1.387.032 1.365.022ordered EOT 1.375.0391.149 .022.584.020.599.0131.248 .024.420.011.719.020.517.017 1.382.0311.333 .025
Logistic-ITMT 1.397.044 1.226.030.588.022.611.016 1.266.026.424.013.744.021.541.023 1.386.034 1.380.028
non-orderedST 1.397.044 1.226.030.588.022.611.016 1.266.026.424.013.744.021.541.023 1.386.034 1.382.028EOT 1.383.0421.151 .024.578 .021.609.0141.249 .027.420.012.740.020 .528 .017 1.385.0321.333 .025
Logistic-IT MT,ST 1.437.054 1.244.027.596.022.603.017 1.297.025.419.013.736.025.555.018 1.402.035 1.363.027ordered EOT 1.398 .0401.169 .026.591.022.601.0171.249 .026.419.012.735.020.550.0171.387 .0291.335 .024
Logistic-AT MT,ST,LB 1.363.039 1.151.025.590.018.598.014 1.251.024.418.010.722.021.520.018 1.386.029 1.339.027ordered EOT 1.371.039 1.148.024.587.021.598.016 1.250.027.421.013.720.020.516.019 1.385.028 1.333.024
OLR-NLL MT,ST,LB 1.362 .0411.150.024.577.021.594.014 1.245.026.418.013.721.020.522.018 1.383.029 1.334.027ordered EOT 1.374.042 1.143.022.574.022.594.016 1.248.025.418.012.717.020.523.017 1.381.033 1.331.024
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT 1.155.025.899.014 1.196.019.915.020 1.144.016 1.084.015.496.007.458.009.249.087EOT 1.145.022.898.015 1.191.019.913.018 1.142.017 1.082.015.495.006 .454 .007.217 .082
Hinge-ITMT 1.329.041.947.015 1.234.024 1.112.017 1.323.022 1.237.020.502.006.456.006.373.094
non-orderedST 1.329.041.947.015 1.234.024 1.112.017 1.323.022 1.237.020.502.006.456.006.373.094EOT 1.197 .024.942.0151.177 .0211.094 .0151.294 .0191.210 .018.495 .007.450 .005.295 .088
Hinge-IT MT,ST 1.401.055.912.015 1.266.028 1.138.021 1.421.030 1.341.032.504.007.452.007.171.075ordered EOT 1.121 .020.901 .0131.191 .0221.100 .0141.301 .0191.230 .019.495 .006.448 .007.148 .062
Hinge-AT MT,ST 1.125.021.942.017 1.186.021 1.105.015 1.283.020 1.210.019.500.008.449.007.210.081ordered EOT 1.126.020.940.014 1.185.020 1.102.016 1.277.017 1.205.020.494 .006.447.007 .169 .048
Logistic-ITMT 1.447.035.945.014 1.237.022 1.113.017 1.314.022 1.233.021.499.007.461.010.279.105
non-orderedST 1.446.035.945.014 1.237.022 1.113.017 1.314.022 1.233.021.499.007.461.010.279.105EOT 1.189 .029.940.0161.183 .0211.095 .0161.291 .0181.212 .018.495 .006.451 .007.232 .080
Logistic-IT MT,ST 1.279.032.910.015 1.256.025.943.022 1.219.020 1.124.019.496.007.451.008.153.045ordered EOT 1.119 .021.905.0151.214 .022.933 .0201.172 .0181.093 .014.494 .006.448 .007.138 .043
Logistic-AT MT,ST,LB 1.132.020.942.014 1.191.021 1.107.015 1.287.019 1.221.024.498.007.450.007.227.080ordered EOT 1.128.020.939.016 1.188.020 1.103.0151.280 .0201.214.018.494 .006.446 .006.197 .071
OLR-NLL MT,ST,LB 1.198.023.940.015 1.183.022 1.096.016 1.287.018 1.197.019.498.007.448.006.199.087ordered EOT 1.167 .021.938.0171.175 .0201.092.014 1.284.020 1.194.015.495 .006.447 .006.181 .083
32Published in Transactions on Machine Learning Research (1/2023)
Table 15: A counterpart of Table 2regarding MAE for Task-A and EL3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT .330 .140.184.122.138.065.073.042.352.092.631.105.048.039.201.040.226.054.041.017EOT.382.141.176.103.126.065.069.047.351.084.621.116.046.038 .181 .043.210 .048.043.016
Hinge-ITMT.346.147.193.130.150.062.070.053.342.086.631.093.048.037.193.048.199.041.032.012
non-orderedST.346.147.193.130.150.062.070.053.342.086.631.093.048.037.193.048.199.041.032.012EOT.382.147.189.095 .124 .052.075.047.355.084.612.103.046.038 .168 .042.193.033.036.012
Hinge-IT MT,ST .324 .156.185.111.146.053.073.045.336.079.643.084.050.037.197.041.201.042.031.012ordered EOT .384.155.183.115 .121 .060.072.049.348.078.620.106.049.037 .170 .043.194.036.036.013
Hinge-AT MT,ST .340.156.179.102.147.062.080.046.329.079.623.107.050.036.194.043.207.048 .030 .014ordered EOT .374.151.187.098 .121 .052.080.047.347.073.626.111.047.039 .168 .044.205.047.034.011
Logistic-ITMT.392.145.223.122.151.075.068.045.365.096.649.107.056.037.168.041.186.046.029.011
non-orderedST.392.145.223.122.151.075.068.045.365.096.649.107.056.037.168.041.186.046.029.011EOT.402.154.196.109 .124 .068.078.049.352.087.625.099.053.040.161.044.184.046.030.011
Logistic-IT MT,ST .394.141.228.140.146.063.066.045.349.074.649.097.056.032.168.039.162.035.029.011ordered EOT .428.140.212.123 .122 .061.079.051.345.086.621.105.055.035.162.042.175.045.031.012
Logistic-AT MT,ST,LB .408.128.219.124.146.061.072.043.341.096.626.106.058.035.166.043.169.039.030.009ordered EOT .406.143.199.114 .121 .050.071.043.347.096.620.101.055.036.161.040.176.038.030.010
OLR-NLL MT,ST,LB .398.135.213.129.139.064.071.047.349.096.625.109.058.036.167.039.175.046.031.012ordered EOT .418.137.207.118.119.051.079.051.349.094.612.093.054.036.165.039.183.045.030.010
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.237.013.030.004.198.011.012.004.287.012.065.010.015.003.126.008.092.009.062.004EOT.238.013.030.005 .194 .014.011.003.285.011 .055 .005.015.003 .120 .007.084 .006.061.004
Hinge-ITMT.236.014.030.004.150.010.010.002.273.011.056.007.013.003 .110 .009.088.006.062.004
non-orderedST.236.014.030.004.150.010.010.002.273.011.056.007.013.003 .110 .009.088.006.062.004EOT.236.014.030.004.149.011.011.003.274.011.055.006.013.003.113.010 .085 .006.061.004
Hinge-IT MT,ST .236.015.030.004.147.012.011.002.274.010.054.006.013.002.110.008.087.006.062.004ordered EOT .236.012.030.004.145.011.011.002.274.010.054.006.013.003.114.008.086.006.061.004
Hinge-AT MT,ST .234.011.030.004.144.009.010.003.272.011.055.006.013.002.115.010.087.005.062.004ordered EOT .235.012.030.004.143.010.010.003.273.012.054.005.013.003.117.010 .085 .005.061.004
Logistic-ITMT.232.013.029.004.138.008.011.003.269.010.053.005.014.003.098.008.086.007.061.004
non-orderedST.232.013.029.004.138.008.011.003.269.010.053.005.014.003.098.008.086.007.061.004EOT.231.013.030.004.138.009.011.003.270.009.054.005.013.002.098.008.086.006.061.004
Logistic-IT MT,ST .231.013.029.004.133.008.011.002.269.010.053.004.013.003.092.007.085.006.061.004ordered EOT .229.012.030.005.131.009.010.002.270.010.054.005.013.002.091.007.086.006.061.004
Logistic-AT MT,ST,LB .231.014.029.004.133.009.011.002.269.010.053.005.014.003.092.006.086.006.061.004ordered EOT .229.014.030.004.131.008.010.002.270.009.054.005.014.003.092.006.086.007.061.004
OLR-NLL MT,ST,LB .231.013.029.004.132.007.011.003.271.010.054.005.013.002.093.007.087.007.061.004ordered EOT .231.013.030.004.132.008.011.002.270.009.053.005.013.003.093.007.086.006.061.004
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.077.005.068.004.019.002.229.006.035.003.044.004.094.003.125.011.002.001EOT.075.006.069.005 .018 .002.228.006.035.002.043.004.095.003.123.008.001.000
Hinge-ITMT.087.005.069.005.019.002.219.006.033.002.044.003.095.003.094.007.002.001
non-orderedST.087.005.069.005.019.002.219.006.033.002.044.003.095.003.094.007.002.001EOT .077 .005.069.005.018.002.218.006.033.003.044.003.095.003 .092 .006.001 .000
Hinge-IT MT,ST .089.005.069.005.019.002.219.006.033.003.044.004.095.003.091.005.002.001ordered EOT .077 .005.068.005 .018 .002.218.007.033.003 .038 .003.095.003.090.006.002.001
Hinge-AT MT,ST .085.005.068.005.019.002.222.006.033.002.037.003.094.003.091.005.002.001ordered EOT .077 .005.069.004 .018 .002.222.007.033.003.038.003.095.003.090.005 .001 .000
Logistic-ITMT.052.004.071.004.019.002.204.005.033.002.043.003.095.003.084.003.002.001
non-orderedST.052.004.071.004.019.002.204.005.033.002.043.003.095.003.084.003.002.001EOT .037 .004.069.005 .018 .002.203.006.033.002 .041 .003.095.003.083.003 .001 .000
Logistic-IT MT,ST .054.004.070.005.018.002.204.006.033.002.038.003.094.003.081.004.002.000ordered EOT .038 .005.069.005.017.002.203.006.033.002.038.003.095.003.081.003 .001 .000
Logistic-AT MT,ST,LB .040.005.070.005.019.002.204.005.033.002.037.003.095.003.082.003.002.000ordered EOT .036 .004.069.004 .018 .002.203.005.033.002.038.003.095.003.081.004 .001 .000
OLR-NLL MT,ST,LB .039.004.070.005.019.002.204.006.033.002.041.003.095.003.082.003.002.000ordered EOT .035 .004.069.005 .018 .002.202.006.033.002.041.003.095.003.081.003 .001 .000
33Published in Transactions on Machine Learning Research (1/2023)
Table 16: A counterpart of Table 2regarding MAE for Task-A and EL5 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.698.182.520.155.203.087.152.093.730.139 1.126.158.102.054.269.053.295.049.168.025EOT.654.218.548.167.213.088.150.087.757.140 1.123.170.103.059.268.055.288.048.167.030
Hinge-ITMT.658.270.521.221.216.092.168.090.743.147 1.109.164.114.068.283.054.321.049.208.033
non-orderedST.658.270.512.200.219.092.168.089.739.142 1.111.164.121.073.283.054.321.049.208.033EOT.656.213.532.173.218.088.186.112.742.136 1.123.179.114.060 .259 .050.297 .042.164 .024
Hinge-IT MT,ST .670.219.531.161.210.097.174.086.744.151 1.121.135.119.069.270.047.292.046.147.025ordered EOT .668.219.529.164.205.086.176.083.759.135 1.094.142.112.066.262.049.290.042.145.025
Hinge-AT MT,ST .722.215.500.153.195.095.168.077.732.132 1.115.161.113.063.267.046.305.058.153.030ordered EOT .644.198.527.156.205.092.168.083.749.128 1.133.178.114.060.264.055.295.044.148.025
Logistic-ITMT.672.203.565.214.235.097.175.076.763.145 1.152.204.135.073.267.047.318.048.145.023
non-orderedST.670.210.540.175.236.097.174.075.757.134 1.151.204.139.081.267.047.318.048.145.023EOT.660.188.525.172.219.088.181.088.734.123 1.136.194.131.067.256.052 .288 .040.141.027
Logistic-IT MT,ST .676.202.531.169.237.098.168.081.741.130 1.141.165.134.068.250.045.279.043.129.021ordered EOT .676.201.517.169.216.088.185.104.737.139 1.121.188.130.067.249.053.287.047.127.023
Logistic-AT MT,ST,LB .680.196.528.163.221.093.161.077.747.127 1.114.154.132.070.252.044.279.042.130.019ordered EOT .666.214.531.151.225.087.168.077.763.126 1.119.184.127.066.259.057.291.051.130.020
OLR-NLL MT,ST,LB .658.181.553.167.225.100.162.085.745.140 1.161.161.135.071.254.044.283.042.129.021ordered EOT .652.217.515.165.215.093.168.101.764.120 1.134.194.133.064.253.050.284.042.129.019
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.284.028.157.009.223.012.052.006.521.014.113.009.069.006.164.009.207.009.178.009EOT .241 .019.140 .009.221.012 .050 .006.519.014 .110 .007.067.006 .160 .010.204.009 .168 .008
Hinge-ITMT.268.018.154.010.234.016.054.006.565.020.111.008.069.007.202.011.227.012.178.008
non-orderedST.268.018.154.010.234.016.054.006.565.020.111.008.069.007.202.011.227.012.178.008EOT .238 .015.138 .009.231.014 .051 .005.522 .012.108 .008.067.006 .164 .011.206 .011.167 .008
Hinge-IT MT,ST .268.018.146.010.221.014.052.005.544.013.111.008.069.006.169.009.226.012.177.008ordered EOT .234 .015.137 .009.218.015.051.005 .521 .013.108 .009.067.006 .161 .009.205 .010.167 .008
Hinge-AT MT,ST .260.019.147.010.228.013.053.005.525.013.111.008.068.007.164.010.213.012.176.009ordered EOT .237 .015.137 .009.224 .014.051 .005.519 .013.109.008.066.007 .158 .009.204 .008.167 .008
Logistic-ITMT.236.017.151.009.217.014.054.005.525.015.106.008.069.006.209.010.208.011.171.009
non-orderedST.236.017.137.009.217.014.054.005.525.015.106.008.068.006.209.010.208.011.168.009EOT.233.016.138.009.213.012 .050 .005.520.012.107.007 .064 .006.160 .011.204 .010.167.008
Logistic-IT MT,ST .232.016.137.010.213.014.053.005.525.014.107.007.066.006.161.012.208.010.168.008ordered EOT .232.016.137.008.210.014 .050 .005.522.013.107.007 .063 .006.157.010 .204 .011.167.008
Logistic-AT MT,ST,LB .230.015.137.008.219.015.052.005.524.014.108.007.064.006.160.011.205.011.167.008ordered EOT .231.014.137.009.216.013 .050 .005.522.013.107.008.063.007.157.011.207.012.167.008
OLR-NLL MT,ST,LB .230.016.137.010.212.014.051.005.522.013.106.007.065.007.159.010.205.010.167.009ordered EOT .231.016.137.008.209.014.050.005.521.014.106.007.063.006.158.011.207.013.167.008
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.049.004.174.007.045.003.387.009.106.006.140.006.172.006.142.006.004.001EOT .046 .004.171 .006.046.004.385.009 .105 .006.132 .006.167 .005.140.004 .003 .001
Hinge-ITMT.171.017.175.006.062.007.445.011.111.008.140.006.177.003.163.009.032.005
non-orderedST.170.017.175.006.062.007.445.011.112.007.140.006.177.003.163.009.032.005EOT .150 .020.170 .007.051 .004.421 .008.103 .005.124 .005.177.004 .152 .009.006 .001
Hinge-IT MT,ST .038.004.174.006.051.004.431.009.133.014.140.006.172.006.143.007.004.001ordered EOT .036 .004.170 .006.048 .004.420 .008.103 .005.125 .005.165 .005.137 .004.003 .001
Hinge-AT MT,ST .031.004.173.006.055.005.421.009.106.005.139.006.175.005.146.006.004.001ordered EOT .030.003 .170 .007.049 .004.420.008 .103 .005.118 .005.167 .005.138 .004.003 .001
Logistic-ITMT.100.008.177.008.057.005.442.009.105.006.112.005.172.005.144.005.043.008
non-orderedST.100.008.174.006.057.005.442.009.103.005.112.005.172.005.144.005.043.008EOT .075 .007.169 .007.050 .004.421 .007.102.004 .109 .005.163 .003.136 .004.007 .002
Logistic-IT MT,ST .030.004.167.006.046.003.433.010.104.005.112.005.163.004.137.004.003.001ordered EOT .029 .004.167.006.046.003 .422 .008.102 .005.110 .005.163.004 .135 .004.003 .001
Logistic-AT MT,ST,LB .029.003.171.006.053.004.422.009.102.005.111.005.163.004.137.004.004.001ordered EOT .028.003.169.008 .049 .004.422.008.102.005.111.005 .162 .003.135 .003.003 .001
OLR-NLL MT,ST,LB .029.003.171.007.050.004.420.008.101.005.109.005.163.004.136.004.010.003ordered EOT .028.004.169.007 .048 .003.420.007.101.005.108.005.162.004.136.004 .007 .001
34Published in Transactions on Machine Learning Research (1/2023)
Table 17: A counterpart of Table 2regarding MAE for Task-A and EL10 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 1.348.369.852.252.523.154.391.150 1.361.224 2.412.289.261.117.558.091.547.069.286.029EOT 1.412.376.888.261.536.149.431.193 1.351.247 2.366.257.248.107.563.087.557.077.289.027
Hinge-ITMT 1.354.416.881.313.553.166.561.170 1.343.216 2.369.370.272.128.579.077.583.077.382.029
non-orderedST 1.354.416.869.295.564.162.523.155 1.336.216 2.378.333.278.131.585.077.582.078.382.029EOT 1.412.374.872.268.513.157 .414 .165 1.354.229 2.349.322.265.116 .542 .079.555 .077.295 .032
Hinge-IT MT,ST 1.376.422.841.271.522.174.428.171 1.343.227 2.380.359.275.121.571.086.553.081.282.031ordered EOT 1.366.391.851.248.515.166.452.168 1.335.260 2.341.298.259.109 .537 .087.550.094.281.030
Hinge-AT MT,ST 1.322.363.844.224.525.147.467.188 1.334.231 2.350.312.287.129.552.083.542.072.285.028ordered EOT 1.358.401.868.255.493.142.456.192 1.339.239 2.365.320.265.111.549.088.555.076 .276 .028
Logistic-ITMT 1.366.407.924.261.578.155.583.200 1.385.230 2.368.359.294.146.559.077.552.073.307.031
non-orderedST 1.352.411.897.241.572.155.538.153 1.378.255 2.354.358.318.142.561.078.551.074.307.031EOT 1.354.396.840.256 .513 .153.526.227 1.351.259 2.394.360.269.113 .535 .084.557.079 .280 .025
Logistic-IT MT,ST 1.350.365.876.264.537.150.378.187 1.383.203 2.383.347.277.135.552.090.557.078.274.027ordered EOT 1.368.364.833.244.510.150.407.208 1.372.231 2.395.361.275.140.536.086.544.080.274.026
Logistic-AT MT,ST,LB 1.300.359.841.254.530.148.426.178 1.349.223 2.298.271.275.129.542.093.546.083.267.027ordered EOT 1.342.372.843.230.514.141.446.207 1.345.215 2.367.289.268.121.540.078.560.074.265.025
OLR-NLL MT,ST,LB 1.362.364.827.287.518.170.368.163 1.356.209 2.377.304.269.130.544.096.544.073.263.025ordered EOT 1.360.389.857.230.486.135.398.214 1.361.219 2.365.349.267.118.529.085.544.066.266.027
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.534.026.228.012.417.017.167.009.994.020.251.010.214.011.327.014.527.024.331.012EOT.534.021 .215 .012.417.017.167.009.995.020.253.013.212.010.322.014 .516 .022.326 .011
Hinge-ITMT.616.029.229.012.435.015.169.010 1.068.030.253.013.214.012.351.015.543.022.332.012
non-orderedST.607.030.229.012.435.016.168.008 1.068.030.253.013.213.012.353.017.543.022.332.012EOT .549 .023.213 .012.417 .020.164 .009 1.000.020.247 .011.207 .010.329 .015.512 .021.326 .011
Hinge-IT MT,ST .582.029.228.011.436.019.161.008 1.130.031.247.012.208.010.342.013.639.026.332.012ordered EOT .550 .021.210 .012.431.020.161.0091.003 .022.247.012.207.011.342.014.511 .020.325 .012
Hinge-AT MT,ST .557.033.224.013.427.018.163.008 1.014.025.249.011.208.012.326.012.524.019.332.011ordered EOT .533 .022.211 .013.427.019.164.010 .992 .023.248.011.207.011.324.012 .510 .019.323 .012
Logistic-ITMT.588.031.213.012.442.019.167.009 1.016.024.247.012.208.010.352.015.521.023.325.012
non-orderedST.562.029.217.012.421.019.165.007 1.016.024.247.012.208.010.355.016.521.023.323.011EOT .536 .024.208 .011.410 .018.160 .010.989 .021.246.011 .198 .010.327 .014.512 .020.321.011
Logistic-IT MT,ST .548.027.206.012.421.018.159.009 1.028.023.245.011.199.011.341.013.547.024.321.011ordered EOT .540 .027.207.011.420.019.158.007 .989 .021.243.011.200.011.336.014 .520 .021.320.011
Logistic-AT MT,ST,LB .529.020.206.011.417.021.161.007.993.022.246.011.201.010.322.012.511.021.320.012ordered EOT .535.026.208.011.416.020.159.008.991.020.245.012.200.010.320.014.511.022.321.011
OLR-NLL MT,ST,LB .526 .020.206.010.408.020.158.008.989.020.244.011.200.012.322.014.513.021.320.011ordered EOT .534.022.206.011.406.019.158.008.990.021.244.011.202.016.323.011.510.021.321.011
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.321.035.300.008.271.006.746.015.284.010.283.010.319.005.263.005.050.004EOT.312.037.298.008.271.005 .741 .014.285.010.283.009 .316 .004.262.005 .041 .004
Hinge-ITMT.211.023.329.014.327.011.867.013.314.011.348.012.348.005.308.007.080.008
non-orderedST.209.022.329.014.327.011.870.011.314.011.348.012.332.006.289.006.067.007EOT .196 .023.300 .008.301 .008.855 .011.300 .011.324 .011.317 .004.269 .005.039 .003
Hinge-IT MT,ST .392.018.300.009.265.005.772.015.330.013.376.038.325.006.269.004.047.005ordered EOT .257 .017.298 .008.264.006.726.012 .307 .011.339 .010.316 .005.268.005 .038 .004
Hinge-AT MT,ST .195.019.300.007.263.006.737.014.312.011.324.010.326.006.270.005.051.006ordered EOT .163 .016.297 .007.264.006.733.014 .295 .010.315 .010.316 .004.268.005 .043 .004
Logistic-ITMT.153.015.311.010.316.011.862.011.302.010.324.011.345.007.309.010.079.007
non-orderedST.153.015.309.009.316.011.864.011.302.010.321.011.331.006.294.008.071.006EOT .137 .013.298 .008.292 .007.853 .012.298 .011.313 .011.316 .004.268 .005.038 .003
Logistic-IT MT,ST .235.019.292.008.262.007.756.013.283.009.342.012.319.004.260.004.038.004ordered EOT .165 .014.292.007.261.007 .723 .010.272 .009.316 .011.317 .005.260.004 .033 .003
Logistic-AT MT,ST,LB .183.014.300.008.284.007.851.011.297.010.313.010.322.005.268.005.043.004ordered EOT .155 .013.297.007 .275 .006.849.010.295.010.310.010 .316 .005.266.005 .037 .003
OLR-NLL MT,ST,LB .151.013.298.007.281.007.848.012.295.010.307.011.321.004.267.005.040.003ordered EOT .135 .014.297.008 .275 .007.846.011.295.010.304.011.316.004 .266 .005.034 .003
35Published in Transactions on Machine Learning Research (1/2023)
Table 18: A counterpart of Table 2regarding RMSE for Task-S and EF3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.877.174.642.121.380.075.489.098.897.100.935.111.535.076.459.053.533.047.282.036EOT.884.152.622.135.372.085.486.106.889.108.930.111.521.072 .429 .045.532.049.279.037
Hinge-ITMT.887.200.639.118.391.076.470.098.896.095.937.122.528.074.459.059.520.049.282.035
non-orderedST.887.200.639.118.391.076.470.098.896.095.937.122.528.074.459.059.520.049.282.035EOT.888.126.628.106.387.065.463.102.878.112.919.103.524.070 .431 .050.517.046.273.035
Hinge-IT MT,ST .894.190.649.119.382.080.478.099.911.112.918.110.520.071.447.055.515.050.282.036ordered EOT .900.157.613.109.375.085.450.078.884.114.914.097.522.065.434.044.518.044.275.036
Hinge-AT MT,ST .908.165.639.102.381.078.483.103.900.118.915.112.510.074.450.053.517.045.277.036ordered EOT .874.135 .598 .108.377.070.475.087.893.105.931.119.524.075.436.048.513.048.274.036
Logistic-ITMT.843.183.672.141.388.086.491.088.914.097.938.118.504.073.444.058.516.043.278.035
non-orderedST.843.183.672.141.388.086.491.088.914.097.938.118.504.073.444.058.516.043.278.035EOT.871.146.631.109.377.065.484.075 .872 .096.920.115.508.072 .422 .045.502 .046.279.035
Logistic-IT MT,ST .849.178.671.119.379.097.496.085.896.105.920.127.519.077.441.052.502.048.269.035ordered EOT .876.137.636.097.358.075.473.074.878.100.933.117.515.074.425.042.500.055.271.035
Logistic-ATMT,ST.828.130.645.116.369.095.485.084.900.099.918.107.513.075.434.046.491.049.273.037
orderedLB.855.199.654.115.373.093.485.088.903.093.919.119.516.078.441.048.493.045.272.035EOT.880.146.633.102.360.077.476.082.883.107.925.116.517.083.427.046.496.053.275.030
OLR-NLLMT,ST.840.129.643.116.368.092.491.090.892.094.908.099.506.084.429.037.495.049.270.036
orderedLB.867.187.663.129.370.094.498.100.892.099.906.118.510.080.444.056.493.045.270.040EOT.878.146.633.098.359.081.475.072.882.112.912.109.520.085.422.046.493.052.275.032
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.651.021.613.011.426.010.419.010.597.014.326.012.456.010.409.011.630.014.627.012EOT .640 .018.610.011.422.011.419.010.597.012.327.012.456.012.408.010 .624 .014.623.011
Hinge-ITMT.660.022.631.013.397.012.416.011.593.011.319.013.456.012.404.012.640.017.629.013
non-orderedST.660.022.631.013.397.012.416.011.593.011.319.013.456.012.404.012.640.017.629.013EOT .637 .016.610 .010.396.012.415.011.593.012.318.013.454.011 .399 .010.624 .015.622 .010
Hinge-IT MT,ST .655.023.631.014.397.013.416.010.594.011.318.012.455.011.399.011.640.014.626.013ordered EOT .636 .018.611 .010.396.011.415.010.594.011.317.013.454.011.398.012 .624 .014.623.011
Hinge-AT MT,ST .638.018.620.014.395.013.416.011.591.011.318.013.454.010.401.010.628.013.624.011ordered EOT .638.018 .608 .010.398.013.416.011.592.011.316.012.453.010.398.012.623.014.623.010
Logistic-ITMT.643.023.608.011.393.012.413.011.593.010.318.011.448.009.418.011.636.014.625.011
non-orderedST.643.023.608.011.393.012.413.011.593.010.318.011.448.009.418.011.636.014.625.011EOT .634 .016.604 .010.391.011.411.011.591.010.317.012.448.010 .397 .010.623 .014.622.011
Logistic-IT MT,ST .640.020.607.010.391.012.413.011.593.011.318.011.449.010.401.011.635.014.626.011ordered EOT .633 .017.604.010.391.010.412.011.591.009.316.012.446.010.399.011 .623 .013.621 .011
Logistic-ATMT,ST.632.020.604.011.393.012.413.010.588.010.317.012.450.010.397.011.624.014.622.010
orderedLB.632.018.604.010.392.012.413.010.589.012.317.012.449.011.398.012.627.015.624.011EOT.632.015.602.010.392.013.413.012.589.011.316.012.447.009.395.011.623.014.622.010
OLR-NLLMT,ST.632.019.604.012.390.012.413.011.590.010.318.012.448.010.396.011.623.013.621.011
orderedLB.633.018.605.010.390.012.412.010.590.011.317.011.448.009.397.010.627.014.622.011EOT.633.017.603.009.390.012.412.011.591.011.316.013.447.010.395.012.623.015.622.011
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.564.007.501.008.576.009.537.007.583.009.559.007.366.005.345.005.095.024EOT.564.008.500.009.575.008.535.008.580.008.557.007.367.005.344.005.093.024
Hinge-ITMT.671.038.497.009.578.008.526.010.630.009.609.010.386.011.348.006.084.007
non-orderedST.671.038.497.009.578.008.526.010.630.009.609.010.386.011.348.006.084.007EOT .607 .011.497.009 .575 .008.524.010 .604 .008.588 .009.370 .004.346 .006.080 .007
Hinge-IT MT,ST .560.008.497.009.578.008.526.010.576.009.557.008.366.005.347.006.086.008ordered EOT .559.007.497.009 .575 .009.524.009.573.008.555.008.365.004 .345 .006.082 .007
Hinge-AT MT,ST .562.007.496.008.576.010.525.008.571.009.555.008.366.004.347.006.090.025ordered EOT .561.007.496.009.575.009.523.008.569.008.553.009.365.005.345.005.086.024
Logistic-ITMT.561.008.493.008.575.010.507.008.562.008.582.008.365.005.348.006.076.007
non-orderedST.561.008.493.008.575.010.507.008.562.008.582.008.365.005.348.006.076.007EOT.560.008.494.009 .570 .009.505.008 .558 .007.569 .008.365.004 .345 .006.073 .007
Logistic-IT MT,ST .560.007.493.009.575.009.510.009.561.008.547.008.365.005.341.005.086.035ordered EOT .560.007.493.009 .570 .009.506 .008.558 .007.545.007.365.004.341.005 .083 .036
Logistic-ATMT,ST.560.008.494.009.570.009.508.009.558.007.579.007.365.004.345.006.125.075
orderedLB.560.007.493.008.573.009.509.009.558.008.581.009.365.004.346.006.125.075EOT.559.007.493.009.570.008.507.008.557.008 .576 .008.365.004.344.006.122.074
OLR-NLLMT,ST.560.007.493.009.571.007.508.010.557.007.573.008.366.004.346.006.113.068
orderedLB.560.007.493.009.574.010.509.009.559.007.575.008.366.004.345.006.113.068EOT.559.007.493.009.572.008.507.009.556.007.570.008.365.004.344.005 .108 .067
36Published in Transactions on Machine Learning Research (1/2023)
Table 19: A counterpart of Table 2regarding RMSE for Task-S and EF5 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 1.435.284 1.051.275.664.098.763.133 1.407.196 1.454.181.769.098.594.055.714.085.425.028EOT 1.399.257 1.021.268.657.095.776.131 1.385.215 1.445.147.728 .088.604.049.712.073.419.031
Hinge-ITMT 1.444.291 1.073.272.702.103.825.150 1.457.245 1.539.243.802.104.583.054.702.068.454.043
non-orderedST 1.431.291 1.073.272.702.103.825.150 1.457.245 1.539.243.802.104.583.054.702.068.454.043EOT 1.339.250 1.068.306.662 .090.793.1281.362 .1941.444 .186.716 .089.592.055.695.065 .397 .033
Hinge-IT MT,ST 1.426.289 1.059.298.685.087.826.179 1.467.221 1.532.220.803.118.580.057.687.071.393.035ordered EOT 1.377.269 1.069.304.651 .089.771 .127 1.393.203 1.464.181.736 .089.579.059.693.064.392.035
Hinge-AT MT,ST 1.430.298 1.027.262.691.100.758.147 1.425.192 1.442.160.750.093.580.057.680.068.395.032ordered EOT 1.415.271 1.060.326.666.084.743.133 1.373.175 1.419.185.724.094.590.060.692.062.390.037
Logistic-ITMT 1.420.281 1.089.294.722.102.829.190 1.465.205 1.480.251.779.115.602.061.715.083.406.039
non-orderedST 1.413.277 1.089.294.722.102.829.190 1.465.205 1.480.251.779.115.602.061.715.083.406.039EOT 1.378.256 1.025.252.659 .087.774.1321.391 .2141.458.172.733 .083.580.059.697.064 .390 .033
Logistic-IT MT,ST 1.439.283 1.100.294.692.110.730.161 1.471.198 1.518.217.774.110.573.062.675.074.369.035ordered EOT 1.371.249 1.031.269.663.103.737.137 1.377.1901.441 .173.742.090.585.056.677.061.369.035
Logistic-ATMT,ST 1.339.267 1.008.310.703.087.706.104 1.386.183 1.415.145.730.088.577.056.670.065.369.032
orderedLB 1.374.273 1.089.299.715.102.697.139 1.426.193 1.447.204.746.098.567.054.665.067.369.033EOT 1.421.253 1.054.292.680.100.715.152 1.370.183 1.450.168.716.088.578.058.681.067.373.036
OLR-NLLMT,ST 1.312.247 1.041.315.700.104.714.1291.387 .1931.440.141.738.070.575.054.676.065.369.033
orderedLB 1.385.263 1.028.247.703.112.722.143 1.452.195 1.452.192.755.094.574.056.666.060.368.031EOT 1.400.281 1.012.283.665 .100.737.1351.378 .2091.436.163.729.079.587.054.675.064.368.034
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.982.026.843.018.570.013.579.011.906.017.455.011.647.014.532.014.975.021.945.017EOT .969 .024.835 .016.566.015 .573 .011.894 .017.453.013.648.013.533.014 .967 .019.923 .014
Hinge-ITMT 1.040.036.849.019.549.013.576.012.952.023.453.010.651.014.538.011 1.011.019 1.023.023
non-orderedST 1.040.036.849.019.549.013.576.012.952.023.453.010.651.014.538.011 1.011.019 1.023.023EOT .966 .024.832 .016.545.012 .572 .013.889 .017.452.010 .640 .012.522 .012.965 .017.921 .012
Hinge-IT MT,ST 1.043.039.847.018.549.013.574.011.946.021.451.011.646.014.530.012 1.013.019 1.044.022ordered EOT .964 .025.831 .016.548.013.570.010 .891 .015.453.009 .639 .013.528.013 .964 .017.922 .013
Hinge-AT MT,ST .968.024.837.017.548.012.570.012.901.017.453.010.639.014.524.012.968.022.935.017ordered EOT .961.021.833.016.546.013.569.010 .889 .016.452.010.637.013.524.011.963.019 .920 .012
Logistic-ITMT 1.026.031.883.022.553.014.570.012.913.019.452.011.641.015.570.014.993.022.988.020
non-orderedST 1.026.031.883.022.553.014.570.012.913.019.452.011.641.015.570.014.993.022.988.020EOT .962 .025.828 .016.540 .014.568.012 .889 .017.451.011 .636 .012.529 .012.963 .019.920 .013
Logistic-IT MT,ST 1.030.032.875.018.541.012.567.013.910.018.451.011.638.015.533.016.995.023.986.016ordered EOT .965 .021.829 .014.538.012.565.012 .889 .016.451.011 .633 .012.532.014 .963 .018.919.012
Logistic-ATMT,ST .959 .021.832 .016.542.012.568.013.890.016.452.010.633.013.515.011 .959 .017.920 .013
orderedLB.970.024.840.018.541.014.566.012.894.017.451.010.635.014.518.011.968.019.936.016EOT .959 .024.827 .016.540.012.566.011.889.015.451.009.633.014.516.012 .960 .018.918 .013
OLR-NLLMT,ST .960 .020.832 .015.537.013.565.011.891.016.451.011.634.015.519.012 .962 .017.922 .012
orderedLB.971.027.840.017.538.015.566.011.896.019.450.010.636.014.520.013.970.020.938.016EOT .961 .023.827 .015.536.013.566.010.888.016.451.010.634.013.520.014 .963 .018.920 .014
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.840.015.728.013.883.012.768.013.937.014.921.014.493.005.471.006.158.017EOT .823 .015.721 .011.876 .012.762 .012.929 .012.907 .011.492.005 .469 .006.148 .019
Hinge-ITMT.910.028.759.014.946.017.868.014.983.019.942.016.498.006.467.005.334.028
non-orderedST.910.028.759.014.946.017.868.014.983.019.942.016.498.006.467.005.334.028EOT .800 .015.732 .012.868 .012.841 .010.927 .012.891 .011.492 .005.464 .005.316 .023
Hinge-IT MT,ST .956.020.730.012.959.017.861.013.981.017.934.015.499.005.463.005.131.016ordered EOT .788 .013.719 .012.867 .013.840 .010.926 .012.890 .012.492 .004.462.004 .126 .014
Hinge-AT MT,ST .837.023.736.013.883.012.844.012.929.013.896.015.498.005.465.005.273.035ordered EOT .821 .019.732 .011.869 .013.840 .010.920 .011.885 .010.492 .005.464 .004.262 .034
Logistic-ITMT.955.020.755.014.936.016.859.014.973.016.922.017.497.006.468.007.285.015
non-orderedST.955.020.755.014.936.016.859.014.973.016.922.017.497.006.468.007.285.015EOT .788 .012.734 .011.871 .012.838 .010.923 .011.881 .010.493 .004.460 .005.267 .011
Logistic-IT MT,ST .967.021.723.012.957.017.854.013.974.016.913.015.496.004.461.005.129.013ordered EOT .784 .012.715 .011.870 .012.837 .011.922 .011.877 .010.493 .005.460.004 .123 .012
Logistic-ATMT,ST.791.012 .731 .012.872 .012.841.011 .917 .011.886 .013.496.005.461.006.295.069
orderedLB.790.013.737.013.888.013.843.012.925.014.896.014.496.005.461.006.295.069EOT .776 .011.730 .011.870 .012.840.010 .915 .011.883 .010.493 .005.460.006 .285 .071
OLR-NLLMT,ST.789.012 .730 .011.868 .012.838.011 .922 .012.879 .011.496.005.461.006.269.060
orderedLB.792.015.737.013.884.014.841.012.929.014.889.013.496.005.461.005.268.059EOT .774 .011.732 .012.867 .012.839.011 .920 .013.876 .011.492 .005.460.006 .261 .058
37Published in Transactions on Machine Learning Research (1/2023)
Table 20: A counterpart of Table 2regarding RMSE for Task-S and EF10 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 2.899.576 1.882.521 1.152.147 1.339.289 2.900.403 2.983.356 1.379.179 1.030.107 1.280.163.640.037EOT 2.922.529 1.872.499 1.102.148 1.327.247 2.816.352 2.945.320 1.378.189 1.055.102 1.287.150.649.050
Hinge-ITMT 2.861.563 1.919.600 1.182.134 1.433.309 2.956.434 2.961.373 1.480.173 1.044.107 1.306.161.707.073
non-orderedST 2.871.569 1.878.548 1.188.135 1.413.328 2.956.433 2.945.381 1.468.162 1.044.107 1.306.161.695.060EOT 2.811.581 1.860.4551.073 .1451.386.349 2.853.426 2.936.3621.396 .1881.067.113 1.263.156.657 .049
Hinge-IT MT,ST 2.977.551 1.961.543 1.170.136 1.354.304 2.941.417 2.934.356 1.531.186 1.045.107 1.285.137.629.050ordered EOT 2.904.544 1.920.5001.099 .1491.345.261 2.876.374 2.923.3661.398 .1651.054.108 1.277.140.624.044
Hinge-AT MT,ST 2.845.521 1.923.563 1.141.171 1.260.243 2.922.352 2.887.318 1.390.1711.014 .1091.224.123.598.042ordered EOT 2.782.535 1.879.522 1.112.159 1.258.2522.791 .3332.910.357 1.358.182 1.052.107 1.220.130.598.044
Logistic-ITMT 2.767.495 2.014.618 1.163.155 1.366.295 2.944.376 2.925.355 1.458.203 1.035.102 1.259.138.678.084
non-orderedST 2.770.499 2.028.623 1.151.161 1.348.300 2.940.372 2.934.403 1.447.199 1.035.102 1.259.138.676.082EOT 2.843.582 1.886.530 1.104.124 1.319.320 2.874.404 2.925.4041.381 .1571.048.102 1.242.120.648.052
Logistic-IT MT,ST 2.853.513 1.961.503 1.158.146 1.390.244 2.972.444 2.947.365 1.503.191 1.031.094 1.262.142.604.038ordered EOT 2.899.568 1.911.5151.107 .1481.317.247 2.849.378 2.937.4031.412 .1741.034.106 1.238.118.597.035
Logistic-ATMT,ST 2.740.477 1.918.562 1.143.133 1.267.259 2.848.331 2.894.342 1.373.175 1.009.096 1.212.119.577.037
orderedLB 2.802.495 1.981.587 1.147.154 1.286.251 2.906.341 2.890.359 1.400.174 1.017.096 1.216.123.584.043EOT 2.889.567 1.931.517 1.108.145 1.266.246 2.789.360 2.911.340 1.369.167 1.033.093 1.218.128.580.038
OLR-NLLMT,ST 2.792.472 1.888.561 1.159.112 1.241.269 2.876.353 2.881.294 1.400.201 1.006.097 1.227.126.587.033
orderedLB 2.812.494 1.963.627 1.150.146 1.231.249 2.896.365 2.888.332 1.413.210 1.002.103 1.233.137.584.032EOT 2.848.567 1.959.546 1.129.157 1.277.271 2.864.404 2.913.352 1.368.168 1.027.103 1.224.129.582.036
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT 1.857.056 1.558.032.926.031.979.019 1.698.034.688.015 1.124.026.842.026 1.865.038 1.738.031EOT 1.838 .0451.535 .028.917 .026.970 .019 1.690.031.688.013 1.119.027.838.028 1.857.0371.723 .027
Hinge-ITMT 1.915.057 1.626.028.917.026.993.021 1.739.033.687.013 1.148.026.854.020 1.877.035 1.766.031
non-orderedST 1.915.057 1.626.028.917.026.993.021 1.739.033.687.013 1.148.026.854.020 1.877.035 1.766.031EOT 1.849 .0481.533 .029.898 .023.975 .0171.685 .033.682 .0121.121 .025.837 .0201.854 .0381.721 .029
Hinge-IT MT,ST 1.973.063 1.641.030.920.030.987.020 1.912.053.683.012 1.145.030.859.023 1.929.040 1.784.031ordered EOT 1.861 .0451.547 .026.906 .026.971 .0201.695 .034.681.0131.117 .026.850 .0221.856 .0361.725 .026
Hinge-AT MT,ST 1.844.057 1.570.028.905.023.951.018 1.709.035.683.013 1.102.027.821.020 1.860.038 1.747.028ordered EOT 1.826.0461.532 .028.904.022.951.0161.685 .035.680.011 1.099.024.819.018 1.851.0361.720 .029
Logistic-ITMT 1.893.063 1.619.029.905.026.981.018 1.726.035.685.014 1.137.030.856.026 1.869.038 1.761.034
non-orderedST 1.893.063 1.619.029.905.026.981.018 1.726.035.685.014 1.137.030.856.026 1.869.038 1.761.034EOT 1.847 .0471.535 .026.890 .029.967 .0171.686 .036.681.0131.118 .025.833 .0181.853 .0351.720 .028
Logistic-IT MT,ST 1.934.063 1.629.029.920.028.975.018 1.787.037.680.014 1.129.031.876.021 1.892.040 1.769.033ordered EOT 1.863 .0441.552 .030.909 .028.960 .0181.688 .032.679.0131.116 .026.860 .0171.856 .0381.723 .027
Logistic-ATMT,ST 1.824 .0481.533 .026.903.021.951.016 1.683.032.680.013 1.095.023.820.020 1.850.0341.721 .027
orderedLB 1.844.051 1.545.028.905.022.949.017 1.693.033.680.012 1.097.025.823.022 1.862.038 1.732.030EOT 1.826 .0441.531 .028.901.024.947.017 1.683.033.680.012 1.094.022.817.019 1.849.0361.720 .029
OLR-NLLMT,ST 1.831.0501.532 .029.893.030.953.018 1.684.033.681.014 1.097.026.826.0191.851 .0341.720 .027
orderedLB 1.848.054 1.549.031.893.030.957.017 1.693.034.681.013 1.102.024.827.020 1.864.039 1.734.031EOT 1.833.0471.529 .027.891.030.949.014 1.682.032.680.013 1.098.025.827.0201.851 .0371.718 .029
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT 1.569.024 1.291.020 1.669.024 1.386.025 1.620.025 1.574.017.770.007.727.008.632.104EOT 1.557 .0211.287.0211.649 .0191.378 .0241.608 .0201.561 .020.766 .006.724 .007.601 .105
Hinge-ITMT 1.813.044 1.348.024 1.723.029 1.611.024 1.865.034 1.758.028.779.007.727.006.739.110
non-orderedST 1.813.044 1.348.024 1.723.029 1.611.024 1.865.034 1.758.028.779.007.727.006.739.110EOT 1.605 .0261.322 .0221.641 .0221.564 .0191.785 .0241.692 .022.767 .006.720 .005.665 .099
Hinge-IT MT,ST 1.868.045 1.314.017 1.740.031 1.657.029 2.000.040 1.904.040.780.008.723.007.487.106ordered EOT 1.533 .0201.286 .0201.653 .0221.566 .0181.783 .0211.709 .024.767 .007.718 .007.464.096
Hinge-AT MT,ST 1.540.020 1.329.022 1.655.024 1.576.021 1.763.024 1.688.024.776.007.719.007.522.094ordered EOT 1.538.0201.316 .0201.639 .0251.565 .0201.746 .0211.668 .023.767 .006.715 .007.480 .065
Logistic-ITMT 1.893.031 1.341.024 1.711.026 1.600.024 1.847.030 1.748.029.775.007.732.010.635.139
non-orderedST 1.892.031 1.341.024 1.711.026 1.600.024 1.847.030 1.748.029.775.007.732.010.635.139EOT 1.597 .0301.319 .0191.641 .0211.564 .0191.778 .0231.686 .025.767 .006.719 .006.576 .102
Logistic-IT MT,ST 1.824.044 1.308.021 1.718.026 1.416.031 1.743.031 1.653.026.771.007.722.009.456.074ordered EOT 1.529 .0191.288 .0191.670 .0221.391 .0241.635 .0221.572 .020.767 .007.716 .007.437 .069
Logistic-ATMT,ST 1.541.0201.318 .0191.643 .0231.568 .0211.751 .0211.677 .023.773.008.719.007.541.101
orderedLB 1.545.021 1.327.021 1.664.024 1.577.023 1.767.025 1.698.026.772.008.720.008.538.101EOT 1.541.0221.316 .0211.638 .0211.563 .0201.747 .0201.669 .022.767 .006.716 .006.514 .100
OLR-NLLMT,ST 1.596 .0231.319 .0211.639 .0231.562 .0211.767 .0221.668 .023.772.007.717.006.515.114
orderedLB 1.620.026 1.328.023 1.667.028 1.572.024 1.782.027 1.687.024.772.007.718.007.511.114EOT 1.575 .0201.316 .0211.634 .0221.560 .0201.766 .0221.665 .022.766 .007.716.007.492.112
38Published in Transactions on Machine Learning Research (1/2023)
Table 21: A counterpart of Table 2regarding RMSE for Task-S and EL3 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.560.126.407.155.362.083.259.108.629.102.859.113.205.104.452.046.481.058.198.040EOT.607.119.400.131.352.096.258.118.634.093.863.111.197.104 .433 .055.468.056.203.038
Hinge-ITMT.574.129.421.180.384.085.248.120.625.100.922.106.199.105.443.058.449.049.176.032
non-orderedST.574.129.421.180.384.085.248.120.625.100.922.106.199.105.443.058.449.049.176.032EOT.608.130.432.138 .347 .082.264.106.640.095 .853 .106.198.115 .416 .053.442.042.186.033
Hinge-IT MT,ST .552 .137.414.156.380.075.263.098.618.092.936.102.207.106.447.048.448.051 .172 .034ordered EOT .610.140.405.167 .344 .094.268.138.633.088 .870 .113.206.114 .418 .056.444.047.186.032
Hinge-AT MT,ST .567.137.407.164.379.086.276.098.610.088.882.119.208.103.445.048.458.054 .167 .044ordered EOT .597.133.430.142 .343 .083.287.103.625.083.861.112.199.114 .410 .060.454.050.183.030
Logistic-ITMT.617.126.473.159.392.113.245.115.664.110.887.112.232.105.408.053.430.055.168.033
non-orderedST.617.126.473.159.392.113.245.115.664.110.887.112.232.105.408.053.430.055.168.033EOT.621.130 .449 .169.348.099.266.114.631.096 .833 .103.218.121.401.057.427.055.170.033
Logistic-IT MT,ST .618.127.473.177.380.094.244.111.647.097.895.106.231.093.409.050.401.044.168.032ordered EOT .646.119.462.183 .345 .096.269.122.632.094 .835 .106.228.104.401.053.415.055.173.033
Logistic-ATMT,ST.604.140.456.171.381.090.263.098.630.098.801.088.232.099.404.050.417.051.169.029
orderedLB.629.109.467.164.380.088.262.099.630.092.864.120.234.098.406.050.410.048.170.028EOT.626.118.446.155 .346 .082.271.111.637.104.837.105.225.103.400.049.419.047.170.030
OLR-NLLMT,ST.618.119.455.161.366.087.256.108.640.108 .792 .083.227.111.407.052.405.045.171.028
orderedLB.623.120.459.172.372.099.254.108.633.103.859.103.236.100.408.050.416.055.172.033EOT.636.113.461.173.344.086.263.122.631.103 .822 .092.224.104.405.049.425.056.170.029
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.488.014.172.012.445.013.107.016.554.015.255.019.120.014.355.011.317.021.248.008EOT.489.014.173.013.440.016.106.014 .539 .012.233 .011.121.014 .346 .010.297 .012.247.008
Hinge-ITMT.486.012.172.012.387.013.101.011.530.012.235.014.115.012 .331 .013.305.012.248.008
non-orderedST.486.012.172.012.387.013.101.011.530.012.235.014.115.012 .331 .013.305.012.248.008EOT.487.015.172.013.385.014.102.012.530.011.233.013.113.011.336.015.301.014.246.007
Hinge-IT MT,ST .485.012.172.012.383.015.102.010.530.011.232.012.114.011 .331 .013.305.011.248.008ordered EOT .486.013.173.012.381.015.102.011.530.012.233.013.114.011.337.012 .299 .013.247.008
Hinge-AT MT,ST .486.012.172.012.379.012.101.013.529.011.234.012.115.010.338.014.304.011.248.008ordered EOT .486.013.172.012.378.013.101.013.530.011.233.011.114.011.342.014 .299 .012.247.008
Logistic-ITMT.483.015.169.012.372.010.108.014.526.010.231.011.117.013.313.013.301.013.246.008
non-orderedST.483.015.169.012.372.010.108.014.526.010.231.011.117.013.313.013.301.013.246.008EOT.481.013.173.012.372.012 .102 .012.526.010.231.010.114.011.313.013.301.012.246.008
Logistic-IT MT,ST .481.013.170.013.364.011.104.012.526.011.230.010.115.011.303.012.300.013.246.008ordered EOT .480.013.172.014.362.012.102.012.527.011.231.011.114.011.301.012.300.012.247.007
Logistic-ATMT,ST.481.014.171.012.364.012.103.013.526.010.231.010.115.012.304.010.300.014.247.008
orderedLB.481.014.170.012.364.012.103.012.526.010.230.010.116.012.304.010.300.013.247.008EOT.478.014.173.013.362.012.101.012.526.009.231.011.116.012.303.010.301.014.247.008
OLR-NLLMT,ST.480.014.170.012.363.010.101.011.527.010.230.011.115.010.305.011.301.013.246.008
orderedLB.481.014.170.012.363.010.104.012.529.012.231.011.115.010.306.011.301.013.246.008EOT.481.014.173.013.363.011.102.011.527.011.230.011.115.011.306.012.300.013.247.007
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.327.015.262.009.138.007.489.006.197.008.234.013.307.005.353.016.040.007EOT.323.015.262.009 .136 .008.488.007.197.009 .224 .011.308.005.351.012.038.006
Hinge-ITMT.351.012.262.009.138.007.478.007.189.007.235.010.308.005.306.010.041.007
non-orderedST.351.012.262.009.138.007.478.007.189.007.235.010.308.005.306.010.041.007EOT .325 .014.262.008.135.009.477.007.189.008 .225 .010.308.005 .303 .010.038 .006
Hinge-IT MT,ST .353.012.262.009.138.008.477.007.191.008.232.013.307.005.302.009.041.007ordered EOT .327 .014.262.009 .134 .007.476.008.189.007 .210 .009.308.004.300.009.039.007
Hinge-AT MT,ST .345.013.262.009.139.008.481.007.190.008.208.009.307.005.302.009.042.006ordered EOT .326 .014.263.008 .135 .008.481.008.190.007.208.008.308.005.300.008 .038 .005
Logistic-ITMT.242.013.266.008.138.008.459.007.189.007.226.010.308.005.290.006.039.007
non-orderedST.242.013.266.008.138.008.459.007.189.007.226.010.308.005.290.006.039.007EOT .202 .013.263.009 .133 .008.459.007.190.008 .217 .009.308.005.289.006 .035 .006
Logistic-IT MT,ST .246.011.265.009.132.008.460.008.189.007.207.009.307.005.285.007.039.006ordered EOT .201 .014.263.009.131.008.459.008.189.007.208.009.308.005.284.006 .036 .006
Logistic-ATMT,ST.203.013.264.009.137.007.459.007.188.007.206.009.308.005.286.006.039.006
orderedLB.210.014.264.009.137.008.458.006.188.008.207.009.308.005.286.006.039.006EOT .199 .012.263.008 .133 .008.458.008.189.007.208.009.308.005.284.006 .037 .006
OLR-NLLMT,ST .199 .013.264.010.137.008.460.007.189.008.216.008.308.005.287.006.040.006
orderedLB.207.013.264.009.137.008.460.006.188.007.217.009.308.005.287.006.040.006EOT .197 .013.263.010 .133 .008.459.007.188.007.216.009.308.004.285.006 .037 .005
39Published in Transactions on Machine Learning Research (1/2023)
Table 22: A counterpart of Table 2regarding RMSE for Task-S and EL5 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT.975.218.798.203.498.168.481.235 1.089.186 1.375.170.343.130.525.054.603.059.408.031EOT .901 .191.820.205.502.152.498.240 1.084.153 1.362.138.343.136.524.059.605.063.408.039
Hinge-ITMT.991.308.789.263.514.168.520.226 1.115.172 1.389.160.371.159.537.057.631.061.455.035
non-orderedST.991.308.775.237.524.168.520.225 1.108.168 1.390.162.386.164.537.057.631.061.455.035EOT .867 .192.814.215.505.158.524.235 1.107.159 1.367.149.365.131 .514 .053.599 .060.405 .028
Hinge-IT MT,ST .965.231.813.218.502.167.524.217 1.093.175 1.408.159.384.157.529.055.600.056.383.032ordered EOT .898.194.811.206.491.164.508.210 1.086.157 1.375.160.354.138.526.060.604.060.381.033
Hinge-AT MT,ST .998.245.787.215.486.178.514.194 1.077.160 1.364.179.364.152.523.051.601.076.390.039ordered EOT .871 .185.802.204.488.165.513.209 1.069.156 1.356.174.363.124.524.051.605.062.384.032
Logistic-ITMT.973.223.856.268.528.160.525.181 1.123.187 1.400.224.424.186.525.050.624.059.380.030
non-orderedST.969.226.825.215.540.163.522.180 1.115.167 1.399.223.433.198.525.050.624.059.380.030EOT .875 .199.808.226.499.153.529.186 1.074.156 1.370.173.400.171.510.052 .581 .062.374.036
Logistic-IT MT,ST .947.189.815.216.541.157.505.190 1.101.160 1.452.212.418.175.506.050.581.065.358.030ordered EOT .903.196.798.219.501.153.511.183 1.085.151 1.387.187.401.167.512.060.586.065.356.033
Logistic-ATMT,ST.920.227.812.214.492.160.484.182 1.085.146 1.362.168.399.160.517.051.573.057.359.027
orderedLB.929.211.819.232.510.161.481.176 1.090.152 1.365.163.408.171.513.051.579.064.360.027EOT.883.211.812.216.498.142.496.201 1.080.148 1.392.196.384.166.515.053.586.065.359.027
OLR-NLLMT,ST.934.174.821.214.512.159.476.184 1.078.163 1.369.185.421.179.509.045.579.061.356.031
orderedLB.931.233.837.224.515.162.491.199 1.108.163 1.399.201.420.179.514.048.584.060.358.030EOT.883.191.800.225.490.151.502.207 1.084.158 1.393.190.403.156.517.053.588.066.359.028
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.596.032.404.012.474.013.228.013.791.016.336.013.262.012.405.011.522.018.430.011EOT .524 .023.376 .012.471.013 .224 .013.785 .013.331 .011.260.012 .400 .012.505 .016.413 .010
Hinge-ITMT.583.027.398.014.486.017.238.015.843.020.333.012.264.013.450.013.580.020.430.011
non-orderedST.583.027.398.014.486.017.235.013.843.020.333.012.263.012.450.013.580.020.430.011EOT .521 .021.371 .012.483.015 .228 .014.785 .013.329 .012.261.011 .405 .013.507 .016.412 .010
Hinge-IT MT,ST .583.027.385.014.471.016.230.012.820.015.333.012.263.011.411.011.574.023.429.011ordered EOT .512 .022.371 .012.468.016.227.012 .786 .013.329 .013.261.011 .401 .011.501 .017.412 .010
Hinge-AT MT,ST .567.029.387.014.480.014.231.011.793.014.333.012.262.012.405.012.536.022.428.011ordered EOT .511 .021.371 .011.477.014 .226 .011.783 .014.330.012.259.013 .397 .010.503 .017.412 .011
Logistic-ITMT.522.026.394.013.468.016.236.013.794.015.326.012.265.013.458.011.524.019.420.012
non-orderedST.522.026 .371 .012.468.016.236.012.794.015.326.012.262.012.458.011.524.019 .412 .011EOT .509 .018.372 .011.463.014 .226 .012.785 .012.327.011 .255 .012.400 .013.502 .016.412 .010
Logistic-IT MT,ST .513.023.370.014.463.016.233.011.795.014.328.010.259.013.401.015.529.018.413.010ordered EOT .510.019.371.012.461.016 .224 .012.786 .013.326.011 .252 .012.396.012 .501 .016.412.010
Logistic-ATMT,ST.507.020.370.012.470.017.227.011.787.014.328.011.254.012.399.015.505.017.413.010
orderedLB.510.022.370.011.469.016.229.012.791.016.328.011.256.013.400.013.508.016.412.010EOT.508.019.370.012.468.016.224.011.788.013.327.012.252.013.397.013.505.018.412.009
OLR-NLLMT,ST.509.019.370.012.462.016.226.012.787.012.326.011.256.012.399.013.505.014.412.010
orderedLB.508.023.370.014.462.016.229.013.789.014.326.011.256.014.399.013.508.018.412.011EOT.508.018.371.011.459.015.224.011.786.013.325.011.252.011.397.013 .500 .018.412.010
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT.250.015.419.009.213.007.688.010.384.017.492.017.415.007.376.008.065.008EOT .241 .015.415 .007.214.009 .683 .009.373 .014.438 .014.409 .006.374 .006.057 .008
Hinge-ITMT.592.048.421.008.252.015.763.013.397.024.492.017.421.004.404.011.177.014
non-orderedST.589.047.421.008.252.015.763.013.401.022.492.017.421.004.404.011.177.014EOT .534 .057.415 .010.226 .009.718 .009.369 .011.423 .014.421.004 .390 .011.076 .008
Hinge-IT MT,ST .207.014.420.008.229.008.741.010.468.042.492.017.415.007.378.009.065.007ordered EOT .203.014 .414 .007.219 .009.718 .009.369 .012.422 .012.407 .006.370 .005.056 .006
Hinge-AT MT,ST .180.012.419.008.237.010.722.008.373.013.489.018.418.006.381.008.066.009ordered EOT .177.012 .414 .009.223 .010.715 .010.361 .012.410 .013.409 .006.372 .005.058 .007
Logistic-ITMT.370.021.424.009.242.012.762.012.380.015.405.014.414.006.380.006.206.019
non-orderedST.370.021.419.008.242.012.762.012.372.014.402.014.414.006.380.006.206.019EOT .308 .020.414 .010.225 .009.718 .010.364 .012.392 .013.403 .004.369 .005.083 .010
Logistic-IT MT,ST .176.011.412.008.214.006.744.010.381.013.407.014.404.005.370.006.059.007ordered EOT .172.012.411.008.214.008 .718 .008.365 .012.392 .014.403.005 .368 .006.051 .007
Logistic-ATMT,ST.174.011.413.008.235.010 .718 .009.357.012.391.014.404.005.370.005.060.007
orderedLB.174.012.416.008.233.008.721.009.360.014.393.013.404.005.370.005.060.007EOT.171.010.413.009 .222 .008.716 .008.357.011.391.012 .402 .004.367 .005.053 .007
OLR-NLLMT,ST.173.012.414.008.223.009 .717 .009.359.013.390.014.403.005.369.006.098.013
orderedLB.173.012.417.008.224.008.720.009.361.012.393.013.403.005.369.006.098.013EOT.171.013.414.009 .219 .008.715 .008.357.012.389.014.403.004.368.005 .082 .009
40Published in Transactions on Machine Learning Research (1/2023)
Table 23: A counterpart of Table 2regarding RMSE for Task-S and EL10 datasets.
Learning Labeling DIA PYR APR SER TRI WBC CPU AMP BOS STO
ADNNT 1.741.419 1.276.544.961.300.935.411 1.943.315 2.858.296.674.286.867.101.983.135.539.028EOT 1.736.397 1.309.534.898.241 1.034.439 1.927.290 2.817.347.633.277.878.098.997.137.544.028
Hinge-ITMT 1.831.450 1.310.587.984.299 1.192.373 1.941.289 2.856.424.699.306.897.092 1.005.137.627.028
non-orderedST 1.831.450 1.312.569 1.020.301 1.107.361 1.936.304 2.764.330.714.320.904.089 1.007.137.627.028EOT 1.731.400 1.276.497.916.266 1.019.328 1.940.309 2.813.380.691.331.873.116.970.135 .550 .034
Hinge-IT MT,ST 1.801.469 1.282.515.958.306 1.057.400 1.939.314 2.821.450.718.304.884.105.981.148.535.033ordered EOT 1.705.367 1.301.473.896.272 1.055.372 1.915.317 2.761.317.692.285.853.093.963.140.533.029
Hinge-AT MT,ST 1.690.418 1.285.514.950.293 1.032.400 1.895.299 2.769.289.731.351.873.099.966.135.535.028ordered EOT 1.703.345 1.277.487.888.263 1.120.421 1.898.295 2.808.385.671.289.871.111.948.135.531.030
Logistic-ITMT 1.713.467 1.325.539 1.033.290 1.237.389 1.944.293 2.770.348.750.376.868.095.973.144.557.030
non-orderedST 1.708.460 1.310.528 1.042.300 1.114.304 1.920.303 2.785.362.801.374.867.097.972.144.557.030EOT 1.732.427 1.284.468.881 .256 1.099.301 1.907.284 2.825.331.672.278.855.106.971.131 .533 .026
Logistic-IT MT,ST 1.758.411 1.312.527.970.278.942.381 1.959.328 2.806.376.715.380.854.106.963.131.525.029ordered EOT 1.733.352 1.276.486.890 .259.959.349 1.927.318 2.780.374.706.361.856.123.947.141.526.024
Logistic-ATMT,ST 1.679.400 1.242.494.935.256.995.368 1.898.277 2.745.283.707.365.858.098.922.134.519.028
orderedLB 1.658.412 1.252.525.940.257 1.020.390 1.930.284 2.715.269.699.366.863.108.938.143.519.027EOT 1.715.392 1.328.509.910.242 1.089.384 1.911.279 2.793.326.661.300.864.113.956.140.518.029
OLR-NLLMT,ST 1.678.368 1.213.495.914.274.890.321 1.914.277 2.745.298.705.341.842.104.928.128.516.029
orderedLB 1.704.438 1.234.556.919.278.912.349 1.915.298 2.781.348.700.351.855.109.943.142.515.026EOT 1.720.401 1.284.479.863.233.957.379 1.907.278 2.794.332.648.287.842.101.946.133.519.032
Learning Labeling ABA AI2 KRA CO1 PU1 BA1 CO2 PU2 BA2 EL2
ADNNT.886.037.512.019.679.019.412.012 1.392.026.509.011.469.013.575.013 1.064.036.639.017EOT.887.030 .488 .018.676.019.412.011 1.383.025.509.012.468.013.571.0131.004 .033.621 .016
Hinge-ITMT 1.003.048.517.017.703.014.418.017 1.503.039.511.015.477.018.600.015 1.112.039.640.018
non-orderedST.981.047.517.017.701.015.416.017 1.503.039.511.015.472.016.600.016 1.112.039.640.018EOT .913 .036.482 .016.679 .023.413.0161.389 .025.502 .012.463 .013.578 .013.999 .033.622 .015
Hinge-IT MT,ST 1.005.047.515.018.700.020.408.014 1.598.038.501.012.462.014.590.013 1.349.042.641.019ordered EOT .915 .033.478 .015.694.022.407.0131.390 .028.500.012.463.015.590.012 .994 .029.621 .014
Hinge-AT MT,ST .939.053.507.019.692.022.410.012 1.413.030.504.012.463.014.577.012 1.060.036.643.018ordered EOT .883 .033.478 .016.689.023.409.0121.379 .024.503.011.462.013.574.012 .993 .030.616 .015
Logistic-ITMT.982.044.493.020.715.020.413.016 1.422.029.502.013.466.014.601.015 1.043.035.631.021
non-orderedST.913.040.491.017.687.021.411.013 1.422.029.502.013.463.014.601.015 1.043.035.624.016EOT .881 .031.475 .014.670 .022.406 .0151.375 .024.501.011 .454 .012.578 .0141.000 .027.613 .014
Logistic-IT MT,ST .932.036.476.016.689.023.402.011 1.450.027.498.012.454.014.588.013 1.120.044.622.016ordered EOT .884 .033.473.013.685.025.403.0121.377 .022.497.012.455.015 .584 .0121.012 .029.613 .015
Logistic-ATMT,ST.866.027.473.015.680.026.404.010 1.377.024.500.012.456.013.571.012 1.001.027.612.015
orderedLB.875.031.473.014.680.025.404.009 1.384.026.500.011.455.013.572.012 1.019.032.612.015EOT.873.029.474.014.677.024.403.011 1.378.023.499.012.455.013.571.014 .991 .029.614.015
OLR-NLLMT,ST.871.030.474.014.668.026.404.011 1.378.023.499.014.456.013.571.012 1.000.030.614.015
orderedLB.874.030.475.015.670.024.401.011 1.384.026.498.012.456.015.572.013 1.015.032.613.015EOT.877.029.473.014.668.025.403.012 1.375.025.498.012.457.012.572.011 .997 .030.613.014
Learning Labeling POT AI1 EL1 CAL CE1 CE2 2DP FRA MVA
ADNNT 1.084.112.575.010.528.007 1.174.017.710.020.748.030.567.005.513.005.223.009EOT 1.046 .102.574.011.529.007 1.169.016.702 .020.746.030 .564 .004.512.005 .202 .010
Hinge-ITMT.750.075.620.023.607.014 1.324.018.787.024.910.031.597.005.562.008.286.015
non-orderedST.745.073.620.023.607.014 1.324.019.787.024.910.031.580.006.539.006.257.012EOT .698 .063.577 .010.572 .0111.288 .015.739 .025.827 .030.565 .004.519 .005.197 .008
Hinge-IT MT,ST 1.194.047.577.011.523.006 1.259.021.833.029.977.063.572.005.519.004.216.012ordered EOT .838 .049.574.010.521.0071.155 .015.757 .026.845 .029.564 .004.518.004 .196 .011
Hinge-AT MT,ST .679.052.575.011.521.006 1.164.019.765.026.817.027.573.005.520.005.225.013ordered EOT .604 .041.574.010.519.0061.150 .017.715 .026.789 .025.564 .004.519.005 .207 .009
Logistic-ITMT.558.041.593.011.586.012 1.312.019.745.024.836.032.592.006.563.012.283.012
non-orderedST.558.041.590.012.586.012 1.312.019.745.024.825.030.578.006.545.008.267.011EOT .514 .042.574 .011.558 .0101.284 .017.726 .027.794 .028.565 .004.518 .005.194 .008
Logistic-IT MT,ST .744.050.569.010.518.007 1.245.017.752.028.899.036.567.004.510.004.194.011ordered EOT .567.041.568.010.518.0071.151 .016.688 .022.804 .031.565 .004.510.004 .181 .008
Logistic-ATMT,ST .567 .038.574.010.545.0081.276 .017.712 .024.774 .028.569.004.519.005.210.009
orderedLB.616.038.575.011.547.009 1.289.017.724.026.787.029.569.004.519.005.208.011EOT .555 .034.574.010 .532 .0071.275 .018.708 .023.773 .026.564 .004.516 .005.192 .008
OLR-NLLMT,ST.502.042.574.010.545.0091.278 .018.722 .024.780 .029.569.004.518.005.200.008
orderedLB.529.043.574.010.544.008 1.288.018.732.026.791.029.568.004.518.005.199.008EOT .488 .040.573.011 .531 .0071.275 .017.721 .025.780 .028.564 .004.516 .005.183 .008
41Published in Transactions on Machine Learning Research (1/2023)
Table 24: The number 𝑁Z(resp.,𝑁A,𝑁S) of times that each method was best for Task-Z (resp., Task-A, S)
in each dataset group in the form ‘ 𝑁Z,𝑁A,𝑁S’, and their summation in the column ‘SUM’. The larger the
number, the better than method is for that dataset group and that task.
Learning Labeling RW EF3 EF5 EF10 EL3 EL5 EL10 SUM
ADNNT 2,1,1 0,0,0 0,0,0 1,2,0 1,1,1 4,3,1 0,1,0 8,8,3
EOT 0,2,0 1,0,0 4,1,1 9,5,3 1,2,3 3,3,3 3,1,3 21,14,13
Hinge-ITMT 0,0,0 1,0,0 0,0,0 0,1,0 2,1,1 1,0,0 0,0,0 4,2,1
non-orderedST 0,0,0 1,0,0 0,1,0 0,0,0 2,1,1 1,0,1 0,0,0 4,2,2
EOT 3,3,1 0,0,0 2,0,2 1,0,2 1,3,1 0,0,1 0,0,0 7,6,7
Hinge-IT MT,ST 0,0,0 0,0,0 0,0,0 1,0,0 2,2,1 0,0,0 1,0,0 4,2,1
ordered EOT 2,2,1 1,1,1 2,3,3 1,0,1 1,0,0 0,1,0 2,0,0 9,7,6
Hinge-AT MT,ST 0,1,1 0,1,0 0,0,0 0,1,0 3,3,3 2,2,1 1,2,1 6,10,6
ordered EOT 2,3,4 1,2,1 2,5,0 2,1,2 0,0,1 1,1,3 0,1,1 8,13,12
Logistic-ITMT 0,0,0 2,4,1 0,0,0 0,0,0 1,2,1 0,0,0 0,0,0 3,6,2
non-orderedST 0,0,0 2,4,1 0,0,0 0,0,0 1,2,1 0,0,0 0,0,0 3,6,2
EOT 2,3,4 5,4,5 0,0,0 0,0,1 2,2,2 1,1,1 2,2,1 12,12,14
Logistic-IT MT,ST 1,0,0 1,1,1 1,0,0 2,0,0 3,5,2 1,0,1 3,1,0 12,7,4
ordered EOT 1,0,0 8,7,6 4,4,3 2,2,3 5,5,4 4,6,4 7,8,6 31,32,26
Logistic-ATMT,ST 0,0,1 1,2,3 3,4,5 1,3,4 0,0,1 0,1,3 3,3,3 8,13,20
orderedLB 0,0,0 0,2,1 2,4,3 2,3,0 1,0,1 0,1,0 0,3,3 5,13,8
EOT 2,4,5 3,2,5 4,2,3 1,2,5 2,1,2 4,4,4 2,2,2 18,17,26
OLR-NLLMT,ST 1,0,0 1,2,2 1,3,1 2,4,1 1,0,1 1,1,1 2,4,3 9,14,9
orderedLB 1,0,1 2,2,1 1,3,1 2,4,2 0,0,1 1,1,0 2,4,2 9,14,8
EOT 4,4,0 2,3,2 3,6,7 2,8,5 3,4,3 6,6,5 1,4,4 21,35,26
42