Published in Transactions on Machine Learning Research (04/2023)
Prior and Posterior Networks: A Survey on Evidential Deep
Learning Methods For Uncertainty Estimation
Dennis Ulmer☼,/compress-arrows-al◎dennis.ulmer@mailbox.org
Christian Hardmeier☼,/compress-arrows-al◎chrha@itu.dk
Jes Frellsen♂robot,/compress-arrows-al◎jefr@dtu.dk
☼IT University of Copenhagen,♂robotTechnical University of Denmark,/compress-arrows-al◎Pioneer Centre for Artificial Intelligence
Reviewed on OpenReview: https: // openreview .net/ forum? id= 1HVpTXwZxK
Abstract
Popular approaches for quantifying predictive uncertainty in deep neural networks often in-
volve distributions over weights or multiple models, for instance via Markov Chain sampling,
ensembling, or Monte Carlo dropout. These techniques usually incur overhead by having to
train multiple model instances or do not produce very diverse predictions. This comprehen-
sive and extensive survey aims to familiarize the reader with an alternative class of models
based on the concept of Evidential Deep Learning : For unfamiliar data, they aim to admit
“what they don’t know”, and fall back onto a prior belief. Furthermore, they allow uncer-
tainty estimation in a single model and forward pass by parameterizing distributions over
distributions . This survey recapitulates existing works, focusing on the implementation in a
classification setting, before surveying the application of the same paradigm to regression.
We also reflect on the strengths and weaknesses compared to other existing methods and
provide the most fundamental derivations using a unified notation to aid future research.
1 Introduction
Figure 1: Taxonomy of surveyed approaches, divided
into tractable parameterizations of the prior or poste-
rior on one axis (see Tables 1 and 2 for an overview)
andintoapproachesforclassificationandregressionon
the other. Regression methods are outlined in Table 3.Many existing methods for uncertainty estimation
leverage the concept of Bayesian model averag-
ing: These include ensembling (Lakshminarayanan
etal.,2017;Wilson&Izmailov,2020), Markovchain
Monte Carlo sampling (de Freitas, 2003; Andrieu
et al., 2000) as well as variational inference ap-
proaches (Mackay, 1992; MacKay, 1995; Hinton &
Van Camp, 1993; Neal, 2012), including approaches
such as Monte Carlo (MC) dropout (Gal & Ghahra-
mani, 2016) and Bayes-by-backprop (Blundell et al.,
2015). Bayesian model averaging for neural net-
works usually involves the approximation of an oth-
erwise infeasible integral using MC samples. This
causes the following problems: Firstly, the quality
of the MC approximation depends on the veracity
and diversity of samples from the weight posterior.
Secondly, the approach often involves increasing the
number of parameters in a model or training more
model instances altogether. Recently, a new class
of models has been proposed to side-step this co-
nundrum by using a different factorization of the posterior predictive distribution. This allows computing
1Published in Transactions on Machine Learning Research (04/2023)
uncertainty in a single forward pass and with a single set of weights. These models are grounded in a concept
coinedEvidential Deep Learning : For out-of-distribution (OOD) inputs, they are encouraged to fall back
onto a prior. This is often described as knowing what they don’t know .
In this paper, we summarize the existing literature and provide an overview of Evidential Deep Learning
approaches. We give an overview over all discussed work in Figure 1, where we distinguish surveyed works for
classification between models parameterizing a Dirichlet prior (Section 3.4.1) or posterior (Section 3.4.2). We
further discuss similar methods for regression problems (Section 4). As we will see, obtaining well-behaving
uncertainty estimates can be challenging in the Evidential Deep Learning framework; proposed solutions that
are also reflected in Figure 1 are the usage of OOD examples during training (Malinin & Gales, 2018; 2019;
Nandy et al., 2020; Shen et al., 2020; Chen et al., 2018; Zhao et al., 2019; Hu et al., 2021; Sensoy et al., 2020),
knowledge distillation (Malinin et al., 2020b;a) or the incorporation of density estimation (Charpentier et al.,
2020; 2022; Stadler et al., 2021), which we discuss in more detail in Section 6. This survey aims to both
serve as an accessible introduction to this model family to the unfamiliar reader as well as an informative
overview, in order to promote a wider application outside the uncertainty quantification literature. We also
provide a collection of the most important derivations for the Dirichlet distribution for Machine Learning,
which plays a central role in many of the discussed approaches.
2 Background
We first introduce the central concepts for this survey, including Bayesian inference in Section 2.1, Bayesian
model averaging in Section 2.2 and Evidential Deep Learning in Section 2.3.1
2.1 Bayesian Inference
The foundation of the following sections is Bayesian inference: Given some prior belief p(θ)about parameters
of interest θ, we use available observations D={(xi,yi)}N
i=1and their likelihood p(D|θ)to obtain an updated
belief in form of the posterior p(θ|D)∝p(D|θ)p(θ). This update rule is derived from Bayes’ rule, namely
p(θ|D) =p(D|θ)p(θ)
p(D)=p(D|θ)p(θ)/integraltext
p(D|θ)p(θ)dθ, (1)
where we often try to avoid computing the term in the denominator since marginalization over a large
(continuous) parameter space of θis usually intractable. In order to perform a prediction yfor a new data
point x, we can now utilize the posterior predictive distribution defined as
P(y|x,D) =/integraldisplay
P(y|x,θ)p(θ|D)dθ. (2)
Sinceweintegrateovertheentireparameterspaceof θ, weightingeachpredictionbytheposteriorprobability
of its parameters to obtain the final result, this process is referred to as Bayesian model averaging (BMA).
Here,predictions P(y|x,θ)stemmingfromparametersthatareplausiblegiventheobserveddatawillreceivea
higherweight p(θ|D)inthefinalprediction P(y|x,D). Aswewillseeinthefollowingsection,thisfactorization
ofthepredictivepredictivedistributionalsohasbeneficialpropertiesforanalyzingtheuncertaintyofamodel.
2.2 Predictive Uncertainty in Neural Networks
In probabilistic modelling, uncertainty is commonly divided into aleatoric and epistemic uncertainty (Der Ki-
ureghian & Ditlevsen, 2009; Kendall & Gal, 2017; Hüllermeier & Waegeman, 2021). Aleatoric uncertainty
refers to the uncertainty that is induced by the data-generating process, for instance noise or inherent overlap
between observed instances of classes. Epistemic uncertainty is the type of uncertainty about the optimal
model parameters (or even hypothesis class). It is reducible with an increasing amount of data, as fewer and
1Note that in the following we will use the suggested notation of the TMLR journal, e.g. by using Pfor probability mass
andpfor probability density functions.
2Published in Transactions on Machine Learning Research (04/2023)
fewer possible models become a plausible fit. These two notions resurface when formulating the posterior
predictive distribution for a new data point x:2
P(y|x,D) =/integraldisplay
P(y|x,θ)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Aleatoricp(θ|D)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Epistemicdθ. (3)
Here, the first factor captures the aleatoric uncertainty about the correct prediction, while the second one
expresses uncertainty about the correct model parameters—the more data we observe, the more density
ofp(θ|D)should lie on reasonable parameter values for θ. For high-dimensional real-valued parameters θ
like in neural networks, this integral becomes intractable, and is usually approximated using Monte Carlo
samples:3
P(y|x,D)≈1
KK/summationdisplay
k=1P(y|x,θ(k));θ(k)∼p(θ|D) (4)
based onKdifferent sets of parameters θ(k). Since this requires obtaining multiple versions of model
parameters through some additional procedure, this however comes with the aforementioned problems of
computational overhead and approximation errors, motivating the approaches discussed in this survey.
2.3 Evidential Deep Learning
Since the traditional approach to predictive uncertainty estimation requires multiple parameter sets and can
only approximate the predictive posterior, we can factorize Equation (2) further to obtain a tractable form:
p(y|x,D) =/integraldisplay/integraldisplay
P(y|π)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Aleatoricp(π|x,θ)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Distributionalp(θ|D)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Epistemicdπdθ≈/integraldisplay
P(y|π)p(π|x,ˆθ)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
p(θ|D)≈δ(θ−ˆθ)dπ.(5)
This factorization contains another type of uncertainty, which Malinin & Gales (2018) call the distributional
uncertainty, uncertainty caused by the mismatch of training and test data distributions. In the last step, Ma-
linin & Gales (2018) replace p(θ|D)by a point estimate ˆθusing the Dirac delta function, i.e. a single trained
neural network, to get rid of the intractable integral. Although another integral remains, retrieving the
uncertainty from this predictive distribution actually has a closed-form analytical solution for the Dirichlet
(see Section 3.3). The advantage of this approach is further that it allows us to distinguish uncertainty about
a data point because it is ambiguous from points coming from an entirely different data distribution. As
an example, consider a binary classification problem, in which the data manifold consists of two overlapping
clusters. As we are classifying a new data point, we obtain a distribution P(y|x,θ)which is uniform over the
two classes. What does this mean? The model might either be confident that the point lies in the region of
overlap and is inherently ambiguous, or that the model is uncertain about the correct class. Without further
context, we cannot distinguish between these two cases (Bengs et al., 2022; Hüllermeier, 2022). Compare
that to instead predicting p(π|x,θ): If the data point is ambiguous, the resulting distribution will be cen-
tered on 0.5, if the model is generally uncertain, the distribution will be uniform, allowing this distinction.
We will illustrate this principle further in the upcoming Sections 2.4 and 3.3.
In the neural network context in Equation (5), it should be noted that restricting oneself to a point estimate
of the parameters prevent the estimation of epistemic uncertainty like in earlier works through the weight
posteriorp(θ|D), as discussed in the next section. However, there are works like Haussmann et al. (2019);
Zhao et al. (2020) that combine both approaches.
2Note that the predictive distribution in Equation (2) generalizes the common case for a single network prediction where
P(y|x,D)≈P(y|x,ˆθ). Mathematically, this is expressed by replacing the posterior p(θ|D)by a Dirac delta distribution as in
Equation (5), where all probability density rests on a single parameter configuration.
3For easier distributions, the integral can often be evaluated analytically exploiting conjugacy. Another approach for more
complex distributions can be the method of moments (see e.g. Duan, 2021).
3Published in Transactions on Machine Learning Research (04/2023)
(a)Iris setosa
(b)Iris versicolor
(c)Iris virginica
1 2
3
Figure 2: Illustration of different approaches to uncertainty quantifying on the Iris dataset, with examples for
the classes given on the left (Figures 2a to 2c). On the right, the data is plotted alongside some predictions
of a prior network (lighter colors indicate higher density) and an ensemble and MC Dropout model on the
probability simplex, with 50predictions each. Iris images were taken from Wikimedia Commons, 2022a;b;c.
The term Evidential Deep Learning (EDL) originates from the work of Sensoy et al. (2018) and is based on
theTheory of Evidence (Dempster, 1968; Audun, 2018): Within the theory, belief mass is assigned to set
of possible states, e.g. class labels, and can also express a lack of evidence, i.e. an “I don’t know”. We can
for instance generalize the predicted output of a neural classifier using the Dirichlet distribution, allowing
us to express a lack of evidence through a uniform Dirichlet. This is different from a uniform Categorical
distribution, which does not distinguish an equal probability for all classes from the lack of evidence. For
the purpose of this survey, we define Evidential Deep Learning as a family of approaches in which a neural
network can fall back onto a uniform prior for unknown inputs. While neural networks usually parameterize
likelihood functions, approaches in this survey parameterize prior or posterior distributions instead. The
advantages of this methodology are now demonstrated using the example in the following section.
2.4 An Illustrating Example: The Iris Dataset
To illustrate the advantages of EDL, we choose a classification problem based on the Iris dataset (Fisher,
1936). It contains measurements of three different species of iris flowers (shown in Figures 2a to 2c). We
use the dataset as made available through scikit-learn (Pedregosa et al., 2011) and plot the relationship
between the width and lengths measurements of the flowers’ petals in Figure 2.
We train an deep neural network ensemble (Lakshminarayanan et al., 2017) with 50model instances, a
model with MC Dropout (Gal & Ghahramani, 2016) with 50predictions and a prior network (Sensoy et al.,
2018), an example of EDL, on all available data points, and plot their predictions on three test points on the
3-probability simplex in Figure 2.4On these simplices, each point signifies a Categorical distribution, with
4For information about training and model details, see Appendix A.1.
4Published in Transactions on Machine Learning Research (04/2023)
  
Figure 3: A prior Dirichlet distribution is updated with a vector of class observations. The posterior Dirichlet
then shifts density towards the classes kwith more observed instances.
the proximity to one of the corners indicating a higher probability for the corresponding class. EDL methods
for classification do not predict a single output distribution, but an entire density over output distributions .
Test point 3lies in a region of overlap between instances of Iris versicolor andIris virginica , thus inducing
high aleatoric uncertainty. In this case, we can see that the prior network places all of its density on between
these two classes, similar to most of the predictions of the ensemble and MC Dropout (bottom right).
However, some of the latter predictions still land in the center of the simplex. The point 1is located in an
area without training examples between instances of Iris versicolor andsetosa, as well as close to a single
virginica outlier. As shown in the top left, ensemble and MC Dropout predictions agree that the point
belongs to either the setosaorversicolor class, with a slight preference for the former. The prior network
concentrates its prediction on versicolor , but admits some uncertainty towards the two other choices. The
last test point 2is placed in an area of the feature space devoid of any data, roughly equidistant from the
three clusters of flowers. Similar to the previous example, the ensemble and MC dropout predictions on the
top right show a preference for Iris setosa andversicolor , albeit with higher uncertainy. The prior network
however shows an almost uniform density, admitting distributional uncertainty about this particular input.
This simple example provides some insights into the potential advantages of EDL: First of all, the prior
network was able to provide reasonable uncertainty estimates in comparison with BMA methods. Secondly,
the prior network is able to admit its lack of knowledge for the OOD data point by predicting an almost
uniform prior, something that the other models are not able to. As laid out in Section 3.3, EDL actually
allows the user to disentangle model uncertainty due to a simple lack of data and due to the input being
out-of-distribution. Lastly, training the prior network only required a single model, which is a noticeable
speed-up compared to MC Dropout and especially the training of ensembles.
3 Evidential Deep Learning for Classification
In order to introduce EDL methods for classification, we first give a brief introduction to the Dirichlet dis-
tribution and its role as a conjugate prior in Bayesian inference in Section 3.1. We then show in Section 3.2
how neural networks can parameterize Dirichlet distributions, while Section 3.3 reveals how such a parame-
terization can be exploited for efficient uncertainty estimation. The remaining sections enumerate different
examples from the literature parameterizing either a prior (Section 3.4.1) or posterior Dirichlet distribution
(Section 3.4.2).
3.1 The Dirichlet distribution
Modelling for instance a binary classification problem is commonly done using the Bernoulli likelihood. The
Bernoulli likelihood has a single parameter π, indicating the probability of success (or of the positive class),
and is given by
Bernoulli (y|π) =πy(1−π)(1−y). (6)
5Published in Transactions on Machine Learning Research (04/2023)
Within Bayesian inference as introduced in Section 2, the Beta distribution is a commonly used prior for a
Bernoulli likelihood. It defines a probability distribution over the parameter π, itself possessing two shape
parameters α1andα2:
Beta(π;α1,α2) =1
B(α1,α2)πα1−1(1−π)α2−1;B(α1,α2) =Γ(α1)Γ(α2)
Γ(α1+α2); (7)
where Γ(·)stands for the gamma function, a generalization of the factorial to the real numbers, and B(·)
is called the Beta function (not to be confused with the distribution). When extending the classification
problem from two to an arbitrary number of classes, we use a Categorical likelihood:
Categorical (y|π) =K/productdisplay
k=1π1y=k
k, (8)
in whichKdenotes the number of categories or classes, and the class probabilities are expressed using a
vector π∈[0,1]Kwith/summationtext
kπk= 1, and 1(·)is the indicator function. This distribution appears for instance
in classification problems when using neural networks, since most neural networks for classification use a
softmax function after their last layer to produce a Categorical distribution of classes s.t. πk≡P(y=k|x).
In this setting, the Dirichlet distribution arises as a suitable prior and multivariate generalization of the Beta
distribution (and is thus also called the multivariate Beta distribution ):
Dir(π;α) =1
B(α)K/productdisplay
k=1παk−1
k;B(α) =/producttextK
k=1Γ(αk)
Γ(α0);α0=K/summationdisplay
k=1αk;αk∈R+; (9)
wheretheBetafunction B(·)isnowdefinedfor KshapeparameterscomparedtoEquation(7). Fornotational
convenience, we also define K={1,...,K}as the set of all classes. The distribution is characterized by its
concentration parameters α, the sum of which, often denoted as α0, is called the precision .5The Dirichlet is
aconjugate prior for such a Categorical likelihood, meaning that according to Bayes’ rule in Equation (1),
they produce a Dirichlet posterior with parameters β, given a data set D={(xi,yi)}N
i=1ofNobservations
with corresponding labels:
p(π|D,α)∝p/parenleftbig
{yi}N
i=1|π,{xi}N
i=1/parenrightbig
p(π|α) =N/productdisplay
i=1K/productdisplay
k=1π1yi=k
k1
B(α)K/productdisplay
k=1παk−1
k
=K/productdisplay
k=1π/parenleftbig/summationtextN
i=11yi=k/parenrightbig
k1
B(α)K/productdisplay
k=1παk−1
k=1
B(α)K/productdisplay
k=1πNk+αk−1
k∝Dir(π;β),(10)
where βis a vector with βk=αk+Nk, withNkdenoting the number of observations for class k. Intuitively,
this implies that the prior belief encoded by the initial Dirichlet is updated using the actual data, sharpening
the distribution for classes for which many instances have been observed. Similar to the Beta distribution in
Equation (7), the Dirichlet is a distribution over Categorical distributions on theK−1probability simplex;
we show an example with its concentration parameters and the Bayesian update in Figure 3.
3.2 Parameterization
For a classification problem with Kclasses, a neural classifier is usually realized as a function fθ:RD→RK,
mapping an input x∈RDtologitsfor each class. Followed by a softmax function, this then defines
a Categorical distribution over classes with a vector πwithπk≡p(y=k|x,θ). The same underlying
architecture can be used without any major modification to instead parameterize a Dirichlet distribution,
5The precision is analogous to the precision of a Gaussian, where a larger α0signifies a sharper distribution.
6Published in Transactions on Machine Learning Research (04/2023)
(a) Categorical distributions pre-
dicted by a neural ensemble on the
probability simplex.
(b) Probability simplex for a con-
fident prediction, for with the den-
sity concentrated in a single corner.
(c) Dirichlet distribution for a case
of data uncertainty, with the den-
sity concentrated in the center.
(d) Dirichlet distribution for a case
of model uncertainty, with the den-
sity spread out more.
(e) Dirichlet for a case of distribu-
tional uncertainty, with the density
spread across the whole simplex.
(f) Alternative approach to distri-
butional uncertainty called repre-
sentation gap, with density concen-
trated along the edges.
Figure 4: Examples of the probability simplex for a K= 3classification problem, where every corner
corresponds to a class and every point to a Categorical distribution. Brighter colors correspond to higher
density. (a) Predicted Categorical distributions by an ensemble of discriminators. (b) – (e) (Desired)
Behavior of Dirichlet in different scenarios by Malinin & Gales (2018): (b) For a confident prediction, the
density is concentrated in the corner of the simplex corresponding to the assumed class. (c) In the case of
aleatoric uncertainty, the density is concentrated in the center, and thus uniform Categorical distributions
are most likely. (d) In the case of model uncertainty, the density may still be concentrated in a corner, but
more spread out, expressing the uncertainty about the right prediction. (e) In the case of an OOD input,
a uniform Dirichlet expresses that any Categorical distribution is equally likely, since there is no evidence
for any known class. (f) Representation gap by Nandy et al. (2020), proposed as an alternative behavior for
OOD data. Here, the density is instead concentrated solely on the edges of the simplex.
predicting a distribution over Categorical distributions p(π|x,ˆθ)as in Equation (9).6In order to classify
a data point x, a Categorical distribution is created from the predicted concentration parameters of the
Dirichlet as follows (this corresponds to the mean of the Dirichlet, see Appendix C.1):
α= exp/parenleftbig
fθ(x)/parenrightbig
;πk=αk
α0; ˆy= arg max
k∈Kπ1,...,πK. (11)
Parameterizing a Dirichlet posterior distribution follows a similar logic, as we will discuss in Section 3.4.2.
7Published in Transactions on Machine Learning Research (04/2023)
3.3 Uncertainty Estimation with Dirichlet Networks
Let us now turn our attention to how to estimate the aleatoric, epistemic and distributional uncertainty as
laid out in Section 2.2 within the Dirichlet framework. In Figure 4, we show different shapes of a Dirichlet
distribution parameterized by a neural network, corresponding to different cases of uncertainty, where each
point on the simplex represents a Categorical distribution, with proximity to a corner indicating a high
probability for the corresponding class. Figure 4a displays the predictions of an ensemble of classifiers
as a point cloud on the simplex. Using a Dirichlet, this finite set of distributions can be extended to
a continuous density over the whole simplex. As we will see in the following sections, parameterizing a
Dirichlet distribution with a neural network enables us to distinguish different scenarios using the shape of
its density, as shown in Figures 4b to 4f, which we will discuss in more detail along the way.
However, sincewedonotwanttoinspectDirichletsvisually, weinsteaduseclosedformexpressiontoquantify
uncertainty, which we will discuss now. Although stated for the prior parameters α, the following methods
can also be applied to the posterior parameters βwithout loss of generality.
Data (aleatoric) uncertainty To obtain a measure of data uncertainty, we can evaluate the expected
entropy of the data distribution p(y|π)(similar to previous works like e.g. Gal & Ghahramani, 2016). As
the entropy captures the “peakiness” of the output distribution, a lower entropy indicates that the model
is concentrating most probability mass on a single class, while high entropy characterizes a more uniform
distribution—the model is undecided about the right prediction. For Dirichlet networks, this quantity has a
closed-form solution (for the full derivation, refer to Appendix D.1):
Ep(π|x,ˆθ)/bracketleftbigg
H/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
=−K/summationdisplay
k=1αk
α0/parenleftbigg
ψ(αk+ 1)−ψ(α0+ 1)/parenrightbigg
(12)
whereψdenotes the digamma function, defined as ψ(x) =d
dxlog Γ(x), andHthe Shannon entropy.
Model (epistemic) uncertainty As we saw in Section 2.2, most approaches in the Dirichlet framework
avoid the intractable integral over network parameters θby using a point estimate ˆθ.7This means that
computing the model uncertainty via the weight posterior p(θ|D)like in Blundell et al. (2015); Gal &
Ghahramani (2016); Smith & Gal (2018) is not possible. Nevertheless, a key property of Dirichlet networks
is that epistemic uncertainty is expressed in the spread of the Dirichlet distribution (for instance in Figure 4
(d)and(e)). Therefore, theepistemicuncertaintycanbequantifiedconsideringtheconcentrationparameters
αthat shape this distribution: Charpentier et al. (2020) simply consider the maximum αkas a score akin
to the maximum probability score by Hendrycks & Gimpel (2017), while Sensoy et al. (2018) compute it by
K//summationtextK
k=1(αk+ 1)or simplyα0(Charpentier et al., 2020). In both cases, the underlying intuition is that
largerαkproduce a sharper density, and thus indicate increased confidence in a prediction.
Distributional uncertainty Another appealing property of this model family is being able to distinguish
uncertaintyduetomodelunderspecification(Figure4d)fromuncertaintyduetounknowninputs(Figure4e).
In the Dirichlet framework, the distributional uncertainty can be quantified by computing the difference
between the total amount of uncertainty and the data uncertainty, which can be expressed through the
mutual information between the label yand its Categorical distribution π:
I/bracketleftig
y,π/vextendsingle/vextendsingle/vextendsinglex,D/bracketrightig
=H/bracketleftbigg
Ep(π|x,D)/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Total Uncertainty−Ep(π|x,D)/bracketleftbigg
H/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Data Uncertainty(13)
6The only thing to note here is that the every αkhas to be strictly positive, which can for instance be enforced by using an
additional softplus, exponential or ReLU function (Sensoy et al., 2018; Malinin & Gales, 2018; Sensoy et al., 2020).
7With exceptions such as Haussmann et al. (2019); Zhao et al. (2020). When the distribution over parameters in Equation (5)
is retained, alternate expressions of the aleatoric and epistemic uncertainty are derived by Woo (2022).
8Published in Transactions on Machine Learning Research (04/2023)
This quantity expresses how much information we would receive about πif we were given the label y,
conditioned on the new input xand the training data D. In regions in which the model is well-defined,
receivingyshould not provide much new information about π—and thus the mutual information would
be low. Yet, such knowledge should be very informative in regions in which few data have been observed,
and there this mutual information would indicate higher distributional uncertainty. Given that E[πk] =αk
α0
(Appendix C.1) and assuming the point estimate p(π|x,D)≈p(π|x,ˆθ)to be sufficient (Malinin & Gales,
2018), we obtain an expression very similar to Equation (12):
I/bracketleftig
y,π/vextendsingle/vextendsingle/vextendsinglex,D/bracketrightig
=−K/summationdisplay
k=1αk
α0/parenleftbigg
logαk
α0−ψ(αk+ 1) +ψ(α0+ 1)/parenrightbigg
(14)
Note on epistemic uncertainty estimation The introduction of distributional uncertainty, a notion
that is non-existent in the Bayesian Model Averaging framework, warrants a note on the estimation of
epistemic uncertainty in general. Firstly, since we often use the point estimate p(θ|D)≈δ(θ−ˆθ)from Equa-
tion (5) in Evidential Deep Learning, model uncertainty usually is no longer estimated via the uncertainty in
the weight posterior, but instead through the parameters of the prior or posterior distribution. Furthermore,
even though they appear similar, distributional uncertainty is different from epistemic uncertainty, since it is
the uncertainty in the distribution p(π|x,θ). Distinguishing epistemic from distributional uncertainty also
allows us to differentiate uncertainty due to underspecification from uncertainty due to a lack of evidence. In
BMA, these notions are indistinguishable: In theory, model uncertainty on OOD data should be high since
the model is underspecified on them, however theoretical and empirical work has shown this is not always
the case (Ulmer et al., 2020; Ulmer & Cinà, 2021; Van Landeghem et al., 2022). Even then, the additive
decomposition of the mutual information has been critized since the model will also have a great deal of
uncertainty about its aleatoric uncertainty in the beginning of the training process (Hüllermeier, 2022), and
thus this decomposition might not be accurate. Furthermore, even when we obtain the best possible model
within its hypothesis class, using the discussed methods it is impossible to estimate uncertainty induced by
a misspecified hypothesis class. This can motivate approaches in which a second, auxiliary model directly
predicts model uncertainty of a target model (Lahlou et al., 2022; Zerva et al., 2022).
3.4 Existing Approaches for Dirichlet Networks
Beingabletoquantifyaleatoric,epistemicanddistributionaluncertaintyinasingleforwardpassandinclosed
form are desirable traits, as they simplify the process of obtaining different uncertainty scores. However, it is
important to note that the behavior of the Dirichlet distributions in Figure 4 is idealized. In the usual way
of training neural networks through empirical risk minimization, Dirichlet networks are not incentivized to
behave in the depicted way. Thus, when comparing existing approaches for parameterizing Dirichlet priors
in Section 3.4.1 and posteriors in Section 3.4.2,8we mainly focus on the different ways in which authors try
to tackle this problem by means of loss functions and training procedures. We give an overview over the
discussed works in Tables 1 and 2 in these respective sections. For additional details, we refer the reader
to Appendix C for general derivations concerning the Dirichlet distribution. We dedicate Appendix D to
derivationsofthedifferentlossfunctionsandregularizersandgiveadetailedoverviewovertheirmathematical
forms in Appendix E. Available code repositories for all works surveyed are listed in Appendix A.2.
3.4.1 Prior Networks
The key challenge in training Dirichlet networks is to ensure both high classification performance and the
intended behavior under OOD inputs. For this reason, most discussed works follow a loss function design
using two parts: One optimizing for task accuracy to achieve the former goal, the other optimizing for a flat
Dirichlet distribution, as flatness suggests a lack of evidence. To enforce flatness, the predicted Dirichlet is
compared to a uniform distribution using some probabilistic divergence measure. We divide prior networks
8Even though the term priorand posterior network were coined by Malinin & Gales (2018) and Charpentier et al. (2020)
for their respective approaches, we use them in the following as an umbrella term for all methods targeting a prior or posterior
distribution.
9Published in Transactions on Machine Learning Research (04/2023)
Table 1: Overview over prior networks for classification. (∗)OOD samples were created inspired by the
approach of Liang et al. (2018). ID: Using in-distribution data samples.
Method Loss function Architecture OOD-free
training?
Prior network
(Malinin & Gales, 2018)ID KL w.r.t smoothed label &
OOD KL w.r.t. uniform priorMLP / CNN ✗
Prior networks
(Malinin & Gales, 2019)Reverse KL of Malinin & Gales (2018) CNN ✗
Information Robust Dirichlet Networks
(Tsiligkaridis, 2019)lpnorm w.r.t one-hot label &
Approx. Rényi divergence
w.r.t. uniform priorCNN ✓
Dirichlet via Function Decomposition
(Biloš et al., 2019)Uncertainty Cross-entropy &
mean & variance regularizerRNN ✓
Prior network with PAC Regularization
(Haussmann et al., 2019)Negative log-likelihood loss +
PAC regularizerBNN ✓
Ensemble Distribution Distillation
(Malinin et al., 2020b)Knowledge distillation objective MLP / CNN ✓
Self-Distribution Distillation
(Fathullah & Gales, 2022)Knowledge distillation objective CNN ✓
Prior networks with representation gap
(Nandy et al., 2020)ID & OOD Cross-entropy +
precision regularizerMLP / CNN ✗
Prior RNN (Shen et al., 2020) Cross-entropy + entropy regularizer RNN ( ✗)∗
Graph-based Kernel Dirichlet distribution
estimation (GKDE) (Zhao et al., 2020)l2norm w.r.t. one-hot label &
KL reg. with node-level distance prior &
Knowledge distillation objectiveGNN ✓
into two groups: Approaches using additional OOD data for this purpose ( OOD-dependent approaches ), and
those which do not required OOD data ( OOD-free approaches ), as listed in Table 1.
OOD-free approaches Apart from a standard negative log-likelihood loss (NLL) as used by Haussmann
etal.(2019), onesimpleapproachtooptimizingthemodelistoimposea lp-lossbetweentheone-hotencoding
yof the original label yand the Categorical distribution π. Tsiligkaridis (2019) show that since the values
ofπdepend directly on the predicted concentration parameters α, a generalized loss can be derived to be
upper-bounded by the following expression (see the full derivation given in Appendix D.3):
Ep(π|x,θ)/bracketleftbig
||y−π||p/bracketrightbig
≤/parenleftbiggΓ(α0)
Γ(α0+p)/parenrightbigg1
p
Γ/parenleftig/summationtext
k̸=yαk+p/parenrightig
Γ/parenleftig/summationtext
k̸=yαk/parenrightig+/summationdisplay
k̸=yΓ(αk+p)
Γ(αk)
1
p
(15)
Since the sum over concentration parameters excludes the one corresponding to the true label, this loss can
be seen as reducing the density on the areas of the probability simplex that do not correspond to the target
class. Sensoy et al. (2018) specifically utilize the l2loss, which has the following form (see Appendix D.4):
Ep(π|x,θ)/bracketleftig
||y−π||2
2/bracketrightig
=K/summationdisplay
k=1/parenleftig
1y=k−αk
α0/parenrightig2
+αk(α0−αk)
α2
0(α0+ 1)(16)
where 1(·)denotes the indicator function. Since αk/α0≤1, we can see that the term with the indicator
functions penalizes the network when the concentration parameter αkcorresponding to the correct label
10Published in Transactions on Machine Learning Research (04/2023)
does not exceed the others. The remaining aspect lies in the regularization: To achieve reliable predictive
uncertainty, the density associated with incorrect classes should be reduced. One such option is to decrease
the Kullback-Leibler divergence from a uniform Dirichlet (see Appendix C.3):
KL/bracketleftig
p(π|α)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|1)/bracketrightig
= logΓ(K)
B(α)+K/summationdisplay
k=1(αk−1)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
(17)
In the case of Zhao et al. (2020), who apply their model to graph structures, they do not decrease the
divergence from a uniform Dirichlet, but incorporate information about the local graph neighborhood into
the reference distribution by considering the distance from and label of close nodes.9Nevertheless, the KL-
divergence w.r.t. a uniform Dirichlet is used by many of the following works. Other divergence measures are
also possible: Tsiligkaridis (2019) instead use a local approximation of the Rényi divergence.10First, the
concentration parameter for the correct class αyis removed from the Dirichlet by creating ˜α= (1−y)·α+y.
Then, the remaining concentration parameters are pushed towards uniformity by the divergence measure,
which can be derived to be
Rényi/bracketleftig
p(π|˜α)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|1)/bracketrightig
≈1
2/bracketleftig/summationdisplay
k̸=y/parenleftbig
αk−1/parenrightbig2/parenleftbig
ψ(1)(αj)−ψ(1)(˜α0)/parenrightbig
−ψ(1)(˜α0)/summationdisplay
k̸=k′
k̸=y, k′̸=y/parenleftbig
αk−1/parenrightbig/parenleftbig
αk′−1/parenrightbig/bracketrightig
(18)
whereψ(1)denotes the first-order polygamma function, defined as ψ(1)(x) =d
dxψ(x). Since the sums
ignore the concentration parameter of the correct class, only the ones of the incorrect classes are penalized.
Haussmannetal.(2019)deriveanentirelydifferentregularizerusingProbablyApproximatelyCorrect(PAC)
bounds from learning theory, that together with the negative log-likelihood gives a proven bound to the
expected true risk of the classifier. Setting a scalar δallows one to set the desired risk, i.e. the model’s
expected risk is guaranteed to be the same or less than the derived PAC bound with a probability of 1−δ.
For a problem with Navailable training data points, the following upper bound is presented:
/radicaligg
KL/bracketleftbig
p(π|α)/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|1)/bracketrightbig
−logδ
N−1. (19)
This upper bound is then used as the actual regularizer term in practice. We see that even from the learning-
theoretic perspective, this method follows the intuition of the original KL regularizer in a shifted and scaled
form. Haussmann et al. (2019) also admit that in this form, the regularizer does not allow for a direct PAC
interpretation anymore, since its approximates only admits a loose bound on the risk. Yet, they demonstrate
its usefulness in their experiments. Summarizing all of the presented approaches thus far, we can see that
they try to force the model to concentrate the Dirichlet’s density solely on the parameter corresponding to
the right label—expecting a more flat density for difficult or unknown inputs.
Knowledge distillation A way to avoid the use of OOD examples while still using external information
for regularization is to use knowledge distillation (Hinton et al., 2015). Here, the core idea lies in a student
model learning to imitate the predictions of a more complex teacher model. Malinin et al. (2020b) exploit
thisideaandshowthatpriornetworks canalsobedistilledusinganensembleof classifiers andtheirpredicted
Categorical distributions (akin to learning Figure 4e from Figure 4a), which does not require regularization
at all, but comes at the cost of having to train an entire ensemble a priori. Trying to solve this shortcoming,
Fathullah & Gales (2022) propose to use a shared feature extractor between the student and the teacher
network. Instead of training an ensemble, diverse predictions are obtained from the teacher network through
the use of Gaussian dropout, which are distilled into a Dirichlet distribution as in Malinin et al. (2020b).
9They also add another knowledge distillation term (Hinton et al., 2015) to their loss, for which the model tries to imitate
the predictions of a vanilla Graph Neural Network that functions as the teacher network.
10The Kullback-Leibler divergence can be seen as a special case of the Rényi divergence (van Erven & Harremoës, 2014),
where the latter has a stronger information-theoretic underpinning.
11Published in Transactions on Machine Learning Research (04/2023)
OOD-dependent approaches A uniform Dirichlet in the face of unknown inputs can also be achieved
explicitly by training with OOD inputs and learning to be uncertain on them. We discuss a series of works
utilizing this direction next. Malinin & Gales (2018) simply minimize the KL divergence to a uniform
Dirichlet on OOD data points. This way, the model is encouraged to be agnostic about its prediction in the
face of unknown inputs. Further, instead of an lpnorm, they utilize another KL term to train the model on
predicting the correct label, minimizing the distance between the predicted concentration parameters and
the true label. However, since only a gold labeland not a gold distribution is available, they create one by
re-distributing some of the density from the correct class onto the rest of the simplex (see Appendix E for full
form). In their follow-up work, Malinin & Gales (2019) argue that the asymmetry of the KL divergence as
the main objective creates undesirable properties in producing the correct behavior of the predicted Dirichlet,
since it creates a multi- instead of unimodal target distribution. They therefore propose to use the reverse
KL instead (see Appendix D.5 for the derivation), which enforces the desired unimodal target. Nandy
et al. (2020) refine this idea further, stating that even with reverse KL training high epistemic and high
distributional uncertainty (Figures 4d and 4e) might be confused, and instead propose novel loss functions
producing a representation gap (Figure 4f), which aims to be more easily distinguishable. In this case,
spread out densities signify epistemic uncertainty, whereas densities concentrated entirely on the edges of
the simplex indicate distributional uncertainty. The way they achieve this goal is two-fold: In addition to
minimizing the negative log-likelihood loss on in-domain and maximizing the entropy on OOD examples,
they also penalize the precision of the Dirichlet (see Appendix E for full form). Maximizing the entropy on
OOD examples hereby serves the same function as minimizing the KL w.r.t. to a uniform distribution, and
can be implemented using the closed-form solution in Appendix C.2:
H/bracketleftbig
p(π|α)/bracketrightbig
= logB(α) + (α0−K)ψ(α0)−K/summationdisplay
k=1(αk−1)ψ(αk) (20)
Sequential models We also have identified two sequential applications of prior networks in the literature:
For Natural Language Processing, Shen et al. (2020) train a recurrent neural network for spoken language
understanding using a simple cross-entropy loss. Instead of using OOD examples for training, they maximize
the entropy of the model on data inputs given a learned, noisy version of the predicted concentration
parameters. Incomparison, Bilošetal.(2019)applytheirmodeltoasynchronouseventclassificationandnote
that the standard cross-entropy loss only involves a point estimate of a Categorical distribution, discarding
all the information contained in the predicted Dirichlet. For this reason, they propose an uncertainty-aware
cross-entropy (UCE) loss instead, which has a closed-form solution in the Dirichlet case (see Appendix D.6)
LUCE=ψ(αy)−ψ(α0), (21)
withψreferring to the digamma function. By mimizing the difference between the digamma values of αyand
α0, the model learns to concentrate density on the correct class. Since their final concentration parameters
are created using additional information from a class-specific Gaussian process, they further regularize the
mean and variance for OOD data points using an extra loss term, incentivizing a loss mean and a variance
corresponding to a pre-defined hyperparameter.
3.4.2 Posterior Networks
As elaborated on in Section 3.1, choosing a Dirichlet prior, due to its conjugacy to the Categorical distri-
bution, induces a Dirichlet posterior distribution. Like the prior before, surveyed works listed in Table 2
parameterize the posterior with a neural network. The challenges hereby are two-fold: Accounting for the
number of class observations Nkthat make up part of the posterior density parameters β(Equation (10)),
and, similarly to prior networks, ensuring the wanted behavior on the probability simplex for in- and out-
of-distribution inputs. Sensoy et al. (2018) base their approach on the Dempster-Shafer theory of evidence
(Yager & Liu, 2008; lending its name to the term “Evidential Deep Learning”) and its formalization via
subjective logic (Audun, 2018), where subjective beliefs about probabilities are expressed through Dirichlet
distributions. In doing so, an agnostic belief in form of a uniform Dirichlet prior ∀k:αk= 1is updated
12Published in Transactions on Machine Learning Research (04/2023)
Table 2: Overview over posterior networks for classification. OOD data is created using (†)the fast-sign
gradient method (Kurakin et al., 2017), a (‡)Variational Auto-Encoder (VAE; Kingma & Welling, 2014) or
(§)a Wasserstein GAN (WGAN; Arjovsky et al., 2017). NLL: Negative log-likelihood. CE: Cross-entropy.
Method Loss function Architecture OOD-free
training?
Evidential Deep Learning
(Sensoy et al., 2018)l2norm w.r.t. one-hot label +
KL w.r.t. uniform priorCNN ✓
Regularized ENN
(Zhao et al., 2019)l2norm w.r.t. one-hot label +
Uncertainty regularizer on OOD/ difficult samplesMLP / CNN ✗
WGAN–ENN
(Hu et al., 2021)l2norm w.r.t. one-hot label +
Uncertainty regularizer on synth. OODMLP / CNN +
WGAN(✗)§
Variational Dirichlet
(Chen et al., 2018)ELBO +
Contrastive Adversarial LossCNN ( ✗)†
Dirichlet Meta-Model
(Shen et al., 2022)ELBO +
KL w.r.t. uniform priorCNN ✓
Belief Matching (Joo et al., 2020) ELBO CNN ✓
Posterior Networks
(Charpentier et al., 2020)Uncertainty CE (Biloš et al., 2019)
+ Entropy regularizerMLP / CNN +
Norm. Flow✓
Graph Posterior Networks
(Stadler et al., 2021)Same as Charpentier et al. (2020) GNN ✓
Generative Evidential Neural Networks
(Sensoy et al., 2020)Contrastive NLL + KL between
uniform & Dirichlet of wrong classesCNN ( ✗)‡
using pseudo-counts Nk, which are predicted by a neural network. This is different from prior networks,
where the prior concentration parameters αare predicted instead. In both cases, this does not require any
modification to a model’s architecture except for replacing the softmax output function by a ReLU (or simi-
lar). Sensoy et al. (2018) for instance train their model using the same techniques presented in the previous
section: The main objective is the l2loss, penalizing the difference between the predicted Dirichlet and the
one-hot encoded class label (Appendix D.4), and the KL divergence from a uniform Dirichlet is used for
regularization.
Generating OOD samples using generative models Since OOD examples are not always readily
available, several works try to create artificial samples using deep generative models. Hu et al. (2021) train
a Wasserstein GAN (Arjovsky et al., 2017) to generate OOD samples, on which the network’s uncertainty is
maximized. The uncertainty is given through vacuity, defined as K//summationtext
kβk. The vacuity compares a uniform
prior belief against the amassed evidence/summationtext
kβk, and thus is 1when there is no additonal evidence available.
In a follow-up work, Sensoy et al. (2020) similarly train a model using a contrastive loss with artificial OOD
samples from a Variational Autoencoder (Kingma & Welling, 2014), and a KL-based regularizer similar
to that of Tsiligkaridis (2019), where the density for posterior concentration parameters βkthat do not
correspond to the true label are pushed to the uniform distribution.
Posterior networks via Normalizing Flows Charpentier et al. (2020) also set αto a uniform prior,
but obtain the pseudo-observations Nkin a different way: Instead of a model predicting them directly, Nk
is determined by the number of examples of a certain class in the training set. This quantity is further
modified in the following way: An encoder model fθproduces a latent representation zof some input.
A (class-specific) normalizing flow11(NF; Rezende & Mohamed, 2015) with parameters ϕthen assigns a
probability to this latent representation, which is used to weight Nk:
11A NF is a generative model, estimating a density in the feature space by mapping it to a Gaussian in a latent space by a
series of invertible, bijective transformations. The probability of an input can then be estimated by calculating the probability
of its latent encoding under that Gaussian and applying the change-of-variable formula, traversing the flow in reverse. Instead
of mapping from the feature space into latent space, the flows in Charpentier et al. (2020) map from the encoder latent space
into a separate, second latent space.
13Published in Transactions on Machine Learning Research (04/2023)
(a)PosteriorNetwork(Charpentieretal.,2020).
 (b) Natural Posterior Network (Charpentier et al., 2022).
Figure 5: Schematic of the Posterior Network and Natural Posterior Network, taken from Charpentier et al.
(2020; 2022), respectively. In both cases, an encoder fθmaps inputs to a latent representation z. NFs then
model the latent densities, which are used together with the prior concentration to produce the posterior
parameters. In (a), the latent representation of x(1)lies right in the modelled density of the first class, and
thus receives a confident prediction. The latent z(2)lies between densities, creating aleatoric uncertainty.
x(3)is an OOD input, is mapped to a low-density area of the latent space and thus produces an uncertain
prediction. The differences in the two approaches is that the Posterior Network in (a) uses one NF per
class, while only one NF is used in (b). Furthermore, (b) constitutes a generalization to different exponential
family distributions, and is not restricted to classification problems (see main text for more detail).
βk=αk+Nk·p(z|y=k,ϕ);z=fθ(x). (22)
ThishastheadvantageofproducinglowprobabilitiesforstrangeinputslikethenoiseasdepictedinFigure5a,
which in turn translate to low concentration parameters of the posterior Dirichlet, as it falls back onto the
uniform prior. The model is optimized using the same uncertainty-aware cross-entropy loss as in Biloš
et al. (2019) with an additional entropy regularizer, encouraging density only around the correct class. This
scheme is also applied to Graph Neural Networks by Stadler et al. (2021): In order to take the neighborhood
structure of the graph into account, the authors also use a Personalized Page Rank scheme to diffuse node-
specific posterior parameters βbetween neighboring nodes. The Page Rank scores, reflecting the importance
of a neighboring node to the current node, can be approximated using power iteration (Klicpera et al., 2019)
and used to aggregate the originally predicted concentration parameters βon a per-node basis.
A generalization of the posterior network method to exponential family distributions is given by Charpentier
et al. (2022). Akin to the update for the posterior Dirichlet parameters, the authors formulate a general
Bayesian update rule as
χpost
i=npriorχprior+niχi
nprior+ni;zi=fθ(xi);ni=N·p(z|ϕ);χi=gψ(xi). (23)
χhere denotes the parameters of the exponential family distribution and nthe evidence. Thus, posterior
parameters for a sample xiare obtained by updating the prior parameter and some prior evidence by some
input-dependent pseudo-evidence niand parameters χi: Again, given a latent representation by an encoder
z, a (this time single) normalizing flow predicts ni=NH·p(z|ϕ)based on some pre-defined certainty
budgetNH.12The update parameters χiare predicted by an additional network χi=gψ(z), see Figure 5b.
For classification, nprior= 1andχpriorcorresponds to the uniform Dirichlet, while χiare concentration
parameterspredictedbyanoutputlayerbasedonthelatentencoding. Forunfamiliarinputs, thismethodwill
12The certainty budget can simply be set to the number of available datapoints, however Charpentier et al. (2022) suggest
to set it to logNH=1
2/parenleftbig
Hlog(2π) + log(H+ 1)/parenrightbig
to better scale with the dimensionality Hof the latent space.
14Published in Transactions on Machine Learning Research (04/2023)
Table 3: Overview over Evidential Deep Learning methods for regression.
Method Parameterized
distributionLoss function Model
Deep Evidential Regression
(Amini et al., 2020)Normal-Inverse
Gamma PriorNegative log-likelihood loss + KL
w.r.t. uniform priorMLP / CNN
Deep Evidential Regression
with Multi-task Learning
(Oh & Shin, 2022)Normal-Inverse
Gamma PriorLike Amini et al. (2020), with additional
Lipschitz-modified MSE lossMLP / CNN
Multivariate Deep Evidential
Regression (Meinert & Lavin, 2021)Normal-Inverse
Wishart PriorLike Amini et al. (2020), but tying two
predicted params. instead of using a regularizerMLP
Regression Prior Network
(Malinin et al., 2020a)Normal-Wishart Prior Reverse KL
(Malinin & Gales, 2019)MLP / CNN
Natural Posterior Network
(Charpentier et al., 2022)Inverse-χ2Posterior Uncertainty Cross-entropy (Biloš et al., 2019)
+ Entropy regularizerMLP / CNN +
Norm. Flow
again result in a small pseudo-evidence term ni, reflecting high model uncertainty. Since the generalization
to the exponential family implies the application of this scheme to normal distributions, we will discuss the
same method applied to regression in the next section.
Posterior networks via variational inference Another route lies in directly parameterizing the poste-
rior parameters β. Given a target distribution defined by a uniform Dirichlet prior plus the number of times
an input is associated with a specific label, Chen et al. (2018) optimize a distribution matching objective, i.e.
the KL-divergence between the posterior parameters predicted by a neural network and the target distribu-
tion. Since this objective is intractable to optimize directly, this leaves us to instead model an approximate
posterior using variational inference methods. As the KL divergence between the true and approximate
posterior is infeasible to estimate, variational methods usually optimize the evidence lower bound (ELBO):
LELBO =ψ(βy)−ψ(β0)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
UCE loss−logB(β)
B(γ)+K/summationdisplay
k=1(βk−γk)/parenleftbig
ψ(βk)−ψ(β0)/parenrightbig
/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright
KL-divergence(24)
in which we can identify to consist of the uncertainty-aware cross-entropy (UCE) loss used by Biloš et al.
(2019); Charpentier et al. (2020; 2022) and the KL-divergence between two Dirichlets (Appendix C.3). This
approach is also employed by Joo et al. (2020), Chen et al. (2018) and Shen et al. (2022), while the latter
predict posterior parameters based on the activations of different layers of a pre-trained feature extractor.
4 Evidential Deep Learning for Regression
Because the EDL framework provides convenient uncertainty estimation, the question naturally arises of
whether it can be extended to regression problems as well. The answer is affirmative, although the Dirichlet
distribution is not an appropriate choice in this case. It is very common to model a regression problem using
a normal likelihood (Bishop, 2006; Chapter 3.3). As such, there are multiple potential choices for a prior
distribution. The methods listed in Table 3 either choose the Normal-Inverse Gamma distribution (Amini
et al., 2020; Charpentier et al., 2022), inducing a scaled inverse- χ2posterior (Gelman et al., 1995),13or a
Normal-Wishart prior (Malinin et al., 2020a). We will discuss these approaches in turn.
Univariate regression Amini et al. (2020) model the regression problem as a normal distribution with
unknown mean and variance N(y;π,σ2), and use a normal prior for the mean with π∼N (γ,σ2ν−1)and
an inverse Gamma prior for the variance with σ2∼Γ−1(α,β), resulting in a combined Inverse-Gamma
13The form of the Normal-Inverse Gamma posterior and the Normal Inverse- χ2posterior are interchangable using some
parameter substitutions (Murphy, 2007).
15Published in Transactions on Machine Learning Research (04/2023)
Figure 6: Example of an application of Evidential Deep Learning for regression, taken from Amini et al.
(2020). The neural network predicts an Normal Inverse-Gamma prior, whose corresponding normal likeli-
hoods display decreasing variance (and thus uncertainty) in the face of stronger evidence.
prior with parameters γ,ν,α,β, shown in Figure 6. These are predicted by different “heads” of a neural
network. For predictions, the expectation of the mean corresponds to E[π] =γ, and aleatoric and epistemic
uncertainty can then be estimated using the expected value of the variance as well as the variance of the
mean, respectively, which have closed form solutions under this parameterization:
E[σ2] =β
α−1;Var[π] =β
ν(α−1)(25)
By choosing to optimize using a negative log-likelihood objective, we can actually evaluate the loss function
analytically, since the likelihood function corresponds to a Student’s t-distribution with γdegrees of freedom,
meanβ(1 +ν)/(να)and2αvariance:
LNLL=1
2log/parenleftigπ
ν/parenrightig
−αlog Ω +/parenleftig
α+1
2/parenrightig
log/parenleftig
(yi−γ)2ν+ Ω/parenrightig
+ log/parenleftbiggΓ(α)
Γ(α+1
2)/parenrightbigg
(26)
using Ω = 2β(1 +ν). Akin to the entropy regularizer for Dirichlet networks, Amini et al. (2020) propose a
regularization term that only allows for concentrating density on the correct prediction:
Lreg=|yi−γ|·(2ν+α) (27)
SinceE[π] =γis the prediction of the network, the second term in the product will be scaled by the degree
to which the current prediction deviates from the target value. Since νandαcontrol the variance of the
mean and the variance of the normal likelihood, this term encourages the network to decrease the evidence
for mispredicted data samples. As Amini et al. (2020) point out, large amounts of evidence are not punished
in cases where the prediction is close to the target. However, Oh & Shin (2022) argue that this combination
of objectives might create adverse incentives for the model during training: Since the difference between
the prediction and target in Equation (26) is scaled by ν, the model could learn to increase the predictive
uncertainty by decreasing νinstead of improving its prediction. They propose to ameliorate this issue by
using a third loss term of the form
LMSE=/braceleftigg
(yi−γ)2if(yi−γ)2<Uν,α
2/radicalbig
Uν,α|yi−γ|−Uν,αif(yi−γ)2≥Uν,α(28)
16Published in Transactions on Machine Learning Research (04/2023)
whereUν,α= min(Uν,Uα)denotes the minimum value for the uncertainty thresholds for ν,αgiven over a
mini-batch, which are themselves defined as
Uν=β(ν+ 1)
αν;Uα=2β(ν+ 1)
ν/bracketleftig
exp/parenleftig
ψ/parenleftig
α+1
2/parenrightig
−ψ(α))−1/parenrightig/bracketrightig
. (29)
These expression are obtained by taking the derivatives ∂LNLL/∂ν,∂LNLL/∂αand solving for the param-
eters, thus giving us the values for νandαfor which the loss gradients are maximal. In combination
with Equation (28), Equation (29) ensures that, should the model error exceed Uν,α, the error is rescaled.
Thus, this rescaling bounds the Lipschitz constant of the loss function, motivating the model to ensure the
correctness of its prediction, since its ability to increase uncertainty to decrease its loss is now limited.
Posterior networks for regression Another approach for regression is the Natural Posterior Network
by Charpentier et al. (2022), which was already discussed for classification in Section 3.4.2. But since the
proposed approach is a generalization for exponential family distributions, it can be applied to regression as
well, usingaNormallikelihoodandNormalInverse-Gammaprior. TheBayesianupdateruleinEquation(23)
is adapted as follows: nis set ton=λ= 2α, and χ=/bracketleftbig
π0|π2
0+ 2β/n/bracketrightbigT. Feeding an input into the natural
posterior network again first produces a latent encoding z, from which a NF predicts ni=NH·p(z|ϕ),
and an additional network produces χi=gψ(z), which are used in Equation (23) to produce χpostand
npost, from which the parameters of the posterior Normal Inverse-Gamma can be derived. The authors also
produce a general exponential family form of the UCE loss by Biloš et al. (2019), consisting of expected
log-likelihood and an entropy regularizer, which they derive for the regression parameterization. Again, this
approach relies on the density estimation capabilities of the NF to produce an agnostic belief about the right
prediction for OOD examples (see Figure 5b).
Multivariate evidential regression There are also some works offering solutions for multivariate regres-
sion problems: Malinin et al. (2020a) can be seen as a multivariate generalization of the work of Amini et al.
(2020), where a combined Normal-Wishart prior is formed to fit the now Multivariate Normal likelihood.
Again, the prior parameters are the output of a neural network, and uncertainty can be quantified in a
similar way. For training purposes, they apply two different training objectives using the equivalent of the
reverse KL objective of Malinin & Gales (2019) as well as of the knowledge distillation objective of Malinin
et al. (2020b), which does not require OOD data for regularization purposes. Meinert & Lavin (2021) also
provide a solution using a Normal Inverse-Wishart prior. In a similar vein to Oh & Shin (2022), they argue
that the original objective proposed by Amini et al. (2020) can be minimized by increasing the network’s
uncertainty instead of decreasing the mismatch of its prediction. As a solution, they simply propose to tie
βandνvia a hyperparameter.
5 Related Work
Other Approaches to Uncertainty Quantification The need for the quantification of uncertainty in
order to earn the trust of end-users and stakeholders has been a key driver for research (Bhatt et al., 2021;
Jacovi et al., 2021; Liao & Sundar, 2022). Existing methods can broadly be divided into frequentist and
Bayesian methods, where the former judge the confidence of a model based on its predicted probabilities.
Unfortunately, standard neural discriminator architectures have been proven to possess unwanted theoretical
properties w.r.t. OOD inputs (Hein et al., 2019; Ulmer & Cinà, 2021) and might therefore be unable to detect
potentially risky inputs.14Further, a large line of research works has questioned the calibration of models
(Guo et al., 2017; Nixon et al., 2019; Desai & Durrett, 2020; Minderer et al., 2021; Wang et al., 2021b), i.e. to
whatextendtheprobabilityscoreofaclass—alsoreferredtoasitsconfidence—correspondstothechanceofa
correctprediction. Insteadofrelyingontheconfidencescorealone,anotherwayliesinconstructingprediction
sets consisting of the classes accumulating a certain share of the total predictive mass (Kompa et al., 2021;
Ulmer et al., 2022). By scoring a held-out population of data points to calibrate these prediction sets, we can
14Pearce et al. (2021) argue that some insights might partially be misled by low-dimensional intuitions, and that empirically
OOD data in higher dimensions tend to be mapped into regions of higher uncertainty.
17Published in Transactions on Machine Learning Research (04/2023)
also obtain frequentist guarantees in a procedure referred to a conformal prediction (Papadopoulos et al.,
2002; Vovk et al., 2005; Lei & Wasserman, 2014; Angelopoulos & Bates, 2021). This however still does not
let us distinguish different notions of uncertainty. A popular Bayesian way to overcome this blemish by
aggregating multiple predictions by networks in the Bayesian model averaging framework (Mackay, 1992;
MacKay, 1995; Hinton & Van Camp, 1993; Neal, 2012; Jeffreys, 1998; Wilson & Izmailov, 2020; Kristiadi
et al., 2020; Daxberger et al., 2021; Gal & Ghahramani, 2016; Blundell et al., 2015; Lakshminarayanan et al.,
2017). Nevertheless, many of these methods have been shown not to produce diverse predictions (Wilson &
Izmailov, 2020; Fort et al., 2019) and to deliver subpar performance and potentially misleading uncertainty
estimates under distributional shift (Ovadia et al., 2019; Masegosa, 2020; Wenzel et al., 2020; Izmailov et al.,
2021a;b), raising doubts about their efficacy. The most robust method in this context is often given by an
ensemble of neural predictors (Lakshminarayanan et al., 2017), with multiple works exploring ways to make
their training more efficient (Huang et al., 2017; Wilson & Izmailov, 2020; Wen et al., 2020; Turkoglu et al.,
2022) or to provide theoretical guarantees (Pearce et al., 2020; Ciosek et al., 2020; He et al., 2020; D’Angelo
& Fortuin, 2021).
Related Approaches to EDL Kull et al. (2019) found an appealing use of the Dirichlet distribution as
a post-training calibration map. Hobbhahn et al. (2022) use the Laplace bridge, a modified inverse based on
an idea by MacKay (1998), to map from the model’s logit space to a Dirichlet distribution. The proposed
Posterior Network (Charpentier et al., 2020; 2022) can furthermore be seen as related to another, competing
approach, namely the combination of neural discriminators with density estimation methods, for instance in
the form of energy-based models (Grathwohl et al.; Elflein et al., 2021) or other hybrid architectures (Lee
et al., 2018; Mukhoti et al., 2021). Furthermore, there is a line of other single-pass uncertainty quantification
approaches which do not originate from the evidential framework, for instance by taking inspiration from
RBF networks (van Amersfoort et al., 2020b) or via Gaussian Process output layers (Liu et al., 2020; Fortuin
et al., 2021; van Amersfoort et al., 2021).
Applications of EDL Some of the discussed models have already found a variety of applications, such
as in autonomous driving (Capellier et al., 2019; Liu et al., 2021; Petek et al., 2022; Wang et al., 2021a),
remote sensing (Gawlikowski et al., 2022), medical screening (Ghesu et al., 2019; Gu et al., 2021; Li et al.,
2022), molecular analysis (Soleimany et al., 2021), open set recognition (Bao et al., 2021), active learning
(Hemmer et al., 2022) and model selection (Radev et al., 2021).
6 Discussion
What is state-of-the-art? As apparent from Table 5, evaluation methods and datasets can vary tremen-
dously between different research works (for an overview, refer to Appendix B,). This can make it hard to
accurately compare different approaches in a fair manner. Nevertheless, we try to draw some conclusion
about the state-of-art in this research direction to the best extent possible: For image classification , the
posterior (Charpentier et al., 2020) and natural posterior network (Charpentier et al., 2022) provide the
best results on the tested benchmarks, both in terms of task performance and uncertainty quality. When
the training an extra normalizing flow creates too much computational overhead, prior networks (Malinin
& Gales, 2018) with the PAC-based regularizer (Haussmann et al., 2019; see Table 6 for final form) or a
simple entropy regularizer (Appendix C.2) can be used. In the case of regression problems, the natural
posterior network (Stadler et al., 2021) performs better or on par with the evidential regression by Amini
et al. (2020) or an ensemble Lakshminarayanan et al. (2017) or MC Dropout (Gal & Ghahramani, 2016).
Forgraph neural networks , the graph posterior network (Stadler et al., 2021) and a ensemble provide
similar performance, but with the former displaying better uncertainty results. Again, this model requires
training a NF, so a simpler fallback is provided by evidential regression (Amini et al., 2020) with the
improvement by Oh & Shin (2022). For NLPandcount prediction , the works of Shen et al. (2020)
and Charpentier et al. (2022) are the only available instances from this model family, respectively. In the
latter case, ensembles and the evidential regression framework (Amini et al., 2020) produce a lower root
mean-squared error, but worse uncertainty estimates on OOD.
18Published in Transactions on Machine Learning Research (04/2023)
Computational Cost When it comes to the computational requirements, most of the proposed methods
in this survey incur the same cost as a single deterministic network using a softmax output, since most
of the architecture remains unchanged. Additional cost is mostly only produced when using knowledge
distillation (Malinin et al., 2020b; Fathullah & Gales, 2022), adding normalizing flow components like for
posterior networks (Charpentier et al., 2020; 2022; Stadler et al., 2021) or using generative models to produce
synthetic OOD data (Chen et al., 2018; Sensoy et al., 2020; Hu et al., 2021).
Comparison to Other Approaches to Uncertainty Quantification As discussed in Section 5, several
existing approaches to uncertainty quantification equally suffer from shortcomings with respect to their
reliability. One possible explanation for this behavior might lie in the insight that neural networks trained in
the empirical risk minimization framework tend to learn spurious but highly predictive features (Ilyas et al.,
2019; Nagarajan et al., 2021). This way, inputs stemming from the training distribution can be mapped to
similar parts of the latent space as data points outside the distribution even though they display (from a
human perspective) blatant semantic differences, simply because these semantic features were not useful to
optimize for the training objective. This can result in ID and OOD points having assigned similar feature
representations by a network, a phenomenon has been coined “feature collapse” (Nalisnick et al., 2019; van
Amersfoort et al., 2021; Havtorn et al., 2021). One strategy to mitigate (but not solve) this issue has been
to enforce a constraint on the smoothness of the neural network function (Wei et al., 2018; van Amersfoort
et al., 2020a; 2021; Liu et al., 2020), thereby maintaining both a sensitivity to semantic changes in the input
and robustness against adversarial inputs (Yu et al., 2019). Another approach lies in the usage of OOD
data as well, sometimes dubbed “outlier exposure” (Fort et al., 2021), but displaying the same shortcomings
as in the EDL case. A generally promising strategy seems to seek functional diversity through ensembling:
Juneja et al. (2022) show how model instances ending up in different low-loss modes correspond to distinct
generalization strategies, indicating that combining diverse strategies may lead to better generalization and
thus potentially more reliable uncertainty. Attaining different solutions still creates computational overhead,
despite new methods to reduce it (Garipov et al., 2018; Dusenberry et al., 2020; Benton et al., 2021).
Bayesian model averaging One of the most fundamental differences between EDL and existing ap-
proaches is the sacrifice of Bayesian model averaging (Equations (2) and (5)): In principle, combining
multiple parameter estimates is supposed to result in a lower predictive risk (Fragoso et al., 2018). The
Machine Learning community has ascribed further desiderata to this approach, such as better generaliza-
tion and robustness to distributional shifts. Recent studies with exact Bayesian Neural Networks however
have cast doubts on these assumptions (Izmailov et al., 2021a;b). Nevertheless, ensembles, that approx-
imate Equation (2) via Monte Carlo estimates, remain state-of-the-art on many uncertainty benchmarks.
EDL abandons modelling epistemic uncertainty through the learnable parameters, and instead expresses it
through the uncertainty in prior / posterior parameters. This loses functional diversity which could aid gen-
eralization, while sidestepping computational costs. Future research could therefore explore the combination
of both paradigms, as proposed by Haussmann et al. (2019); Zhao et al. (2020); Charpentier et al. (2022).
Challenges Despite their advantages, the last chapters have pointed out key weaknesses of Dirichlet
networks as well: In order to achieve the right behavior of the distribution and thus guarantee sensible
uncertainty estimates (since ground truth estimates are not available), the surveyed literature proposes a
variety of loss functions. Bengs et al. (2022) show formally that many of the loss functions used so far
arenotappropriate and violate basic asymptotic assumptions about epistemic uncertainty: With increasing
amount of data, epistemic uncertainty should vanish, but this is not guaranteed using the commonly used
loss functions. Furthermore, some approaches (Malinin & Gales, 2018; 2019; Nandy et al., 2020; Malinin
et al., 2020a) require out-of-distribution data points during training. This comes with two problems: Such
data is often not available or in the first place, or cannot guarantee robustness against otherkinds of unseen
OOD data, of which infinite types exist in a real-valued feature space.15Indeed, Kopetzki et al. (2021) found
OOD detection to deteriorate across a family of EDL models under adversarial perturbation and OOD data.
Stadler et al. (2021) point out that much of the ability of posterior networks stems from the addition of a NF,
which have been shown to also sometimes behave unreliably on OOD data (Nalisnick et al., 2019). Although
the NFs in posterior networks operate on the latent and not the feature space, they are also restricted to
15The same applies to the artificial OOD data in Chen et al. (2018); Shen et al. (2020); Sensoy et al. (2020).
19Published in Transactions on Machine Learning Research (04/2023)
operate on features that the underlying network has learned to recognize. Recent work by Dietterich &
Guyer (2022) has hinted at the fact that networks might identify OOD by the absence of known features,
and not by the presence of new ones, providing a case in which posterior networks are likely to fail. Such
evidence on OOD data and adversarial examples has indeed been identified by a study by Kopetzki et al.
(2021).
Future Research Directions Overall, the following directions for future research on EDL crystallize
from our previous reflections: (1) Explicit epistemic uncertainty estimation: Since we often employ the point
estimate in Equation (5) to avoid the posterior p(θ|D), explicit estimation of the epistemic uncertainty is
not possible, and some summary statistic of the concentration parameters is used for classification problems
instead (Section 3.3). Estimating model uncertainty through modelling the (approximate) posterior p(θ|D)
in Bayesian model averaging is a popular technique (Houlsby et al., 2011; Gal et al., 2016; Smith & Gal,
2018; Ulmer et al., 2020), but comes with the disadvantage of additional computational overhead. However,
Sharmaetal.(2022)recentlyshowedthataBayesiantreatmentofallmodelparametersmaynotbenecessary,
potentially allowing for a compromise. (2) Robustness to diverse OOD data: The emprical evidence compiled
by Kopetzki et al. (2021) indicates that EDL classification models are not completely able to robustly classify
and detect OOD and adversarial inputs. These findings hold both for prior networks trained with OOD data,
or for posterior networks using density estimators. We speculate that through the information bottleneck
principle (Tishby & Zaslavsky, 2015), EDL models might not learn input features that are useful to indicate
uncertainty in their prediction, or at best identify the absence of known features, but not the presence
of new ones (Dietterich & Guyer, 2022). Finding a way to have models identify unusual features could
this help to mitigate this problem. (3) Theoretical guarantees: Even though some guarantees have been
derived for EDL classifiers w.r.t. OOD data points (Charpentier et al., 2020; Stadler et al., 2021), Bengs
et al. (2022) point out the flaws of current training regimes for epistemic uncertainty in the limit of infinite
limit. Furthermore, Hüllermeier & Waegeman (2021) argue that even uncertainty estimates are affected by
uncertainty themselves, impacting their usefulness.
7 Conclusion
This survey has given an overview over contemporary approaches for uncertainty estimation using neu-
ral networks to parameterize conjugate priors or the corresponding posteriors instead of likelihoods, called
Evidential Deep Learning. We highlighted their appealing theoretical properties allowing for uncertainty es-
timation with minimal computational overhead, rendering them as a viable alternative to existing strategies.
We also emphasized practical problems: In order to nudge models towards the desired behavior in the face
of unseen or out-of-distribution samples, the design of the model architecture and loss function have to be
carefully considered. Based on a summary and discussion of experimental findings in Section 6, the entropy
regularizer seems to be a sensible choice in prior networks when OOD data is not available. Combining dis-
criminators with generative models like normalizing flows as in Charpentier et al. (2020; 2022), embedded in
a sturdy Bayesian framework, also appears as an exciting direction for practical applications. In summary,
we believe that recent advances show promising results for Evidential Deep Learning, making it a viable
option in uncertainty estimation to improve safety and trustworthiness in Machine Learning systems.
Acknowledgements
WewouldliketothankGiovanniCinà, MaxMüller-Eberstein, DanielVarabandMikeZhangforreadingearly
versions of this draft and providing tremendously useful feedback. Further, we would like to explicitly thank
Mike Zhang for helping to improve Figure 1. We also would like to thank Alexander Amini for providing a
long list of references that helped to further improve the coverage of this work and the anonymous reviewers
for their suggestions. Lastly, we owe our gratitude to the anonymous reviewers that helped us such much to
improve the different versions of this paper.
20Published in Transactions on Machine Learning Research (04/2023)
References
Alexander Amini, Wilko Schwarting, Ava Soleimany, and Daniela Rus. Deep Evidential Regression. In
Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Pro-
cessing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020.
Christophe Andrieu, Nando de Freitas, and Arnaud Doucet. Reversible Jump MCMC Simulated Annealing
for Neural Networks. In Craig Boutilier and Moisés Goldszmidt (eds.), UAI ’00: Proceedings of the 16th
Conference in Uncertainty in Artificial Intelligence, Stanford University, Stanford, California, USA, June
30 - July 3, 2000 , pp. 11–18. Morgan Kaufmann, 2000.
Anastasios N Angelopoulos and Stephen Bates. A Gentle Introduction to Conformal Prediction and
Distribution-free Uncertainty Quantification. arXiv preprint arXiv:2107.07511 , 2021.
Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein Generative Adversarial Networks. In
International conference on machine learning , pp. 214–223. PMLR, 2017.
Jsang Audun. Subjective Logic: A Formalism for Reasoning under Uncertainty . Springer, 2018.
WentaoBao, QiYu, andYuKong. EvidentialDeepLearningforOpenSetActionRecognition. In Proceedings
of the IEEE/CVF International Conference on Computer Vision , pp. 13349–13358, 2021.
Alexei Bastidas. Tiny Imagenet Image Classification, 2017.
Viktor Bengs, Eyke Hüllermeier, and Willem Waegeman. On the Difficulty of Epistemic Uncertainty Quan-
tification in Machine Learning: The Case of Direct Uncertainty Estimation through Loss Minimisation.
arXiv preprint arXiv:2203.06102 , 2022.
Gregory W. Benton, Wesley J. Maddox, Sanae Lotfi, and Andrew Gordon Wilson. Loss Surface Simplexes
for Mode Connecting Volumes and Fast Ensembling. In Proceedings of the 38th International Conference
on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , volume 139 of Proceedings of Machine
Learning Research , pp. 769–779. PMLR, 2021.
Umang Bhatt, Javier Antorán, Yunfeng Zhang, Q. Vera Liao, Prasanna Sattigeri, Riccardo Fogliato,
Gabrielle Gauthier Melançon, Ranganath Krishnan, Jason Stanley, Omesh Tickoo, Lama Nachman, Rumi
Chunara, Madhulika Srikumar, Adrian Weller, and Alice Xiang. Uncertainty as a Form of Transparency:
Measuring, Communicating, and Using Uncertainty. In AIES ’21: AAAI/ACM Conference on AI, Ethics,
and Society, Virtual Event, USA, May 19-21, 2021 , pp. 401–413. ACM, 2021.
Marin Biloš, Bertrand Charpentier, and Stephan Günnemann. Uncertainty on Asynchronous Time Event
Prediction. In Advances in Neural Information Processing Systems , pp. 12851–12860, 2019.
Christopher M Bishop. Pattern Recognition. Machine learning , 128(9), 2006.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight Uncertainty in Neural
Networks. arXiv preprint arXiv:1505.05424 , 2015.
Yaroslav Bulatov. NotMNIST Dataset. Google (Books/OCR), Tech. Rep.[Online]. Available:
http://yaroslavvb. blogspot. it/2011/09/notmnist-dataset. html , 2, 2011.
Edouard Capellier, Franck Davoine, Véronique Cherfaoui, and You Li. Evidential Deep Learning for Ar-
bitrary LIDAR Object Classification in the Context of Autonomous Driving. In 2019 IEEE Intelligent
Vehicles Symposium, IV 2019, Paris, France, June 9-12, 2019 , pp. 1304–1311. IEEE, 2019.
Bertrand Charpentier, Daniel Zügner, and Stephan Günnemann. Posterior network: Uncertainty estimation
withoutoodsamplesviadensity-basedpseudo-counts. Advances in Neural Information Processing Systems ,
33:1356–1367, 2020.
21Published in Transactions on Machine Learning Research (04/2023)
Bertrand Charpentier, Oliver Borchert, Daniel Zügner, Simon Geisler, and Stephan Günnemann. Natural
Posterior Network: Deep Bayesian Predictive Uncertainty for Exponential Family Distributions. In The
Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29,
2022. OpenReview.net, 2022.
Wenhu Chen, Yilin Shen, Hongxia Jin, and William Wang. A Variational Dirichlet Framework for Out-Of-
Distribution Detection. arXiv preprint arXiv:1811.07308 , 2018.
Kamil Ciosek, Vincent Fortuin, Ryota Tomioka, Katja Hofmann, and Richard Turner. Conservative Uncer-
tainty Estimation by Fitting Prior Networks. In International Conference on Learning Representations ,
2020.
Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David Ha.
Deep Learning for Classical Japanese Literature. arXiv preprint arXiv:1812.01718 , 2018.
AndreaCoraddu,LucaOneto,AessandroGhio, StefanoSavio,DavideAnguita, andMassimoFigari. Machine
Learning Approaches for Improving Condition-Based Maintenance of Naval Propulsion Plants. Proceedings
of the Institution of Mechanical Engineers, Part M: Journal of Engineering for the Maritime Environment ,
230(1):136–153, 2016.
Peter I Corke. A Robotics Toolbox for MATLAB. IEEE Robotics & Automation Magazine , 3(1):24–32, 1996.
PauloCortez, AntónioCerdeira, FernandoAlmeida, TelmoMatos, andJoséReis. ModelingWinePreferences
by Data Mining from Physicochemical Properties. Decision support systems , 47(4):547–553, 2009.
Alice Coucke, Alaa Saade, Adrien Ball, Théodore Bluche, Alexandre Caulier, David Leroy, Clément
Doumouro, Thibault Gisselbrecht, Francesco Caltagirone, Thibaut Lavril, et al. Snips Voice Platform:
An Embedded Spoken Language Understanding System for Private-by-Design Voice Interfaces. arXiv
preprint arXiv:1805.10190 , 2018.
Francesco D’Angelo and Vincent Fortuin. Repulsive deep ensembles are bayesian. Advances in Neural
Information Processing Systems , 34:3451–3465, 2021.
Mindy I Davis, Jeremy P Hunt, Sanna Herrgard, Pietro Ciceri, Lisa M Wodicka, Gabriel Pallares, Michael
Hocker,DanielKTreiber,andPatrickPZarrinkar. ComprehensiveAnalysisofKinaseInhibitorSelectivity.
Nature biotechnology , 29(11):1046–1051, 2011.
Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and Philipp
Hennig. Laplace Redux - Effortless Bayesian Deep Learning. In Marc’Aurelio Ranzato, Alina Beygelzimer,
Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan (eds.), Advances in Neural Information
Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS
2021, December 6-14, 2021, virtual , pp. 20089–20103, 2021.
João Ferdinando Gomes de Freitas. Bayesian Methods for Neural Networks . PhD thesis, University of
Cambridge, 2003.
Arthur P Dempster. A Generalization of Bayesian Inference. Journal of the Royal Statistical Society: Series
B (Methodological) , 30(2):205–232, 1968.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A Large-Scale Hierarchical
Image Database. In 2009 IEEE conference on computer vision and pattern recognition , pp. 248–255. Ieee,
2009.
Armen Der Kiureghian and Ove Ditlevsen. Aleatory or Epistemic? Does it matter? Structural safety , 31
(2):105–112, 2009.
Shrey Desai and Greg Durrett. Calibration of Pre-trained Transformers. In Bonnie Webber, Trevor Cohn,
Yulan He, and Yang Liu (eds.), Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing, EMNLP 2020, Online, November 16-20, 2020 , pp. 295–302. Association for Com-
putational Linguistics, 2020.
22Published in Transactions on Machine Learning Research (04/2023)
Thomas G. Dietterich and Alexander Guyer. The Familiarity Hypothesis: Explaining the Behavior of Deep
Open Set Methods. Pattern Recognit. , 132:108931, 2022.
Dheeru Dua, Casey Graff, et al. UCI Machine Learning Repository. 2017.
Haonan Duan. Method of Moments in Approximate Bayesian Inference: From Theory to Practice. Master’s
thesis, University of Waterloo, 2021.
Michael Dusenberry, Ghassen Jerfel, Yeming Wen, Yi-An Ma, Jasper Snoek, Katherine A. Heller, Balaji
Lakshminarayanan, and Dustin Tran. Efficient and Scalable Bayesian Neural Nets with Rank-1 Factors.
InProceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020,
Virtual Event , volume 119 of Proceedings of Machine Learning Research , pp. 2782–2792. PMLR, 2020.
Sven Elflein, Bertrand Charpentier, Daniel Zügner, and Stephan Günnemann. On Out-of-distribution De-
tection with Energy-based Models. arXiv preprint arXiv:2107.08785 , 2021.
Hadi Fanaee-T and Joao Gama. Event Labeling Combining Ensemble Detectors and Background Knowledge.
Progress in Artificial Intelligence , 2(2):113–127, 2014.
Yassir Fathullah and Mark J. F. Gales. Self-distribution distillation: efficient uncertainty estimation. In
James Cussens and Kun Zhang (eds.), Uncertainty in Artificial Intelligence, Proceedings of the Thirty-
Eighth Conference on Uncertainty in Artificial Intelligence, UAI 2022, 1-5 August 2022, Eindhoven, The
Netherlands , volume 180 of Proceedings of Machine Learning Research , pp. 663–673. PMLR, 2022.
Ronald A Fisher. The Use of Multiple Measurements in Taxonomic Problems. Annals of eugenics , 7(2):
179–188, 1936.
Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep Ensembles: A Loss Landscape Perspective.
arXiv preprint arXiv:1912.02757 , 2019.
Stanislav Fort, Jie Ren, and Balaji Lakshminarayanan. Exploring the Limits of Out-of-Distribution Detec-
tion. InAdvances in Neural Information Processing Systems 34: Annual Conference on Neural Information
Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual , pp. 7068–7081, 2021.
Vincent Fortuin, Mark Collier, Florian Wenzel, James Allingham, Jeremiah Liu, Dustin Tran, Balaji Laksh-
minarayanan, Jesse Berent, Rodolphe Jenatton, and Effrosyni Kokiopoulou. Deep Classifiers with Label
Noise Modeling and Distance Awareness. arXiv preprint arXiv:2110.02609 , 2021.
Tiago M Fragoso, Wesley Bertoli, and Francisco Louzada. Bayesian Model Averaging: A Systematic Review
and Conceptual Classification. International Statistical Review , 86(1):1–28, 2018.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian Approximation: Representing Model Uncertainty
in Deep Learning. In International conference on Machine Learning , pp. 1050–1059, 2016.
Yarin Gal et al. Uncertainty in Deep Learning. 2016.
Timur Garipov, Pavel Izmailov, Dmitrii Podoprikhin, Dmitry P. Vetrov, and Andrew Gordon Wilson. Loss
Surfaces, ModeConnectivity, andFastEnsemblingofDNNs. In Advances in Neural Information Processing
Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December
3-8, 2018, Montréal, Canada , pp. 8803–8812, 2018.
Jakob Gawlikowski, Sudipan Saha, Anna M. Kruspe, and Xiao Xiang Zhu. An Advanced Dirichlet Prior
Network for Out-of-Distribution Detection in Remote Sensing. IEEE Trans. Geosci. Remote. Sens. , 60:
1–19, 2022.
Andrew Gelman, John B Carlin, Hal S Stern, and Donald B Rubin. Bayesian Data Analysis . Chapman and
Hall/CRC, 1995.
J Gerritsma, R Onnink, and A Versluis. Geometry, Resistance and Stability of the Delft Systematic Yacht
Hull Series. International shipbuilding progress , 28(328):276–297, 1981.
23Published in Transactions on Machine Learning Research (04/2023)
Florin C. Ghesu, Bogdan Georgescu, Eli Gibson, Sebastian Gündel, Mannudeep K. Kalra, Ramandeep Singh,
Subba R. Digumarthy, Sasa Grbic, and Dorin Comaniciu. Quantifying and Leveraging Classification
Uncertainty for Chest Radiograph Assessment. In Medical Image Computing and Computer Assisted
Intervention - MICCAI 2019 - 22nd International Conference, Shenzhen, China, October 13-17, 2019,
Proceedings, Part VI , volume 11769 of Lecture Notes in Computer Science , pp. 676–684. Springer, 2019.
C Lee Giles, Kurt D Bollacker, and Steve Lawrence. CiteSeer: An Automatic Citation Indexing System. In
Proceedings of the third ACM conference on Digital libraries , pp. 89–98, 1998.
Ian J. Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha Arnoud, and Vinay D. Shet. Multi-Digit Number
Recognition from Street View Imagery using Deep Convolutional Neural Networks. In 2nd International
Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference
Track Proceedings , 2014.
Will Grathwohl, Kuan-Chieh Wang, Jörn-Henrik Jacobsen, David Duvenaud, Mohammad Norouzi, and
Kevin Swersky. Your Classifier is Secretly an Energy-Based Model and You Should Treat It Like One.
In8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April
26-30, 2020 .
Ang Nan Gu, Christina Luong, Mohammad H. Jafari, Nathan Van Woudenberg, Hany Girgis, Purang Abol-
maesumi, andTeresaTsang. EfficientEchocardiogramViewClassificationwithSampling-FreeUncertainty
Estimation. In Simplifying Medical Ultrasound - Second International Workshop, ASMUS 2021, Held in
Conjunction with MICCAI 2021, Strasbourg, France, September 27, 2021, Proceedings , volume 12967 of
Lecture Notes in Computer Science , pp. 139–148. Springer, 2021.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On Calibration of Modern Neural Networks.
InProceedings of the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW,
Australia, 6-11 August 2017 , volume 70 of Proceedings of Machine Learning Research , pp. 1321–1330.
PMLR, 2017.
David Harrison Jr and Daniel L Rubinfeld. Hedonic Housing Prices and the Demand for Clean Air. Journal
of environmental economics and management , 5(1):81–102, 1978.
Manuel Haussmann, Sebastian Gerwinn, and Melih Kandemir. Bayesian Evidential Deep Learning with
PAC Regularization. arXiv preprint arXiv:1906.00816 , 2019.
Jakob Drachmann Havtorn, Jes Frellsen, Søren Hauberg, and Lars Maaløe. Hierarchical VAEs Know What
They Don’t Know. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021,
18-24 July 2021, Virtual Event , volume 139 of Proceedings of Machine Learning Research , pp. 4117–4128.
PMLR, 2021.
Bobby He, Balaji Lakshminarayanan, and Yee Whye Teh. Bayesian Deep Ensembles via the Neural Tangent
Kernel.Advances in neural information processing systems , 33:1010–1022, 2020.
MatthiasHein, MaksymAndriushchenko, andJulianBitterwolf. WhyReLUNetworksYieldHigh-Confidence
Predictions Far Away From the Training Data and How to Mitigate the Problem. In IEEE Conference on
Computer Vision and Pattern Recognition, CVPR 2019, Long Beach, CA, USA, June 16-20, 2019 , pp.
41–50. Computer Vision Foundation / IEEE, 2019.
Patrick Hemmer, Niklas Kühl, and Jakob Schöffer. Deal: Deep Evidential Active Learning for Image Clas-
sification. In Deep Learning Applications, Volume 3 , pp. 171–192. Springer, 2022.
Charles T Hemphill, John J Godfrey, and George R Doddington. The ATIS Spoken Language Systems Pilot
Corpus. In Speech and Natural Language: Proceedings of a Workshop Held at Hidden Valley, Pennsylvania,
June 24-27, 1990 , 1990.
Dan Hendrycks and Kevin Gimpel. A Baseline for Detecting Misclassified and Out-of-Distribution Examples
in Neural Networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon,
France, April 24-26, 2017, Conference Track Proceedings , 2017.
24Published in Transactions on Machine Learning Research (04/2023)
José Miguel Hernández-Lobato and Ryan Adams. Probabilistic Backpropagation for Scalable Learning of
Bayesian Neural Networks. In International conference on machine learning , pp. 1861–1869. PMLR, 2015.
Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distilling the Knowledge in a Neural Network. arXiv
preprint arXiv:1503.02531 , 2(7), 2015.
Geoffrey E Hinton and Drew Van Camp. Keeping the Neural Networks Simple by Minimizing the Description
Length of the Weights. In Proceedings of the sixth annual conference on Computational learning theory ,
pp. 5–13, 1993.
Marius Hobbhahn, Agustinus Kristiadi, and Philipp Hennig. Fast predictive uncertainty for classification
with bayesian deep networks. In Uncertainty in Artificial Intelligence , pp. 822–832. PMLR, 2022.
Neil Houlsby, Ferenc Huszár, Zoubin Ghahramani, and Máté Lengyel. Bayesian Active Learning for Classi-
fication and Preference Learning. arXiv preprint arXiv:1112.5745 , 2011.
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and
Jure Leskovec. Open Graph Benchmark: Datasets for Machine Learning on Graphs. Advances in neural
information processing systems , 33:22118–22133, 2020.
Yibo Hu, Yuzhe Ou, Xujiang Zhao, Jin-Hee Cho, and Feng Chen. Multidimensional Uncertainty-Aware
Evidential Neural Networks. In Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,
Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh
Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9,
2021, pp. 7815–7822. AAAI Press, 2021.
Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E. Hopcroft, and Kilian Q. Weinberger. Snapshot
Ensembles: Train 1, Get M for Free. In 5th International Conference on Learning Representations, ICLR
2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings , 2017.
Xinyu Huang, Xinjing Cheng, Qichuan Geng, Binbin Cao, Dingfu Zhou, Peng Wang, Yuanqing Lin, and
Ruigang Yang. The Apolloscape Dataset for Autonomous Driving. In Proceedings of the IEEE conference
on computer vision and pattern recognition workshops , pp. 954–960, 2018.
Eyke Hüllermeier. Quantifying Aleatoric and Epistemic Uncertainty in Machine Learning: Are Conditional
Entropy and Mutual Information Appropriate Measures? arXiv preprint arXiv:2209.03302 , 2022.
Eyke Hüllermeier and Willem Waegeman. Aleatoric and Epistemic Uncertainty in Machine Learning: An
Introduction to Concepts and Methods. Mach. Learn. , 110(3):457–506, 2021.
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander Madry.
Adversarial Examples Are Not Bugs, They Are Features. In Advances in Neural Information Processing
Systems 32: Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada , pp. 125–136, 2019.
Pavel Izmailov, Patrick Nicholson, Sanae Lotfi, and Andrew G Wilson. Dangers of Bayesian Model Averaging
under Covariate Shift. Advances in Neural Information Processing Systems , 34:3309–3322, 2021a.
Pavel Izmailov, Sharad Vikram, Matthew D. Hoffman, and Andrew Gordon Wilson. What Are Bayesian
Neural Network Posteriors Really Like? In Proceedings of the 38th International Conference on Machine
Learning, ICML 2021, 18-24 July 2021, Virtual Event , volume 139 of Proceedings of Machine Learning
Research , pp. 4629–4640. PMLR, 2021b.
Alon Jacovi, Ana Marasović, Tim Miller, and Yoav Goldberg. Formalizing trust in artificial intelligence:
Prerequisites, Causes and Goals of Human Trust in AI. In Proceedings of the 2021 ACM conference on
fairness, accountability, and transparency , pp. 624–635, 2021.
Harold Jeffreys. The Theory of Probability . OUP Oxford, 1998.
25Published in Transactions on Machine Learning Research (04/2023)
Robin Jia, Larry Heck, Dilek Hakkani-Tür, and Georgi Nikolov. Learning Concepts through Conversations
in Spoken Dialogue Systems. In 2017 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP) , pp. 5725–5729. IEEE, 2017.
Taejong Joo, Uijung Chung, and Min-Gwan Seo. Being bayesian about categorical probability. In Interna-
tional conference on machine learning , pp. 4950–4961. PMLR, 2020.
Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An Introduction to
Variational Methods for Graphical Models. Machine learning , 37(2):183–233, 1999.
Jeevesh Juneja, Rachit Bansal, Kyunghyun Cho, João Sedoc, and Naomi Saphra. Linear Connectivity
Reveals Generalization Strategies. arXiv preprint arXiv:2205.12411 , 2022.
Alex Kendall and Yarin Gal. What Uncertainties do We Need in Bayesian Deep Learning for Computer
Vision?Advances in neural information processing systems , 30, 2017.
Sunghwan Kim, Jie Chen, Tiejun Cheng, Asta Gindulyte, Jia He, Siqian He, Qingliang Li, Benjamin A
Shoemaker, Paul A Thiessen, Bo Yu, et al. PubChem 2019 Update: Improved Access to Chemical Data.
Nucleic acids research , 47(D1):D1102–D1109, 2019.
Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In Yoshua Bengio and
Yann LeCun (eds.), 3rd International Conference on Learning Representations, ICLR 2015, San Diego,
CA, USA, May 7-9, 2015, Conference Track Proceedings , 2015.
Diederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International Confer-
ence on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Conference Track
Proceedings , 2014.
JohannesKlicpera,AleksandarBojchevski,andStephanGünnemann. PredictthenPropagate: GraphNeural
Networks meet Personalized PageRank. In 7th International Conference on Learning Representations,
ICLR 2019, New Orleans, LA, USA, May 6-9, 2019 , 2019.
Benjamin Kompa, Jasper Snoek, and Andrew L. Beam. Empirical Frequentist Coverage of Deep Learning
Uncertainty Quantification Procedures. Entropy, 23(12):1608, 2021.
Anna-Kathrin Kopetzki, Bertrand Charpentier, Daniel Zügner, Sandhya Giri, and Stephan Günnemann.
Evaluating Robustness of Predictive Uncertainty Estimation: Are Dirichlet-based Models Reliable? In
Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021,
Virtual Event , volume 139 of Proceedings of Machine Learning Research , pp. 5707–5718. PMLR, 2021.
Agustinus Kristiadi, Matthias Hein, and Philipp Hennig. Being Bayesian, Even Just a Bit, Fixes Overcon-
fidence in ReLU Networks. In Proceedings of the 37th International Conference on Machine Learning,
ICML 2020, 13-18 July 2020, Virtual Event , volume 119 of Proceedings of Machine Learning Research ,
pp. 5436–5446. PMLR, 2020.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning Multiple Layers of Features from Tiny Images. 2009.
Meelis Kull, Miquel Perello Nieto, Markus Kängsepp, Telmo Silva Filho, Hao Song, and Peter Flach. Beyond
Temperature Scaling: Obtaining Well-Calibrated Multi-Class Probabilities with Dirichlet Calibration.
Advances in neural information processing systems , 32, 2019.
Morton Kupperman. Probabilities of Hypotheses and Information-Statistics in Sampling from Exponential-
Class Populations. Selected Mathematical Papers , 29(2):57, 1964.
Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. Adversarial Examples in the Physical World. In 5th
International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017,
Workshop Track Proceedings , 2017.
26Published in Transactions on Machine Learning Research (04/2023)
Salem Lahlou, Moksh Jain, Hadi Nekoei, Victor I Butoi, Paul Bertin, Jarrid Rector-Brooks, Maksym Ko-
rablyov, and Yoshua Bengio. DEUP: Direct Epistemic Uncertainty Prediction. Transactions on Machine
Learning Research , 2022. ISSN 2835-8856.
BrendenMLake, RuslanSalakhutdinov, andJoshuaBTenenbaum. Human-LevelConceptLearningThrough
Probabilistic Program Induction. Science, 350(6266):1332–1338, 2015.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and Scalable Predictive Un-
certainty Estimation using Deep Ensembles. In Advances in neural information processing systems , pp.
6402–6413, 2017.
Yann LeCun. The MNIST Database of Handwritten Digits, 1998. URL http://yann .lecun.com/exdb/
mnist/.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-Based Learning Applied to
Document Recognition. Proceedings of the IEEE , 86(11):2278–2324, 1998.
Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A Simple Unified Framework for Detecting Out-of-
Distribution Samples and Adversarial Attacks. In Advances in Neural Information Processing Systems 31:
Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018,
Montréal, Canada , pp. 7167–7177, 2018.
Jing Lei and Larry Wasserman. Distribution-free Prediction Bands for Non-parametric Regression. Journal
of the Royal Statistical Society: Series B (Statistical Methodology) , 76(1):71–96, 2014.
Hao Li, Yang Nan, Javier Del Ser, and Guang Yang. Region-Based Evidential Deep Learning to Quantify
Uncertainty and Improve Robustness of Brain Tumor Segmentation. arXiv preprint arXiv:2208.06038 ,
2022.
Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing The Reliability of Out-of-distribution Image Detection in
Neural Networks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver,
BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings , 2018.
Q. Vera Liao and S. Shyam Sundar. Designing for Responsible Trust in AI Systems: A Communication
Perspective. In FAccT ’22: 2022 ACM Conference on Fairness, Accountability, and Transparency, Seoul,
Republic of Korea, June 21 - 24, 2022 , pp. 1257–1268. ACM, 2022.
Jiayu Lin. On the Dirichlet Distribution. Mater’s Report , 2016.
Jeremiah Z. Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax-Weiss, and Balaji Lakshminarayanan.
Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness.
InAdvances in Neural Information Processing Systems 33: Annual Conference on Neural Information
Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020.
Tiqing Liu, Yuhmei Lin, Xin Wen, Robert N Jorissen, and Michael K Gilson. BindingDB: A Web-Accessible
Database of Experimentally Determined Protein–Ligand Binding Affinities. Nucleic acids research , 35
(suppl_1):D198–D201, 2007.
Zhijian Liu, Alexander Amini, Sibo Zhu, Sertac Karaman, Song Han, and Daniela L. Rus. Efficient and
Robust LiDAR-Based End-to-End Navigation. In IEEE International Conference on Robotics and Au-
tomation, ICRA 2021, Xi’an, China, May 30 - June 5, 2021 , pp. 13247–13254. IEEE, 2021.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep Learning Face Attributes in the Wild. In
Proceedings of the IEEE international conference on computer vision , pp. 3730–3738, 2015.
David JC MacKay. Developments in Probabilistic Modelling with Neural Networks—Ensemble Learning. In
Neural Networks: Artificial Intelligence and Industrial Applications , pp. 191–198. Springer, 1995.
David JC MacKay. Choice of basis for Laplace approximation. Machine learning , 33:77–86, 1998.
27Published in Transactions on Machine Learning Research (04/2023)
David John Cameron Mackay. Bayesian Methods for Adaptive Models . California Institute of Technology,
1992.
Andrey Malinin and Mark J. F. Gales. Predictive Uncertainty Estimation via Prior Networks. In Advances in
Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems
2018, NeurIPS 2018, 3-8 December 2018, Montréal, Canada , pp. 7047–7058, 2018.
Andrey Malinin and Mark J. F. Gales. Reverse KL-Divergence Training of Prior Networks: Improved
Uncertainty and Adversarial Robustness. In Advances in Neural Information Processing Systems 32:
Annual Conference on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019,
Vancouver, BC, Canada , pp. 14520–14531, 2019.
Andrey Malinin, Sergey Chervontsev, Ivan Provilkov, and Mark Gales. Regression Prior Networks. arXiv
preprint arXiv:2006.11590 , 2020a.
Andrey Malinin, Bruno Mlodozeniec, and Mark J. F. Gales. Ensemble Distribution Distillation. In 8th
International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,
2020, 2020b.
Lei Mao. Introduction to Exponential Family, 2019. URL https://zhiyzuo .github.io/Exponential-
Family-Distributions/ . Accessed April 2022.
Andrés R. Masegosa. Learning under Model Misspecification: Applications to Variational and Ensemble
methods. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural In-
formation Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020.
Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel. Image-Based Recommen-
dations on Styles and Substitutes. In Proceedings of the 38th international ACM SIGIR conference on
research and development in information retrieval , pp. 43–52, 2015.
Andrew Kachites McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. Automating the Construc-
tion of Internet Portals with Machine Learning. Information Retrieval , 3(2):127–163, 2000.
Nis Meinert and Alexander Lavin. Multivariate Deep Evidential Regression. arXiv preprint
arXiv:2104.06135 , 2021.
Moritz Menze and Andreas Geiger. Object Scene Flow for Autonomous Vehicles. In Proceedings of the IEEE
conference on computer vision and pattern recognition , pp. 3061–3070, 2015.
Jeffrey W. Miller. (ML 7.7.A2) Expectation of a Dirichlet Random Variable, 2011. URL https:
//www.youtube.com/watch?v=emnfq4txDuI .
Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin
Tran, and Mario Lucic. Revisiting the Calibration of Modern Neural Networks. Advances in Neural
Information Processing Systems , 34:15682–15694, 2021.
Jose G Moreno-Torres, Troy Raeder, RocíO Alaiz-RodríGuez, Nitesh V Chawla, and Francisco Herrera. A
Unifying View on Dataset Shift in Classification. Pattern recognition , 45(1):521–530, 2012.
Jishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip HS Torr, and Yarin Gal. Deterministic
Neural Networks With Appropriate Inductive Biases Capture Epistemic and Aleatoric Uncertainty. arXiv
preprint arXiv:2102.11582 , 2021.
Kevin P Murphy. Conjugate Bayesian Analysis of the Gaussian Distribution. 2007.
Vaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur. Understanding the Failure Modes of
Out-Of-Distribution Generalization. In 9th International Conference on Learning Representations, ICLR
2021, Virtual Event, Austria, May 3-7, 2021 , 2021.
28Published in Transactions on Machine Learning Research (04/2023)
Eric T. Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Görür, and Balaji Lakshminarayanan. Do
Deep Generative Models Know What They Don’t Know? In 7th International Conference on Learning
Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019 , 2019.
Galileo Namata, Ben London, Lise Getoor, Bert Huang, and UMD EDU. Query-Driven Active Surveying for
Collective Classification. In 10th International Workshop on Mining and Learning with Graphs , volume 8,
pp. 1, 2012.
Jay Nandy, Wynne Hsu, and Mong Li Lee. Towards Maximizing the Representation Gap between In-Domain
& Out-of-Distribution Examples. Advances in Neural Information Processing Systems , 33, 2020.
Radford M Neal. Bayesian Learning for Neural Networks , volume 118. Springer Science & Business Media,
2012.
Jeremy Nixon, Michael W Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring
Calibration in Deep Learning. In CVPR Workshops , volume 2, 2019.
DongpinOhandBonggunShin. ImprovingEvidentialDeepLearningviaMulti-TaskLearning. In Proceedings
of the AAAI Conference on Artificial Intelligence , volume 36, pp. 7895–7903, 2022.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua Dillon, Balaji
Lakshminarayanan, and Jasper Snoek. Can You Trust Your Model’s Uncertainty? Evaluating Predictive
UncertaintyunderDatasetShift. In Advances in Neural Information Processing Systems , pp.13991–14002,
2019.
Harris Papadopoulos, Kostas Proedrou, Volodya Vovk, and Alex Gammerman. Inductive Confidence Ma-
chines for Regression. In European Conference on Machine Learning , pp. 345–356. Springer, 2002.
Fabian Paschke, Christian Bayer, Martyna Bator, Uwe Mönks, Alexander Dicks, Olaf Enge-Rosenblatt, and
Volker Lohweg. Sensorlose Zustandsüberwachung an Synchronmotoren. In Proc, pp. 211, 2013.
Tim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in Neural Networks: Approximately
Bayesian Ensembling. In International conference on artificial intelligence and statistics , pp. 234–244.
PMLR, 2020.
Tim Pearce, Alexandra Brintrup, and Jun Zhu. Understanding Softmax Confidence and Uncertainty. arXiv
preprint arXiv:2106.04972 , 2021.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R.Weiss,V.Dubourg,J.Vanderplas,A.Passos,D.Cournapeau,M.Brucher,M.Perrot,andE.Duchesnay.
Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research , 12:2825–2830, 2011.
Kürsat Petek, Kshitij Sirohi, Daniel Büscher, and Wolfram Burgard. Robust Monocular Localization in
Sparse HD Maps Leveraging Multi-Task Uncertainty Estimation. In 2022 International Conference on
Robotics and Automation, ICRA 2022, Philadelphia, PA, USA, May 23-27, 2022 , pp. 4163–4169. IEEE,
2022.
Stefan T Radev, Marco D’Alessandro, Ulf K Mertens, Andreas Voss, Ullrich Köthe, and Paul-Christian
Bürkner. Amortized Bayesian Model Comparison with Evidential Deep Learning. IEEE Transactions on
Neural Networks and Learning Systems , 2021.
Danilo Jimenez Rezende and Shakir Mohamed. Variational Inference with Normalizing Flows. In Proceedings
of the 32nd International Conference on Machine Learning, ICML 2015, Lille, France, 6-11 July 2015 ,
volume 37 of JMLR Workshop and Conference Proceedings , pp. 1530–1538. JMLR.org, 2015.
Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential Deep Learning to Quantify Classification
Uncertainty. In Advances in Neural Information Processing Systems , pp. 3179–3189, 2018.
29Published in Transactions on Machine Learning Research (04/2023)
Murat Sensoy, Lance M. Kaplan, Federico Cerutti, and Maryam Saleki. Uncertainty-Aware Deep Classifiers
Using Generative Models. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020,
The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth
AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA,
February 7-12, 2020 , pp. 5620–5627. AAAI Press, 2020.
Mrinank Sharma, Sebastian Farquhar, Eric Nalisnick, and Tom Rainforth. Do Bayesian Neural Networks
Need To Be Fully Stochastic? arXiv preprint arXiv:2211.06291 , 2022.
Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan Günnemann. Pitfalls of Graph
Neural Network Evaluation. arXiv preprint arXiv:1811.05868 , 2018.
Maohao Shen, Yuheng Bu, Prasanna Sattigeri, Soumya Ghosh, Subhro Das, and Gregory Wornell. Post-hoc
Uncertainty Learning using a Dirichlet Meta-Model. arXiv preprint arXiv:2212.07359 , 2022.
Yilin Shen, Wenhu Chen, and Hongxia Jin. Modeling Token-level Uncertainty to Learn Unknown Concepts
in SLU via Calibrated Dirichlet Prior RNN. CoRR, abs/2010.08101, 2020.
Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. Indoor Segmentation and Support
Inference from RGBD Images. In European conference on computer vision , pp. 746–760. Springer, 2012.
Lewis Smith and Yarin Gal. Understanding Measures of Uncertainty for Adversarial Example Detection. In
Proceedings of the Thirty-Fourth Conference on Uncertainty in Artificial Intelligence, UAI 2018, Monterey,
California, USA, August 6-10, 2018 , pp. 560–569, 2018.
Ava P Soleimany, Alexander Amini, Samuel Goldman, Daniela Rus, Sangeeta N Bhatia, and Connor W
Coley. Evidential Deep Learning for Guided Molecular Property Prediction and Discovery. ACS central
science, 7(8):1356–1367, 2021.
Maximilian Stadler, Bertrand Charpentier, Simon Geisler, Daniel Zügner, and Stephan Günnemann. Graph
Posterior Network: Bayesian Predictive Uncertainty for Node Classification. Advances in Neural Infor-
mation Processing Systems , 34, 2021.
Jing Tang, Agnieszka Szwajda, Sushil Shakyawar, Tao Xu, Petteri Hintsanen, Krister Wennerberg, and Tero
Aittokallio. Making Sense of Large-Scale Kinase Inhibitor Bioactivity Data Sets: A Comparative and
Integrative Analysis. Journal of Chemical Information and Modeling , 54(3):735–743, 2014.
Naftali Tishby and Noga Zaslavsky. Deep Learning and the Information Bottleneck Principle. In 2015 ieee
information theory workshop (itw) , pp. 1–5. IEEE, 2015.
Athanasios Tsanas and Angeliki Xifara. Accurate Quantitative Estimation of Energy Performance of Resi-
dential Buildings using Statistical Machine Learning Tools. Energy and buildings , 49:560–567, 2012.
Theodoros Tsiligkaridis. Information Robust Dirichlet Networks for Predictive Uncertainty Estimation.
arXiv preprint arXiv:1910.04819 , 2019.
MehmetOzgurTurkoglu, AlexanderBecker, HüseyinAnilGündüz, MinaRezaei, BerndBischl, RodrigoCaye
Daudt, Stefano D’Aronco, Jan Dirk Wegner, and Konrad Schindler. FiLM-Ensemble: Probabilistic Deep
Learning via Feature-wise Linear Modulation. arXiv preprint arXiv:2206.00050 , 2022.
Dennis Ulmer and Giovanni Cinà. Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails
at Reliable OOD Detection. In Uncertainty in Artificial Intelligence , pp. 1766–1776. PMLR, 2021.
Dennis Ulmer, Lotta Meijerink, and Giovanni Cinà. Trust Issues: Uncertainty Estimation Does not Enable
Reliable OOD Detection on Medical Tabular Data. In Machine Learning for Health , pp. 341–354. PMLR,
2020.
Dennis Ulmer, Jes Frellsen, and Christian Hardmeier. "Exploring Predictive Uncertainty and Calibration in
NLP:AStudyontheImpactofMethod&DataScarcity". In Findings of the Association for Computational
Linguistics: EMNLP 2022 , pp.2707–2735, AbuDhabi, UnitedArabEmirates, December2022.Association
for Computational Linguistics.
30Published in Transactions on Machine Learning Research (04/2023)
Joost van Amersfoort, Lewis Smith, Yee Whye Teh, and Yarin Gal. Uncertainty Estimation Using a Single
Deep Deterministic Neural Network. In Proceedings of the 37th International Conference on Machine
Learning, ICML 2020, 13-18 July 2020, Virtual Event , volume 119 of Proceedings of Machine Learning
Research , pp. 9690–9700. PMLR, 2020a.
Joost van Amersfoort, Lewis Smith, Yee Whye Teh, and Yarin Gal. Uncertainty Estimation Using a Single
Deep Deterministic Neural Network. In Proceedings of the 37th International Conference on Machine
Learning, ICML 2020, 13-18 July 2020, Virtual Event , volume 119 of Proceedings of Machine Learning
Research , pp. 9690–9700. PMLR, 2020b.
Joost van Amersfoort, Lewis Smith, Andrew Jesson, Oscar Key, and Yarin Gal. On Feature Collapse and
Deep Kernel Learning for Single Forward Pass Uncertainty. arXiv preprint arXiv:2102.11409 , 2021.
Tim van Erven and Peter Harremoës. Rényi Divergence and Kullback-Leibler Divergence. IEEE Trans. Inf.
Theory, 60(7):3797–3820, 2014.
Jordy Van Landeghem, Matthew Blaschko, Bertrand Anckaert, and Marie-Francine Moens. Benchmarking
Scalable Predictive Uncertainty in Text Classification. Ieee Access , 10:43703–43737, 2022.
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. Algorithmic lLarning in a Random World .
Springer Science & Business Media, 2005.
Chen Wang, Xiang Wang, Jiawei Zhang, Liang Zhang, Xiao Bai, Xin Ning, Jun Zhou, and Edwin Hancock.
Uncertainty Estimation for Stereo Matching Based on Evidential Deep Learning. Pattern Recognition , pp.
108498, 2021a.
Deng-Bao Wang, Lei Feng, and Min-Ling Zhang. Rethinking Calibration of Deep Neural Networks: Do not
be Afraid of Overconfidence. Advances in Neural Information Processing Systems , 34:11809–11820, 2021b.
Xiang Wei, Boqing Gong, Zixia Liu, Wei Lu, and Liqiang Wang. Improving the Improved Training of
Wasserstein GANs: A Consistency Term and Its Dual Effect. In 6th International Conference on Learn-
ing Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track
Proceedings , 2018.
Yeming Wen, Dustin Tran, and Jimmy Ba. BatchEnsemble: an Alternative Approach to Efficient Ensemble
and Lifelong Learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis
Ababa, Ethiopia, April 26-30, 2020 , 2020.
Florian Wenzel, Kevin Roth, Bastiaan S Veeling, Jakub Światkowski, Linh Tran, Stephan Mandt, Jasper
Snoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How Good is the Bayes Posterior in
Deep Neural Networks Really? arXiv preprint arXiv:2002.02405 , 2020.
Wikimedia Commons. Iris setosa, 2022a. URL https://en .wikipedia.org/wiki/Iris_setosa .
File:Irissetosa1.jpg.
Wikimedia Commons. Iris versicolor, 2022b. URL https://en .wikipedia.org/wiki/Iris_versicolor .
File:Blue_Flag,_Ottawa.jpg.
Wikimedia Commons. Iris virginica, 2022c. URL https://en .wikipedia.org/wiki/Iris_virginica#/
media/File:Iris_virginica_2 .jpg. File:Iris_virginica_2.jpg.
Andrew Gordon Wilson and Pavel Izmailov. Bayesian Deep Learning and a Probabilistic Perspective of
Generalization. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020.
John Michael Winn. Variational Message Passing and Its Applications. 2004.
Jae Oh Woo. Analytic Mutual Information in Bayesian Neural Networks. In IEEE International Symposium
on Information Theory, ISIT 2022, Espoo, Finland, June 26 - July 1, 2022 , pp. 300–305. IEEE, 2022.
31Published in Transactions on Machine Learning Research (04/2023)
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-MNIST: A Novel Image Dataset for Benchmarking
Machine Learning Algorithms. arXiv preprint arXiv:1708.07747 , 2017.
Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun Database: Large-
scale Scene Recognition from Abbey to Zoo. In 2010 IEEE computer society conference on computer vision
and pattern recognition , pp. 3485–3492. IEEE, 2010.
Ronald R Yager and Liping Liu. Classic Works of the Dempster-Shafer Theory of Belief Functions , volume
219. Springer, 2008.
I-C Yeh. Modeling of Strength of High-Performance Concrete using Artificial Neural Networks. Cement and
Concrete research , 28(12):1797–1808, 1998.
Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song, Thomas Funkhouser, and Jianxiong Xiao. LSUN: Con-
struction of a Large-Scale Image Dataset using Deep Learning with Humans in the Loop. arXiv preprint
arXiv:1506.03365 , 2015.
Fuxun Yu, Zhuwei Qin, Chenchen Liu, Liang Zhao, Yanzhi Wang, and Xiang Chen. Interpreting and Eval-
uating Neural Network Robustness. In Proceedings of the Twenty-Eighth International Joint Conference
on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019 , pp. 4199–4205. ijcai.org, 2019.
Chrysoula Zerva, Taisiya Glushkova, Ricardo Rei, and André F. T. Martins. "Disentangling Uncertainty in
Machine Translation Evaluation". In Proceedings of the 2022 Conference on Empirical Methods in Natural
Language Processing , pp. 8622–8641, Abu Dhabi, United Arab Emirates, December 2022. Association for
Computational Linguistics.
XujiangZhao,YuzheOu,LanceKaplan,FengChen,andJin-HeeCho. QuantifyingClassificationUncertainty
Using Regularized Evidential Neural Networks. arXiv preprint arXiv:1910.06864 , 2019.
Xujiang Zhao, Feng Chen, Shu Hu, and Jin-Hee Cho. Uncertainty Aware Semi-Supervised Learning on
Graph Data. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural
Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual , 2020.
32Published in Transactions on Machine Learning Research (04/2023)
A Code Appendix
A.1 Iris Example Training Details
ThecodeusedtoproduceFigure2isavailableonline.16Allmodelsusethreelayerswith 100hiddenunitsand
ReLU activations each. We furthermore optimized all of the models with a learning rate of 0.001using the
Adam optimizer (Kingma & Ba, 2015) with its default parameter settings. We also regularize the ensemble
and MC Dropout model with a dropout probability of 0.1each.
PriorNetworkspecifics Wechoosetheexpected l2lossbySensoyetal.(2018)andregularizethenetwork
usingtheKLdivergencew.r.t. toauniformDirichletasinSensoyetal.(2018). Intheregularizationterm, we
donotusetheoriginalconcentrationparameters α, butaversioninwhichtheconcentrationoftheparameter
αkcorresponding to the correct class is removed using a one-hot label encoding yby˜α= (1−α)⊙α+y⊙α,
where⊙denotes point-wise multiplication. The regularization term is added to the loss using a weighting
factor of 0.05.
A.2 Code Availability
We list the available code repositories for surveyed works in Table 4. Works for which no official implemen-
tation could be found are not listed.
B Datasets & Evaluation Techniques Appendix
This section contains a discussion of the used datasets, methods to evaluate the quality of uncertainty
evaluation, as well as a direct of available models based on the reported results to determine the most useful
choices for practitioners. An overview over the differences between the surveyed works is given in Table 5.
Datasets Most models are applied to image classification problems, where popular choices involve the
MNIST dataset (LeCun, 1998), using as OOD datasets Fashion-MNIST (Xiao et al., 2017), notMNIST
(Bulatov, 2011) containing English letters, K-MNIST (Clanuwat et al., 2018) with ancient Japanese
Kuzushiji characters, and the Omniglot dataset (Lake et al., 2015), featuring handwritten characters from
more than 50 alphabets. Other choices involve different versions of the CIFAR-10 object recognition dataset
(LeCun et al., 1998; Krizhevsky et al., 2009) for training purposes and SVHN (Goodfellow et al., 2014),
iSUN (Xiao et al., 2010), LSUN (Yu et al., 2015), CelebA (Liu et al., 2015), ImageNet (Deng et al., 2009)
and TinyImagenet (Bastidas, 2017) for OOD samples. Regression image datasets include for instance the
NYU Depth Estimation v2 dataset (Silberman et al., 2012), using ApolloScape (Huang et al., 2018) or
KITTI (Menze & Geiger, 2015) as an OOD dataset. Many authors also illustrate model uncertainty on
synthetic data, for instance by simulating clusters of data points using Gaussians (Malinin & Gales, 2018;
2019; Nandy et al., 2020; Zhao et al., 2019; Hu et al., 2020; Charpentier et al., 2020; 2022), spiral data
(Malinin et al., 2020b) or polynomials for regression (Amini et al., 2020; Oh & Shin, 2022; Meinert &
Lavin, 2021; Malinin et al., 2020a; Charpentier et al., 2022). Tabular datasets include the Segment dataset,
predicting image segments based on pixel features (Dua et al., 2017), and the sensorless drive dataset
(Dua et al., 2017; Paschke et al., 2013), describing the maintenance state of electric current drives as well
as popular regression datasets included in the UCI regression benchmark used by Hernández-Lobato &
Adams (2015); Gal & Ghahramani (2016): Boston house prices (Harrison Jr & Rubinfeld, 1978), concrete
compression strength (Yeh, 1998), energy efficiency of buildings (Tsanas & Xifara, 2012), forward kinematics
of an eight link robot arm (Corke, 1996), maintenance of naval propulsion systems (Coraddu et al., 2016),
properties of protein tertiary stuctures, wine quality (Cortez et al., 2009), and yacht hydrodynamics
(Gerritsma et al., 1981). Furthermore, Oh & Shin (2022) use a number of drug discovery datasets, such as
Davis (Davis et al., 2011), Kiba (Tang et al., 2014), BindingDB (Liu et al., 2007) and PubChem (Kim et al.,
2019). Biloš et al. (2019) are the only authors working on asynchronous time even prediction, and supply
their own data in the form of processed stack exchange postings, smart home data, and car indicators.
16The code is available under https://github .com/Kaleidophon/evidential-deep-learning-survey .
33Published in Transactions on Machine Learning Research (04/2023)
Table 4: Overview over code repositories of surveyed works.
Paper Code Repository
Prior network
(Malinin & Gales, 2018)https://github .com/KaosEngineer/PriorNetworks-OLD
Prior networks
(Malinin & Gales, 2019)https://github .com/KaosEngineer/PriorNetworks
Dirichlet via Function Decomposition
(Biloš et al., 2019)https://github .com/sharpenb/Uncertainty-Event-Prediction
Prior network with PAC Regularization
(Haussmann et al., 2019)https://github .com/manuelhaussmann/bedl
Prior networks with representation gap
(Nandy et al., 2020)https://github .com/jayjaynandy/maximize-representation-gap
Graph-based Kernel Dirichlet distribution
estimation (GKDE) (Zhao et al., 2020)https://github .com/zxj32/uncertainty-GNN
Evidential Deep Learning
(Sensoy et al., 2018)https://muratsensoy .github.io/uncertainty .html
WGAN–ENN
(Hu et al., 2021)https://github .com/snowood1/wenn
Belief Matching (Joo et al., 2020) https://github .com/tjoo512/belief-matching-framework
Posterior Networks
(Charpentier et al., 2020)https://github .com/sharpenb/Posterior-Network
Graph Posterior Networks
(Stadler et al., 2021)https://github .com/stadlmax/Graph-Posterior-Network
Generative Evidential Neural Networks
(Sensoy et al., 2020)https://muratsensoy .github.io/gen.html
Deep Evidential Regression
with Multi-task Learning
(Oh & Shin, 2022)https://github .com/deargen/MT-ENet
Multivariate Deep Evidential
Regression (Meinert & Lavin, 2021)https://github .com/avitase/mder/
Regression Prior Network
(Malinin et al., 2020a)https://github .com/JanRocketMan/regression-prior-networks
Natural Posterior Network
(Charpentier et al., 2022)https://github .com/borchero/natural-posterior-network
Shen et al. (2020) provide the sole method on language data, and use three different concept learning
datasets, i.e. Concept Learning (Jia et al., 2017), Snips (Coucke et al., 2018) and ATIS (Hemphill et al.,
1990), which contains new OOD concepts to be learned by design. For graph neural networks, Zhao et al.
(2020) and Stadler et al. (2021) select data from the co-purchase datasets Amazon Computer, Amazon
Photos (McAuley et al., 2015) and the CoraML (McCallum et al., 2000), CiteSeer (Giles et al., 1998)
and PubMed (Namata et al., 2012), Coauthors Physics (Shchur et al., 2018), CoauthorCS (Namata et al.,
2012) and OGBN Arxiv (Hu et al., 2020) citation datasets. Lastly, Charpentier et al. (2022) use a sin-
gle count prediction dataset concerned with predicting the number of bike rentals (Fanaee-T & Gama, 2014).
Uncertainty Evaluation Methods There usually are no gold labels for uncertainty estimates, which is
why the efficacy of proposed solutions has to be evaluated in a different way. One such way used by almost
all the surveyed works is using uncertainty estimates in a proxy OOD detection task: Since the model is
underspecified on unseen samples from another distribution, it should be more uncertain. By labelling
34Published in Transactions on Machine Learning Research (04/2023)
OOD samples as the positive and ID inputs as the negative class, we can measure the performance of
uncertainty estimates using the area under the receiver-operator characteristic (AUROC) or the area under
the precision-recall curve (AUPR). We can thereby characterize the usage of data from another dataset
as a form of covariate shift, while using left-out classes for testing can be seen as a kind of concept shift
(Moreno-Torres et al., 2012). Instead of using OOD data, another approach is to use adversarial examples
(Malinin & Gales, 2019; Tsiligkaridis, 2019; Sensoy et al., 2018; Hu et al., 2021; Chen et al., 2018; Amini
et al., 2020), checking if they can be identified through uncertainty. In the case of Shen et al. (2020), OOD
detection or new concept extraction is the actual and not a proxy task, and thus can be evaluated using
classical metrics such as the F1score. Another way is misclassification detection: In general, we would desire
the model to be more uncertain about inputs it incurs a higher loss on, i.e., what it is more wrong about.
For this purpose, some works (Malinin & Gales, 2018; Zhao et al., 2020; Charpentier et al., 2020) measure
whether let missclassified inputs be the positive class in another binary proxy classification test, and again
measure AUROC and AUPR. Alternatively, Malinin et al. (2020b); Stadler et al. (2021); Amini et al. (2020)
show or measure the area under the prediction / rejection curve, graphing how task performance varies as
predictions on increasingly uncertain inputs is suspended. Lastly, some authors look at a model’s calibration
(Guo et al., 2017): While this does not allow to judge the quality of uncertainty estimates themselves,
quantities like the expected calibration error quantify to what extent the output distribution of a clas-
sifiercorrespondstothetruelabeldistribution, andthuswhetheraleatoricuncertaintyisaccuratelyreflected.
35Published in Transactions on Machine Learning Research (04/2023)
Table 5: Overview over uncertainty evaluation techniques and datasets.(∗)indicates that a dataset was
used as an OOD dataset for evaluation purposes, while(⋄)signifies that it was used as an in-distribution or
out-of-distribution dataset.(†)means that a dataset was modified to create ID and OOD splits (for instance
by removing some classes for evaluation or corrupting samples with noise).
Data Modality
Method Uncertainty Evaluation Images Tabular Other
Prior network
(Malinin & Gales, 2018)OOD Detection,
Misclassification DetectionMNIST, CIFAR-10,
Omniglot(∗), SVHN(∗),
LSUN(∗), TIM(∗)✗ Clusters (Synthetic)
Prior networks
(Malinin & Gales, 2019)OOD Detection,
Adversarial Attack DetectionMNIST, CIFAR-10/100,
SVHN(∗), LSUN(∗), TIM(∗) ✗ Clusters (Synthetic)
Information Robust Dirichlet Networks
(Tsiligkaridis, 2019)OOD Detection,
Adversarial Attack DetectionMNIST, FashionMNIST(∗)
notMNIST(∗), Omniglot(∗)
CIFAR-10, TIM(∗), SVHN(∗)✗ ✗
Dirichlet via Function Decomposition
(Biloš et al., 2019)OOD Detection ✗Erdős-Rényi Graph
(Synthetic), Stack Exchange,
Smart Home, Car Indicators✗
Prior network with PAC Regularization
(Haussmann et al., 2019)OOD DetectionMNIST, FashionMNIST(∗)
CIFAR-10(†) ✗ ✗
Ensemble Distribution Distillation
(Malinin et al., 2020b)OOD Detection,
Misclassification Detection,
CalibrationCIFAR-10, CIFAR-100(⋄)
TIM(⋄), LSUN(∗) ✗ Spirals (Synthetic)
Self-Distribution Distillation
(Fathullah & Gales, 2022)OOD Detection,
CalibrationCIFAR-100
SVHN(∗), LSUN(∗) ✗ ✗
Prior networks with representation gap
(Nandy et al., 2020)OOD DetectionCIFAR-10(⋄), CIFAR-100(⋄)
TIM, ImageNet(∗) ✗ Clusters (Synthetic)
Prior RNN (Shen et al., 2020) New Concept Extraction ✗ ✗Concept Learning(⋄), Snips(⋄),
ATIS(⋄)(Language)
Graph-based Kernel Dirichlet distribution
estimation (GKDE) (Zhao et al., 2020)OOD Detection
Misclassification Detection✗ ✗Coauthors Physics(⋄),
Amazon Computer(⋄)
Amazon Photo(⋄)(Graph)
Evidential Deep Learning
(Sensoy et al., 2018)OOD Detection,
Adversarial Attack DetectionMNIST, notMNIST(∗),
CIFAR-10(†) ✗ ✗
Regularized ENN
Zhao et al. (2019)OOD Detection CIFAR-10(†)✗ Clusters (Synthetic)
WGAN–ENN
(Hu et al., 2021)OOD Detection,
Adversarial Attack DetectionMNIST, notMNIST(∗),
CIFAR-10(†) ✗ Clusters (Synthetic)
Variational Dirichlet
(Chen et al., 2018)OOD Detection,
Adversarial Attack DetectionMNIST, CIFAR-10/100,
iSUN(∗), LSUN(∗),
SVHN(∗), TIM(∗)✗ ✗
Dirichlet Meta-Model
(Shen et al., 2022)OOD Detection
Misclassification DetectionMNIST(⋄,†), CIFAR-10(⋄,†),
CIFAR-100(⋄), Omniglot(∗),
FashionMNIST(∗), K-MNIST(∗),
SVHN(∗), LSUN(∗),
TIM(∗)✗ ✗
Belief Matching (Joo et al., 2020) OOD Detection, Calibration CIFAR-10/100, SVHN(∗)✗ ✗
Posterior Networks
(Charpentier et al., 2020)OOD Detection,
Misclassification Detection,
CalibrationMNIST, FashionMNIST(∗),
K-MNIST(∗), CIFAR-10,
SVHN(∗)Segment(†),
Sensorless Drive(†) Clusters (Synthetic)
Graph Posterior Networks
(Stadler et al., 2021)OOD Detection,
Misclassification Detection,
Calibration✗ ✗Amazon Computer(⋄), Amazon Photo(⋄)
CoraML(⋄), CiteSeerCoraML(⋄),
PubMed(⋄), Coauthors Physics(⋄),
CoauthorsCS(⋄), OBGN Arxiv(⋄)(Graph)
Deep Evidential Regression
(Amini et al., 2020)OOD Detection,
Misclassification Detection,
Adversarial Attack Detection
CalibrationNYU Depth v2
ApolloScape∗
(Depth Estimation)UCI Regression
BenchmarkUnivariate Regression (Synthetic)
Deep Evidential Regression
with Multi-task Learning
(Oh & Shin, 2022)OOD Detection,
Calibration✗Davis, Kiba(†),
BindingDB, PubChem(∗)
(Drug discovery),
UCI Regression
BenchmarkUnivariate Regression (Synthetic)
Multivariate Deep Evidential
Regression Meinert & Lavin (2021)Qualitative Evaluation ✗ ✗ Multivariate Regression (Synthetic)
Regression Prior Network
(Malinin et al., 2020a)OOD DetectionNYU Depth v2⋄,
KITTI⋄
(Depth Estimation)UCI Regression
BenchmarkUnivariate Regression (Synthetic)
Natural Posterior Network
(Charpentier et al., 2022)OOD Detection, CalibrationNYU Depth v2,
KITTI∗, LSUN(∗)
(Depth Estimation),
MNIST, FashionMNIST(∗),
K-MNIST(∗), CIFAR-10(†),
SVHN(∗), CelebA(∗)UCI Regression
Benchmark(†),
Sensorless Drive(†),
Bike Sharing(†)Clusters (Synthetic),
Univariate Regression (Synthetic))
36Published in Transactions on Machine Learning Research (04/2023)
C Fundamental Derivations Appendix
This appendix section walks the reader through generalized versions of recurring theoretical results using
Dirichlet distributions in a Machine Learning context, such as their expectation in Appendix C.1, their
entropy in Appendix C.2 and the Kullback-Leibler divergence between two Dirichlets in Appendix D.3.
C.1 Expectation of a Dirichlet
Here, we show results for the quantities E[πk]andE[logπk]. For the first, we follow the derivation by Miller
(2011). Another proof is given by Lin (2016).
E[πk] =/integraldisplay
···/integraldisplay
πkΓ(α0)/producttextK
k′=1Γ(α′
k)K/productdisplay
k′=1παk′−1
k′dπ1...dπK (30)
Movingπαk−1
kout of the product:
=/integraldisplay
···/integraldisplayΓ(α0)/producttextK
k′=1Γ(αk′)παk−1+1
k/productdisplay
k′̸=kπαk′−1
k′dπ1...dπK (31)
For the next step, we define a new set of Dirichlet parameters with βk=αk+ 1and∀k′̸=k:βk′=αk′.
For those new parameters, β0=/summationtext
kβk= 1 +α0. So by virtue of the Gamma function’s property that
Γ(β0) = Γ(α0+ 1) =α0Γ(α0), replacing all terms in the normalization factor yields
=/integraldisplay
···/integraldisplayαk
α0Γ(β0)/producttextK
k′=1Γ(βk′)K/productdisplay
k′=1πβk′−1
k′dπ1...dπK=αk
α0(32)
where in the last step we obtain the final result, since the Dirichlet with new parameters βkmust nevertheless
integrate to 1, and the integrals do not regard αkorα0. For the expectation E[logπk], we first rephrase
the Dirichlet distribution in terms of the exponential family (Kupperman, 1964). The exponential family
encompasses many commonly-used distributions, such as the normal, exponential, Beta or Poisson, which
all follow the form
p(x;η) =h(x) exp/parenleftbig
ηTu(x)−A(η)/parenrightbig
(33)
withnatural parameters η,sufficient statistic u(x), andlog-partition function A(η). For the Dirichlet
distribution, Winn (2004) provides the sufficient statistic as u(π) = [log π1,...,πK]Tand the log-partition
function
A(α) =K/summationdisplay
k=1log Γ(αk)−log Γ(αo) (34)
By Mao (2019), we also find that by the moment-generating function that for the sufficient statistic, its
expectation can be derived by
E[u(x)k] =∂A(η)
∂ηk(35)
Therefore we can evaluate the expected value of logπk(i.e. the sufficient statistic) by inserting the definition
of the log-partition function in Equation (34) into Equation (35):
37Published in Transactions on Machine Learning Research (04/2023)
E[logπk] =∂
∂αkK/summationdisplay
k=1log Γ(αk)−log Γ(α0) =ψ(αk)−ψ(α0) (36)
which corresponds precisely to the definition of the digamma function as ψ(x) =d
dxlog Γ(x).
C.2 Entropy of Dirichlet
The following derivation is adapted from Lin (2016), with the result stated in Charpentier et al. (2020) as
well.
H[π] =−E[logp(π|α)] (37)
=−E/bracketleftbigg
log/parenleftig1
B(α)K/productdisplay
k=1παk−1
k/parenrightig/bracketrightbigg
(38)
=−E/bracketleftbigg
−logB(α) +K/summationdisplay
k=1(αk−1) logπk/bracketrightbigg
(39)
= logB(α)−K/summationdisplay
k=1(αk−1)E[logπk] (40)
Using Equation (36):
= logB(α)−K/summationdisplay
k=1(αk−1)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
(41)
= logB(α) +K/summationdisplay
k=1(αk−1)ψ(α0)−K/summationdisplay
k=1(αk−1)ψ(αk) (42)
= logB(α) + (α0−K)ψ(α0)−K/summationdisplay
k=1(αk−1)ψ(αk) (43)
C.3 Kullback-Leibler Divergence between two Dirichlets
The following result is presented using an adapted derivation by Lin (2016) and appears in Chen et al. (2018)
and Joo et al. (2020) as a starting point for their variational objective (see Appendix D.7). In the following
we use Dir (π;α)to denote the optimized distribution, and Dir (π;γ)the reference or target distribution.
KL/bracketleftig
p(π|α)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|γ)/bracketrightig
=E/bracketleftbigg
logp(π|α)
p(π|γ)/bracketrightbigg
=E/bracketleftbigg
logp(π|α)/bracketrightbigg
−E/bracketleftbigg
logp(π|γ)/bracketrightbigg
(44)
=E/bracketleftbigg
−logB(α) +K/summationdisplay
k=1(αk−1) logπk/bracketrightbigg
−E/bracketleftbigg
−logB(γ) +K/summationdisplay
k=1(γk−1) logπk/bracketrightbigg
(45)
Distributing and pulling out B(α)andB(γ)out of the expectation (they don’t depend on π):
=−logB(γ)
B(α)+E/bracketleftbiggK/summationdisplay
k=1(αk−1) logπk−(γk−1) logπk/bracketrightbigg
(46)
38Published in Transactions on Machine Learning Research (04/2023)
=−logB(γ)
B(α)+E/bracketleftbiggK/summationdisplay
k=1(αk−γk) logπk/bracketrightbigg
(47)
Moving the expectation inward and using the identity E[πk] =ψ(αk)−ψ(α0)from Appendix C.1:
=−logB(γ)
B(α)+K/summationdisplay
k=1(αk−γk)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
(48)
The KL divergence is also used by some works as regularizer by penalizing the distance to a uniform Dirichlet
withγ=1(Sensoy et al., 2018). In this case, the result above can be derived to be
KL/bracketleftig
p(π|α)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|1)/bracketrightig
= logΓ(K)
B(α)+K/summationdisplay
k=1(αk−1)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
(49)
where the log Γ(K)term can also be omitted for optimization purposes, since it does not depend on α.
39Published in Transactions on Machine Learning Research (04/2023)
D Additional Derivations Appendix
In this appendix we present relevant results in a Machine Learning context, including from some of the
surveyed works, featuring as unified notation and annotated derivation steps. These include derivations
of expected entropy (Appendix D.1) and mutual information (Appendix D.2) as uncertainty metrics for
Dirichlet networks. Also, we derive a multitude of loss functions, including the l∞norm loss of a Dirichlet
w.r.t. a one-hot encoded class label in Appendix D.3, the l2norm loss in Appendix D.4, as well as the
reverse KL loss by Malinin & Gales (2019), the UCE objective Biloš et al. (2019); Charpentier et al. (2020)
and ELBO Shen et al. (2020); Chen et al. (2018) as training objectives (Appendices D.5 to D.7).
D.1 Derivation of Expected Entropy
The following derivation is adapted from Malinin & Gales (2018) appendix section C.4. In the following, we
assume that∀k∈K:πk>0:
Ep(π|x,ˆθ)/bracketleftbigg
H/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
=/integraldisplay
p(π|x,ˆθ)/parenleftbigg
−K/summationdisplay
k=1πklogπk/parenrightbigg
dπ (50)
=−K/summationdisplay
k=1/integraldisplay
p(π|x,ˆθ)/parenleftig
πklogπk/parenrightig
dπ (51)
Inserting the definition of p(π|x,ˆθ)≈p(π|x,D):
=−K/summationdisplay
k=1/parenleftigg
Γ(α0)/producttextK
k′=1Γ(αk′)/integraldisplay
πklogπkK/productdisplay
k′=1παk′−1
k′dπ/parenrightigg
(52)
Singling out the factor πk:
=−K/summationdisplay
k=1/parenleftigg
Γ(α0)
Γ(αk)/producttext
k′̸=kΓ(αk′)παk−1
k/integraldisplay
πklogπk/productdisplay
k′̸=kπαk′−1
k′dπ/parenrightigg
(53)
Adjusting the normalizing constant (this is the same trick used in Appendix C.1):
=−K/summationdisplay
k=1/parenleftigg
αk
α0/integraldisplayΓ(α0+ 1)
Γ(αk+ 1)/producttext
k′̸=kΓ(αk′)παk−1
klogπk/productdisplay
k′̸=kπαk′−1
k′dπ/parenrightigg
(54)
Using the identity E[logπk] =ψ(αk)−ψ(α0)(Equation (36)). Since the expectation here is w.r.t to a
Dirichlet with concentration parameters αk+ 1, we obtain
=−K/summationdisplay
k=1αk
α0/parenleftbigg
ψ(αk+ 1)−ψ(α0+ 1)/parenrightbigg
(55)
D.2 Derivation of Mutual Information
We start from the expression in Equation (13):
I/bracketleftig
y,π/vextendsingle/vextendsingle/vextendsinglex,D/bracketrightig
=H/bracketleftbigg
Ep(π|x,D)/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
−Ep(π|x,D)/bracketleftbigg
H/bracketleftig
P(y|π)/bracketrightig/bracketrightbigg
(56)
40Published in Transactions on Machine Learning Research (04/2023)
Given that E[πk] =αk
α0(Appendix C.1) and assuming that point estimate p(π|x,D)≈p(π|x,ˆθ)is suffi-
cient (Malinin & Gales, 2018), we can identify the first term as the Shannon entropy −/summationtextK
k=1πklogπk=
−/summationtextK
k=1αk
α0logαk
α0. Furthermore, the second part we already derived in Appendix D.1 and thus we obtain:
=−K/summationdisplay
k=1αk
α0logαk
α0+K/summationdisplay
k=1αk
α0/parenleftbigg
ψ(αk+ 1)−ψ(α0+ 1)/parenrightbigg
(57)
=−K/summationdisplay
k=1αk
α0/parenleftbigg
logαk
α0−ψ(αk+ 1) +ψ(α0+ 1)/parenrightbigg
(58)
D.3l∞Norm Derivation
In this section we elaborate on the derivation of Tsiligkaridis (2019) deriving a generalized lploss, upper-
bounding the l∞loss. This in turn allows us to easily derive the l2loss used by Sensoy et al. (2018); Zhao
et al. (2020). Here we assume the classification target yis provided in the form of a one-hot encoded label
y= [1y=1,...,1y=K]T.
Ep(π|x,θ)/bracketleftbig
||y−π||∞/bracketrightbig
≤Ep(π|x,θ)/bracketleftbig
||y−π||p/bracketrightbig
(59)
Using Jensen’s inequality
≤/parenleftig
Ep(π|x,θ)/bracketleftbig
||y−π||p
p/bracketrightbig/parenrightig1/p
(60)
Evaluating the expression with ∀k̸=y:yk= 0:
=/parenleftig
E[(1−πy)p] +/summationdisplay
k̸=yE[πp
k]/parenrightig1/p
(61)
In order to compute the expression above, we first realize that all components of πare distributed according
to a Beta distribution Beta (α,β)(since the Dirichlet is a multivariate generalization of the beta distribution)
for which the moment-generating function is given as follows:
E[πp] =Γ(α+p)Γ(β)Γ(α+β)
Γ(α+p+β)Γ(α)Γ(β)=Γ(α+p)Γ(α+β)
Γ(α+p+β)Γ(α)(62)
Given that the first term in Equation (59) is characterized by Beta (α0−αy,αy)and the second one by
Beta(αk,α0−αk), we can evaluate the result in Equation (59) using the moment generating function:
Ep(π|x,θ)/bracketleftig
||y−π||∞/bracketrightig
≤/parenleftigg
Γ(α0−αy+p)Γ(α0−αy+αy)
Γ(α0−αy+p+αy)Γ(α0−αy)+/summationdisplay
k̸=yΓ(αk+p)Γ(αk+α0−αk)
Γ(αk+p+α0−αk)Γ(αk)/parenrightigg1
p
(63)
=/parenleftigg
Γ(α0−αy+p)Γ(α0)
Γ(α0+p)Γ(α0−αy)+/summationdisplay
k̸=yΓ(αk+p)Γ(α0)
Γ(p+α0)Γ(αk)/parenrightigg1
p
(64)
Factoring out common terms:
=
Γ(α0)
Γ(α0+p)
Γ(α0−αy+p)
Γ(α0−αy)+/summationdisplay
k̸=yΓ(αk+p)
Γ(αk)

1
p
(65)
41Published in Transactions on Machine Learning Research (04/2023)
Expressing α0−αk=/summationtext
k̸=yαk:
=/parenleftbiggΓ(α0)
Γ(α0+p)/parenrightbigg1
p
Γ/parenleftig/summationtext
k̸=yαk+p/parenrightig
Γ/parenleftig/summationtext
k̸=yαk/parenrightig+/summationdisplay
k̸=yΓ(αk+p)
Γ(αk)
1
p
(66)
D.4l2Norm Loss Derivation
Here we present an adapted derivation by Sensoy et al. (2018) for the l2-norm loss to train Dirichlet networks.
Here we again use a one-hot vector for a label with y= [1y=1,...,1y=K]T.
Ep(π|x,θ)/bracketleftig
||y−π||2
2/bracketrightig
=E/bracketleftbiggK/summationdisplay
k=1(1y=k−πk)2/bracketrightbigg
(67)
=E/bracketleftbiggK/summationdisplay
k=112
y=k−2πk1y=k+π2
k/bracketrightbigg
(68)
=K/summationdisplay
k=112
y=k−2E[πk]1y=k+E[π2
k] (69)
Using the identity that E[π2
k] =E[πk]2+Var(πk):
=K/summationdisplay
k=112
y=k−2E[πk]1y=k+E[πk]2+Var(πk) (70)
=K/summationdisplay
k=1/parenleftig
1y=k−E[πk]/parenrightig2
+Var(πk) (71)
Finally, we use the result from Appendix C.1 and the result that Var (πk) =αk(α0−αk)
α2
0(α0+ 1)(see Lin, 2016):
=K/summationdisplay
k=1/parenleftig
1y=k−αk
α0/parenrightig2
+αk(α0−αk)
α2
0(α0+ 1)(72)
D.5 Derivation of Reverse KL loss
Here we re-state and annotate the derivation of reverse KL loss by Malinin & Gales (2019) in more detail,
starting from the forward KL loss by Malinin & Gales (2018). Note that here, ˆαcontains a dependence on k,
since Malinin & Gales (2018) let ˆαk= ˆπkˆα0with ˆα0being a hyperparameter and ˆπk=1k=y+(−1k=yK+1)ε
andεbeing a small number.
Ep(x,y)/bracketleftbiggK/summationdisplay
k=11y=kKL/bracketleftig
p(π|ˆα)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|x,θ)/bracketrightig/bracketrightbigg
(73)
=Ep(x,y)/bracketleftbiggK/summationdisplay
k=11y=k/integraldisplay
p(π|ˆα) logp(π|ˆα)
p(π|x,θ)dπ/bracketrightbigg
(74)
Writing the expectation explicitly:
=/integraldisplayK/summationdisplay
k=1p(y=k,x)K/summationdisplay
k=11y=k/integraldisplay
p(π|ˆα) logp(π|ˆα)
p(π|x,θ)dπdx (75)
42Published in Transactions on Machine Learning Research (04/2023)
=/integraldisplayK/summationdisplay
k=1p(x)P(y=k|x)K/summationdisplay
k=11y=k/integraldisplay
p(π|ˆα) logp(π|ˆα)
p(π|x,θ)dπdx (76)
=Ep(x)/bracketleftiggK/summationdisplay
k=1P(y=k|x)K/summationdisplay
k=11y=k/integraldisplay
p(π|ˆα) logp(π|ˆα)
p(π|x,θ)dπ/bracketrightigg
(77)
Adding factor in log, collapsing double sum:
=Ep(x)/bracketleftiggK/summationdisplay
k=1P(y=k|x)/integraldisplay
p(π|ˆα) log/parenleftigg
p(π|ˆα)/summationtextK
k=1P(y=k|x)
p(π|x,θ)/summationtextK
k=1P(y=k|x)/parenrightigg
dπ/bracketrightigg
(78)
Reordering, separating constant factor from log:
=Ep(x)/bracketleftigg/integraldisplayK/summationdisplay
k=1P(y=k|x)p(π|ˆα)/parenleftigg
log/parenleftbigg/summationtextK
k=1P(y=k|x)p(π|ˆα)
p(π|x,θ)/parenrightbigg
(79)
−log/parenleftigK/summationdisplay
k=1P(y=k|x)/parenrightig
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
=0/parenrightigg
dπ/bracketrightigg
(80)
=Ep(x)/bracketleftigg
KL/bracketleftbiggK/summationdisplay
k=1P(y=k|x)p(π|ˆα)
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Mixture of KDirichlets/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|x,θ)/bracketrightbigg/bracketrightigg
(81)
where we can see that this objective actually tries to minimizes the divergence towards a mixture of K
Dirichletdistributions. Inthecaseofhighdatauncertainty, thisisclaimedincentivizethemodeltodistribute
massaroundeachofthecornersofthesimplex, insteadofthedesiredbehaviorshowninFigure4c. Therefore,
Malinin & Gales (2019) propose to swap the order of arguments in the KL-divergence, resulting in the
following:
Ep(x)/bracketleftbiggK/summationdisplay
k=1P(y=k|x)·KL/bracketleftig
p(π|x,θ)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|ˆα)/bracketrightig/bracketrightbigg
(82)
=Ep(x)/bracketleftbiggK/summationdisplay
k=1p(y=k|x)·/integraldisplay
p(π|x,θ) logp(π|x,θ)
p(π|ˆα)dπ/bracketrightbigg
(83)
Reordering:
=Ep(x)/bracketleftbigg/integraldisplay
p(π|x,θ)K/summationdisplay
k=1P(y=k|x) logp(π|x,θ)
p(π|ˆα)dπ/bracketrightbigg
(84)
=Ep(x)/bracketleftigg
Ep(π|x,θ)/bracketleftbiggK/summationdisplay
k=1P(y=k|x) logp(π|x,θ)−K/summationdisplay
k=1P(y=k|x) logp(π|ˆα)/bracketrightbigg/bracketrightigg
(85)
=Ep(x)/bracketleftigg/integraldisplay
p(π|x,θ)/parenleftbigg
log/parenleftbiggK/productdisplay
k=1p(π|x,θ)P(y=k|x)/parenrightbigg
−log/parenleftbiggK/productdisplay
k=1p(π|ˆα)P(y=k|x)/parenrightbigg/parenrightbigg
dπ/bracketrightigg
(86)
=Ep(x)/bracketleftigg/integraldisplay
p(π|x,θ)/parenleftbigg
log/parenleftbigg
p(π|x,θ)/summationtextK
k=1P(y=k|x)/parenrightbigg
−log/parenleftbiggK/productdisplay
k=1/parenleftig1
B(α)K/productdisplay
k′=1παk′−1
k′/parenrightigp(y=k|x)/parenrightbigg/parenrightbigg
dπ/bracketrightbigg
(87)
=Ep(x)/bracketleftigg/integraldisplay
p(π|x,θ)/parenleftbigg
log/parenleftbig
p(π|x,θ)/parenrightbig
−log/parenleftbiggK/productdisplay
k=1/parenleftig1
B(α)K/productdisplay
k′=1παk′−1
k′/parenrightigP(y=k|x)/parenrightbigg
dπ/bracketrightigg
(88)
43Published in Transactions on Machine Learning Research (04/2023)
=Ep(x)/bracketleftigg/integraldisplay
p(π|x,θ)/parenleftbigg
log/parenleftbig
p(π|x,θ)/parenrightbig
−log/parenleftbigg1
B(α)K/productdisplay
k′=1π/summationtextK
k=1P(y=k|x)αk′−1
k′/parenrightbigg
dπ/bracketrightigg
(89)
=Ep(x)/bracketleftigg
KL/bracketleftig
p(π|x,θ)||p(π|¯α)/bracketrightig/bracketrightigg
where ¯α=K/summationdisplay
k=1p(y=k|x)αk′ (90)
Therefore, instead of a mixture of Dirichlet distribution, we obtain a single distribution whose parameters
are a mixture of the concentrations of each class.
D.6 Uncertainty-aware Cross-Entropy Loss
The uncertainty-aware cross-entropy loss in Biloš et al. (2019); Charpentier et al. (2020) has the form
LUCE=Ep(π|x,θ)[logp(y|π)] =E[logπy] =ψ(αy)−ψ(α0) (91)
asp(y|π)is given by the true label in form of a delta distribution, we can apply the result from Appendix C.1.
D.7 Evidence-Lower Bound For Dirichlet Posterior Estimation
The evidence lower bound is a well-known objective to optimize the KL-divergence between an approximate
proposal and target distribution (Jordan et al., 1999; Kingma & Welling, 2014). We derive it based on
Chen et al. (2018) in the following for the Dirichlet case with a proposal distribution p(π|x,θ)to the target
distribution p(π|y). For the first part of the derivation, we omit the dependence on βfor clarity.
KL/bracketleftbig
p(π|x,θ)/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|y)/bracketrightbig
=Ep(π|x,θ)/bracketleftbigg
logp(π|x,θ)
p(π|y)/bracketrightbigg
=Ep(π|x,θ)/bracketleftbigg
logp(π|x,θ)p(y)
p(π,y)/bracketrightbigg
(92)
Factorizing p(π,y) =P(y|π)p(π), pulling out p(y)as it doesn’t depend on π:
=Ep(π|x,θ)/bracketleftbigg
logp(π|x,θ)
P(y|π)p(π)/bracketrightbigg
+p(y) (93)
=Ep(π|x,θ)/bracketleftbigg
logp(π|x,θ)
p(π)/bracketrightbigg
−Ep(π|x,θ)/bracketleftbig
logP(y|π)/bracketrightbig
+p(y) (94)
≤KL/bracketleftbig
p(π|x,θ)/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π)/bracketrightbig
−Ep(π|x,θ)/bracketleftbig
logP(y|π)/bracketrightbig
(95)
Now note that the second part of the result is the uncertainty-aware cross-entropy loss from Appendix D.6
and re-adding the dependence of p(π)onγ, we can re-use our result regarding the KL-divergence between
two Dirichlets in Appendix C.3 and thus obtain:
LELBO =ψ(βy)−ψ(β0)−logB(β)
B(γ)+K/summationdisplay
k=1(βk−γk)/parenleftbig
ψ(βk)−ψ(β0)/parenrightbig
(96)
which is exactly the solution obtained by both Chen et al. (2018) and Joo et al. (2020).
44Published in Transactions on Machine Learning Research (04/2023)
E Overview over Loss Functions Appendix
In Tables 6 and 7, we compare the forms of the loss function used by Evidential Deep Learning methods for
classification, using the consistent notation from the paper. Most of the presented results can be found in
the previous Appendix C and Appendix D. We refer to the original work for details about the objective of
Nandy et al. (2020).
45Published in Transactions on Machine Learning Research (04/2023)
Table 6: Overview over objectives used by prior networks for classification.
Method Loss function Regularizer Comment
Prior networks
(Malinin & Gales, 2018)logB(ˆα)
B(α)+/summationtextK
k=1(αk−ˆαk)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
−logΓ(K)
B(α)+/summationtextK
k=1(αk−1)(ψ(αk)−ψ(α0)) Target concentration parameters ˆαare created
using a label smoothing approach,
i.e.ˆπk=/braceleftigg
1−(K−1)εify=k
ε ify̸=k.
Together with setting ˆα0as a hyperparameter,
ˆαk= ˆπkˆα0
Prior networks
(Malinin & Gales, 2019)logB(ˆα)
B(α)+/summationtextK
k=1(αk−ˆαk)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
logB(¯α)
B(α)+/summationtextK
k=1(αk−¯αk)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbig
Similar to above, ˆα(k)
c=1c=kαin+ 1
for in-distribution and ¯α(k)
c=1c=kαout+ 1
where we have hyperparameters set to αin= 0.01
andαout= 0. Then finally, ˆα=/summationtextK
k=1p(y=k|x)ˆαk
and ¯α=/summationtextK
k=1p(y=k|x)¯αk.
Information Robust
Dirichlet Networks
(Tsiligkaridis, 2019)/parenleftbigg
Γ(α0)
Γ(α0+p)/parenrightbigg1
p
Γ/parenleftig/summationtext
k̸=yαk+p/parenrightig
Γ/parenleftig/summationtext
k̸=yαk/parenrightig+/summationtext
k̸=yΓ(αk+p)
Γ(αk)
1
p
1
2/summationtext
k̸=y(αk−1)2(ψ(1)(αk)−ψ(1))(α0)) ψ(1)is the polygamma function defined as
ψ(1)(x) =d
dxψ(x).
Dirichlet via Function
Decomposition
(Biloš et al., 2019)ψ(αy)−ψ(α0) λ1/integraltextT
0πk(τ)2dτ+λ2/integraltextT
0(ν−σ2(τ))2dτ Factorsλ1andλ2that are treated as hyperparameters
that weigh first term pushing the for logit kto zero,
while pushing the variance in the first term to ν.
Prior network
with PAC Reg.
(Haussmann et al., 2019)−logE/bracketleftbigg/producttextK
k=1/parenleftbigg
αk
α0/parenrightbigg1k=y/bracketrightbigg/radicalbigg
KL/bracketleftbig
p(π|α)/vextendsingle/vextendsingle/vextendsingle/vextendsinglep(π|1)/bracketrightbig
−logδ
N−1 The expectation in the loss function is evaluated
using parameter samples from a weight distribution.
δ∈[0,1].
Ensemble Distribution
Distillation
(Malinin et al., 2020b)ψ(α0)−/summationtextK
k=1ψ(αk) +1
M/summationtextM
m=1/summationtextK
k=1(αk−1)
logp(y=k|x,θ(m))- The objective uses predictions from a trained ensemble
with parameters θ1,...,θM.
Prior networks with
representation gap
(Nandy et al., 2020)−logπy−λin
K/summationtextK
k=1σ(αk) −/summationtext
k=11
Klogπk−λout
K/summationtextK
k=1σ(αk) The main objective is being optimized on in-distribution,
the regularizer on out-of-distribution data. λinand
λoutweighing terms and σdenotes the sigmoid function.
Prior RNN
(Shen et al., 2020)/summationtext
k=11k=ylogπk −logB(˜α) + (ˆα0−K)ψ(ˆα0)−/summationtextK
k=1(ˆαk−1)ψ(ˆαk)Here, the entropy regularizer operates on a scaled version of the
concentration parameters ˜α= (IK−W)α, where Wis learned.
Graph-based Kernel
Dirichlet dist. est. (GKDE)
(Zhao et al., 2020)/summationtextK
k=1/parenleftig
1y=k−αk
α0/parenrightig2
+αk(α0−αk)
α2
0(α0+1)−logB(α)
B(ˆα)+/summationtextK
k=1(αk−ˆαk)/parenleftbig
ψ(αk)−ψ(α0)/parenrightbigˆαhere corresponds to a uniform prior including some
information about the local graph structure. The authors
also use an additional knowledge distillation objective,
which was omitted here since it doesn’t related to the Dirichlet.
46Published in Transactions on Machine Learning Research (04/2023)
Table 7: Overview over objectives used by posterior networks for classification.
Method Loss function Regularizer Comment
Evidential Deep Learning
(Sensoy et al., 2018)/summationtextK
k=1/parenleftig
1y=k−βk
β0/parenrightig2
+βk(β0−βk)
β2
0(β0+1)−logΓ(K)
B(β)+/summationtextK
k=1(βk−1)(ψ(βk)−ψ(β0))
Variational Dirichlet
(Chen et al., 2018)ψ(βy)−ψ(β0) −logB(β)
B(γ)+/summationtextK
k=1(βk−γk)/parenleftbig
ψ(βk)−ψ(β0)/parenrightbig
Regularized ENN
Zhao et al. (2019)/summationtextK
k=1/parenleftig
1y=k−βk
β0/parenrightig2
+βk(β0−βk)
β2
0(β0+1)−λ1Epout(x,y)/bracketleftig
αy
α0/bracketrightig
−λ2Epconfl.(x,y)/bracketleftigg
/summationtextK
k=1/parenleftbigg
βk/summationtext
k′̸=kβk′/parenleftbig
1−|βk′−βk|
βk′+βk/parenrightbig
/summationtext
k′̸=kβk′/parenrightbigg/bracketrightigg
The first term represents vacuity, i.e. the lack of evidence and is
optimized using OOD examples. The second term stands for dissonance ,
and is computed using points with neighborhoods with different classes
from their own. λ1,λ2are hyperparameters.
WGAN–ENN
(Hu et al., 2021)/summationtextK
k=1/parenleftig
1y=k−βk
β0/parenrightig2
+βk(β0−βk)
β2
0(β0+1)−λEpout(x,y)/bracketleftig
αy
α0/bracketrightig
Belief Matching
(Joo et al., 2020)ψ(βy)−ψ(β0) −logB(β)
B(γ)+/summationtextK
k=1(βk−γk)/parenleftbig
ψ(βk)−ψ(β0)/parenrightbig
Posterior networks
(Charpentier et al., 2020)ψ(βy)−ψ(β0) −logB(β) + (β0−K)ψ(β0)−/summationtextK
k=1(βk−1)ψ(βk)
Graph Posterior Networks
(Stadler et al., 2021)ψ(βy)−ψ(β0) −logB(β) + (β0−K)ψ(β0)−/summationtextK
k=1(βk−1)ψ(βk)
Generative Evidential
Neural Network
(Sensoy et al., 2020)−/summationtextK
k=1/parenleftbigg
Epin(x)/bracketleftbig
log(σ(fθ(x)))/bracketrightbig
+Epout(x)/bracketleftbig
log(1−σ(fθ(x)))/bracketrightbig/parenrightbigg
−logΓ(K)
B(β−y)+/summationtext
k̸=y(βk−1)(ψ(βk)−ψ(β0)) The main loss is a discriminative loss using ID and OOD samples,
generated by a VAE. The regularizer is taken over all classes
excluding the true class y(also indicated by β−y).
47