Causal Discovery from Event Sequences
by Local Cause-Effect Attribution
Joscha Cüppers◦
CISPA Helmholtz Center
for Information Security
joscha.cueppers@cispa.deSascha Xu◦
CISPA Helmholtz Center
for Information Security
sascha.xu@cispa.de
Ahmed Musa•
Institute for Structural Analysis
TU Dresden
ahmed.musa@tu-dresden.deJilles Vreeken
CISPA Helmholtz Center
for Information Security
jv@cispa.de
Abstract
Sequences of events, such as crashes in the stock market or outages in a network,
contain strong temporal dependencies, whose understanding is crucial to react to
and influence future events. In this paper, we study the problem of discovering the
underlying causal structure from event sequences. To this end, we introduce a new
causal model, where individual events of the cause trigger events of the effect with
dynamic delays. We show that in contrast to existing methods based on Granger
causality, our model is identifiable for both instant and delayed effects.
We base our approach on the Algorithmic Markov Condition, by which we identify
the true causal network as the one that minimizes the Kolmogorov complexity. As
the Kolmogorov complexity is not computable, we instantiate our model using
Minimum Description Length and show that the resulting score identifies the
causal direction. To discover causal graphs, we introduce the CASCADE algorithm,
which adds edges in topological order. Extensive evaluation shows that CASCADE
outperforms existing methods in settings with instantaneous effects, noise, and
multiple colliders, and discovers insightful causal graphs on real-world data.
1 Introduction
Suppose we are considering a multivariate event sequence. What caused a specific event to happen?
Which variables are causes of each other? Data-driven methods can infer causal relationships from
observed data. Existing methods for discovering causal networks from event sequence data [ 1–3]
are based on Granger causality [4]. This purely predictive notion defines a variable Xto be a cause
of another variable Yif the past of Xhelps to predict the future Y. It is a relatively weak notion of
causality that excludes instantaneous effects and is often unable to discover true causal dependencies;
in Granger causality, baking a cake is causal to a birthday.
In this paper, we instead build upon Pearl’s model of causality, which assumes the existence of an
an underlying causal structure in the form of a directed acyclic graph (DAG) [ 5]. In our context,
such a graph describes the causal relationships between types of events, such as alarms in a network.
We propose a new causal model for event sequences based on a one-to-one matching of individual
events, where we model the process of one individual event of a certain type possibly causing an
◦Equal contribution
•This work was done while at CISPA Helmholtz Center for Information Security
38th Conference on Neural Information Processing Systems (NeurIPS 2024).individual event of another type. In our model, we take into account the uncertainty of whether an
event is actually caused or independently generated, the uncertainty of an event actually causing
an effect or failing to do so, and the uncertainty of the delay between cause and effect. As we will
show, our model has several advantages, such as a clear notion of what event caused another and the
identifiability for both instant and non-instant effects.
We base our theory on the Algorithmic Markov Condition (AMC) [ 6], which postulates that the
true causal model achieves the lowest Kolmogorov complexity. As Kolmogorov complexity is not
computable, we instantiate it via the Minimum Description Length (MDL) principle [ 7]. We show
that our score is consistent, identifies the true causal direction for both instantaneous and delayed
effects, and formally connect it to Hawkes processes. To discover causal networks in practice,
we introduce the CASCADE algorithm, which adds edges in topological order. Through extensive
empirical evaluation, we show that CASCADE performs well in practice and outperforms the state of
the art by a wide margin. On synthetic data, CASCADE recovers the ground truth without reporting
spurious edges, and on real-world data, it returns graphs that correspond to existing knowledge.
2 Preliminaries
We write i→jwhen Siis a cause of Sjand pa(j)for the set of parents of node j. We assume
faithfulness, sufficiency, and the causal Markov condition [8].
Information-Theoretic Causal Discovery The Algorithmic Markov Condition (AMC) postulates
that the factorization of the joint distribution according to the true causal network achieves the lowest
Kolmogorov complexity [ 6]. The Kolmogorov complexity K(x)of a binary string xis the length
of the shortest program pfor a universal Turing machine Uthat computes xand halts [ 9]. For a
distribution P, it is the length of the shortest program that uniformly approximates Parbitrarily well,
K(P) = min
p∈0,1∗{|p|:∀y|U(p, y, q )−P(y)| ≤1
q}.
The AMC states that the Kolmogorov complexity of the joint distribution P(X)is the sum of the
complexities of the conditional distributions P(Xi|pa(i))of the true DAG G∗, i.e.
K(P(X)) =pX
i=1K(P(Xi|pa(i))),
up to a constant independent of the input. Due to, among others, the halting problem, Kolmogorov
complexity is not computable, but we can approximate it from above. A statistically well-founded
way to do so is by Minimum Description Length (MDL) [ 7,10]. For a fixed class of models H, MDL
identifies a description length Lof encoding data Xtogether with its optimal model,
L(X| H) = min
h∈H(L(X|h) +L(h)).
Next, we introduce the assumed data generating process, its corresponding model class Hand
encoding length function L, and show under which conditions it can be identified.
3 Theory
Si:
Sj:0.2 0.3 Nj ∞∞ ∞
Figure 1: Cause-effect matching, where
Sicauses Sj.To be able to infer causal relationships from observational
data, we need to make assumptions about the underlying
data-generating process [ 5]. The key assumption we make
here is that an individual event of type iat time twith
probability αi,jcauses an individual event of type jat
timet′≥t. To illustrate, we give a toy example in Fig. 1
in which event sequence Sicauses event sequence Sj. The
individual events in Sioccur uniformly at random. The
first and third events in Sicause events in Sj, resp. with
a delay of 0.2 and 0.3. The other two events in Sido not
cause events in Sj, denoted by a delay of ∞. The final
event in Sjis due to noise, marked by Nj.
2Next, we formally describe the causal mechanism. We differentiate between source and effect nodes.
Source nodes are nodes iinG∗with an empty parent set pa(i). For source nodes iwe assume that
the events in Sioccur uniformly at random with a rate of λievents per time unit. This mechanism,
commonly known as a homogeneous Poisson process , is used, for example, as a model for accident
rates requiring hospital admission [ 11]. In this work, we focus on the delay times between individual
events, denoted as dkfor the delay tk−tk−1and as ∆i→i={dk}ni
k=1for the sequence. For a
Poisson process, the delay times are independently and exponentially distributed. Thus, we model a
source event sequence Sias
Si={tk}ni
k=1,where tk=kX
l=1dl,∆i→i={dk∼Exp(λi)iid}ni
k=1. (1)
Effect nodes are nodes jinG∗with at least one parent pa(j). For each effect node j, the individual
events in Sjare either caused by an individual event in an Siwithi∈pa(j)or due to noise. That
is, reasoning from the causing node i, every event tk∈Simay trigger an event of the effect Sj
with a probability of αi,j. If triggered, an individual event in Sjwill occur after a random delay dk,
drawn from a cause-effect specific delay distribution Φi,jparameterized by θi,j, e.g. the rate λof
an exponential distribution, and αi,j. If no event is triggered, then we model the delay as infinite,
i.e.dk=∞. The sequence of delays ∆i→jfrom Si→Sjis modeled as
∆i→j={dk}ni
k=1, d k∼Φi,j(αi,j, θi,j)iid , ϕ i,j(d) =1−αi,j ifd=∞
p(d;θi,j)·αi,j else
(2)
where ϕi,j(d)denotes the density of the delay distribution. Thus, given the event sequence Siof the
cause and delays ∆i→j, the individual events in Sjcaused by Siare obtained by adding the delays
dkto the time stamps tkof the individual cause events, with the reconstruction function fas
fi,j(Si,∆i→j) ={tk+dk|dk̸=∞},fork= 1, . . . , n i.
In addition, individual events in Sjcan also be due to noise. Like for source nodes, we assume these
a Poisson process as per Eq. (1)with rate λj, i.e.Nj∼Poisson (λj). Putting this together, given
causal structure G∗, an effect event sequence Sjis generated by taking the union of the individual
delays from the causal parents pa(j)and the time stamps due to noise Nj,
Sj=
[
i∈pa(j)fi,j(Si,∆i→j)
∪Nj. (3)
Next, we instantiate an MDL score for this causal model and consider its identifiability.
3.1 Minimum Description Length Instantiation
We now develop a score for our causal model using MDL [ 7]. It consists of the cost of the data given
the model, L(S|Θ), i.e. the negative log-likelihood of the data, and the cost of the model, i.e. that of
the parameters, L(Θ), and that of the graph, L(G), all measured in bits.
Data Cost The cost of data in bits directly corresponds to its negative log-likelihood, i.e. the
likelihood of each delay as per Eq. (2)over all the event sequences corresponding to the parents of
node jand that of the noise events. Formally, we have
L 
Sj|Spa(j),Θ
=X
i∈pa(j)X
dk∈∆i→j−log(ϕi,j(dk)) +X
dl∈∆j→j−log (ϕj,j(dl)).
The first term encodes those events that were caused by the parent Sithrough the delays ∆i→j. Here,
we use a Shannon-optimal coding that requires −log(ϕi,j(dk))bits per sample [ 7]. In the second
term, we encode all remaining events as noise using the delay distribution of a Poisson process. For
source events, i.e. variables without any parents, only the noise term is present.
The cost of all sequences is then simply L(S|G,Θ) =P
j∈[p]L(Sj|Spa(j),Θ).
3Parameter Cost Next, we define the costs of the DAG, L(G), and that of the parameters, L(Θ). We
encode the DAG in topological order. Per node we encode its number of parents |pa(i)|and identify
which those are, i.e. L(G) =Pd−1
k=0
log(k) + log k
|pa(i)|
. Depending on their type, we encode
the parameters θ∈Θ. For parameters θ∈Nwe use LN, the MDL-optimal encoding for integers [ 12].
It is defined as LN(z) = log∗z+ log c0where log∗zis the expansion, logz+ log log z+···in
which we only include positive terms. To ensure this is a valid encoding, i.e. one that satisfies the
Kraft inequality, we set c0= 2.865064 [12]. For parameters θ∈Rwe use LR(θ) =LN(d)+LN(⌈θ·
10d⌉) + 1 as the number of bits needed to encode a real number up to a user-specified precision [ 7].
For an edge i→j, the parameters are the trigger probability αi,jand those of the delay distribution
ϕ. For the cost of an edge we hence have L(i→j) =LR(αi,j) +P
θ∈ϕi,jL(θ). For Θas a whole,
we have L(Θ) =P
i→j∈GL(i→j).
The overall MDL score is then
L(S|G,Θ) + L(G) +L(Θ).
3.2 Identifiability
We now study the identifiability guarantees of our model and score, i.e. under what conditions we can
identify from a given pair which is the cause and which the effect. Consider a pair of event sequences
SiandSj, where Si→Sjand the cause Siis a source event while Sjis an effect event.
Instant Effects We begin with the case of instant effects only. Instant effects are observed when the
sampling frequency of the data, e.g. a daily time scale, is insufficient to pick up a difference in time,
such as a financial crash that can spread across the globe within hours. It is well-known that Granger
causality cannot identify the causal direction for instant effects [ 13]. In Pearl’s causal framework,
on the other hand, the causal direction between two binary variables is identifiable [ 14–16]. We can
build upon these results and show that our causal model and MDL-based score can identify the causal
direction for non-deterministic instant effects.
Theorem 1. LetSibe an event sequence generated by a Poisson process as per Eq. (1)andSjbe an
effect of Sias per Eq. (3), with, low noise λj<(1−αi,j)λi, and a trigger probability αi,j<1.
In the case of exclusively instant effects, i.e. ϕi,j(d) =δ(d), where δ(d)is the Dirac delta function,
the MDL score in the true causal direction is lower than in the anti-causal direction, i.e.
lim
ni→∞L(Sj|Si,Θ1) +L(Si|Θ1)< L(Si|Sj,Θ2) +L(Sj|Θ2).
We provide the full proof in the Appx. A.1, the general idea is under a non-deterministic trigger
mechanism, i.e. αi,j<1. Then, in the causal direction, we can fully explain SjwithSi, but not
vice-versa, as the cause is generated by a Poisson process. If αi,j= 1, i.e. the process is deterministic,
we always observe cause and effect together, making them indistinguishable.
Delayed Effects Next, we consider the case of exclusively delayed effects. Here, there is an
inherent asymmetry in the benefit of knowing the cause versus the effect. As shown by Didelez [17]
for marked point processes, and later used by Xu et al. [1], Eichler et al. [18] for Granger causality in
Hawkes processes, the intensity of observing the cause after an event of the effect is unchanged. That
is, the future of the cause is independent of the past of the effect, while if a cause triggers an effect,
the intensity of the effect is increased by the cause. We have the following identifiability guarantee.
Theorem 2. LetSibe an event sequence generated by a Poisson process as per Eq. (1)andSjbe an
effect of Sias per Eq. (3), such that H(ϕj,j)> H(p(;θi,j)) +α−1
i,jH(B(αi,j)) +α−1
j,jH(B(αj,j)),
where Hdenotes the entropy and Bthe Bernoulli distribution.
Then the matching in the anti-causal direction ∆j→iof the effect Sjto the cause Sihas a worse
MDL score than the true matching ∆i→j, i.e.
L(Sj|Si,Θi→j) +L(Si|Θi)< L(Si|Sj,Θj→i) +L(Sj|Θj).
We provide the full proof in the Appx. A.2. In the anti-causal direction Sj→Si, the delay times
follow the same exponential distribution of Exp(λi), leading to no gain in score compared to the
4self-delay encoding. On the other hand, in the true causal direction, knowing the times of the cause
leads to a better knowledge of the delay and hence a lower cost, so long as the delay distribution
ϕi,jprovides a better description than treating it as noise. This requirement is closely related to the
algorithmic Markov condition, which postulates that the shortest description of a variable is given
through its parents.
3.3 Connection to Hawkes Processes
Hawkes processes [ 19] are analytically convenient and well-suited for modeling real-world processes
where events trigger further events, e.g. earthquakes triggering aftershocks. Consequently, the
majority of methods focusing on Granger causality are based on Hawkes processes [ 1–3]. The
Hawkes process extends the Poisson process by incorporating the influence of past events on the
intensity, i.e. the rate of occurrence of future events. This is done by means of excitation functions
vi,j(t−tk), which increase/inhibit the intensity of future events based on past events. The intensity
function of a Hawkes process under a DAG structure is given by
λj(t) =uj+X
i∈pa(j)X
tk<t,tk∈Sivi,j(t−tk).
Each event tk∈Siincreases the intensity of seeing an effect by vi,j(t−tk). The main difference
between our model and a Hawkes process is our direct trigger model from cause to effect. In a Hawkes
process, an event of type iincreases the intensity and, therewith, the probability of effect events
occurring. That is, contrary to our framework, in a Hawkes process there is no explicit one-to-one
relationship between causing and effect events, i.e. no one event can be attributed solely to causing
another. Nonetheless, in Appendix A.5 we show how to identify Sias a parent of Sjby constructing
a sequence of delays ∆i→jwith the most-influential past event and therewith ϕi,j. Ifϕi,jfulfills
Theorem 2, we can identify Sias a parent of Sj. Hence, should the data be generated by a Hawkes
process, our method can still pick up the causal relationship between the two event classes, so long as
there are sufficiently many events where Siis the primary cause.
4 Algorithm
With our model in place, we now turn to the problem of discovering the underlying causal structure
from an observed sequence of events. In recent years, several methods that find and proceed on
a topological ordering of the true graph have been introduced [ 20–22], which outperform other
score-based frameworks such as GES [ 23] in terms of accuracy. We here propose the CASCADE
algorithm that instantiates this idea for information-theoretic scores. We prove that in the limit, it
recovers not only the correct topological ordering but also the correct parent set of each node.
CASCADE derives its guarantees from the gain in bits of adding an edge i→jto the model, i.e.
g(i→j|Θ) = L(Sj|Spa(j),Θ)−L(Sj|Spa(j)∪i,Θ∪θi,j) +L(i→j).
The edge cost L(i→j)is constant and independent of the number of samples ni. In the limit
ni→ ∞ , the gain inherits the identifiability guarantees from Sec. 3.2, such that g(i→j|Θ)>
g(j→i|Θ)ifSiis a true ancestor of Sj. In other words, the gain of an edge is greater in the causal
than in the anti-causal direction.
4.1 High Level Overview
CASCADE initializes the model Θwith an empty graph Gand without any causal edges. During the
search, we maintain a set of nodes C= [p], from which we remove nodes in a topological order of
G∗. We iterate over the following four steps until Cis empty.
1.Source Node Selection : Select that node i∈Cwith minimal gain for any edge j→i,
j∈C, i.e.
arg min
i∈Cmax
j∈Cg(j→i|Θ)−g(i→j|Θ). (4)
2.Edge Adding : Add all outgoing edges from i→j,j∈C, toGthatimprove our score.
3.Edge Pruning : Remove all incoming edges j→ifrom Gthat harm our score.
54.Node Set Update Remove ifrom C.
Each iteration, CASCADE selects that node i, which has the minimal achievable gain when adding
any edge j→ito the current graph G, expressed in Eq. (4); below, we will show that under our
causal model this node is guaranteed to be a true source of the graph G∗. We then add all edges from
ito nodes j∈Cthat improve our score; provided that all true causal edges i→jwere added, there
is now at least one node j∈Cwhose parents are all accounted for, that in the next iteration can
be identified as a source. We remove edges j→ifrom Gto remove shortcuts. By repeating this
process, CASCADE proceeds in a topological order of the true graph G∗. In total, CASCADE requires
piterations, leading to an overall cubic complexity O(p3).
Source Node Selection. To identify a source node in the graph, we can use the identifiability
guarantees from Sec. 3.2. They show that the gain g(i→j|Θ)correctly orients the edge i→jin
the unconfounded bi-variate case. We additionally require that the edge gain is pathwise oracle , i.e. it
can identify the direction of the path from itok.
Theorem 3. Given an event sequence Sgenerated by a causal structure G∗, letSibe a source node
ofG∗andSvbe a descendant of Si, where there exists a path i→j→ ··· → vinG∗.
Then, the gain in the causal direction of the path g(i→v|Θ)−g(v→i|Θ)is greater.
We provide the proof in Appx. A.3. We can now show that the criterion in Eq. (4)selects nodes in
a topological ordering of G∗. Initially, CASCADE has to identify a true source of G∗, i.e. a node i
without parents. For that node i, all other nodes jare either ancestors or independent of i. Ifiis an
ancestor of j, then g(j→i|Θ)−g(i→j|Θ)<0, i.e. the gain in the anti-causal direction is
lower. If iis independent of j, then g(j→i|Θ) = 0 andg(i→j|Θ) = 0 . Hence, the maximum
achievable gain for a node without parents is zero.
Now consider a node vwhich does have a parent. For this node, there exists an ancestor uwhich is a
true source. Hence, for that pair g(u→v|Θ)−g(v→u|Θ)>0. Consequently, the maximum
achievable gain is positive, whilst for a source node, we can maximally achieve zero, allowing us to
identify true sources with Eq. (4).
In the next step, we add all outgoing edges from the source itoGthat improve the score. As G∗is a
DAG, we are now guaranteed to have another node j, whose incoming edges are all accounted for in
G. Then, as per the causal model from Eq. (3), the only events that remain are those of the noise Nj.
Hence, jis now a source node for which the guarantees from above apply. By repeating this process,
CASCADE thus follows a topological order of G∗.
Edge Addition Given a source i,CASCADE adds all outgoing edges i→jthat improve the
score. We restrict the set to nodes j∈Cfrom the candidate set only, i.e. to nodes further down
the topological order. By the Algorithm Markov Condition, the description length of the true set of
parents of a node jis smaller than the description length of any other set of parents, and hence the
gain of the true edge is positive in the limit of ni→ ∞ .
When adding an edge i→j, where there is already an edge v→j, we use an Expectation
Maximization approach to attribute all events to their respective cause. That is, we first find the
bi-variate alignment ∆i→jusing all events in Sj. Now, it is very likely that there are conflicts between
∆i→jand∆v→j, as the same event can be attributed to both iandv. In those cases, we choose that
event where the density ϕi,j/ϕv,jis higher and set the delay to infinity in the other matching. After
re-assigning all events, we refit the delay distribution function ϕi,jusing the new matching.
i j v
Figure 2: Causal chainEdge Pruning Lastly, we deal with removing any shortcuts that
have been added in the previous iteration. With the previous two
steps, we are guaranteed to have a superset of all true causal edges
incoming to i. Fortunately, we can prune such edges directly with
MDL by removing any incoming edge i→jthat does not improve
the MDL score. In the chain graph i→j→v, we would remove
i→vas the edge j→vis sufficient to explain the data. In practice,
given the current set of parents of iinG, we search for the true set
of parents by starting with the empty set and greedily adding only those edges that improve the score.
As we show in Appx. A.3, a shortcut always has a lower gain than the true edge and hence will not be
6re-added. In this manner, we are asymptotically left with only the true causal parents. We can now
finally show the consistency of C ASCADE .
Theorem 4. Given an event sequence S, where each individual subsequence Siwas generated as
per Eq. (3)by an underlying causal graph G∗. Assuming all ∆i→jare the true causal matchings.
Under the Algorithmic Markov Condition, CASCADE recovers the true graph G∗forn→ ∞ .
We postpone the proof to Appx. A.7. In the experiment section, we show that CASCADE recovers the
true DAG even in challenging settings and works well on real-world data.
5 Related Work
Causal discovery on observational data is an active research topic. Two main research directions
exist: constraint-based [ 5] and score-based [ 23,24] methods. Our approach belongs to the latter and
is based on the Algorithmic Markov Condition [ 6]. While Kolmogorov complexity is uncomputable,
Marx and Vreeken [10] formally showed that if we instantiate the AMC with two-part MDL [ 7],
we, on expectation, achieve the same results. MDL has been successfully used for bivariate causal
inference [ 25,15,26], causal discovery [ 27], identifying hidden confounding [ 28], identifying
mechanisms shifts [29], and identifying selection bias [30].
In this paper, we consider point processes. Particularly close to our method are Hawkes processes
[31] as a way to model the influence of past events onto future events. As such, our work is also
related to the concept of transfer entropy [ 32], which measures the influence in terms of Shannon
entropy. Budhathoki and Vreeken [33] proposed an MDL-based method for bivariate causal inference
on event sequences, which is unsuitable for learning a global causal structure.
Existing methods for discovering causal graphs from event sequence data focus on different instan-
tiations of Granger causality and can mostly be categorized by different intensity functions. Most
common are parametric approaches with different regularizing [ 34,2,1]. ADM4 [ 34] uses the nuclear
matrix norm in combination with lasso, THP [2] uses BIC for regularization. The method MDLH
by Jalaldoust et al. [3]is most closely related, as they also use MDL for regularization. NPHC [ 35]
takes a non-parametric approach by using a moment matching method to fit second and third-order
integrated cumulants. A recent development is neural point processes. Mei and Eisner [36] propose a
deep neural network that learns the dependencies [ 36], which Xiao et al. [37] extended to include
attention mechanisms. Zhang et al. [38] first learn a neural point process and then use a feature
importance attribution method to obtain a weight matrix of pairwise variable influence.
6 Experiments
We evaluate C ASCADE on both synthetic and real-world data. C ASCADE is implemented in Python.
We provide the source code, along with the synthetic data generator and the used real-world datasets
online.3We compare our method to four of state of the art methods: THP [2] as representative for the
regularized parametric approaches, CAUSE [38] as representative for the neural point processes and
NPHC [ 35] as a representative non-parametric approach, and MDLH [ 39] who also rely on MDL, as
our most closely related competitor. CAUSE andNPHC do not return a graph but rather a weight
matrix where the weight indicates the strength of the causal relation. On synthetic data, we can obtain
a graph by thresholding such that we optimize the F1score.
6.1 Evaluation
We evaluate the estimated graphs in terms of structural similarity by the Structural Hamming Distance
(SHD) [ 40], in terms of causal similarity by the Structural Intervention Distance (SID) [ 41], and
predictive performance by F1 score. To compare graphs of different sizes, we report the scores
normalized by the maximally achievable SHD/SID and show the unnormalized scores in Appendix B.
NPHC ,CAUSE , and MDLH can and often do return cyclic graphs. As SID is strictly only defined
for acyclic graphs, we omit these methods from the SID evaluation.
3https://eda.rg.cispa.io/prj/cascade/
75 10 15 20 30 4000.10.20.30.40.5SHD
5 10 15 20 30 4000.20.40.60.81SID
5 10 15 20 30 4000.20.40.60.81
# Event TypesF1(a)
0.9 0.8 0.7 0.6 0.500.10.20.3SHD
0.9 0.8 0.7 0.6 0.500.20.40.6SID
0.9 0.8 0.7 0.6 0.500.20.40.60.81
Noise level aF1 (b)
506070809010015020000.0010.0020.003 SHDMDLH THP CAUSE
NPHC CASCADE
50607080901001502000.0001.0002.0003.0004 SID
506070809010015020000.20.40.60.81
# Event TypesF1 (c)
Figure 3: DAG recovery in different settings. We show normalized SHD, normalized SID, and F1
score, the Y-axis are truncated for better visualization. In (a) we vary the number of event types, on
the SID score we observe that the graph reported by CASCADE is casually, the most similar to the
true DAG. In (b) we decrease the noise, CASCADE does recover a close causal graph, even under
high noise. Finally, in (c) we increase the number of parents of a collider, we observe that a high
number of parents does not pose a problem for C ASCADE .
6.2 Synthetic Data
We begin by comparing all methods on data with known ground truth. To this end, we generate
synthetic data. We generate both data within and outside our causal model and vary aspects such as
noise intensity, number of event types and the number of parents of a variable. We describe the full
data-generating process in Appendix B.
Sanity Check We start with a sanity check on data without any structure over 20 variables,
CASCADE correctly does not report any causal edge. THP reports in 45% of the cases at least one
spurious edge. We omit the results of CAUSE andNPHC as it is unclear how to choose a meaningful,
non-trivial threshold, in this setting. MDLH did not terminate within 96 hours.
Scalability We evaluate how well each method scales under an increasing number of variables. We
vary the number of nodes, which correspond to the number of unique event types, from 5 to 50 and
report the results in Fig. 3a. As MDLH did not terminate within 96 hours for 15 variables, we omit it
from here on out. For a lower number of nodes, both CASCADE andTHP obtain far better results
than NPHC andCAUSE . With increasing event types, all methods SID and F1 scores decrease.
Amongst all methods, CASCADE scales best with an increasing number of nodes, whereas Granger
causality based methods such as THP andNPHC find many spurious edges of connected but not
causal variables. On the other hand, CASCADE is the most accurate method for a higher number of
nodes, showing the efficacy of its causal model and MDL-based approach.
Noise Next, we assess the impact of noise, which are events that is not caused by any parent. To
this end, we vary the ‘cause’ probability and the fraction of events due to additive noise. We do so by
varying a noise parameter a, adding an additional ni·aevents to Si(additive noise), and by setting
the ‘cause’ probability α= 1−a, i.e. we decrease additive noise and increase trigger probability.
We show the results in Fig. 3b. We observe that CASCADE does quite well for high noise and that
for noise levels of a= 0.7and lower, it (mostly) recovers the true DAG. All other methods perform
considerably worse.
8Colliders Matching an effect event to the correct parent, resp. modeling the correct excitation,
becomes increasingly challenging for a larger number of parents. We test this through a setting where
half (⌈p−1
2⌉) the variables converge into a collider, and the other half ( ⌊p−1
2⌋) are independent. We
vary the total number of variables, pand we show the results in Fig. 3c. We observe that CASCADE
achieves almost perfect results. THP is robust, but with an increasing number of nodes, it starts
to miss edges. Beyond 100 variables, it does not terminate within 24 hours. To validate that our
method can recover structures with multiple colliders, we repeat the same experiment where 10% of
nodes are colliders. That is, for 50 event types, 5 are colliders and 23 direct causes of all 5 colliders.
The remaining 22 are independent. Resulting in an F1score of 0.97 for 50 event types, slightly
decreasing to 0.82 for 200 event types; as such C ASCADE can deal well with multiple colliders.
Instantaneous Effects Next, we evaluate performance under instantaneous effects. First, we
consider data with exclusively instant effects. CASCADE achieves an average unnormalized SHD of
32.8. The second best-performing method, NPHC , achieves 46.85. Next, we generate a setting where
90% of the effects are instantaneous and the others occur with a small delay. CASCADE improves to
an SHD of 19.45, while NPHC achieves the second lowest average with 47.5. We provide all results
in the Appendix B.
0.40.71.01.31.61.92.22.52.83.100.51
Expected Events per CauseF1
Figure 4: DAG recovery on data gener-
ated by a Hawkes process.Hawkes Processes Finally, we evaluate how effectively
CASCADE recovers the true DAG on data generated by a
Hawkes process. We vary the intensity of the excitation
function, i.e., the expected number of events generated
per cause. We show the results in Figure 4. We observe
thatCASCADE performs best when our assumptions hold,
when there is one effect per cause or fewer, but still demon-
strates strong performance across all settings.
6.3 Real-World Data
We evaluate CASCADE on three distinct datasets of real-world event sequences. We begin by
evaluating C ASCADE on a dataset of network alarms, where the causal structure is known.
Network Alarms This data was provided by Huawei for the NeurIPS 2023 CSL-competition4and
consists of data from a simulated network of devices in which alarms can cause other alarms. We run
all methods and get an (unnormalized) SHD score of 42 for CASCADE , 127 for THP , 214 for NPHC ,
and 1564 for CAUSE . As the network connectivity structure is known, we can take it into account
during the search. THP supports this natively, CASCADE can be trivially constrained to only consider
the given edges. CASCADE correctly identifies 142 out of 147 causal edges, THP 20. Neither method
reports spurious edges. We show the full recovered graph in Appendix B.5.
Global Banks Second, we run CASCADE on a daily return volatility dataset [ 42], we follow the
preprocessing of Jalaldoust et al. [39], specifically we turn the time series into an event sequence by
rolling a one year window over the data and register an event if the last value is among the top 10%.
The dataset includes the 96 world’s largest publicly traded banks. We show the largest discovered
subgraph in Fig. 5. In addition, three unconnected sub-graphs are discovered, one covering two banks
in Australia and two others connecting banks in Japan, which we provide in Appendix B.5.
Daily Activities We run CASCADE on a dataset of recorded daily activities [ 43]. Our method
reports plausible causal connections such as Sleeping End →Showering Start →Showering End →
Breakfast Start →Breakfast End , etc. We show the complete graph in the Appendix B.5. This result
reinforces the suitability of our causal model and CASCADE for real-world data, and illustrates the
potential of our method to discover causal structures in a wide range of applications.
7 Conclusion
We studied the problem of causal discovery from event sequences, we propose a cause-effect matching
approach to learn a fully directed acyclic graph (DAG). To this end, we introduced a new causal model
4https://github.com/huawei-noah/trustworthyAI/tree/master/competition/NeurIPS2023/sample
9HSBC
BNP
Paribas
BarclaysRBSSantander GoldmanSachsIntesa
SanpaoloBBV A PohjolaBank
JPMorgan
Chase & CoDeutsche
BankCredit
Agricole
SocGen
ING
LloydsCredit
Suisse
Nordea
Commerzbank
Danske
Svenska
Handelsbanken
SEBKBC
SwedbankFifth Third
Erste
Group BankUBS
Bank of
AmericaCitigroupWells
Fargo
Morgan
Stanely
TD BankStandard
Chartered
CIBCBNYMellon
U.S.
Bancorp
PNC
Capital
One
State Street CorporationBB&T CorpNational
Bank of
Canada
SunTrust
American
ExpressDNB ASA
BMORegions
FinancialANZ
RBCBank ofNova ScotiaMalayan
Banking
BerhadAsia
Europe
AmericaAustralia
Top 10 BanksFigure 5: Result of CASCADE on the Global Banks dataset, we show the largest subgraph, we
highlight the 10 largest, by assets, banks. We clearly see CASCADE recovers locality and that larger
banks have a strong influence on the market, both information not provided in the input.
and an MDL based score. We proposed the CASCADE algorithm to discover causal graphs through a
topological search from observational data. Finally, we evaluated CASCADE on synthetic and realistic
data. On synthetic data, we find that CASCADE is either the best or close to the best-performing
method across all settings, both within and outside our causal model. In particular, whenever
conditions get challenging, e.g. due to noise or with multiple colliders, CASCADE outperforms all
other methods by a significant margin. We examined how CASCADE performs on real world event
sequences, where the true data-generating process may lie outside our causal model. We found that
CASCADE recovers meaningful graphs that match with a common understanding of the world.
Limitations As is necessary, we have to make causal assumptions. The most prominent in our work is
the direct matching between a cause event and an effect event – which precludes modeling of a single
event causing multiple other events, as well as multiple events jointly causing a single effect event –
and that we only consider excitatory effects – which precludes modeling the absence of events due to
a cause. Our proof of identifiability for instantaneous effects depends on the strengths of the trigger
resp. noise probabilities. The identifiability of the model seems provable via the independence of
these, but how to operationalize this into an effective score and search algorithm are open questions.
Future Work Currently, our structural equations are ‘or‘ relations over the parent‘s variables. An
interesting future direction would be to explore ‘and‘ relations, e.g., A and B together cause C.
This raises several questions, like how close to each other A and B have to occur or if the order
matters. Another interesting future direction is to allow matching of multiple causing events to one
event, where each parent could have caused the event. This would allow us to answer counterfactual
questions, such as if a causing event had not occurred, would we nevertheless observe its effect? This
strongly relates to the firing squad example by Pearl [5], where multiple guards shoot a prisoner at
the same time; if one guard did not shoot, the prisoner would still have died.
10References
[1]Hongteng Xu, Mehrdad Farajtabar, and Hongyuan Zha. Learning granger causality for hawkes
processes. In International conference on machine learning , pages 1717–1726. PMLR, 2016.
[2]Ruichu Cai, Siyu Wu, Jie Qiao, Zhifeng Hao, Keli Zhang, and Xi Zhang. Thps: Topological
hawkes processes for learning causal structure on event sequences. IEEE Transactions on
Neural Networks and Learning Systems , 2022.
[3] Amirkasra Jalaldoust, Kate ˇrina Hlavá ˇcková-Schindler, and Claudia Plant. Causal discovery in
hawkes processes by minimum description length. In Proceedings of the AAAI Conference on
Artificial Intelligence , volume 36, pages 6978–6987, 2022.
[4]Clive WJ Granger. Investigating causal relations by econometric models and cross-spectral
methods. Econometrica: journal of the Econometric Society , pages 424–438, 1969.
[5]Judea Pearl. Causality: Models, Reasoning and Inference . Cambridge University Press, 2nd
edition, 2009.
[6]Dominik Janzing and Bernhard Schölkopf. Causal inference using the algorithmic markov
condition. IEEE Transactions on Information Theory , 56(10):5168–5194, 2010.
[7] Peter Grünwald. The Minimum Description Length Principle . MIT Press, 2007.
[8]Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques .
MIT press, 2009.
[9]Ming Li, Paul Vitányi, et al. An introduction to Kolmogorov complexity and its applications ,
volume 3. Springer, 2008.
[10] Alexander Marx and Jilles Vreeken. Formally justifying mdl-based inference of cause and
effect. In AAAI Workshop on Information-Theoretic Causal Inference and Discovery (ITCI’22) ,
2022.
[11] Donald C Weber. Accident rate potential: An application of multiple regression analysis of a
poisson process. Journal of the American Statistical Association , 66(334):285–288, 1971.
[12] Jorma Rissanen. A universal prior for integers and estimation by minimum description length.
11(2):416–431, 1983.
[13] Jonas Peters, Dominik Janzing, and Bernhard Schlkopf. Elements of Causal Inference: Founda-
tions and Learning Algorithms . The MIT Press, 2017. ISBN 0262037319.
[14] Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. Causal inference on discrete data
using additive noise models. IEEE Transactions on Pattern Analysis and Machine Intelligence ,
33(12):2436–2450, 2011.
[15] Kailash Budhathoki and Jilles Vreeken. Accurate causal inference on discrete data. In Proceed-
ings of the IEEE International Conference on Data Mining (ICDM’18) . IEEE, 2018.
[16] Murat Kocaoglu, Alexandros Dimakis, Sriram Vishwanath, and Babak Hassibi. Entropic causal
inference. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 31, 2017.
[17] Vanessa Didelez. Graphical models for marked point processes based on local independence.
Journal of the Royal Statistical Society Series B: Statistical Methodology , 70(1):245–264, 2008.
[18] Michael Eichler, Rainer Dahlhaus, and Johannes Dueck. Graphical modeling for multivariate
hawkes processes with nonparametric link functions. Journal of Time Series Analysis , 38(2):
225–242, 2017.
[19] Alan G Hawkes. Spectra of some self-exciting and mutually exciting point processes.
Biometrika , 58(1):83–90, 1971.
[20] Peter Bühlmann, Jonas Peters, and Jan Ernest. Cam: Causal additive models, high-dimensional
order search and penalized regression. The Annals of Statistics , 42(6):2526–2556, 2014.
11[21] Paul Rolland, V olkan Cevher, Matthäus Kleindessner, Chris Russell, Dominik Janzing, Bernhard
Schölkopf, and Francesco Locatello. Score matching enables causal discovery of nonlinear
additive noise models. In International Conference on Machine Learning , pages 18741–18753.
PMLR, 2022.
[22] Spencer Compton, Kristjan Greenewald, Dmitriy A Katz, and Murat Kocaoglu. Entropic causal
inference: Graph identifiability. In International Conference on Machine Learning , pages
4311–4343. PMLR, 2022.
[23] David Maxwell Chickering. Optimal structure identification with greedy search. Journal of
machine learning research , 3(Nov):507–554, 2002.
[24] Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, and Clark Glymour. A million
variables and more: the fast greedy equivalence search algorithm for learning high-dimensional
graphical causal models, with an application to functional magnetic resonance images. Interna-
tional journal of data science and analytics , 3:121–129, 2017.
[25] Alexander Marx and Jilles Vreeken. Telling cause from effect using mdl-based local and global
regression. In 2017 IEEE international conference on data mining (ICDM) , pages 307–316.
IEEE, 2017.
[26] Sascha Xu, Osman Mian, Alexander Marx, and Jilles Vreeken. Inferring cause and effect in the
presence of heteroscedastic noise. In Proceedings of the International Conference on Machine
Learning (ICML) . PMLR, 2022.
[27] Osman A Mian, Alexander Marx, and Jilles Vreeken. Discovering fully oriented causal networks.
InProceedings of the AAAI Conference on Artificial Intelligence , volume 35, pages 8975–8982,
2021.
[28] David Kaltenpoth and Jilles Vreeken. Nonlinear causal discovery with latent confounders. In
Proceedings of the International Conference on Machine Learning (ICML) . PMLR, 2023.
[29] Sarah Mameche, David Kaltenpoth, and Jilles Vreeken. Learning causal models under indepen-
dent changes. In Proceedings of Neural Information Processing Systems (NeurIPS) . PMLR,
2023.
[30] David Kaltenpoth and Jilles Vreeken. Identifying selection bias from observational data. In
Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) . AAAI, 2023.
[31] Alan G Hawkes. Spectra of some self-exciting and mutually exciting point processes.
Biometrika , 58(1):83–90, 1971.
[32] Thomas Schreiber. Measuring information transfer. Physical review letters , 85(2):461, 2000.
[33] Kailash Budhathoki and Jilles Vreeken. Causal inference on event sequences. In Proceedings
of the 2018 SIAM International Conference on Data Mining , pages 55–63. SIAM, 2018.
[34] Ke Zhou, Hongyuan Zha, and Le Song. Learning social infectivity in sparse low-rank networks
using multi-dimensional hawkes processes. In Artificial Intelligence and Statistics , pages
641–649. PMLR, 2013.
[35] Massil Achab, Emmanuel Bacry, Stéphane Gaïffas, Iacopo Mastromatteo, and Jean-François
Muzy. Uncovering causality from multivariate hawkes integrated cumulants. Journal of Machine
Learning Research , 18(192):1–28, 2018.
[36] Hongyuan Mei and Jason M Eisner. The neural hawkes process: A neurally self-modulating
multivariate point process. Advances in neural information processing systems , 30, 2017.
[37] Shuai Xiao, Junchi Yan, Mehrdad Farajtabar, Le Song, Xiaokang Yang, and Hongyuan Zha.
Learning time series associated event sequences with recurrent point process networks. IEEE
transactions on neural networks and learning systems , 30(10):3124–3136, 2019.
[38] Wei Zhang, Thomas Panum, Somesh Jha, Prasad Chalasani, and David Page. Cause: Learning
granger causality from event sequences using attribution methods. In International Conference
on Machine Learning , pages 11235–11245. PMLR, 2020.
12[39] Amirkasra Jalaldoust, Kate ˇrina Hlavá ˇcková-Schindler, and Claudia Plant. Causal discovery in
hawkes processes by minimum description length. In Proceedings of the AAAI Conference on
Artificial Intelligence , volume 36, pages 6978–6987, 2022.
[40] Markus Kalisch and Peter Bühlman. Estimating high-dimensional directed acyclic graphs with
the pc-algorithm. Journal of Machine Learning Research , 8(3), 2007.
[41] Jonas Peters and Peter Bühlmann. Structural intervention distance for evaluating causal graphs.
Neural computation , 27(3):771–799, 2015.
[42] Mert Demirer, Francis X Diebold, Laura Liu, and Kamil Yilmaz. Estimating global bank
network connectedness. Journal of Applied Econometrics , 33(1):1–15, 2018.
[43] Fco Javier Ordónez, Paula De Toledo, and Araceli Sanchis. Activity recognition using hybrid
generative/discriminative models on home environments using binary sensors. Sensors , 13(5):
5460–5477, 2013.
[44] Dominique MA Haughton. On the choice of a model to fit data from an exponential family. The
annals of statistics , pages 342–355, 1988.
13A Theory
A.1 Proof - Identifiability on Instant Effects
Theorem 1. LetSibe an event sequence generated by a Poisson process as per Eq. (1)andSjbe an
effect of Sias per Eq. (3), with, low noise λj<(1−αi,j)λi, and a trigger probability αi,j<1.
In the case of exclusively instant effects, i.e. ϕi,j(d) =δ(d), where δ(d)is the Dirac delta function,
the MDL score in the true causal direction is lower than in the anti-causal direction, i.e.
lim
ni→∞L(Sj|Si,Θ1) +L(Si|Θ1)< L(Si|Sj,Θ2) +L(Sj|Θ2).
Proof. Letnibe the number of events in Siandnjthe number of events in Sj. Asni→ ∞
L(Si) =niH(ϕi,i), L (Sj|Si) =niH(B(αi,j))
where Bis the Bernoulli distribution. In the reverse direction, we have
L(Sj) =njH(ϕj,j), L (Si|Sj) =niH(B(αi,i)) + ( ni−nj)H(ϕi,i)
To show
L(Si) +L(Sj|Si)< L(Sj) +L(Si|Sj)
niH(ϕi,i) +niH(B(αi,j))< njH(ϕj,j) +niH(B(αi,i)) + ( ni−nj)H(ϕi,i)
αi,j=αi,isince every event that does not cause an i, can not be explain by j in the reverse direction,
hence
niH(ϕi,i) +((((((niH(B(αi,j))< njH(ϕj,j) +((((((niH(B(αi,i)) + ( ni−nj)H(ϕi,i)
niH(ϕi,i)< njH(ϕj,j) +niH(ϕi,i)−njH(ϕi,i)
niH(ϕi,i)< njH(ϕj,j) +niH(ϕi,i)−njH(ϕi,i)
njH(ϕi,i)< njH(ϕj,j)
H(ϕi,i)< H(ϕj,j)
ForH(ϕi,i)< H(ϕj,j)to hold ni> nj.
ni∝λi, n j∝αi,jλi+λj
λi> αi,jλi+λj
λi−αi,jλi> λj
(1−αi,j)λi> λj
It directly follows that H(ϕi,i)< H(ϕj,j), and hence for ni→ ∞
L(Sj|Si,Θ1) +L(Si|Θ1)< L(Si|Sj,Θ2) +L(Sj|Θ2).
A.2 Proof - Identifiability on Delayed Effects
Theorem 2. LetSibe an event sequence generated by a Poisson process as per Eq. (1)andSjbe an
effect of Sias per Eq. (3), such that H(ϕj,j)> H(p(;θi,j)) +α−1
i,jH(B(αi,j)) +α−1
j,jH(B(αj,j)),
where Hdenotes the entropy and Bthe Bernoulli distribution.
Then the matching in the anti-causal direction ∆j→iof the effect Sjto the cause Sihas a worse
MDL score than the true matching ∆i→j, i.e.
L(Sj|Si,Θi→j) +L(Si|Θi)< L(Si|Sj,Θj→i) +L(Sj|Θj).
14We will show that the delays between Siitself, i.e. ∆i→i, and the delays between SjtoSi, i.e.∆i→j,
are equivalent.
Proof. We consider a source event Siwith exponentially distributed delays, i.e. ∆i→i∼exp(λi).
Consider any event tk∈Sj, then the intensity of observing an event in Siat time t > t kis given
byλi. The distribution of the delay to the next event in Siis exponential with λ=λi. Thus, the
difference between
L(Si|Sj)−L(Si) =X
dk∈∆i→jlog(λi)−dk/λi−X
dl∈∆i→ilog(λi) +dl/λi= 0.
It remains to show that the likelihood in the causal direction is better when conditioning effect on the
cause, i.e. L(Sj|Si)< L(Sj).
Gain by i→jForito cause jit has to provide information about j, that is the cost of selecting
which ievents cause j, and with what dealys. Additional it has to ofset the cost which jevents do
not have to be encoded as a self delay. Formally this is,
niH(B(αi,j)) +ni,jH(p(;θi,j)) +njH(B(ni,j
nj))< ni,jH(ϕj,j),
where ni,jare the number of events in jcaused by i, and H(p(;θi,j))is the entropy of distribution
described by the pdf p.
Asn→ ∞ ,
L(Sj) =njH(ϕj,j) L(Sj|Si) =niH(ϕi,j) + (nj−ni,j)H(ϕj,j) +njH(B(αj,j))
To show,
L(Sj)> L(Sj|Si)
njH(ϕj,j)> niH(ϕi,j) + (nj−ni,j)H(ϕj,j) +njH(B(αj,j))
ni,jH(ϕj,j) +((((((((((nj−ni,j)H(ϕj,j)> niH(ϕi,j) +((((((((((nj−ni,j)H(ϕj,j) +njH(B(αj,j))
ni,jH(ϕj,j)> niH(ϕi,j) +njH(B(αj,j))
we can substitute niH(ϕi,j) =ni,jH(p(;θi,j)) +niH(B(αi,j))
ni,jH(ϕj,j)> ni,jH(p(;θi,j)) +niH(B(αi,j)) +njH(B(αj,j))
Now, note that the number of caused items αi,jni=ni,jandαj,jnj=ni,j, then it follows
ni,jH(ϕj,j)> ni,jH(p(;θi,j)) +ni,j
αi,jH(B(αi,j)) +ni,j
αj,jH(B(αj,j))
H(ϕj,j)> H(p(;θi,j)) +1
αi,jH(B(αi,j)) +1
αj,jH(B(αj,j))
Hence, we show that i→jis identifiable.
A.3 Proof - Path Identifiability
Theorem 3. Given an event sequence Sgenerated by a causal structure G∗, letSibe a source node
ofG∗andSvbe a descendant of Si, where there exists a path i→j→ ··· → vinG∗.
Then, the gain in the causal direction of the path g(i→v|Θ)−g(v→i|Θ)is greater.
Proof. We begin by proving that the path identifiability holds for a triplet of nodes i→j→v, by
constructing a new alignment from i→v.
From ∆i→jand∆j→vwe can construct ∆i→v. For each dk∈∆i→j, there is a corresponding
dl∈∆j→v, i.e. the trigger time of the triggered event. To construct ∆i→v, we consider the following
cases:
151. Ifdk=∞fordk∈∆i→j, then dk∈∆i→v, is set to dk=∞.
2.Letdl∈∆j→vbe the delay of event aof type jwhere ahas been caused by delay dk. If
dk̸=∞fordk∈∆i→janddl=∞then then dk∈∆i→v, is set to dk=∞.
3.Letdl∈∆j→vbe the delay of event aof type jwhere ahas been caused by delay dk. If
dk̸=∞fordk∈∆i→janddl̸=∞then then dk∈∆i→v, is set to dk=dk+dl.
As∆i→vis another valid alignment, and iremains a source node, the guarantees of Theorem 1 and 2
hold, i.e. the path is identifiable. This extends to a path of arbitrary length. Consider an additional
edgev→w, then we construct the alignment ∆i→wby considering the delays of ∆i→vand∆v→w.
Furthermore, we can show that the true path j→vhas a better gain than the shortcut i→v, so that we
can remove the shortcut in the pruning stage. (1) Since i→jandj→vare independent processes,
it follows either Var(ϕi,v)>Var(ϕj,v), orαi,v> αj,vand by that a more costly description of v.
(2) If j→v /∈G, we can construct a new function fi,v=fj,v(fi,j(Si,∆i→j)∪Nj,∆j→v)by
Theorem 2 it follows that edge i→vimproves our score.
(3) Assume j→v∈Gthen each individual vevent that is matched to by i→vis already matched
to by j→v, and from (1) we know it does so cheaper, hence we get no gain by adding the shortcut
i→v.
A.4 Consistency
Proof. Here we will show that L(Sn,Θ)asymptotically behaves like BIC.L(S,Θ)directly corre-
sponds to the log likelihood, which we rewrite as logp(Sn|Θ, G)Our approach can be instantiated
with arbitrary delay distribution, to show consistency we have to upper bound the number of param-
eters by O(logn), this trivially holds for the parametric setting we focus on in this paper, because
|pa(i)| ∈ O (logn)[27]. The encoding of the graph Gis independent of n, i.e. fixed for a given
network, hence in O(1). Finally this results at,
logp(Sn|Θ, G) +clogn+O(1)
we set c=d
2where dis the number of free parameters, arriving at the BIC score.
From Haughton [44] and Chickering [23] we know that BICidentifies a Markov equivalence class of
the true DAG. For the identifiability of undirected edges we refer to Theorem 1 and 2.
A.5 Connection to Hawkes Processes
The key difference between a linear Hawkes process and our model is the assumption of direct triggers,
that is the mechanism of one event and one event only causing another. In a linear Hawkes process
‘cause events’ increase the intensity and therewith the probability of events occurring. However, one
can generally not label for a specific event another as the ‘cause’, as each event is the result of a
multitude of causes.
In this section, we are going to explore under which conditions we can identify a Hawkes process
under our causal model.
Given an event sequence Sj={tk}nj
tk=0generated by a linear Hawkes process,
λj(t) =uj+X
i∈pa(j)X
tk<t,tk∈Sivi,j(t−tk).
We construct a set of primary causes for each event tk∈Sjas
Cj=(
(t, i, t k)|t∈Sj,(i, tk) = arg max
(i,tk), i∈pa(j),tk<t,tk∈Sjvi,j(t−tk))
,
where we consider as primary cause of an event that past event with the highest influence at time
point tfrom a causal parent i∈pa(j). Using these delays, we construct an alignment (mapping of
delays) as
16∆i→j={β(tk)|tk∈Si} β(tk) =t−tkifvi,j(t−tk)> uj
∞ else,
where t= arg maxt∈Sj∧∃(t,i,tk)∈Cjvi,j(t−tk)if∄(t, i, t k)∈Cjthenβ(tk) =∞. We consider
tk∈Sia cause of an event t∈Sjif it is the primary cause of tandtkhas no stronger influence on
any other event of Sj. Finally, the influence has to be stronger than that of the base intensity of Sj.
To be able to identify a causal edge between SiandSjthe improvement gained by this alignment
must outweigh the edge cost L(i→j). For this, there are two conditions: firstly, the number of
primary cause events from itoj, i.e. those instances where an event from Sihas the maximum
influence on an event from Sj, must be large enough. This is the case as long as |∆i→j|increases
withnj, i.e. the total number of events of Sj. Then, in the limit nj→ ∞ the number of primary
cause events is large enough to offset the constant edge cost.
The achievable score gain is obtained by constructing a delay distribution from |∆i→j|as
ϕi,j(d) =1−αi,j ifd=∞
p∆i→j(d)·αi,j elsewhere αi,j= 1−P(∆i→j=∞).
If this density ϕi,j(d)fulfills the conditions of Theorem 2, we can identify Sias a parent of Sjin the
limit of nj→ ∞ .
In conclusion, CASCADE can identify a causal pair generated under a Hawkes process, if there exist
sufficiently many events from Si→Sj, where vi,j(t)has the strongest influence on λj(t)for some
of the t. By aligning the delays of these events, we can identify the causal edge and recover the
underlying causal structure.
A.6 Empirical Evaluation
0.40.71.01.31.61.92.22.52.83.100.51
Expected Events per CauseF1
Figure 6: DAG recovery on data gener-
ated by a Hawkes process.[From main paper] To empirically evaluate how effectively
CASCADE recovers the true DAG on data generated by a
Hawkes process, we generate synthetic data using the tick
library5. We vary the intensity of the excitation function,
i.e., the expected number of events generated per cause.
We show the results in Figure 6. We observe that CAS-
CADE performs best when our assumptions hold, when
there is one effect per cause or fewer, but still demonstrates
strong performance across all settings.
A.7 Consistency of Algorithm
Theorem 4. Given an event sequence S, where each individual subsequence Siwas generated as
per Eq. (3)by an underlying causal graph G∗. Assuming all ∆i→jare the true causal matchings.
Under the Algorithmic Markov Condition, CASCADE recovers the true graph G∗forn→ ∞ .
Proof. We begin by proving that in the first step, CASCADE identifies a true source node of G∗. We
denote the parents of iin the true causal graph G∗aspa(i), whilst we write for the parents in the
graph maintained by C ASCADE aspa′(i, G).
Leti∈[p]be a node of G∗without parents, i.e. a source. By Theorem 3, for a path i→ ··· → v∈G∗
the gain in the causal direction g(i→v|Θ)is greater than the gain in the reverse direction
g(v→i|Θ).
For all nodes v∈[p], v̸=i,vis either an descendant of ior unrelated.
1.Ifvis a descendant of i, then the gain of g(i→v|Θ)is greater than the gain of
g(v→i|Θ).
2. Ifvis unrelated to i, then the gain in both sides is 0.
5https://x-datainitiative.github.io/tick/
17Hence it follows, that for a node iwhere pa(i) =∅,
max
j∈Cg(j→i|Θ)−g(i→j|Θ) = 0 .
On the other hand, consider a node iwith parents pa(i)̸=∅. Then, as G∗is a DAG, there exists an
ancestor vofi, where vis a source node, i.e. pa(v) =∅. For that v, it holds that the gain from vtoi
is greater than the gain from itov. Hence, for a node iwith parents, it holds that
max
j∈Cg(j→i|Θ)−g(i→j|Θ)>0.
Therefore, by taking the argmin over all nodes, C ASCADE identifies the true source node of G∗, i.e.
arg min
i∈Cmax
j∈Cg(j→i|Θ)−g(i→j|Θ) =⇒pa(i)∩C=∅.
Edge Addition Now, we show that CASCADE always identifies a true causal edge for ni→ ∞ .
First, note that given a source node i, there do not exist any incoming causal edges in the graph G∗,
pa(i)∩C=∅=⇒∄j∈C:j→i∈G∗.
Hence, by fitting outgoing edges only, we test all possible edges for iand never add a false oriented
edge,
∀j∈C:i→j∈G∗=⇒j→i /∈G .
Finally, we recall that the true causal graph G∗is the graph that minimizes the description length of
the data as per the Algorithm Markov Condition. Hence, adding a true causal edge to the graph will
result in a lower description length, i.e.
∀j∈C, i→j∈G∗:L(Sj|Spa′(j,G),Θ′)> L(Sj|Spa′(j,G)∪i,Θ′∪θi,j).
Edge Removal Consider the node i, where pa(i)∩C=∅, and given a graph Gwhere all true
causal edges have been added, i.e.
∀j∈¯C:∀j→v∈G∗:j→v∈G .
Then, for iit holds that
∀j∈pa(i) :i→j∈G .
It follows, that pa′(i, G)⊇pa(i). By the Algorithm Markov Condition, the shortest description
length of the data is achieved by the true causal graph G∗. Hence, a superset of the true parents of i
will result in a higher description length, and it holds that
L(Si|Spa′(i),Θ′)> L(Si|Spa(i),Θ).
Therefore, by testing that subset of the parents of iresults in a lower description length, CASCADE
identifies the true parents of i.
Overall Consistency Forni→ ∞ , we note that in each step for the node iit holds that
1.ihas no parents in the candidate set pa(i)∩C=∅.
2.We add no false oriented edges to the graph, as pa(i)∩C=∅=⇒∄j∈C:j→i∈G∗.
3.We add all true edges i→jto the graph G, i.e.∀j∈C, i→j∈G∗:
L(Sj|Spa′(j,G),Θ′)> L(Sj|Spa′(j,G)∪i,Θ′∪θi,j).
4.Fori, the current graph Gcontains a superset of all true parents, i.e. pa′(i, G)⊇pa(i),
while the description length of the data is minimized by the true graph L(Si|Spa′(i),Θ′)>
L(Si|Spa(i),Θ).
Hence, by repeating the edge addition and pruning in a topological order, in the limit of ni→ ∞
under our causal model and by the Algorithm Markov Condition, CASCADE identifies the true causal
graph G∗.
18B Experiments
In this section we provide additional detail on the synthetic data generation and the experiment setup.
Additional we provide further metrics on the synthetic experiments. For the real-world data we
provide additional results.
B.1 Synthetic Experiments
We generate synthetic data according to our causal model. We discretize the timestamps to 1 million
unique timestamps. Throughout the experiments we vary the following parameters:
• Variables: Number of unique events types p.
• Edges: The total number edges in the generating causal graph G∗.
•Delay Distribution: For all synthetic experiments we generate delays according to geometric
distribution (as a discretize instantiation of the exponential).
•Delay Distribution Parameter: For each causal edge we sample the rate λuniformly from a
specified range.
• Cause probability: For each causal edge we sample αuniformly from a specified range.
•# Source Events: Number of events sampled for source nodes (variables without any parents
in the DAG).
•Additive noise parameter: percentage of additional added events to the caused events, also
applies to source nodes, where # Source Events are considered as ‘caused’.
• Instant effect: Except for the ‘Instant Effect’ experiments no instant effects are created.
For all experiments, unless otherwise stated a random DAG is generated. And for each parameteriza-
tion 20 independent samples are generated.
Sanity Check We set the number of types to 20 and generate 100 root events per source node (in
this every node is a source node).
Increase of Event Types In this experiment we increase the number of event types pfrom 5 to 40,
We set the number of edges to (d2−d)/(2∗5), that is 20% of all possible edges. To avoid overly
many events in the colliders we set the number of root events to 20, for 40 variables this results in up
to≈30.000events. We do not include any additive noise and set α= 1. For the delay distribution,
we sample λfrom a range between of [0.3,1].
Decrease of Noise In this experiment we increase the probability of α, and decrease the fraction of
additive noise. We set the number of variables to 20 and set the number of root events to 100. We
sample λfrom a range of [0.1,0.4].
Distribution Misspecification To further evaluate robustness of CASCADE we test recovery on
generated data where the actual distribution does not match the assumed distribution. To this end, we
change the assumed distribution of CASCADE and use the same setup as the previous experiment
(Increase of Event Types) with 20 unique events. For the, true, exponential we observe an average
F1 score of 0.82, for the Poisson 0.81, with a Normal distribution 0.76, and uniform 0.75. While
recovery is best when assumed and generating distribution match CASCADE still performs well under
misspecification.
Multiple Parents For this experiment we specify a DAG, where ⌈n−1
2⌉are direct parents and
⌊n−1
2⌋are independent, the nthnode is the collider. We plant 30 events per root cause and increase
the number of variables from 50 to 200. We add 30 % of additive noise and set the cause probability
randomly between 0.9 and 0.6. We repeat the same experiment where 10% of nodes are colliders.
That is, for 50 event types, 5 are colliders and ⌈p−5
2⌉direct causes of all 5 colliders. The remaining
⌊p−5
2⌋are independent. We show the results in Table 1.
19F1
Number of Colliders
5 0.97 ±0.01
6 0.96 ±0.01
7 0.95 ±0.02
8 0.93 ±0.01
9 0.92 ±0.02
10 0.91 ±0.01
15 0.88 ±0.02
20 0.82 ±0.01
Table 1: Average F1score on Multiple Parents experiment with multiple colliders.
F1 SHD SID SHD-Norm SID-Norm
Method
CASCADE 0.74 19.45 104.10 0.05 0.27
CAUSE 0.19 264.50 NaN 0.69 NaN
NPHC 0.57 47.50 NaN 0.12 NaN
THP 0.23 64.20 180.70 0.16 0.47
Table 2: Average results on 90% instant data
Instant Effects For the instant effects experiments we again use 20 variables with 100 root events,
we shift the geometric delay distribution and set λ= 0.9, such that 90% of the events are generated
at the same timestamp. We randomly sample the trigger probability between 0.7and0.5. For the
exclusively instant effects we set λ= 1. We show the full results in Table 2 and
B.2 Method Parameterization
CASCADE We set the precision parameter for all experiments to 2. For all synthetic experiments
we consider events as potential causes of at most 100 timestamps. For all experiments we consider a
geometric distribution, which we shift back to cover instant effects.
MDLH For the results of the Increase event types experiment we use the sparse version, where we
set the maximum degree to the true maximal degree and set T =1000. In an effort to reduce runtime
with higher number of types (i.e. nodes), we tested it with T=100, where it also did not terminate
within 96 hours.
Other For all other competing methods we used the default parameters.
B.3 Compute Recourses
All experiments where executed on a internal cluster on compute nodes equipped with a AMD EPYC
7773X 64-Core Processor (2.2 GHz; Turboboost: 3.5 GHz), with 2 TB of RAM, while in practice a
fraction of that was necessary. We provide the average runtimes below.
F1 SHD SID SHD-Norm SID-Norm
Method
CASCADE 0.55 32.80 216.05 0.08 0.56
CAUSE 0.19 249.60 NaN 0.65 NaN
NPHC 0.57 46.85 NaN 0.12 NaN
Table 3: Results of instant effects, we omit the results of THP as it only reports empty DAGs
20# Event Types C ASCADE CAUSE NPHC THP MDLH
5 2.05 6.50 4.30 2.35 3.00
10 2.80 9.50 4.25 3.55 16489.00
15 7.10 16.75 4.40 13.80 NaN
20 35.20 42.95 4.15 40.90 NaN
30 362.65 225.70 4.75 305.50 NaN
40 1957.65 890.45 4.85 1984.60 NaN
Table 4: Mean runtime, in seconds, of Increase Event Types Experiment
Noise C ASCADE CAUSE NPHC THP
0.10 147.85 231.50 4.55 97.20
0.50 66.85 176.85 4.40 71.45
0.60 42.75 142.30 4.50 61.55
0.70 25.20 113.30 4.40 51.35
0.80 14.05 76.75 4.25 41.65
0.90 7.55 48.60 4.45 32.95
Table 5: Mean runtime, in seconds, under increasing Noise.
B.4 Network Alarms
In the provided dataset each event happens on a specific device. In addition to the event sequences a
topology Tover the devices is provided. An event can cause an event on each neighboring device,
in addition to the device where the event occurred. To support this we can include a matching for
connected devices. That is if {a, b} ∈ T we include ∆(a,b)
i→jand∆(b,a)
i→j, we include both directions
since events on acan cause events on band events on bcan cause events on a. For all devices we
include the self loop ∆(a,a)
i→j.
B.5 Real World Experiment
In this section we provide Causal Graphs reported by CASCADE and for the Global Banks dataset
additionally the result of THP.
# Event Types C ASCADE CAUSE NPHC THP
50 45.80 323.65 6.30 587.45
60 79.60 536.75 6.10 1596.55
70 131.30 904.50 5.90 3175.30
80 196.80 1129.00 6.45 5393.70
90 283.90 1513.60 6.95 8295.25
100 392.55 1941.80 7.20 12923.50
150 1479.60 4694.75 10.05 NaN
200 3736.70 9736.05 16.95 NaN
Table 6: Mean runtime, in seconds, of Increase Event Types (Collider Experiment)
215 10 15 20 30 400100200300 SHD
5 10 15 20 30 4002004006008001,000 SID
5 10 15 20 30 4000.20.40.60.81
# Event TypesF1
0.9 0.8 0.7 0.6 0.5050100150 SHD
0.9 0.8 0.7 0.6 0.5050100150200250 SID
0.9 0.8 0.7 0.6 0.500.20.40.60.81
NoiseF1
5060708090100150200050100150200250SHDMDLH THP CAUSE
NPHC CASCADE
506070809010015020002550SID
506070809010015020000.20.40.60.81
# Event TypesF1Figure 7: SHD, SID, and F1 score for the synthetic experiments
GroomingendGroomingstartLeavingendSpareTime/TVstartLeavingstartLunchendLunchstartShoweringendShoweringstartSleepingendToiletingstartToiletingendSleepingstartSnackendSnackstartSpareTime/TVend
(a)
BreakfastendBreakfaststartDinnerendDinnerstart
GroomingendGroomingstartLeavingendLeavingstartLunchendLunchstartShoweringendShoweringstartSleepingendToiletingstartSpareTime/TVstartToiletingendSleepingstartSnackendSnackstartSpareTime/TVend
(b)
Figure 8: Recovered Causal Graphs on the two Daily Activities datasets.
22012345678910111213 14 15 16171819
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40414243 44 45 46474849505152535455565758Correctly Recovered
Not RecoveredFigure 9: Recovered Causal Graph on Network Alarms dataset.
 Westpac
Banking
Commonwealth Bank of
AustraliaJapan
HSBC
BNP
Paribas
BarclaysRBSSantander GoldmanSachsIntesa
SanpaoloBBV A PohjolaBank
JPMorgan
Chase & CoDeutsche
BankCredit
Agricole
SocGen
ING
LloydsCredit
Suisse
Nordea
Commerzbank
Danske
Svenska
Handelsbanken
SEBKBC
SwedbankFifth Third
Erste
Group BankUBS
Bank of
AmericaCitigroupWells
Fargo
Morgan
Stanely
TD BankStandard
Chartered
CIBCBNYMellon
U.S.
Bancorp
PNC
Capital
One
State Street CorporationBB&T CorpNational
Bank of
Canada
SunTrust
American
ExpressDNB ASA
BMORegions
FinancialANZ
RBCBank ofNova ScotiaMalayan
Banking
BerhadAsia
Europe
AmericaAustralia
Top 10 Banks
Mitsubishi
FukuokaMizuho
Resona
Sumitomo
Trust
Sumitomo
GroupBank Of
YokohamaShizuoka
Bank
Chiba
Bank
Figure 10: DAG reported by CASCADE on the Global Banks dataset [ 42]. We omit unconnected
nodes for clarity.
23HSBC
Lloyds
CommerzbankING
SocGenBNPParibas
Credit
Suisse
NationalAustralia
Bank
JPMorganMorgan
Stanley
ANZDeutscheBankNational
Bank ofCanada
SunTrustBank ofAmerica Citigroup
U.S.
Bancorp
TD Bank
RBCBMO
FukuokaResona
Sumitomo
Trust
BNY Mellon Capital
One
PNC
American
Express
Fifth
ThirdBB&T CorpBank OfYokohama
Chiba BankFigure 11: DAG reported by THP on the Global Banks dataset [ 42]. We omit unconnected nodes for
clarity.
24NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: All claims made in the abstract and introduction are supported by the findings
and the main body of the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: We discuss limitations and assumptions in the conclusion.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: We clearly state all theorems and proof them in the appendix.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Our results can be fully reproduced, we provide all the data and code online.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: We provide the full code along with the synthetic data generator. All used
dataset are publicly available.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: We provide an experiment setup description in the appendix. We did not do
any hyperparameter tuning. Our method does not require data splitting.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: We show Box-Plots for all (synthetic) experiments.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Yes, we provide a detailed description of the compute recourse in the appendix.
259.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: Our research complies with NeurIPS Code of Ethics, we do not expect any
harmful consequences resulting from our research.
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [NA]
Justification:
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification:
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
Answer: [Yes]
Justification: We provided citations sources for all datasets.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: We use only already publicly available datasets, and do not introduce any new.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: No Human Subjects where involved.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [NA]
Justification:
26