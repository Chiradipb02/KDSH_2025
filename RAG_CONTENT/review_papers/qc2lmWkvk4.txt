Published in Transactions on Machine Learning Research (04/2024)
Hybrid Federated Learning for Feature & Sample Hetero-
geneity: Algorithms and Implementation
Xinwei Zhang∗zhan6234@umn.edu
Department of Electrical and Computer Engineering
University of Minnesota
Wotao Yin wotaoyin@math.ucla.edu
Department of Mathematics
University of California, Los Angeles
Tianyi Chen†chent18@rpi.edu
Department of Electrical and Computer Engineering
Rensselaer Polytechnic Institute
Mingyi Hong∗mhong@umn.edu
Department of Electrical and Computer Engineering
University of Minnesota
Reviewed on OpenReview: https: // openreview. net/ forum? id= qc2lmWkvk4
Abstract
Federatedlearning(FL)isapopulardistributedmachinelearningparadigmdealingwithdis-
tributed and private data sets. Based on the data partition pattern, FL is often categorized
into horizontal, vertical, and hybrid settings. All three settings have many applications, but
hybrid FL remains relatively less explored because it deals with the challenging situation
whereboththe feature space and the data samples are heterogeneous . Hybrid FL combines
theadvantagesofbothhorizontalandverticalFL,addressingsomeoftheirindividuallimita-
tions, such as the same-features requirement of the former and the same-entities requirement
of the latter.
This work designs a novel mathematical model that allows clients to aggregate distributed
data with heterogeneous and possibly overlapping features and samples. Our main idea is
to partition each client’s model into a feature extractor part and a classifier part, where the
former can be used to process the input data, while the latter is used to perform the learning
from the extracted features. The heterogeneous feature aggregation is done by building a
server model that assimilates local classifiers and feature extractors through a carefully
designed matching mechanism. A communication-efficient algorithm is then designed to
train both the client and server models. Finally, we conducted numerical experiments on
multipleimageclassificationdatasetstovalidatetheperformanceoftheproposedalgorithm.
To our knowledge, this is the first formulation and algorithm developed for hybrid FL.
1 Introduction
Federated Learning (FL) is an emerging distributed machine learning (ML) framework that enables hetero-
geneous clients – such as organizations or mobile devices – to collaboratively train ML models (Konečn` y
∗The work of M. Hong and X. Zhang was partially supported by NSF grant EPCN-2311007 and CNS-2003033. This work
is also part of AI-CLIMATE: “AI Institute for Climate-Land Interactions, Mitigation, Adaptation, Tradeoffs and Economy,”
and is supported by USDA National Institute of Food and Agriculture (NIFA) and the National Science Foundation (NSF)
National AI Research Institutes Competitive Award no. 2023-67021-39829.
†The work of T. Chen was partially supported by National Science Foundation Grant 2047177.
1Published in Transactions on Machine Learning Research (04/2024)
Table 1: Examples of applications that generate heterogeneous data
Application Client Feature Blocks Sample
Medical Diagnosis clinic output of different diagnostic devices patient
Recommendation System retailer record of different product categories customer
Social Network SNS provider user activity & relationship SNS user
et al., 2016; Yang et al., 2019). The development of FL aims to address practical challenges in distributed
learning, such as feature and data heterogeneity, high communication cost, and data privacy requirements.
The challenge due to heterogeneous data is particularly evident in FL. The most well-known form of hetero-
geneous data is sample heterogeneity (SH), where the distributions of training samples are different across
the clients (Kairouz et al., 2021; Bonawitz et al., 2019). Severe SH can cause common FL algorithms such as
FedAvg to diverge (Khaled et al., 2019; Karimireddy et al., 2020b). Recently, better-performing algorithms
and system architectures for distributed ML (including FL) under SH include Karimireddy et al. (2020b);
Li et al. (2018); Wang et al. (2020); Fallah et al. (2020); Vahidian et al. (2021).
Figure 1: The heterogeneous data distribution
in a medical diagnosis example.BesidesSH,anotherformofheterogeneityis feature heterogene-
ity(FH). Traditionally, we say the samples are FH if we can
partition them into subsets that bear distinct features. In the
FL setting, when the sample subsets of different clients have
different, but not necessarily distinct, features, we call it FH.
That is, under FH, different clients have unique and possibly
alsocommonfeatures. FHandSHariseinMLtaskssuchascol-
laborative medical diagnosis (Ng et al., 2021), recommendation
systems (Yang et al., 2020), and graph learning (Zhang et al.,
2021), where the data collected by different clients have differ-
ent and possibly overlapping features and sample IDs. Next,
we provide a few examples.
Medical diagnosis application (see Figure 1). The clients are clinics, and they collect data samples from
patients. Each clinic may have a different set of diagnostic devices, e.g., clinic A has MRI and ultrasound,
while clinic B has MRI and electrocardiographs (ECG). FH arises as the feature set of each sample collected
by clinic A may partially overlap with that done by clinic B. Besides FH, SH also arises as multiple clinics
may not have the chance of treating the same patient and each patient usually visits only a subset of clinics.
Recommendation systems (Yang et al., 2020; Zhan et al., 2010). In this case, the clients are large retailers,
and they collect samples (such as shopping records) from their customers. The retailers share a subset of
common products and a subset of common customers.
A third example pertains to an application of learning over multiple social networks (Zhang et al., 2021; Guo
& Wang, 2020). Here the clients are social network providers (e.g., Twitter, Facebook), and the samples are
the set of participating users, their activities and relations. We summarize these three examples in Table. 1.
In the previous three applications, client data can be heterogeneous in bothfeature and sample. Surprisingly,
none of the existing FL algorithms can fully handle such data. Rather, Horizontal FL (HFL) and Vertical
FL (VFL) methods can handle data with only one heterogeneity, the former with SH and the latter with
FH. By keeping only the common features (and ignoring the other features), we can avoid FH and apply an
HFL method. By keeping only the common samples (and discarding the remaining samples), we can avoid
SH and apply a VFL method. Clearly, they both waste data.
Consider the HFL algorithms (Konečn` y et al., 2016; Karimireddy et al., 2020b;a; Dinh et al., 2021). The
clients perform multiple local model updates, and the server averages those updates and broadcasts the new
model to the clients. This scheme works when the clients share the same model and their data share an
identical set of features (see Figure 2b for an illustration); otherwise, the server cannot average their models.
Consider the Vertical FL (VFL) algorithms (Liu et al., 2019; Chen et al., 2020). They split the model
into blocks. Each client processes a subset of the blocks while the server aggregates the processed features
2Published in Transactions on Machine Learning Research (04/2024)
(a) Heterogeneous data on clients
 (b) HFL data usage
 (c) VFL data usage
Figure 2: The data distribution patterns of a) heterogeneous client data; b) HFL and c) VFL.
to compute training losses and gradients. They require all the clients to have the same set of samples
(see Figure 2c); otherwise, they cannot compute the loss and its gradient.
According to Yang et al. (2019); Rahman et al. (2021), the FL setting with heterogeneous features and
samplesisreferredtoas hybrid FL .TodevelopahybridFLmethod, wemustaddressthefollowingchallenges:
1.Global and local inference requires global and local models. Hybrid FL makes it possible for a
client to make its local inference and also for all the clients (or the server) to make a global inference. The
former requires only the features local to a client; the latter requires all the features and training a global
model at the server.
2.Limited data sharing. IntypicalHFL,theclientsdonotsharetheirlocaldataorlabelsduringtraining.
In VFL, the labels are either made available by the clients to the server (Chen et al., 2020) or stored in a
designated client (Liu et al., 2019). A hybrid FL system may be subject to a “no sharing” requirement, so
it is desirable to develop a method in which the server has no access to any data, including the labels.
3.Sample synchronization. A technical challenge with VFL is that the server wants the clients to draw
the same mini-batch of samples at each iteration. This challenge is exacerbated in hybrid FL since not all
the clients will have the same samples. Therefore, to avoid idling clients, a hybrid FL method should allow
uncoordinated sample draws.
Our contributions: Towards addressing the previous challenges, this work proposes a novel model and its
training method. We summarize our contribution as follows.
1. We propose a new hybrid FL approach. For each client, the model consists of a feature extractor and
a subsequent classifier. The clients collaborate and share their knowledge through building a model at the
server that assimilates local classifiers and features. The assimilation is achieved by a matching mechanism
inspired by the non-parametric modeling idea in Yurochkin et al. (2019). This approach enables both global
and local inferences and can handle data with both SH and FH. To our knowledge, this is the first concrete
hybrid FL model in the literature.
2. We develop a hybrid FL algorithm that enables knowledge transfer among the clients. The algorithm
maintains data locality, so the server does not access clients’ data, and it allows uncoordinated sample draws
by the clients.
3. We evaluated the performance of the hybrid FL algorithm on a number of real datasets. The learned
model achieved an accuracy that was comparable to that of a centrally trained model.
1.1 Related work
Federated graph learning (FGL) is applied to molecular classification (He et al., 2021), relation or node
classification for social networks (Zhang et al., 2021; Ng et al., 2021) and financial network (Suzumura et al.,
2019). Inthefirstapplication, thegraphsarerelativelysmallandtheclientshavelargelymanygraphs(Zhang
et al., 2021; He et al., 2021). In the last two application scenarios, the clients possess partial yet overlapping
data of a single large graph, including partial node and edge information (Zhang et al., 2021). However,
3Published in Transactions on Machine Learning Research (04/2024)
existing FGL algorithms mainly focus on the first application scenario (He et al., 2021) and fail to deal with
the latter two scenarios. So we cannot apply them to our hybrid FL setting.
HFLhas a popular algorithm FedAvg (Konečn` y et al., 2016), which adopts the computation-then-
aggregation strategy. The clients locally perform a few steps of model updates, and then the server ag-
gregates the updated local models and averages them before sending the updated global model back to the
clients. Beyond model averaging, PFNM (Yurochkin et al., 2019) and FedMA (Wang et al., 2020) use a
parameter-matching-based strategy and FedGKT (He et al., 2020) uses a knowledge distillation strategy to
get better global model performance, and they do not require the global model to have the same size as the
local models. All HFL algorithms assume their data have the same set of features.
Personalized FL (PFL) has been studied as a potential way to tackle different levels of task heterogeneity.
MAML (Jiang et al., 2019; Fallah et al., 2020) uses meta-learning to build a global model that can fast adapt
to heterogeneous data distribution; FedProx (Li et al., 2018) and LG-FedAvg (Hanzely & Richtárik, 2020)
regularize the distance between the local models and the global model. MOCHA (Smith et al., 2017)
and FedU (Dinh et al., 2021) combine multi-task learning with FL to train models for personalized tasks.
FedPer (Arivazhagan et al., 2019) separates the model into base +personalized layers to decouple the common
and personal knowledge. However, most of the algorithms assume that all local models take the same input
size and format.
Vertical Federated Learning. In VFL, the features and thus the models are divided over different
clients (Hardy et al., 2017; Ma et al., 2019; Liu et al., 2019; Chen et al., 2020). VFL has fewer results than
HFL. Federated Block Coordinate Descent (FedBCD) (Liu et al., 2019) uses a parallel BCD-like algorithm
to optimize the local blocks and transmits essential information for the other clients to compute their local
gradients. Vertical Asynchronous Federated Learning (VAFL) (Chen et al., 2020) assumes that the server
holds the global inference model while local clients train the feature extractors that deal with the local
features. VFL algorithms ignore the overlapping features and can only make joint inferences, which requires
full client participation.
Federated Contrastive Learning (FedCL). FedCL is another set of algorithms related to Hybrid FL.
In this setting, the clients hold non-overlapping features and partially overlapping samples and aim to learn
separate models for local inference (Kang et al., 2022; He et al., 2022). The algorithms perform vertical FL
on the overlapping samples to train a global guidance model and perform local contrastive learning (self-
supervised learning) with the non-overlapped local data to train local models. Compared with our setting,
the FedCL algorithm requires overlapping samples and transmitting intermediate features as VFL and fails
to make use of overlapping feature spaces and non-overlapping samples during VFL training.
2 Problem Formulation
In this section, we first provide a mathematical characterization of the heterogeneous data distributions of
interest to this work. We then propose a unified hybrid FL model.
Notation: Due to the nature of hybrid FL, we must carefully set up its notation. We denote the all one
(column) vector of length das 1d; the identity matrix of size dasId; the positive integer set {1,2,...,N}
as[N]. Feature selection below uses a selector matrix of dimension d1×d2, which belongs to the following
set:Data description: See Figure 3a for an illustration of a dataset with three clients, where the client
datasets has no fullyoverlapped sample or feature, so neither HFL nor VFL can be used. We consider a
hybrid FL system with Mclients indexed by m∈[M], and they collaborate to accomplish the same task.
For convenience, we index the server as m= 0.
First, assume that each sample can have at most d0feature blocks, and the ith block has the set Diof
features,i∈[d0]; clientmhas a set of dmfeature blocks indexed by Im, that is, we write ⟨Dim⟩im∈Imand
write the feature space of client masXm=/producttext
im∈ImDim,which is a Cartesian product of the subset of the
feature blocks possessed by client m. Similarly, we denote the “full feature” space as X0=/producttextd0
i=1Di,which
is the Cartesian product of all feature blocks.
4Published in Transactions on Machine Learning Research (04/2024)
(a) Data partition pattern and notations.
 (b) Block structure of client and server models
Figure 3: The partitioned data and notations, and the structure of the client and server models with heterogeneous
feature extractors and classifiers.
Second, client mholds a private dataset with index set Nmand the samples (xm,n,yn)forn∈Nm, where
xm,n∈Xmdenotes the features of the nthsample on client m, andyndenotes the label of the nthsample.
Collecting all the clients’ data together, we can define the (virtual) global dataset to have sample index set
N0= [N], with samples (x0,n,yn)wherex0,n∈X 0denotes the “full feature” of the nthsample (for the
precise relation between the full-featured x0,nand the local sample xm,n, please see the property P2 below).
The dataset defined above satisfies the following properties.
P1)The global index set is the union of the clients’ index sets:
N0=M/uniondisplay
m=1Nm,which impliesNm⊆N 0.
P2)For a given client m, the features of the nthsample is a sub-vector of the “full features”. That is, there
exists a selector matrix Pmsuch that it can map the global feature x0,ntoxm,n:
xm,n=Pmx0,n,for somePm∈S(dm,d0), (1)
wherePmis a selector matrix that selects the feature blocks on client mfrom the full feature.
Remark 1 . (Data structures of HFL and VFL) The data structure that the HFL deals with can be viewed
as a special case of what has been described above, where the clients have fully overlapping features, i.e.,
d0= 1, Pm= 1,∀m∈[M]; Similarly, the data structure for VFL can be viewed as a special case that the
clients have fully overlapping sample indices, i.e., Nm=N0,∀m∈[M]. □
Model design: With the above description of data, we are ready to present the proposed hybrid FL model
and the corresponding optimization problem.
Client and server model design: Similar to VFL, we split the ML model into feature extractors and
classifiers . Each feature extractor takes a feature block as input and extracts an intermediate feature as
output; the classifier takes the concatenated intermediate features of multiple feature extractors as input
and outputs the prediction.
As illustrated by Figure 3b, on client m, the feature extractor him(θm,im;·)for input feature block Dimis
parameterized by θm,imfor allim∈Im. The feature extractors can have different neural network archi-
tectures (e.g., CNN for CT/MRI images, LSTM/Transformer for medical records, and 1-D CNN for ECG
data). We denote the concatenated feature extractors and their parameters as:
Hm(Θm;·) := [him(θm,im;·)]im∈Im,and Θm:= [θm,im]im∈Im. (2)
The classifier Fm(wm;·)is parameterized by wm, and we denote the prediction loss function as ℓ(·,·). The
data processing procedure on client mis described as follows:
5Published in Transactions on Machine Learning Research (04/2024)
(1)The features xm,nof thenthsample are passed to the feature extractors {him(θm,im;·)}im∈Im;
(2)The classifier Fm(wm;·)makes the prediction based on the concatenated output of the feature extractors
Hm(Θm;xm,n);
(3)The prediction Fm(wm;Hm(Θm;xm,n))and the true label yntogether evaluates the loss ℓ(·,·).
With the specified data processing procedure, the prediction loss on clientmis defined as:
fm(Θm,wm) :=1
|Nm|/summationdisplay
n∈Nmℓ(Fm(wm;Hm(Θm;xm,n)),yn). (3)
Additionally, the server will have a model with fullfeature extractors, concatenated with a classifier; see
the top figure in Fig. 3b. This model structure covers a wide range of ML models for classification and
regression problems, e.g., image classification, language processing, and recommendation systems.
Remark 2 . (Local and server models). A few remarks are ready. First, although the construction of the
client model has been partly motivated by the model splitting idea from VFL, one key difference with VFL
is that each client holds a complete model, capable of performing local inference withoutcommunication to
the server. Second, it is important to have a separate server model, because: 1)in case a test data with
“full feature” comes in, the server can deal with it; 2)in case a new client comes who needs to process a
new subset of features, it can directly download the corresponding feature extractors from the server, which
significantly reduces the complexity of building the local model; and most importantly 3)the server’s model
is instrumental in helping the clients to learn from each other’s data (as we will see shortly). □
At this point, we have defined the models and the prediction loss for each individual client. A key question
is: how the client can effectively collaborate and leverage each other’s data to train high-quality server/client
models? Unlike HFL, where all clients share the same model, the clients in this problem have local models
(i.e., feature extractors and classifiers) of different sizes to deal with feature heterogeneity. Therefore, one
cannot directly perform the conventional model averaging.
Model matching: Toenableeffectivecollaborationamongtheclients, ourideaistoproperly matchdifferent
parts of the model, by imposing a number of carefully designed regularizers.
First, it is natural to assume that when client mandm′share the same feature block Di, the corresponding
feature extractors hi(θm,i;·)should produce the same output, that is θm,i≈θ0,i≈θm′,i. Therefore, we
impose the following regularizer for the feature extractors, which matches the ithfeature extractor at user
mwith the corresponding extractor at the server:
rm,1(Θm,Θ0) :=/summationdisplay
i∈Im1
2∥θm,i−θ0,i∥2=1
2∥Θm−PmΘ0∥2, (4)
wherePmis the data selection matrix defined in (1) and Θmconcatenates parameters defined in (2).
We then design the regularizer for the classifiers. As the classifiers on different clients share partially
overlapping input and identical output space, we model the client’s classifiers wmas some “pruned” versions
of the server-side classifier w0, but with unknown pruning pattern. More specifically, assume that wm∈
Rdm,w,w0∈Rd0,w, we impose the following regularizer for the classifier:
rm,2(wm,Πm,w0) =1
2∥wm−Πmw0∥2,s.t.Πm∈S(dm,w,d0,w), (5)
where Πmis a selection matrix defining the unknown pruning pattern. It is important to note that, the
pruning pattern matrices Πm’s are unknown and need to be optimized. On the contrary, when in the
definition of the feature extractor regularizer (4), the matrix data selection matrices Pm’s are fixed, and they
are defined by the data partitioning pattern. Detailed discussion about the structure of the constraints on
the pruning matrix Πm’s and the regularizer rm,2are given in Appendix A.1
6Published in Transactions on Machine Learning Research (04/2024)
Overall problem formulation: By combining the models discussed in the previous two subsections, we
arrive at the following training problem:
min
{Θm,wm}M
m=0,{Πm}M
m=1M/summationdisplay
m=1pm(fm(Θm,wm) +µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0)),
s.t. Πm∈S(dm,w,d0,w),∀m∈[M],(6)
whereµ1,µ2are hyper-parameters for the regularizers; pm’s are the weights for each local problem satisfying/summationtextM
m=1pm= 1, with common choices pm=1
Morpm=|Nm|
|N|.
Remark 3 . (Relation with HFL). When d0= 1, that is, there is only a single feature block across all the
clients, then the data structure can be handled by the conventional HFL. Below let us discuss the relations
between our model (6) and some popular HFL models. First note that when d0= 1, the feature extractor
regularizer (4) reduces to rm,1(Θm,Θ0) =1
2∥Θm−Θ0∥2.
1)Reduction to FedMA (Wang et al., 2020) and Sub-FedAvg (Vahidian et al., 2021). If we set
Θm=I, i.e., the features are directly processed by the wm’s, then (6) is equivalent to the problem solved
by FedMA and Sub-FedAvg.
2)Reduction to FedProx (Li et al., 2018) and LG-FedAvg (Hanzely & Richtárik, 2020). By
settingwm=I.pm=1
Mand letting Θmdirectly predict the labels, the problem reduces to
min
{Θm}M
m=01
MM/summationdisplay
m=1(fm(Θm) +µ1·rm,1(Θm,Θ0)), (7)
which is equivalent to the formulation solved by FedProx and LG-FedAvg.
3)Reduction to FedAvg. Further by letting µ1→∞in (7), the regularizer enforces Θm’s to achieve
exact consensus, the problem reduces to the one solved by FedAvg.
4)Reduction to FedPer (Arivazhagan et al., 2019). By letting µ2= 0andµ1→∞in (6), the
regularizer on wm’s is removed and Θm’s achieve exact consensus. In this case, Θmserves as the base layers
whilewm’s are the personalized layers, equivalent to the model design of FedPer. □
Remark 4 . (Relation with VFL). VFL assumes that the clients cannot perform prediction independently, so
it directly trains a global model with the local data (Liu et al., 2019; Chen et al., 2020). In contrast, we
assume that each client has sufficient features for independent training and construct a local model, which
is further used to construct a global model. This way, we avoid data sharing and sample synchronization
issues that often limit VFL use in practice. □
3 Algorithm Design
In this section, we propose a training algorithm for the proposed Hybrid FL formulation (6). This algorithm
will alternate between the server-side updates and the client-side updates. To proceed, we will first split
(6) into a server-side problem and a client-side problem, and then develop algorithms to optimize each part.
One key consideration in our algorithm design is to ensure that the server-side model is optimized without
directly accessing any clients’ data.
Problem splitting: Notice that the problem contains parameter blocks {Θm}M
m=1,{wm}M
m=1,Θ0,w0and
{Πm}M
m=1. First we divide the parameters into two groups: 1)the server-side parameters Θ0,w0, and
{Πm}M
m=1and2)the client-side parameters {Θm}M
m=1and{wm}M
m=1.
By fixing the server-side parameters, (6) decomposes into mindependent problems, one for each client. The
problem related to client mis given by:
min
Θm,wmfm(Θm,wm) +µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0). (8)
7Published in Transactions on Machine Learning Research (04/2024)
Algorithm 1 Hybrid Federated Matching Algorithm (HyFEM)
1:Input:w0
0,Θ0
0,{Π0
m}M
m=1,η,T,Q,P
2:fort= 0,...,T−1do
3:for clientm= 1,...,Min parallel do
4: Θt,Q
m,wt,Q
m←ClientUpdate/parenleftbig
Θt
0,Πt
m,wt
0,Q,η/parenrightbig
//Local perturbed SGD solving (8)
5:Send client model Θt,Q
m,wt,Q
mto server
6:for server do
7: Θt+1
0←/parenleftbig/summationtextM
m=1pmPT
mPm/parenrightbig−1/parenleftbig/summationtextM
m=1pmPT
mΘt,Q
m/parenrightbig
//Exact minimization for (10)
8:wt+1
0,{Πt+1
m}M
m=1←ModelMatching/parenleftbig
{wt,Q
m,Πt
m}M
m=1,P/parenrightbig
//Solving (11)
9:Distribute server model wt+1
0,Θt+1
0,{Πt+1
m}M
m=1to clients
10:Output:{wT
m,ΘT
m}M
m=0,{ΠT
m}M
m=1
Similarly, by fixing the client-side parameters, the fm’s in (6) become constants, and the problem reduces
to the following server-side problem:
min
Θ0,w0,{Πm}M
m=1M/summationdisplay
m=1pm(µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0)),
s.t. Πm∈S(dm,w,d0,w),∀m∈[M].(9)
The above problem can be naturally separated into two sub-problems. The first sub-problem is:
min
Θ0M/summationdisplay
m=1pm·rm,1(Θm,Θ0), (10)
and the second one is:
min
w0,{Πm}M
m=1M/summationdisplay
m=1pm·rm,2(wm,Πm,w0),s.t.Πm∈S(dm,w,d0,w),∀m∈[M]. (11)
Algorithm design: WeproposeablockcoordinatedescenttypealgorithmcalledHybridFederatedMatched
Averaging (HyFEM) in Algorithm 1 to solve (6) with the above problem splitting strategy and the sub-
routines are given by Algorithm 2 in Appendix A.2. In global iteration t, the clients first perform Qlocal
perturbed SGD steps on problem (8) to optimize client models wt
m,Θt
m(lines 1−7in Algorithm 2); then
the server aggregates the updated client models, updates global feature extractors by optimizing (10) that
has a closed-form solution as line 7in Algorithm 1, and match the classifiers by optimizing (11); finally, the
server distributes the models and the selection matrices to clients.
The major step in the algorithm is solving the sub-problem (11). We optimize it by the ModelMatching
procedure described on lines 8−14of Algorithm 2 in Appendix A.2: 1)for each client index m′, construct
the server model wt,p
0without the impact of the selected client; 2) apply the Hungarian algorithm to solve a
parameter assignment problem and obtain Πt,p+1
m′in at mostO((dm,w)3)run-time complexity Kuhn (1955).
With a few rounds of updates, we obtain the server classifier and the selection matrices for each client.
This procedure is inspired by the model matching algorithms Wang et al. (2020); Yurochkin et al. (2019)
for matching parameters in deep neural networks of the same size. Our matching algorithm is a non-trivial
extension to the existing model matching algorithm. Because the server-side and client-side models do not
share the exact same functionality, we cannot replace the client-side models with the server-side model.
Such a special property introduces some significant challenges for model matching. The detailed matching
procedure is included in Appendix A.2.
Remark 5 . Although Algorithm 1 seems to be complicated, it can be viewed as a problem with three
parameter blocks L(x,y,z), where xis the collection of {wm,Θm}M
m=1;yis the collection of {Πm}M
m=1and
zis{w0,Θ0}. Then the update can be viewed as follows:
x+←x−η˜∇xL(x,y,z)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
Qtimes,y+←arg min
y∈Range (y)L(x+,y,z),z+←arg min
zL(x+,y+,z), (12)
8Published in Transactions on Machine Learning Research (04/2024)
where ˜∇xL(·)denotes the stochastic partial gradient estimation w.r.t. x. □
Theorem 1 (Informal) Suppose that for each m∈[M],fmhas Lipschitz continuous gradients w.r.t.
[Θm,wm]and thatw0has a fixed dimension. Then with stepsize η=O(1/√QT)and client update Q=O(T),
by running Algorithm 1, the expected gradient norm square w.r.t. {Θm,wm}M
m=1converges with rate O(1/T)
and the successive update difference/vextenddouble/vextenddoublewt+1
0−wt
0/vextenddouble/vextenddouble2+/vextenddouble/vextenddoubleΘt+1
0−Θt
0/vextenddouble/vextenddouble2converges with rate O(1/T). Alternatively,
if we assume the solution to {Πm}M
m=1for sub-problem (11)is unique, and we update client models with one-
step gradient descent, then Algorithm 1 asymptotically converges to the first-order stationary point of (6).
Remark 6 . Theorem 1 is a non-trivial extension of the convergence results for traditional BCD-type
algorithms. The major challenges in the analysis of HyFEM are: 1) it runs multiple, yet a fixed number of
stochastic gradient updates on (potentially nonconvex) blocks {Θm,wm}M
m=1, which results in non-strictly
decrease; 2) the problem w.r.t. block {Πm}M
m=1is nonconvex and non-smooth and does not have a unique
global minimum. Such a setting is different from existing work on BCD-type algorithms. The detailed
convergence statement and its proofs are given in Appendix B. □
We highlight the merits of the proposed approach: 1)Unlike the typical VFL formulations (Liu et al., 2019;
Chen et al., 2020), our approach keeps the data at the clients. Hence, the local problems are fully separable.
There is no sample-drawing synchronization needed during local updates; 2)By utilizing the proposed model
matching technique, we can generate a global model at the server, which makes use of full features. This
makes the inference stage flexible: the clients can use either partial features (by using its local parameters
(Θm,wm)) or the full features by requesting (Θ0,w0)from the server or letting the server do the inference.
Although we formulate the problem by adopting the idea of model splitting from VFL and model prun-
ing/matching from HFL, optimizing (5) is still a non-trivial procedure. Specifically, we can only train
clients’ classifiers wm’s of different sizes, and construct unknown server’s classifier w0withwm’s and find
Πm’s, while existing algorithms either require w0to be given (Vahidian et al., 2021), or wm’s to have the
same size (Wang et al., 2020; Yurochkin et al., 2019).
4 Numerical Experiments
To evaluate the proposed algorithms, we have conducted experiments on a number of standard datasets,
and compared the results with several baselines including centralized training and stand-alone local training
(without any client-server communication). Since existing FL algorithms cannot be applied to our setting
where the client features are only partially overlapped, we do not compare HyFEM with other FL algorithms
in this section. However, we include an additional set of experiments in Appendix C comparing HyFEM and
FedProx with less heterogeneous features.
Dataset & data splitting: We consider the ModelNet40, Cifar-10, and EuroSAT datasets, the details of
which are explained below. We also consider an additional multi-modal dataset, we refer the readers to
Appendix C.3 for details.
ModelNet40 (Wu et al., 2015): ModelNet40 is a multiview object classification dataset that has 12
views from different angles as 12feature blocks for each object. The dataset has N0= 40,000samples
from 40classes. Cifar-10 (Krizhevsky, 2009): Cifar-10 is an image classification dataset with N=
50,000samples from 10classes. We manually split each image into (top left,top right,bottom left,bottom
right)×(red,green,blue) blocks, resulting in total d0= 12feature blocks. EuroSAT (Helber et al., 2019):
EuroSAT is a land cover classification satellite image dataset with N0= 27,000samples from 10classes, and
the images are split into 12feature blocks the same as Cifar-10.
In the training phase of each task, we manually assign a few feature blocks and classes to each client, so
that the clients have partially overlapping features and samples and exhibit FH and SH. The settings are
summarized in Table 2. It is worth pointing out that in setting ModelNet40:2, 12.08%of the data have
neverbeen used by any of the clients during training, and in all settings, there is no feature or sample that
is shared by all clients, so VFL and HFL algorithms cannot be applied. We conduct two sets of experiments
on ModelNet40 dataset where setting 1 uses d0= 4views and setting 2 uses full d0= 12views. The first
setting has fewer features, so the classifiers are smaller and the matching procedure is easier and expected
9Published in Transactions on Machine Learning Research (04/2024)
Table 2: Experiment settings for each dataset. d0,dmdenote the # of feature blocks; N0,Nmdenote the #
of samples; Mdenotes the number of clients.
Dataset d0ClassesN0ClientM d mClasses/client Nm
ModelNet40:1 4 40 40k 4 3 20 20k
ModelNet40:2 12 40 40k 8 6 15 15k
Cifar-10 12 10 50k 9 6-8 5 25k
EuroSAT 12 10 27k 9 6-8 5 13.5k
to be more accurate. Thus the performance of the server model should be closer to the model obtained with
centralized training. In the second setting, the matching procedure is more complex than that of the first
setting and should result in worse server model performance. The illustration of the data assignment pattern
is given in Appendix C.2.
In the testing phase, the clients evaluate their model on all testing samples with corresponding feature blocks
used in the training phase. We average over the accuracies obtained by the clients to obtain the averaged
local accuracy. The global accuracy is evaluated using the matched server model on all testing samples with
full features.
Training settings: In the experiments, we use the MLP model with one hidden layer as the classifier
fm(wm;·). We use the CNN part of ResNet-18 followed by one pooling layer as the feature extractors for
the Cifar-10 and EuroSAT datasets; we use the CNN part of ResNet-34 followed by one pooling layer as
the feature extractors for ModelNet40 dataset. We use the following experiment settings as a comparison:
Centralized training: we train a full-sized server model with all data. This setting serves as the perfor-
mance upper bound among all trained models. Stand-alone training: each client trains a client model
only with local data and without any communication. This setting serves as the baseline (and the perfor-
mance lower bound) of HyFEM. In all settings, we fix the totalnumber of updates (i.e., T·Q= 4096, with
T= 128,Q= 32) for fair comparison and tune the learning rate to achieve the optimal performance for each
experiment separately.
Numerical results: The global accuracy is shown in Figure 4 under different settings. We can see that
HyFEM algorithm can train a server model with higher accuracy than stand-alone training in all settings.
Moreover, the server models can achieve comparable performance as models obtained with centralized train-
ing, even if none of the clients has full features or full classes of the data. HyFEM can deal with data
with SH and FH. As expected, in setting ModelNet40:2, the server model accuracy is lower than in setting
ModelNet40:1, because the matching problem is harder for larger classifiers and 12.08%of the data have
never been used by any of the clients compared with centralized training.
(a) ModelNet40:1
 (b) ModelNet40:2
 (c) Cifar-10
 (d) EuroSAT
Figure 4: Test accuracy of server model trained with HyFEM compared with centralized training and stand-alone
training for a) ModelNet40:1, b) ModelNet40:2, c) Cifar-10, and d) EuroSAT datasets.
The average client accuracy is shown in Figure 5 for different settings. Client models have lower testing
accuracies compared with server models. This is reasonable as the client models are trained with partial
features and biased data with partial classes. We also observe that the stand-alone accuracy under setting
ModelNet40:1 is higher than ModelNet40:2, as each client has more samples. However, the accuracy im-
provement with HyFEM under setting ModelNet40:1 is less than setting ModelNet40:2, as the latter one uses
more features. Nevertheless, HyFEM can train much better client models than stand-alone training even if
the clients do not share the same input space and classes. By using the global model matching algorithm,
the local classifiers can share knowledge with other clients on unseen classes and deal with SH.
10Published in Transactions on Machine Learning Research (04/2024)
(a) ModelNet40:1
 (b) ModelNet40:2
 (c) Cifar-10
 (d) EuroSAT
Figure 5: Averaged test accuracy (with standard deviation) of all clients trained with HyFEM compared with
centralized training and stand-alone training for a) ModelNet40:1, b) ModelNet40:2, c) Cifar-10, and d) EuroSAT
datasets.
5 Conclusions
We propose a hybrid FL framework that handles a general collaborative-learning scenario with partially
overlapped features and samples. We first clarify how the data are partitioned in the hybrid FL scenario and
propose a generic problem formulation. Next, we show that the proposed formulation covers many horizontal
and personalized FL settings, and develop a BCD-based algorithm, HyFEM, to solve the proposed problem.
Finally, our numerical results on a number of image classification datasets demonstrate that HyFEM enables
clients with partial features and samples to achieve a performance comparable to centralized training with
full features.
References
Manoj Ghuhan Arivazhagan, Vinay Aggarwal, Aaditya Kumar Singh, and Sunav Choudhary. Federated
learning with personalization layers. arXiv preprint arXiv:1912.00818 , 2019.
Nan Bai, Pirouz Nourian, Renqian Luo, and Ana Pereira Roders. Heri-graphs: A workflow of creating
datasets for multi-modal machine learning on graphs of heritage values and attributes with social media,
2022. URL https://arxiv.org/abs/2205.07545 .
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov,
ChloeKiddon,JakubKonecny,StefanoMazzocchi,HBrendanMcMahan,etal. Towardsfederatedlearning
at scale: System design. arXiv preprint arXiv:1902.01046 , 2019.
Tianyi Chen, Xiao Jin, Yuejiao Sun, and Wotao Yin. VAFL: a method of vertical asynchronous federated
learning. FL-ICML’20; also arXiv preprint arXiv:2007.06081 , 2020.
Canh T Dinh, Tung T Vu, Nguyen H Tran, Minh N Dao, and Hongyu Zhang. Fedu: A unified framework
for federated multi-task learning with laplacian regularization. arXiv preprint arXiv:2102.07148 , 2021.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning: A meta-learning
approach. arXiv preprint arXiv:2002.07948 , 2020.
Zhiwei Guo and Heng Wang. A deep graph neural network-based mechanism for social recommendations.
IEEE Transactions on Industrial Informatics , 17(4):2776–2783, 2020.
Filip Hanzely and Peter Richtárik. Federated learning of a mixture of global and local models. arXiv preprint
arXiv:2002.05516 , 2020.
Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and
Brian Thorne. Private federated learning on vertically partitioned data via entity resolution and additively
homomorphic encryption. arXiv preprint arXiv:1711.10677 , 2017.
Chaoyang He, Murali Annavaram, and Salman Avestimehr. Group knowledge transfer: Federated learning
of large cnns at the edge. Advances in Neural Information Processing Systems , 33:14068–14080, 2020.
11Published in Transactions on Machine Learning Research (04/2024)
Chaoyang He, Keshav Balasubramanian, Emir Ceyani, Carl Yang, Han Xie, Lichao Sun, Lifang He, Liangwei
Yang, Philip S Yu, Yu Rong, et al. Fedgraphnn: A federated learning system and benchmark for graph
neural networks. arXiv preprint arXiv:2104.07145 , 2021.
Yuanqin He, Yan Kang, Xinyuan Zhao, Jiahuan Luo, Lixin Fan, Yuxing Han, and Qiang Yang. A hybrid
self-supervised learning framework for vertical federated learning. arXiv preprint arXiv:2208.08934 , 2022.
Patrick Helber, Benjamin Bischke, Andreas Dengel, and Damian Borth. Eurosat: A novel dataset and deep
learning benchmark for land use and land cover classification. IEEE Journal of Selected Topics in Applied
Earth Observations and Remote Sensing , 2019.
Yihan Jiang, Jakub Konečn` y, Keith Rush, and Sreeram Kannan. Improving federated learning personaliza-
tion via model agnostic meta learning. arXiv preprint arXiv:1909.12488 , 2019.
Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances and open
problems in federated learning. Foundations and Trends ®in Machine Learning , 14(1-2):1–210, 2021.
Yan Kang, Yang Liu, and Xinle Liang. Fedcvt: Semi-supervised vertical federated learning with cross-view
training. ACM Transactions on Intelligent Systems and Technology (TIST) , 13(4):1–16, 2022.
Sai Praneeth Karimireddy, Martin Jaggi, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich,
and Ananda Theertha Suresh. Mime: Mimicking centralized stochastic algorithms in federated learning.
arXiv preprint arXiv:2008.03606 , 2020a.
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. pp. 5132–
5143, 2020b.
Ahmed Khaled, Konstantin Mishchenko, and Peter Richtárik. First analysis of local GD on heterogeneous
data.arXiv preprint arXiv:1909.04715 , 2019.
Jakub Konečn` y, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and
Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv preprint
arXiv:1610.05492 , 2016.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis, University of Tront ,
2009.
Harold W Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly , 2
(1-2):83–97, 1955.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. arXiv preprint arXiv:1812.06127 , 2018.
Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian Chen, Mingyi Hong, and Qiang Yang.
A communication efficient vertical federated learning framework. arXiv preprint arXiv:1912.11187 , 2019.
Jing Ma, Qiuchen Zhang, Jian Lou, Joyce C Ho, Li Xiong, and Xiaoqian Jiang. Privacy-preserving ten-
sor factorization for collaborative health data analysis. In Proceedings of the 28th ACM International
Conference on Information and Knowledge Management , pp. 1291–1300, 2019.
Dianwen Ng, Xiang Lan, Melissa Min-Szu Yao, Wing P Chan, and Mengling Feng. Federated learning: a
collaborative effort to achieve better medical imaging models for individual sites that have small labelled
datasets. Quantitative Imaging in Medicine and Surgery , 11(2):852, 2021.
KM Jawadur Rahman, Faisal Ahmed, Nazma Akhter, Mohammad Hasan, Ruhul Amin, Kazi Ehsan Aziz,
AKM Muzahidul Islam, Md Saddam Hossain Mukta, and AKM Najmul Islam. Challenges, applications
and design aspects of federated learning: A survey. IEEE Access , 9:124682–124700, 2021.
12Published in Transactions on Machine Learning Research (04/2024)
Meisam Razaviyayn, Mingyi Hong, and Zhi-Quan Luo. A unified convergence analysis of block successive
minimization methods for nonsmooth optimization. SIAM Journal on Optimization , 23(2):1126–1153,
2013.
Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet S Talwalkar. Federated multi-task learning.
InAdvances in Neural Information Processing Systems , pp. 4424–4434, 2017.
Toyotaro Suzumura, Yi Zhou, Natahalie Baracaldo, Guangnan Ye, Keith Houck, Ryo Kawahara, Ali Anwar,
Lucia Larise Stavarache, Yuji Watanabe, Pablo Loyola, et al. Towards federated graph learning for
collaborative financial crimes detection. arXiv preprint arXiv:1909.12946 , 2019.
Saeed Vahidian, Mahdi Morafah, and Bill Lin. Personalized federated learning by structured and unstruc-
tured pruning under data heterogeneity. In 2021 IEEE 41st International Conference on Distributed
Computing Systems Workshops (ICDCSW) , pp. 27–34. IEEE, 2021.
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni. Federated
learning with matched averaging. In International Conference on Learning Representations (ICLR) , 2020.
Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao.
3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE conference on
computer vision and pattern recognition , pp. 1912–1920, 2015.
Liu Yang, Ben Tan, Vincent W Zheng, Kai Chen, and Qiang Yang. Federated recommendation systems. In
Federated Learning , pp. 225–239. Springer, 2020.
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. Federated machine learning: Concept and
applications. ACM Transactions on Intelligent Systems and Technology (TIST) , 10(2):1–19, 2019.
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and Yasaman
Khazaeni. Bayesian nonparametric federated learning of neural networks. In International Conference on
Machine Learning , pp. 7252–7261, 2019.
Justin Zhan, Chia-Lung Hsieh, I-Cheng Wang, Tsan-Sheng Hsu, Churn-Jung Liau, and Da-Wei Wang.
Privacy-preserving collaborative recommender systems. IEEE Transactions on Systems, Man, and Cyber-
netics, Part C (Applications and Reviews) , 40(4):472–476, 2010.
HuandingZhang, Tao Shen, Fei Wu, MingyangYin, HongxiaYang, andChao Wu. Federatedgraph learning–
a position paper. arXiv preprint arXiv:2105.11099 , 2021.
13Published in Transactions on Machine Learning Research (04/2024)
A Heterogeneous Model Matching Algorithm
In this section, we describe the details of the model-matching algorithm. First, we describe the motivation
behindthedesignoftheclassifiers’regularizer(5),whichencourages wm’stobematchedtogethertoconstruct
w0isdesigned. Thenwepresentthedetailedversionofline 8−14inAlgorithm2foroptimizingtheregularizer
(11).
A.1 Regularizer Design
Recall the regularizer for the classifiers is given by:
rm,2(wm,Πm,w0) =1
2∥wm−Πmw0∥2,s.t.Πm∈S(dm,w,d0,w),
wheredm,w,d0,ware the dimensions of wm,w0andΠmis a selection matrix corresponding to the unknown
pruning pattern. In this section, we explain why such a regularizer is used, and how the selection matrices
Πm’s are constructed.
We note that the proposed matching method is a non-trivial extension of the neural matching
method (Yurochkin et al., 2019) (designed for horizontal FL) to the case of hybrid FL. In Yurochkin et al.
(2019), the author considered the horizontal FL setting where the sizes and the functionalities of all the
clients’ models as well as the server’s model are identical, so after matching, the clients can use the matched
server-side model directly as their new model. However, in the considered hybrid FL setting, the input
dimension of each of the client’s inference block can be very different, and the server-side and client-side
models do not share the same functionality. Therefore we cannot replace the client-side models with the
server-side model. Such a special property of the hybrid FL problem introduces some significant challenges
for the matching procedure. This is the main reason that in our proposed algorithm, the matching matrices
and the client/server models have to be iteratively optimized.
Suppose that for each client m, its classifier fm(wm;·)hasLlayers; then the inference block has the following
structure:
y=σm,L(wm,L·σm,L−1(wm,L−1...σm,1(wm,1vm)...)), (13)
whereσm,l(·)represents the element-wise nonlinear activation function of layer l;wm,l’s are the weight
matrices of layer l, and vmis the input of the classifier which is the stacked output of the feature extractors,
i.e.,vm=Hm(Θm;x). Thenwm={wm,l}L
l=1; see Figure 6 for an illustration. Let us further define the
server’s output of feature extractors, activation functions and weights as v0{σ0,l(···)}L
l=1similarly as above.
Note that giving a selection matrix with appropriate shape Π∈S, left multiply the weight matrix wm,lby
ΠT(ΠTwm,l) results in selecting the rows of wm,l, which is equivalent to selecting the output neurons of the
lthlayer. And right multiply the weight matrix wm,lbyΠ(wm,lΠ) results in selecting the columns of wm,l,
which is equivalent to selecting the input neurons of the lthlayer.
The goal is to match wm,l’s with the corresponding parameters w0,lat the server. Below, we discuss how
the first layer, the middle layers, and the last layer are matched.
First, recall that the input of the classifiers has the following relation:
Hm(Θm;xm) =PmH0(Θ0;x0),thatis,vm=Pmv0,
wherePmis the selection matrix defined by the feature overlapping pattern between xmandx0. Then, let
us multiply PT
mon both sides of the above equation, we obtain
PT
mPmv0=PT
mvm. (14)
Note thatPT
mvmpads zeros in the missing feature indices of the vm, so that it matches the size of v0. Let
us define Πm,1=Pm.By utilizing the fact that Pm∈S(dm,d0)is a selection matrix, it holds PmPT
m=Idm,
then we have the following relation:
σm,1((wm,1Πm,1)(ΠT
m,1vm)) =σm,1(wm,1vm).
14Published in Transactions on Machine Learning Research (04/2024)
This process expands the input vmto the same size as v0, while keeping the output of the first layer
unchanged; see Fig. 7 for an illustration of this process.
Next, we would like to find a selection matrix Πm,2∈Sthat compresses the output of the first layer of the
server to match the output of the first layer of client m, as follows:
σm,1((wm,1Πm,1)(ΠT
m,1vm))≈Πm,2·σ0,1(w0,1v0). (15)
This output-matching relation imposes the following assumption on the model parameters:
wm,1= Πm,2w0,1ΠT
m,1. (16)
To see why (16) implies (15), we can plug (16) into the left hand side of (16), and obtain:
σm,1((wm,1Πm,1)(ΠT
m,1vm)) =σm,1((Πm,2w0,1ΠT
m,1Πm,1)(ΠT
m,1vm))
(i)= Πm,2·σ0,1((w0,1ΠT
m,1Πm,1)(ΠT
m,1vm))
= Πm,2·σ0,1((w0,1ΠT
m,1Πm,1)(ΠT
m,1Πm,1v0))
= Πm,2·σ0,1(w0,1ΠT
m,1Πm,1v0)
(ii)≈Πm,2·σ0,1(w0,1v0),(17)
where (i)comesfromthefactthatprojectiononlychangestheorderandpadszerostotheoutput, soapplying
element-wise activation before or after the projection does not affect the final output; in (ii)we use the fact
that ΠT
m,1Πm,1is a diagonal matrix with 1’s and 0’s on diagonal that can be approximated by a identity
matrix. The above discussion suggests that, if (16) holds approximately, then (15) holds approximately.
As a result, we design the regularizer on the first layer between client mand the server, by approximately
enforcing (16) as
1
2/vextenddouble/vextenddoublewm,1−Πm,2w0,1ΠT
m,1/vextenddouble/vextenddouble2.
Let us now analyze the constraint for Πm,2. First, since the dimension of w0,1is larger or equal to that
ofwm,1for each client m, we require that each coordinate of wm,1is matched to one coordinate in w0,1.
Therefore we need Πm,2to satisfy 1= Πm,21. Further, each coordinate in w0,1should match to a coordinate
in at least one clients m∈[M]’swm,1, so this means/summationtextM
m=11TΠm,2≥1. The above process is illustrated in
Fig. 8.
For thelthmiddle layer, its input is the output of the previous layer. By fixing the projection matrices
{Πm,l}M
m=1that match the output of the (l−1)thlayer at each client to the output of the (l−1)thlayer
at the server, the matching problem for the lthmiddle layer takes the same form as the matching problem
for the input layer: the output of the previous layer σm,l−1(·)corresponds to the input vm; the projection
matrices{Πm,l}M
m=1correspondtotheinputprojectionmatrices {Πm,1}M
m=1; thegoalistofindtheprojection
matrices{Πm,l+1}M
m=1that match the output of the lthlayer at each client to the output of the same layer
as the server.
By using the same argument that we used for the input layer, we design the regularizer on the lthmiddle
layer between client mand the server as
1
2/vextenddouble/vextenddoublewm,l−Πm,l+1w0,lΠT
m,l/vextenddouble/vextenddouble2.
For the last layer, the output at each client is the same as the server, which is the predicted label. Therefore,
the projection matrix of the output for the last layer is an identity matrix, and we design the regularizer for
the last layer as
1
2/vextenddouble/vextenddoublewm,L−w0,LΠT
m,L/vextenddouble/vextenddouble2.
Next, by vectorizing wm,l’s we have following relation:
vec(Πm,l+1w0,lΠT
m,l) = (Πm,l⊗Πm,l+1)vec(w0,l),
15Published in Transactions on Machine Learning Research (04/2024)
Algorithm 2 Sub-routines for Algorithm 1
1:ClientUpdate (Θt
0,Πt
m,wt
0,Q,η )
2:Initialize: Θt,0
m←PmΘt
0,wt,0
m←Πt
mwt
0
3:forq= 0,...,Q−1do
4:Uniformly sample n∈Nm
5: Θt,q+1
m←Θt,q
m−η/parenleftbig
∇Θmℓ(Fm(wt,q
m;Hm(Θt,q
m;xm,n)),yn) +µ1(Θt,q
m−PmΘt
0)/parenrightbig
6:wt,q+1
m←wt,q
m−η/parenleftbig
∇wmℓ(Fm(wt,q
m;Hm(Θt,q
m;xm,n)),yn) +µ2(wt,q
m−Πt
mwt
0)/parenrightbig
7:Output: Θt,Q
m,wt,Q
m
8:ModelMatching ({wt,Q
m,Πt
m}M
m=1,wt
0,P)
9:forp= 0,...,P−1do
10: form′= 1,...,Min parallel do
11: ˆwt,p
0←/parenleftig/summationtext
m̸=m′pm(Πt,p
m)TΠt,p
m/parenrightig−1/parenleftig/summationtext
m̸=m′pm(Πt,p
m)Twt,Q
m/parenrightig
12: Πt,p+1
m′←arg minΠm′rm′,2(wt,Q
m′,Πm′,ˆwt,p
0), // Using Hungarian algorithm
13:wt+1
0←/parenleftbig/summationtextM
m=1pm(Πt,P
m)TΠt,P
m/parenrightbig−1/parenleftbig/summationtextM
m=1pm(Πt,P
m)Twt,Q
m/parenrightbig
,Πt+1
m←Πt,P
m
14:Output:wt+1
0,{Πt+1
m}M
m=1
where⊗denotes the Kronecker product. Therefore the regularizer for each layer can be rewritten as
1
2∥vec(wm,l)−(Πm,l⊗Πm,l+1)vec(w0,l)∥2.
Finally we can stack the sub-vector {vec(wm,l)}L
l=1intowm, and define the projection matrix of the long
vector as
Πm:= diag((Π m,1⊗Πm,2),..., (Πm,L⊗I)).
Again, Πmis a block diagonal matrix, and it is easy to verify that it satisfies the following conditions:
ΠT
m1=1,M/summationdisplay
m=11Πm≥1; Πm≥0. (18)
Finally, we obtain the final formulation of the regularizer
rm,2(wm,Πmw0) =1
2∥wm−Πmw0∥2,∀m∈[M]
where Πm’s satisfy: Πm∈S(dw,m,dw,0),M/summationdisplay
m=11T
dw,mΠm≥1T
dw,0.(19)
A.2 Optimization Procedure
In this subsection, we describe the detailed procedures in line 8−14of Algorithm 2 to optimize the classifier
matching problem (5) or its more detailed formulation (19). The procedure with more details is given in
Algorithm 3.
We iteratively solve the matching problem (11) for Piterations. In each iteration, we randomly pick a client
m′to match it with the server’s classifier from the first layer to the last layer.
For the first L−1layers, we first fix Πm′,l−1and construct an assignment cost matrix Clthat computes the
cost to match jthrow in client m′toithrow in the server of layer lfor all (i,j). The element Cl(i,j)of the
cost matrix is defined as:
Cl(i,j) =/braceleftigg
dist1(w0,lΠT
m,l−1[i],wm,l[j])w0,lΠT
m,l−1[i]̸=0
dist2(wm,l[j]) otherwise ,(20)
wherew0,lΠT
m,l−1[i]andwm,l[j]denote the ithandjthrow of the matrices, dist1is the similarity cost for
matchingwm,l[j]to an existing row, and dist2is the dimension penalty to match wm,l[j]to a new row in
16Published in Transactions on Machine Learning Research (04/2024)
Algorithm 3 Model Matching Procedure
1:ModelMatching
2:Input:{wt,Q
m,Πt
m}M
m=1,wt
0,P
3:forp= 0,...,P−1do
4:Uniformly sample m′∈[M]
5:wt,p
0←/parenleftig/summationtext
m̸=m′pm(Πt,p
m)TΠt,p
m/parenrightig−1/parenleftig/summationtext
m̸=m′pm(Πt,p
m)Twt,Q
m/parenrightig
6: forl= 1,...,L−1:do
7: Construct cost matrix Clwith (20).
8: Πt,p+1
m′,l←arg minΠm′/summationtext
i,jΠm′(i,j)·Cl(i,j), // Using Hungarian algorithm
9:wt+1←/parenleftbig/summationtextM
m=1pm(Πt,P
m)TΠt,P
m/parenrightbig−1/parenleftbig/summationtextM
m=1pm(Πt,P
m)Twt,Q
m/parenrightbig
,Πt+1
m←Πt,P
m
10:Output:wt+1
0,{Πt+1
m}M
m=1
w0,l. One specification of the cost functions is PFNM (Yurochkin et al., 2019) that uses the MAP loss of
the Beta-Bernoulli process, where dist1is based on the Gaussian prior and dist2follows the Indian Buffet
process prior. Then we can solve the assignment problem to obtain Πm′,lwith the celebrated Hungarian
algorithm (Kuhn, 1955).
Note that for the first layer, the matching pattern Πm,0is given by Πm,0=Pm. And we do not need to
match the output layer.
B Convergence Analysis
In this section, we analyze the convergence property of Algorithm 1. We first make the following assumptions
on the problem:
A 1 (Block Lipschitz Gradient) For each parameter blocks in {wm,Θm}M
m=1, there exists an Lmsuch
that the following holds:
/vextenddouble/vextenddouble∇Θmfm(Θm,wm)−∇ Θ′mfm(Θ′
m,w′
m)/vextenddouble/vextenddouble+/vextenddouble/vextenddouble∇wmfm(Θm,wm)−∇w′mfm(Θ′
m,w′
m)/vextenddouble/vextenddouble
≤Lm(∥Θm−Θ′
m∥+∥wm−w′
m∥),∀Θm,Θ′
m,wm,w′
m,
A 2 (Lower Bounded Loss) There exist finite lower bounds for each client classification loss, i.e.,
∃fm>−∞,s.t. fm(Θm,wm)≥fm,∀Θm,wm,m.
A 3 (Bounded Variance) The stochastic partial gradient estimation has bounded variance σ2
Θandσ2
w,
i.e.,
En∥∇Θmℓ(Fm(wm;Hm(Θm;xm,n)),yn)−∇ Θmfm(wm,Θm)∥2≤σ2
Θ,∀Θm,wm,∀m∈[M],
En∥∇wmℓ(Fm(wm;Hm(Θm;xm,n)),yn)−∇wmfm(wm,Θm)∥2≤σ2
w,∀Θm,wm,∀m∈[M].
We can abstract HyFEM to a BCD-type algorithm by redefining the model parameters and the problem as
follows:
1. Define x:= [Θ 1;...; ΘM;w1;...;wM],y:= [vec(Π 1);...,vec(ΠM)], and z:= [Θ 0;w0].
2. DefineL(x,y,z) :=/summationtextM
m=1pm(fm(Θm,wm) +µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0)).
Then the optimization problem (6) can be simplified as:
min
x,y,zL(x,y,z),s.t.y∈Range( y). (21)
17Published in Transactions on Machine Learning Research (04/2024)
Moreover, the algorithm can be simplified as:
xt,q+1=xt,q−η˜∇xL(xt,q,yt,zt),forq= 0,...,Q−1 (22a)
yt+1= arg min
y∈Range( y)L(xt,Q,y,zt), (22b)
zt+1= arg min
zL(xt,Q,yt+1,z), (22c)
where we assume xt+1,0=xt+1=xt,Qand ˜∇xL(·)denotes the stochastic partial gradient of x.
We make the following assumptions to problem (21).
A 4 (Block Lipschitz Gradient) Lis block smooth, and for parameter xandz, there exists positive
constantsLx,LzandCxsuch that the following holds:
∥∇xL(x,y,z)−∇ x′L(x′,y,z)∥≤Lx∥x−x′∥,∀x,x′,z,∀y∈Range( y).
∥∇xL(x,y,z)−∇ xL(x,y,z′)∥≤Cx∥z−z′∥,∀z,z′,x,∀y∈Range( y).
A 5 (Block Strong Convexity of z)For parameter z, there exists a positive constant µsuch that the
following holds:
L(x,y,z′)≥L(x,y,z) +⟨∇zL(x,y,z),z′−z⟩+µ
2∥z′−z∥2,∀x,z,z′,∀y∈Range( y).
A 6 (Unbiased Stochastic Partial Gradient) The stochastic partial gradient of xis unbiased:
E˜∇xL(x,y,z) =∇xL(x,y,z),∀x,z,∀y∈Range( y).
A 7 (Bounded Variance of Stochastic Partial Gradient) The stochastic partial gradient of xhas
bounded variance σ2:
E/vextenddouble/vextenddouble˜∇xL(x,y,z)−∇ xL(x,y,z)/vextenddouble/vextenddouble2≤σ2,∀x,z,∀y∈Range( y).
A 8 (Lower Bounded Function) The problemLis bounded from below, i.e.,
∃L>−∞,s.t.L(x,y,z)≥L,∀x,z,∀y∈Range( y).
A 9 (Compact Constraint Set) For parameter y, the constraint set Range (y)is compact.
Note that in A4 and A5, we only assume blocks x,zare smooth, and only block zis strongly convex while
block ycan be non-smooth and non-convex and xcan potentially be non-convex. Further we assume that
∇xLis smooth w.r.t. z, which is non-standard, but we can prove that it holds for problem (6). The
remaining assumptions A6-A9 are common when analyzing stochastic algorithms. Further, we can verify
that the above assumptions hold for the original problem (6).
Lemma 1 Suppose (6)satisfies assumptions A1-A3, then it satisfies A4-A9 with the constants in the as-
sumptions given as:
Lx= max
m{pmLm+ max{µ1,µ2}}, Cx= max{µ1,µ2},
µ≥min
m{pm}·min{µ1,µ2}, σ2=σ2
Θ+σ2
w,L=M/summationdisplay
m=1pmfm.
The proof is given in Section B.2.
Then we have the following result:
18Published in Transactions on Machine Learning Research (04/2024)
Theorem 2 Suppose the problem (21)satisfies A4-A9 and run (22)forTiterations with stepsize η≤
min{1
Lx,8µ
5C2x}. Then the sequence {xt,q,yt,zt}T
t=0generated by (22)satisfies:
1
TQT−1/summationdisplay
t=0E/parenleftigg
µ
η/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2+/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2+Q/summationdisplay
q=0/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2/parenrightigg
≤10
TQη/parenleftbig
L(x0,y0,z0)−L/parenrightbig
+/parenleftbigg
5Lxη+2L2
xη2
Q/parenrightbigg
σ2,(23)
and∥∇zL(xt,yt,zt)∥2= 0,∀t∈[T].
This result indicates that by setting Q=T,η =/radicalig
2(L(x0,y0,z0)−L)
LxQTσ2, the right-hand-side (RHS) of (23)
becomes10σ√
2(L(x0,y0,z0)−L)Lx
T+2Lx(L(x0,y0,z0)−L)
T3 =O(1
T).Let us analyze the left-hand-side (LHS) terms
of (23). First, we have
1
TQT−1/summationdisplay
t=0Eµ
η/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2=µ
TT−1/summationdisplay
t=0E/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2=O/parenleftbigg1
T/parenrightbigg
,
indicating that E/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2=O/parenleftbig1
T/parenrightbig
.Second, we have
1
TQT−1/summationdisplay
t=0E/parenleftigg
/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2+Q/summationdisplay
q=0/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2/parenrightigg
=O/parenleftbigg1
T/parenrightbigg
,
where the LHS is the sum of T(Q+ 2)terms of∥∇xL∥2divide byTQ, which also indicates that
E∥∇xL(xt,q,yt,zt)∥2=O/parenleftbig1
T/parenrightbig
. Together we have that algorithm (22) finds a stationary solution of (21)
w.r.t. x,zwith rateO/parenleftbig1
T/parenrightbig
. Combining Theorem 2 with Lemma 1, we have that by running Algorithm 1,
parameters{wm,Θm}M
m=0converges to their stationary point of (6), while {Πm}M
m=1stays in a compact set.
Alternatively, if we assume the solution to yis unique, and update on xis a one-step gradient descent, i.e.,
Q= 1and
xt+1=xt−η∇xL(xt,yt,zt),
then by applying (Razaviyayn et al., 2013, Theorem 2), Algorithm 1 asymptotically converges to the first-
order stationary point of (6).
B.1 Proof for Theorem 2
We begin by proving the following descent result:
EtL(xt+1,yt+1,zt+1)−L(xt,yt,zt)≤−η
2Q−1/summationdisplay
q=0Et/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2
−µ
2/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2+QLxη2σ2
2,(24)
where we denote the expectation conditioned on the information up to iteration tasEt. First, we write the
LHS of the above equation into three terms as below:
L(xt+1,yt+1,zt+1)−L(xt,yt,zt) =/parenleftbig
L(xt+1,yt+1,zt+1)−L(xt+1,yt+1,zt)/parenrightbig
+/parenleftbig
L(xt+1,yt+1,zt)−L(xt+1,yt,zt)/parenrightbig
+/parenleftbig
L(xt+1,yt,zt)−L(xt,yt,zt)/parenrightbig
.(25)
We bound the three terms on the RHS of the above equation separately.
19Published in Transactions on Machine Learning Research (04/2024)
1)The first term/parenleftbig
L(xt+1,yt+1,zt+1)−L(xt+1,yt+1,zt)/parenrightbig
can be bounded by applying A5:
L(xt+1,yt+1,zt+1)−L(xt+1,yt+1,zt)
A5
≤−/angbracketleftbig
∇Lz(xt+1,yt+1,zt+1),zt−zt+1/angbracketrightbig
−µ
2/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2
(a)=−µ
2/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2,(26)
where in (a)uses update rule (22c) that by exact minimization ∇zL(xt+1,yt+1,zt+1) = 0.
2)By the update rule (22b), the second term/parenleftbig
L(xt+1,yt+1,zt)−L(xt+1,yt,zt)/parenrightbig
can be bound by
L(xt+1,yt+1,zt)−L(xt+1,yt,zt)≤0. (27)
3)The third term/parenleftbig
L(xt+1,yt,zt)−L(xt,yt,zt)/parenrightbig
can be further decompose into:
L(xt+1,yt,zt)−L(xt,yt,zt) =L(xt,Q,yt,zt)−L(xt,0,yt,zt)
=Q−1/summationdisplay
q=0/parenleftbig
L(xt,q+1,yt,zt)−L(xt,q,yt,zt)/parenrightbig
,(28)
where the first inequality uses the definition that xr,Q=xr+1andxr,0=xr. Then we bound each term in
the summation as:
L(xt,q+1,yt,zt)−L(xt,q,yt,zt)A4
≤/angbracketleftbig
∇xL(xt,q,yt,zt),xr,q+1−xr,q/angbracketrightbig
+Lx
2/vextenddouble/vextenddoublext,q+1−xt,q/vextenddouble/vextenddouble2
(22a)=−η/angbracketleftbig
∇xL(xt,q,yt,zt),˜∇xL(xt,q,yt,zt)/angbracketrightbig
+Lxη2
2/vextenddouble/vextenddouble˜∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2.(29)
Taking expectation on (t,q), we have:
Et,qL(xt,q+1,yt,zt)−L(xt,q,yt,zt)
≤−η/angbracketleftbig
∇xL(xt,q,yt,zt),Et,q˜∇xL(xt,q,yt,zt)/angbracketrightbig
+Lxη2
2Et,q/vextenddouble/vextenddouble˜∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2
(a)=η/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2+Lxη2
2/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2
+Lxη2
2Et,q/vextenddouble/vextenddouble˜∇xL(xt,q,yt,zt)−∇ xL(xt,q,yt,zt)/vextenddouble/vextenddouble2
A7
≤−/parenleftbigg
η−Lxη2
2/parenrightbigg/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2+Lxη2σ2
2,(30)
where (a)first applies the fact that E(X2) = (EX)2+E((X−E(X))2)to the second therm, then applies
A6 to the first and the second term.
By picking η≤1
Lxand substituting (30) to (28), we have:
EtL(xt+1,yt,zt)−L(xt,yt,zt)≤−η
2Q−1/summationdisplay
q=0Et/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2+QLxη2σ2
2. (31)
Then we substitute (26), (27) and (31) back to (25), then we obtain (24).
20Published in Transactions on Machine Learning Research (04/2024)
To prove Theorem 2, we need to further bound/vextenddouble/vextenddouble∇xL(xt+1,yt,zt)/vextenddouble/vextenddouble2and/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2. We bound
them as follows. Term/vextenddouble/vextenddouble∇xL(xt+1,yt,zt)/vextenddouble/vextenddouble2can be bound as:
Et,Q−1/vextenddouble/vextenddouble∇xL(xt+1,yt,zt)/vextenddouble/vextenddouble2(a)
≤2/vextenddouble/vextenddouble∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2
+Et,Q−12/vextenddouble/vextenddouble∇xL(xt,Q,yt,zt)−∇ xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2
A4
≤2L2
xEt,Q−1/vextenddouble/vextenddoublext,Q−xt,Q−1/vextenddouble/vextenddouble2+ 2/vextenddouble/vextenddouble∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2
(22a)= 2L2
xη2Et,Q−1/vextenddouble/vextenddouble˜∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2+ 2/vextenddouble/vextenddouble∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2
A7
≤/parenleftbig
2 + 2L2
xη2/parenrightbig/vextenddouble/vextenddouble∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2+ 2L2
xη2σ2,(32)
where in (a)we add and subtract ∇xL(xt,Q−1,yt,zt)and apply Cauchy–Schwarz inequality. Similarly, term/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2can be bound as:
/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2(a)
≤2/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)−∇ xL(xt+1,yt+1,zt+1)/vextenddouble/vextenddouble2
+ 2/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt+1)/vextenddouble/vextenddouble2
A4
≤2C2
x/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2+ 2/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt+1)/vextenddouble/vextenddouble2, (33)
where in (a)we add and subtract ∇xL(xt+1,yt+1,zt+1)and apply Cauchy–Schwarz inequality.
Then we sum the above results as (24) ×2 +(32)×η
5+(33)×η
5and obtain the following:
2EtL(xt+1,yt+1,zt+1)−2L(xt,yt,zt) +η
5Et,Q−1/vextenddouble/vextenddouble∇xL(xt+1,yt,zt)/vextenddouble/vextenddouble2
+η
5/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt)/vextenddouble/vextenddouble2≤−ηQ−1/summationdisplay
q=0Et/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2−µ/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2
+QLxη2σ2+2C2
xη
5/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2+2η
5/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt+1)/vextenddouble/vextenddouble2
+2η+ 2L2
xη3
5/vextenddouble/vextenddouble∇xL(xt,Q−1,yt,zt)/vextenddouble/vextenddouble2+2L2
xη3σ2
5.(34)
Rearrange the terms, notice that we choose η≤1
Lx, so that 2η+ 2L2
xη3≤4η, we have:
η
5Q/summationdisplay
q=0Et/vextenddouble/vextenddouble∇xL(xt,q,yt,zt)/vextenddouble/vextenddouble2+η
5Et/vextenddouble/vextenddouble∇xL(xt+1,yt+1,zt+1)/vextenddouble/vextenddouble2+/parenleftbigg
µ−2C2
xη
5/parenrightbigg/vextenddouble/vextenddoublezt+1−zt/vextenddouble/vextenddouble2
≤2/parenleftbig
L(xt,yt,zt)−EtL(xt+1,yt+1,zt+1)/parenrightbig
+/parenleftbigg2L2
xη3
5+QLxη2/parenrightbigg
σ2.(35)
Sum the above equation from t= 0toT−1, chooseµ−2C2
xη
5≥µ
5(η≤8µ
5C2x), and devide both side byηQT
5,
then Theorem 2 is proved.
B.2 Proof for Lemma 1
In this section, we verify the assumptions A4-A9 for the original problem (6) under assumptions A1-A3.
21Published in Transactions on Machine Learning Research (04/2024)
Recall that we have the following correspondence:
x:= [Θ 1;...; ΘM;w1;...;wM],y:= [vec(Π 1);...,vec(ΠM)],z:= [Θ 0;w0],
L(x,y,z) :=M/summationdisplay
m=1pm(fm(Θm,wm) +µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0)),
rm,1(Θm,Θ0) =1
2∥Θm−PmΘ0∥2,
rm,2(wm,Πm,w0) =1
2∥wm−Πmw0∥2,s.t.Πm∈S(dw,m,dw,0),M/summationdisplay
m=11T
dw,mΠm≥1T
dw,0.
1)For A4, we have
∇xL(x,y,z) =/bracketleftbiggpm∇Θmfm(Θm,wm) +pmµ1(Θm−PmΘ0)
pm∇wmfm(Θm,wm) +pmµ2(wm−Πmw0)/bracketrightbiggM
m=1.
Therefore we have the following bound:
∥∇xL(x,y,z)−∇ xL(x′,y,z)∥
=M/summationdisplay
m=1pm∥∇Θmfm(Θm,wm) +µ1Θm−∇ Θmfm(Θ′
m,w′
m)−µ1Θ′
m∥
+M/summationdisplay
m=1pm∥∇wmfm(Θm,wm) +µ2wm−∇wmfm(Θ′
m,w′
m)−µ2w′
m∥
≤M/summationdisplay
m=1pm(∥∇Θmfm(Θm,wm)−∇ Θmfm(Θ′
m,w′
m)∥+µ1∥Θm−Θ′
m∥)
+M/summationdisplay
m=1pm(∥∇wmfm(Θm,wm)−∇wmfm(Θ′
m,w′
m)∥+µ2∥wm−w′
m∥)
A1
≤M/summationdisplay
m=1pm((Lm+µ1)·∥Θm−Θ′
m∥+ (Lm+µ2)·∥wm−w′
m∥)
≤max
m{pmLm+ max{µ1,µ2}}M/summationdisplay
m=1(∥Θm−Θ′
m∥+∥wm−w′
m∥)
=Lx∥x−x′∥.
where we obtain Lx= maxm{pmLm+ max{µ1,µ2}}. Also, we have
∥∇xL(x,y,z)−∇ xL(x,y,z′)∥=M/summationdisplay
m=1pm(µ1∥Pm(Θ0−Θ′
0)∥+µ2∥Πm(w0−w′
0)∥)
≤M/summationdisplay
m=1pm(µ1∥Pm∥∥Θ0−Θ′
0∥+µ2∥Πm∥∥w0−w′
0∥)
(a)=M/summationdisplay
m=1pm(µ1∥Θ0−Θ′
0∥+µ2∥w0−w′
0∥)
(b)
≤max{µ1,µ2}(∥Θ0−Θ′
0∥+∥w0−w′
0∥)
=Cx∥z−z′∥.
where in (a)we use the fact that Pm∈S(dm,d0),Πm∈S(dw,m,dw,0)are selection matrices so that ∥Pm∥=
1,∥Πm∥= 1;(b)uses the fact that/summationtextM
m=1pm= 1.Therefore A4 is verified.
22Published in Transactions on Machine Learning Research (04/2024)
2)Next, we verify A5. We proceed by directly computing the second derivitive of z:
∇2
zL(x,y,z)
=M/summationdisplay
m=1pm/bracketleftbigg∇2
Θ0µ1·rm,1+µ2·rm,2∇Θ0∇w0µ1·rm,1+µ2·rm,2
∇Θ0∇w0µ1·rm,1+µ2·rm,2∇2
w0µ1·rm,1+µ2·rm,2/bracketrightbigg
=/bracketleftigg
µ1·/summationtextM
m=1pmPT
mPm 0
0 µ2/summationtextM
m=1pmΠT
mΠm/bracketrightigg
.
Then we analyze the range of the eigenvalues of this matrix. First we know that Πm,Pm’s are selection
matricies, therefore PT
mPm,ΠT
mΠmare diagonal matricies, indicating that ∇2
zL(x,y,z)is also a diagonal
matrix.
For the first block µ1·/summationtextM
m=1pmPT
mPm, we have that Pm’s are the feature selection matrix, i.e.,
xm=Pmx0, xm∈Xm=/productdisplay
i∈ImDi, x 0∈X0=d0/productdisplay
i=1Di.
It is clear that if client mhas theithfeature, then the ithdiagonal entry of PT
mPmisPT
mPm(i,i) = 1, and
PT
mPm(i,i) = 0otherwise. That is, the following holds:
PT
mPm(i,i) =/braceleftigg
1,i∈Im,
0,i /∈Im.
Further, we have that the full feature space X0is the union of the clients’ feature spaces, i.e.,/uniontext
m∈[M]Im=
[d0].Therefore, we have
1T
d0M/summationdisplay
m=1PT
mPm≥ 1T
d0,and min
i∈[d0]M/summationdisplay
m=1pmPT
mPm(i,i)≥min
m{pm}.
Similarly, the constraint on Πm’s that/summationtextM
m=11T
dw,mΠm≥1T
dw,0indicates that the following holds:
min
i∈[dm,0]M/summationdisplay
m=1pmΠT
mΠm(i,i)≥min
m{pm}.
Therefore, the Hessien matrix ∇2
zL(x,y,z)is positive definite, with smallest eigenvalue µ≥minm{pm}·
min{µ1,µ2}.Thus A5 is verified.
3)A6 holds true as in Algorithm 1, we uniformly samples n∈Nmfor allm∈[M], therefore
En∇Θmℓ(Fm(wm;Hm(Θm;xm,n)),yn) =∇Θmfm(Θm,wm),
En∇wmℓ(Fm(wm;Hm(Θm;xm,n)),yn) =∇wmfm(Θm,wm),
Further, from A3, we can obtain A7 with σ2=σ2
Θ+σ2
w.
4)To verify A8, we apply A2 that:
L(x,y,z) =M/summationdisplay
m=1pm(fm(Θm,wm) +µ1·rm,1(Θm,Θ0) +µ2·rm,2(wm,Πm,w0))
(a)
≥M/summationdisplay
m=1pmfm(Θm,wm)A2
≥M/summationdisplay
m=1pmfm:=L,
23Published in Transactions on Machine Learning Research (04/2024)
Client index mAssigned features ImAssigned class #
1 1,2,3 25
2 1,2,3 25
3 1,3,4 25
4 1,3,4 25
5 1,3 25
6 1,3 25
Table 3: The data assignment pattern for MultiView40 dataset. Note that 6.88%of data has never been
used.
Client index mAssigned features ImAssigned classes
1 1,2,3 1–5
2 1,2,3 6–10
3 1,3,4 1–5
4 1,3,4 6–10
5 1,3 1–5
6 1,3 6–10
Table 4: The data assignment pattern for Cifar-10 and EuroSAT dataset.
where (a)uses the fact that rm,1(Θm,Θ0) =1
2∥Θm−PmΘ0∥2≥0andrm,2(wm,Πm,w0) =
1
2∥wm−Πmw0∥2≥0.
5)A9 directly comes from the constraint on Πm’s that
Πm∈S(dw,m,dw,0),M/summationdisplay
m=11T
dw,mΠm≥1T
dw,0,
which is a compact set.
At this point, we have verified A4-A9 for problem (6) with Algorithm 1, and the corresponding constants
are summarized below:
Lx= max
m{pmLm+ max{µ1,µ2}}, Cx= max{µ1,µ2},
µ≥min
m{pm}·min{µ1,µ2}, σ2=σ2
Θ+σ2
w,L=M/summationdisplay
m=1pmfm.
This completes the proof for Lemma 1.
C Additional Numerical Experiments
In this section, we include additional sets of numerical experiments. In the first set of additional experiments,
we reduce the feature heterogeneity of the data on the clients by allowing clients to have common features
so that HFL algorithms such as FedProx and FedAvg apply. Further, we include an additional multi-modal
dataset with both image and text features.
C.1 Comparison with HFL
In this section, we conduct numerical experiments to compare FedProx (Li et al., 2018) with HyFEM. In
the experiments, we split the features into d0= 4blocks for the datasets and assign the first and the third
blocks as the common blocks for all M= 6clients. Then we can apply FedProx to train a model with the
overlapped features and compare with the models trained with HyFEM with more features. The detailed
data assignment patterns for different datasets are described in Table 3 - 4. Note that in the MultiView40
dataset, there are 6.88%of the data has never been used by HyFEM and 50%of the data has never been
24Published in Transactions on Machine Learning Research (04/2024)
used by FedProx. For Cifar-10 and EuroSAT datasets, all data has been used by at least one client with
HyFEM while 50%of the data are dropped by FedProx.
For Cifar-10 and EuroSAT datasets, we split each image into (top left, top right, bottom left, bottom right)
totald0= 4feature blocks. For the MultiView40 dataset, we choose four views of different angles of the
objects as the full feature space. The total communication round is T= 64and local update # Q= 32are
fixed for all experiments. We conducted a line search on the learning rate ηandµ2for the algorithms to
obtain the best performance.
The results for the datasets are shown in Figure 9 and Figure 10. From the results, we can see that the
models trained with HyFEM can obtain better performance than FedProx. This is because HyFEM can use
more data than FedProx by using heterogeneous models.
C.2 Data Partitioning Pattern
In this subsection, we provide the data partitioning patterns for each setting. Note that in Figure 11(b),
and Figure 12(a), the black boxes with 0inside them indicate that the corresponding feature block of the
samples in this class has not been used for training by any of the clients.
C.3 Experiments on HeriGraph Dataset
HeriGraph (Bai et al., 2022) dataset is a multi-modal dataset for heritage site classification. This dataset
consists of totalN0= 41,621samples from 9classes. Each sample has at most d0= 4preprocessed feature
blocks, including one text feature block and three different image feature blocks. Note that not all samples
have all features. For example, only 25,325samples have text features, and the rest do not. We will include
the result for this dataset in the revised manuscript.
In the experiments, we use the MLP model with one hidden layer as the classifier fm(wm;·). We use MLPs
of different sizes as feature extractors for each feature block. We set client number M= 6, client feature
block number dm= 2, and each client has 6out of 9classes.
The result is shown in Figure 13. The server model trained with HyFEM has comparable performance as
the centralized trained model. The average performance of the clients’ models has worse performance than
the full model due to the lack of full features and classes, but the accuracy is 20%higher than the models
obtained with stand-alone training.
C.4 Ablation Study on Reqularizer Weight
In this subsection, we provide extra numerical results on different choices of the regularizer weight µ2. In
the experiment, we trained the model on the MultiView40 dataset under setting MultiView40:2. In the
experiment, we choose µ2={0.1,0.3,0.5}to control the strength of the impact of model matching and the
divergence between the local and global model. The results are shown in Figure ??From the result, we can
see that with larger µ2, i.e., when regularizing the client and the matched server model to be more similar,
both the server-side and the client-side models achieve better performance.
25Published in Transactions on Machine Learning Research (04/2024)
Figure 6: Illustration of the layer structure of the inference blocks on the clients, for the L= 3case.
Figure 7: Aligning the input of the first layer by rearranging and padding the corresponding coordinates of
the input vmand the first layer wm,1.
Figure 8: Aligning the output of the first layer by rearranging and padding the corresponding coordinates
of the first layer wm,1.
26Published in Transactions on Machine Learning Research (04/2024)
(a) ModelNet40
 (b) Cifar-10
 (c) EuroSAT
Figure 9: Test accuracy of server models trained with HyFEM compared with FedProx on a) ModelNet40, b) Cifar-
10, and c) EuroSAT.
(a) ModelNet40
 (b) Cifar-10
 (c) EuroSAT
Figure 10: Averaged test accuracy of client models trained with HyFEM compared with FedProx on a) ModelNet40,
b) Cifar-10, and c) EuroSAT.
27Published in Transactions on Machine Learning Research (04/2024)
123456789101112131415161718192021222324252627282930313233343536373839401
2
3
4
1
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
1
2
21
2
2
11
2
2
11
2
2
11
2
2
11
2
2
11
2
2
11
2
2
11
2
2
11
2
2
11
2
2
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
2
1
12
1
1
22
1
1
22
1
1
22
1
1
22
1
1
22
1
1
22
1
1
22
1
1
22
1
1
22
1
1
2
(a) ModelNet40:1
123456789101112131415161718192021222324252627282930313233343536373839401
2
3
4
5
6
7
8
9
10
11
12
33
3
3
3
33
3
3
3
3
33
3
3
33
3
3
33
33
33
3
3
3
3
33
3
33
3
3
33
3
3
3
3
3
4
4
43
3
33
4
3
4
3
4
3
43
333
3
30
0
0
1
1
1
2
2
2
1
1
12
1
2
2
2
1
0
1
1
2
12
2
2
1
2
1
2
1
1
0
11
1
1
1
1
1
1
1
1
1
1
12
1
2
2
2
1
0
1
1
2
10
0
0
1
1
1
1
1
1
0
0
02
2
2
1
1
1
2
2
21
1
1
2
2
2
2
2
22
2
2
2
2
2
1
1
12
2
2
1
1
1
2
2
2
1
1
10
0
0
1
1
1
1
1
1
2
2
22
1
2
1
2
1
2
10
0
0
1
1
1
1
1
1
0
0
01
2
1
2
1
2
1
21
2
1
2
1
2
0
1
0
21
1
1
2
2
2
1
1
1
2
2
20
0
0
1
1
1
0
0
0
1
1
12
1
2
1
2
1
2
0
1
02
2
2
2
2
22
2
2
1
1
1
1
1
1
2
2
22
1
2
1
2
1
2
1
2
1
2
12
1
2
2
2
2
1
2
0
1
01
1
1
0
0
0
2
2
2
1
1
11
2
1
2
1
2
0
1
0
22
1
2
2
2
2
1
2
0
1
01
2
1
2
1
2
2
2
21
1
1
1
1
1
1
1
1
1
1
12
2
2
1
1
1
1
1
1
0
0
02
2
2
1
1
1
2
2
2
1
1
12
2
22
2
2
1
2
1
2
1
22
2
2
21
1
1
0
0
0
2
2
2
1
1
12
1
2
1
2
1
2
0
1
00
1
0
2
1
2
2
2
2
1
21
2
1
2
1
2
1
2
1
2
1
22
1
2
1
2
1
2
2
21
1
1
1
1
1
0
0
0
0
0
02
2
2
2
2
2
1
1
1
1
1
11
2
1
1
0
1
1
2
1
1
0
1
(b) ModelNet40:2
1 2 3 4 5 6 7 8 9 101
2
3
4
5
6
7
8
9
10
11
12
3
3
3
33
3
4
3
33
3
3
34
3
4
3
4
3
3
3
33
3
4
3
3
3
4
33
4
3
3
3
3
4
3
3
33
3
3
3
3
4
43
3
3
33
3
3
3
4
3
43
3
3
31
2
2
2
1
2
2
22
2
1
2
1
2
21
2
2
2
1
2
2
22
2
21
2
1
22
22
2
2
1
22
1
2
2
2
1
2
22
1
2
2
22
2
2
1
2
2
2
1
(c) Cifar-10 & EuroSAT
Figure 11: The illustration of how many clients (the numbers in boxes) possess the training data of each feature
block in each class for the settings in Section 4, with a) ModelNet40:1 with d0= 4features,M= 4clients, and 40
classes; b) ModelNet40:2 with d0= 12features,M= 8clients, and 40 classes; c) Cifar-10 & EuroSAT with d0= 12
features,M= 9clients, and 10 classes. The x-axis of each plot is the class axis and y-axis is the feature axis.
28Published in Transactions on Machine Learning Research (04/2024)
123456789101112131415161718192021222324252627282930313233343536373839401
2
3
4
6
64
45
54
44
44
44
45
54
45
56
65
56
64
44
45
54
44
45
54
45
55
52
23
0
3
13
2
3
02
1
2
13
2
3
12
23
1
3
13
1
3
13
2
3
12
13
1
3
12
11
12
13
1
3
12
0
2
01
12
0
2
22
12
0
2
22
1
2
01
11
22
21
22
21
22
12
21
13
0
3
12
22
0
2
12
13
1
3
11
12
21
23
0
3
23
2
3
0
(a) ModelNet40
1 2 3 4 5 6 7 8 9 101
2
3
4
3
1
3
13
1
3
13
1
3
13
1
3
13
1
3
13
1
3
13
1
3
13
1
3
13
1
3
13
1
3
1
(b) Cifar-10 & EuroSAT
Figure 12: The illustration of how many clients (the numbers in boxes) possess the training data of each feature
block in each class for the settings in Appendix C.1, with a) ModelNet40 with d0= 4features,M= 6clients, and
40 classes; c) Cifar-10 & EuroSAT with d0= 4features,M= 6clients, and 10 classes. The x-axis of each plot is the
class axis and y-axis is the feature axis.
(a) Server
 (b) Client
Figure 13: Test accuracy of a) server model, b) client models trained with HyFEM compared with Centralized
training and stand-alone training for HeriGraph dataset.
29Published in Transactions on Machine Learning Research (04/2024)
(a) Server
Figure 14: Test accuracy of a) server model, b) client models trained with HyFEM compared with Centralized
training on ModelNet40:2 under different µ2.
30