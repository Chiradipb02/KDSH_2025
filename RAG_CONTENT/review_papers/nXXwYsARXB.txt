A hierarchical decomposition for explaining ML
performance discrepancies
Harvineet Singh1Fan Xia1Adarsh Subbaswamy2Alexej Gossmann2Jean Feng1∗
1University of California, San Francisco
2U.S. Food and Drug Administration, Center for Devices and Radiological Health
Abstract
Machine learning (ML) algorithms can often differ in performance across domains.
Understanding whytheir performance differs is crucial for determining what types
of interventions (e.g., algorithmic or operational) are most effective at closing
the performance gaps. Aggregate decompositions express the total performance
gap as the gap due to a shift in the feature distribution p(X)plus the gap due
to a shift in the outcome’s conditional distribution p(Y|X). While this coarse
explanation is helpful for guiding root cause analyses, it provides limited details
and can only suggest coarse fixes involving all variables in an ML system. De-
tailed decompositions quantify the importance of each variable to each term in the
aggregate decomposition, which can provide a deeper understanding and suggest
more targeted interventions. Although parametric methods exist for conducting a
full hierarchical decomposition of an algorithm’s performance gap at the aggregate
and detailed levels, current nonparametric methods only cover parts of the hier-
archy; many also require knowledge of the entire causal graph. We introduce a
nonparametric hierarchical framework for explaining why the performance of an
ML algorithm differs across domains, without requiring causal knowledge. Fur-
thermore, we derive debiased, computationally-efficient estimators and statistical
inference procedures to construct confidence intervals for the explanations.
1 Introduction
The performance of an ML algorithm can differ across domains due to shifts in the data distribution.
Understanding what contributed to this performance gap can help teams choose the most effective
corrective action(s), ranging from algorithmic modifications (e.g. model retraining) to operational
fixes (e.g. updating data pipelines). Prior works have focused primarily on aggregate decompositions,
which decompose the performance gap into that due to a shift in the marginal distribution of the
input features p(X)(covariate shift [ 37]) and that due to a shift in the conditional distribution of the
outcome p(Y|X)(concept shift or conditional outcome shift) [ 5,50,30,36,16]. However, coarse
decompositions can only suggest coarse corrective actions, such as investigating data pipelines for
all features. The goal of this work is to provide a hierarchical nonparametric framework that first
decomposes a performance gap into aggregate terms and then each aggregate term into detailed terms.
This helps narrow down the features to investigate and understand how they affect the gap.
If one is willing to make the strong assumption that the expected loss of a model is a linear function
of some feature set X, the problem of obtaining aggregate anddetailed decompositions drastically
simplifies. This is the key assumption underlying the Oaxaca-Blinder (OB) decomposition, one of the
most widely used frameworks in the (income and health) disparities literature [32, 3]. Given an ML
∗Corresponding author: jean.feng@ucsf.edu
38th Conference on Neural Information Processing Systems (NeurIPS 2024).Figure 1: ( left) Proposed framework called Hierarchical Decomposition of Performance Differences
(namely, HDPD) helps to understand performance gaps of an ML algorithm between two domains. It
decomposes the overall gap (say, in classification accuracy) into gaps due to shifts in the covariate
versus outcome distribution (Aggregate). Then, it quantifies the importance of each feature to the
two components (Detailed). ( right ) In terms of directed acyclic graphs, aggregate decompositions
describe the effect of shift interventions, for instance, on the outcome Ydistribution while keeping
all else fixed between domains. Detailed decompositions quantify how well can we explain those
shift interventions by more targeted shifts with respect to feature subsets Zsalone.
model with average loss ED[ℓ]in domains D= 0and1and assuming the linear loss relationship
ED[ℓ|X] =β⊤
DX, the OB framework decomposes the performance gap at the aggregate level into
that due to a covariate shift ( β⊤
0(E1[X]−E0[X])) and that due to a conditional outcome shift
((β1−β0)⊤E1[X]). That is, the former is due to a shift in the feature means and the latter is due
to a shift in the coefficients. At the detailed level, the aggregate terms corresponding to covariate
and conditional outcome shifts are further broken down into the contributions from each feature, i.e.
β0,j(E1[Xj]−E0[Xj])and(β1,j−β0,j)E1[Xj], respectively. Although the highly intuitive nature of
the OB framework has led to its widespread popularity, the terms are difficult to interpret under model
misspecification. As such, this work aims to define a similar hierarchical decomposition framework
for explaining ML performance disparities, without making strong parametric assumptions .
There is currently no unified, nonparametric framework that obtains aggregate and detailed decompo-
sitions. Instead, solutions have been proposed for parts of the hierarchy (see Table 1): nonparametric
methods exist for the aggregate decomposition [ 5,30,48] and, assuming the causal graph is known,
detailed decompositions of the covariate shift [ 40,44,50,38,4,23]. However, the causal graph is
unlikely to be known in high-dimensional settings and, more importantly, there are no methods for
simultaneously obtaining a detailed decomposition of the conditional outcome shift. There are also
methods that do not decompose the performance gap and instead describe distribution shifts in the
variables [ 29] or model explanations [ 12,31,23]. However, such approaches do not quantify how
such shifts ultimately contribute to an ML performance gap. We make the following contributions.
•We introduce a unified hierarchical nonparametric framework for decomposing the performance
gap of an ML algorithm (Fig 1 left). Using the concept of partial distribution shifts, we generalize
shifts with respect to variable subgroups to encompass not only covariate shifts but also conditional
outcome shifts. We then introduce a unified scoring rule for (candidate) partial shifts, which can be
used even when the causal graph is not known.
•We derive novel debiased and asymptotically normal estimators for terms in the decomposition,
which allow us to construct confidence intervals (CIs) with asymptotically valid coverage rates .
•We demonstrate the utility of our framework in real-world examples of prediction models for
hospital readmission and insurance coverage. Code for reproducing experiments is available at
https://github.com/jjfeng/HDPD .
2 A unifying framework for explaining performance gaps
Notation. Consider a prediction algorithm f:X ⊆Rm→[0,1]for binary outcomes Yacross
source and target domains, denoted by D= 0 andD= 1, respectively. Let the performance of
fbe quantified in terms of a loss function ℓ:X × { 0,1} →R, such as the 0-1 misclassification
loss 1{f(X)̸=Y}. Suppose variables Xcan be partitioned into disjoint sets W∈Rm1and
Z=X\W∈Rm2, where m=m1+m2. Although our framework does not require knowing the
causal ordering between variables, the interpretation is more intuitive when Wis causally upstream
2Table 1: Comparison of HDPD to prior works that decompose ML performance gaps. The distin-
guishing contribution of this work is that it unifies aggregate and detailed decompositions under a
nonparametric framework with uncertainty quantification.
Papers Aggregate
decomp.Detailed decomp. for Does not require
causal graphConfidence
intervalsNonparametric
p(X)-shift p(Y|X)-shift
Zhang et al. [50] ✓ ✓ ✓
Cai et al. [5] ✓ ✓ ✓ ✓
Quintas-Martinez et al. [38] ✓ ✓ ✓ ✓
Wu et al. [48] ✓ ✓ ✓
Liu et al. [30] ✓ ✓ ✓ ✓
Dodd and Pepe [11] ✓ ✓ ✓
Oaxaca [32], Blinder [3] ✓ ✓ ✓ ✓ ✓
HDPD (this paper) ✓ ✓ ✓ ✓ ✓ ✓
ofZandY(Fig 1 right). Variables Zcan be chosen to be mediators or modifiers of the effect of
the domain shift DonY. For instance, if Zare treatment variables and Ware baseline variables,
one can interpret a covariate shift as a change in the treatment policy and an outcome shift as a
change in the treatment effect across the two environments. In absence of any causal knowledge,
another option is to choose Was the variables for which one would like the expected loss given W
to be invariant across the two environments; this can be useful to promote fairness of ML algorithms
across environments. When this invariance does not hold, the framework explains how variables Z
contribute to these differences. We refer to Was baseline variables and Zas conditional covariates.
Please refer to Appendix C for more discussion on choosing WandZas well as a summary of
notation (Table 2).
Our proposed hierarchical decomposition of an ML performance gap is based on a stratification of
distribution shifts into aggregate andpartial shifts. At the aggregate level, the joint distribution of
(W, Z, Y )can be factorized with respect to the aggregate variable groups W, Z, andY, i.e.
pDW(W)pDZ(Z|W)pDY(Y|W, Z), (1)
where subscripts DW, DZandDYindicate the domain of that factor. An aggregate shift substitutes a
factor from the source domain in (1)with that from the target domain, i.e. we swap the factor from
p0top1. Apartial shift with respect to variable subset s(or an s-partial shift) shifts a factor from the
source domain in (1)only with respect to variable subset s; we denote this by swapping a factor from
p0tops. (We keep the precise definition of s-partial shifts purposely vague until Section 2.2.) We
denote expectations with respect to the joint distribution (1) as EDWDZDY.
The overall performance gap between domains, Λ =E111[ℓ(W, Z, Y )]−E000[ℓ(W, Z, Y )],can be
decomposed hierarchically as follows. In the Appendix D, we also discuss how this decomposition
can be interpreted causally under certain conditions.
Aggregate. At the first level of the hierarchy, the framework quantifies how aggregate shifts contribute
to the performance gap individually. This leads to the decomposition Λ = Λ W+ Λ Z+ Λ Y, where ΛW
quantifies the impact of a shift in the baseline distribution p(W),ΛZquantifies the impact of a shift in
the conditional covariate distribution p(Z|W), and ΛYquantifies the impact of a shift in the outcome
distribution p(Y|W, Z). More concretely,
ΛW=E100[ℓ]−E000[ℓ]
ΛZ=E110[ℓ]−E100[ℓ] =E1··
E·10[ℓ|W]−E·00[ℓ|W]| {z }
∆·10(W)
ΛY=E111[ℓ]−E110[ℓ] =E11·
E··1[ℓ|W, Z]−E··0[ℓ|W, Z]| {z }
∆··0(W,Z)
.
The same (or similar) aggregate decompositions have also appeared in prior works [ 5,30,15,50,38].
Detailed. At the detailed level, each aggregate term is further broken down into variable-level
attributions. The effect of each variable can be isolated using partial shifts. However, because
variables can interact to induce complex partial distribution shifts, we define variable importance
(VI) using the Shapley attribution framework [ 41,6,31,17], which has the benefits of satisfying
axiomatic properties such as fairness, monotonicity, and full attribution. Thus, given a real-valued
value function vthat quantifies the contribution of an s-partial shift to an aggregate shift for all
3s⊆ {1,···, m}, the attribution to variable jis the average gain in value when additionally shifting
with respect to j, i.e.
ϕj:=1
mX
s⊆{1,···,m}\j 
m−1
|s|!−1
{v(s∪j)−v(s)}. (2)
Interpretation. Such VI values can help ML teams identify the underlying cause(s) for a performance
gap and design targeted operational and/or algorithmic interventions. For instance, a variable with
high importance to the conditional covariate shift term ΛZmay indicate differences in the variable’s
missingness rates, prevalence, or selection bias across domains. If instead the variable is highly
important to the conditional outcome shift term ΛY, it may indicate inherent differences in the
conditional distribution (i.e. effect modification), differences in measurement error or the way
outcome is defined between domains, or omission of variables predictive of the outcome. Finally,
note that variable importances should be viewed as relative to the variables included in the framework
rather than absolute importances, as one cannot include all possible explanatory variables.
To define VI values, the key question is how to define a value function vthat is applicable to
different types of s-partial shifts, even when the causal graph is not known. It turns out that the
answer is far from straightforward. The next section discusses how the value function and candidate
s-partial shifts must be defined with care.
2.1 Value of partial distribution shifts
When the true causal graph is known, prior works define an s-partial covariate shift as the substitution
of nodes swith mechanisms from the target domain and its value v(s)as the difference in the average
loss, e.g. E1s0[ℓ]−E100[ℓ][50,38]. However, this has a number of limitations: (i) knowing the
entire causal graph is often impractical, (ii) in the absence of such a graph, this value function is not a
proper scoring rule and can assign high values to partial shifts that contradict the true causal graph
(see Example E.1 for details), and (iii) v(s)can be high even if the shift does not induce similar shifts
in the loss as the aggregate shift.
Instead, we propose to evaluate candidate s-partial shifts by how closely they approximate aggregate
shifts, using a nonparametric extension of the traditional R2measure. In the case of conditional
covariate shifts, an aggregate shift induces a performance difference of ∆·10(W)in strata Wwhile
a candidate s-partial shift induces a performance difference of ∆·s0(W) =E·s0[ℓ|W]−E·00[ℓ|W].
The value of this s-partial shift is then the percent variation of ∆·10explained by ∆·s0, i.e.
vZ(s) := 1 −E1··h
(∆·s0(W)−∆·10(W))2i
E1··[∆2
·10(W)]. (3)
Likewise, for conditional outcome shifts, an aggregate shift induces a performance difference of
∆··1(W, Z)in strata (W, Z)while a candidate s-partial shift induces a performance difference of
∆··s(W, Z) =E··s[ℓ|W, Z]−E··0[ℓ|W, Z]. The value of this s-partial conditional outcome shift is
then defined as the percent variation of ∆··1explained by ∆··s, i.e.
vY(s) := 1 −E11·h
(∆··s(W, Z)−∆··1(W, Z))2i
E11·[∆2
··1(W, Z)]. (4)
This formulation of the value function in terms of R2provides a unified way to score partial
conditional covariate and outcome shifts, does not require knowledge of the true causal graph, and is
a strictly proper scoring rule under certain conditions (see Appendix E). In general, we expect the
highest scoring candidate s-partial shifts to be those that are close to the true causal graph andinduce
large shifts in the ML algorithm’s loss. Finally, we acknowledge one caveat with this framework:
because some variables must be held out to define the R2measure, we cannot score partial shifts in
the baseline variables W. We hope to close this gap in future work.
2.2 Candidate partial distribution shifts
We now present the set of candidate partial shifts considered in this work. High-level illustrations
for the candidate partial shifts are given in Fig 1 right top; more detailed illustrations are given in
4Fig 4 of the Appendix. We emphasize that these are candidates , as the true causal graph is not known.
While there are certainly other partial shifts that one may consider, many have various disadvantages.
As such, we leave the investigation of other partial shifts to future work.
s-partial conditional covariate shift : Suppose Z−sis downstream of Zs. Then ps(z|w) :=
p1(zs|w)p0(z−s|zs, w). Wu et al. [48] considered a similar proposal.
s-partial conditional outcome shift : Shifting the conditional distribution of Yonly with respect to a
variable subset Zsbut not Z−srequires care. We cannot simply define ps(Y|W, Z)as a function of
onlyWandZs. Such a definition would imply that an s-partial shift has a non-zero effect, even in
settings with no shift in the conditional outcome distribution (i.e. p1(Y|W, Z)≡p0(Y|W, Z)).
Instead, we define an s-partial outcome shift based on models commonly used in model recalibra-
tion/revision [ 42,34], where the modified risk (conditional probability of Y) is a function of the risk
in the source domain Q:=q(W, Z) :=p0(Y= 1|W, Z),W, andZs. That is, we define the shift as
ps(y|z, r, w ) :=p1(y|zs, r, w) =Z
p1(y|˜z−s, zs, w)p1(˜z−s|zs, q(w, zs,˜z−s) =r, w)d˜z−s(5)
By defining the shifted outcome distribution solely as a function of Q, W , and Zs, any direct
effect from Z−stoYis eliminated and pshas the desired behavior in the setting where there is no
conditional outcome shift.
3 Estimation and statistical inference
Here we discuss estimation and statistical inference for the aggregate terms ( ΛW,ΛZ, andΛY), the value
functions vZ(s)andvY(s), and the Shapley-based detailed terms ϕZ,jandϕY,jforj∈(0,···, m2).
One approach is to rely on plug-in estimators, which plug in estimates of conditional means (also
called outcome models) or density ratios [ 43], which we collectively refer to as nuisance parameters.
For instance, one can estimate the conditional means µ·10(w) =E·10[ℓ|W]andµ·00(w) =E·00[ℓ|W]
using ML and take the empirical mean of ˆµ·10−ˆµ·00with respect to the target domain to get a
plug-in estimator for ΛZ=E1··[µ·10−µ·00]. However, because estimation of the true nuisance
parameters using ML typically converge at a rate slower than n−1/2, plug-in estimators generally fail
to be consistent at a rate of n−1/2and cannot be used to construct CIs [25].
To this end, we use the method of one-step correction from semiparametric inference to derive
debiased ML estimators [ 45,7]. The core idea is to subtract the first-order bias of a plug-in estimator,
which requires characterizing the canonical gradient (or efficient influence function) of the estimand
[25]. The primary technical contribution in this section is the derivation of debiased estimators for the
detailed decompositions. (Estimation and inference for the aggregate decomposition is well-studied,
as the aggregate terms can be formulated as average causal effects.) Due to space limitations, this
section only presents estimators for the detailed decomposition of the conditional outcome shift. This
estimand is particularly interesting, as its unique structure is not amenable to standard techniques
for debiasing ML estimators. We refer the reader to the Appendix for derivations, pseudocode, and
proofs for all the estimators.
Notation. LetPDdenote the expectation with respect to domain D. For ease of exposition, suppose
the number of IID observations from each domain is the same, denoted by n. We present split-sample
estimators, though the results can be readily extended using cross-fitting [ 7,25]. Let the data be
randomly split into “training” and “evaluation” partitions. Let PD,ndenote the empirical average in
the evaluation partition for domain D. All estimated quantities are denoted using hat notation.
3.1 Value of s-partial conditional outcome shifts
Here we describe the high-level steps for deriving a debiased estimator for vY(s), the value of a
candidate s-partial conditional outcome shift. The following section describes a computationally
efficient procedure for combining such estimates to obtain Shapley values.
Standard recipes for deriving asymptotically normal, nonparametric-efficient estimators rely on
pathwise differentiability of the estimand and analyzing its efficient influence function [ 25]. However,
vY(s)is not pathwise differentiable because it is a function of (5), which conditions on the source risk
q(w, z)equalling some value r. Taking the pathwise derivative of vY(s)requires taking a derivative
5of the indicator function 1{q(w, z) =r}, which generally does not exist. Given the difficulties in
deriving an asymptotically normal estimator for vY(s), we propose estimating a close alternative that
ispathwise differentiable.
The idea is to replace qin(5)with its binned variant qbin(w, z) =1
B⌊q(w, z)B+1
2⌋for some
B∈Z+, which discretizes outputs from qintoBdisjoint bins. As long as Bis sufficiently high, the
binned version of the estimand, denoted vY,bin(s), is a close approximation to vY(s). (We use B= 20
in the empirical analyses, which we believe to be sufficient in practice.) The benefit of this binned
variant is that the derivative of the indicator function 1{qbin(w, z)=r}is zero almost everywhere as
long as observations with source risks exactly equal to a bin edge have measure zero. More formally,
we require the following:
Condition 3.1. LetΞbe the set of (W, Z)such that q(W, Z)falls precisely on some bin edge and is
not equal to zero or one. The set Ξis measure zero.
Under this condition, vY,bin(s)is pathwise differentiable and, using one-step correction, we derive a
debiased ML estimator that has the unique form of a V-statistic (this follows from the integration
over “phantom” ˜z−sin(5)). We represent V-statistics using the operator P1,n˜P1,n, which takes the
average over all pairs of observations Oiwith replacement, i.e.1
n2Pn
i=1Pn
j=1g(Oi, Oj)for some
function g. Calculation of this estimator and its theoretical properties are as follows.
Estimation. Using the training partition, estimate the outcome models µ··D(W, Z) =E··D[ℓ|W, Z]
forD= 0,1, the shifted outcome model µ··s(W, Z) =E··s[ℓ|W, Z]; and the density ratio mod-
elsπ110(W, Z) =p1(W, Z)/p0(W, Z)andπ(W, Z s, Z−s, Qbin) =p1(Z−s|W, Z s, qbin(W, Z) =
Qbin)/p1(Z−s). The outcome and density ratio models can be fit using ML-based regression models
and probabilistic classifiers [ 43], respectively (see Section H for details). The estimator for vY,bin(s)
is the ratio ˆvY,bin(s) = ˆvnum
Y,n(s)/ˆvden
Y,n, where the numerator and denominator are estimated using the
evaluation partition as
ˆvnum
Y,n(s) =P1,nˆξs(W, Z )2+ 2P1,nˆξs(W, Z )(ℓ−ˆµ··1(W, Z ))
−2P1,n˜P1,nˆξs(W, Z s,˜Z−s)ℓ(W, Z s,˜Z−s, Y)ˆπ(W, Z s,˜Z−s, Qbin)
+ 2P1,n˜P1,nˆξs(W, Z s,˜Z−s)ˆµ··s(W, Z s,˜Z−s)ˆπ(W, Z s,˜Z−s, Qbin) (6)
ˆvden
Y,n=P1,n(ˆµ··1(W, Z )−ˆµ··0(W, Z ))2+ 2P1,n(ˆµ··1(W, Z )−ˆµ··0(W, Z )) (ℓ−ˆµ··1(W, Z ))
−2P0,n(ˆµ··1(W, Z )−ˆµ··0(W, Z )) (ℓ−ˆµ··0(W, Z ))ˆπ110(W, Z ), (7)
where ˆξs(W, Z) = ˆµ··1(W, Z)−ˆµ··s(W, Z). Note that the first terms in (6)and(7)are the plug-in
estimates, followed by additional terms that correct its bias.
Inference. This estimator is asymptotically normal assuming the estimators for the nuisance parame-
ters converge at a fast enough rate, per the following theorem.
Theorem 3.2. Suppose Condition 3.1 holds. For variable subset s, suppose the density ratios
π(W, Z s, Z−s, Qbin)andπ110(W, Z)are bounded; denominator in case of no shift vden
Y(∅)>0;
estimator ˆπis consistent; estimators ˆµ··0,ˆµ··1andˆµ··sconverge at an op(n−1/4)rate, and
P1(ˆqbin−qbin)2=op(n−1) (8)
P1(µ··s−ˆµ··s)(π−ˆπ) =op(n−1/2),P0(µ··0−ˆµ··0)(π110−ˆπ110) =op(n−1/2) (9)
Then the estimator ˆvY,bin(s)is asymptotically normal centered at the estimand vY,bin(s).
Note that the product terms in (9)mean that the estimator converges to normal at n−1/2-rate even if
one of the nuisance parameters is estimated at a rate slower than n−1/2. Hence, it is multiply-robust to
nuisance model misspecification. A convergence rate of op(n−1/4)can be achieved by ML estimators
in a wide variety of conditions, and such assumptions are commonly used to construct debiased ML
estimators. The additional requirement in (8)thatˆqbinconverges at a op(n−1)rate is new, but fast or
even super-fast convergence rates of binned risks is achievable under suitable margin conditions [ 2]
such as Condition G.7 in the Appendix.
3.2 Shapley values
Calculating the exact Shapley value is computationally intractable as it involves an exponential
number of terms. However, Williamson and Feng [47] showed that calculating the exact Shapley
60.00.51.0CoverageSubset = {Z1}
0.00.51.0CoverageSubset = {Z2}
20004000800016000
n0.00.51.0CoverageSubset = {Z3}
Plug-in
Debiased ML
0.00.51.0CoverageSubset = {Z1}
0.00.51.0CoverageSubset = {Z2}
20004000800016000
n0.00.51.0CoverageSubset = {Z3}(a)(i) Conditional covariate
(ii) Conditional outcome
(b)
Figure 2: (a) Coverage rates of 90% CIs for value of s-partial shifts for the conditional covariate (first
column) and outcome shifts (second column) across dataset sizes n. Dashed horizontal line indicates
90% coverage rate. (b) Comparison of variable importance reported by proposed method HDPD
(debiased) versus existing methods for conditional covariate and outcome shift terms.
value is unnecessary for the purposes of statistical inference. Because there is inherent uncertainty in
estimates of the value functions v(s), one only needs to sample and estimate the values for enough
variable subsets such that the uncertainty due to estimation dominates that due to subset sampling.
This leads to a drastic reduction in computation time: Williamson and Feng [47] proves that the
number of subsets one needs to sample only needs to be linear or super-linear in the total number
of observations n. Using this result, Algorithm 4 outlines a computationally efficient procedure for
estimation and inference of the detailed decomposition.
4 Simulation
We now present simulations to show that the proposed procedure achieves the desired coverage
rates (Section 4.1) and illustrate how the HDPD framework provides more intuitive explanations
of performance gaps (Section 4.2). In all empirical analyses, performance of the ML algorithm is
quantified in terms of 0-1 accuracy. Below, we briefly describe the simulation settings; full details are
provided in Section I in the Appendix.
4.1 Verifying theoretical properties
We first verify that the inference procedures for the decomposition terms have CIs with coverage close
to their nominal rate. We check the coverage of the aggregate decomposition as well as the value
ofs-partial conditional covariate and partial conditional outcome shifts for s={Z1},{Z2},{Z3}.
(W, Z 1, Z2, Z3)are sampled from independent normal distributions with different means in source
and target, while Yis simulated from logistic regression models with different coefficients. CIs for
the debiased ML estimator converge to the nominal 90% coverage rate with increasing sample size,
whereas those for the naïve plug-in estimator do not (Fig 2a and Fig 6).
4.2 Comparing explanations
We now compare the proposed definitions for the detailed decomposition with existing methods. For
the detailed decomposition due to conditional covariate shift, the comparators are:
•MeanChange Tests for a difference in means for each feature. Defines importance as 1−p-value.
•Oaxaca-Blinder : Fits a linear model of the logit-transformed expected loss with respect to Zin
the source domain. Defines importance of Zias its coefficient multiplied by the difference in the
means of Zi[32, 3].
•WuShift [48]: Defines importance of subset sas change in overall performance due to s-partial
conditional covariate shifts. Applies Shapley framework to obtain VIs.
7(a) Readmission risk (General →Heart Failure) (b) Insurance coverage (NE →LA)
Figure 3: Aggregate and detailed decompositions for performance gaps of (a) a model predicting
readmission risk across patient populations and (b) a model predicting insurance coverage across US
states. A subset of VI estimates is shown; see full list in Section J in the Appendix.
For the detailed decomposition due to conditional outcome shifts, we compare against:
•ParametricChange : Fits a logistic model for Ywith interaction terms between domain and Z.
Defines importance of Zias the coefficient of its interaction term.
•ParametricAcc : Same as ParametricChange but models the 0-1 loss rather than Y.
•RandomForestAcc : Compares VI of random forest models trained on data from both domains
with input features D,Z, and Wto predict the 0-1 loss.
•Oaxaca-Blinder : Fits linear models for the logit-transformed expected loss in each domain.
Defines importance of Zias its mean in the target domain multiplied by the difference in its
coefficients across domains.
Although the proposed method may agree with these other methods on the top features in certain data
settings, we highlight important situations where the methods differ.
Conditional covariate. (Fig 2b(i)) We simulate (W, Z 1)from a standard normal distribution,
Z2from a mixture of two Gaussians whose means depend on the value of Z1(i.e.Z1→Z2),
andYfrom a logistic regression model depending on (W, Z 1, Z2). We induce a shift from the
source domain to the target domain by shifting only the distribution of Z1, so that p1(Z|W) =
p0(Z2|Z1, W)p1(Z1|W). Only the proposed estimator correctly recovers that Z1is more important
thanZ2, as the {1}-partial conditional covariate shift explains all the variation in performance gaps
across strata W(i.e. the corresponding R2-based value function vZ({1})is equal to 1). The other
methods incorrectly assign higher importance to Z2.MeanChange only measures shifts but not
loss due to shifts, Oaxaca-Blinder uses a misspecified linear model, and WuShift estimates the
performance change due to hypothesized s-partial shifts but does not check if the partial shifts are
good explanations in the first place.
Conditional outcome. (Fig 2b(ii)) WandZ∈R4are simulated from the same distribution in
both domains. Yis generated from a logistic regression model with coefficients for (W, Z 1,···, Z4)
as(0.5,0.5,1,0.3,0.3)in the source and (0.5,0.3,1,1.3,−0.1)in the target. Interestingly, none of
the methods have the same ranking of the features. ParametricChange identifies Z1as having
the largest shift on the logit scale, but this does not mean that it is the most important explanation
for changes in the loss. According to our decomposition framework, Z3is actually the most
important for explaining changes in model performance due to outcome shifts. Oaxaca-Blinder ,
ParametricAcc , and RandomForestAcc have odd behavior. Oaxaca-Blinder assigns Z3second
to the lowest importance and ParametricAcc assigns Z2the highest importance), likely because
they misspecify the outcome models. RandomForestAcc likely ranks Z2highly because its VI
values quantify which variables are good predictors of performance, not performance shift.
A more objective evaluation is to compare the performance of fixes based on the different explanations.
To this end, we re-fit the ML algorithm in the target domain with respect to input features Q, W ,
and the top variables Zsfrom each explanation. We find that model revisions based on the proposed
method achieve the highest performance gain (Table 3 in Appendix).
85 Real-world data case studies
We now demonstrate applicability of the framework on two datasets with naturally-occurring shifts.
Hospital readmission. Using electronic health record data from the Zuckerberg San Francisco
General Hospital, we analyzed performance of a Gradient Boosted Tree (GBT) trained on the general
patient population (source) to predict 30-day readmission risk but applied to patients diagnosed with
heart failure (HF, target). Features include 4 demographic variables ( W) and 16 diagnosis codes ( Z).
Each domain supplied n= 3750 observations from which we keep 20% in the evaluation partition.
Model accuracy drops from 70% to 53% in HF population. From the aggregate decompositions
(Fig 3a), we observe that the drop is mainly due to covariate shift. If one performed the standard
check to see which variables significantly changed in their mean value ( MeanChange ), then one
would find a significant shift in nearly every variable. Little support is offered to identify main drivers
of the performance drop. In contrast, the detailed decomposition from the proposed framework
estimates diagnoses “Drug-induced or toxic-related condition” and “Mental & substance use disorder
in remission” as having the highest estimated contributions to the conditional covariate shift, and most
other variables having little to no contribution. Upon discussion with clinicians from this hospital,
differences in the top two diagnoses may be explained by (i) substance use being a major cause of HF
at this hospital, with over eighty percent of its HF patients reporting current or prior substance use,
and (ii) substance use and mental health disorders often occurring simultaneously in this HF patient
population. Based on these findings, closing the performance gap may require a mixture of both
operational (e.g. care programs centered around substance use) and algorithmic interventions (e.g.
reweighting data with respect to the top two features). Finally, CIs from the debiased ML procedure
provide valuable information on the uncertainty of the estimates and highlight, for instance, that more
data is necessary to determine the true ordering between the top two features. In contrast, existing
methods do not provide (asymptotically valid) CIs.
ACS Public Coverage. We analyze a neural network trained to predict whether a person has public
health insurance using data from Nebraska in the American Community Survey (source, n= 3000 ),
applied to data from Louisiana (target, n= 6000 ). Baseline variables include 3 demographics (sex,
age, race), and covariates Zinclude 31 variables related to health conditions, employment, marital
status, citizenship status, and education.
Model accuracy drops from 84% to 66% across the two states. The main driver is the shift in the
outcome distribution per the aggregate decomposition (Fig 3b) and the most important contributor
to the outcome shift is annual income, perhaps due to differences in cost of living across the two
states. Income is significantly more important than all the other variables; the ranking between the
remaining variables is unclear. In comparing the performance of targeted model revisions, we find
that revising the model based on top variables identified by the proposed procedure leads to AUCs
that are better or as good as those based on RandomForestAcc (Table 4 in the Appendix).
6 Prior work
Describing distribution shifts. This line of work focuses on detecting and localizing which distribu-
tions shift between datasets [ 29,39]. Budhathoki et al. [4]identify the main variables contributing
to a distribution shift via a Shapley framework, Kulinski and Inouye [28] fits interpretable optimal
transport maps, and Liu et al. [30] finds the region with the largest shift in the conditional out-
come distribution. However, these works do not quantify how these shifts contribute to changes in
performance , the metric of practical importance.
Explaining loss differences across subpopulations. Understanding differences in model perfor-
mance across subpopulations in a single dataset is similar to understanding differences in model
performance across datasets, but the focus is typically to findsubpopulations with poor performance
rather than to explain how distribution shifts contributed to the performance change. Existing ap-
proaches include slice discovery methods [ 35,22,10,13] and structured representations of the
subpopulation using e.g. Euclidean balls [1].
Attributing performance changes. Prior works have described similar aggregate decompositions of
the performance change into covariate and conditional outcome shift components [ 5,36]. To provide
more granular explanations of performance shifts, existing works on causal attribution [ 50,38] and
9mediation analysis [ 44] quantify the importance of shifts in each variable assuming the causal graph is
correctly specified; covariate shifts restricted to variable subsets assuming that the partial shifts follow
a particular structure [ 48]; and conditional shifts in each variable assuming a parametric model [ 11].
However, the strong assumptions made by these methods make them difficult to apply in practice,
and model misspecification can lead to unintuitive interpretations. Furthermore, such methods do not
provide hierarchical decompositions, i.e. VIs for each type of shift. Decomposition methods such
as Oaxaca-Blinder similarly make strong parametric assumptions [ 32,3,16,14,49,15], which is
inappropriate for the complex data settings in ML. In addition, there is no unifying nonparametric
framework for decomposing both covariate and outcome shifts, and many methods do not output CIs,
which is important when the amount of labeled data from a given domain is limited. A summary of
how the proposed framework compares against prior works is shown in Table 1.
7 Discussion
ML algorithms regularly encounter distribution shifts in practice, leading to drops in performance.
We present a novel framework that helps ML developers and deployment teams build a more
nuanced understanding of the shifts. Compared to past work, the approach provides a nonparametric
hierarchical framework for decomposing both conditional covariate and outcome shifts, does not
require fine-grained knowledge of the causal relationship between variables, and quantifies the
uncertainty of the estimates by constructing confidence intervals. We present real-world case studies
to demonstrate how this framework can help diagnose performance drops and guide corrective actions.
This framework requires overlapping support of the covariates, which may not always be applicable
in practice. In such cases, one solution is to restrict to the common support [5].
Important extensions of this work include decompositions of more complex measures of model
performance such as AUC and analyzing other factorizations of the data distribution (e.g. label/prior
shifts [ 27]). For unstructured data (e.g. image and text), the current framework can be applied to
low-dimensional embeddings or by extracting interpretable concepts [ 26]; more work is needed to
directly analyze unstructured data. Finally, while the focus of this work is to interpret performance
gaps, future work may take this work one step further to design optimal interventions for closing the
performance gap.
Acknowledgments and Disclosure of Funding
We would like to thank Lucas Zier for supplying the dataset from the Zuckerberg San Francisco
General Hospital and providing their clinical expertise to interpret results. We are grateful to Nicholas
Petrick, Berkman Sahiner, Gene Pennello, Mi-Ok Kim, Romain Pirracchio, Julian Hong, Avni
Kothari, and the anonymous reviewers for helpful feedback. This work was funded through a
Patient-Centered Outcomes Research Institute ®(PCORI ®) Award (ME-2022C1-25619). The views
presented in this work are solely the responsibility of the author(s) and do not necessarily represent
the views of the PCORI ®, its Board of Governors or Methodology Committee. The contents are
those of the author(s) and do not necessarily represent the official views of, nor an endorsement, by
FDA/HHS, or the U.S. Government.
References
[1]Alnur Ali, Maxime Cauchois, and John C. Duchi. The lifecycle of a statistical model: Model
failure detection, identification, and refitting, 2022. URL https://arxiv.org/abs/2202.
04166 .
[2]Jean-Yves Audibert and Alexandre B Tsybakov. Fast learning rates for plug-in classifiers. Ann.
Stat., 35(2):608–633, April 2007.
[3]Alan S. Blinder. Wage discrimination: Reduced form and structural estimates. The Journal
of Human Resources , 8(4):436–455, 1973. ISSN 0022166X. URL http://www.jstor.org/
stable/144855 .
[4]Kailash Budhathoki, Dominik Janzing, Patrick Bloebaum, and Hoiyi Ng. Why did the dis-
tribution change? In Arindam Banerjee and Kenji Fukumizu, editors, Proceedings of The
1024th International Conference on Artificial Intelligence and Statistics , volume 130 of Pro-
ceedings of Machine Learning Research , pages 1666–1674. PMLR, 13–15 Apr 2021. URL
https://proceedings.mlr.press/v130/budhathoki21a.html .
[5]Tiffany Tianhui Cai, Hongseok Namkoong, and Steve Yadlowsky. Diagnosing model perfor-
mance under distribution shift. March 2023. URL http://arxiv.org/abs/2303.02011 .
[6]A Charnes, B Golany, M Keane, and J Rousseau. Extremal principle solutions of games in
characteristic function form: Core, chebychev and shapley value generalizations. In Jati K
Sengupta and Gopal K Kadekodi, editors, Econometrics of Planning and Efficiency , pages
123–133. Springer Netherlands, Dordrecht, 1988.
[7]Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen,
Whitney Newey, and James Robins. Double/debiased machine learning for treatment and
structural parameters. Econom. J. , 21(1):C1–C68, February 2018.
[8]Juan Correa and Elias Bareinboim. A calculus for stochastic Interventions:Causal effect
identification and surrogate experiments. AAAI , 34(06):10093–10100, April 2020. URL
https://ojs.aaai.org/index.php/AAAI/article/view/6567 .
[9]A P Dawid. Influence diagrams for causal modelling and inference. Int. Stat. Rev. , 70
(2):161–189, August 2002. URL https://onlinelibrary.wiley.com/doi/10.1111/
j.1751-5823.2002.tb00354.x .
[10] Greg d’Eon, Jason d’Eon, James R. Wright, and Kevin Leyton-Brown. The spotlight: A
general method for discovering systematic errors in deep learning models. In 2022 ACM
Conference on Fairness, Accountability, and Transparency , FAccT ’22, page 1962–1981, New
York, NY , USA, 2022. Association for Computing Machinery. ISBN 9781450393522. doi:
10.1145/3531146.3533240. URL https://doi.org/10.1145/3531146.3533240 .
[11] Lori E Dodd and Margaret Sullivan Pepe. Semiparametric regression for the area under the
receiver operating characteristic curve. J. Am. Stat. Assoc. , 98(462):409–417, 2003.
[12] Christopher Duckworth, Francis P Chmiel, Dan K Burns, Zlatko D Zlatev, Neil M White,
Thomas W V Daniels, Michael Kiuber, and Michael J Boniface. Using explainable machine
learning to characterise data drift and detect emergent health risks for emergency department
admissions during COVID-19. Sci. Rep. , 11(1):23017, November 2021.
[13] Sabri Eyuboglu, Maya Varma, Khaled Kamal Saab, Jean-Benoit Delbrouck, Christopher Lee-
Messer, Jared Dunnmon, James Zou, and Christopher Re. Domino: Discovering systematic
errors with cross-modal embeddings. In International Conference on Learning Representations ,
2022. URL https://openreview.net/forum?id=FPCMqjI0jXN .
[14] Robert W Fairlie. An extension of the blinder-oaxaca decomposition technique to logit and
probit models. Journal of economic and social measurement , 30(4):305–316, 2005.
[15] Sergio P. Firpo, Nicole M. Fortin, and Thomas Lemieux. Decomposing wage distributions using
recentered influence function regressions. Econometrics , 6(2), 2018. ISSN 2225-1146. doi:
10.3390/econometrics6020028. URL https://www.mdpi.com/2225-1146/6/2/28 .
[16] Nicole Fortin, Thomas Lemieux, and Sergio Firpo. Chapter 1 - decomposition methods in
economics. volume 4 of Handbook of Labor Economics , pages 1–102. Elsevier, 2011. doi:
https://doi.org/10.1016/S0169-7218(11)00407-2. URL https://www.sciencedirect.com/
science/article/pii/S0169721811004072 .
[17] Amirata Ghorbani and James Zou. Data shapley: Equitable valuation of data for machine
learning. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th
International Conference on Machine Learning , volume 97 of Proceedings of Machine Learning
Research , pages 2242–2251. PMLR, 09–15 Jun 2019. URL https://proceedings.mlr.
press/v97/ghorbani19c.html .
[18] Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and estimation.
Journal of the American Statistical Association , 102(477):359–378, 2007. doi: 10.1198/
016214506000001437. URL https://doi.org/10.1198/016214506000001437 .
11[19] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural
networks. International Conference on Machine Learning , 70:1321–1330, 2017.
[20] Oliver Hines, Karla Diaz-Ordaz, and Stijn Vansteelandt. Variable importance measures for
heterogeneous causal effects. April 2022.
[21] John W Jackson. Meaningful causal decompositions in health equity research: definition,
identification, and estimation through a weighting framework. Epidemiology , 32(2):282–290,
2021.
[22] Saachi Jain, Hannah Lawrence, Ankur Moitra, and Aleksander Madry. Distilling model
failures as directions in latent space. In The Eleventh International Conference on Learning
Representations , 2023. URL https://openreview.net/forum?id=99RpBVpLiX .
[23] Yonghan Jung, Shiva Kasiviswanathan, Jin Tian, Dominik Janzing, Patrick Bloebaum, and Elias
Bareinboim. On measuring causal contributions via do-interventions. In Kamalika Chaudhuri,
Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings
of the 39th International Conference on Machine Learning , volume 162 of Proceedings of
Machine Learning Research , pages 10476–10501. PMLR, 17–23 Jul 2022. URL https:
//proceedings.mlr.press/v162/jung22a.html .
[24] Joseph D. Y . Kang and Joseph L. Schafer. Demystifying Double Robustness: A Comparison
of Alternative Strategies for Estimating a Population Mean from Incomplete Data. Statistical
Science , 22(4):523 – 539, 2007. doi: 10.1214/07-STS227. URL https://doi.org/10.1214/
07-STS227 .
[25] Edward H Kennedy. Semiparametric doubly robust targeted double machine learning: a review.
March 2022.
[26] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Viegas,
and Rory sayres. Interpretability beyond feature attribution: Quantitative testing with concept
activation vectors (TCA V). In Jennifer Dy and Andreas Krause, editors, Proceedings of the
35th International Conference on Machine Learning , volume 80 of Proceedings of Machine
Learning Research , pages 2668–2677. PMLR, 10–15 Jul 2018. URL https://proceedings.
mlr.press/v80/kim18d.html .
[27] Wouter M. Kouw and Marco Loog. An introduction to domain adaptation and transfer learning,
2019.
[28] Sean Kulinski and David I. Inouye. Towards explaining distribution shifts. In Andreas Krause,
Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett,
editors, Proceedings of the 40th International Conference on Machine Learning , volume 202
ofProceedings of Machine Learning Research , pages 17931–17952. PMLR, 23–29 Jul 2023.
URL https://proceedings.mlr.press/v202/kulinski23a.html .
[29] Sean Kulinski, Saurabh Bagchi, and David I Inouye. Feature shift detection: Localizing which
features have shifted via conditional distribution tests. In H. Larochelle, M. Ranzato, R. Had-
sell, M.F. Balcan, and H. Lin, editors, Advances in Neural Information Processing Systems ,
volume 33, pages 19523–19533. Curran Associates, Inc., 2020. URL https://proceedings.
neurips.cc/paper/2020/file/e2d52448d36918c575fa79d88647ba66-Paper.pdf .
[30] Jiashuo Liu, Tianyu Wang, Peng Cui, and Hongseok Namkoong. On the need for a language
describing distribution shifts: Illustrations on tabular datasets. July 2023.
[31] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In
I. Guyon, U. V on Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett,
editors, Advances in Neural Information Processing Systems , volume 30. Curran Associates,
Inc., 2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/file/
8a20a8621978632d76c43dfd28b67767-Paper.pdf .
[32] Ronald Oaxaca. Male-female wage differentials in urban labor markets. International Economic
Review , 14(3):693–709, 1973. ISSN 00206598, 14682354. URL http://www.jstor.org/
stable/2525981 .
12[33] F. Pedregosa, G. Varoquaux, A. Gramfort, V . Michel, B. Thirion, O. Grisel, M. Blondel,
P. Prettenhofer, R. Weiss, V . Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,
M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine
Learning Research , 12:2825–2830, 2011.
[34] John Platt. Probabilistic outputs for support vector machines and comparisons to regularized
likelihood methods. Advances in large margin classifiers , 10(3):61–74, 1999.
[35] Gregory Plumb, Nari Johnson, Angel Cabrera, and Ameet Talwalkar. Towards a more rigorous
science of blindspot discovery in image classification models. Transactions on Machine
Learning Research , 2023. ISSN 2835-8856. URL https://openreview.net/forum?id=
MaDvbLaBiF . Expert Certification.
[36] Hongxiang Qiu, Eric Tchetgen Tchetgen, and Edgar Dobriban. Efficient and multiply robust
risk estimation under general forms of dataset shift. June 2023.
[37] Joaquin Quiñonero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D Lawrence.
Dataset shift in machine learning . Mit Press, 2022.
[38] Victor Quintas-Martinez, Mohammad Taha Bahadori, Eduardo Santiago, Jeff Mu, Dominik
Janzing, and David Heckerman. Multiply-robust causal change attribution, 2024.
[39] Stephan Rabanser, Stephan Günnemann, and Zachary Lipton. Failing loudly: An empirical
study of methods for detecting dataset shift. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d'Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing
Systems , volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.
cc/paper/2019/file/846c260d715e5b854ffad5f70a516c88-Paper.pdf .
[40] James M Robins, Thomas S Richardson, and Ilya Shpitser. An interventionist approach
to mediation analysis. In Probabilistic and Causal Inference: The Works of Judea Pearl .
Association for Computing Machinery, August 2020. URL http://arxiv.org/abs/2008.
06019 .
[41] L S Shapley. 17. a value for n-person games. In Harold William Kuhn and Albert William
Tucker, editors, Contributions to the Theory of Games (AM-28), Volume II , pages 307–318.
Princeton University Press, Princeton, December 1953.
[42] Ewout W Steyerberg. Clinical Prediction Models: A Practical Approach to Development,
Validation, and Updating . Springer, New York, NY , 2009.
[43] Masash Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul Buenau, and Motoaki Kawan-
abe. Direct importance estimation with model selection and its application to covariate shift
adaptation. Adv. Neural Inf. Process. Syst. , 2007.
[44] Eric J. Tchetgen Tchetgen and Ilya Shpitser. Semiparametric theory for causal mediation
analysis: Efficiency bounds, multiple robustness and sensitivity analysis. The Annals of
Statistics , 40(3):1816 – 1845, 2012. doi: 10.1214/12-AOS990. URL https://doi.org/10.
1214/12-AOS990 .
[45] Anastasios A Tsiatis. Semiparametric Theory and Missing Data . Springer New York, 2006.
[46] A W van der Vaart. Asymptotic Statistics . Cambridge University Press, October 1998.
[47] Brian D Williamson and Jean Feng. Efficient nonparametric statistical inference on population
feature importance using shapley values. International Conference on Machine Learning , 2020.
URL https://proceedings.icml.cc/static/paper_files/icml/2020/3042-Paper.
pdf.
[48] Eric Wu, Kevin Wu, and James Zou. Explaining medical AI performance disparities across
sites with confounder shapley value analysis. November 2021. URL http://arxiv.org/
abs/2111.08168 .
[49] Myeong-Su Yun. Decomposing differences in the first moment. Economics Letters , 82(2):
275–280, 2004. ISSN 0165-1765. doi: https://doi.org/10.1016/j.econlet.2003.09.008. URL
https://www.sciencedirect.com/science/article/pii/S0165176503002866 .
13[50] Haoran Zhang, Harvineet Singh, Marzyeh Ghassemi, and Shalmali Joshi. "Why did the model
fail?": Attributing model performance changes to distribution shifts. In Andreas Krause,
Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett,
editors, Proceedings of the 40th International Conference on Machine Learning , volume 202
ofProceedings of Machine Learning Research , pages 41550–41578. PMLR, 23–29 Jul 2023.
URL https://proceedings.mlr.press/v202/zhang23ai.html .
14A Appendix
Contents of the Appendix are as follows.
• Table 2 collects all the notation used for reference.
• Section B discusses broader impacts of the work.
•Algorithms 1 and 4 provide the steps required for computing the aggregate and detailed decomposi-
tion respectively. Detailed decompositions require computing the value of s-partial conditional
outcome and conditional covariate shifts which is described in Algorithms 2 and 3.
•Section C discusses considerations for choosing baseline variables Wand conditional covariates Z.
•Section D describes a causal interpretation of the aggregate and detailed decompositions as effects
of stochastic (or shift) interventions on a structural causal model.
•Section E explain why value functions in prior work give unintuitive attribution and that the
R2-based value functions are proper scoring rules.
•Section F describes the estimation and inference for aggregate decomposition and detailed decom-
position of conditional covariate shift.
• Section G provides the derivations of the results.
• Sections H and I describe the implementation and simulation details.
• Section J provides additional details on the two real world datasets and results.
B Broader impacts
This work presents a method for understanding failures of ML algorithms when they are deployed in
settings or populations different from the ones in development datasets. Therefore, the work can be
used to suggest ways of improving the algorithms or mitigating their harms. The method is generally
applicable to tabular data settings for any classification algorithm, hence, it can potentially be applied
across multiple domains where ML is used including medicine, finance, and online commerce.
Care must be taken while interpreting the results. As usual, assumptions underlying the decompo-
sitions such as the coarse causal ordering between the variables W, Z , and Yshould be validated
through domain knowledge.
Algorithm 1 Aggregate decompositions into baseline, conditional covariate, and conditional outcome
shifts
Input: Source and target data {(W(d)
i, Z(d)
i, Y(d)
i)}nd
i=1ford∈ {0,1}, loss function ℓ(W, Z, Y ;f).
Output: Performance change due to baseline, conditional covariate, and conditional outcome shifts
ΛW,ΛZ,ΛY.
1Split source and target data into training Trand evaluation Evpartitions. Let nEvbe the total number
of data points in the Evpartition.
2Fit nuisance parameters ηW, ηZ, ηY, defined in Section G.1, on the Trpartition as outlined in
Section H.1.
3Estimate ΛW,ΛZ,ΛYusing fitted nuisance parameters on the Evpartitions following the equations in
Section F.1.
4Estimate variance of influence functions ψW(d, w, z, y ; ˆηN), ψZ(d, w, z, y ; ˆηN), and ψY(d, w, z, y ; ˆηN)
as defined in (23), (24), and (25), respectively.
5Compute α-level confidence intervals as ˆΛN±z1−α/2p
dvar(ψN(d, w, z, y ; ˆηN))/nEvforN∈ {W,Z,Y},
where zis the inverse CDF of the standard normal distribution.
6return ˆΛW,ˆΛZ,ˆΛYand confidence intervals
15Table 2: Notation
Symbol Meaning
W, Z, Y Variables: Baseline, Conditional covariates, Outcome
f Prediction model being analyzed
ℓ(W, Z, Y )orℓ Loss function e.g. 0-1 loss
D= 0andD= 1 Indicators for source and target domain
p0, p1 Probability density (or mass) function for the two domains D= 0,1
ps Probability density (or mass) function when only variable subset sshifts
from source to target
EDWDZDY Expectation over the distribution pDW(W)pDZ(Z|W)pDY(Y|W, Z)
Q:=q(W, Z) Source domain risk at W, Z , i.e.p0(Y= 1|W, Z)
TrandEv Training dataset used to fit models and evaluation dataset used to compute
decompositions
ϕZ,jandϕY,j Shapley values for variable jin the detailed decomposition of conditional
covariate and outcome shifts
vZ(s)andvY(s) Value of a subset sfors-partial conditional covariate shift and s-partial
outcome shift
vnum
·(s)andvden
·(s) Numerator and denominator of the ratio defined in the value of a subset
Models µ· Outcome models for the conditional expectation of the loss across differ-
ent settings
Models π· Density ratio models for feature densities across datasets
P Notation for expectation
P0,nandP1,n sample average over source and target data in the evaluation dataset
ψ(d, w, z, y ) Influence function defined in the linear approximation of an estimand,
see e.g. (22)
Algorithm 2 VALUE CONDITIONAL OUTCOME (S): Value for s-partial conditional outcome shift for
a subset s
Input: Training Trand evaluation Evpartitions of source and target data, subset of variables s.
Output: Value for s-partial conditional outcome shift for subset s.
1Fit nuisance parameters ηnum
Y,s, ηden
Y, defined in Sections G.3, on the Trpartitions as outlined in H.2.
2Estimate vY(s)byˆvnum
Y(s)/ˆvden
Ywhere ˆvnum
Y(s)is estimated using (6)andˆvden
Yis estimated using (7)
on the Evpartition.
3Estimate variance of influence function ψY,bin,s(d, w, z, y ; ˆηnum
Y,s,ˆηden
Y)as defined in (74).
4Compute α-level confidence interval as ˆvY(s)±z1−α/2q
dvar(ψY,bin,s(d, w, z, y ; ˆηnum
Y,s,ˆηden
Y))/nEv.
5return ˆvY(s)and confidence interval
Algorithm 3 VALUE CONDITIONAL COVARIATE (S): Value for s-partial conditional covariate shift
for a subset s
Input: Training Trand evaluation Evpartitions of source and target data, subset of variables s.
Output: Value for s-partial conditional covariate shift for subset s.
1Fit nuisance parameters ηnum
Z,s, defined in Sections G.2, on the Trpartition, as outlined in H.3.
2Estimate vZ(s)byˆvnum
Z(s)/ˆvnum
Z(∅)using (21) on the Evpartition.
3Estimate variance of influence function ψZ,s(d, w, z, y ; ˆηnum
Z,s)as defined in (41).
4Compute α-level confidence interval as ˆvZ(s)±z1−α/2q
dvar(ψZ,s(d, w, z, y ; ˆηnum
Z,s))/nEv.
5return ˆvZ(s)and confidence interval
16Algorithm 4 Detailed decomposition for conditional outcome and covariate shift
Input: Source and target data {(W(d)
i, Z(d)
i, Y(d)
i)}nd
i=1ford∈ {0,1}, loss function ℓ(W, Z, Y ;f),
γ∈R+.
Output: Detailed decomposition for conditional outcome or covariate shift, {ϕY,j:j= 0,···, m2}
or{ϕZ,j:j= 1,···, m2}.
1Split source and target data into training Trand evaluation Evpartitions. Let nEvbe the total number
of data points in the Evpartition.
2Subsample ⌊γnEv⌋subsets from Z={1,···, m2}with respect to Shapley weights, including ∅and
Z, denoted s1,···, sk.
3Estimate vY(s)←VALUE CONDITIONAL OUTCOME (S)andvZ(s)←VALUE CONDITIONAL CO-
VARIATE (S) fors∈s1,···, sk.
4Get estimated Shapley values {ϕY,j}and{ϕZ,j}by solving constrained linear regression problems in
(7) in Williamson and Feng [47] with value functions vY(s)andvZ(s), respectively.
5Compute confidence intervals based on the influence functions defined in Theorem 1 in Williamson
and Feng [47].
6return Shapley values {ϕY,j:j= 0, . . . , m 2}and{ϕZ,j:j= 1, . . . , m 2}and confidence intervals
C Considerations for the choice of WandZvariables
We suppose that variables Xare partitioned into baseline variables Wand conditional covariates
Z. We suggest selecting Zto be the variables that may act as mediators of the environment shift
and/or variables whose associations with Yare likely to be modified by the environment shift (i.e.
effect modification). This selection can be chosen based on a high-level causal graph, where Ware
variables known to be upstream of Z. For instance, if Zare treatment variables and Ware baseline
variables, one can interpret a covariate shifts as a change in the treatment policy and an outcome shift
as a change in the treatment effect across the two environments.
In the absence of any prior knowledge, another option is to choose Was the variables for which
one would like the expected loss given Wto be invariant across the two environments; this can be
useful to promote fairness of ML algorithms across environments. When this invariance does not
hold, the proposed framework explains how variables Zcontribute to these differences, which can
inform efforts to eliminate performance gaps. This last option is similar to how variables are typically
chosen in disparity analyses [ 21]. For instance, to understand why income differs between males and
females controlling for age, one would set domain to D=gender, W=age, and Zas variables that
may explain this disparity (e.g. marital status, employment status).
In general, including more variables in WandZto explain the performance difference is preferable.
Nevertheless, there are tradeoffs. For instance, including more variables in Wleads to higher
variance of ∆·10(W), so it allows one to better distinguish the relative importance of variables in
Zfor explaining its variability. On the other hand, when more variables are assigned to W, the
performance gap with respect to W(∆·10(W)) is a more complex function. Thus we may have
more uncertainty in our estimate of ∆·10(W), which may lead to wider confidence intervals for the
variable importance values.
D Causal interpretation of aggregate and detailed decompositions
Partial distribution shifts that we define in the framework can be equivalently described as stochastic
(or shift) interventions in a structural causal model (SCM) respecting a causal directed acyclic graph
(DAG) [ 8]. To represent an intervention on variable X, we use regime indicator σXwhich means
that the conditional probability distribution for Xin the SCM has been updated to a new one [9].
Suppose that the source and target data (W, Z, Y )are generated by SCMs respecting the same DAG
Gin Figure 4 with no unmeasured confounders. Intervening on a variable in source SCM sets its
17ZYWZsYWZ−sZsYWZ−sQZYWZYWAGGREGATEDETAILEDσWσWσZσWσZσYσWσZsσWσZσY,ZsFigure 4: Decomposition framework for explaining the performance gap from source to target domain,
visualized through causal directed acyclic graphs. Aggregate decompositions describe the incremental
effect of stochastic interventions on each aggregate variable’s distribution at the source with that in
the target, indicated by regime indicators σW, σZ, andσY. Detailed decompositions quantify how well
candidate partial distribution shifts explain the variability of performance gaps across strata. The
candidate partial shifts considered in this work are shown in the DAGs on the right. An s-partial
conditional covariate shift is a stochastic intervention on variable subset Zs. Ans-partial conditional
outcome shift is a stochastic intervention on variable Y, in which the conditional outcome distribution
fine-tunes the risk in the source domain (indicated by the additional node Q=p0(Y= 1|W, Z))
with respect to Zs.
conditional distribution to the corresponding one in the target SCM. Under the assumption of no
unmeasured confounders, we have
p0(V;σX) =Y
Vi∈V\Xp0(Vi|paG(Vi);σX)Y
Vi∈Xp1(Vi|paG(Vi)) (10)
for any variable set Vwhere paGdenotes parents in G. Therefore, the target data is obtained by
intervening on all the variables p0(W, Z, Y ;σW, σZ, σY) =p1(W, Z, Y ). Expectation Eis taken over
the source distribution or its shifted version based on the specified regime indicator.
Aggregate decompositions can then be written as causal effect of intervening on W, Z, Y incremen-
tally as follows
ΛW=E[ℓ|σW]−E[ℓ]
ΛZ=E[ℓ|σW, σZ]−E[ℓ|σW]
ΛY=E[ℓ|σW, σZ, σY]−E[ℓ|σW, σZ]
Due to the factorization (10), the above are equivalent to aggregate decompositions presented in
Section 2.
For detailed decomposition of the conditional covariate shift, assume the causal DAG in Figure
4 with Zs→Z−sfor variable subset s. The s-partial conditional covariate shift is represented
byp0(V;σZs)and, under the factorization (10), is equivalent to the one considered in Section 2.2.
Thus, the performance difference ∆·s0(W)can be equivalently written as E[ℓ|W;σZs]−E[ℓ|W]and
∆·10(W)asE[ℓ|W;σZ]−E[ℓ|W]. The value function is then
vZ(s) := 1 −Eh
(∆·s0(W)−∆·10(W))2;σWi
E[∆2
·10(W);σW].
Thes-partial conditional outcome shift corresponds to a stochastic intervention that changes the
distribution of Yto(5). Denoting it as p0(V;σY,Zs), the performance difference ∆··s(W, Z)can be
equivalently written as E[ℓ|W, Z;σY,Zs]−E[ℓ|W, Z]and∆··1(W, Z)asE[ℓ|W, Z;σY]−E[ℓ|W, Z].
The value function (4) is then
vY(s) := 1 −Eh
(∆··s(W, Z)−∆··1(W, Z))2;σW, σZi
E[∆2
··1(W, Z);σW, σZ]. (11)
18E Proper scoring rules for partial distribution shift
Prior works have considered scoring rules for partial distribution shifts in terms of their change in the
average loss [ 48]. For instance, for conditional covariate shifts, prior works have considered scoring
rules of the form
E1s0[ℓ]−E100[ℓ] =Z
ℓ(Y, f(Z, W )) (ps(z|w)−p0(z|w))p1(w)dzdw. (12)
However, in the absence of a detailed causal graph, we show that this can lead to unintuitive
attributions. Consider the following counterexample. We drop Wfrom the data example for
simplicity of exposition.
Example E.1.Consider the following data-generating process with random variables Z1andZ2, a
real-valued outcome Y, and loss function as squared error ℓ= (f(Z1, Z2)−Y)2:
Z1∼N(D+ 1,1) (13)
Z2=|Z1| (14)
ϵ∼N(0,1) (15)
Y=Z1+Z2+ϵ 1{Z1≤0} (16)
where D= 0 andD= 1 correspond to the source and target domains, respectively. Suppose
the ML model is the optimal model for minimizing the expected loss in the source domain, i.e.
f(Z1, Z2) =Z1+Z2. Consider the following candidate partial distribution shifts for explaining
the performance change, where Option 1 hypothesizes Z1causes Z2and Option 2 hypothesizes Z2
causes Z1.
(Option 1) Fors={1},ps(Z) =p1(Z1)p0(Z2|Z1)
(Option 2) Fors={2},ps(Z) =p1(Z2)p0(Z1|Z2)
Per the given data-generating process, the partial shift in Option 1 exactly corresponds to the true
(aggregate) dataset shift; thus we would expect it to have a higher value than Option 2. Nevertheless,
the MSE resulting from Option 2’s shift is 0.5 (the marginal distribution of Z1under Option 2 is
symmetric around 0). In contrast, the MSE resulting from Option 1’s shift is the probability that a
standard normal variable is less than -1, which is 0.159.
In Example E.1, scoring rule (12) assigns a higher value to a partial shift that contradicts the true
causal graph than even the true aggregate shift, because the rule assumes the hypothesized dataset
shift is true. Consequently, (12) is not a proper scoring rule. In contrast, the proposed value functions
described in Section 2.1 are.
More formally, we extend the traditional definition for a proper scoring rule [ 18] to the context of
explaining performance changes as follows. Let a scoring function χ:O0×O1×Qbe defined
as a function of source observation O0= (W0, Z0, Y0), target observation O1= (W1, Z1, Y1),
and candidate shift probability model Q. A scoring rule χis proper with respect to the set of
distribution shift models Fif the following holds: for any true model of the post-shift data distribution
p∗(W, Z, Y )∈ F, the expectation of the scoring function χ(O0, O1, p∗)with respect to O0∼p0
andO1∼p∗is always no smaller than the expectation of χ(O0, O1, p)for any p∈ F, i.e.
Ep0,p∗[χ(O0, O1, p∗)]≥Ep0,p∗[χ(O0, O1, p)]∀p∈ F (17)
Moreover, we say that χis strictly proper if (17) holds with equality iff p=p∗.
LetFZbe the set of candidate s-partial conditional covariate shifts p·s0andFYbe the set of candidate
s-partial conditional outcome shifts p··s, i.e.
FZ={p·s0(y, z|w) =p0(y|z, w)ps(z|w) :s⊆ {1,···, m2}}
FY={ps(y|z, w) :s⊆ {1,···, m2}}.
Then, vZdefined in (3)is a proper scoring rule with respect to FZ, asvZattains its largest value when
∆·s0≡∆·10, which holds when p·s0matches the true covariate-only distribution shift model p·10.
Similarly, vYdefined in (4)is a proper scoring rule with respect to FY. Moreover, these are strictly
proper scoring rules as long as the conditional expectation of the losses of candidate distribution
shifts are not adversarially aligned. That is, under the assumptions that
E·s0[ℓ|W]≡E·10[ℓ|W]⇐⇒ p·s0≡p·10∀p·s0∈ F Z (A.1)
E··s[ℓ|W, Z]≡E··1[ℓ|W, Z]⇐⇒ p··s≡p··1∀p··s∈ F Y (A.2)
19vZandvYare strictly proper scoring rules with respect to FZandFY, respectively. As the candidate
distribution shifts considered in this work are functionals of the observed distribution shift and
observed distribution shifts are unlikely to be adversarial in many real-world situations, Assumptions
(A.1) and (A.2) are likely reasonable in practice.
F Estimation and Inference
Let{(W(d)
i, Z(d)
i, Y(d)
i) :i= 1,···, nd}denote ndindependent and identically distributed (IID)
observations from the source and target domains d= 0and1, respectively. Let a fixed fraction of
the data be partitioned towards “training” ( Tr) and the remaining to “evaluation” ( Ev); let nEvbe
the number of observations in the evaluation partition. Let Pddenote the expectation with respect
to domain dandPd,ndenote the empirical average over observations in partition Evfrom domain
d={0,1}.
F.1 Aggregate decomposition
The aggregate decomposition terms can be formulated as an average treatment effect, a well-studied
estimand in causal inference, where domain Dcorresponds to treatment. As such, one can use
augmented inverse probability weighting (AIPW) to define debiased ML estimators of the aggregate
decomposition terms (e.g. Kang and Schafer [24]). We review estimation and inference for these
terms below.
Estimation. Using the training data, estimate outcome models µ·00(W) =E·00[ℓ|W=w]and
µ··0(W, Z) =E[ℓ|W, Z]and density ratio models π100(W) =p1(W)/p0(W)andπ110(W, Z) =
p1(W, Z)/p0(W, Z). The debiased ML estimators for ΛW,ΛZ,ΛYare
ˆΛW=P0,n(ℓ−ˆµ·00(W)) ˆπ100(W) +P1,nˆµ·00(W)−P0,nℓ
ˆΛZ=P0,n(ℓ−ˆµ··0(W, Z)) ˆπ110(W, Z) +P1,nˆµ··0(W, Z)
−P0,n(ℓ−ˆµ·00(W)) ˆπ100(W)−P1,nˆµ·00(W)
ˆΛY=P1,nℓ−P0,n(ℓ−ˆµ··0(W, Z)) ˆπ(W, Z)−P1,nˆµ0(W, Z)
Inference. Assuming the estimators for the outcome and density ratio models converge at a fast
enough rate, the AIPW estimators for the aggregate decomposition terms are asymptotically linear
and, thus, facilitate the construction of CIs.
Theorem F.1. Suppose π100andπ110are bounded; estimators ˆµ·00,ˆπ··0,ˆπ100, and ˆπ110are
consistent; and
P0(ˆµ·00−µ·00) (ˆπ100−π100) =op(n−1/2)
P0(ˆµ··0−µ··0) (ˆπ110−π110) =op(n−1/2).
Then ˆΛW,ˆΛZ,andˆΛYare asymptotically linear estimators of their respective estimands.
F.2 Value of s-partial conditional covariate shifts
Estimation. Using the training partition, estimate the density ratio π1s0(zs, w) =
p1(zs, w)/p0(zs, w)and the outcome models
µ·0−s0(zs, w) =E·00[ℓ|zs, w] =Z Z
ℓp0(y|w, z)p0(z−s|zs, w)dydz−s (18)
µ·10(w) =E·10[ℓ|w] (19)
µ·s0(w) =E·s0[ℓ|w] =Z Z Z
ℓp0(y|w, z)p0(z−s|zs, w)p1(zs|w)dydz−sdzs, (20)
20in addition to the other nuisance models previously mentioned. We propose the estimator ˆvZ(s) =
ˆvnum
Z(s)/ˆvden
Z, where
ˆvnum
Z(s) :=P1,n(ˆµ·s0(W)−ˆµ·10(W))2
+ 2P0,n(ˆµ·s0(W)−ˆµ·10(W))(ℓ−ˆµ·0−s0(W, Z s))ˆπ1s0(W, Z s)
−2P0,n(ˆµ·s0(W)−ˆµ·10(W))(ℓ−ˆµ··0(W, Z))ˆπ110(W, Z)
+ 2P1,n(ˆµ·s0(W)−ˆµ·10(W))(ˆµ·0−s0(W, Z s)−ˆµ·s0(W))
−2P1,n(ˆµ·s0(W)−ˆµ·10(W))(ˆµ··0(W, Z)−ˆµ·10(W))(21)
andˆvden
Z:= ˆvnum
Z(∅).
Inference. The estimator is asymptotically normal as long as the outcome and density ratio models
are estimated at a fast enough rate defined formally as follows.
Condition F.2. For variable subset s, suppose the following holds
•P0(µ001(W)−µ01(W))2is bounded
•P0(µ·0−s0(Zs, W)−ˆµ·0−s0(Zs, W))(ˆπ1s0(Zs, W)−π1s0(Zs, W)) =op(n−1/2)
•P0(µ··0(W, Z)−ˆµ··0(W, Z))(ˆπ110(W, Z)−π110(W, Z)) =op(n−1/2)
•P1(ˆµ·s0(W)−µ·s0(W))2=op(n−1/2)
•P1(ˆµ·10(W)−µ·10(W))2=op(n−1/2)
•(Positivity) p0(zs, w)>0andp0(w, z)>0almost everywhere, such that the density ratios
π1s0(w, zs)andπ110(w, z)are well-defined and between (0,1).
Theorem F.3. For variable subset s, suppose vden
Z(s)>0and Condition F .2 hold. Then the estimator
ˆvZ(s)is asymptotically normal.
G Proofs
Notation. For all proofs, we will write Pto mean expectation on the evaluation partition (and likewise
for the empirical version) for notational simplicity.
Overview of derivation strategy. We first present the general strategy for proving asymptotic
normality of the estimators for the decompositions. Details on nonparametric debiased estimation
can be found in texts such as Tsiatis [45] and Kennedy [25].
Letv(P)be a pathwise differentiable quantity that is a function of the true regular (differentiable in
quadratic mean) probability distribution Pover random variable O. For instance, vin the case of
mean is defined as v(P) :=Eo∼P(O)[o]. Let ˆPdenote an arbitrary regular estimator of P, such as the
maximum likelihood estimator. The plug-in estimator is then defined as v(ˆP).
The von-Mises expansion of the functional v(which linearizes vin analogy to the first-order Taylor
expansion), given it is pathwise differentiable, gives
v(ˆP)−v(P) =−Pψ(o;ˆP) +R(ˆP,P). (22)
Here, the function ψis called an influence function (or a functional gradient of vatˆP).R(ˆP,P)is
a second-order remainder term. The one-step corrected estimators we consider have the form of
v(ˆP) +Pnψ(o;ˆP)where Pndenotes a sample average. Following the expansion above, the one-step
corrected estimator can be analyzed as follows,

v(ˆP) +Pnψ(o;ˆP)
−v(P)
= (Pn−P)ψ(o;ˆP) +R(ˆP,P)
= (Pn−P)ψ(o;P) + (Pn−P)(ψ(o;ˆP)−ψ(o;P)) +R(ˆP,P)
21Our goal will be to analyze each of the three terms and to show that they are asymptotically negligible
at√n-rate, such that the one-step corrected estimator satisfies

v(ˆP) +Pnψ(o;ˆP)
−v(P) =Pnψ(o;P) +op(n−1/2),
where we used the property of influence functions that they have zero mean. Thus the one-step
corrected estimator is asymptotically normal with mean v(P)and variance var(ψ(o;P))/n, which
allows for the construction of CIs. In the following proofs, we present the influence functions without
derivations; see Kennedy [25] and Hines et al. [20] for strategies for deriving influence functions.
G.1 Aggregate decompositions
Let the nuisance parameters in the one-step estimators ΛW,ΛZ,ΛYbe denoted by ηW=
(µ·00, π100), ηZ= (µ··0, µ·00, π110), ηY= (µ··0, π110)respectively. Denote the estimated nuisances
byˆηW,ˆηZ,ˆηY. The canonical gradients for the three estimands are
ψW(d, w, z, y ;ηW) = [( ℓ(w, z, y )−µ·00(w))π100(w)−ℓ(w, z, y )]1{d= 0}
p(d= 0)
+µ·00(w)1{d= 1}
p(d= 1)−ΛW (23)
ψZ(d, w, z, y ;ηZ) = [( ℓ(w, z, y )−µ··0(w, z))π110(w, z)]1{d= 0}
p(d= 0)+µ··0(w, z)1{d= 1}
p(d= 1)
−[(ℓ(w, z, y )−µ·00(w))π100(w)]1{d= 0}
p(d= 0)+µ·00(w)1{d= 1}
p(d= 1)−ΛZ
(24)
ψY(d, w, z, y ;ηY) = (ℓ(w, z, y )−µ··0(w, z))1{d= 1}
p(d= 1)
−[(ℓ(w, z, y )−µ··0(w, z))π110(w, z)]1{d= 0}
p(d= 0)−ΛY. (25)
Theorem G.1 (Theorem F.1) .Under conditions outlined in Theorem F .1, the one-step corrected
estimators for the aggregate decomposition terms, baseline, conditional covariate, and conditional
outcome ˆΛW,ˆΛZ, and ˆΛY, are asymptotically linear, i.e.
ˆΛN−ΛN=PnψN+op(n−1/2)∀N∈ {W,Z,Y}. (26)
Proof. The estimands ΛW,ΛZ,ΛYhave similarities to the standard average treatment effect (ATE)
in the causal inference literature (see [ 25, Example 2]. Hence, the estimators and their asymptotic
properties directly follow. For treatment T, outcome O, and confounders C, the mean outcome under
T= 1among the population with T= 0is identified as
ϕ=Z
op(o|c, t= 1)p(c|t= 0)dodc (27)
and its one-step corrected estimator can be derived from the canonical gradient of ϕ, which takes the
following form after plugging in the estimates of the nuisance models:
ˆϕn=Pn1{T= 1}
Pr(T= 1)ˆπ(c) (O−ˆµ1(c)) +1{T= 0}
Pr(T= 0)ˆµ1(c)
satisfies
ˆϕn−ϕ=Pn1{T= 1}
Pr(T= 1)π(c) (O−µ1(c)) +1{T= 0}
Pr(T= 0)µ1(c)−ϕ
+op(n−1/2)
where µ1(c) =E[o|c, t= 1] andπ(c) =p(c|t= 0)/p(c|t= 1) as long as the following conditions
hold:
•p(c|t= 1) >0almost everywhere such that the density ratios π(c)are well-defined and
bounded,
22•P1(ˆµ1−µ1)(ˆπ−π) =op(n−1/2).
We establish the estimators and their influence functions by showing that they can all be viewed as
mean outcomes of the form (27).
Baseline term ΛW. The first term E100[ℓ(w, z, y )]is a mean outcome with respect to
p(ℓ(w, z, y )|w, d = 0)p(w|d= 1) , which is the same as that in (27) but with ℓ(w, z, y )as the
outcome, was the confounder, and das the (flipped) treatment. The second term E000[ℓ(w, z, y )]is
a simple average over D= 0population whose influence function is the ℓ(w, z, y )itself.
Conditional covariate term ΛZ. First term E110[ℓ(w, z, y )]is the mean outcome with respect
top(ℓ(w, z, y )|w, z, d = 0)p(w, z|d= 1) , where the chief difference is (w, z)is the confounder.
Second term E100[ℓ(w, z, y )]is also a mean outcome, as discussed above.
Conditional outcome term ΛY. First term E111[ℓ(w, z, y )]is a simple average over the D= 1
population.
G.2 Value of s-partial conditional covariate shifts
Let nuisance parameters in the one-step estimator vnum
Z,s be denoted ηnum
Z,s =
(µ·s0, µ·10, µ·0−s0, µ001, µ··0, π1s0, π110)and the set of estimated nuisances by ˆηnum
Z,s. The
canonical gradient of vnum
Z(s)is
ψnum
Z,s(D, W, Z, Y ;ηnum
Z,s) = (µ·s0(W)−µ·10(W))2 1{D= 1}
Pr(D= 1)
+ 2(µ·s0(W)−µ·10(W))(ℓ−µ·0−s0(W, Z s))π1s0(W, Z s)1{D= 0}
Pr(D= 0)
−2(µ·s0(W)−µ·10(W))(ℓ−µ··0(W, Z))π110(W, Z)1{D= 0}
Pr(D= 0)
+ 2(µ·s0(W)−µ·10(W))(µ·0−s0(W, Z s)−µ·s0(W))1{D= 1}
Pr(D= 1)
−2(µ·s0(W)−µ·10(W))(µ··0(W, Z)−µ·10(W))1{D= 1}
Pr(D= 1)
−vnum
Z(s). (28)
Lemma G.2. Under Condition F .2, ˆvnum
Z(s)satisfies
ˆvnum
Z(s)−vnum
Z(s) =Pnψnum
Z,s(D, W, Z, Y ;ηnum
Z,s) +op(n−1/2) (29)
ˆvden
Z−vden
Z=Pnψnum
Z,∅(D, W, Z, Y ;ηnum
Z,s) +op(n−1/2) (30)
Proof. Consider the following decomposition
ˆvnum
Z(s)−vnum
Z(s)
=(Pn−P)ψnum
Z(D, W, Z, Y ;ηnum
Z,s) (31)
+ (Pn−P)(ψnum
Z(D, W, Z, Y ; ˆηnum
Z,s)−ψnum
Z(W, Z, Y ;ηnum
Z,s)) (32)
+P(ψnum
Z(D, W, Z, Y ; ˆηnum
Z,s)−ψnum
Z(D, W, Z, Y ;ηnum
Z,s)) (33)
We note that (32) converges to a normal distribution per CLT assuming the variance of ψnum
Z,sis finite.
The empirical process term (32) is asymptotically negligible, as the nuisance parameters ηnum
Z,sare
estimated using a separate training data split from the evaluation data and [ 25, Lemma 1] states that
(Pn−P)(ψnum
Z,s(D, W, Z, Y ; ˆηnum
Z,s)−ψnum
Z,s(D, W, Z, Y ;ηnum
Z,s) =op(n−1/2)
23as long as estimators for all nuisance parameters are consistent. We now establish that the remainder
term (33) is also asymptotically negligible. Integrating with respect to Y, we have that
(33)=P2(ˆµ·s0(W)−ˆµ·10(W))×
(µ·0−s0(Zs, W)−ˆµ·0−s0(Zs, W))ˆπ1s0(W, Z s)1{D= 0}
p(D= 0)
+ (ˆµ·0−s0(Zs, W)−ˆµ·s0(W))1{D= 1}
p(D= 1)
−(µ··0(W, Z)−ˆµ··0(W, Z))ˆπ110(W, Z)1{D= 0}
p(D= 0)
−(ˆµ··0(W, Z)−ˆµ·10(W))1{D= 1}
p(D= 1)
(34)
+P((ˆµ·s0(W)−ˆµ·10(W))2−(µ·s0(W)−µ·10(W))2)1{D= 1}
p(D= 1)(35)
=P2(ˆµ·s0(W)−ˆµ·10(W))×
(µ·0−s0(Zs, W)−ˆµ·0−s0(Zs, W)) (ˆπ1s0(W, Z s)−π1s0(W, Z s))1{D= 0}
p(D= 0)
+ (µ·0−s0(Zs, W)−ˆµ·0−s0(Zs, W))π1s0(W, Z s)1{D= 0}
p(D= 0)
+ (ˆµ·0−s0(Zs, W)−ˆµ·s0(W))1{D= 1}
p(D= 1)
−(µ··0(W, Z)−ˆµ··0(W, Z)) (ˆπ110(W, Z)−π110(W, Z))1{D= 0}
p(D= 0)
−(µ··0(W, Z)−ˆµ··0(W, Z))π110(W, Z)1{D= 0}
p(D= 0)
−(ˆµ··0(W, Z)−ˆµ·10(W))1{D= 1}
p(D= 1)
(36)
+P((ˆµ·s0(W)−ˆµ·10(W))2−(µ·s0(W)−µ·10(W))2)1{D= 1}
p(D= 1)(37)
From convergence conditions in Condition F.2, this simplifies to
(33)=P2(ˆµ·s0(W)−ˆµ·10(W))×
(µ·0−s0(Zs, W)−ˆµ·0−s0(Zs, W))π1s0(W, Z s)1{D= 0}
p(D= 0)
+ (ˆµ·0−s0(Zs, W)−ˆµ·s0(W))1{D= 1}
p(D= 1)
−(µ··0(W, Z)−ˆµ··0(W, Z))π110(W, Z)1{D= 0}
p(D= 0)
−(ˆµ··0(W, Z)−ˆµ·10(W))1{D= 1}
p(D= 1)
(38)
+P((ˆµ·s0(W)−ˆµ·10(W))2−(µ·s0(W)−µ·10(W))2)1{D= 1}
p(D= 1)(39)
+op(n−1/2), (40)
Given the true density ratios, we can further simplify the expectations over D= 0weighted by the
density ratios in the expression above to expectations over D= 1. By definition of µ·0−s0(Zs, W)in
24(18) andµ·s0(W)in(20) and the definition of µ··0(W, Z)andµ·10(W)in Section F.1, (33) simplifies
to
(33)=P12(ˆµ·s0(W)−ˆµ·10(W))(µ·s0(W)−ˆµ·s0(W))
−P12(ˆµ·s0(W)−ˆµ·10(W))(µ·10(W)−ˆµ·10(W))
+P1(ˆµ·s0(W)−ˆµ·10(W))2−(µ·s0(W)−µ·10(W))2)
+op(n−1/2),
which is op(n−1/2)as long as the convergence conditions in Condition F.2 hold.
As the denominator vden
Zis equal to the numerator vnum
Z(∅), it follows that the one-step estimator for
the denominator ˆvden
Zis asymptotically linear with influence function ψnum
Z,∅.
Proof for Theorem F .3. Combining Lemma G.2 and the Delta method [ 46, Theorem 3.1], the estima-
torˆvZ(s) = ˆvnum
Z(s)/ˆvden
Zis asymptotically linear
ˆvnum
Z(s)
ˆvden
Z−vnum
Z(s)
vden
Z= PnψZ,s(D, W, Z, Y ;ηnum
Z,s, ηden
Z) +op(n−1/2),
with influence function
ψZ,s(D, W, Z, Y ;ηnum
Z,s, ηden
Z,s) =1
vden
Zψnum
Z,s(D, W, Z, Y ;ηnum
Z,s)−vnum
Z(s)
(vden
Z)2ψden
Z(D, W, Z, Y ;ηden
Z),
(41)
where ψnum
Z,s(D, W, Z, Y ;ηnum
Z,s)is defined in (28) and ψden
Z(D, W, Z, Y ;ηden
Z) =
ψnum
Z,∅(D, W, Z, Y ;ηnum
Z,∅).
Accordingly, the estimator asymptotically follows the normal distribution,
√n(ˆvZ(s)−vZ(s))→dN(0,var(ψZ,s(D, W, Z, Y ;ηnum
Z,s, ηden
Z,s)) (42)
G.3 Value of s-partial conditional outcome shifts
Let the nuisance parameters in vnum
Y,binbe denoted ηnum
Y,s= (Qbin, µ··1, µ··s, π)and its estimate as ˆηnum
Y,s.
We represent the one-step corrected estimator for vnum
Y,bin(s)as the V-statistic
ˆvnum
Y,bin(s) =P1,n˜P1,n(ˆµ··1(W, Z)−ˆµ··s(W, Z))2(43)
+ 2P1,n˜P1,n(ˆµ··1(W, Z)−ˆµ··s(W, Z)) (ℓ−µ··1(W, Z)) (44)
−2P1,n˜P1,nh
ˆµ··1(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)
(ℓ(W, Z s,˜Z−s, Y)−µ··s(W, Z s,˜Z−s))π(˜Z−s, Zs, W, q bin(W, Z))i
(45)
=P1,n˜P1,nh
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
. (46)
In more detail, the conditions in Theorem 3.2 are as follows.
Condition G.3. For variable subset s, suppose the following hold
•π(W, Z s, Z−s, Qbin)is bounded
•ˆπis consistent
•P1(ˆµ··0−µ··0)2=op(n−1/2)
•P1(ˆµ··1−µ··1)2=op(n−1/2)
•P1(ˆµ··s−µ··s)2=op(n−1/2)
25•P1(ˆqbin−qbin)2=op(n−1)
•P1(ˆµ··s−µ··s) (ˆπ−π) =op(n−1/2).
Lemma G.4. Assuming Condition G.3 holds, ˆvnum
Y,binis an asymptotically linear estimator for vnum
Y,bin,
i.e.
ˆvnum
Y,bin(s)−vnum
Y,bin(s) =P1,nψnum
Y,s(D, W, Z, Y ;ηnum
Y,s) +op(n−1/2), (47)
with influence function
ψnum
Y,s 
d, w, z, y ;ηnum
Y,s
=(µ··1(w, z)−µ··s(w, z))2
+ 2(µ··1(w, z)−µ··s(w, z)) [ℓ(w, z, y )−µ··1(w, z)]
−2P1h
(µ··1(w, zs, Z−s)−µ··s(w, zs, Z−s))
[ℓ(w, zs, Z−s, y))−µ··s(w, zs, Z−s)]π(Z−s, zs, w, q bin(w, z))i
−vnum
Y,bin(s). (48)
Proof. Defining the symmetrized version of hin(46) ashsym(W, Z, Y, ˜W,˜Z,˜Y) =
h(W,Z,Y, ˜W,˜Z,˜Y)+h(˜W,˜Z,˜Y ,W,Z,Y )
2, we rewrite the estimator as
ˆvnum
Y,bin(s) =P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
.
Per Theorem 12.3 in [46], the Hájek projection of ˆvnum
Y,bin(s)is
ˆunum
Y,bin(s) =nX
i=1P1h
P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
−¯ˆvnum
Y(s)|Xi, Yii
=nX
i=1P1h
hsym
Xi, Yi, X(2), Y(2); ˆηnum
Y,s
−¯ˆvnum
Y(s)|Xi, Yii
=nX
i=1hsym, 1 
Xi, Yi; ˆηnum
Y,s
where ¯ˆvnum
Y(s) =P1˜P1hsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
.
Consider the decomposition
ˆvnum
Y,bin(s)−vnum
Y,bin(s) =P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
−P1˜P1hsym
W, Z, Y, ˜W,˜Z,˜Y;ηnum
Y,s
=P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
−P1,n
hsym, 1 
X, Y; ˆηnum
Y,s
+¯ˆvnum
Y(s)
(49)
+ (P1,n−P1) 
hsym, 1 
X, Y; ˆηnum
Y,s
+¯ˆvnum
Y(s)−hsym, 1(X, Y)−vnum
Y(s)
(50)
+ (P1,n−P1) (hsym, 1(X, Y) +vnum
Y(s)) (51)
+P1 
hsym, 1 
X, Y; ˆηnum
Y,s
+¯ˆvnum
Y(s)−hsym, 1 
X, Y;ηnum
Y,s
−vnum
Y(s)
.
(52)
We analyze each term in turn.
Term (49): Suppose P1h2
sym(W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s)<∞. Via a straightforward extension of the
proof in Theorem 12.3 in van der Vaart [46], one can show that
var
P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
var 
P1,nhsym, 1 
W, Z, Y ; ˆηnum
Y,s →p1.
26Then by Theorem 11.2 in van der Vaart [46] and Slutsky’s lemma, we have
P1,n˜P1,nhsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
−P1,n
hsym, 1 
W, Z, Y ; ˆηnum
Y,s
+¯ˆvnum
Y(s)
=op
n−1/2
.
Term (50): We perform sample splitting to estimate the nuisance parameters and calculate the
estimator for ˆvnum
Y(s). Then by Lemma 1 in Kennedy [25], we have that
(P1,n−P1) 
hsym, 1 
W, Z, Y ; ˆηnum
Y,s
+¯ˆvnum
Y(s)−hsym, 1 
W, Z, Y ;ηnum
Y,s
−vnum
Y(s)
=op(n−1/2)
as long as the estimators for the nuisance parameters are consistent.
Term (51): This term (P1,n−P1) 
hsym, 1 
W, Z, Y ;ηnum
Y,s
+vnum
Y(s)
=
(P1,n−P1)hsym, 1 
W, Z, Y ;ηnum
Y,s
follows an asymptotic normal distribution per CLT.
Term (52): We will show that this bias term is asymptotically negligible. For notational simplicity,
letˆξ(W, Z s, Z−s) = ˆµ··1(W, Z)−ˆµ··s(W, Z).
P1˜P1
hsym
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
+¯ˆvnum
Y(s)−hsym
W, Z, Y, ˜W,˜Z,˜Y;ηnum
Y,s
−vnum
Y(s)
=P1˜P1
h
W, Z, Y, ˜W,˜Z,˜Y; ˆηnum
Y,s
−h
W, Z, Y, ˜W,˜Z,˜Y;ηnum
Y,s
=P1(ˆµ··1(W, Z)−ˆµ··s(W, Z))2−P1(µ··1(W, Z)−µ··s(W, Z))2
+ 2P1(ˆµ··1(W, Z)−ˆµ··s(W, Z)) [µ··1(W, Z)−ˆµ··1(W, Z)]
−2P1˜P1n
ˆµ··1(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)h
ℓ(W, Z s,˜Z−s, Y)−ˆµ··s(W, Z s,˜Z−s)i
ˆπ
˜Z−s, Zs, W,ˆqbin(W, Z)o
=P1(ˆµ··1(W, Z)−ˆµ··s(W, Z))2−P1(µ··1(W, Z)−µ··s(W, Z))2
+ 2P1(ˆµ··1(W, Z)−ˆµ··s(W, Z)) [µ··1(W, Z)−ˆµ··1(W, Z)]
−2P1˜P1ˆξ(W, Z s,˜Z−s)h
µ··s(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)i
ˆπ
˜Z−s, Zs, W, q bin(W, Z)
−2P1˜P1n
ˆξ(W, Z s,˜Z−s)h
ℓ(W, Z s,˜Z−s, Y)−ˆµ··s(W, Z s,˜Z−s)i
h
ˆπ
˜Z−s, Zs, W,ˆqbin(W, Z)
−ˆπ
˜Z−s, Zs, W, q bin(W, Z)io
=P1(µ··s(W, Z)−ˆµ··s(W, Z)) (ˆµ··1(W, Z)−ˆµ··s(W, Z) +µ··1(W, Z)−µ··s(W, Z)) (53)
+P1(ˆµ··1(W, Z)−µ··1(W, Z)) (µ··1(W, Z)−µ··s(W, Z)−ˆµ··1(W, Z) + ˆµ··s(W, Z)) (54)
−2P1˜P1ˆξ(W, Z s,˜Z−s)h
µ··s(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)i
ˆπ
˜Z−s, Zs, W, q bin(W, Z)
(55)
−2P1˜P1n
ˆξ(W, Z s,˜Z−s)h
ℓ(W, Z s,˜Z−s, Y)−ˆµ··s(W, Z s,˜Z−s)i
h
ˆπ
˜Z−s, Zs, W,ˆqbin(W, Z)
−ˆπ
˜Z−s, Zs, W, q bin(W, Z)io
. (56)
Note that (56) isop(n−1/2)under the assumed convergence rates for ˆqbin. In addition, (54) is
op(n−1/2), under the assumed convergence rates for ˆµ··1andˆµ··s.
27Analyzing the remaining summands (53) + (55), we note that it simplifies as follows:
P1(µ··s(X)−ˆµ··s(X)) (ˆµ··1(X)−ˆµ··s(X) +µ··1(X)−µ··s(X))
−2P1˜P1n
ˆξ(W, Z s,˜Z−s)h
µ··s(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)i

ˆπ
˜Z−s, Zs, W, q bin(W, Z))
−π
˜Z−s, Zs, W, q bin(W, Z))o
−2P1˜P1ˆξ(W, Z s,˜Z−s)h
µ··s(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)i
π
˜Z−s, Zs, W, q bin(W, Z))
=P1(µ··s(X)−ˆµ··s(X)) (µ··1(X)−ˆµ··1(X)−µ··s(X) + ˆµ··s(X))
−2P1˜P1n
ˆξ(W, Z s,˜Z−s)h
µ··s(W, Z s,˜Z−s)−ˆµ··s(W, Z s,˜Z−s)i
h
ˆπ
˜Z−s, Zs, W, q bin(W, Z))
−π
˜Z−s, Zs, W, q bin(W, Z))io
,
which is op(n−1/2), under the assumed convergence rates for ˆµ··s,ˆµ··1, and ˆπ.
Condition G.5 (Convergence conditions for ˆvden
Y).Suppose the following holds
•P1(µ··1−µ··0−(ˆµ··1−ˆµ··0))2=op(n−1/2)
•P0(µ··0−ˆµ··0)(π110−ˆπ110) =op(n−1/2)
•P0(µ··1−µ··0)2is bounded
•(Positivity) p(w, z|d= 0) >0almost everywhere, such that the density ratios π110(w, z)are
well-defined and bounded.
Let the nuisance parameters in the one-step estimator vden
Ybe denoted by ηden
Y= (µ··0, µ··1, π110)
and the set of estimated nuisances by ˆηden
Y.
Lemma G.6. Assuming Condition G.5 holds, then ˆvden
Yis an asymptotically linear estimator for vden
Y,
i.e.
ˆvden
Y−vden
Y=Pnψden
Y(D, W, Z, Y ;ηden
Y) +op(n−1/2)
with influence function
ψden
Y(D, W, Z, Y ;ηden
Y) = (µ··1(W, Z)−µ··0(W, Z))2 1{D= 1}
p(D= 1)(57)
+ 2 (µ··1(W, Z)−µ··0(W, Z)) (ℓ−µ··1(W, Z))1{D= 1}
p(D= 1)(58)
−2 (µ··1(W, Z)−µ··0(W, Z)) (ℓ−µ··0(W, Z))π110(W, Z)1{D= 0}
p(D= 0)
(59)
−vden
Y. (60)
Proof. Consider the following decomposition of bias in the one-step corrected estimate
ˆvden
Y−vden
Y
=(Pn−P)ψden
Y(D, W, Z, Y ;ηden
Y) (61)
+ (Pn−P)(ψden
Y(D, W, Z, Y ; ˆηden
Y)−ψden
Y(D, W, Z, Y ;ηden
Y)) (62)
+P(ψden
Y(D, W, Z, Y ; ˆηden
Y)−ψden
Y(D, W, Z, Y ;ηden
Y)) (63)
We observe that (61) converges to a normal distribution per CLT assuming that the variance of ψden
Y
is finite. The empirical process term (62) is asymptotically negligible since the nuisance parameters
ηden
Yare evaluated on an separate evaluation data split from the training data used for estimation.
28In addition assuming that the estimators for the nuisance parameters are consistent, Kennedy [25,
Lemma 1] states that
(Pn−P)(ψden
Y(D, W, Z, Y ; ˆηden
Y)−ψden
Y(D, W, Z, Y ;ηden
Y)) =op(n−1/2).
We now show that the remainder term (63) is also asymptotically negligible. Substituting the influence
function and integrating with respect to Y, (63) becomes
(63)=P(ˆµ··1(W, Z)−ˆµ··0(W, Z)−(µ··1(W, Z)−µ··0(W, Z)))2 1(D= 1)
p(D= 1)(64)
+ 2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)−(µ··1(W, Z)−µ··0(W, Z))) (µ··1(W, Z)−µ··0(W, Z))1(D= 1)
p(D= 1)
(65)
+ 2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)) (µ··1(W, Z)−ˆµ··1(W, Z))1{D= 1}
p(D= 1)(66)
−2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)) (µ··0(W, Z)−ˆµ··0(W, Z))ˆπ110(W, Z)1{D= 0}
p(D= 0)(67)
=P(ˆµ··1(W, Z)−ˆµ··0(W, Z)−(µ··1(W, Z)−µ··0(W, Z)))2 1(D= 1)
p(D= 1)(68)
+ 2P(µ··0(W, Z)−ˆµ··0(W, Z))(µ··1(W, Z)−µ··0(W, Z))1(D= 1)
p(D= 1)(69)
−2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)) (µ··0(W, Z)−ˆµ··0(W, Z))(ˆπ110(W, Z)−π110(W, Z))1{D= 0}
p(D= 1)
(70)
−2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)) (µ··0(W, Z)−ˆµ··0(W, Z))π110(W, Z)1{D= 0}
p(D= 0)(71)
=P(ˆµ··1(W, Z)−ˆµ··0(W, Z)−(µ··1(W, Z)−µ··0(W, Z)))2 1(D= 1)
p(D= 1)(72)
−2P(ˆµ··1(W, Z)−ˆµ··0(W, Z)) (µ··0(W, Z)−ˆµ··0(W, Z))(ˆπ110(W, Z)−π110(W, Z))1{D= 0}
p(D= 0)
(73)
Thus the remainder term is op(n−1/2)if Condition G.5 holds.
Proof for Theorem 3.2. Combining Lemmas G.4, G.6, and the Delta method [ 46, Theorem 3.1], the
estimator ˆvY,bin(s) = ˆvnum
Y,bin(s)/ˆvden
Yis asymptotically linear
ˆvnum
Y,bin(s)
ˆvden
Y−vnum
Y,bin(s)
vden
Y= PnψY,bin,s(D, W, Z, Y ;ηnum
Y,s, ηden
Y) +op(n−1/2),
with influence function
ψY,bin,s(D, W, Z, Y ;ηnum
Y,s, ηden
Y) =1
vden
Yψnum
Y,s(D, W, Z, Y ;ηnum
Y,s)−vnum
Y,bin(s)
(vden
Y)2ψden
Y(D, W, Z, Y ;ηden
Y),
(74)
where ψnum
Y,sandψden
Yare defined in (48) and (60).
Accordingly, the estimator follows a normal distribution asymptotically,
√n(ˆvY(s)−vY(s))→dN(0,var(ψY,bin,s(D, W, Z, Y ;ηnum
Y, ηden
Y)) (75)
Remark on super-fast convergence of ˆqbin.One of the conditions in Condition G.3 states that the
ˆqbinconverges at op(n−1)rate. While this seems restrictive, binned risk converges exponentially
under suitable margin conditions presented in Audibert and Tsybakov [2]. In particular, consider the
following margin condition which is a relaxation of Condition 3.1.
29Condition G.7. For all bin edges bexcept b∈ {0,1}, the set Ξϵ={x:|q(x)−b| ≤ϵ}is measure
zero for some ϵ >0.
Suppose the function qbelongs to the Hölder class Σ(β, L,Rd)for positive integer βandL > 0
(see definition in Audibert and Tsybakov [2]), the marginal law of Xsatisfies the strong density
assumption, and the margin condition G.7 is satisfied. Then the rate of convergence of ˆqbinis
exponential, i.e.
E(ˆqbin(X)−qbin(X))2≤C1exp(−C2n) (76)
for constants C1, C2>0that do not depend on n.
Remark on value of s-partial conditional outcome shift. Unlike the case of s-partial conditional
covariate shift, note that vY(∅)may be non-zero when the risk in the target domain is a recalibration
(i.e. temperature-scaling) of the risk in the source domain [ 34,19]. For instance, there may be general
environmental factors such that readmission risks in the target domain are uniformly lower.
H Implementation details
Here we describe how the nuisance parameters can be estimated in each of the decompositions. In
general, density ratio models can be estimated via a standard reduction to a classification problem
where a probabilistic classifier is trained to discriminate between source and target domains [43].
Note on computation time . Shapley value computation can be parallelized over the subsets. For
high-dimensional tabular data, grouping together variables can further reduce computation time (and
increase interpretability).
H.1 Aggregate decompositions
Density ratio models. Using direct importance estimation [ 43], density ratio models π100(W)and
π110(W, Z)can be estimated by fitting classifiers on the combined source and target data to predict
D= 0or1from features Wand(W, Z), respectively.
Outcome models. The outcome models µ·00(W)andµ··0(W, Z)can be fit in a number of ways.
One option is to estimate the conditional distribution of the outcome (i.e. p0(Y|W)orp0(Y|W, Z))
using binary classifiers, from which one can obtain an estimate of the conditional expectation of
the loss. Alternatively, one can estimate the conditional expectations of the loss directly by fitting
regression models.
H.2 Detailed decomposition for s-partial outcome shift
Density ratio models. The density ratio π(W, Z s, Z−s, Q) = p1(Z−s|W, Z s, q(W, Z) =
Q)/p1(Z−s)in(6)can be estimated as follows. Create a second (“phantom”) dataset of the target
domain in which Z−sis independent of Zsby permuting the original Z−sin the target domain.
Compute qbinfor all observations in the original dataset and the permuted dataset. Concatenate the
original dataset from the target domain with the permuted dataset. Train a classifier to predict if an
observation is from the original versus the permuted dataset.
Outcome models. The outcome models µ··1andµ··s(W, Z)can be similarly fit by estimating the
conditional distributions p0(Y|W, Z)andps(Y|W, Z, q bin(W, Z))on the target domain, and then
taking expectation of the loss.
Computing U-statistics. Calculating the double average P1,n˜P1,nin the estimator requires evaluating
alln2pairs of data points in target domain. This can be computationally expensive, so a good
approximation is to subsample the inner average. We take 2000 subsamples. We did not see large
changes in the bias of the estimates compared to calculating the exact U-statistics.
H.3 Detailed decomposition for s-partial conditional outcome shift
Density ratio models. The ratio π1s0(W, Z s) =p1(W, Z s)/p0(W, Z s)can be similarly fit using
direct importance estimation.
Outcome models. We require the following models.
30•µ·0−s0(zs, w) =E·00[ℓ|zs, w], defined in (18), can be estimated by regressing loss against w, zs
on the source domain.
•µ·10(w) =E·10[ℓ|w], defined in (19), can be estimated by regressing µ··0(w, z)against win the
target domain.
•µ·s0(w) =E·s0[ℓ|zs, w], defined in (20), can be estimated by regressing µ·0−s0(zs, w)against w
in the target domain.
For all models, we use cross-validation to select among model types and hyperparameters. Model
selection is important so that the convergence rate conditions for the asymptotic normality results are
met.
I Simulation details
Data generation : We generate synthetic data under two settings. For the coverage checks in
Section 4.1, all features are sampled independently from a multivariate normal distribution. The
mean of the (W, Z)in the source and target domains are (0,2,0.7,3)and(0,0,0,0), respectively.
The outcome in the source and target domains are simulated from a logistic regression model with
coefficients (0.3,1,0.5,1)and(0.3,0.1,0.5,1.4).
In the second setting for baseline comparisons in Figure 2b(ii), each feature in W∈RandZ∈R5
is sampled independently from the rest from a uniform distribution over [−1,1). The binary outcome
Yis sampled from a logistic regression model with coefficients (0.2,0.4,2,0.25,0.1,0.1)in source
and(0.2,−0.4,0.8,0.1,0.1,0.1)in target.
In both the settings, we analyze performance gap of logistic regression models fit on a held-out source
dataset.
Sample-splitting : We fit all models on 80% of the data points from both source and target datasets
which is the Trpartition, and keep the remaining 20% for computing the estimators which is the Ev
partition.
Model types : We use scikit-learn implementations for all models [ 33]. We use 3-fold cross
validation to select models. For density models, we fit random forest classifiers and logistic regression
models with polynomial features of degree 3. We clip the predicted probabilities from the density
model for πat10−6to avoid very large density weights. Depending on whether the target outcome
in outcome models is binary or real-valued, we fit random forest classifiers or regressors, and logistic
regression or linear regression models with ridge penalty. Specific hyperparameter ranges for the grid
search are provided in the code.
Computing time and resources : Computation for the VI estimates can be quite fast, as Shapley
value computation can be parallelized over the subsets and the number of unique variable subsets
sampled in the Shapley value approximation is often quite small. For instance, for the ACS Public
Coverage case study with 34 features, the unique subsets is 131even when the number of sampled
subsets is 3000 , and it takes around 160 seconds to estimate the value of a single variable subset. All
experiments are run on a 2.60 GHz processor with 8 CPU cores.
J Data analysis details
Synthetic. We describe accuracy of the ML algorithm after it is retrained with the top kfeatures and
predictions from the original model (Table 3). Proposed method results in the revised model with
highest gain in accuracy and AUC. Figure 5 shows the aggregate and detailed decompositions for
the simulation setup in Section 4.1. Figure 6 shows the coverage rates of 90% CIs for the aggregate
decompositions.
Hospital readmission. Using data from the electronic health records of a large safety-net hospital in
the US, we analyzed the transferability of performance measures of a Gradient Boosted Tree (GBT)
trained to predict 30-day readmission risk for the general patient population (source) but applied
to patients diagnosed with heart failure (target). Each of the source and target datasets have 3750
observations for analyzing the performance gap. The GBT is trained on a held-out sample of 18,873
points from the general population. Features include 4 demographic variables ( W) and 16 diagnosis
31Figure 5: Sample estimates and CIs for simulation from Section 4.1. Proposed is debiased ML
estimator for HDPD.
Figure 6: Coverage rates of 90% CIs for the aggregate decomposition terms for the simulation setup
in Section 4.1.
Table 3: Accuracy and AUC for the revised model with respect to the top k={1,2,3}variables
identified by different methods. Proposed method leads to a model with highest improvement in
performance, thus, reducing the performance gap. We compare against two additional baselines that
are outperformed by the proposed method: retraining a model on the target data with all features
(AUC 0.89, Acc 0.84) and retraining on a weighted source-target data where loss for each point in
source and target is weighted by a tuned parameter αand1−αrespectively (AUC 0.89, Acc 0.85).
Method AUC-1 Acc-1 AUC-2 Acc-2 AUC-3 Acc-3
ParametricChange 0.87 0.82 0.87 0.82 0.91 0.86
ParametricAcc 0.87 0.82 0.87 0.82 0.91 0.86
RandomForestAcc 0.87 0.82 0.87 0.82 0.91 0.86
OaxacaBlinder 0.87 0.82 0.87 0.82 0.87 0.82
HDPD (proposed) 0.91 0.86 0.91 0.86 0.91 0.86
32Table 4: Difference in AUCs between the revised insurance prediction model with respect to the top k
variables identified by the proposed versus RandomForestAcc procedures (Diff AUC-k = Proposed
−RandomForestAcc ). 95% CIs are shown.
k Diff AUC-k Lower CI Upper CI
1 0.000 0.000 0.000
2 0.006 0.001 0.010
3 -0.002 -0.007 0.002
4 0.004 -0.002 0.008
5 -0.001 -0.006 0.003
6 -0.002 -0.008 0.003
7 0.007 0.002 0.011
8 0.006 0.001 0.010
Figure 7: Detailed decompositions for the performance gap of a model predicting hospital readmission
in HF population. Plot shows values for the full set of 16 variables.
codes ( Z). While training, we reweigh samples by class weights to address class imbalance. Figure 7
shows the detailed decomposition of conditional covariate shift for the dataset.
ACS Public Coverage. We extract data from the American Community Survey (ACS) to predict
whether a person has public health insurance. The data only contains persons of age less than 65
and having an income of less than $30,000. We analyze a neural network (MLP) trained on data
from Nebraska (source) to data from Louisiana (target) given 3000 and 6000 observations from the
source and target domains, respectively. Another 3300 from source for training the model. Figure 8
shows the detailed decomposition of conditional outcome shift for the dataset. Table 4 shows the
difference in AUCs for the revised models based on top features from the proposed method versus
RandomForestAcc method.
NeurIPS Paper Checklist
1.Claims
Question: Do the main claims made in the abstract and introduction accurately reflect the
paper’s contributions and scope?
Answer: [Yes]
Justification: Main contributions are stated in Section 1. Theoretical and experimental
results are presented in Sections 3 and 5 respectively.
Guidelines:
•The answer NA means that the abstract and introduction do not include the claims
made in the paper.
33Figure 8: Detailed decompositions for the performance gap of a model predicting insurance coverage
prediction across two US states (NE →LA). Plot shows values for the full set of 31 covariates.
•The abstract and/or introduction should clearly state the claims made, including the
contributions made in the paper and important assumptions and limitations. A No or
NA answer to this question will not be perceived well by the reviewers.
•The claims made should match theoretical and experimental results, and reflect how
much the results can be expected to generalize to other settings.
•It is fine to include aspirational goals as motivation as long as it is clear that these goals
are not attained by the paper.
2.Limitations
Question: Does the paper discuss the limitations of the work performed by the authors?
Answer: [Yes]
Justification: Limitations are discussed in Section 7.
Guidelines:
•The answer NA means that the paper has no limitation while the answer No means that
the paper has limitations, but those are not discussed in the paper.
• The authors are encouraged to create a separate "Limitations" section in their paper.
•The paper should point out any strong assumptions and how robust the results are to
violations of these assumptions (e.g., independence assumptions, noiseless settings,
model well-specification, asymptotic approximations only holding locally). The authors
should reflect on how these assumptions might be violated in practice and what the
implications would be.
•The authors should reflect on the scope of the claims made, e.g., if the approach was
only tested on a few datasets or with a few runs. In general, empirical results often
depend on implicit assumptions, which should be articulated.
•The authors should reflect on the factors that influence the performance of the approach.
For example, a facial recognition algorithm may perform poorly when image resolution
is low or images are taken in low lighting. Or a speech-to-text system might not be
34used reliably to provide closed captions for online lectures because it fails to handle
technical jargon.
•The authors should discuss the computational efficiency of the proposed algorithms
and how they scale with dataset size.
•If applicable, the authors should discuss possible limitations of their approach to
address problems of privacy and fairness.
•While the authors might fear that complete honesty about limitations might be used by
reviewers as grounds for rejection, a worse outcome might be that reviewers discover
limitations that aren’t acknowledged in the paper. The authors should use their best
judgment and recognize that individual actions in favor of transparency play an impor-
tant role in developing norms that preserve the integrity of the community. Reviewers
will be specifically instructed to not penalize honesty concerning limitations.
3.Theory Assumptions and Proofs
Question: For each theoretical result, does the paper provide the full set of assumptions and
a complete (and correct) proof?
Answer: [Yes]
Justification: Assumptions and proofs for the theoretical results are provided in Sections 3,
F, and G.
Guidelines:
• The answer NA means that the paper does not include theoretical results.
•All the theorems, formulas, and proofs in the paper should be numbered and cross-
referenced.
•All assumptions should be clearly stated or referenced in the statement of any theorems.
•The proofs can either appear in the main paper or the supplemental material, but if
they appear in the supplemental material, the authors are encouraged to provide a short
proof sketch to provide intuition.
•Inversely, any informal proof provided in the core of the paper should be complemented
by formal proofs provided in appendix or supplemental material.
• Theorems and Lemmas that the proof relies upon should be properly referenced.
4.Experimental Result Reproducibility
Question: Does the paper fully disclose all the information needed to reproduce the main ex-
perimental results of the paper to the extent that it affects the main claims and/or conclusions
of the paper (regardless of whether the code and data are provided or not)?
Answer: [Yes]
Justification: Pseudocode is provided in Algorithms 1, 2, 3, and 4. Implementation details
are described in Section H.
Guidelines:
• The answer NA means that the paper does not include experiments.
•If the paper includes experiments, a No answer to this question will not be perceived
well by the reviewers: Making the paper reproducible is important, regardless of
whether the code and data are provided or not.
•If the contribution is a dataset and/or model, the authors should describe the steps taken
to make their results reproducible or verifiable.
•Depending on the contribution, reproducibility can be accomplished in various ways.
For example, if the contribution is a novel architecture, describing the architecture fully
might suffice, or if the contribution is a specific model and empirical evaluation, it may
be necessary to either make it possible for others to replicate the model with the same
dataset, or provide access to the model. In general. releasing code and data is often
one good way to accomplish this, but reproducibility can also be provided via detailed
instructions for how to replicate the results, access to a hosted model (e.g., in the case
of a large language model), releasing of a model checkpoint, or other means that are
appropriate to the research performed.
35•While NeurIPS does not require releasing code, the conference does require all submis-
sions to provide some reasonable avenue for reproducibility, which may depend on the
nature of the contribution. For example
(a)If the contribution is primarily a new algorithm, the paper should make it clear how
to reproduce that algorithm.
(b)If the contribution is primarily a new model architecture, the paper should describe
the architecture clearly and fully.
(c)If the contribution is a new model (e.g., a large language model), then there should
either be a way to access this model for reproducing the results or a way to reproduce
the model (e.g., with an open-source dataset or instructions for how to construct
the dataset).
(d)We recognize that reproducibility may be tricky in some cases, in which case
authors are welcome to describe the particular way they provide for reproducibility.
In the case of closed-source models, it may be that access to the model is limited in
some way (e.g., to registered users), but it should be possible for other researchers
to have some path to reproducing or verifying the results.
5.Open access to data and code
Question: Does the paper provide open access to the data and code, with sufficient instruc-
tions to faithfully reproduce the main experimental results, as described in supplemental
material?
Answer: [Yes]
Justification: Code is available at the link https://github.com/jjfeng/HDPD .
Guidelines:
• The answer NA means that paper does not include experiments requiring code.
•Please see the NeurIPS code and data submission guidelines ( https://nips.cc/
public/guides/CodeSubmissionPolicy ) for more details.
•While we encourage the release of code and data, we understand that this might not be
possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not
including code, unless this is central to the contribution (e.g., for a new open-source
benchmark).
•The instructions should contain the exact command and environment needed to run to
reproduce the results. See the NeurIPS code and data submission guidelines ( https:
//nips.cc/public/guides/CodeSubmissionPolicy ) for more details.
•The authors should provide instructions on data access and preparation, including how
to access the raw data, preprocessed data, intermediate data, and generated data, etc.
•The authors should provide scripts to reproduce all experimental results for the new
proposed method and baselines. If only a subset of experiments are reproducible, they
should state which ones are omitted from the script and why.
•At submission time, to preserve anonymity, the authors should release anonymized
versions (if applicable).
•Providing as much information as possible in supplemental material (appended to the
paper) is recommended, but including URLs to data and code is permitted.
6.Experimental Setting/Details
Question: Does the paper specify all the training and test details (e.g., data splits, hyper-
parameters, how they were chosen, type of optimizer, etc.) necessary to understand the
results?
Answer: [Yes]
Justification: Implementation and simulation details are described in Section H and Section
I. Full details are in the provided code.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The experimental setting should be presented in the core of the paper to a level of detail
that is necessary to appreciate the results and make sense of them.
36•The full details can be provided either with the code, in appendix, or as supplemental
material.
7.Experiment Statistical Significance
Question: Does the paper report error bars suitably and correctly defined or other appropriate
information about the statistical significance of the experiments?
Answer: [Yes]
Justification: Results are accompanied by confidence intervals.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The authors should answer "Yes" if the results are accompanied by error bars, confi-
dence intervals, or statistical significance tests, at least for the experiments that support
the main claims of the paper.
•The factors of variability that the error bars are capturing should be clearly stated (for
example, train/test split, initialization, random drawing of some parameter, or overall
run with given experimental conditions).
•The method for calculating the error bars should be explained (closed form formula,
call to a library function, bootstrap, etc.)
• The assumptions made should be given (e.g., Normally distributed errors).
•It should be clear whether the error bar is the standard deviation or the standard error
of the mean.
•It is OK to report 1-sigma error bars, but one should state it. The authors should
preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis
of Normality of errors is not verified.
•For asymmetric distributions, the authors should be careful not to show in tables or
figures symmetric error bars that would yield results that are out of range (e.g. negative
error rates).
•If error bars are reported in tables or plots, The authors should explain in the text how
they were calculated and reference the corresponding figures or tables in the text.
8.Experiments Compute Resources
Question: For each experiment, does the paper provide sufficient information on the com-
puter resources (type of compute workers, memory, time of execution) needed to reproduce
the experiments?
Answer: [Yes]
Justification: Compute resources are described in Section I.
Guidelines:
• The answer NA means that the paper does not include experiments.
•The paper should indicate the type of compute workers CPU or GPU, internal cluster,
or cloud provider, including relevant memory and storage.
•The paper should provide the amount of compute required for each of the individual
experimental runs as well as estimate the total compute.
•The paper should disclose whether the full research project required more compute
than the experiments reported in the paper (e.g., preliminary or failed experiments that
didn’t make it into the paper).
9.Code Of Ethics
Question: Does the research conducted in the paper conform, in every respect, with the
NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines ?
Answer: [Yes]
Justification: We adhere to the NeurIPS Code of Ethics.
Guidelines:
•The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.
37•If the authors answer No, they should explain the special circumstances that require a
deviation from the Code of Ethics.
•The authors should make sure to preserve anonymity (e.g., if there is a special consid-
eration due to laws or regulations in their jurisdiction).
10.Broader Impacts
Question: Does the paper discuss both potential positive societal impacts and negative
societal impacts of the work performed?
Answer: [Yes]
Justification: Although we do not envision any direct negative impacts of the work, potential
positive and negative impacts are discussed in Section B.
Guidelines:
• The answer NA means that there is no societal impact of the work performed.
•If the authors answer NA or No, they should explain why their work has no societal
impact or why the paper does not address societal impact.
•Examples of negative societal impacts include potential malicious or unintended uses
(e.g., disinformation, generating fake profiles, surveillance), fairness considerations
(e.g., deployment of technologies that could make decisions that unfairly impact specific
groups), privacy considerations, and security considerations.
•The conference expects that many papers will be foundational research and not tied
to particular applications, let alone deployments. However, if there is a direct path to
any negative applications, the authors should point it out. For example, it is legitimate
to point out that an improvement in the quality of generative models could be used to
generate deepfakes for disinformation. On the other hand, it is not needed to point out
that a generic algorithm for optimizing neural networks could enable people to train
models that generate Deepfakes faster.
•The authors should consider possible harms that could arise when the technology is
being used as intended and functioning correctly, harms that could arise when the
technology is being used as intended but gives incorrect results, and harms following
from (intentional or unintentional) misuse of the technology.
•If there are negative societal impacts, the authors could also discuss possible mitigation
strategies (e.g., gated release of models, providing defenses in addition to attacks,
mechanisms for monitoring misuse, mechanisms to monitor how a system learns from
feedback over time, improving the efficiency and accessibility of ML).
11.Safeguards
Question: Does the paper describe safeguards that have been put in place for responsible
release of data or models that have a high risk for misuse (e.g., pretrained language models,
image generators, or scraped datasets)?
Answer: [NA]
Justification: We do not release a model or a new dataset.
Guidelines:
• The answer NA means that the paper poses no such risks.
•Released models that have a high risk for misuse or dual-use should be released with
necessary safeguards to allow for controlled use of the model, for example by requiring
that users adhere to usage guidelines or restrictions to access the model or implementing
safety filters.
•Datasets that have been scraped from the Internet could pose safety risks. The authors
should describe how they avoided releasing unsafe images.
•We recognize that providing effective safeguards is challenging, and many papers do
not require this, but we encourage authors to take this into account and make a best
faith effort.
12.Licenses for existing assets
Question: Are the creators or original owners of assets (e.g., code, data, models), used in
the paper, properly credited and are the license and terms of use explicitly mentioned and
properly respected?
38Answer: [Yes]
Justification: Medical dataset used for the case study is accessed and analyzed under the
terms of an IRB.
Guidelines:
• The answer NA means that the paper does not use existing assets.
• The authors should cite the original paper that produced the code package or dataset.
•The authors should state which version of the asset is used and, if possible, include a
URL.
• The name of the license (e.g., CC-BY 4.0) should be included for each asset.
•For scraped data from a particular source (e.g., website), the copyright and terms of
service of that source should be provided.
•If assets are released, the license, copyright information, and terms of use in the
package should be provided. For popular datasets, paperswithcode.com/datasets
has curated licenses for some datasets. Their licensing guide can help determine the
license of a dataset.
•For existing datasets that are re-packaged, both the original license and the license of
the derived asset (if it has changed) should be provided.
•If this information is not available online, the authors are encouraged to reach out to
the asset’s creators.
13.New Assets
Question: Are new assets introduced in the paper well documented and is the documentation
provided alongside the assets?
Answer: [NA]
Justification: We do not introduce new assets. The code is provided only for reproducing the
experiments.
Guidelines:
• The answer NA means that the paper does not release new assets.
•Researchers should communicate the details of the dataset/code/model as part of their
submissions via structured templates. This includes details about training, license,
limitations, etc.
•The paper should discuss whether and how consent was obtained from people whose
asset is used.
•At submission time, remember to anonymize your assets (if applicable). You can either
create an anonymized URL or include an anonymized zip file.
14.Crowdsourcing and Research with Human Subjects
Question: For crowdsourcing experiments and research with human subjects, does the paper
include the full text of instructions given to participants and screenshots, if applicable, as
well as details about compensation (if any)?
Answer: [NA]
Justification: Study does not involve crowdsourcing or research with human subjects.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Including this information in the supplemental material is fine, but if the main contribu-
tion of the paper involves human subjects, then as much detail as possible should be
included in the main paper.
•According to the NeurIPS Code of Ethics, workers involved in data collection, curation,
or other labor should be paid at least the minimum wage in the country of the data
collector.
15.Institutional Review Board (IRB) Approvals or Equivalent for Research with Human
Subjects
39Question: Does the paper describe potential risks incurred by study participants, whether
such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)
approvals (or an equivalent approval/review based on the requirements of your country or
institution) were obtained?
Answer: [Yes]
Justification: Medical dataset was accessed according to the terms of use of an IRB.
Guidelines:
•The answer NA means that the paper does not involve crowdsourcing nor research with
human subjects.
•Depending on the country in which research is conducted, IRB approval (or equivalent)
may be required for any human subjects research. If you obtained IRB approval, you
should clearly state this in the paper.
•We recognize that the procedures for this may vary significantly between institutions
and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the
guidelines for their institution.
•For initial submissions, do not include any information that would break anonymity (if
applicable), such as the institution conducting the review.
40