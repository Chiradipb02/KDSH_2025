Published in Transactions on Machine Learning Research (10/2022)
MixTailor: Mixed Gradient Aggregation for
Robust Learning Against Tailored Attacks
Ali Ramezani-Kebrya∗alir@es.aau.dk
Aalborg University
Iman Tabrizian∗iman.tabrizian@gmail.com
University of Toronto and Vector Institute
Fartash Faghri faghri@cs.toronto.edu
University of Toronto and Vector Institute
Petar Popovski petarp@es.aau.dk
Aalborg University
Reviewed on OpenReview: https://openreview.net/forum?id=tqDhrbKJLS
Abstract
Implementations of SGD on distributed systems create new vulnerabilities, which can be
identiﬁed and misused by one or more adversarial agents. Recently, it has been shown
that well-known Byzantine-resilient gradient aggregation schemes are indeed vulnerable to
informed attackers that can tailor the attacks (Fang et al., 2020; Xie et al., 2020b). We
introduce MixTailor, a scheme based on randomization of the aggregation strategies that
makes it impossible for the attacker to be fully informed. Deterministic schemes can be
integrated into MixTailor on the ﬂy without introducing any additional hyperparameters.
Randomization decreases the capability of a powerful adversary to tailor its attacks, while
the resulting randomized aggregation scheme is still competitive in terms of performance. For
both iid and non-iid settings, we establish almost sure convergence guarantees that are both
stronger and more general than those available in the literature. Our empirical studies across
various datasets, attacks, and settings, validate our hypothesis and show that MixTailor
successfully defends when well-known Byzantine-tolerant schemes fail.
1 Introduction
As the size of deep learning models and the amount of available datasets grow, distributed systems become
essential and ubiquitous commodities for learning human-like tasks and beyond. Meanwhile, new settings such
asfederated learning are deployed to reduce privacy risks, where a deep model is trained on data distributed
among multiple clients without exposing that data (McMahan et al., 2017; Kairouz et al., 2021; Li et al.,
2020a). Unfortunately, this is only half the story, since in a distributed setting there is an opportunity for
malicious agents to launch adversarial activities and disrupt training or inference. In particular, adversarial
agents plan to intelligently corrupt training/inference through adversarial examples, backdoor, Byzantine,
and tailored attacks (Lamport et al., 1982; Goodfellow et al., 2015; Blanchard et al., 2017; Bagdasaryan et al.,
2020; Fang et al., 2020; Xie et al., 2020b). Development of secure and robust learning algorithms, while not
compromising their eﬃciency, is one of the current grand challenges in large-scale and distributed machine
learning.
It is known that machine learning models are vulnerable to adversarial examples at test time (Goodfellow
et al., 2015). Backdoor or edge-case attacks target input data points, which are either under-represented or
∗Equal contributions.
This work was done while the ﬁrst three authors were at Vector Institute and the University of Toronto.
1Published in Transactions on Machine Learning Research (10/2022)
unlikely to be observed through training or validation data (Bagdasaryan et al., 2020). Backdoor attacks
happen through data poisoning and model poisoning. The model poisoning attack is closely related to
Byzantine model, which is well studied by the community of distributed computing (Lamport et al., 1982).
In a distributed system, honest and good workers compute their correct gradients using their own local
data and then send them to a server for aggregation. Byzantines are workers that communicate arbitrary
messages instead of their correct gradients (Lamport et al., 1982). These workers are either compromised by
adversarial agents or simply send incorrect updates due to network/hardware failures, power outages, and
other causes. In machine learning, Byzantine-resilience is typically achieved by robust gradient aggregation
schemes (Blanchard et al., 2017). These robust schemes are typically resilient against attacks that are designed
in advance, which is not a realistic scenario since the attacker will eventually learn the aggregation rule
and tailor its attack accordingly. Recently, it has been shown that well-known Byzantine-resilient gradient
aggregation schemes are vulnerable to informed and tailored attacks (Fang et al., 2020; Xie et al., 2020b).
Fang et al. (2020) and Xie et al. (2020b) proposed eﬃcient and nearly optimal attacks carefully designed
to corrupt training (an optimal training-time attack is formally deﬁned in Section 4). A tailored attack is
designed with prior knowledge of the robust aggregation rule used by the server, such that the attacker has a
provable way to corrupt the training process.
Establishing successful defense mechanisms against such tailored attacks is a signiﬁcant challenge. As a
dividend, an aggregation scheme that is immune to tailored attacks automatically provides defense against
untargeted or random attacks.
In this paper, we introduce MixTailor, a scheme based on randomization of the aggregation strategies.
Randomization is a principal way to prevent the adversary from being omniscient and in this way decrease its
capability to launch tailored attacks by creating an ignorance at the side of the attacker. We address scenarios
where neither the attack method is known in advance by the aggregator nor the exact aggregation rule used
in each iteration is known in advance by the attacker (the attacker can still know the set of aggregation rules
in the pool).
The proposed scheme exhibits high resilience to attacks, while retaining eﬃcient learning performance. We
emphasize that any deterministic Byzantine-resilient algorithm can be used in the pool of our randomized
approach (our scheme is compatible with any deterministic robust aggregation rule), which makes it open for
simple extensions by adding new strategies, but the essential protection from randomization remains.
1.1 Summary of contributions
•We propose an eﬃcient aggregation scheme, MixTailor, and provide a suﬃcient condition to ensure its
robustness according to a generalized notion of Byzantine-resilience in non-iid settings.1
•For both iid and non-iid settings, we establish almost sure convergence guarantees that are both stronger
and more general than those available in the literature.
•Our extensive empirical studies across various datasets, attacks, and settings, validate our hypothesis and
show that MixTailor successfully defends when prior Byzantine-tolerant schemes fail. MixTailor reaches
within 2% of the accuracy of an omniscient model on MNIST.
1.2 Related work
Federated learning. Federated Averaging (FedAvg) and its variants have been extensively studied in
the literature mostly as optimization algorithms with a focus on communication eﬃciency and statistical
heterogeneity of users using various techniques such as local updates and ﬁne tuning (McMahan et al., 2017;
Li et al., 2020b; Wang et al., 2020b; Fallah et al., 2020). Bonawitz et al. (2017); So et al. (2020) studied
secure aggregation protocols to ensure that an average value of multiple parties is computed collectively
without revealing the original values. Secure aggregation protocols allow a server to compute aggregated
updates without being able to inspect the clients’ local models and data. In this work, we focus on tailored
training-time attacks and robust aggregation schemes.
1Non-iid settings refer to settings with heterogeneous data over workers. In this paper, we focus on non-identical and
independent settings.
2Published in Transactions on Machine Learning Research (10/2022)
Data poisoning and model poisoning. Adversaries corrupt traning via data poisoning and model
poisoning. In the data poisoning, compromised workers replace their local datasets with those of their
interest (Huang et al., 2011; Biggio et al., 2012; Mei & Zhu, 2015; Alfeld et al., 2016; Koh & Liang, 2017;
Mahloujifar et al., 2019; Gu et al., 2019; Bagdasaryan et al., 2020; Xie et al., 2020a; Wang et al., 2020a). Data
poisoning can be viewed as a relatively restrictive attack class since the adversary is not allowed to perturb
gradient/model updates. In the model poisoning, the attacker is allowed to tweak and send its preferred
gradient/model updates to the server (Bhagoji et al., 2019; Bagdasaryan et al., 2020; Wang et al., 2020a;
Sun et al., 2021). These model replacement attacks are similar to Byzantine and tailored attacks. In this
paper, we focus on tailored training-time attacks, which belong to the class of poisoning availability attacks
based on the deﬁnition of Demontis et al. (2019). We do not study poisoning integrity attacks (Demontis
et al., 2019), and MixTailor is not designed to defend against backdoor or edge-case attacks aiming to modify
predictions on a few targeted points.
Robust aggregation and Byzantine resilience. Byzantine-resilient mechanisms based on robust ag-
gregations and coding theory have been extensively studied in the existing literature (Su & Vaidya, 2016;
Blanchard et al., 2017; Chen et al., 2017; 2018; Yin et al., 2018; Alistarh et al., 2018; El Mhamdi et al., 2018;
Damaskinos et al., 2019; Bernstein et al., 2019; Yin et al., 2019; Yang & Bajwa, 2019; Rajput et al., 2019;
Baruch et al., 2019; Xie et al., 2019; Pillutla et al., 2022; Li et al., 2019; Xie et al., 2020c; Sohn et al., 2020;
Peng & Ling, 2020; Karimireddy et al., 2022; Allen-Zhu et al., 2021; Gorbunov et al., 2022; Zhu et al., 2022).
Under the assumption that the server has access to underlying training dataset or the server can control and
arbitrarily transfer training samples across workers, a server can successfully output a correct model (Xie
et al., 2019; Chen et al., 2018; Rajput et al., 2019; Xie et al., 2020c; Sohn et al., 2020). However, in a variety of
settings including federated learning, such assumptions do not hold. Alternatively, Yin et al. (2018) proposed
to use coordinate-wise median (comed). Bernstein et al. (2019) proposed a variant of signSGD as a robust
aggregation scheme, where gradients are normalized before averaging, which limits the eﬀect of Byzantines
as the number of Byzantines matters rather than the magnitude of their gradients. It is well known that
signSGD is not guaranteed to converge (Karimireddy et al., 2019). Alistarh et al. (2018) proposed a diﬀerent
scheme, where the state of workers, i.e.,their gradients and particular estimate sequences, is kept over time,
which is used to update the set of good workers at each iteration. This technique might be useful when
Byzantines send random updates. However, the server has to keep track of the history of updates by each
individual user, which is not practical in large-scale systems. Blanchard et al. (2017) proposed Krum, which
is a distance-based gradient aggregation scheme over L2. El Mhamdi et al. (2018) showed that distance-based
schemes are vulnerable to leewayattacks and proposed Bulyan, which applies an aggregation rule such as
Krum iteratively to reject a number of Byzantines followed by a variant of coordinate-wise trimmed mean.
Karimireddy et al. (2021) proposed using momentum to defend against time-coupled attacks in an iid setting
with a ﬁxed set of Byzantines, which is a diﬀerent setting compared to our work. While most of the existing
results focus on homogeneous data over machines, i.e.,iid settings, robust aggregation schemes have been
proposed in non-iid settings (Pillutla et al., 2022; Li et al., 2019; Karimireddy et al., 2022). Pillutla et al.
(2022) proposed using approximate geometric median of local weights using Smoothed Weiszfeld algorithm.
Li et al. (2019) proposed a model aggregation scheme by modifying the original optimization problem and
adding anL1penalty term. Karimireddy et al. (2022) showed that, in non-iid settings, Krum’s selection is
biased toward certain workers and proposed a method based on resampling to homogenize gradients followed
by applying existing aggregation rules. Recently, it has been shown that well-known Byzantine-resilient
gradient aggregation schemes are vulnerable to informed and tailored attacks (Fang et al., 2020; Xie et al.,
2020b). In this paper, we propose a novel and eﬃcient aggregation scheme, MixTailor, which makes the design
of successful attack strategies extremely diﬃcult, if not impossible, for an informed and powerful adversary.
Allen-Zhu et al. (2021) proposed a method where the server keeps track of the history of updates by each
individual user. Such additional memory is not required for MixTailor. Recently, Gorbunov et al. (2022) and
Zhu et al. (2022) proposed robust methods under bounded global Hessian variance and local Hessian variance,
and strong convexity of the loss function, respextively. Such assumptions are not required for MixTailor.
Robust mean estimation. The problem of robust mean estimation of a high-dimensional and multi-variate
Gaussian distribution has been studied in (Huber, 1964; 2011; Lai et al., 2016; Diakonikolas et al., 2019; Data
3Published in Transactions on Machine Learning Research (10/2022)
& Diggavi, 2021), where unlike corrupted samples, correct samples are evenly distributed in all directions.
We note that such strong assumptions do not hold in typical machine learning problems in practice.
Game theory. Nash (1950) introduced the notion of mixed strategy in game theory. Unlike game theory, in
our setting, the agents, i.e.,the server and adversary do not have a complete knowledge of their proﬁles and
payoﬀs.
Notation: We use E[·]to denote the expectation and /bardbl·/bardblto represent the Euclidean norm of a vector. We
use lower-case bold font to denote vectors. Sets and scalars are represented by calligraphic and standard fonts,
respectively. We use [n]to denote{1,···,n}for an integer n.
2 Gradient aggregation, informed adversary, and tailored attacks
Letw∈Rddenote a high-dimensional machine learning model. We consider the optimization problem
min
w∈RdF(w) =1
nn/summationdisplay
i=1Fi(w) (1)
whereFi:Rd→Rcan be 1) a ﬁnite sum representing empirical risk of worker ior 2)Fi(w) =Ez∼Di[/lscript(w;z)]
in an online setting where Diand/lscript(w;z)denote the data distribution of worker iand the loss of model won
example z, respectively. In federated learning settings, each worker has its own local data distribution, which
modelse.g.,mobile users from diverse geographical regions with diverse socio-economical status (Kairouz
et al., 2021).
At iteration t, agoodworkericomputes and sends its stochastic gradient gi(wt)withEDi[gi(wt)] =∇Fi(wt).
A server aggregates the stochastic gradients following a particular gradient aggregation rule AGG. Then the
server broadcasts the updated model wt+1to all workers. A Byzantine worker returns an arbitrary vector such
that the basic gradient averaging converges to an ineﬀective model even if it converges. Byzantine workers may
collude and may be omniscient, i.e.,they are controlled by an informed adversary with perfect knowledge of
the state of the server, prefect knowledge of good workers and transferred data over the network (El Mhamdi
et al., 2018; Fang et al., 2020; Xie et al., 2020b). State refers to data and code. The adversary does not
have access to the random seed generator at the server. Our model of informed adversary is described in the
following.
2.1 Informed adversary
We assume an informed adversary has access to the local data stored in fcompromised (Byzantine) workers.
Note that the adversary controls the output ( i.e.,computed gradients) of Byzantine workers in all iterations.
Those Byzantine workers may output any vector at any step of training, possibly tailor their attacks to
corrupt training. Byzantine workers may collude. The adversary cannot control the output of good workers.
However, an (unomniscient) adversary may be able to inspect the local data or the output of good workers.
On the other hand, an informed adversary, has full knowledge of the local data or the output of all good
workers. More importantly, an informed adversary may know the set of aggregation rules that the server
applies throughout training. Nevertheless, if the set contains more than one rule, the adversary does not
know the random choice of a rule made by the aggregator at a particular instance.2
Byzantine workers can optimize their attacks based on gradients sent by good workers and the server’s
aggregation rule such that the output of the aggregation rule leads to an ineﬀective model even if it converges.
It is shown that well-known Byzantine-resilient aggregation rules with a deterministic structure are vulnerable
to such tailored attacks (Fang et al., 2020; Xie et al., 2020b).
2The exact rule will be determined at the time of aggregation after the updates are received. We assume the server has access
to a source of entropy or a secure seed to generate a random number at each iteration, which is a mild assumption (common in
cryptography).
4Published in Transactions on Machine Learning Research (10/2022)
2.2 Knowledge of the server
We assume that the server knows an upper bound on the number of Byzantine workers denoted by fand
thatn≥2f+ 1, which is a common assumption in the literature (Blanchard et al., 2017; El Mhamdi et al.,
2018; Alistarh et al., 2018; Rajput et al., 2019; Karimireddy et al., 2022).
Suppose there is no Byzantine worker, i.e.,f= 0. At iteration t, good workers compute {gi(wt)}. The
update rule is given by
wt+1=wt−ηtAGG({gi(wt)}n
i=1)
whereηtis the learning rate at step tandAGGis an aggregation rule at the server.
Remark 1. To improve communication eﬃciency, user imay opt to update its copy of model locally for
τiterations using its own local data and output wi
t. Then the server aggregates local models, updates the
global model wt+1=AGG ({wi
t}n
i=1), and broadcasts the updated model. In this work, we focus on gradient
aggregation following the robust aggregation literature. Note that, to improve communication eﬃciency, a
number of eﬃcient gradient compression schemes have been proposed (Alistarh et al., 2017; Faghri et al.,
2020; Ramezani-Kebrya et al., 2021). Furthermore, optimizing over τis a challenging problem and, to the
best of our knowledge, there are very special problems for which local SGD is provably shown to outperform
minibatch SGD. Finally, MixTailor is a plug and play scheme, which is compatible with local updating and
ﬁne tuning tricks to further improve communication eﬃciency and fairness.
2.3 Tailored attacks against a given aggregation rule
A tailored attack is designed with prior knowledge of the robust aggregation rule AGGused by the server.
Without loss of generality, we assume an adversary controls the ﬁrst fworkers. Let g=AGG (g1,···,gn)
denote the aggregated gradient under no attack . The Byzantines collude and modify their updates such that
the aggregated gradient becomes
g/prime= AGG( g/prime
1,···,g/prime
f,gf+1,···,gn).
A tailored attack is an attack towards the inverse of the direction of gwithout attacks:3
max
g/prime
1,···,g/prime
f,λλ
subject to g/prime= AGG( g/prime
1,···,g/prime
f,gf+1,···,gn),
g/prime=−λg.
If feasible, this attack moves the model toward a local maxima of our original objective F(w). This
attack requires the adversary to have access to the aggregation rule and gradients of all good workers. In
Appendix A.1, we extend our consideration to suboptimal tailored attacks, tailored attacks under partial
knowledge, and model-based tailored attacks, where the server aggregates the local models instead of gradients.
3 Mixed gradient aggregation
It is shown that an informed adversary can eﬃciently and successfully attack standard robust aggregation
rules such as Krum, TrimmedMean, and comed. In particular, Fang et al. (2020); Xie et al. (2020b) found
nearly optimal attacks, which are optimized to circumvent aggregation rules with a deterministic structure
by exploiting the suﬃciently large variance of stochastic gradients throughout training deep neural networks.
Randomization is the principal way to decrease the degree by which the attacker is informed and thus ensure
some level of security.
We propose that, at each iteration, the server draws a robust aggregation rule from a set Mcomputationally-
eﬃcient (robust) aggregation rules uniformly at random. We argue that such randomization makes the design
3This tailored attack is shown to be suﬃcient against several aggregation rules (Fang et al., 2020); however, it is not necessarily
an optimal attack.
5Published in Transactions on Machine Learning Research (10/2022)
of successful and tailored attack strategies extremely diﬃcult, if not impossible, even if an informed adversary
has perfect knowledge of the pool of aggregation rules. The speciﬁc pool we used for MixTailor is described
in Section 5. We should emphasize that our pool is not limited to those aggregation rules that are developed
so far. This makes it open for simple extensions by adding new strategies, but the essential protection from
randomization remains.
Intuitively, MixTailor creates suﬃcient uncertainty for the adversary and increases computational complexity
of designing tailored attacks, which are guaranteed to corrupt training. To see how MixTailor provides
robustness in practice, consider the standard threat model in Byzantine robustness literature: The attack
method is decided in advance and the server applies an aggregation strategy to counter this attack. This is
favorable for deterministic aggregations such as Krum and comed, but is hardly realistic, as after some time
the attacker will ﬁnd out what the aggregation rule is and use a proper attack accordingly.
An alternative threat model is the aggregation method is known in advance and the attacker applies an
attack that is tailored to degrade the chosen aggregation rule. This is a realistic case. To counter it, we
introduce MixTailor. By introducing randomization in the aggregation method, we assume we can withhold
the knowledge of the exact aggregation rule used in each iteration from the attacker but the attacker can still
know the set of aggregation rules in the pool. As we prove, randomization is a principled approach to limit
the capability of an attacker to launch tailored attacks in every iteration.
We propose to use a randomized aggregation rule with Mcandidate rules where AGGmis selected with
probability 1/Msuch that an informed adversary cannot take advantage of knowing the exact aggregation
rule to design an eﬀective attack. Formally, let Vi(w) =gi(w,z)∈Rdbe independent random vectors for
i∈[n].4LetG(w,z)denote a random function that captures randomness w.r.t. both an honest node i
drawn uniformly at random and also an example z∼Diof that node such that E[G(w,z)] =∇F(w). Let
]AGGdenote a random aggregation rule, which selects a rule from {AGG 1,···,AGGM}uniformly at random.
LetB={B1,···,Bf}denote arbitrary Byzantine gradients, possibly dependent on Vi’s. We note that the
indices of Byzantines may change over training iterations.
The output of MixTailor algorithm is given by
U(w) =]AGG(V1(w),···,B1,···,Bf,···,Vn(w)) (2)
where]AGG = AGG mwith probability 1/M.
In the following, we deﬁne a general robustness deﬁnition, which leads to almost sure convergence guarantees
to a local minimum of Fin(1), which is equivalent to being immune to training-time attacks. Note that our
deﬁnition covers a general non-iid setting, a general mixed strategy with arbitrary set of candidate robust
aggregation rules, and both omniscient and unomniscient adversary models.
Deﬁnition 1. Letw∈Rd. LetVi(w) =gi(w,z)∈Rdbe independent random vectors for i∈[n]. Let
G(w,z)denote a random function that captures randomness w.r.t. both an honest node idrawn uniformly at
random and also an example z∼Diof that node such that E[G(w,z)] =∇F(w). Let]AGGdenote a mixed
aggregation rule, which selects a rule from {AGG 1,···,AGGM}uniformly at random. Let B={B1,···,Bf}
denote arbitrary Byzantine gradients, possibly dependent on Vi’s.
A mixed aggregation rule ]AGGis Byzantine-resilient if U(w)satisﬁes E[U(w)]/latticetop∇F(w)>0andE[/bardblU(w)/bardblr]≤
KrE[/bardblG(w,z)/bardblr]forr= 2,3,4and some constant Kr. Note that the expectation is w.r.t. the randomness in
both sampling and aggregation.
The analysis of computational complexity of MixTailor is discussed in Appendix A.2.
4In the following, we remove the index tfor simplicity.
6Published in Transactions on Machine Learning Research (10/2022)
4 Theoretical guarantees
We ﬁrst provide a suﬃcient condition to guarantee that MixTailor algorithm is Byzantine-resilient according
to Deﬁnition 1. Proofs are in appendices. Let
Um(w) = AGG m(V1(w),···,B1,···,Bf,···,Vn(w))
denote the output of AGGmform∈[M].
Proposition 1. Letw∈Ωand0<q<M . LetG(w,z)denote a random function that captures randomness
w.r.t. both an honest node idrawn uniformly at random and also an example z∼Diof that node such that
E[G(w,z)] =∇F(w). LetL > 0denote the Lipschitz parameter of F. LetBdenote an attack against q
aggregation rules such that E[Ui(ˆw)]/latticetop∇F(ˆw)<0for some ˆwandi∈[q]. Suppose that aggregation rules
AGGm/prime’s are resilient against this attack, i.e.,
E[Um/prime(w)]/latticetop∇F(w)≥βm/prime>0
andE[/bardblU(w)/bardblr]≤KrE[/bardblG(w,z)/bardblr]withU(w)in(2)forr= 2,3,4, some constant Kr, andm/prime∈{q+
1,···,M}.Suppose that Mis large enough such that
M
q>1 +λL
minm/primeβm/prime
whereλ=maxi∈[q]supw∈Ω/bardblE[Ui(w)]/bardbl, then the mixed aggregation rule ]AGGis resilient against any such B.
Proof.See Appendix A.3.
Proposition 1 shows resilience of the mixed aggregation rule when only a subset of rules are resilient against
an attack no matter how the attack is designed (it could be computationally expensive).
Remark 2. There are possibly tailored attacks against any individual aggregation rule. On the other hand,
all aggregation rules are not vulnerable to the same attack. In sum, robustness is achieved as long as we
have a suﬃciently diverse set of aggregation rules in our pool. In (Fang et al., 2020, Theorem 1), an upper
bound is established on the norm of the attack vector that is tailored against Krum. In (Xie et al., 2020b,
Theorem 1), a lower bound is established on the norm of the attack that is tailored against comed. Theoretical
results are consistent with the attacks developed empirically in (Fang et al., 2020; Xie et al., 2020b) and
conﬁrm that Krum and comed are indeed vulnerable to diﬀerent types of attacks, so they are diverse w.r.t.
their vulnerabilities. We emphasize that the key element that provides robustness is randomization.
Remark 3. Letˆw∈Rd. To fail the conditions speciﬁed in Proposition 1, an adversary should have suﬃcient
computational resources to ﬁnd an attack (if exists) such that E[Ui(ˆw)]/latticetop∇F(ˆw)<0fori∈[q]whereqshould
be large enough. Suppose that the adversary has suﬃcient random samples from each honest client to compute
the expectation over the output of an aggregation rule AGGiand has access to an accurate estimate of ∇F(ˆw).
An aggregation AGGiis typically a nonconvex function of the attack Bin Proposition 1. Instead of designing
an optimal attack, suppose that the adversary plans to verify an attack, which is a computationally simpler
problem. By veriﬁcation, we mean computing the output of AGGiunder an attackBand computing the sign
ofE[Ui(ˆw)]/latticetop∇F(ˆw). The veriﬁcation runtime increases monotonically as qincreases. We note that due to
nonconvexity of baseline aggregation rules such as comed and Krum, we are unaware of any polynomial time
algorithm with provable guarantees to eﬃciently corrupt multiple aggregation rules at the same time.
In Appendix A.4, we deﬁne an optimal training-time attack and discuss an alternative attack design based
on a min-max problem.
4.1 Attack complexity
Unlike hyperparameter-based randomization techniques such as sub-sampling, MixTailor provides randomness
in thestructure of aggregation rules , which makes it impossible for the attacker to control the optimization
7Published in Transactions on Machine Learning Research (10/2022)
trajectory . Hyperparameter-based randomization techniques as sub-sampling can also improve robustness by
some extent, however, the adversary can still design a successful attack by focusing on the speciﬁc aggregation
structure . The adversary can do so for example by mimicking the subsampling procedure to fail it.
Formally, suppose that The set of Maggregators used by the server is denoted by A=
{AGG 1,AGG 2,..., AGGM}.We note that each aggregation rule AGGiis either deterministic or has some
hyperparameters which can be set randomly such as sub-sampling parameters. For each AGGi, we deﬁne
attack complexity as follows:
LetTi(n,f,d,/epsilon1 )denote the number of elementary operations an informed adversary requires to design a
tailored attack in terms of solving the optimization problem in Section 2.3 with precision /epsilon1for satisfying
constraints such that /epsilon1=arg cos/parenleftBig
−g/latticetopg/prime
/bardblg/prime/bardbl/bardblg/bardbl/parenrightBig
=π−arg cos/parenleftBig
g/latticetopg/prime
/bardblg/prime/bardbl/bardblg/bardbl/parenrightBig
. For a given AGGi, the number of
elementary operations increases to achieve smaller values of /epsilon1, which amounts to optimizing more eﬀective
attacks. We note that all realizations of aggregations with a random hyperparameter but the same structure,
for example Krum with various sub-sampling parameters, have the same attack complexity. The attack
complexity for MixTailor is Ω(/summationtextM
i=1Ti/parenleftbig
n,f,d,/epsilon1 )/parenrightbig
, which monotonically increases by M. To see this, assume
there exists an attacker with lower complexity, then the attacker fails to break at least one of the aggregators.
Note that precise expressions of Ti’s, i.e., the exact numbers of elementary operations depend on the speciﬁc
problem to solve (dataset, loss, architecture, etc), and the hyperparameters to chosen (for example aggregators
used for the selection and aggregation phases of Bulyan), the optimization method the attacker uses for
designing an attack, and the implementation details (code eﬃciency).
4.2 Generalized Krum
In the following, we develop a lower bound on E[Um(w)]/latticetop∇F(w)when AGGmis a generalized version of
Krum. LetGandBdenote the set of good and Byzantine workers, respectively. Let Ng(i)andNb(i)denote
the set good and Byzantine workers among n−f−2closest values to the gradient (model update) of worker i.
We consider a generalized version of Krum where AGGmselects a worker that minimizes this score function:
Letp≥1speciﬁes a particular norm. The generalized Krum selects worker
i∗= arg min
i∈[n]/summationdisplay
j∈Ng(i)∪Nb(i)/bardblGi−Gj/bardbl2
p (3)
whereGiis the update from worker i. Note that Gican be either Vi(w)orBidepending on whether worker
iis good or Byzantine. We drop wand subscript mfor notational simplicity. We ﬁrst ﬁnd upper bounds on
/bardblE[U(w)]−∇F(w)/bardbl2
2andE[/bardblU(w)/bardblr
2]forr= 2,3,4.
Theorem 1. Letw∈Rdandp≥1. Suppose E[/bardblVi(w)−∇F(w)/bardbl2
2]≤σ2for all good workers Vi(w)∈G.
The output of AGGin(3)guarantees:
/bardblE[U(w)]−∇F(w)/bardbl2
2≤2σ2/parenleftbig
1 + Λ(n,f,d,p )/parenrightbig
where Λ(n,f,d,p ) =dmax{p,2}−min{p,2}
pC(n,f)andC(n,f) = 1 +2f
n−2f−2. In addition, for r= 2,3,4, there is
a constantCsuch that E[/bardblU(w)/bardblr
2]≤CE[/bardblG(w,z)/bardblr
2].
Proof.See Appendix A.5.
Remark 4. The bounds available in (Blanchard et al., 2017; Karimireddy et al., 2022) can be considered as
special cases of our bounds for the case of p= 2. Our analysis is tighter than those bounds for this special
case.
4.3 Non-iid setting
We now consider a non-iid setting assuming bounded inter-client gradient variance, which is a common
assumption in federated learning literature (Kairouz et al., 2021, Sections 3.2.1 and 3.2.2). We ﬁnd an upper
bound on/bardblE[U(w)]−∇F(w)/bardbl2
2for the generalized Krum in (3). Our assumption is as follows:
8Published in Transactions on Machine Learning Research (10/2022)
Assumption 1. LetEDi[Vi(w)] =gi(w). For all good workers i∈Gand all w, we assume
EDi[/bardblVi(w)−gi(w)/bardbl2
2]≤σ2,
1
n−fn−f/summationdisplay
i=1/bardblgi(w)−∇F(w)/bardbl2
2≤∆2.
Recall that G(w,z)denotes a random function that captures randomness w.r.t. both an honest node idrawn
uniformly at random and also an example z∼Diof that node such that E[G(w,z)] =∇F(w). The following
assumption, which bounds higher-order moments of the gradients of good workers, is needed to prove almost
sure convergence (Bottou, 1998; Blanchard et al., 2017; Karimireddy et al., 2022).
Assumption 2. EDi[/bardblVi(w)/bardblr
2]≤Kr,iE[/bardblG(w,z)/bardblr
2]forr= 2,3,4,i∈G, and some constant Kr,i.
Theorem 2. Letw∈Rdandp≥1. Under Assumption 1, the output of AGGin(3)guarantees:
/bardblE[U(w)]−∇F(w)/bardbl2
2≤C1+C2Λ(n,f,d,p ).
whereC1= 6σ2+ 2/parenleftBig
n−f+ 3 +2(n−f)
n−2f−2/parenrightBig
∆2andC2= 4σ2+ 8(n−f)∆2. In addition, under Assumption 2
and forr= 2,3,4, there is a constant Csuch that E[/bardblU(w)/bardblr
2]≤CE[/bardblG(w,z)/bardblr
2].
Proof.See Appendix A.6.
Note that our bound recovers the results in Theorem 1 in the special case of homogeneous data. Substituting
∆ = 0, we note that the constant term in Theorem 1 is slightly smaller than that in Theorem 2.
Remark 5. Note thatC1andC2are monotonically increasing with n, which is due to data heterogeneity.
Even without Byzantines, we can establish a lower bound on the worst-case variance of a good worker that
grows with n.
Finally, for both iid and non-iid settings and a general nonconvex loss function, we can establish almost sure
convergence (∇F(wt)→0a.s.) of the output of AGGin(3)along the lines of (Fisk, 1965; Métivier, 1982;
Bottou, 1998). The following theorem statement is for the non-iid setting.
Theorem 3. Letw∈Rdandp≥1. Letn>1andf≥0denote integers with n>2f+ 2. LetC0,r,C1,r
denote some constants for r= 2,3,4,F(w)≥0denote a possibly nonconex and three times diﬀerentiable
function5with continuous derivatives, and G(w,z)denote a random vector such that E[G(w,z)] =∇F(w)
andE[/bardblG(w,z)/bardblr
2]≤C0,r+C1,r/bardblw/bardblr
2forr= 2,3,4. Suppose that the generalized Krum algorithm with
AGGin(3)is executed with a learning rate schedule {ηt}, which satisﬁes/summationtext
tηt=∞and/summationtext
tη2
t<∞.
Suppose there exists β > 0,R > 0, and 0≤θ < π/ 2−sup/bardblw/bardbl2
2≥Rαsuch that inf/bardblw/bardbl2
2≥R/bardblE[U(w)]/bardbl2
2+
inf/bardblw/bardbl2
2≥R/bardbl∇F(w)/bardbl2
2−C1−C2Λ(n,f,d,p )≥βand
inf
/bardblw/bardbl2
2≥Rw/latticetop∇F(w)
/bardblw/bardbl2/bardbl∇F(w)/bardbl2≥cos(θ)
where
α= arccos/parenleftBigβ
2/bardblE[U(w)]/bardbl2/bardbl∇F(w)/bardbl2/parenrightBig
.
Then the sequence of gradients {∇F(wt)}converges to zero almost surely.
Proof.See Appendix A.7.
In Proposition 1 and Theorem 3, we ﬁnd conditions, for example an upper bound on the number of failed
aggregation rules under an attack, under which MixTailor is guaranteed to converge to an empirical risk
minimizer of the original objective of honest workers , i.e., converge to an eﬀective model.
5It can be the true risk in an online setting.
9Published in Transactions on Machine Learning Research (10/2022)
0 1 2 3 4 5
Training Iteration 1e460708090100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum
(a)MNIST,/epsilon1= 0.1
0 1 2 3 4 5
Training Iteration 1e460708090100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum (b)MNIST,/epsilon1= 10
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Training Iteration 1e4020406080Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum (c)CIFAR-10, /epsilon1= 0.1
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Training Iteration 1e4020406080Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum (d)CIFAR-10, /epsilon1= 10
Figure 1: Test accuracy on MNIST and CIFAR-10 under iid setting. MixTailor outperforms individual
aggregators in terms of robustness. Tailored attacks ( /epsilon1= 0.1,10) are applied at each iteration. There are n= 12total
workers including f= 2Byzantine workers. The dataset is randomly and equally partitioned among workers. The
omniscient aggregator receives and averages 10 honest gradients at each iteration. For MixTailor, we randomly select
an aggregator from the pool of 64 aggregators at each iteration.
5 Experimental evaluation
In this section, we evaluate the resilience of MixTailor against tailored attacks. We construct a pool of
aggregators based on 4 robust aggregation rules: comed (Yin et al., 2018), Krum (Blanchard et al., 2017), an
eﬃcient implementation of geometric median (Pillutla et al., 2022), and Bulyan (El Mhamdi et al., 2018).
Each Bulyan aggregator uses a diﬀerent aggregator from Krum, average, geometric median, and comed for
either the selection phase or in the aggregation phase. For each class, we generate 16 aggregators, each with
a randomly generated /lscriptpnorm from one to 16. MixTailor selects one aggregator from the entire pool of 64
aggregators uniformly at random at each iteration.6We compare MixTailor with the following baselines:
omniscient, which receives and averages all honest gradients at each iteration, vanilla comed, and vanilla
Krum. Our results for variations of MixTailor under diﬀerent pools along with additional experimental results
are provided in Appendix A.8. In particular, we show the performance of modiﬁed versions of MixTailor
under tailored attacks and MixTailor under “A Little” attack (Baruch et al., 2019).
We simulate training with 12 total workers, where 2 workers are compromised by an informed Byzantine
workers sending tailored attacks. We train a CNN model on MNIST (LeCun et al., 1998) and CIFAR-
10 (Krizhevsky) under both iid and non-iid settings. The details of the model and training hyper-parameters
are provided in Appendix A.8. In the iid settings (Fig. 1), the dataset is shuﬄed and equally partitioned
among workers. In the non-iid setting (Fig. 3), the dataset is ﬁrst sorted by labels and then partitioned
among workers such that each good worker computes its local gradient on particular examples corresponding
to a label. This creates statistical heterogeneity across good workers. In both settings, the informed adversary
has access to the gradients of honest workers. Our PyTorch code will be made publicly available (Paszke
et al., 2019).
We consider tailored attacks as described in (Fang et al., 2020; Xie et al., 2020b). The adversary computes
the average of correct gradients, scales the average with a parameter /epsilon1, and has the Byzantine workers send
back scaled gradients towards the inverse of the direction along which the global model would change without
attacks. Since the adversary does not know the exact rule in the randomized case in each iteration, we use
/epsilon1’s that are proposed in (Fang et al., 2020; Xie et al., 2020b) for our baseline deterministic rules. A small /epsilon1
corrupts Krum, while a large one corrupts comed.
Consistent robustness across the course of training. Our randomized scheme successfully decreases
the capability of the adversary to launch tailored attacks. Fig. 1a and Fig. 1b show test accuracy when we
train on MNIST under tailored attacks proposed by (Fang et al., 2020; Xie et al., 2020b). Fig. 2 shows that a
setting where Krum fails while MixTailor is able to defend the attacks. The reason that MixTailor is able to
defend is using aggregators that are able to defend against this attack such as comed and geometric median.
We note that MixTailor consistently defends when vanilla Krum and comed fail. In addition, compared with
Krum and comed, MixTailor has much less ﬂuctuations in terms of test accuracy across the course of training.
6To ensure that the performance of MixTailor is not dominated by a single aggregation rule, in Appendix A.8, we show the
results when we remove a class of aggregation rule (each with 16 aggregators) from MixTailor pool. We observe that MixTailor
with a smaller pool performs roughly the same.
10Published in Transactions on Machine Learning Research (10/2022)
0 1 2 3 4 5
Training Iteration 1e4020406080100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum
Figure 2: Krum fails. Test accuracy on MNIST with
/epsilon1= 0.2for the tailored attack. We set n= 12andf= 2.
The batch size is set to 128. The dataset is randomly and
equally partitioned among workers. Omniscient receives
and averages 10 honest gradients at each iteration.
0 1 2 3 4 5
Training Iteration 1e4020406080100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=KrumFigure 3: Test accuracy on MNIST under non-
iid setting. MixTailor is robust to Byzantine workers
in the heterogeneous setting ( /epsilon1= 0.1). The dataset is
partitioned by labels such that each worker holds samples
for a single digit. The rest of the setup is similar to Fig. 1.
0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0
Training Iteration 1e4020406080100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum
AGG=Geomed
AGG=Bulyan
(a)Random attack
0 1 2 3 4 5
Training Iteration 1e4020406080100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum
AGG=Geomed (b)f= 4Byzantines
0 1 2 3 4 5
Training Iteration 1e4406080100Test Accuracy (%)AGG=Krum
AGG=Comed
AGG=MixTailor
AGG=Omniscient (c)Adaptive attack
Figure 4: Test accuracy on MNIST with random attack (left), f= 4Byzantines under /epsilon1= 10(middle), and adaptive
attack (right). MixTailor is robust to random and adaptive attacks and always outperforms the worst aggregator. The
rest of the setup is similar to Fig. 1.
MixTailor reaches within 1% of the accuracy of the omniscient aggregator, under /epsilon1= 0.1and/epsilon1= 10attacks,
respectively.
There is a free lunch! Note that the robustness of MixTailor comes at no additional computation cost. As
discussed in Section 3, the per-step computation cost of MixTailor is on par with deterministic aggregation
rules. In addition, MixTailor does not impose any additional communication cost. Our comparison in terms
of the number of training iterations is independent of a particular distributed setup.
Deterministic methods are sensitive to the attack’s parameters. We note that, unlike Krum and
comend, the performance of MixTailor is stable across large and small /epsilon1’s. Fig. 1c and Fig. 1d show test
accuracy when we train on CIFAR-10. The attack with small /epsilon1successfully corrupts Krum in the beginning
of training. Note that we have not optimized /epsilon1and opted to use those proposed by Xie et al. (2020b).
Surprisingly, we observe that comed fails under both small and large /epsilon1’s on CIFAR-10. We also observed
that comed is also unstable to the choice of hyper-parameters. In particular, we noticed that comed does
not converge when the learning rate is set to 0.1 even when there are no Byzantines. To the best of our
knowledge, this vulnerability has not been reported in the literature. We emphasize that under each attack,
MixTailor always outperforms the worst aggregator but there is an aggregator in the pool that outperforms
MixTailor.
MixTailor with resampling in non-iid settings. Finally, we note that MixTailor can be combined with
various techniques that are proposed to handle data heterogeneity. In particular, we used resampling before
all robust aggregation methods (Karimireddy et al., 2022). Resampling is a simple method which homogenizes
the received gradients before aggregating. In particular, in Fig. 3 we show test accuracy when MNIST is
partitioned among workers in a non-iid manner. Similar to the iid case, MixTailor shows consistent robustness
across the course of training.
11Published in Transactions on Machine Learning Research (10/2022)
Table 1: Time per iteration. Computational cost of each aggregator. The aggregation methods use 12 workers.
The computational cost is collected on a T4 GPU. The Bulyan aggregator uses Krum for the aggregation phase and
FedAvg for the selection phase.
AggregatorTime per iteration
(us)
Omniscient 60
MixTailor 4980
Krum 2176
Comed 153
Bulyan 6700
Comparison with geomed and Bulyan, random- /epsilon1attack, and more number of Byzantine work-
ers.We evaluate MixTailor and other rules against the random attack randomly drawn from the set of a
small/epsilon1to corrupt Krum, a large one to corrupt comed. Fig. 4a shows that such random attack is not as
eﬀective as tailored attacks against any speciﬁc rule. For a training-time attack to be eﬀective, it should be
applied consistently for some consecutive iterations.The best attack against any deterministic rule is designed
deterministically against that rule. Fig. 4b shows the results with 4 Byzantines under /epsilon1= 10. Due to the
structure of Bulyan (it requires n>4f+ 3), we had to remove it from the pool of aggregators for MixTailor.
We note that geomed is vulnerable to this attack.
We focused on Krum and comed since we are aware of tailored attacks against them (Fang et al., 2020; Xie
et al., 2020b). Fig 4b shows that geomed may be vulnerable to such attacks designed for Krum and comed.
MixTailor always outperforms the worst aggregator, which is the target of a tailored attack.
MixTailor under an adaptive attack. We have considered a stronger and adaptive attacker, which
optimizes its attack by enumerating over a set of /epsilon1’s and selects the worst/epsilon1against the aggregator at every
single iteration . The adversary enumerates among all those /epsilon1’s and ﬁnds out which one is the most eﬀective
attack by applying the aggregator (the attacker simulates the server job by applying the aggregator with
diﬀerent/epsilon1’s and ﬁnds the best attack and then outputs the best attack for the server to aggregate). Regarding
MixTailor, the attacker selects a random aggregator from the MixTailor’s aggregator pool in each iteration
and ﬁnds the worst epsilon corresponding to this aggregator. The attacker ﬁnds an adaptive attack by
calculating the dot product of the output of the aggregator and the direction of aggregated gradients without
attacks when diﬀerent epsilons are fed into the aggregator. The attacker chooses the epsilon that causes the
aggregator to produce the gradient that has the smallest dot product with the true gradient. Note that in
order to keep the computational cost of the attack similar to the Comed and Krum baselines, the adaptive
attack selects an aggregator randomly in each iteration and ﬁnds the worst /epsilon1with regard to this aggregator.
In Fig. 4c, we ran this experiment over MNIST and observe that MixTailor is able to outperform both
Krum and Comed. Comed’s accuracy changes between 85-87%, Krum’s accuracy is 83-85%, and MixTailor’s
accuracy is 91.80-92.55%. The accuracy of the omniscient aggregator is 97.62-97.68%. The set of epsilons
used by the adaptive attacker is 0.1, 0.5, 1, and 10.
Computational costs. In Table 1, we empirically provide computational costs for diﬀerent aggregation
rules after running 10 iterations. This table shows the time per iteration for each aggregator used. The
average computation cost of MixTailor across the course of training is the average of the costs for candidate
rules. AsMincreases, the average time per iteration for MixTailor increases linearly with the average
computation costs of Munderlying aggregators.
6 Conclusions and future work
To increase computational complexity of designing tailored attacks for an informed adversary, we introduce
MixTailor based on randomization of robust aggregation strategies. We provide a suﬃcient condition to
guarantee the robustness of MixTailor based on a generalized notion of Byzantine-resilience in non-iid settings.
Under both iid and non-iid data, we establish almost sure convergence guarantees that are both stronger
12Published in Transactions on Machine Learning Research (10/2022)
and more general than those available in the literature. We demonstrate the superiority of MixTailor over
deterministic robust aggregation schemes empirically under various attacks and settings. Beyond tailored
attacks in (Fang et al., 2020; Xie et al., 2020b), we show the superiourity of MixTailor under a stronger and
adaptive attacker, which optimizes its attack at every single iteration.
In this paper, we focus on stationary settings where the maximum gradient norm of the loss across the course
of training is suﬃciently small such that the eﬀective poison cannot change the accuracy much at a single
iteration. Developing defense mechanisms in more challenging settings where an adversary is able to design
an eﬀective poison in one iteration is an interesting problem for future work.
Recently, Yang & Bajwa (2019); Peng & Ling (2020); Xie et al. (2020c) proposed Byzantine-resilient schemes
for decentralized and asynchronous settings. Extending the structure of MixTailor to those settings is an
interesting problem for future work. Secure aggregation rules guarantee some level of input privacy. However,
secure aggregation creates additional vulnerabilities and makes defenses more challenging since the server only
observes the aggregate of client’s updates (Kairouz et al., 2021). Developing eﬃcient and secure protocols to
compute MixTailor using, e.g.,multi-party computation remains an open problem for future research.
Acknowledgments
The authors would like to thank Daniel M. Roy, Sadegh Farhadkhani, and our reviewers at Transactions
on Machine Learning Research (TMLR) for providing helpful suggestions, which improve the quality of the
paper and clarity of presentation. Ramezani-Kebrya was supported by an NSERC Postdoctoral Fellowship.
Faghri was supported by an OGS Scholarship. Resources used in preparing this research were provided, in
part, by the Province of Ontario, the Government of Canada through CIFAR, and companies sponsoring the
Vector Institute.7
References
Scott Alfeld, Xiaojin Zhu, and Paul Barford. Data poisoning attacks against autoregressive models. In AAAI
Conference on Artiﬁcial Intelligence , 2016.
Dan Alistarh, Demjan Grubic, Jerry Li, Ryota Tomioka, and Milan Vojnovic. QSGD: Communication-eﬃcient
SGD via gradient quantization and encoding. In Advances in neural information processing systems
(NeurIPS) , 2017.
Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li. Byzantine stochastic gradient descent. In Advances in neural
information processing systems (NeurIPS) , 2018.
Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, and Dan Alistarh. Byzantine-resilient non-convex stochastic
gradient descent. In International Conference on Learning Representations (ICLR) , 2021.
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How to backdoor
federated learning. In Proc. International Conference on Artiﬁcial Intelligence and Statistics (AISTATS) ,
2020.
Gilad Baruch, Moran Baruch, and Yoav Goldberg. A little is enough: Circumventing defenses for distributed
learning. In Advances in neural information processing systems (NeurIPS) , 2019.
Jeremy Bernstein, Jiawei Zhao, Kamyar Azizzadenesheli, and Anima Anandkumar. signsgd with majority
vote is communication eﬃcient and fault tolerant. In International Conference on Learning Representations
(ICLR), 2019.
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. Analyzing federated learning
through an adversarial lens. In International Conference on Machine Learning (ICML) , 2019.
Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector machines. In
International Conference on Machine Learning (ICML) , 2012.
7www.vectorinstitute.ai/#partners
13Published in Transactions on Machine Learning Research (10/2022)
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine learning with
adversaries: Byzantine tolerant gradient descent. In Advances in neural information processing systems
(NeurIPS) , 2017.
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel,
Daniel Ramage, Aaron Segal, and Karn Seth. Practical secure aggregation for privacy-preserving machine
learning. In Proc. ACM SIGSAC Conference on Computer and Communications Security , 2017.
Léon Bottou. Online learning and stochastic approximations. On-line learning in neural networks , 1998.
Lingjiao Chen, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos. Draco: Byzantine-resilient
distributed training via redundant gradients. In International Conference on Machine Learning (ICML) ,
2018.
Yudong Chen, Lili Su, and Jiaming Xu. Distributed statistical machine learning in adversarial settings:
Byzantine gradient descent. In Proc. ACM on Measurement and Analysis of Computing Systems , 2017.
Georgios Damaskinos, El-Mahdi El-Mhamdi, Rachid Guerraoui, Arsany Guirguis, and Sébastien Rouault.
Aggregathor: Byzantine machine learning via robust gradient aggregation. In Proc. Conference on Systems
and Machine Learning (SysML) , 2019.
Deepesh Data and Suhas Diggavi. Byzantine-resilient high-dimensional SGD with local iterations on
heterogeneous data. In International Conference on Machine Learning (ICML) , 2021.
Ambra Demontis, Marco Melis, Maura Pintor, Matthew Jagielski, Battista Biggio, Alina Oprea, Cristina
Nita-Rotaru, and Fabio Roli. Why do adversarial attacks transfer? explaining transferability of evasion
and poisoning attacks. In Proc. USENIX Security Symposium , 2019.
Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart. Robust
estimators in high-dimensions without the computational intractability. SIAM Journal on Computing , 48:
742–864, 2019.
El Mahdi El Mhamdi, Rachid Guerraoui, and Sébastien Rouault. The hidden vulnerability of distributed
learning in byzantium. In International Conference on Machine Learning (ICML) , 2018.
Fartash Faghri, Iman Tabrizian, Ilia Markov, Dan Alistarh, Daniel M. Roy, and Ali Ramezani-Kebrya.
Adaptive gradient quantization for data-parallel SGD. In Advances in neural information processing
systems (NeurIPS) , 2020.
Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. Personalized federated learning with theoretical
guarantees: A model-agnostic meta-learning approach. In Advances in neural information processing
systems (NeurIPS) , 2020.
Minghong Fang, Xiaoyu Cao, Jinyuan Jia, and Neil Gong. Local model poisoning attacks to byzantine-robust
federated learning. In Proc. USENIX Security Symposium , 2020.
Donald L. Fisk. Quasi-martingales. Transactions of the American Mathematical Society , 120:369–389, 1965.
Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples.
arXiv preprint arXiv:1412.6572v3 , 2015.
Eduard Gorbunov, Samuel Horváth, Peter Richtárik, and Gauthier Gidel. Variance reduction is an antidote
to byzantines: Better rates, weaker assumptions and communication compression as a cherry on the top.
arXiv preprint arXiv:2206.00529 , 2022.
Tianyu Gu, Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. BadNets: Evaluating backdooring attacks
on deep neural networks. IEEE Access , 7:47230–47244, 2019.
Douglas M. Hawkins. On the bounds of the range of order statistics. Journal of the American Statistical
Association , 66:644–645, 1971.
14Published in Transactions on Machine Learning Research (10/2022)
Ling Huang, Anthony D Joseph, Blaine Nelson, Benjamin IP Rubinstein, and J. Doug Tygar. Adversarial
machine learning. In Proc. ACM Workshop on Security and Artiﬁcial Intelligence , 2011.
Peter J. Huber. Robust estimation of a location parameter. The Annals of Mathematical Statistics , 35:73–101,
1964.
Peter J. Huber. Robust Statistics . Springer, 2011.
Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,
Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D’Oliveira, Hubert
Eichner, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adrià Gascón, Badih Ghazi,
Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson,
Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Kone˘ cný, Aleksandra Korolova,
Farinaz Koushanfar, Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard
Nock, Ayfer Özgür, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn
Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tramèr, Praneeth
Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances
and open problems in federated learning. Foundations and Trends in Machine Learning , 14:1–210, 2021.
Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian Stich, and Martin Jaggi. Error feedback ﬁxes SignSGD
and other gradient compression schemes. In International Conference on Machine Learning (ICML) , 2019.
Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Learning from history for byzantine robust optimization.
InInternational Conference on Machine Learning (ICML) , 2021.
Sai Praneeth Karimireddy, Lie He, and Martin Jaggi. Byzantine-robust learning on heterogeneous datasets
via bucketing. In International Conference on Learning Representations (ICLR) , 2022.
Pang Wei Koh and Percy Liang. Understanding black-box predictions via inﬂuence functions. In International
Conference on Machine Learning (ICML) , 2017.
Alex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, University of
Toronto, 2009.
Kevin A. Lai, Anup B. Rao, and Santosh Vempala. Agnostic estimation of mean and covariance. In Proc.
IEEE Annual Symposium on Foundations of Computer Science (FOCS) , 2016.
Leslie Lamport, Robert Shostak, and Marshall Pease. The Byzantine generals problem. ACM Transactions
on Programming Languages and Systems , 4:382–401, 1982.
Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haﬀner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE , 86:2278–2324, 1998.
Liping Li, Wei Xu, Tianyi Chen, Georgios B. Giannakis, and Qing Ling. Rsa: Byzantine-robust stochastic
aggregation methods for distributed learning from heterogeneous datasets. In AAAI Conference on Artiﬁcial
Intelligence , 2019.
Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,
and future directions. IEEE Signal Processing Magazine , 37:50–60, 2020a.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federated
optimization in heterogeneous networks. In Proc. Conference on Machine Learning and Systems (MLSys) ,
2020b.
Saeed Mahloujifar, Mohammad Mahmoody, and Ameer Mohammed. Data poisoning attacks in multi-party
learning. In International Conference on Machine Learning (ICML) , 2019.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-
eﬃcient learning of deep networks from decentralized data. In International Conference on Artiﬁcial
Intelligence and Statistics (AISTATS) , 2017.
15Published in Transactions on Machine Learning Research (10/2022)
Shike Mei and Xiaojin Zhu. Using machine teaching to identify optimal training-set attacks on machine
learners. In AAAI Conference on Artiﬁcial Intelligence , 2015.
Michel Métivier. Semimartingales . Walter de Gruyter, 1982.
John F. Nash. Equilibrium points in N-person games. Proceedings of the National Academy of Sciences , 36:
48–49, 1950.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,
Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas KÃűpf, Edward Yang, Zach
DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and
Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. In Advances in
neural information processing systems (NeurIPS) , 2019.
Jie Peng and Qing Ling. Byzantine-robust decentralized stochastic optimization. In Proc. IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP) , 2020.
Krishna Pillutla, Sham M. Kakade, and Zaid Harchaoui. Robust aggregation for federated learning. IEEE
Transactions on Signal Processing , 70:1142–1154, 2022.
Shashank Rajput, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos. DETOX: A redundancy-based
framework for faster and more robust gradient aggregation. In Advances in neural information processing
systems (NeurIPS) , 2019.
Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan Alistarh, and Daniel M. Roy.
NUQSGD: Provably communication-eﬃcient data-parallel SGD via nonuniform quantization. Journal of
Machine Learning Research (JMLR) , 22(114):1–43, 2021.
Jinhyun So, Başak Güler, and A Salman Avestimehr. Byzantine-resilient secure federated learning. IEEE
Journal on Selected Areas in Communications , 39:2168–2181, 2020.
Jy-yong Sohn, Dong-Jun Han, Beongjun Choi, and Jaekyun Moon. Election coding for distributed learning:
Protecting signsgd against byzantine attacks. In Advances in neural information processing systems
(NeurIPS) , 2020.
Lili Su and Nitin H. Vaidya. Non-Bayesian learning in the presence of Byzantine agents. In Proc. International
Symposium on Distributed Computing , 2016.
Jingwei Sun, Ang Li, Louis DiValentin, Amin Hassanzadeh, Yiran Chen, and Hai Li. FL-WBC: Enhancing
robustness against model poisoning attacks in federated learning from a client perspective. In Advances in
neural information processing systems (NeurIPS) , 2021.
Hongyi Wang, Kartik Sreenivasan, Shashank Rajput, Harit Vishwakarma, Saurabh Agarwal, Jy-yong Sohn,
Kangwook Lee, and Dimitris Papailiopoulos. Attack of the tails: Yes, you really can backdoor federated
learning. In Advances in neural information processing systems (NeurIPS) , 2020a.
Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khazaeni. Federated
learning with matched averaging. In International Conference on Learning Representations (ICLR) , 2020b.
Chulin Xie, Keli Huang, Pin-Yu Chen, and Bo Li. DBA: Distributed backdoor attacks against federated
learning. In International Conference on Learning Representations (ICLR) , 2020a.
Cong Xie, Sanmi Koyejo, and Indranil Gupta. Zeno: Distributed stochastic gradient descent with suspicion-
based fault-tolerance. In International Conference on Machine Learning (ICML) , 2019.
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Fall of empires: Breaking byzantine-tolerant SGD by
inner product manipulation. In Proc. Uncertainty in Artiﬁcial Intelligence Conference , 2020b.
Cong Xie, Sanmi Koyejo, and Indranil Gupta. Zeno++: Robust fully asynchronous sgd. In International
Conference on Machine Learning (ICML) , 2020c.
16Published in Transactions on Machine Learning Research (10/2022)
Zhixiong Yang and Waheed U. Bajwa. Byrdie: Byzantine-resilient distributed coordinate descent for
decentralized learning. IEEE Transactions on Signal and Information Processing over Networks , 5:611–627,
2019.
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Byzantine-robust distributed learning:
Towards optimal statistical rates. In International Conference on Machine Learning (ICML) , 2018.
Dong Yin, Yudong Chen, Ramchandran Kannan, and Peter Bartlett. Defending against saddle point attack
in Byzantine-robust distributed learning. In International Conference on Machine Learning (ICML) , 2019.
Banghua Zhu, Lun Wang, Qi Pang, Shuai Wang, Jiantao Jiao, Dawn Song, and Michael I. Jordan.
Byzantine-robust federated learning with optimal statistical rates and privacy guarantees. arXiv preprint
arXiv:2205.11765 , 2022.
A Appendix
A.1 Tailored attacks
Without loss of generality (W.L.O.G.), we assume an adversary controls the ﬁrst fworkers. Let g=
AGG (g1,···,gn)denote the current gradient under no attack . The Byzantines collude and modify their
updates such that the aggregated gradient becomes
g/prime= AGG( g/prime
1,···,g/prime
f,gf+1,···,gn).
A tailored attack is an attack towards the inverse of the direction of gwithout attacks:
max
g/prime
1,···,g/prime
f,λλ
subject to g/prime= AGG( g/prime
1,···,g/prime
f,gf+1,···,gn),
g/prime=−λg.
If successful, this attack moves the model toward a local maxima of our original objective F(w). This attack
requires the adversary to have access to the aggregation rule and gradients of all good workers. We now extend
our consideration to suboptimal tailored attacks, tailored attacks under partial knowledge, and model-based
tailored attacks, where the server aggregates local models instead of gradients.
A.1.1 Suboptimal tailored attacks
To reduce computational complexity of the problem of designing successful attacks, we consider the solution
to the following problem by restricting the space of optimization variables, which returns a nearly optimal
tailored attack (Fang et al., 2020; Xie et al., 2020b):
max
g/prime
1,λλ
subject to g/prime= AGG/parenleftBig
g/prime
1,g/prime
1,···,g/prime
1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
f,gf+1,···,gn/parenrightBig
,
g/prime=−λg.
A.1.2 Tailored attacks under partial knowledge
Now suppose, an unomniscient adversary has access to the models of workers gf+1,···,gk. We propose
a tailored attack towards the inverse of the direction of ˆg=AGG/parenleftBig
g1,···,gk,k/summationdisplay
i=1gi/k,···,k/summationdisplay
i=1gi/k
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
. An
17Published in Transactions on Machine Learning Research (10/2022)
optimal attack is the solution of the following problem:
max
g/prime
1,···,g/prime
f,λλ
subject to g/prime= AGG/parenleftBig
g/prime
1,···,g/prime
f,gf+1,···,gk,g,···,g/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
,
g/prime=−λˆg.
where g=/summationtextk
i=1gi/k.
A suboptimal attack under partial knowledge is given by a solution to this problem:
max
g/prime
1,λλ
subject to g/prime= AGG/parenleftBig
g/prime
1,g/prime
1,···,g/prime
1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
f,gf+1,···,gk,g,···,g/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
,
g/prime=−λˆg.
A.1.3 Model-based tailored attacks
Letw0denote the previous weight vector sent by the server. W.L.O.G., we assume an adversary controls
the ﬁrstfworkers. Let w=AGG (w1,···,wn)denote the current model under no attack. The Byzantines
collude and modify their weights such that the aggregated model becomes
w/prime= AGG( w/prime
1,···,w/prime
f,wf+1,···,wn).
We consider an attack towards the inverse of the direction along which the global model would change without
attacks:
max
w/prime
1,···,w/prime
f,λλ
subject to w/prime= AGG( w/prime
1,···,w/prime
f,wf+1,···,wn),
w/prime=w0−λs.
where s=w−w0is the changing direction of global model parameters under no attack. Note that diﬀerent
from (Fang et al., 2020), we consider w−w0instead of sign(w−w0), and we present an optimal attack,
where each Byzantine can inject its own attack independent of other workers.
A.1.4 Model-based and suboptimal tailored attacks
To reduce computation complexity of the problem of designing successful attacks, we also consider the solution
to the following problem by restricting the space of optimization variables, which returns a nearly optimal
tailored attack (Fang et al., 2020; Xie et al., 2020b):
max
w/prime
1,λλ
subject to w/prime= AGG/parenleftBig
w/prime
1,w/prime
1,···,w/prime
1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
f,wf+1,···,wn/parenrightBig
,
w/prime=w0−λs.
A.1.5 Model-based tailored attacks under partial knowledge
Now suppose, an unomniscient adversary has access to the models of workers wf+1,···,wk. We propose
a tailored attack towards the inverse of the direction along which the global model would change under
18Published in Transactions on Machine Learning Research (10/2022)
ˆw= AGG/parenleftBig
w1,···,wk,w,···,w/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
. An optimal attack is the solution to the following problem:
max
w/prime
1,···,w/prime
f,λλ
subject to w/prime= AGG/parenleftBig
w/prime
1,···,w/prime
f,wf+1,···,wk,w,···,w/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
,
w/prime=w0−λˆs
where ˆs=ˆw−w0andw=/summationtextk
i=1wi/k.
A suboptimal attack under partial knowledge is given by a solution to this problem:
max
w/prime
1,λλ
subject to w/prime= AGG/parenleftBig
w/prime
1,···,w/prime
1/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
f,wf+1,···,wk,w,···,w/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
n−k/parenrightBig
,
w/prime=w0−λˆs.
A.2 Computational complexity
The worst-case computational cost of MixTailor is upper bounded by that of the candidate aggregation rule
with the maximum number of elementary operations per iteration. The average computation cost across the
course of training is the average of the costs for candidate rules. In particular, the number of operations per
iteration for Bulyan with Krum as its aggregation rule is in the order of O(n2d)(El Mhamdi et al., 2018). The
computational cost for coordinate-wise median and an eﬃcient implementation of an approximate geometric
median based on Weiszfeld algorithm is O(nd)(Pillutla et al., 2022). Increasing the number of aggregators in
the pool does not necessarily increase the computation costs of MixTailor as long as the number of elementary
operations per iteration for new aggregators is in the order of those rules that have been already in the pool
of aggregators.
A.3 Proof of Proposition 1
LetB={B1,···,Bf}be an attack designed against AGGisuch that E[Ui(ˆw)]/latticetop∇F(ˆw)<0for some ˆw
whereUi(w) = AGG i(V1(w),···,B1,···,Bf,···,Vn(w)).
LetLdenote the Lipschitz parameter of our loss function, i.e.,L=supw∈Ω/bardbl∇F(w)/bardblwhere Ωdenotes the
parameter space. Then we have the following lower bound:
−λiL≤−/bardblE[Ui(ˆw)]/bardbl/bardbl∇F(ˆw)/bardbl≤E[Ui(ˆw)]/latticetop∇F(ˆw)<0 (4)
whereλi= supw∈Ω/bardblE[Ui(w)]|/bardbl.
Suppose that an adversary can successfully attack qaggregation rules (W.L.O.G. assume AGG 1,···,AGGq
are compromised). We denote
λ= max
i∈[q]λi.
Letw∈Ω. Other aggregation rules AGGm/primeform/prime∈[M]\[q]are resilient against this attack and satisfy
E[Um/prime(w)]/latticetop∇F(w)≥βm/prime
for someβm/prime>0.
Note thatβm/primedepends on the the gradient variance and bounds on the heterogeneity of gradients across
workers. In Section 4, we obtain βfor a generalized version of Krum.
19Published in Transactions on Machine Learning Research (10/2022)
Recall that MixTailor outputs a rule U(w)∈{U1(w),···,UM(w)}uniformly at random. Combining the
lower bounds above, we have
E[U(w)]/latticetop∇F(w)≥M−q
M/parenleftbig
min
m/primeβm/prime/parenrightbig
−q
MλL.
Finally, a suﬃcient condition for Byzantine-resilience in term of Deﬁnition 1 is that Mis large enough to
satisfy:
M
q>1 +λL
minm/primeβm/prime.
A.4 Optimal and alternative training-time attack design
In this section, we ﬁrst deﬁne an optimal training-time attack.
Deﬁnition 2. LetAGGdenote an aggregation rule. An optimal attack is any vector [B1,B2,···,Bf]/latticetop∈Rfd
such that
AGG(B1,···,Bf,Vf+1,···,Vn)/latticetopn/summationdisplay
i=1Vi/n≤0.
By optimality of an attack, we refer to almost sure convergence guarantees for the problem max wF(w)
instead of the original problem in (1). Assuming such an attack exists given a pool of aggregators, along the
lines of (Bottou, 1998, Section 5.2), the outputs of the aggregation rule are guaranteed to converge to local
maxima of F,i.e.,the attack provably corrupts training. In the following, we consider an alternative attack
design based on a min-max problem.
Alternative attack design. Now suppose there is a similarity ﬁlter, which rejects all similar updates. To
circumvent such a ﬁlter, the adversary can design a tailored attack by solving the following min max problem:8
P1: min
(B1,···,Bf)max
m∈[M]AGGm(B1,···,Bf,Vf+1,···,Vn)/latticetopn/summationdisplay
i=1Vi
n
subject to/bardblBi−Bj/bardbl≥/epsilon1,∀(i,j).
Letξ,maxm∈[M]AGGm(B1,···,Bf,Vf+1,···,Vn)/latticetop
/summationtextn
i=1Vi/ndenote the solution to the inner maximization problem. Then P1is equivalent to the following
problem:
P2: min
(B1,···,Bf),ξξ
subject to AGG m(B1,···,Bf,Vf+1,···,Vn)/latticetopn/summationdisplay
i=1Vi
n≤ξ,∀m,
/bardblBi−Bj/bardbl≥/epsilon1∀(i,j).
We note that if the optimal value of P2is negative, i.e.,ξ(/epsilon1)∗<0, the solution will be a theoretically
guaranteed and successful attack to circumvent MixTailor algorithm. Note that such an attack circumvents
the similarity ﬁlter too. P2can be infeasible. In general, P2is an NP-hard problem due to complex and
nonconvex constraints. Even by ignoring a similarity ﬁlter and restricting the search space, the adversary
should solve this nonconvex problem:
P3: min
λ,ξξ
8Suboptimal attacks, attacks under partial knowledge, and model-based tailored attacks can be designed along the lines of
Appendix A.1.
20Published in Transactions on Machine Learning Research (10/2022)
subject to vm(λ)/latticetopn/summationdisplay
i=1Vi
n≤ξ,∀m∈[M].
where vm(λ) = AGG m(−λn/summationdisplay
i=1Vi,···,−λn/summationdisplay
i=1Vi
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
f,Vf+1,···,Vn).
We note theP3is not guaranteed to be feasible. If feasible, a solution might be obtained by relaxing the
nonconvex constraint to a convex one. Developing eﬃcient algorithms to solve this problem approximately is
an interesting future direction.
Intersection of upper bounds in (Fang et al., 2020, Theorem 1) and lower bounds in (Xie
et al., 2020b, Theorem 1). In (Fang et al., 2020, Theorem 1), an upper bound is established on the
norm of the attack vector that is tailored against Krum. In particular, λ=O(1/√
d)fails Krum. Let
g=1
n−f/summationtextn
i=f+1E[gi]denote expected value of honest updates sent by good workers. Building on a similar
argument as in (Xie et al., 2020b, Theorem 1) and (Hawkins, 1971, Theorem 1(b)), a lower bound on λtailored
against comed is given by λ= Ω/parenleftBig/vextendsingle/vextendsingle/vextendsingle1−ˆσ√
n−f−1/bardblg/bardbl∞/vextendsingle/vextendsingle/vextendsingle/parenrightBig
where ˆσis the coordinate-wise variance deﬁned in (Xie
et al., 2020b, Theorem 1). A suﬃcient condition that guarantees emptiness of the intersection for an attack,
which fails both Krum and comed is that the variance ˆσis large enough such thatˆσ√
n−f−1/bardblg/bardbl∞≥1−1√
d.
A.5 Proof of Theorem 1
Leti∗denote the index of the worker selected by (3). Using Jensen’s inequality, we have
/bardblE[U]−∇F/bardbl2
2=/vextenddouble/vextenddouble/vextenddoubleE/bracketleftBig
U−1
|Ng(i∗)|/summationdisplay
j∈Ng(i∗)Vj/bracketrightBig/vextenddouble/vextenddouble/vextenddouble2
2
≤E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleU−1
|Ng(i∗)|/summationdisplay
j∈Ng(i∗)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
.
The law of total expectation implies
/bardblE[U]−∇F/bardbl2
2≤n−f/summationdisplay
i=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−1
|Ng(i)|/summationdisplay
j∈Ng(i)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
Pr(i∗=i)
+f/summationdisplay
k=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
Pr(i∗=k).
In the following we develop upper bounds that hold for each conditional expectation uniformly over i∈[n−f]
andk∈[f].
LetVi∈G. We ﬁrst ﬁnd an upper bound on E/bracketleftbig/vextenddouble/vextenddoubleVi−1
|Ng(i)|/summationtext
j∈Ng(i)Vj/vextenddouble/vextenddouble2
2/bracketrightbig
. Using the Jensen’s inequity and
the variance upper bound σ2, we can show that
E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−1
|Ng(i)|/summationdisplay
j∈Ng(i)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤1
|Ng(i)|/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤2σ2.
21Published in Transactions on Machine Learning Research (10/2022)
Note that above upper bound holds for all Vi∈G. Now letBk∈Bdenote a Byzantine worker that is selected
by (3). For all good Vi∈G, we have
/summationdisplay
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(k)/vextenddouble/vextenddoubleBk−Bl/vextenddouble/vextenddouble2
p
≤/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
p.(5)
Note that Jensen’s inequality implies that
E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤1
|Ng(k)|/summationdisplay
j∈Ng(k)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
.
In the rest of our proof, we use the following lemma.
Lemma 1. Letx∈Rd. Then, for all 0<p<q, we have/bardblx/bardblq≤/bardblx/bardblp≤d1/p−1/q/bardblx/bardblq.
Letp≥2. By Lemma 1, we have
/bardblBk−Vj/bardbl2
2≤d1−2/p/bardblBk−Vj/bardbl2
p.
Combining the above inequality with (5), it follows that
1
|Ng(k)|/summationdisplay
j∈Ng(k)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤d1−2/p
|Ng(k)|/parenleftBig/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig
+/summationdisplay
l∈Nb(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig/parenrightBig
.(6)
The following lemma is useful for our proofs.
Lemma 2. Leti∈[n]. Then we have
0≤Nb(i)≤f
n−2f−2≤Ng(i)≤n−f−2.
By Lemmas 1 and 2, we have
d1−2/p
|Ng(k)|/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig
≤d1−2/p
|Ng(k)|/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤2σ2d1−2/p|Ng(i)|
|Ng(k)|
≤2σ2d1−2/pn−f−2
n−2f−2.
Sincef <n/ 2, for eachl∈Nb(i)andVi∈G, there exists an ζ(i)such thatVζ(i)∈Gsuch that
/bardblVi−Bl/bardbl2
p≤/bardblVi−Vζ(i)/bardbl2
p.
By Lemma 1 and the law to total expectation, for all Vi∈G, we have
22Published in Transactions on Machine Learning Research (10/2022)
E[/bardblVi−Vζ(i)/bardbl2
p]≤E[/bardblVi−Vζ(i)/bardbl2
2]
≤E[/bardblVi−Vj/bardbl2
2] Pr(ζ(i) =j)
≤2σ2.
By Lemma 2, we have
d1−2/p
|Ng(k)|/summationdisplay
l∈Nb(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig
≤2d1−2/pσ2|Nb(i)|
|Ng(k)|
≤2d1−2/pσ2f
n−2f−2.
Combining above upper bounds, we have /bardblE[U(w)]−∇F(w)/bardbl2
2≤2σ2/parenleftBig
1 +d1−2/p/parenleftBig
n−f−2
n−2f−2+f
n−2f−2/parenrightBig/parenrightBig
.
Now let 1≤p≤2. By Lemma 1, we have
ξ(Ng(k))≤/summationdisplay
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
p
≤/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
p
≤d2/p−1/parenleftBig/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
2+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
2/parenrightBig
.
whereξ(Ng(k)) =/summationtext
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
2.
Following a similar approach, we obtain /bardblE[U(w)]−∇F(w)/bardbl2
2≤2σ2/parenleftBig
1 +d2/p−1/parenleftBig
n−f−2
n−2f−2+f
n−2f−2/parenrightBig/parenrightBig
.
For the last part of the proof, using the law of total expectation, we have
E[/bardblU/bardblr
2]≤E[/bardblG/bardblr
2] +f/summationdisplay
k=1E[/bardblBk/bardblr
2] Pr(i∗=k).
LetBk∈Bdenote a Byzantine worker that is selected by (3). Using Lemma 1, for all good Vi∈G, we have
/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2≤/radicalbig
∆p
≤Cn−f/summationdisplay
i=1/bardblVi/bardbl2
where ∆p=Cd,p
|Ng(k)|/summationtext
j∈Ng(i)/bardblVi−Vj/bardbl2
p+Cd,p|Nb(i)|
|Ng(k)|/bardblVi−Vζ(i)/bardbl2
pandCd,p=dmax{p,2}−min{p,2}
p. Note that
/bardblBk/bardbl2≤/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2+/vextenddouble/vextenddouble/vextenddouble1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2
≤Cn−f/summationdisplay
i=1/bardblVi/bardbl2.
This follows that
/bardblBk/bardblr
2≤C/summationdisplay
r1+···+rn−f=r/bardblV1/bardblr1
2···/bardblVn−f/bardblrn−f
2.
23Published in Transactions on Machine Learning Research (10/2022)
Taking expectation and applying weighted AMâĂŞGM inequality, we have
E[/bardblBk/bardblr
2]≤C/summationdisplay
r1+···+rn−f=r/parenleftBigr1
r/bardblV1/bardblr1
2+···+rn−f
r/bardblVn−f/bardblrn−f
2/parenrightBig
≤CE[/bardblG/bardblr
2].
This completes the proof.
A.6 Proof of Theorem 2
Leti∗denote the index of the worker selected by (3). Using Jensen’s inequality, we have
/bardblE[U]−∇F/bardbl2
2=/vextenddouble/vextenddouble/vextenddoubleE/bracketleftBig
U−1
n−fn−f/summationdisplay
j=1Vj/bracketrightBig/vextenddouble/vextenddouble/vextenddouble2
2
≤E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleU−1
n−fn−f/summationdisplay
j=1Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
.
The law of total expectation implies
/bardblE[U]−∇F/bardbl2
2≤n−f/summationdisplay
i=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−1
n−fn−f/summationdisplay
j=1Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
Pr(i∗=i)
+f/summationdisplay
k=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−1
n−fn−f/summationdisplay
j=1Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
Pr(i∗=k).
In the following we develop upper bounds that hold for each conditional expectation uniformly over i∈[n−f]
andk∈[f].
LetVi∈G. We ﬁrst ﬁnd an upper bound on E/bracketleftbig/vextenddouble/vextenddoubleVi−1
n−f/summationtextn−f
j=1Vj/vextenddouble/vextenddouble2
2/bracketrightbig
. We use the following lemma in our
proofs.
Lemma 3. Letu,v∈Rd. Then we have
/bardblu+v/bardbl2≤2/bardblu/bardbl2+ 2/bardblv/bardbl2.
Using the Jensen’s inequity and Lemma 3 under Assumption 1, we can show that
δ(Vi)≤1
n−fn−f/summationdisplay
j=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−gi/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
+1
n−fn−f/summationdisplay
j=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVj−gi/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤2σ2+1
n−fn−f/summationdisplay
j=1/bardblgj−gi/bardbl2
2
≤2σ2+ 2/bardblgi−∇F/bardbl2
2+2
n−fn−f/summationdisplay
j=1/bardblgj−∇F/bardbl2
2
≤2σ2+ 2(n−f+ 1)∆2
whereδ(Vi) =E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−1
n−f/summationtextn−f
j=1Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
.
24Published in Transactions on Machine Learning Research (10/2022)
Note that above upper bound holds for all Vi∈G. Now letBk∈Bdenote a Byzantine worker that is selected
by (3). By Lemma 3, we have
E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−1
n−fn−f/summationdisplay
j=1Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤2E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
+ 2E/bracketleftBig/vextenddouble/vextenddouble/vextenddouble1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj−1
n−fn−f/summationdisplay
l=1Vl/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
.
We ﬁrst ﬁnd an upper bound on the second term. Note that Jensen’s inequality implies that
δ(Ng(k))≤1
|Ng(k)|/summationdisplay
j∈Ng(k)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVj−1
n−fn−f/summationdisplay
l=1Vl/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤1
|Ng(k)|/summationdisplay
j∈Ng(k)/parenleftBig1
n−fn−f/summationdisplay
l=1E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVj−Vl/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig/parenrightBig
≤2σ2+1
|Ng(k)|/summationdisplay
j∈Ng(k)/parenleftBig1
n−fn−f/summationdisplay
l=1/bardblgj−gl/bardbl2
2/parenrightBig
≤2σ2+ 2/parenleftBign−f
|Ng(k)|+ 1/parenrightBig
∆2
≤2σ2+ 2/parenleftBign−f
n−2f−2+ 1/parenrightBig
∆2
whereδ(Ng(k)) =E/bracketleftbig/vextenddouble/vextenddouble 1
|Ng(k)|/summationtext
j∈Ng(k)Vj−1
n−f/summationtextn−f
l=1Vl/vextenddouble/vextenddouble2
2/bracketrightbig
.
We now ﬁnd an upper bound on E/bracketleftbig/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationtext
j∈Ng(k)Vj/vextenddouble/vextenddouble2
2/bracketrightbig
. The Jensen’s inequality implies that
E/bracketleftbig/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationtext
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤1
|Ng(k)|/summationtext
j∈Ng(k)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
2/bracketrightbig
.For all good Vi∈G, we have
/summationdisplay
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(k)/vextenddouble/vextenddoubleBk−Bl/vextenddouble/vextenddouble2
p
≤/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
p.(7)
Letp≥2. By Lemma 1 and inequality (7), we have
1
|Ng(k)|/summationdisplay
j∈Ng(k)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤d1−2/p
|Ng(k)|/parenleftBig/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig
+/summationdisplay
l∈Nb(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig/parenrightBig
.(8)
By Lemmas 1 and 2, we have
˜∆p≤d1−2/p
|Ng(k)|/summationdisplay
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
2/bracketrightBig
≤d1−2/p 1
|Ng(k)|/parenleftBig
2σ2|Ng(i)|+/summationdisplay
j∈Ng(i)/bardblgi−gj/bardbl2
2/parenrightBig
≤/parenleftbig
2σ2+ 4(n−f)∆2/parenrightbig
d1−2/p|Ng(i)|
|Ng(k)|
25Published in Transactions on Machine Learning Research (10/2022)
≤/parenleftbig
2σ2+ 4(n−f)∆2/parenrightbig
d1−2/pn−f−2
n−2f−2
where ˜∆p=d1−2/p
|Ng(k)|/summationtext
j∈Ng(i)E/bracketleftBig/vextenddouble/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble/vextenddouble2
p/bracketrightBig
.
Sincef <n/ 2, for eachl∈Nb(i)andVi∈G, there exists an ζ(i)such thatVζ(i)∈Gsuch that
/bardblVi−Bl/bardbl2
p≤/bardblVi−Vζ(i)/bardbl2
p.
By Lemma 1 and the law to total expectation, for all Vi∈G, we have
E[/bardblVi−Vζ(i)/bardbl2
p]≤E[/bardblVi−Vζ(i)/bardbl2
2]
≤E[/bardblVi−Vj/bardbl2
2] Pr(ζ(i) =j)
≤2σ2+ 4(n−f)∆2.
By Lemma 2, we have
ˆ∆p≤/parenleftbig
2σ2+ 4(n−f)∆2/parenrightbig
d1−2/p|Nb(i)|
|Ng(k)|
≤/parenleftbig
2σ2+ 4(n−f)∆2/parenrightbig
d1−2/pf
n−2f−2
where ˆ∆p=d1−2/p
|Ng(k)|/summationtext
l∈Nb(i)E/bracketleftbig/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
p/bracketrightbig
.
Combining above upper bounds, we have /bardblE[U(w)]−∇F(w)/bardbl2
2≤C1+C2d1−2/p/parenleftbign−f−2
n−2f−2+f
n−2f−2/parenrightbig
.
Now let 1≤p≤2. By Lemma 1, we have
ξ(Ng(k))≤/summationdisplay
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
p
≤/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
p+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
p
≤d2/p−1/parenleftBig/summationdisplay
j∈Ng(i)/vextenddouble/vextenddoubleVi−Vj/vextenddouble/vextenddouble2
2+/summationdisplay
l∈Nb(i)/vextenddouble/vextenddoubleVi−Bl/vextenddouble/vextenddouble2
2/parenrightBig
whereξ(Ng(k)) =/summationtext
j∈Ng(k)/vextenddouble/vextenddoubleBk−Vj/vextenddouble/vextenddouble2
2.
Following a similar approach, we obtain /bardblE[U(w)]−∇F(w)/bardbl2
2≤C1+C2d2/p−1/parenleftbign−f−2
n−2f−2+f
n−2f−2/parenrightbig
.
Finally, under Assumption 2 and using the law of total expectation, we have
E[/bardblU/bardblr
2]≤n−f/summationdisplay
i=1Kr,iE[/bardblG/bardblr
2] +f/summationdisplay
k=1E[/bardblBk/bardblr
2] Pr(i∗=k).
LetBk∈Bdenote a Byzantine worker that is selected by (3). Using Lemma 1, for all good Vi∈G, we have
/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2≤/radicalbig
∆p
≤Cn−f/summationdisplay
i=1/bardblVi/bardbl2
26Published in Transactions on Machine Learning Research (10/2022)
Table 2: Training hyper-parameters for CIFAR-10 and MNIST. The network architecture is a 4 layer neural net with
2 convolutional layers and two fully connected layers. Drop out is used between the convulutional layers and the fully
connected layers.
Hyper-parameterCIFAR-
10MNIST
Learning Rate 0.001 0.001
Batch Size 80 50
Momentum 0.9 0.9
Total Iterations 40K 50K
Weight Decay 10−410−4
and∆p=Cd,p
|Ng(k)|/summationtext
j∈Ng(i)/bardblVi−Vj/bardbl2
p+Cd,p|Nb(i)|
|Ng(k)|/bardblVi−Vζ(i)/bardbl2
pandCd,p=dmax{p,2}−min{p,2}
p. Furthermore,
we have
/bardblBk/bardbl2≤/vextenddouble/vextenddouble/vextenddoubleBk−1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2+/vextenddouble/vextenddouble/vextenddouble1
|Ng(k)|/summationdisplay
j∈Ng(k)Vj/vextenddouble/vextenddouble/vextenddouble
2
≤Cn−f/summationdisplay
i=1/bardblVi/bardbl2.
This follows that
/bardblBk/bardblr
2≤C/summationdisplay
r1+···+rn−f=r/bardblV1/bardblr1
2···/bardblVn−f/bardblrn−f
2.
Taking expectation and applying weighted AMâĂŞGM inequality, we have E[/bardblBk/bardblr
2]≤
C/summationtext
r1+···+rn−f=r/parenleftBig
r1
r/bardblV1/bardblr1
2+···+rn−f
r/bardblVn−f/bardblrn−f
2/parenrightBig
≤CE[/bardblG/bardblr
2],which completes the proof.
A.7 Proof of Theorem 3
LetR={w|/bardblw/bardbl2
2≥R}denote a horizon. Following Theorem 2, we note that
2E[U(w)]/latticetop∇F(w)≥/bardblE[U(w)]/bardbl2
2+/bardbl∇F(w)/bardbl2
2−˜C
≥inf
w∈R/parenleftbig
/bardblE[U(w)]/bardbl2
2+/bardbl∇F(w)/bardbl2
2/parenrightbig
−˜C
≥inf
w∈R/bardblE[U(w)]/bardbl2
2+ inf
w∈R/bardbl∇F(w)/bardbl2
2−˜C
≥β
where ˜C=C1+C2Λ(n,f,d,p ).
Combining this bound with
inf
w∈Rw/latticetop∇F(w)
/bardblw/bardbl2/bardbl∇F(w)/bardbl2≥cos(θ)
and noting θ+supw∈Rα<π/ 2, we have w/latticetopE[U(w)]>0forw∈R. The rest of the proof follows along the
lines of (Fisk, 1965; Métivier, 1982; Bottou, 1998).
We note that median-based aggregators such as Krum, comed, and Bulyan do not necessarily output an
unbiased estimate of the gradient of the true empirical risk (Karimireddy et al., 2021, Section 3).
A.8 Experimental details and additional experiments
In this section, we run a series of experiments to ﬁnd out the eﬀect of individual aggregators in the pool
of aggregators. As explained in the main body, the pool of aggregators contains four diﬀerent aggregation
mechanism. In this section, we remove one aggreagtor from the pool, to see what will be the eﬀect.
27Published in Transactions on Machine Learning Research (10/2022)
0 1 2 3 4 5
Training Iteration 1e460708090100Test Accuracy (%)AGG=MixTailor,w/o=Comed
AGG=MixTailor,w/o=Bulyan
AGG=MixTailor,w/o=Geomed
AGG=MixTailor,w/o=Krum
AGG=MixTailor,w/o=N/A
AGG=Omniscient
(a)/epsilon1= 0.1
0 1 2 3 4 5
Training Iteration 1e460708090100Test Accuracy (%)AGG=MixTailor,w/o=Bulyan
AGG=MixTailor,w/o=Comed
AGG=MixTailor,w/o=Geomed
AGG=MixTailor,w/o=Krum
AGG=MixTailor,w/o=N/A
AGG=Omniscient (b)/epsilon1= 10
Figure 5: Test accuracy on MNIST for the tailored attack, which is applied at each iteration. The total number of
workers and the number of Byzantines are set to n= 12andf= 2, respectively. The dataset is randomly and equally
partitioned among workers. The omniscient aggregator receives and averages 10 honest gradients at each iteration.
0 1 2 3 4 5
Training Iteration 1e4020406080100Test Accuracy (%)AGG=Omniscient
AGG=MixTailor
AGG=Comed
AGG=Krum
Figure 6: Test accuracy on MNIST under “A Little” attack (Baruch et al., 2019). The total number of workers and
the number of Byzantines are set to n= 12andf= 2, respectively. The dataset is randomly and equally partitioned
among workers. The omniscient aggregator receives and averages 10 honest gradients at each iteration.
Details of implementation. The details of training hyper-parameters are shown in Table 2. The network
architecture is a 4 layer neural net with 2 convolutional layers + two fully connected layers. Drop out is used
between the convulutional layers and the fully connected layers. All experiments where run on single-GPU
machines using a cluster that had access to T4, RTX6000, and P100 GPUs.
Fig. 5 shows the result when one of the aggregators is removed from the pool. The w/o tag represents the
aggregator that is not included in the pool. We observe that under both attacks, removing the Bulyan from
the pool of aggregators increases the validation accuracy by around 2%. Also, it is worth noting that removing
the geometric median reduces the accuracy, which is expected since these tailored attacks are designed for
Krum and comed.
Fig. 6 shows the performance of MixTailor under “A Little” attack in (Baruch et al., 2019). To observe
resilience of diﬀerent aggregation methods decoupled from momentum, we set momentum to zero in this
experiment. We observe that all aggregation methods including MixTailor are resilient against “A Little”
attack in this setting. This observation conﬁrms that tailored attacks in (Fang et al., 2020; Xie et al., 2020b)
are more eﬀective than “A Little” attack. We emphasize that both Krum and comed fail under carefully
designed tailored attacks with f= 2Byzantines with and without momentum, which is not the case for “A
Little” attack.
28Published in Transactions on Machine Learning Research (10/2022)
0 1 2 3 4 5
Training Iteration 1e4406080100Test Accuracy (%)AGG=Krum
AGG=Comed
AGG=MixTailor
AGG=Omniscient
Figure 7: Test accuracy on MNIST under adaptive attack. MixTailor is robust to the adaptive attack. The
rest of the setup is similar to Fig. 1.
MixTailor under an adaptive attack. We have considered a stronger and adaptive attacker which
optimizes its attack by enumerating over a set of /epsilon1’s and selects the worst/epsilon1against the aggregator at every
single iteration . The adversary enumerates among all those /epsilon1’s and ﬁnds out which one is the most eﬀective
attack by applying the aggregator (the attacker simulates the server job by applying the aggregator with
diﬀerent/epsilon1’s and ﬁnds the best attack and then outputs the best attack for the server to aggregate). Regarding
MixTailor, the attacker selects a random aggregator from the MixTailor’s aggregator pool in each iteration
and ﬁnds the worst epsilon corresponding to this aggregator. The attacker ﬁnds an adaptive attack by
calculating the dot product of the output of the aggregator and the direction of aggregated gradients without
attacks when diﬀerent epsilons are fed into the aggregator. The attacker chooses the epsilon that causes
the aggregator to produce the gradient that has the smallest dot product with the true gradient. In Fig. 7,
we ran this experiment over MNIST and observe that MixTailor is able to outperform both Krum and
Comed. Comed’s accuracy changes between 85-87%, Krum’s accuracy is 83-85%, and MixTailor’s accuracy is
91.80-92.55%. The accuracy of the omniscient aggregator is 97.62-97.68%. The set of epsilons used by the
adaptive attacker is 0.1, 0.5, 1, and 10.
29