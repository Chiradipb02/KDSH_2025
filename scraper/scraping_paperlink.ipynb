{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: /path/to/scrape_neurips.py\n",
    "# Initialize WebDriver\n",
    "service = Service('C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver-win64\\\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperlinks(url_list):\n",
    "    all_papers = {}\n",
    "    for url_ in url_list:\n",
    "        url = f\"https://openreview.net/group?id=TMLR&referrer=%5BHomepage%5D(%2F)#tab-{url_}\"\n",
    "        print(f\"Scraping {url}...\")\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        driver.get(url)\n",
    "        time.sleep(10)\n",
    "        papers = []\n",
    "        try:\n",
    "            while True:\n",
    "                # Wait for the page to load\n",
    "                time.sleep(3)\n",
    "                \n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                print(\"HI\")\n",
    "                # Extract all hyperlinks\n",
    "                # only extract hyperlinks which are within div id same as url_\n",
    "                # first extract the part within the div id\n",
    "                div = soup.find('div', {'id': url_})\n",
    "                if div is None:\n",
    "                    break\n",
    "                # then extract all the hyperlinks within that div if it starts with /forum?id=\n",
    "                for a in div.find_all('a', href=True):\n",
    "                    if a['href'].startswith('/forum?id='):\n",
    "                        papers.append(a['href'])\n",
    "                   \n",
    "                # Try to find and click the \"Next\" button\n",
    "                try:\n",
    "                    next_button = driver.find_elements(By.CSS_SELECTOR, f'div#{url_} li.right-arrow a')[0]\n",
    "                    if 'disabled' in next_button.get_attribute('class'):\n",
    "                        print(\"No more pages.\")\n",
    "                        break\n",
    "                    print(\"Clicking the next button.\")\n",
    "                    next_button.click()\n",
    "                except Exception as e:\n",
    "                    # print(e)\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            # print(e)\n",
    "            pass\n",
    "        finally:\n",
    "            driver.quit()\n",
    "        all_papers[url_] = papers\n",
    "\n",
    "    return all_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://openreview.net/group?id=TMLR&referrer=%5BHomepage%5D(%2F)#tab-accepted-papers...\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n",
      "Clicking the next button.\n",
      "HI\n"
     ]
    }
   ],
   "source": [
    "#accept-oral\n",
    "#accept-spotlight\n",
    "#accept-poster\n",
    "#reject\n",
    "all_papers = get_hyperlinks(['accepted-papers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted-papers 1827\n"
     ]
    }
   ],
   "source": [
    "for i in all_papers:\n",
    "    print(i, len(all_papers[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/forum?id=eakh1Edffd',\n",
       " '/forum?id=bHdEtW5E7O',\n",
       " '/forum?id=MvYddudHuE',\n",
       " '/forum?id=vZGZIIgcG4',\n",
       " '/forum?id=DqWvxSQ1TK']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_papers['accepted-papers'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump in json file\n",
    "import json\n",
    "with open('tmlr_2024_papers.json', 'w') as f:\n",
    "    json.dump(all_papers, f, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
